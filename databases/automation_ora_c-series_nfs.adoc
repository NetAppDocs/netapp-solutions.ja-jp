---
sidebar: sidebar 
permalink: databases/automation_ora_c-series_nfs.html 
keywords: Database, Oracle, Azure, ANF, Ansible, Automation 
summary: この解決策では、NFSプロトコルを使用したプライマリデータベースストレージとしてのNetApp AFF CシリーズへのOracleの自動導入の概要と詳細について説明します。Oracleデータベースは、dNFSを有効にしたコンテナデータベースとして導入されます。 
---
= TR-4992：『Simplified、Automated Oracle Deployment on NetApp C-Series with NFS』
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


ネットアップ、Niyaz Mohamed、Allen Cao氏

[role="lead"]
この解決策では、NFSプロトコルを使用したプライマリデータベースストレージとしてのNetApp AFF CシリーズへのOracleの自動導入の概要と詳細について説明します。Oracleデータベースは、dNFSを有効にしたコンテナデータベースとして導入されます。



== 目的

NetApp AFF Cシリーズは、オールフラッシュのアクセス性を高め、ユニファイドストレージを低コストで実現する大容量フラッシュストレージです。多くのティア1またはティア2のOracleデータベースワークロードに対して十分なパフォーマンスが得られます。NetApp ONTAP®データ管理ソフトウェアを搭載したAFF Cシリーズシステムは、業界をリードする効率性、卓越した柔軟性、業界最高のデータサービス、クラウド統合機能を提供し、ITインフラの拡張、データ管理の簡易化、ストレージコストと消費電力の削減を実現します。

このドキュメントでは、Ansibleの自動化機能を使用したNFSマウントを使用して、NetApp CシリーズにOracleデータベースを簡単に導入する方法について説明します。Oracleデータベースは、Oracle dNFSプロトコルを有効にしたコンテナデータベース（CDB）およびプラガブルデータベース（PDB）構成に導入され、パフォーマンスが向上します。さらに、解決策には、CシリーズのストレージコントローラでNFSプロトコルを使用してストレージネットワークとStorage Virtual Machine（SVM）を設定する際のベストプラクティスが記載されています。解決策には、NetApp SnapCenter UIツールを使用したOracleデータベースの高速バックアップ、リストア、クローニングに関する情報も含まれています。

この解決策 は、次のユースケースに対応します。

* NetApp CシリーズストレージコントローラへのOracleコンテナデータベースの自動導入
* Cシリーズでは、SnapCenter UIツールを使用したOracleデータベースの保護とクローン作成が可能です。




== 対象者

この解決策 は、次のユーザーを対象としています。

* NetApp CシリーズにOracleを導入したいと考えているデータベース管理者。
* データベース解決策アーキテクト。NetApp CシリーズでOracleワークロードのテストを実施したいと考えています。
* NetApp CシリーズにOracleデータベースを導入して管理したいと考えているストレージ管理者。
* NetApp CシリーズでOracleデータベースを構築するアプリケーション所有者。




== 解決策 のテストおよび検証環境

この解決策のテストと検証は、最終的な導入環境とは一致しない可能性があるラボ環境で実行しました。を参照してください <<導入にあたって考慮すべき主な要因>> を参照してください。



=== アーキテクチャ

image::automation_ora_c-series_nfs_archit.png[このイメージは、iSCSIとASMを使用したAWSパブリッククラウドでのOracle導入構成の詳細な図を示しています。]



=== ハードウェアおよびソフトウェアコンポーネント

[cols="33%, 33%, 33%"]
|===


3+| * ハードウェア * 


| NetApp CシリーズC400 | ONTAPバージョン9.13.1P3 | ディスクシェルフ×2 /ディスク×24、容量278TiB 


| DBサーバ用VM | vCPU×4、16GiB RAM | 2つのLinux VMインスタンスによる同時導入 


| SnapCenter用VM | vCPU×4、16GiB RAM | Windows VMインスタンス×1 


3+| *ソフトウェア* 


| Red Hat Linux | RHEL Linux 8.6（LVM）- x64 Gen2 | テスト用にRedHatサブスクリプションを導入 


| Windows Serverの場合 | 2022年データセンターx64 Gen2 | SnapCenterサアハノホスト 


| Oracle データベース | バージョン19.18 | RUパッチp34765931_190000_Linux-x86-64.zipを適用しました 


| Oracle OPatchの略 | バージョン12.2.0.1.36 | 最新のパッチp6880880_190000_Linux-x86-64.zip 


| SnapCenter サーバ | バージョン5.0 | ワークグループの導入 


| JDKを開く | バージョンjava-11-openjdk | DB VMでのSnapCenterプラグインの要件 


| NFS | バージョン 3.0 以降 | Oracle dNFSが有効 


| Ansible | コア2.16.2 | Python 3.6.8 
|===


=== ラボ環境でのOracleデータベースの構成

[cols="33%, 33%, 33%"]
|===


3+|  


| * サーバ * | * データベース * | * DBストレージ* 


| ORA_01 | NTAP1（NTAP1_PDB1、NTAP1_PDB2、NTAP1_PDB3） | /u01、/u02、/u03 C400ボリュームへのNFSマウント 


| ORA_02 | NTAP2（NTAP2_PDB1、NTAP2_PDB2、NTAP2_PDB3） | /u01、/u02、/u03 C400ボリュームへのNFSマウント 
|===


=== 導入にあたって考慮すべき主な要因

* * Oracleデータベースのストレージレイアウト。*この自動化されたOracle導入では、Oracleのバイナリ、データ、ログをホストするために、各データベースに3つのデータベースボリュームをデフォルトでプロビジョニングします。ボリュームは、NFS経由で/u01-binary、/u02-data、/u03-logsとしてOracle DBサーバにマウントされます。冗長性を確保するために、/u02と/u03のマウントポイントにデュアル制御ファイルが設定されています。
* *複数のDBサーバの導入。*自動化解決策では、1回のAnsibleプレイブック実行でOracleコンテナデータベースを複数のDBサーバに導入できます。DBサーバの数に関係なく、プレイブックの実行は変わりません。複数のコンテナデータベースを1つのVMインスタンスに導入するには、別 々 のデータベースインスタンスID（Oracle SID）を使用して同じ環境を繰り返します。ただし、導入したデータベースをサポートするのに十分なメモリがホストにあることを確認してください。
* * dNFS構成。* dNFS（Oracle 11g以降で利用可能）を使用すると、DB VM上で実行されるOracleデータベースは、ネイティブNFSクライアントよりも大幅に多くのI/Oを処理できます。Oracleの自動導入では、NFSv3にdNFSがデフォルトで設定されます。
* * C400コントローラペアでのロードバランシング。* OracleデータベースボリュームをC400コントローラノードに均等に配置して、ワークロードを分散します。DB1をコントローラ1に、DB2をコントローラ2に（以下同様）。DBボリュームをローカルのLIFアドレスにマウントします。
* *データベースのバックアップ。* NetAppは、データベースのバックアップ、リストア、クローニングを実行するためのSnapCenterソフトウェアスイートで、使いやすいUIインターフェイスを備えています。NetAppでは、このような管理ツールを実装して、高速（1分未満）のSnapshotバックアップ、高速（数分）のデータベースリストア、データベースクローンを実現することを推奨しています。




== 解決策 の導入

以降のセクションでは、Oracle 19Cの自動導入の手順と、導入後のOracleデータベースの保護とクローニングについて説明します。



=== 導入の前提条件

[%collapsible]
====
導入には、次の前提条件が必要です。

. NetApp Cシリーズストレージコントローラペアがラックに設置され、スタックされ、最新バージョンのONTAPオペレーティングシステムがインストールされて設定されている。必要に応じて、このセットアップガイドを参照してください。 https://docs.netapp.com/us-en/ontap-systems/c400/install-detailed-guide.html#step-1-prepare-for-installation["詳細ガイド- AFF C400"^]
. 2台のLinux VMをOracle DBサーバとしてプロビジョニング環境のセットアップの詳細については、前のセクションのアーキテクチャ図を参照してください。
. NetApp SnapCenter UIツールを最新バージョンで実行するようにWindowsサーバをプロビジョニングします。詳細については、次のリンクを参照してください。 link:https://docs.netapp.com/us-en/snapcenter/install/task_install_the_snapcenter_server_using_the_install_wizard.html["SnapCenter サーバをインストールします"^]
. 最新バージョンのAnsibleとGitがインストールされたAnsibleコントローラノードとしてLinux VMをプロビジョニングします。詳細については、次のリンクを参照してください。 link:../automation/getting-started.html["NetApp解決策 自動化の導入"^] セクション-
`Setup the Ansible Control Node for CLI deployments on RHEL / CentOS` または
`Setup the Ansible Control Node for CLI deployments on Ubuntu / Debian`。
+
AnsibleコントローラとデータベースVMの間のSSH公開鍵/秘密鍵認証を有効にします。

. Ansibleコントローラの管理者ユーザのホームディレクトリから、NetApp向けのOracle Deployment Automation Toolkitのコピーをクローニングします。
+
[source, cli]
----
git clone https://bitbucket.ngage.netapp.com/scm/ns-bb/na_oracle_deploy_nfs.git
----
. 777権限のDB vm/tmp/archiveディレクトリにOracle 19Cインストールファイルをステージングします。
+
....
installer_archives:
  - "LINUX.X64_193000_db_home.zip"
  - "p34765931_190000_Linux-x86-64.zip"
  - "p6880880_190000_Linux-x86-64.zip"
....


====


=== Cシリーズfor OracleでのネットワークとSVMの設定

[%collapsible]
====
このセクションでは、ONTAP System ManagerのUIを使用して、NFSプロトコルを使用するOracleワークロード向けにCシリーズコントローラのネットワークとStorage Virtual Machine（SVM）を設定するためのベストプラクティスについて説明します。

. ONTAP System Managerにログインして、ONTAPクラスタの初回インストール後にブロードキャストドメインに各ドメインに適切に割り当てられたイーサネットポートが設定されていることを確認します。通常は、クラスタ用のブロードキャストドメイン、管理用のブロードキャストドメイン、データなどのワークロード用のブロードキャストドメインを使用します。
+
image::automation_ora_c-series_nfs_net_01.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. ネットワーク-イーサネットポートで、 `Link Aggregate Group` LACPリンクアグリゲートグループポートa0aを作成して、アグリゲートグループポートのメンバーポート間で負荷分散とフェイルオーバーを実現します。C400コントローラでは、4つのデータポート（e0e、e0f、e0g、e0h）を使用できます。
+
image::automation_ora_c-series_nfs_net_02.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. グループ内のイーサネットポートを選択します。 `LACP` モードの場合、および `Port` 負荷分散用。
+
image::automation_ora_c-series_nfs_net_03.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. 作成されたLACPポートa0aとブロードキャストドメインを検証 `Data` はLACPポートで動作しています。
+
image::automation_ora_c-series_nfs_net_04.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

+
image::automation_ora_c-series_nfs_net_05.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. 移動元 `Ethernet Ports`をクリックします。 `VLAN` NFSプロトコルでのOracleワークロード用に各コントローラノードにVLANを追加します。
+
image::automation_ora_c-series_nfs_net_06.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

+
image::automation_ora_c-series_nfs_net_07.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

+
image::automation_ora_c-series_nfs_net_08.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. クラスタ管理IPからsshを使用してCシリーズコントローラにログインし、ネットワークフェイルオーバーグループが正しく設定されていることを確認します。ONTAPでは、フェイルオーバーグループが自動的に作成および管理されます。
+
....

HCG-NetApp-C400-E9U9::> net int failover-groups show
  (network interface failover-groups show)
                                  Failover
Vserver          Group            Targets
---------------- ---------------- --------------------------------------------
Cluster
                 Cluster
                                  HCG-NetApp-C400-E9U9a:e0c,
                                  HCG-NetApp-C400-E9U9a:e0d,
                                  HCG-NetApp-C400-E9U9b:e0c,
                                  HCG-NetApp-C400-E9U9b:e0d
HCG-NetApp-C400-E9U9
                 Data
                                  HCG-NetApp-C400-E9U9a:a0a,
                                  HCG-NetApp-C400-E9U9a:a0a-3277,
                                  HCG-NetApp-C400-E9U9b:a0a,
                                  HCG-NetApp-C400-E9U9b:a0a-3277
                 Mgmt
                                  HCG-NetApp-C400-E9U9a:e0M,
                                  HCG-NetApp-C400-E9U9b:e0M
3 entries were displayed.

....
. 移動元 `STORAGE - Storage VMs`をクリックし、[+Add]をクリックしてOracle用のSVMを作成します。
+
image::automation_ora_c-series_nfs_svm_01.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. Oracle SVMに名前を付け、 `Enable NFS` および `Allow NFS client access`。
+
image::automation_ora_c-series_nfs_svm_02.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. NFSエクスポートポリシーの追加 `Default` ルール。
+
image::automation_ora_c-series_nfs_svm_03.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. インチ `NETWORK INTERFACE`で、各ノードのNFS LIFアドレスにIPアドレスを入力します。
+
image::automation_ora_c-series_nfs_svm_04.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. SVMでOracleが稼働中でNFS LIFのステータスがアクティブであることを検証します。
+
image::automation_ora_c-series_nfs_svm_05.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

+
image::automation_ora_c-series_nfs_svm_06.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. 移動元 `STORAGE-Volumes` タブをクリックしてOracleデータベース用のNFSボリュームを追加します。
+
image::automation_ora_c-series_nfs_vol_01.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. ボリュームに名前を付け、容量を割り当て、パフォーマンスレベルを指定します。
+
image::automation_ora_c-series_nfs_vol_02.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. インチ `Access Permission`で、前の手順で作成したデフォルトポリシーを選択します。オフにする `Enable Snapshot Copies` SnapCenterを使用してアプリケーションと整合性のあるSnapshotを作成することを推奨します。
+
image::automation_ora_c-series_nfs_vol_03.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

. DBサーバごとに3つのDBボリューム（server_name_u01-binary、server_name_u02-data、server_name_u03-logs）を作成します。
+
image::automation_ora_c-series_nfs_vol_04.png[このイメージは、cシリーズコントローラの設定のスクリーンショットを示しています。]

+

NOTE: 自動化が正しく機能するように、DBボリュームの命名規則は上記の形式に厳密に従う必要があります。



これで、Oracle用のCシリーズコントローラの設定は完了です。

====


=== 自動化パラメータファイル

[%collapsible]
====
Ansible Playbookは、事前定義されたパラメータを使用してデータベースのインストールと設定のタスクを実行します。このOracle自動化解決策では、プレイブックを実行する前にユーザ入力が必要な3つのユーザ定義パラメータファイルがあります。

* Hosts -自動化プレイブックの実行対象となるターゲットを定義します。
* vars/vars.yml -すべてのターゲットに適用される変数を定義するグローバル変数ファイル。
* host_vars/host_name.yml -名前付きターゲットにのみ適用される変数を定義するローカル変数ファイル。今回のユースケースでは、これらがOracle DBサーバです。


これらのユーザー定義変数ファイルに加えて、必要でない限り変更を必要としないデフォルトパラメータを含むデフォルトの変数ファイルがいくつかあります。次のセクションでは、ユーザ定義の変数ファイルを設定する方法について説明します。

====


=== パラメータファイルの設定

[%collapsible]
====
. Ansibleターゲット `hosts` ファイル構成：
+
[source, shell]
----
# Enter Oracle servers names to be deployed one by one, follow by each Oracle server public IP address, and ssh private key of admin user for the server.
[oracle]
ora_01 ansible_host=10.61.180.21 ansible_ssh_private_key_file=ora_01.pem
ora_02 ansible_host=10.61.180.23 ansible_ssh_private_key_file=ora_02.pem

----
. グローバル `vars/vars.yml` ファイル構成
+
[source, shell]
----
######################################################################
###### Oracle 19c deployment user configuration variables       ######
###### Consolidate all variables from ONTAP, linux and oracle   ######
######################################################################

###########################################
### ONTAP env specific config variables ###
###########################################

# Prerequisite to create three volumes in NetApp ONTAP storage from System Manager or cloud dashboard with following naming convention:
# db_hostname_u01 - Oracle binary
# db_hostname_u02 - Oracle data
# db_hostname_u03 - Oracle redo
# It is important to strictly follow the name convention or the automation will fail.


###########################################
### Linux env specific config variables ###
###########################################

redhat_sub_username: XXXXXXXX
redhat_sub_password: XXXXXXXX


####################################################
### DB env specific install and config variables ###
####################################################

# Database domain name
db_domain: solutions.netapp.com

# Set initial password for all required Oracle passwords. Change them after installation.
initial_pwd_all: XXXXXXXX

----
. ローカルDBサーバ `host_vars/host_name.yml` ora_01.yml、ora_02.ymlなどの構成
+
[source, shell]
----
# User configurable Oracle host specific parameters

# Enter container database SID. By default, a container DB is created with 3 PDBs within the CDB
oracle_sid: NTAP1

# Enter database shared memory size or SGA. CDB is created with SGA at 75% of memory_limit, MB. The grand total of SGA should not exceed 75% available RAM on node.
memory_limit: 8192

# Local NFS lif ip address to access database volumes
nfs_lif: 172.30.136.68

----


====


=== Playbookの実施

[%collapsible]
====
自動化ツールキットには、合計5つのプレイブックが用意されています。それぞれが異なるタスクブロックを実行し、さまざまな目的に対応します。

....
0-all_playbook.yml - execute playbooks from 1-4 in one playbook run.
1-ansible_requirements.yml - set up Ansible controller with required libs and collections.
2-linux_config.yml - execute Linux kernel configuration on Oracle DB servers.
4-oracle_config.yml - install and configure Oracle on DB servers and create a container database.
5-destroy.yml - optional to undo the environment to dismantle all.
....
次のコマンドを使用してプレイブックを実行する方法は3つあります。

. すべての導入プレイブックを1回の組み合わせで実行します。
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml
----
. 1～4の番号順でプレイブックを1つずつ実行します。
+
[source, cli]]
----
ansible-playbook -i hosts 1-ansible_requirements.yml -u admin -e @vars/vars.yml
----
+
[source, cli]
----
ansible-playbook -i hosts 2-linux_config.yml -u admin -e @vars/vars.yml
----
+
[source, cli]
----
ansible-playbook -i hosts 4-oracle_config.yml -u admin -e @vars/vars.yml
----
. タグを指定して0-all_playbook.ymlを実行します。
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t ansible_requirements
----
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t linux_config
----
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t oracle_config
----
. 環境を元に戻す
+
[source, cli]
----
ansible-playbook -i hosts 5-destroy.yml -u admin -e @vars/vars.yml
----


====


=== 実行後の検証

[%collapsible]
====
Playbookの実行後、Oracle DBサーバVMにログインして、Oracleがインストールおよび設定され、コンテナデータベースが正常に作成されたことを確認します。次に、DB VM ora_01またはora_02でのOracleデータベース検証の例を示します。

. NFSマウントの検証
+
....

[admin@ora_01 ~]$ cat /etc/fstab

#
# /etc/fstab
# Created by anaconda on Wed Oct 18 19:43:31 2023
#
# Accessible filesystems, by reference, are maintained under '/dev/disk/'.
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info.
#
# After editing this file, run 'systemctl daemon-reload' to update systemd
# units generated from this file.
#
/dev/mapper/rhel-root   /                       xfs     defaults        0 0
UUID=aff942c4-b224-4b62-807d-6a5c22f7b623 /boot                   xfs     defaults        0 0
/dev/mapper/rhel-swap   none                    swap    defaults        0 0
/root/swapfile swap swap defaults 0 0
172.21.21.100:/ora_01_u01 /u01 nfs rw,bg,hard,vers=3,proto=tcp,timeo=600,rsize=65536,wsize=65536 0 0
172.21.21.100:/ora_01_u02 /u02 nfs rw,bg,hard,vers=3,proto=tcp,timeo=600,rsize=65536,wsize=65536 0 0
172.21.21.100:/ora_01_u03 /u03 nfs rw,bg,hard,vers=3,proto=tcp,timeo=600,rsize=65536,wsize=65536 0 0


[admin@ora_01 tmp]$ df -h
Filesystem                 Size  Used Avail Use% Mounted on
devtmpfs                   7.7G     0  7.7G   0% /dev
tmpfs                      7.8G     0  7.8G   0% /dev/shm
tmpfs                      7.8G   18M  7.8G   1% /run
tmpfs                      7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/mapper/rhel-root       44G   28G   17G  62% /
/dev/sda1                 1014M  258M  757M  26% /boot
tmpfs                      1.6G   12K  1.6G   1% /run/user/42
tmpfs                      1.6G  4.0K  1.6G   1% /run/user/1000
172.21.21.100:/ora_01_u01   50G  8.7G   42G  18% /u01
172.21.21.100:/ora_01_u02  200G  384K  200G   1% /u02
172.21.21.100:/ora_01_u03  100G  320K  100G   1% /u03

[admin@ora_02 ~]$ df -h
Filesystem                 Size  Used Avail Use% Mounted on
devtmpfs                   7.7G     0  7.7G   0% /dev
tmpfs                      7.8G     0  7.8G   0% /dev/shm
tmpfs                      7.8G   18M  7.8G   1% /run
tmpfs                      7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/mapper/rhel-root       44G   28G   17G  63% /
/dev/sda1                 1014M  258M  757M  26% /boot
tmpfs                      1.6G   12K  1.6G   1% /run/user/42
tmpfs                      1.6G  4.0K  1.6G   1% /run/user/1000
172.21.21.101:/ora_02_u01   50G  7.8G   43G  16% /u01
172.21.21.101:/ora_02_u02  200G  320K  200G   1% /u02
172.21.21.101:/ora_02_u03  100G  320K  100G   1% /u03

....
. Oracleリスナーの検証
+
....

[admin@ora_02 ~]$ sudo su
[root@ora_02 admin]# su - oracle
[oracle@ora_02 ~]$ lsnrctl status listener.ntap2

LSNRCTL for Linux: Version 19.0.0.0.0 - Production on 29-MAY-2024 12:13:30

Copyright (c) 1991, 2022, Oracle.  All rights reserved.

Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=ora_02.cie.netapp.com)(PORT=1521)))
STATUS of the LISTENER
------------------------
Alias                     LISTENER.NTAP2
Version                   TNSLSNR for Linux: Version 19.0.0.0.0 - Production
Start Date                23-MAY-2024 16:13:03
Uptime                    5 days 20 hr. 0 min. 26 sec
Trace Level               off
Security                  ON: Local OS Authentication
SNMP                      OFF
Listener Parameter File   /u01/app/oracle/product/19.0.0/NTAP2/network/admin/listener.ora
Listener Log File         /u01/app/oracle/diag/tnslsnr/ora_02/listener.ntap2/alert/log.xml
Listening Endpoints Summary...
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=ora_02.cie.netapp.com)(PORT=1521)))
  (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521)))
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcps)(HOST=ora_02.cie.netapp.com)(PORT=5500))(Security=(my_wallet_directory=/u01/app/oracle/product/19.0.0/NTAP2/admin/NTAP2/xdb_wallet))(Presentation=HTTP)(Session=RAW))
Services Summary...
Service "192551f1d7e65fc3e06308b43d0a63ae.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "1925529a43396002e06308b43d0a2d5a.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "1925530776b76049e06308b43d0a49c3.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "NTAP2.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "NTAP2XDB.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "ntap2_pdb1.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "ntap2_pdb2.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "ntap2_pdb3.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
The command completed successfully
[oracle@ora_02 ~]$

....
. OracleデータベースとdNFSの検証
+
....

[oracle@ora-01 ~]$ cat /etc/oratab
#
# This file is used by ORACLE utilities.  It is created by root.sh
# and updated by either Database Configuration Assistant while creating
# a database or ASM Configuration Assistant while creating ASM instance.

# A colon, ':', is used as the field terminator.  A new line terminates
# the entry.  Lines beginning with a pound sign, '#', are comments.
#
# Entries are of the form:
#   $ORACLE_SID:$ORACLE_HOME:<N|Y>:
#
# The first and second fields are the system identifier and home
# directory of the database respectively.  The third field indicates
# to the dbstart utility that the database should , "Y", or should not,
# "N", be brought up at system boot time.
#
# Multiple entries with the same $ORACLE_SID are not allowed.
#
#
NTAP1:/u01/app/oracle/product/19.0.0/NTAP1:Y


[oracle@ora-01 ~]$ sqlplus / as sysdba

SQL*Plus: Release 19.0.0.0.0 - Production on Thu Feb 1 16:37:51 2024
Version 19.18.0.0.0

Copyright (c) 1982, 2022, Oracle.  All rights reserved.


Connected to:
Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Version 19.18.0.0.0

SQL> select name, open_mode, log_mode from v$database;

NAME      OPEN_MODE            LOG_MODE
--------- -------------------- ------------
NTAP1     READ WRITE           ARCHIVELOG

SQL> show pdbs

    CON_ID CON_NAME                       OPEN MODE  RESTRICTED
---------- ------------------------------ ---------- ----------
         2 PDB$SEED                       READ ONLY  NO
         3 NTAP1_PDB1                     READ WRITE NO
         4 NTAP1_PDB2                     READ WRITE NO
         5 NTAP1_PDB3                     READ WRITE NO
SQL> select name from v$datafile;

NAME
--------------------------------------------------------------------------------
/u02/oradata/NTAP1/system01.dbf
/u02/oradata/NTAP1/sysaux01.dbf
/u02/oradata/NTAP1/undotbs01.dbf
/u02/oradata/NTAP1/pdbseed/system01.dbf
/u02/oradata/NTAP1/pdbseed/sysaux01.dbf
/u02/oradata/NTAP1/users01.dbf
/u02/oradata/NTAP1/pdbseed/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/system01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/sysaux01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/users01.dbf

NAME
--------------------------------------------------------------------------------
/u02/oradata/NTAP1/NTAP1_pdb2/system01.dbf
/u02/oradata/NTAP1/NTAP1_pdb2/sysaux01.dbf
/u02/oradata/NTAP1/NTAP1_pdb2/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb2/users01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/system01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/sysaux01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/users01.dbf

19 rows selected.

SQL> select name from v$controlfile;

NAME
--------------------------------------------------------------------------------
/u02/oradata/NTAP1/control01.ctl
/u03/orareco/NTAP1/control02.ctl

SQL> select member from v$logfile;

MEMBER
--------------------------------------------------------------------------------
/u03/orareco/NTAP1/onlinelog/redo03.log
/u03/orareco/NTAP1/onlinelog/redo02.log
/u03/orareco/NTAP1/onlinelog/redo01.log

SQL> select svrname, dirname from v$dnfs_servers;

SVRNAME
--------------------------------------------------------------------------------
DIRNAME
--------------------------------------------------------------------------------
172.21.21.100
/ora_01_u02

172.21.21.100
/ora_01_u03

172.21.21.100
/ora_01_u01


....
. Oracle Enterprise Manager Expressにログインして、データベースを検証します。
+
image::automation_ora_c-series_nfs_em_01.png[このイメージは、Oracle Enterprise Manager Expressのログイン画面を示しています。]

+
image::automation_ora_c-series_nfs_em_02.png[このイメージは、Oracle Enterprise Manager Expressのコンテナデータベースビューを提供します。]

+
image::automation_ora_c-series_nfs_em_03.png[このイメージは、Oracle Enterprise Manager Expressのコンテナデータベースビューを提供します。]



====


=== SnapCenterによるOracleのバックアップ、リストア、クローニング

[%collapsible]
====
NetAppでは、Cシリーズに導入されたOracleデータベースを管理するために、SnapCenter UIツールを推奨しています。TR-4979を参照 link:aws_ora_fsx_vmc_guestmount.html#oracle-backup-restore-and-clone-with-snapcenter["ゲストマウント型FSx ONTAPにより、VMware Cloud on AWSでシンプルな自己管理型Oracleを実現"^] セクション。 `Oracle backup, restore, and clone with SnapCenter` SnapCenterのセットアップと、データベースのバックアップ、リストア、クローニングのワークフローの実行の詳細については、を参照してください。

====


== 追加情報の参照先

このドキュメントに記載されている情報の詳細については、以下のドキュメントや Web サイトを参照してください。

* NetApp AFF Cシリーズ
+
link:https://www.netapp.com/pdf.html?item=/media/81583-da-4240-aff-c-series.pdf["https://www.netapp.com/pdf.html?item=/media/81583-da-4240-aff-c-series.pdf"^]

* ネットアップのエンタープライズデータベースソリューション
+
link:https://docs.netapp.com/us-en/netapp-solutions/databases/index.html["https://docs.netapp.com/us-en/netapp-solutions/databases/index.html"^]

* Oracle Direct NFSの導入
+
link:https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/deploying-dnfs.html#GUID-D06079DB-8C71-4F68-A1E3-A75D7D96DCE2["https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/deploying-dnfs.html#GUID-D06079DB-8C71-4F68-A1E3-A75D7D96DCE2"^]


