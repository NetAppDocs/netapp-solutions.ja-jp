---
sidebar: sidebar 
permalink: data-analytics/apache-spark-major-ai,-ml,-and-dl-use-cases-and-architectures.html 
keywords: nlp pipelines, tensorflow distributed inferenceing, horovod distributed training, multi-worker, deep learning, keras, ctr prediction 
summary: このページでは、主なAI、ML、DLのユースケースとアーキテクチャについて詳しく説明します。 
---
= AI、ML、DLの主なユースケースとアーキテクチャ
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:apache-spark-use-cases-summary.html["Previous：ユースケースの概要。"]

[role="lead"]
主なAI、ML、DLのユースケースと手法は、以下のセクションに分類できます。



== SparkのNLPパイプラインとTensorFlow分散推論です

次のリストには、データサイエンスコミュニティで採用されている最も一般的なオープンソースのNLPライブラリが、さまざまな開発レベルで含まれています。

* https://www.nltk.org/["Natural Language Toolkit（NLTK）"^]。すべてのNLP手法に対応する完全なツールキットです。2000年代初頭から維持されています。
* https://textblob.readthedocs.io/en/dev/["TextBLOB"^]。NLTKとPatternの上に構築された使いやすいNLPツールPython API。
* https://stanfordnlp.github.io/CoreNLP/["Stanford Core NLP"^]。Stanford NLP Groupが開発したJavaのNLPサービスとパッケージ。
* https://radimrehurek.com/gensim/["Gensim氏"^]。人間のトピックモデリングは、チェコデジタル数学ライブラリプロジェクトのPythonスクリプトの集合として開始されました。
* https://spacy.io/["スパレーシー"^]。PythonとCythonを使用した、トランスフォーマ用GPUアクセラレーションを備えたエンドツーエンドの産業用NLPワークフロー。
* https://fasttext.cc/["Fasttextの場合"^]。FacebookのAI Research（Fair）ラボで作成された単語埋め込みや文分類の学習用の無料の軽量オープンソースNLPライブラリです。


Spark NLPは、あらゆるNLPタスクと要件に対応する単一のユニファイド解決策 です。拡張性が高く、パフォーマンスが高く、精度の高いNLPベースのソフトウェアを、実稼働環境で使用できます。また、転移学習を活用し、研究やさまざまな業界における最新のアルゴリズムとモデルを実装しています。Sparkは上記のライブラリを完全にサポートしていないため、Spark NLPはの上に構築されました https://spark.apache.org/docs/latest/ml-guide.html["Spark ML"^] Sparkの汎用インメモリ分散データ処理エンジンを、ミッションクリティカルな本番ワークフロー向けのエンタープライズクラスのNLPライブラリとして活用しよう。アノテータは、ルールベースのアルゴリズム、機械学習、TensorFlowを利用してディープラーニングの実装を強化しています。トークン化、レマタイ化、語幹化、部分読み上げタギング、名前付きエンティティー認識など、一般的なNLPタスクを取り上げますが、これらに限定されません。 スペルチェックと感情分析。

トランスフォーマー（BERT）の双方向エンコーダリプレゼンテーションは、NLPのトランスベースの機械学習技術です。事前トレーニングと微調整の概念を普及させました。BERTの変圧器アーキテクチャは機械翻訳から生まれたもので、回帰型ニューラルネットワーク（RNN）ベースの言語モデルよりも長期的な依存関係をモデル化します。また、マスク言語モデリング（MLM）タスクも導入されました。このタスクでは、すべてのトークンのランダムな15%がマスクされ、モデルによって予測され、真の双方向性が実現されます。

金融感情の分析は、専門的な言語と、その分野のラベル付けされたデータが不足しているために困難になっています。 https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html["FinBert"^]事前に訓練されたBERTに基づく言語モデルであるBERTは、ドメインに適合しています https://trec.nist.gov/data/reuters/reuters.html["ロイターTRRC2"^]、金融コーパス、およびラベル付けされたデータと微調整された( https://www.researchgate.net/publication/251231364_FinancialPhraseBank-v10["金融PhraseBankの"^]）を参照してください。研究者たちは、財務用語を使ってニュース記事から4、500件の文章を抽出した。次に、16人の専門家と修士の学生が、財務上の背景にポジティブ、ニュートラル、ネガティブのラベルを付けています。2016年から2020年までの間に、FinBERTと他の2つの事前トレーニングパイプライン（）を使用してNASDAQ企業収益の売上高記録の感情を分析するために、Sparkのエンドツーエンドのワークフローを構築しました https://nlp.johnsnowlabs.com/2021/11/11/classifierdl_bertwiki_finance_sentiment_pipeline_en.html["財務ニュースの業況分析"^]、 https://nlp.johnsnowlabs.com/2020/03/19/explain_document_dl.html["ドキュメントDLについて説明する"^]）をSparkのNLPから取得します。

Spark NLPの基礎となるディープラーニングエンジンは、機械学習向けのエンドツーエンドのオープンソースプラットフォームであるTensorFlowです。モデル構築が容易で、どこでも堅牢なML生産を実現し、研究のための強力な実験を可能にします。このため、Sparkの「yarn cluster」モードでパイプラインを実行する場合、基本的には分散TensorFlowを実行し、1つのマスターノードと複数のワーカーノード、およびクラスタにマウントされたネットワーク接続型ストレージにわたって、データとモデルの並列化を行いました。



== Horovodの分散トレーニング

MapReduce関連のパフォーマンスの中核となるHadoop検証は、TeraGen、TeraSort、TeraValidate、およびDFSIO（読み取りおよび書き込み）を使用して実行されます。に、TeraGenおよびTeraSortの検証結果を示します http://www.netapp.com/us/media/tr-3969.pdf["TR-3969：『NetApp Solutions for Hadoop』"^] Eシリーズおよび「ストレージ階層化」（xref）for AFF のセクションに記載されています。

お客様からの要望に基づいて、Sparkを使用したトレーニングの配布は、さまざまなユースケースで最も重要なトレーニングの1つと考えています。このドキュメントでは、を使用しました https://horovod.readthedocs.io/en/stable/spark_include.html["Hovorod on Spark（SparkでのHovorod"^] ネットアップのオンプレミス、クラウドネイティブ、ハイブリッドクラウドソリューションでSparkのパフォーマンスを検証するには、AFF ストレージコントローラ、Azure NetApp Files 、FAS StorageGRID をご利用ください。

Horovod on Sparkパッケージは、Horovodの便利なラッパーを提供します。このラッパーはSparkクラスタで分散されたトレーニングワークロードを簡単に実行できるようにするものです。厳密なモデル設計ループでは、トレーニングデータと推論データが存在するSparkで、データ処理、モデルトレーニング、モデル評価がすべて行われます。

SparkでHorovodを実行するためのAPIには、高レベルのエスティメータAPIと低レベルの実行APIの2つがあります。どちらも、Sparkの実行者に対してHorovodを起動するために同じ基盤メカニズムを使用していますが、Estimator APIはデータ処理、モデルトレーニングループ、モデルチェックポイント、メトリック収集、および分散トレーニングを抽象化します。Horovod Spark Estimators、TensorFlow、Kerasを使用して、に基づくエンドツーエンドのデータ準備と分散トレーニングワークフローを実施しました https://www.kaggle.com/c/rossmann-store-sales["Kagle Rossmann Store Sales"^] 競合他社

スクリプト「kers_spark_horovod_Rossmann _ estimator.py」は、のセクションにあります link:apache-spark-python-scripts-for-each-major-use-case.html["主なユースケースごとにPythonスクリプトを使用できます。"] 次の3つの部分で構成されます

* 最初の部分では、Kaggleが提供し、コミュニティが収集した最初のCSVファイルのセットを介して、さまざまなデータ前処理ステップを実行します。入力データは'Validation'サブセットとテストデータセットで構成されるトレーニングセットに分かれています
* 2番目の部分では、対数シグスモイド活性化関数とAdamオプティマイザを使用してKeras Deep Neural Network（DNN）モデルを定義し、Sparkに対してHorovodを使用してモデルの分散トレーニングを実行します。
* 3番目の部分では、検証セット全体の平均絶対エラーを最小化する最適なモデルを使用して、テストデータセットの予測を実行します。次に、出力CSVファイルが作成されます。


を参照してください link:apache-spark-use-cases-summary.html#machine-learning["「機械学習」"] を参照してください。



== CTR予測にKerasを使用したマルチワーカーディープラーニング

ML プラットフォームとアプリケーションの最近の進歩により、現在は大規模な学習が注目されています。クリックスルー率（ CTR ）は、オンライン広告インプレッション数 100 件あたりの平均クリックスルー数（パーセンテージ）と定義されています。デジタルマーケティング、小売、 E コマース、サービスプロバイダなど、さまざまな業界やユースケースで重要な指標として広く採用されています。を参照してください https://docs.netapp.com/us-en/netapp-solutions/ai/aks-anf_introduction.html["TR-4904 ：『 Distributed Training in Azure - Click Through Rate Prediction 』"^] Kubernetes、分散データETL、DaskおよびCUDA MLを使用したモデルトレーニングなど、CTRのアプリケーションとエンドツーエンドのクラウドAIワークフロー実装の詳細を確認できます。

このテクニカルレポートでは、別のを使用しました https://labs.criteo.com/2013/12/download-terabyte-click-logs-2/["Criteo Terabyteのログデータセットをクリックします"^] （TR-4904を参照）。Kerasを使用した複数のワーカーによる分散型ディープラーニングで、Deep NetworkモデルとCross Network（DCN）モデルを使用したSparkワークフローを構築し、ログ損失エラー機能のパフォーマンスをベースラインSparkのSpark ML Logistic Regression(ログ記録的回帰)モデルと比較します。DCNは、制限された角度の効率的な機能の相互作用を効率的にキャプチャし、高度な非線形相互作用を学習し、手動によるフィーチャーエンジニアリングや完全な検索を必要とせず、計算コストも低くなります。

Webスケールのレコメンダシステムのデータはほとんどが個別に分類されるため、フィーチャーの探索には困難な大規模でスパースな機能スペースが必要になります。これは、大規模なシステムのほとんどをロジスティック回帰などの線形モデルに限定しています。しかし、予測可能な機能を頻繁に特定すると同時に、見過ごしていない機能やまれなクロス機能を調べることが、予測を適切に行うための鍵となります。線形モデルは単純で、解析可能で、簡単にスケール変更できますが、表現力は限られています。

一方、クロス機能は、モデルの表現力を向上させる上で重要であることが示されています。残念なことに、このような機能を特定するには、手動での機能開発や完全な検索が必要になることがよくあります目に見えない機能の相互作用を一般化することは、しばしば困難です。DCNのような十字型ニューラルネットワークを使用すると、自動で機能交差を明示的に適用することで、タスク固有の機能エンジニアリングを回避できます。クロスネットワークは複数のレイヤで構成されており、レイヤの深さによって高度な相互作用がプロバンスされます。各レイヤは、既存のレイヤに基づいて上位の相互作用を生成し、以前のレイヤからの相互作用を保持します。

Deep Neural Network（DNN；ディープニューラルネットワーク）は、さまざまな機能で非常に複雑なインタラクションをキャプチャすることを約束します。ただし、DCNと比較して、必要なパラメータの数は非常に多く、クロス機能を明示的に形成できず、一部のタイプの機能の相互作用を効率的に学習できない場合があります。クロスネットワークはメモリ効率が高く、実装も簡単です。クロスコンポーネントとDNNコンポーネントを共同でトレーニングし、予測機能のインタラクションを効率的に取り込み、Crito CTRデータセットで最先端のパフォーマンスを提供します。

DCNモデルは、埋め込みレイヤーとスタッキングレイヤーから始まり、クロスネットワークとディープネットワークが並行して使用されます。次に、2つのネットワークからの出力を組み合わせた最終的な組み合わせレイヤを示します。入力データは、スパースフィーチャーとデンスフィーチャーを持つベクトルにすることができます。Sparkでは、その両方です https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.linalg.SparseVector.html["ml"^] および https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.mllib.linalg.SparseVector.html["ミリリブ"^] ライブラリには「SparseVector」タイプが含まれます。したがって、ユーザーがそれぞれの機能やメソッドを呼び出す際には、2つの機能を区別し、注意することが重要です。CTR予測などのWebスケールの推薦システムでは、入力は主に「country = USA」などの分類的な機能です。このような機能は、多くの場合、1つのホットベクトルとしてエンコードされます。たとえば、「[0,1,0,..]」のようになります。「SparseVector」を使用したワン・ホット・エンコーディング（OHE）は、絶えず変化する語彙や拡大する語彙を持つ実世界のデータセットを扱う場合に便利です。で例を変更しました https://github.com/shenweichen/DeepCTR["Deepctr"^] 大きなボキャブラリを処理するために、DCNの埋め込みレイヤーとスタッキングレイヤーに埋め込みベクトルを作成します。

。 https://www.kaggle.com/competitions/criteo-display-ad-challenge/data["Critoディスプレイ広告のデータセット"^] 広告のクリックスルーレートを予測します。13の整数型の機能と、各カテゴリの基数が多い26の分類的な機能があります。このデータセットでは、入力サイズが大きいため、ログロスの0.001が実質的に大きく改善されています。大規模なユーザベースの予測精度がわずかに向上すると、企業の収益が大きく増加する可能性があります。データセットには7日間の11GBのユーザログが格納されており、これは約4100万レコードに相当します。Sparkのdataframe .randomSplit()関数を使用して、トレーニング用のデータ(80%)、クロス検証(10%)、およびテスト用の残りの10%をランダムに分割しました。

DCNは、Kerasを使用したTensorFlowに実装されました。DCNを使用したモデルトレーニングプロセスの実装には、次の4つの主要コンポーネントがあります。

* *データ処理と埋め込み。*ログトランスフォームを適用することで、リアルタイム機能が正規化されます。カテゴリフィーチャーの場合、寸法6×（カテゴリの基数）1/4の密度の高いベクトルにフィーチャーを埋め込みます。すべての埋め込み結果を次元1026のベクトルに連結します。
* *最適化* Adam Optimizerを使用してミニバッチ確率的最適化を適用しました。バッチサイズは512に設定されています。ディープネットワークにバッチ正規化が適用され、グラジエントクリップの基準が100に設定されました。
* *均一化。*私達はL2の均一化かドロップアウトが有効であることが見つけられなかったので早い停止を使用した。
* * Hyperparameters*。非表示レイヤー数、非表示レイヤーサイズ、初期学習レート、およびクロスレイヤー数に基づくグリッド検索に基づく結果を報告します。非表示レイヤーの数は2～5で、非表示レイヤーのサイズは32～1024です。DCNの場合、クロスレイヤの数は1～6です。初期学習レートは0.0001から0.001に調整され、0.0001単位で増加しました。すべての実験は訓練ステップ150,000で早期停止を適用し、それを超えて過剰なフィッティングが発生し始めました。


DCNに加えて、CTRの予測に使用される他の一般的なディープラーニングモデルもテストしました https://www.ijcai.org/proceedings/2017/0239.pdf["DeepFM"^]、 https://arxiv.org/pdf/1803.05170.pdf["xDeepFM"^]、 https://arxiv.org/abs/1810.11921["自動内部（AutoInt"^]および https://arxiv.org/abs/2008.13535["DCN v2"^]。



== 検証に使用するアーキテクチャ

この検証では、4つのワーカーノードと1つのマスターノードにAFF-A800 HAペアを使用しました。すべてのクラスタ・メンバーを、10GbEネットワーク・スイッチを介して接続しました。

今回のNetApp Sparkの解決策 検証では、E5760、E5724、AFF-A800の3種類のストレージコントローラを使用しました。Eシリーズストレージコントローラは、12Gbps SAS接続の5つのデータノードに接続されました。AFF のHAペアストレージコントローラは、エクスポートされたNFSボリュームを10GbEでHadoopワーカーノードに接続することで提供します。Hadoopクラスタのメンバーは、Eシリーズ、AFF 、およびStorageGRID のHadoopソリューションで10GbE接続を介して接続されます。

image:apache-spark-image10.png["検証に使用するアーキテクチャ。"]

link:apache-spark-testing-results.html["次の手順：テスト結果"]
