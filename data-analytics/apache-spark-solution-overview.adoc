---
sidebar: sidebar 
permalink: data-analytics/apache-spark-solution-overview.html 
keywords: introduction, overview, 4570, tr4570, customer challenges, justification 
summary: 本ドキュメントでは、Apache Sparkのアーキテクチャ、お客様のユースケース、ビッグデータ分析と人工知能に関連するネットアップストレージポートフォリオについて説明します。また、一般的なHadoopシステムに対して業界標準のAI、機械学習、ディープラーニングツールを使用してさまざまなテスト結果を提示することで、適切なSpark解決策 を選択できます。 
---
= TR-4570：『NetApp Storage Solutions for Apache Spark：Architecture、Use Cases、Performance Results』
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


ネットアップKarthikeyan Nagalingam、Rick Huang氏

本ドキュメントでは、Apache Sparkのアーキテクチャ、お客様のユースケース、ビッグデータ分析と人工知能（AI）に関連するネットアップストレージポートフォリオについて説明します。また、一般的なHadoopシステムに対して業界標準のAI、機械学習（ML）、ディープラーニング（DL）ツールを使用してさまざまなテスト結果を提示することで、適切なSpark解決策 を選択できます。まず、Sparkアーキテクチャ、適切なコンポーネント、2つの配置モード（クラスタとクライアント）が必要です。

このドキュメントでは、構成の問題に対処するためのユースケースも紹介しています。また、Sparkでのビッグデータ分析、AI、ML、DLに関連するネットアップのストレージポートフォリオの概要についても説明しています。その後、Spark固有のユースケースとNetApp Sparkの解決策 ポートフォリオから得られたテスト結果をご紹介します。



== お客様の課題

このセクションでは、小売、デジタルマーケティング、銀行業務、ディスクリート製造、プロセス製造などのデータ成長業界におけるビッグデータ分析とAI / ML / DLに関するお客様の課題に焦点を当てます。 政府機関やプロフェッショナルサービスも利用できます。



=== 予測不可能なパフォーマンス

従来型のHadoop導入では、一般にコモディティハードウェアを使用します。パフォーマンスを向上させるには、ネットワーク、オペレーティングシステム、Hadoopクラスタ、Sparkなどのエコシステムコンポーネント、ハードウェアをチューニングする必要があります。それぞれのレイヤを調整しても、Hadoopは環境内のハイパフォーマンスを想定して設計されていないコモディティハードウェア上で実行されるため、必要なパフォーマンスレベルを達成することは困難です。



=== メディアおよびノードの障害

通常の状態でも、コモディティハードウェアは障害が発生しやすくなります。データノードの1つのディスクに障害が発生すると、Hadoopマスターはデフォルトでそのノードを正常な状態ではないとみなします。次に、レプリカから正常なノードに、そのノードからネットワーク経由で特定のデータをコピーします。このプロセスにより、Hadoopジョブのネットワークパケット速度が低下します。正常な状態に戻ったら、クラスタでデータを再度コピーしてレプリケートデータを削除する必要があります。



=== Hadoopベンダーロックイン

Hadoopディストリビュータは独自のバージョン管理機能を備えたHadoopディストリビューションを所有しており、これによってお客様はこれらのディストリビューションにロックされます。ただし、多くのお客様が、特定のHadoopディストリビューションにお客様を結び付けることのないインメモリ分析をサポートしている必要があります。ディストリビューションを自由に変更し、分析機能を活用する必要があります。



=== 複数の言語をサポートしていない

MapReduce Javaプログラムに加えて、ジョブを実行するために複数の言語のサポートが必要になることがよくあります。SQLやスクリプトなどのオプションを使用すると、回答を取得する柔軟性が高まり、データを整理して取得するためのオプションが増え、データを分析フレームワークにすばやく移動できます。



=== 使用の難しさ

しばらくの間、Hadoopが使いにくいとユーザからクレームを受けています。Hadoopは新しいバージョンが登場するたびにシンプルかつ強力になりましたが、今もこの批評家は存続しています。Hadoopを使用するには、JavaおよびMapReduceのプログラミングパターンを理解する必要があります。これは、データベース管理者や、従来のスクリプトスキルセットを持つユーザにとっての課題です。



=== 複雑なフレームワークとツール

企業のAIチームは、さまざまな課題に直面します。導入エコシステムやアプリケーションごとに専門的なデータサイエンスの知識があるとしても、ツールやフレームワークは単に相互に変換されるわけではありません。データサイエンスプラットフォームは、Spark上に構築された対応するビッグデータプラットフォームとシームレスに統合する必要があります。データ移動が容易で、再利用可能なモデル、すぐに使えるコード、プロトタイプ作成、検証、バージョン管理、共有、再利用といったベストプラクティスに対応するツールを備えています。 また、モデルを迅速に本番環境に導入できます。



== ネットアップを選ぶ理由

ネットアップでは、次の方法でSpark体験を向上させています。

* NetApp NFSから直接アクセスする（次の図を参照）ことで、データを移動したりコピーしたりすることなく、既存または新規のNFSv3 / NFSv4データに対してビッグデータ分析ジョブを実行できます。データの複数のコピーが作成されるため、ソースとデータを同期する必要がありません。
* ストレージ効率が向上し、サーバのレプリケーションが不要になります。たとえば、NetApp EシリーズHadoop解決策 にはデータのレプリカが3つではなく2つ必要であり、FAS Hadoop解決策 にはデータソースが必要ですが、データのレプリケーションやコピーは必要ありません。ネットアップのストレージソリューションは、サーバ間のトラフィックも削減します。
* ドライブおよびノードの障害時のHadoopジョブとクラスタの動作が向上します。
* データ取り込みのパフォーマンスが向上します。


image:apache-spark-image1.png["別のApache Spark設定。"]

たとえば、金融機関や医療機関では、ある場所から別の場所へデータを移動する際に法的義務を果たす必要がありますが、これは容易な作業ではありません。このシナリオでは、NetApp NFSから直接アクセスして、財務データと医療データを元の場所から分析します。もう1つの主なメリットは、NetApp NFS直接アクセスを使用することで、ネイティブのHadoopコマンドを使用してHadoopデータを簡単に保護できるようになることと、ネットアップの充実したデータ管理ポートフォリオでデータ保護ワークフローを実現できることです。

NetApp NFS直接アクセスでは、HadoopクラスタとSparkクラスタに対して次の2種類の導入オプションを提供しています。

* デフォルトでは、HadoopクラスタまたはSparkクラスタは、データストレージとデフォルトのファイルシステムにHadoop Distributed File System（HDFS；Hadoop分散ファイルシステム）を使用しています。NetApp NFSから直接アクセスできるため、デフォルトのHDFSをデフォルトのファイルシステムとしてNFSストレージに置き換えることができ、NFSデータを直接分析できます。
* もう1つの導入オプションでは、NetApp NFS直接アクセスを使用して、1つのHadoopクラスタまたはSparkクラスタ内でHDFSを追加のストレージとして構成することもできます。この場合、 NFS エクスポートを介してデータを共有し、 HDFS データと同じクラスタからデータにアクセスできます。


NetApp NFS直接アクセスを使用する主な利点は次のとおりです。

* 現在の場所からデータを分析することで、分析データをHDFSなどのHadoopインフラに移動するための時間とパフォーマンスのかかる作業を回避できます。
* レプリカの数を3分の1から1に削減。
* ユーザを分離してコンピューティングとストレージを分離し、個別に拡張
* ONTAP の充実したデータ管理機能を活用して、エンタープライズデータを保護
* Hortonworksデータプラットフォームの認定。
* ハイブリッドデータ分析の導入を実現
* 動的なマルチスレッド機能を活用してバックアップ時間を短縮


を参照してください https://docs.netapp.com/us-en/netapp-solutions/data-analytics/hdcs-sh-solution-overview.html["TR-4657 ：ネットアップのハイブリッドクラウドデータソリューション - Spark と Hadoop はお客様のユースケースに基づいています"^] Hadoopデータのバックアップ、クラウドからオンプレミスへのバックアップ、ディザスタリカバリ、既存のHadoopデータに対するDevTestの有効化、データ保護とマルチクラウド接続の実現、分析ワークロードの高速化を実現します。

次のセクションでは、Sparkのお客様にとって重要なストレージ機能について説明します。



=== ストレージ階層化

Hadoopストレージ階層化を使用すると、ストレージポリシーに従ってさまざまなタイプのファイルを格納できます。ストレージ・タイプには' hot ''cold ''warm ''all_sssd ''one _sssd 'が含まれます 「lazy_persist`」。

<<<<そこで、NetApp AFF ストレージコントローラと、ストレージポリシーが異なるSSDとSASドライブを搭載したEシリーズストレージコントローラでHadoopストレージの階層化を検証しました。AFF-A800のSparkクラスタには4つのコンピュートワーカーノードがあり、Eシリーズのクラスタには8つのノードがあります。主な用途は、ソリッドステートドライブ（SSD）とハードドライブディスク（HDD）のパフォーマンスを比較することです。

[]
====
ネットアップのAFF ストレージコントローラと、ストレージポリシーが異なるSSDおよびSASドライブを搭載したEシリーズストレージコントローラでHadoopストレージの階層化を検証しました。AFF-A800のSparkクラスタには4つのコンピュートワーカーノードがあり、Eシリーズのクラスタには8つのノードがあります。これは主に、ソリッドステートドライブとハードドライブディスクのパフォーマンスを比較するために行いました。>>>>>>>>a51c9ddf73ca69e1120ce05edc7b0b9607b96eae

次の図に、ネットアップのHadoop SSD向けソリューションのパフォーマンスを示します。

image:apache-spark-image2.png["1TBのデータをソートする時間です。"]

* ベースラインNL-SAS構成では、8つのコンピューティングノードと96本のNL-SASドライブを使用しました。この構成では、1TBのデータが4分38秒で生成され、を参照してください https://www.netapp.com/media/16420-tr-3969.pdf["TR-3969『NetApp Eシリーズ解決策 for Hadoop』"^] クラスタとストレージ構成の詳細については、を参照してください。
* TeraGenを使用した場合、SSD構成ではNL-SAS構成よりも1TBのデータが15.66x高速で生成されました。さらに、SSD構成では、コンピューティングノードの半分とディスクドライブの半分（合計24本のSSDドライブ）が使用されていました。ジョブの完了時間に基づき、NL-SAS構成の約2倍の速さで処理されました。
* SSD構成は、TeraSortを使用してNL-SAS構成の1TBのデータを1138.36倍高速にソートしました。さらに、SSD構成では、コンピューティングノードの半分とディスクドライブの半分（合計24本のSSDドライブ）が使用されていました。そのため、ドライブあたりの速度は、NL-SAS構成の約3倍です。< < < < < < < < < < < < < < 頭部
* ここで重要なのは、回転式ディスクからオールフラッシュに移行することでパフォーマンスを向上させることです。コンピューティングノードの数がボトルネックになっていません。ネットアップのオールフラッシュストレージなら、ランタイムのパフォーマンスを大幅に向上できます。
* NFSでは、データがすべてプールされる機能と同等で、ワークロードに応じてコンピューティングノードの数を減らすことができました。コンピューティングノードの数を変更した場合、Apache Sparkクラスタユーザは手動でデータをリバランシングする必要がありません。


====
* つまり、回転式ディスクからオールフラッシュに移行することでパフォーマンスが向上します。コンピューティングノードの数がボトルネックになっていません。ネットアップのオールフラッシュストレージなら、ランタイムのパフォーマンスを大幅に向上できます。
* NFSでは、データがすべてプールされる機能と同等で、ワークロードに応じてコンピューティングノードの数を減らすことができました。コンピューティングノードの数を変更した場合、Apache Sparkクラスタユーザは手動でデータをリバランシングする必要がありません。>>>>>>>>a51c9ddf73ca69e1120ce05edc7b0b9607b96eae




=== パフォーマンスの拡張-スケールアウト

AFF 解決策 のHadoopクラスタの処理能力を強化する必要がある場合は、適切な数のストレージコントローラを使用してデータノードを追加できます。ワークロードの特性に応じて、ストレージコントローラアレイごとにデータノードを4つから始めて、ストレージコントローラごとにデータノードを8つに増やすことを推奨します。

AFF とFAS はインプレース分析に最適です。コンピューティング要件に基づいて、ノードマネージャを追加できます。また、ノンストップオペレーション機能により、ダウンタイムなしでストレージコントローラをオンデマンドで追加できます。AFF とFAS を備えた豊富な機能を備えており、NVMeメディアのサポート、効率性の保証、データ削減、QoS、予測分析、 クラウドの階層化、レプリケーション、クラウドの導入、セキュリティお客様が要件を満たせるように、ネットアップでは、追加のライセンスコストなしでファイルシステム分析、クォータ、オンボックスロードバランシングなどの機能を提供しています。ネットアップは、同時ジョブ数やレイテンシの低減、処理の簡易化、1秒あたりのスループットの向上といった、競合他社よりも優れたパフォーマンスを提供しています。さらに、ネットアップのCloud Volumes ONTAP は、主要な3つのクラウドプロバイダすべてで動作します。



=== パフォーマンスの拡張-スケールアップ

ストレージ容量を追加する必要がある場合は、スケールアップ機能を使用して、AFF 、FAS 、およびEシリーズシステムにディスクドライブを追加できます。Cloud Volumes ONTAP を使用してストレージをPBレベルに拡張するには、使用頻度の低いデータをブロックストレージからオブジェクトストレージに階層化し、追加のコンピューティングなしでCloud Volumes ONTAP ライセンスをスタックするという2つの要素を組み合わせます。



=== 複数のプロトコル

ネットアップシステムは、SAS、iSCSI、FCP、InfiniBandなど、Hadoop導入のほとんどのプロトコルをサポートしています。 およびNFSが必要です。



=== 運用およびサポートされるソリューション

本ドキュメントに記載されているHadoopソリューションは、ネットアップによってサポートされています。これらのソリューションは、主要なHadoopディストリビュータでも認定されています。詳細については、を参照してください https://www.mapr.com/partners/partner/netapp["MapR"^] サイト、 http://hortonworks.com/partner/netapp/["Hortonworks"^] サイト、Cloudera http://www.cloudera.com/partners/partners-listing.html?q=netapp["認定資格"^] および http://www.cloudera.com/partners/solutions/netapp.html["パートナー"^] サイト：

link:apache-spark-target-audience.html["次のステップ：対象となるお客様"]
