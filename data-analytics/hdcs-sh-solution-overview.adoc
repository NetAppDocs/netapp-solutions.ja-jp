---
sidebar: sidebar 
permalink: data-analytics/hdcs-sh-solution-overview.html 
keywords: tr-4657, tr4657, 4657, hybrid cloud, spark, hadoop, aff, fas 
summary: 本ドキュメントでは、 NetApp AFF および FAS ストレージシステム、 NetApp Cloud Volumes ONTAP 、ネットアップ接続ストレージ、 Spark および Hadoop 向けの NetApp FlexClone テクノロジを使用したハイブリッドクラウドデータソリューションについて説明します。これらの解決策アーキテクチャを使用することで、お客様の環境に適したデータ保護解決策を選択できます。ネットアップは、お客様とのやり取りと、お客様のビジネスユースケースに基づいてこれらのソリューションを設計しました。 
---
= TR-4657 ：ネットアップのハイブリッドクラウドデータソリューション - Spark と Hadoop はお客様のユースケースに基づいています
:allow-uri-read: 


ネットアップ、 Karthikeyan Nagalingam と Sathish Thyagarajan

本ドキュメントでは、 NetApp AFF および FAS ストレージシステム、 NetApp Cloud Volumes ONTAP 、ネットアップ接続ストレージ、 Spark および Hadoop 向けの NetApp FlexClone テクノロジを使用したハイブリッドクラウドデータソリューションについて説明します。これらの解決策アーキテクチャを使用することで、お客様の環境に適したデータ保護解決策を選択できます。ネットアップは、お客様とのやり取りと、お客様のビジネスユースケースに基づいてこれらのソリューションを設計しました。このドキュメントでは、次の詳細情報を提供します。

* Spark 環境や Hadoop 環境、お客様の課題に対応するデータ保護が必要な理由
* ネットアップのビジョンと、そのビルディングブロックとサービスを基盤とするデータファブリック。
* これらのビルディングブロックを使用して、柔軟なデータ保護ワークフローを構築する方法
* 実際のお客様のユースケースに基づく、複数のアーキテクチャの長所と短所各ユースケースには、次のコンポーネントがあります。
+
** お客様のシナリオ
** 要件と課題
** 解決策
** ソリューションの概要






== Hadoop のデータ保護を選ぶ理由

Hadoop 環境と Spark 環境では、次の点に注意する必要があります。

* * ソフトウェアや人為的なエラー。 * Hadoop データの処理中にソフトウェアを更新したときに人的エラーが発生すると、業務によって原因が予期せぬ結果を招く可能性がある動作不良になることがあります。このような場合は、障害や妥当でない結果が生じないように、データを保護する必要があります。たとえば、ソフトウェアアップデートの実行が不十分でトラフィック信号分析アプリケーションが実行されたため、トラフィック信号データをプレーンテキスト形式で適切に分析できない新機能があります。ソフトウェアは JSON やその他の非テキストファイル形式を分析して、リアルタイムトラフィック制御分析システムを生成し、データポイントが不足している予測結果を生成します。このような状況では、原因が出力不良の可能性があり、交通信号で事故につながるおそれがあります。データ保護機能を使用すると、以前の作業中のアプリケーションバージョンにすばやくロールバックできるため、この問題に対応できます。
* * サイズと拡張性。 * 分析データのサイズは日々増え続けています。その理由は、データソースとボリュームの数が増え続けることにあります。現在のビッグデータ市場では、ソーシャルメディア、モバイルアプリ、データ分析、クラウドコンピューティングの各プラットフォームがデータの主要なソースとなっており、データは急速に増加しています。そのため、データを保護して、正確なデータ運用を確保する必要があります。
* * Hadoop のネイティブデータ保護。 * Hadoop には、データを保護するためのネイティブコマンドがありますが、このコマンドはバックアップ中のデータの整合性を提供しません。ディレクトリレベルのバックアップのみをサポートします。Hadoop によって作成された Snapshot は読み取り専用であり、バックアップデータを直接再利用することはできません。




== Hadoop や Spark のお客様にとって、データ保護の課題が発生しています

Hadoop と Spark のお客様にとってよくある課題は、データ保護の際に本番クラスタのパフォーマンスに悪影響を与えることなく、バックアップ時間を短縮し、バックアップの信頼性を向上させることです。

また、 RPO （目標復旧時点）と RTO （目標復旧時間）のダウンタイムを最小限に抑え、オンプレミスとクラウドベースのディザスタリカバリサイトを制御して、ビジネス継続性を最適化する必要もあります。この制御は、通常、エンタープライズレベルの管理ツールを使用して行われます。

データ量が膨大で増え続けているだけでなく、データの到着率も増加しているため、 Hadoop 環境と Spark 環境は複雑化しています。このようなシナリオでは、ソースデータから効率的で最新の DevTest 環境と QA 環境を迅速に構築することは困難です。ネットアップはこれらの課題を認識し、本ホワイトペーパーで紹介しているソリューションを提供しています。

link:hdcs-sh-data-fabric-powered-by-netapp-for-big-data-architecture.html["次のステップ：ネットアップのビッグデータアーキテクチャを基盤とするデータファブリック。"]
