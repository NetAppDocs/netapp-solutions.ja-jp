---
sidebar: sidebar 
permalink: data-analytics/kafka-nfs-performance-overview-and-validation-in-aws.html 
keywords: AWS cloud, ha pair, high availability, openmessage benchmarking, architectural setup 
summary: ストレージレイヤをNetApp NFS上にマウントしたKafkaクラスタは、AWSクラウドでのパフォーマンスについてベンチマークテストを実施しました。ベンチマークの例については、次のセクションで説明します。 
---
= AWSでのパフォーマンスの概要と検証
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:kafka-nfs-why-netapp-nfs-for-kafka-workloads.html["以前：KafkaワークロードにネットアップのNFSを使用する理由。"]

[role="lead"]
ストレージレイヤをNetApp NFS上にマウントしたKafkaクラスタは、AWSクラウドでのパフォーマンスについてベンチマークテストを実施しました。ベンチマークの例については、次のセクションで説明します。



== AWSクラウドのKafkaとNetApp Cloud Volumes ONTAP （ハイアベイラビリティペアとシングルノード）

NetApp Cloud Volumes ONTAP （HAペア）を使用したKafkaクラスタは、AWSクラウドでのパフォーマンスについてベンチマークを実施しました。このベンチマークについては、以降のセクションで説明します。



=== アーキテクチャのセットアップ

次の表に、NASを使用するKafkaクラスタの環境構成を示します。

|===
| プラットフォームコンポーネント | 環境の構成 


| Kafka 3.2.3.  a| 
* 3 x動物飼育係–T2.small
* ブローカーサーバ×3–i3en.2xlarge
* Grafana–c5n.2xlarge×1
* 4 x producer/consumer -- c5n.2xlarge *




| すべてのノード上のオペレーティングシステム | RHEL8.6 


| NetApp Cloud Volumes ONTAP インスタンス | HAペアインスタンス–m5dn.12xLarge x 2ノードシングルノードインスタンス- m5dn.12xLarge x 1ノード 
|===


=== ネットアップクラスタボリュームのONTAP セットアップ

. Cloud Volumes ONTAP HAペアについては、各ストレージコントローラの各アグリゲートに3つのボリュームを含む2つのアグリゲートを作成しました。単一のCloud Volumes ONTAP ノードの場合は、アグリゲートに6つのボリュームを作成します。
+
image:kafka-nfs-image25.png["この図は、aggr3とaggr22のプロパティを示しています。"]

+
image:kafka-nfs-image26.png["この図は、aggr2のプロパティを示しています。"]

. ネットワークパフォーマンスを高めるために、HAペアとシングルノードの両方で高速ネットワークを有効にしました。
+
image:kafka-nfs-image27.png["この図は、高速ネットワークを有効にする方法を示しています。"]

. ONTAP NVRAMのIOPSが多いことに気付いたので、Cloud Volumes ONTAP ルートボリュームのIOPSを2350に変更しました。Cloud Volumes ONTAP のルートボリュームディスクのサイズは47GBでした。次のONTAP コマンドはHAペア用で、同じ手順をシングルノードにも適用します。
+
....
statistics start -object vnvram -instance vnvram -counter backing_store_iops -sample-id sample_555
kafka_nfs_cvo_ha1::*> statistics show -sample-id sample_555
Object: vnvram
Instance: vnvram
Start-time: 1/18/2023 18:03:11
End-time: 1/18/2023 18:03:13
Elapsed-time: 2s
Scope: kafka_nfs_cvo_ha1-01
    Counter                                                     Value
    -------------------------------- --------------------------------
    backing_store_iops                                           1479
Object: vnvram
Instance: vnvram
Start-time: 1/18/2023 18:03:11
End-time: 1/18/2023 18:03:13
Elapsed-time: 2s
Scope: kafka_nfs_cvo_ha1-02
    Counter                                                     Value
    -------------------------------- --------------------------------
    backing_store_iops                                           1210
2 entries were displayed.
kafka_nfs_cvo_ha1::*>
....
+
image:kafka-nfs-image28.png["このイメージは、ボリュームプロパティを変更する方法を示しています。"]



次の図は、NASベースのKafkaクラスタのアーキテクチャを示しています。

* *コンピューティング。* 3ノードのKafkaクラスタを使用し、3ノードのZookeeperアンサンブルを専用サーバ上で実行しました。各ブローカーには、専用のLIFを介してCloud Volumes ONTAP インスタンス上の単一のボリュームへのNFSマウントポイントが2つあります。
* *監視。* Prometheus-Grafanaの組み合わせには2つのノードを使用しました。ワークロードの生成には、独立した3ノードクラスタを使用し、このKafkaクラスタを生成して使用しました。
* *ストレージ。* HAペアCloud Volumes ONTAP インスタンスを使用し、インスタンスに6TB gp3 AWS-EBSボリュームを1つマウントしました。その後、ボリュームはNFSマウントを使用してKafkaブローカーにエクスポートされました。


image:kafka-nfs-image29.png["この図は、NASベースのKafkaクラスタのアーキテクチャを示しています。"]



=== OpenMessageベンチマーク設定

. NFSのパフォーマンスを向上させるには、NFSサーバとNFSクライアントの間のネットワーク接続を増やす必要があります。この接続は、nconnectを使用して作成できます。次のコマンドを実行して、nconnectオプションを使用して、ブローカーノードにNFSボリュームをマウントします。
+
....
[root@ip-172-30-0-121 ~]# cat /etc/fstab
UUID=eaa1f38e-de0f-4ed5-a5b5-2fa9db43bb38/xfsdefaults00
/dev/nvme1n1 /mnt/data-1 xfs defaults,noatime,nodiscard 0 0
/dev/nvme2n1 /mnt/data-2 xfs defaults,noatime,nodiscard 0 0
172.30.0.233:/kafka_aggr3_vol1 /kafka_aggr3_vol1 nfs defaults,nconnect=16 0 0
172.30.0.233:/kafka_aggr3_vol2 /kafka_aggr3_vol2 nfs defaults,nconnect=16 0 0
172.30.0.233:/kafka_aggr3_vol3 /kafka_aggr3_vol3 nfs defaults,nconnect=16 0 0
172.30.0.242:/kafka_aggr22_vol1 /kafka_aggr22_vol1 nfs defaults,nconnect=16 0 0
172.30.0.242:/kafka_aggr22_vol2 /kafka_aggr22_vol2 nfs defaults,nconnect=16 0 0
172.30.0.242:/kafka_aggr22_vol3 /kafka_aggr22_vol3 nfs defaults,nconnect=16 0 0
[root@ip-172-30-0-121 ~]# mount -a
[root@ip-172-30-0-121 ~]# df -h
Filesystem                       Size  Used Avail Use% Mounted on
devtmpfs                          31G     0   31G   0% /dev
tmpfs                             31G  249M   31G   1% /run
tmpfs                             31G     0   31G   0% /sys/fs/cgroup
/dev/nvme0n1p2                    10G  2.8G  7.2G  28% /
/dev/nvme1n1                     2.3T  248G  2.1T  11% /mnt/data-1
/dev/nvme2n1                     2.3T  245G  2.1T  11% /mnt/data-2
172.30.0.233:/kafka_aggr3_vol1   1.0T   12G 1013G   2% /kafka_aggr3_vol1
172.30.0.233:/kafka_aggr3_vol2   1.0T  5.5G 1019G   1% /kafka_aggr3_vol2
172.30.0.233:/kafka_aggr3_vol3   1.0T  8.9G 1016G   1% /kafka_aggr3_vol3
172.30.0.242:/kafka_aggr22_vol1  1.0T  7.3G 1017G   1% /kafka_aggr22_vol1
172.30.0.242:/kafka_aggr22_vol2  1.0T  6.9G 1018G   1% /kafka_aggr22_vol2
172.30.0.242:/kafka_aggr22_vol3  1.0T  5.9G 1019G   1% /kafka_aggr22_vol3
tmpfs                            6.2G     0  6.2G   0% /run/user/1000
[root@ip-172-30-0-121 ~]#
....
. Cloud Volumes ONTAP でネットワーク接続を確認します。次のONTAP コマンドは、単一のCloud Volumes ONTAP ノードから使用します。同じ手順をCloud Volumes ONTAP HAペアにも適用できます。
+
....
Last login time: 1/20/2023 00:16:29
kafka_nfs_cvo_sn::> network connections active show -service nfs* -fields remote-host
node                cid        vserver              remote-host
------------------- ---------- -------------------- ------------
kafka_nfs_cvo_sn-01 2315762628 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762629 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762630 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762631 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762632 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762633 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762634 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762635 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762636 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762637 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762639 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762640 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762641 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762642 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762643 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762644 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762645 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762646 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762647 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762648 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762649 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762650 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762651 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762652 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762653 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762656 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762657 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762658 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762659 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762660 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762661 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762662 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762663 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762664 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762665 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762666 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762667 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762668 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762669 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762670 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762671 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762672 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762673 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762674 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762676 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762677 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762678 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762679 svm_kafka_nfs_cvo_sn 172.30.0.223
48 entries were displayed.
 
kafka_nfs_cvo_sn::>
....
. 以下のKafkaを使用します `server.properties` Cloud Volumes ONTAP HAペアのすべてのKafkaブローカー。 `log.dirs` プロパティはブローカーごとに異なり、残りのプロパティはブローカーに共通です。broker1の場合は `log.dirs` 値は次のとおりです。
+
....
[root@ip-172-30-0-121 ~]# cat /opt/kafka/config/server.properties
broker.id=0
advertised.listeners=PLAINTEXT://172.30.0.121:9092
#log.dirs=/mnt/data-1/d1,/mnt/data-1/d2,/mnt/data-1/d3,/mnt/data-2/d1,/mnt/data-2/d2,/mnt/data-2/d3
log.dirs=/kafka_aggr3_vol1/broker1,/kafka_aggr3_vol2/broker1,/kafka_aggr3_vol3/broker1,/kafka_aggr22_vol1/broker1,/kafka_aggr22_vol2/broker1,/kafka_aggr22_vol3/broker1
zookeeper.connect=172.30.0.12:2181,172.30.0.30:2181,172.30.0.178:2181
num.network.threads=64
num.io.threads=64
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
replica.fetch.max.bytes=524288000
background.threads=20
num.replica.alter.log.dirs.threads=40
num.replica.fetchers=20
[root@ip-172-30-0-121 ~]#
....
+
** 仲介業者2の場合は、 `log.dirs` プロパティ値は次のとおりです。
+
....
log.dirs=/kafka_aggr3_vol1/broker2,/kafka_aggr3_vol2/broker2,/kafka_aggr3_vol3/broker2,/kafka_aggr22_vol1/broker2,/kafka_aggr22_vol2/broker2,/kafka_aggr22_vol3/broker2
....
** 仲介業者3の場合は、 `log.dirs` プロパティ値は次のとおりです。
+
....
log.dirs=/kafka_aggr3_vol1/broker3,/kafka_aggr3_vol2/broker3,/kafka_aggr3_vol3/broker3,/kafka_aggr22_vol1/broker3,/kafka_aggr22_vol2/broker3,/kafka_aggr22_vol3/broker3
....


. 単一のCloud Volumes ONTAP ノードの場合は、Kafka `servers.properties` は、を除き、Cloud Volumes ONTAP HAペアと同じです `log.dirs` プロパティ。
+
** broker1の場合は `log.dirs` 値は次のとおりです。
+
....
log.dirs=/kafka_aggr2_vol1/broker1,/kafka_aggr2_vol2/broker1,/kafka_aggr2_vol3/broker1,/kafka_aggr2_vol4/broker1,/kafka_aggr2_vol5/broker1,/kafka_aggr2_vol6/broker1
....
** 仲介業者2の場合は、 `log.dirs` 値は次のとおりです。
+
....
log.dirs=/kafka_aggr2_vol1/broker2,/kafka_aggr2_vol2/broker2,/kafka_aggr2_vol3/broker2,/kafka_aggr2_vol4/broker2,/kafka_aggr2_vol5/broker2,/kafka_aggr2_vol6/broker2
....
** 仲介業者3の場合は、 `log.dirs` プロパティ値は次のとおりです。
+
....
log.dirs=/kafka_aggr2_vol1/broker3,/kafka_aggr2_vol2/broker3,/kafka_aggr2_vol3/broker3,/kafka_aggr2_vol4/broker3,/kafka_aggr2_vol5/broker3,/kafka_aggr2_vol6/broker3
....


. OMB内のワークロードには、次のプロパティが設定されます。 `(/opt/benchmark/workloads/1-topic-100-partitions-1kb.yaml)`。
+
....
topics: 4
partitionsPerTopic: 100
messageSize: 32768
useRandomizedPayloads: true
randomBytesRatio: 0.5
randomizedPayloadPoolSize: 100
subscriptionsPerTopic: 1
consumerPerSubscription: 80
producersPerTopic: 40
producerRate: 1000000
consumerBacklogSizeGB: 0
testDurationMinutes: 5
....
+
。 `messageSize` はユースケースごとに異なる場合があります。パフォーマンステストでは、3Kを使用しました。

+
OMBのSyncまたはThroughputという2つのドライバを使用して、Kafkaクラスタでワークロードを生成しました。

+
** 同期ドライバのプロパティに使用されるYAMLファイルは次のとおりです `(/opt/benchmark/driver- kafka/kafka-sync.yaml)`：
+
....
name: Kafka
driverClass: io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver
# Kafka client-specific configuration
replicationFactor: 3
topicConfig: |
  min.insync.replicas=2
  flush.messages=1
  flush.ms=0
commonConfig: |
  bootstrap.servers=172.30.0.121:9092,172.30.0.72:9092,172.30.0.223:9092
producerConfig: |
  acks=all
  linger.ms=1
  batch.size=1048576
consumerConfig: |
  auto.offset.reset=earliest
  enable.auto.commit=false
  max.partition.fetch.bytes=10485760
....
** スループットドライバのプロパティに使用されるYAMLファイルは次のとおりです `(/opt/benchmark/driver- kafka/kafka-throughput.yaml)`：
+
....
name: Kafka
driverClass: io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver
# Kafka client-specific configuration
replicationFactor: 3
topicConfig: |
  min.insync.replicas=2
commonConfig: |
  bootstrap.servers=172.30.0.121:9092,172.30.0.72:9092,172.30.0.223:9092
  default.api.timeout.ms=1200000
  request.timeout.ms=1200000
producerConfig: |
  acks=all
  linger.ms=1
  batch.size=1048576
consumerConfig: |
  auto.offset.reset=earliest
  enable.auto.commit=false
  max.partition.fetch.bytes=10485760
....






== テストの方法論

. Kafkaクラスタは、前述の仕様に従ってTerraformとAnsibleを使用してプロビジョニングされました。Terraformを使用して、Kafkaクラスタ用のAWSインスタンスを使用してインフラを構築し、Ansibleを使用してKafkaクラスタを構築します。
. 上記のワークロード構成とSyncドライバでOMBワークロードがトリガーされました。
+
....
Sudo bin/benchmark –drivers driver-kafka/kafka- sync.yaml workloads/1-topic-100-partitions-1kb.yaml
....
. 同じワークロード構成でスループットドライバを使用して別のワークロードがトリガーされました。
+
....
sudo bin/benchmark –drivers driver-kafka/kafka-throughput.yaml workloads/1-topic-100-partitions-1kb.yaml
....




== 観察

NFSで実行されるKafkaインスタンスのパフォーマンスをベンチマークするために、2種類のドライバを使用してワークロードを生成しました。ドライバの違いは、log flushプロパティです。

Cloud Volumes ONTAP HAペアの場合：

* Syncドライバによって一貫して生成される合計スループット：最大1236 Mbps
* スループットドライバに対して生成された合計スループット：ピーク時最大1412 Mbps


単一のCloud Volumes ONTAP ノードの場合：

* Syncドライバで一貫して生成される合計スループット：約1962MBps
* スループットドライバによって生成される合計スループット：最大1660MBps


Syncドライバはログが即座にディスクにフラッシュされるときに一貫したスループットを生成できますが、Throughputドライバはログがディスクに一括コミットされるときにスループットのバーストを生成します。

これらのスループット値は、指定されたAWS構成に対して生成されます。より高いパフォーマンス要件に対応するには、インスタンスタイプをスケールアップしてさらに調整し、スループットを向上させることができます。総スループットまたは総レートは、生産者と消費者の両方のレートの組み合わせです。

image:kafka-nfs-image30.png["ここでは、4つの異なるグラフを示します。CVO-HAペアスループットドライバCVO-HAペアSyncドライバ：CVO -シングルノードスループットドライバ。CVO -シングルノードSyncドライバ。"]

スループットまたは同期ドライバのベンチマークを実行するときは、必ずストレージスループットを確認してください。

image:kafka-nfs-image31.png["このグラフには、レイテンシ、IOPS、およびスループットのパフォーマンスが表示されます。"]



== AWS FSxNのApache Kafka



=== 概要

Network File System（NFS；ネットワークファイルシステム）は、大量のデータを格納するために広く使用されているネットワークファイルシステムです。ほとんどの組織では、データがApache Kafkaなどのストリーミングアプリケーションによって生成されるようになっています。このようなワークロードには、拡張性、低レイテンシ、最新のストレージ機能を備えた堅牢なデータ取り込みアーキテクチャが必要です。リアルタイム分析を実現し、実用的な分析情報を提供するには、適切に設計されたパフォーマンスの高いインフラが必要です。

Kafkaは、設計上POSIX準拠のファイルシステムと連携し、ファイル操作をファイルシステムに依存して処理しますが、NFSv3ファイルシステムにデータを格納する場合、KafkaブローカーのNFSクライアントは、ファイル操作をXFSやext4などのローカルファイルシステムとは異なる方法で解釈できます。一般的な例としては、NFSのsilly renameがあり、クラスタの拡張時やパーティションの再割り当て時にKafkaブローカーでエラーが発生していました。この課題に対処するため、NetAppはオープンソースのLinux NFSクライアントを更新し、RHEL8.7とRHEL9.1で一般提供されるようになりました。また、最新のFSx for ONTAPリリースであるONTAP 9.12.1からサポートされるようになりました。

Amazon FSx for NetApp ONTAPは、拡張性とパフォーマンスに優れたフルマネージドのNFSファイルシステムをクラウドで提供します。FSx for NetAppのKafkaデータは、大量のデータを処理し、フォールトトレランスを確保するように拡張できます。NFSは、重要で機密性の高いデータセットに対して一元的なストレージ管理とデータ保護を提供します。

これらの機能強化により、AWSのお客様はAWSコンピューティングサービスでKafkaワークロードを実行する際にFSx for ONTAPを活用できるようになります。次のようなメリットがあります。
* CPU使用率を削減して、I/O待機時間を短縮します
* Kafkaブローカーのリカバリ時間の短縮
*信頼性と効率性
*拡張性とパフォーマンス
*マルチアベイラビリティゾーンの可用性
*データ保護



=== AWS FSxNでのパフォーマンスの概要と検証

ストレージレイヤをNetApp NFS上にマウントしたKafkaクラスタは、AWS FSxNでパフォーマンスのベンチマークを実施しました。ベンチマークの例については、次のセクションで説明します。



==== AWS FSxNのKafka（アクティブパッシブ）

AWS FSxNを使用したKafkaクラスタは、AWSクラウドでのパフォーマンスについてベンチマークを実施しました。このベンチマークについては、以降のセクションで説明します。



==== アーキテクチャのセットアップ

次の表に、AWS FSxNを使用するKafkaクラスタの環境設定を示します。

|===
| プラットフォームコンポーネント | 環境の構成 


| Kafka 3.2.3.  a| 
* 3 x動物飼育係–T2.small
* ブローカーサーバ×3–i3en.2xlarge
* Grafana–c5n.2xlarge×1
* 4 x producer/consumer -- c5n.2xlarge *




| すべてのノード上のオペレーティングシステム | RHEL8.6 


| AWS FSxN | 4GB/秒のスループットと160000 IPSのアクティブパッシブインスタンス 
|===


==== NetApp FSxNセットアップ

. 最初のテストでは、2TB、40000 IOPS、2GB/秒のスループットを実現するFSx for NetApp ONTAPファイルシステムを作成しました。
. FSx for NetApp ONTAPでは、テストリージョン（US-East-1）の2GB/秒スループットファイルシステムで達成可能な最大IOPSは8万IOPSです。FSx for NetApp ONTAPファイルシステムの合計最大IOPSは16万IOPSですが、そのためには4GB/秒のスループット導入が必要です。このことについては、このドキュメントの後半で説明します
+
....
[root@ip-172-31-33-69 ~]# aws fsx create-file-system --region us-east-2  --storage-capacity 2048 --subnet-ids <desired subnet 1> subnet-<desired subnet 2> --file-system-type ONTAP --ontap-configuration DeploymentType=MULTI_AZ_HA_1,ThroughputCapacity=2048,PreferredSubnetId=<desired primary subnet>,FsxAdminPassword=<new password>,DiskIopsConfiguration="{Mode=USER_PROVISIONED,Iops=40000"}
....
+
FSx「create-file-system」のコマンドライン構文の詳細については、以下を参照してください。 https://docs.aws.amazon.com/cli/latest/reference/fsx/create-file-system.html[]
たとえば、KMSキーが指定されていない場合に使用されるデフォルトのFSxマスターキーとは異なり、特定のKMSキーを指定できます。

. ファイルシステムを次のように記述したら、JSONの「lifecycle」ステータスが「available」に変わるまで待ちます。
+
....
[root@ip-172-31-33-69 ~]# aws fsx describe-file-systems  --region us-east-1 --file-system-ids fs-02ff04bab5ce01c7c
....
. fsxadminのパスワードは、最初にファイルシステムを作成するときに設定したパスワードです。
. fsxadminからFsxNにログインして、クレデンシャルを検証します
+
....
[root@ip-172-31-33-69 ~]# ssh fsxadmin@198.19.250.244
The authenticity of host '198.19.250.244 (198.19.250.244)' can't be established.
ED25519 key fingerprint is SHA256:mgCyRXJfWRc2d/jOjFbMBsUcYOWjxoIky0ltHvVDL/Y.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '198.19.250.244' (ED25519) to the list of known hosts.
(fsxadmin@198.19.250.244) Password:

This is your first recorded login.
....
. FSxNにStorage Virtual Machineを作成
+
....
[root@ip-172-31-33-69 ~]# aws fsx --region us-east-1 create-storage-virtual-machine --name svmkafkatest --file-system-id fs-02ff04bab5ce01c7c
....
. 新しく作成したFSx for NetApp ONTAPファイルシステムにSSH接続し、以下のサンプルコマンドを使用してSVMにボリュームを作成します。同様に、この検証用に6つのボリュームを作成します。Kafkaのパフォーマンスは、デフォルトのコンスティチュエント（8個）以下のままにすると向上します。
+
....
FsxId02ff04bab5ce01c7c::*> volume create -volume kafkafsxN1 -state online -policy default -unix-permissions ---rwxr-xr-x -junction-active true -type RW -snapshot-policy none  -junction-path /kafkafsxN1 -aggr-list aggr1
....
. ボリュームのサイズを2TBに拡張し、ジャンクションパスにマウントします。
+
....
FsxId02ff04bab5ce01c7c::*> volume size -volume kafkafsxN1 -new-size +2TB
vol size: Volume "svmkafkatest:kafkafsxN1" size set to 2.10t.

FsxId02ff04bab5ce01c7c::*> volume size -volume kafkafsxN2 -new-size +2TB
vol size: Volume "svmkafkatest:kafkafsxN2" size set to 2.10t.

FsxId02ff04bab5ce01c7c::*> volume size -volume kafkafsxN3 -new-size +2TB
vol size: Volume "svmkafkatest:kafkafsxN3" size set to 2.10t.

FsxId02ff04bab5ce01c7c::*> volume size -volume kafkafsxN4 -new-size +2TB
vol size: Volume "svmkafkatest:kafkafsxN4" size set to 2.10t.

FsxId02ff04bab5ce01c7c::*> volume size -volume kafkafsxN5 -new-size +2TB
vol size: Volume "svmkafkatest:kafkafsxN5" size set to 2.10t.

FsxId02ff04bab5ce01c7c::*> volume size -volume kafkafsxN6 -new-size +2TB
vol size: Volume "svmkafkatest:kafkafsxN6" size set to 2.10t.

FsxId02ff04bab5ce01c7c::*> volume show -vserver svmkafkatest -volume *
Vserver   Volume       Aggregate    State      Type       Size  Available Used%
--------- ------------ ------------ ---------- ---- ---------- ---------- -----
svmkafkatest
          kafkafsxN1   -            online     RW       2.10TB     1.99TB    0%
svmkafkatest
          kafkafsxN2   -            online     RW       2.10TB     1.99TB    0%
svmkafkatest
          kafkafsxN3   -            online     RW       2.10TB     1.99TB    0%
svmkafkatest
          kafkafsxN4   -            online     RW       2.10TB     1.99TB    0%
svmkafkatest
          kafkafsxN5   -            online     RW       2.10TB     1.99TB    0%
svmkafkatest
          kafkafsxN6   -            online     RW       2.10TB     1.99TB    0%
svmkafkatest
          svmkafkatest_root
                       aggr1        online     RW          1GB    968.1MB    0%
7 entries were displayed.

FsxId02ff04bab5ce01c7c::*> volume mount -volume kafkafsxN1 -junction-path /kafkafsxN1

FsxId02ff04bab5ce01c7c::*> volume mount -volume kafkafsxN2 -junction-path /kafkafsxN2

FsxId02ff04bab5ce01c7c::*> volume mount -volume kafkafsxN3 -junction-path /kafkafsxN3

FsxId02ff04bab5ce01c7c::*> volume mount -volume kafkafsxN4 -junction-path /kafkafsxN4

FsxId02ff04bab5ce01c7c::*> volume mount -volume kafkafsxN5 -junction-path /kafkafsxN5

FsxId02ff04bab5ce01c7c::*> volume mount -volume kafkafsxN6 -junction-path /kafkafsxN6
....
. FSxNのスループット容量を2GB/秒から4GB/秒に、IOPSを160000に拡張しました
+
....
[root@ip-172-31-33-69 ~]# aws fsx update-file-system --region us-east-1  --storage-capacity 5120 --ontap-configuration 'ThroughputCapacity=4096,DiskIopsConfiguration={Mode=USER_PROVISIONED,Iops=160000}' --file-system-id fs-02ff04bab5ce01c7c
....
+
FSx「update-file-system」の詳細なコマンドライン構文は、次のとおりです。
https://docs.aws.amazon.com/cli/latest/reference/fsx/update-file-system.html[]

. FSxNボリュームは、kafkarブローカーでnconnectとdefault opionを使用してマウントされます
+
image:aws-fsx-kafka-arch1.png["この図は、FSxNベースのKafkaクラスタのアーキテクチャを示しています。"]

+
** コンピューティング：3ノードのKafkaクラスタを使用し、専用サーバで3ノードのZookeeperアンサンブルを実行しました。各ブローカーには、FSxNインスタンス上の6つのボリュームに対する6つのNFSマウントポイントがあります。
** 監視：Prometheus-Grafanaの組み合わせには2つのノードを使用しました。ワークロードの生成には、独立した3ノードクラスタを使用し、このKafkaクラスタを生成して使用しました。
** ストレージ：FSxNを使用し、1TBのボリュームを6個マウントしました。その後、ボリュームはNFSマウントを使用してKafkaブローカーにエクスポートされました。






==== OpenMessageベンチマーク設定。

ここでは、NetApp Cloud Volume ONTAPと同じ構成を使用しました。詳細はこちらをご覧ください。
https://docs.netapp.com/us-en/netapp-solutions/data-analytics/kafka-nfs-performance-overview-and-validation-in-aws.html#architectural-setup[]



==== テストの方法論

. Kafkaクラスタは、前述の仕様に従ってterraformとAnsibleを使用してプロビジョニングされました。Terraformを使用して、Kafkaクラスタ用のAWSインスタンスを使用してインフラを構築し、Ansibleを使用してKafkaクラスタを構築します。
. 上記のワークロード構成とSyncドライバでOMBワークロードがトリガーされました。
+
....
sudo bin/benchmark –drivers driver-kafka/kafka-sync.yaml workloads/1-topic-100-partitions-1kb.yaml
....
. 同じワークロード構成でスループットドライバを使用して別のワークロードがトリガーされました。
+
....
sudo bin/benchmark –drivers driver-kafka/kafka-throughput.yaml workloads/1-topic-100-partitions-1kb.yaml
....




==== 観察

NFSで実行されるKafkaインスタンスのパフォーマンスをベンチマークするために、2種類のドライバを使用してワークロードを生成しました。ドライバの違いは、log flushプロパティです。

Kafkaレプリケーションファクタ1とFSxNの場合：

* Syncドライバで一貫して生成された総スループット：最大3218 Mbps、最大パフォーマンス（最大3652 Mbps）
* スループットドライバによって一貫して生成された総スループット：最大3679 Mbps、最大3908 Mbpsのパフォーマンス。


Kafkaのレプリケーションファクタが3でFSxNの場合：

* Syncドライバで一貫して生成される合計スループット：最大1252 Mbps、最大1382 Mbps。
* スループットドライバによって一貫して生成される総スループット：最大1218 Mbps、最大パフォーマンス（最大1328 Mbps）


Kafkaレプリケーションファクタ3では、FSxNで読み取りと書き込みの処理が3回行われました。Kafkaレプリケーションファクタ1では、FSxNで読み取りと書き込みの処理が1回行われたため、どちらの検証でも最大スループットである4GB/秒に到達できました。

Syncドライバはログが即座にディスクにフラッシュされるときに一貫したスループットを生成できますが、Throughputドライバはログがディスクに一括コミットされるときにスループットのバーストを生成します。

これらのスループット値は、指定されたAWS構成に対して生成されます。より高いパフォーマンス要件に対応するには、インスタンスタイプをスケールアップしてさらに調整し、スループットを向上させることができます。総スループットまたは総レートは、生産者と消費者の両方のレートの組み合わせです。

image:aws-fsxn-performance-rf-1-rf-3.png["この画像は、RF1およびRF3でのKafkaのパフォーマンスを示しています"]

次の表は、Kafkaレプリケーションファクタ3の2GB/秒FSxnと4GB/秒のパフォーマンスを示しています。レプリケーションファクタ3は、FSxNストレージで読み取りおよび書き込み処理を3回実行します。スループットドライバの合計レートは881 MB/秒で、2GB/秒のFSxNファイルシステムでKafkaの読み取りと書き込みを行います。スループットドライバの合計レートは1328 MB/秒で、Kafkaの読み取りと書き込みを行います。Kafkaのパフォーマンスは、FSxNスループットに基づいてリニアで拡張可能です。

image:aws-fsxn-2gb-4gb-scale.png["この図は、2GB/秒と4GB/秒のスケールアウトパフォーマンスを示しています。"]

次のグラフは、EC2インスタンスとFSxNのパフォーマンスを示しています（Kafkaレプリケーション係数：3）。

image:aws-fsxn-ec2-fsxn-comparition.png["この図は、RF3でのEC2とFSxNのパフォーマンス比較を示しています。"]

link:kafka-nfs-performance-overview-and-validation-with-aff-on-premises.html["次の記事：オンプレミスのAFF でのパフォーマンスの概要と検証"]
