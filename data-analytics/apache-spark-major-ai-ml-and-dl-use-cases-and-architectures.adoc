---
sidebar: sidebar 
permalink: data-analytics/apache-spark-major-ai-ml-and-dl-use-cases-and-architectures.html 
keywords: nlp pipelines, tensorflow distributed inferenceing, horovod distributed training, multi-worker, deep learning, keras, ctr prediction 
summary: このページでは、主なAI、ML、DLのユースケースとアーキテクチャについて詳しく説明します。 
---
= AI、ML、DLの主なユースケースとアーキテクチャ
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
主なAI、ML、DLのユースケースと手法は、以下のセクションに分類できます。



== SparkのNLPパイプラインとTensorFlow分散推論です

次のリストには、データサイエンスコミュニティで採用されている最も一般的なオープンソースのNLPライブラリが、さまざまな開発レベルで含まれています。

* https://www.nltk.org/["Natural Language Toolkit（NLTK）"^]です。すべてのNLP手法に対応する完全なツールキットです。2000年代初頭から維持されています。
* https://textblob.readthedocs.io/en/dev/["TextBLOB"^]です。NLTKとPatternの上に構築された使いやすいNLPツールPython API。
* https://stanfordnlp.github.io/CoreNLP/["Stanford Core NLP"^]です。Stanford NLP Groupが開発したJavaのNLPサービスとパッケージ。
* https://radimrehurek.com/gensim/["Gensim氏"^]です。人間のトピックモデリングは、チェコデジタル数学ライブラリプロジェクトのPythonスクリプトの集合として開始されました。
* https://spacy.io/["スパレーシー"^]です。PythonとCythonを使用した、トランスフォーマ用GPUアクセラレーションを備えたエンドツーエンドの産業用NLPワークフロー。
* https://fasttext.cc/["Fasttextの場合"^]です。FacebookのAI Research（Fair）ラボで作成された単語埋め込みや文分類の学習用の無料の軽量オープンソースNLPライブラリです。


Spark NLPは、あらゆるNLPタスクと要件に対応する単一のユニファイド解決策 です。拡張性が高く、パフォーマンスが高く、精度の高いNLPベースのソフトウェアを、実稼働環境で使用できます。また、転移学習を活用し、研究やさまざまな業界における最新のアルゴリズムとモデルを実装しています。上記のライブラリに対するSparkの完全なサポートがないため、Sparkの汎用インメモリ分散Data Processingエンジンをミッションクリティカルな本番ワークフロー向けのエンタープライズクラスのNLPライブラリとして活用するために、Sparkの上に構築されました https://spark.apache.org/docs/latest/ml-guide.html["Spark ML"^]。アノテータは、ルールベースのアルゴリズム、機械学習、TensorFlowを利用してディープラーニングの実装を強化しています。トークン化、レマタイ化、語幹化、部分読み上げタギング、名前付きエンティティー認識など、一般的なNLPタスクを取り上げますが、これらに限定されません。 スペルチェックと感情分析。

トランスフォーマー（BERT）の双方向エンコーダリプレゼンテーションは、NLPのトランスベースの機械学習技術です。事前トレーニングと微調整の概念を普及させました。BERTの変圧器アーキテクチャは機械翻訳から生まれたもので、回帰型ニューラルネットワーク（RNN）ベースの言語モデルよりも長期的な依存関係をモデル化します。また、マスク言語モデリング（MLM）タスクも導入されました。このタスクでは、すべてのトークンのランダムな15%がマスクされ、モデルによって予測され、真の双方向性が実現されます。

金融感情の分析は、専門的な言語と、その分野のラベル付けされたデータが不足しているために困難になっています。FinBERTは、事前訓練されたBERTに基づく言語モデルであり、金融コーパスに適応し https://trec.nist.gov/data/reuters/reuters.html["ロイターTRRC2"^]、金融感情分類のためにラベル付けされたデータ()で微調整された https://www.researchgate.net/publication/251231364_FinancialPhraseBank-v10["金融PhraseBankの"^]。研究者たちは、財務用語を使ってニュース記事から4、500件の文章を抽出した。次に、16人の専門家と修士の学生が、財務上の背景にポジティブ、ニュートラル、ネガティブのラベルを付けています。Spark NLPのFinBERTと他の2つのトレーニング済みパイプラインを使用して、2016年から2020年までのNASDAQ企業収益コールトランスクリプトトップ10のセンチメントを分析するために、エンドツーエンドのSparkワークフローを構築しまし https://nlp.johnsnowlabs.com/2020/03/19/explain_document_dl.html["ドキュメントDLについて説明する"^]た。

Spark NLPの基礎となるディープラーニングエンジンは、機械学習向けのエンドツーエンドのオープンソースプラットフォームであるTensorFlowです。モデル構築が容易で、どこでも堅牢なML生産を実現し、研究のための強力な実験を可能にします。そのため、Sparkモードでパイプラインを実行するときは `yarn cluster`、基本的に分散型TensorFlowを実行し、1つのマスターノードと複数のワーカーノードでデータとモデルを並列化し、クラスタにマウントされたネットワーク接続型ストレージを実行していました。



== Horovodの分散トレーニング

MapReduce関連のパフォーマンスの中核となるHadoop検証は、TeraGen、TeraSort、TeraValidate、およびDFSIO（読み取りおよび書き込み）を使用して実行されます。TeraGenおよびTeraSortの検証結果は、 https://www.netapp.com/pdf.html?item=/media/16420-tr-3969pdf.pdf[]（Eシリーズ）およびAFFの「Storage Tiering」（xref）セクションに記載されています。

お客様からの要望に基づいて、Sparkを使用したトレーニングの配布は、さまざまなユースケースで最も重要なトレーニングの1つと考えています。本ドキュメントでは、を使用して、 https://horovod.readthedocs.io/en/stable/spark_include.html["Hovorod on Spark（SparkでのHovorod"^]NetApp All Flash FAS（AFF）ストレージコントローラ、Azure NetApp Files、StorageGRIDを使用するオンプレミス、クラウドネイティブ、ハイブリッドクラウドソリューションのNetAppのパフォーマンスを検証しました。

Horovod on Sparkパッケージは、Horovodの便利なラッパーを提供します。このラッパーはSparkクラスタで分散されたトレーニングワークロードを簡単に実行できるようにするものです。厳密なモデル設計ループでは、トレーニングデータと推論データが存在するSparkで、データ処理、モデルトレーニング、モデル評価がすべて行われます。

SparkでHorovodを実行するためのAPIには、高レベルのエスティメータAPIと低レベルの実行APIの2つがあります。どちらも、Sparkの実行者に対してHorovodを起動するために同じ基盤メカニズムを使用していますが、Estimator APIはデータ処理、モデルトレーニングループ、モデルチェックポイント、メトリック収集、および分散トレーニングを抽象化します。Horovod Spark Estimators、TensorFlow、Kerasを使用して、エンドツーエンドのデータ準備と、競合他社に基づく分散型トレーニングワークフローを https://www.kaggle.com/c/rossmann-store-sales["Kagle Rossmann Store Sales"^]実現しました。

スクリプトは `keras_spark_horovod_rossmann_estimator.py`、次の3つの部分で構成されているセクションにありlink:apache-spark-python-scripts-for-each-major-use-case.html["主なユースケースごとにPythonスクリプトを使用できます。"]ます。

* 最初の部分では、Kaggleが提供し、コミュニティが収集した最初のCSVファイルのセットを介して、さまざまなデータ前処理ステップを実行します。入力データは、サブセットを持つトレーニングセットとテストデータセットに分割され `Validation`ます。
* 2番目の部分では、対数シグスモイド活性化関数とAdamオプティマイザを使用してKeras Deep Neural Network（DNN）モデルを定義し、Sparkに対してHorovodを使用してモデルの分散トレーニングを実行します。
* 3番目の部分では、検証セット全体の平均絶対エラーを最小化する最適なモデルを使用して、テストデータセットの予測を実行します。次に、出力CSVファイルが作成されます。


さまざまなランタイム比較結果については、セクションを参照してくださいlink:apache-spark-use-cases-summary.html#machine-learning["「機械学習」"]。



== CTR予測にKerasを使用したマルチワーカーディープラーニング

ML プラットフォームとアプリケーションの最近の進歩により、現在は大規模な学習が注目されています。クリックスルー率（ CTR ）は、オンライン広告インプレッション数 100 件あたりの平均クリックスルー数（パーセンテージ）と定義されています。デジタルマーケティング、小売、 E コマース、サービスプロバイダなど、さまざまな業界やユースケースで重要な指標として広く採用されています。CTRのアプリケーションとKubernetesを使用したエンドツーエンドのクラウドAIワークフローの実装、分散型データETL、DaskとCUDA MLを使用したモデルトレーニングの詳細については、を参照してくださいlink:../ai/aks-anf_introduction.html["TR-4904 ：『 Distributed Training in Azure - Click Through Rate Prediction 』"^]。

本テクニカルレポートでは、Kerasを使用したマルチワーカー分散ディープラーニング用ののバリエーション（TR-4904を参照）を使用して https://labs.criteo.com/2013/12/download-terabyte-click-logs-2/["Criteo Terabyteのログデータセットをクリックします"^]、Deep and Cross Network（DCN;ディープネットワーク）モデルでSparkワークフローを構築し、ログ損失エラー関数とベースラインSpark MLロジスティック回帰モデルのパフォーマンスを比較しました。DCNは、制限された角度の効率的な機能の相互作用を効率的にキャプチャし、高度な非線形相互作用を学習し、手動によるフィーチャーエンジニアリングや完全な検索を必要とせず、計算コストも低くなります。

Webスケールのレコメンダシステムのデータはほとんどが個別に分類されるため、フィーチャーの探索には困難な大規模でスパースな機能スペースが必要になります。これは、大規模なシステムのほとんどをロジスティック回帰などの線形モデルに限定しています。しかし、予測可能な機能を頻繁に特定すると同時に、見過ごしていない機能やまれなクロス機能を調べることが、予測を適切に行うための鍵となります。線形モデルは単純で、解析可能で、簡単にスケール変更できますが、表現力は限られています。

一方、クロス機能は、モデルの表現力を向上させる上で重要であることが示されています。残念なことに、このような機能を特定するには、手動での機能開発や完全な検索が必要になることがよくあります目に見えない機能の相互作用を一般化することは、しばしば困難です。DCNのような十字型ニューラルネットワークを使用すると、自動で機能交差を明示的に適用することで、タスク固有の機能エンジニアリングを回避できます。クロスネットワークは複数のレイヤで構成されており、レイヤの深さによって高度な相互作用がプロバンスされます。各レイヤは、既存のレイヤに基づいて上位の相互作用を生成し、以前のレイヤからの相互作用を保持します。

Deep Neural Network（DNN；ディープニューラルネットワーク）は、さまざまな機能で非常に複雑なインタラクションをキャプチャすることを約束します。ただし、DCNと比較して、必要なパラメータの数は非常に多く、クロス機能を明示的に形成できず、一部のタイプの機能の相互作用を効率的に学習できない場合があります。クロスネットワークはメモリ効率が高く、実装も簡単です。クロスコンポーネントとDNNコンポーネントを共同でトレーニングし、予測機能のインタラクションを効率的に取り込み、Crito CTRデータセットで最先端のパフォーマンスを提供します。

DCNモデルは、埋め込みレイヤーとスタッキングレイヤーから始まり、クロスネットワークとディープネットワークが並行して使用されます。次に、2つのネットワークからの出力を組み合わせた最終的な組み合わせレイヤを示します。入力データは、スパースフィーチャーとデンスフィーチャーを持つベクトルにすることができます。Sparkでは、ライブラリにタイプが含まれてい `SparseVector`ます。したがって、ユーザーがそれぞれの機能やメソッドを呼び出す際には、2つの機能を区別し、注意することが重要です。CTR予測のようなWebスケールのレコメンダシステムでは、入力は主にカテゴリ的な特徴である `‘country=usa’`。そのような特徴は、例えば1ホットベクトルとして符号化されることが多い `‘[0,1,0, …]’`。を使用したワンホットエンコード（OHE） `SparseVector`は、絶え間なく変化する語彙が増え続ける現実世界のデータセットを処理する場合に役立ちます。大規模な語彙を処理するために、の例を修正し https://github.com/shenweichen/DeepCTR["Deepctr"^]、DCNの埋め込みおよびスタッキング層に埋め込みベクトルを作成しました。

は、 https://www.kaggle.com/competitions/criteo-display-ad-challenge/data["Critoディスプレイ広告のデータセット"^]広告のクリック率を予測します。13の整数型の機能と、各カテゴリの基数が多い26の分類的な機能があります。このデータセットでは、入力サイズが大きいため、ログロスの0.001が実質的に大きく改善されています。大規模なユーザベースの予測精度がわずかに向上すると、企業の収益が大きく増加する可能性があります。データセットには7日間の11GBのユーザログが格納されており、これは約4100万レコードに相当します。Sparkを使用し `dataFrame.randomSplit()function`て、トレーニング用（80%）、クロスバリデーション用（10%）、テスト用（10%）のデータをランダムに分割しました。

DCNは、Kerasを使用したTensorFlowに実装されました。DCNを使用したモデルトレーニングプロセスの実装には、次の4つの主要コンポーネントがあります。

* * Data Processingおよび埋め込み。*実数値フィーチャは、ログ変換を適用することによって正規化されます。カテゴリフィーチャーの場合、寸法6×（カテゴリの基数）1/4の密度の高いベクトルにフィーチャーを埋め込みます。すべての埋め込み結果を次元1026のベクトルに連結します。
* *最適化。*Adamオプティマイザを用いてミニバッチ確率最適化を適用した。バッチサイズは512に設定されています。ディープネットワークにバッチ正規化が適用され、グラジエントクリップの基準が100に設定されました。
* *規則化。*L2正規化またはドロップアウトが効果的でないことが判明したため、早期停止を使用しました。
* *ハイパーパラメータ。*非表示レイヤーの数、非表示レイヤーのサイズ、初期学習率、クロスレイヤーの数に関するグリッド検索に基づいて結果を報告します。非表示レイヤーの数は2～5で、非表示レイヤーのサイズは32～1024です。DCNの場合、クロスレイヤの数は1～6です。初期学習レートは0.0001から0.001に調整され、0.0001単位で増加しました。すべての実験は訓練ステップ150,000で早期停止を適用し、それを超えて過剰なフィッティングが発生し始めました。


DCNに加えて、CTR予測のための他の一般的なディープラーニングモデル（、 https://arxiv.org/abs/1810.11921["自動内部（AutoInt"^]、、など https://arxiv.org/abs/2008.13535["DCN v2"^]）もテストしました https://www.ijcai.org/proceedings/2017/0239.pdf["DeepFM"^]。



== 検証に使用するアーキテクチャ

この検証では、4つのワーカーノードと1つのマスターノードにAFF-A800 HAペアを使用しました。すべてのクラスタ・メンバーを、10GbEネットワーク・スイッチを介して接続しました。

今回のNetApp Sparkの解決策 検証では、E5760、E5724、AFF-A800の3種類のストレージコントローラを使用しました。Eシリーズストレージコントローラは、12Gbps SAS接続の5つのデータノードに接続されました。AFF のHAペアストレージコントローラは、エクスポートされたNFSボリュームを10GbEでHadoopワーカーノードに接続することで提供します。Hadoopクラスタのメンバーは、Eシリーズ、AFF 、およびStorageGRID のHadoopソリューションで10GbE接続を介して接続されます。

image:apache-spark-image10.png["検証に使用するアーキテクチャ。"]
