---
sidebar: sidebar 
permalink: data-analytics/confluent-kafka-technology-overview.html 
keywords: storagegrid, apache, confluent, kafka, grid manager, 
summary: このセクションでは、この解決策で使用されるテクノロジーについて説明します。 
---
= テクノロジの概要
:hardbreaks:
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:confluent-kafka-solution.html["前へ：解決策。"]

このセクションでは、この解決策で使用されるテクノロジーについて説明します。



== NetApp StorageGRID

NetApp StorageGRID は、ハイパフォーマンスで対費用効果の高いオブジェクトストレージプラットフォームです。ノードベースの分散グリッドアーキテクチャを使用して、インテリジェントなポリシーベースのグローバルデータ管理を実現します。数ペタバイトの非構造化データと数十億のオブジェクトを、ユビキタスなグローバルオブジェクトネームスペースと高度なデータ管理機能を組み合わせることでシンプルに管理できます。単一コールのオブジェクトアクセスはサイト間を拡張し、高可用性アーキテクチャを簡素化しながら、サイトやインフラストラクチャの停止に関係なく、オブジェクトへの継続的なアクセスを保証します。

マルチテナンシーを使用すると、複数の非構造化クラウドアプリケーションやエンタープライズデータアプリケーションを同じグリッド内で安全に処理できるため、 NetApp StorageGRID の ROI とユースケースが向上します。メタデータベースのオブジェクトライフサイクルポリシーを使用して複数のサービスレベルを作成し、複数の地域にわたってデータの保持、保護、パフォーマンス、ローカリティを最適化できます。ユーザは、要件の変化に応じて、ポリシーを調整し、システムを停止せずにデータの再配置を行うことができます。

SmartStore は StorageGRID をリモートストレージ階層として使用し、地理的に分散した複数のサイトを展開して、単一のオブジェクトネームスペースとして提供される堅牢な可用性と耐久性を実現します。これにより、 Splunk SmartStore は、 StorageGRID の高パフォーマンスで高密度な容量を活用し、 1 つの URL で複数の物理サイトにまたがる数百のノードに拡張し、オブジェクトとやり取りすることができます。また、 1 つの URL だけで、ストレージの拡張、アップグレード、修復を、 1 つのサイトだけでなく無停止で実行することもできます。StorageGRID 独自のデータ管理ポリシーエンジンにより、最適なレベルのパフォーマンスと耐久性を実現し、データローカリティ要件を満たします。



=== StorageGRID の機能は Apache と競合製品の Kafka です。

StorageGRID には、ユーザが絶えず変化する環境に合わせてカスタマイズできるさまざまな機能があります。Kafka クラスタの導入から拡張に至るまで、環境には変化への迅速な導入が求められますが、 Kafka を利用することは避けてください。StorageGRID の柔軟なデータ管理ポリシー（ ILM ）とトラフィック分類子（ QoS ）を使用すると、お客様の環境を計画して適合させることができます。



=== Grid Manager で管理を簡易化

Grid Manager はブラウザベースのグラフィカルインターフェイスで、世界中に分散された複数の拠点にわたって、単一のコンソールから StorageGRID システムの設定、管理、監視を実行できます。

image:confluent-kafka-image4.png["エラー：グラフィックイメージがありません"]

Grid Manager インターフェイスでは次のタスクを実行できます。

* イメージ、ビデオ、レコードなどのオブジェクトを収めた、グローバルに分散されたペタバイト規模のリポジトリを管理します。
* グリッドノードとサービスを監視してオブジェクトの可用性を確保します。
* Information Lifecycle Management （ ILM ；情報ライフサイクル管理）ルールを使用してオブジェクトデータの配置を継続的に管理します。これらのルールによって、取り込まれたオブジェクトのデータの処理、損失から保護する方法、格納場所と保管期間が決まります。
* システム内のトランザクション、パフォーマンス、処理を監視します。




=== 情報ライフサイクル管理ポリシー

StorageGRID には柔軟なデータ管理ポリシーが用意されており、特定のパフォーマンスやデータ保護の要件に応じて、オブジェクトの複数のコピーを保持し、 2+1 や 4+2 などの EC （イレイジャーコーディング）スキームを使用してオブジェクトを格納することができます。ワークロードと要件が時間の経過とともに変化する場合、 ILM ポリシーも時間の経過とともに変化する必要があることがよくあります。ILM ポリシーの変更は中核的な機能であり、絶えず変化する環境に StorageGRID のお客様がすばやく簡単に適応できるようにします。



=== パフォーマンス

StorageGRID は SG5712 、 SG5760 、 SG6060 、 SGF6024 などのベアメタルアプライアンスまたは専用アプライアンスであるノードを追加することで、パフォーマンスを拡張します。今回のテストでは、 SG6024 アプライアンスを使用した最小サイズの 3 ノードグリッドを使用して、 Apache Kafka の主要なパフォーマンス要件を超えました。Kafka クラスタを追加のブローカーとともに拡張すれば、ストレージノードを追加してパフォーマンスと容量を高めることができます。



=== ロードバランサとエンドポイントの設定

StorageGRID の管理ノードは、 StorageGRID システムを表示、設定、管理するための Grid Manager UI （ユーザインターフェイス）エンドポイントと REST API エンドポイント、およびシステムアクティビティを追跡するための監査ログを提供します。そこで、 Conluent Kafka の階層化ストレージに可用性の高い S3 エンドポイントを提供するために、 StorageGRID ロードバランサを実装しました。このロードバランサは、管理ノードとゲートウェイノードでサービスとして実行されます。また、ロードバランサはローカルトラフィックを管理し、ディザスタリカバリに役立つ GSLB （グローバルサーバロードバランシング）と通信します。

エンドポイントの設定をさらに強化するために、 StorageGRID は管理ノードに組み込まれたトラフィック分類ポリシーを提供し、ワークロードトラフィックを監視し、さまざまな Quality of Service （ QoS ；サービス品質）制限をワークロードに適用できます。トラフィック分類ポリシーは、ゲートウェイノードおよび管理ノードの StorageGRID ロードバランササービス上のエンドポイントに適用されます。これらのポリシーは、トラフィックの制限と監視に役立ちます。



== Apache Kafka です

Apache Kafka は、 Java と Scala で書かれたストリーム処理を使用したソフトウェアバスのフレームワーク実装です。リアルタイムデータフィードを処理するための、スループットが高く、低レイテンシの統合プラットフォームを提供することを目的としています。Kafka は外部システムに接続して Kafka Connect からデータをエクスポートし、インポートすることができます。また、 Java のストリーム処理ライブラリである Kafka ストリームが提供されます。Kafka では、効率性を重視して最適化されたバイナリの TCP ベースのプロトコルを使用しています。また、ネットワーク往復のオーバーヘッドを軽減するために、メッセージを自然にまとめてグループ化する「メッセージセット」抽象化に依存しています。これにより、より大規模なシーケンシャルディスク処理や、大容量のネットワークパケット、連続するメモリブロックが実現し、 Kafka では、バースト性の高いランダムメッセージ書き込みをリニア書き込みに変換することができます。次の図は、 Apache Kafka の基本的なデータフローを示しています。

image:confluent-kafka-image5.png["エラー：グラフィックイメージがありません"]

Kafka には、 Producer と呼ばれる任意の数のプロセスから生成されるキーと値のメッセージが格納されます。データは、異なるトピック内の異なるパーティションにパーティショニングできます。パーティション内では、メッセージはオフセット（パーティション内のメッセージの位置）によって厳密に順序付けされ、インデックスが作成され、タイムスタンプとともに格納されます。コンシューマと呼ばれる他のプロセスは、パーティションからメッセージを読み取ることができます。Kafka はストリーム処理用の API を提供しており、 Kafka からデータを利用する Java アプリケーションを作成して Kafka に結果を書き込むことができます。Apache Kafka は、 Apache Apex 、 Apache Flink 、 Apache Spark 、 Apache Storm 、 Apache NiFi などの外部ストリーム処理システムとも連携します。

Kafka は 1 つ以上のサーバで構成されたクラスタ（ブローカー）上で実行され、すべてのトピックのパーティションがクラスタノード全体に分散されます。さらに、パーティションは複数のブローカーにレプリケートされます。Kafka はこのアーキテクチャにより、フォールトトレラントな方法で大量のメッセージストリームを配信でき、 Java Message Service （ JMS ）や Advanced Message Queuing Protocol （ AMQP ）などの従来のメッセージングシステムの一部を置き換えることができます。0.11.0.0 リリース以降、 Kafka はトランザクション書き込みを提供しており、これは Streams API を使用して一度のストリーム処理を提供します。

Kafka では、 Regular とコンパクションの 2 種類のトピックをサポートしています。通常のトピックでは、保持期限またはスペースバインドを設定できます。指定した保持期限よりも古いレコードがある場合や、パーティションのスペースバインドを超過している場合、 Kafka では古いデータを削除してストレージスペースを解放することができます。デフォルトでは、トピックの保持期間は 7 日間に設定されていますが、データを無期限に保存することもできます。コンパクションの対象となるトピックについては、レコードの有効期限は時刻やスペースの上限に基づいて切れません。Kafka では、以降のメッセージを同じキーを持つ古いメッセージの更新として扱い、キーごとに最新のメッセージを削除しないことを保証しています。ユーザは、特定のキーのヌル値を持つ、いわゆる tombstone メッセージを書き込むことによって、メッセージを完全に削除できます。

Kafka には 5 つの主要な API があります。

* * Producer API. * は、アプリケーションがレコードのストリームをパブリッシュすることを許可します。
* *Consumer API. * は、アプリケーションがトピックを購読し、レコードのストリームを処理することを許可します。
* * Connector API. * は、トピックを既存のアプリケーションにリンクできる再利用可能なプロデューサおよびコンシューマ API を実行します。
* *Streams API. * この API は入力ストリームを出力に変換し、結果を生成します。
* * 管理者 API 。 Kafka のトピック、ブローカー、その他の Kafka のオブジェクトを管理するのに使用されます。


Kafka メッセージングプロトコルをベースに構築されたコンシューマ向け API とプロデューサー用 API は、 Java で Kafka コンシューマクライアントとプロデューサークライアント向けのリファレンス実装を提供します。基本的なメッセージングプロトコルは、開発者が任意のプログラミング言語で独自のコンシューマクライアントまたはプロデューサクライアントを作成するために使用できるバイナリプロトコルです。これにより、 Java Virtual Machine （ JVM ； Java 仮想マシン）エコシステムの Kafka のロックが解除されます。使用可能な Java 以外のクライアントの一覧は、 Apache Kafka wiki で管理されています。



== 矛盾したカフカ

Conflicent Platform は、データへのアクセス、保存、管理を継続的なリアルタイムストリームとして簡単に行うことができる、フルスケールのデータストリーミングプラットフォームです。ConFluent では、 Apache Kafka を作成した元のクリエイターが開発したサービスを利用して、 Kafka のメリットをエンタープライズクラスの機能で拡張しながら、 Kafka の管理や監視の負担を軽減することができます。現在、 Fortune 100 企業の 80% 以上がデータストリーミングテクノロジを採用しており、そのほとんどが Conluent 社を使用しています。



=== 流暢な理由

履歴データとリアルタイムデータを一元化された単一の情報源に統合することで、 Conluent は、まったく新しいカテゴリの最新のイベント駆動型アプリケーションを簡単に構築し、ユニバーサルデータパイプラインを取得し、拡張性、パフォーマンス、信頼性を備えた強力な新しいユースケースを開放します。



=== 流暢なものは何のために使用されるか。

Conflicent Platform を使用すると、データが異なるシステム間でどのように転送または統合されるかなど、基本的なメカニズムを気にすることなく、データからビジネス価値を引き出す方法に集中できます。具体的には、 Con裕福 なプラットフォームによって、 Kafka へのデータソースの接続やストリーミングアプリケーションの構築、 Kafka インフラの保護、監視、管理が簡易化されます。現在、 Conluent Platform は、金融サービス、オムニチャネル小売、自律走行車など、さまざまな業界のさまざまなユースケースに使用されています。 マイクロサービス、 IoT 。

以下の図は、 ConFluent Kafka プラットフォームのコンポーネントを示しています。

image:confluent-kafka-image6.png["エラー：グラフィックイメージがありません"]



=== 流暢なイベントストリーミング技術の概要

流暢なプラットフォームの中核はです https://kafka.apache.org/["Apache Kafka です"^]最も人気の高いオープンソースの分散ストリーミングプラットフォームです。Kafka の主な機能は次のとおりです。

* レコードのストリームをパブリッシュしてサブスクライブします。
* レコードのストリームをフォールトトレラントな方法で保存します。
* レコードのストリームを処理します。


Conluent Platform には Schema Registry 、 REST Proxy 、合計 100 以上の Kafka コネクタ、および ksqlDB も含まれています。



=== 流暢なプラットフォームのエンタープライズ機能の概要

* * Conluent Control Center * Kafka を管理および監視するための GUI ベースのシステム。Kafka Connect の管理や、他のシステムとの接続の作成、編集、管理を簡単に行うことができます。
* * Kubernetes には流暢な言葉があります。 * Kubernetes の流暢な言葉は Kubernetes のオペレータです。Kubernetes の運用担当者は、特定のプラットフォームアプリケーションに固有の機能と要件を提供することで、 Kubernetes のオーケストレーション機能を拡張します。Con裕福 なプラットフォームの場合は、 Kubernetes での Kafka の導入プロセスを大幅に簡易化し、一般的なインフラのライフサイクルタスクを自動化します。
* * Kafka コネクタは、 Kafka Connect API を使用して、 Kafka をデータベース、キーバリューストア、検索インデックス、ファイルシステムなどの他のシステムに接続します。Confluent Hub には、一般的なデータソースおよびシンク用のダウンロード可能なコネクタがあります。これには、 Conluent Platform でこれらのコネクタの完全なテストとサポートされたバージョンが含まれます。詳細については、を参照してください https://docs.confluent.io/home/connect/userguide.html["こちらをご覧ください"^]。
* * セルフバランシングクラスタ。 * 自動ロードバランシング、障害検出、自己修復機能を提供します。必要に応じてブローカーの追加や運用停止をサポートし、手動での調整は不要です。
* * クラスタを直接接続し、リンクブリッジを介して 1 つのクラスタから別のクラスタにトピックをミラーリングします。クラスタリンクにより、マルチデータセンター、マルチクラスタ、ハイブリッドクラウドの導入を簡易化できます。
* * 流暢な自動データバランサ。 * ブローカーの数、パーティションのサイズ、パーティションの数、およびクラスタ内のリーダーの数について、クラスタを監視します。これにより、データを移動してクラスタ全体で均等なワークロードを作成しながら、トラフィックのリバランシングを調整して、リバランシング中の本番ワークロードへの影響を最小限に抑えることができます。
* * 流暢なリプリケータ * により、複数のデータセンターで複数の Kafka クラスターを容易に保守できます。
* * 階層化ストレージ。 * 任意のクラウドプロバイダを使用して大量の Kafka データを保存するオプションを提供し、運用上の負担とコストを削減します。階層型ストレージでは、コスト効率に優れたオブジェクトストレージにデータを格納し、ブローカーを拡張するために、必要なコンピューティングリソースが増えた場合のみデータを利用できます。
* * Conluent JMS Client. * Conluent Platform には Kafka 用の JMS 対応クライアントが含まれています。Kafka クライアントは、 Kafka ブローカーをバックエンドとして使用して、 JMS 1.1 標準 API を実装しています。これは 'JMS を使用するレガシーアプリケーションがあり ' 既存の JMS メッセージブローカを Kafka に置き換える場合に便利です
* * Coneluent MQTT プロキシ * を使用すると、 MQTT デバイスやゲートウェイから Kafka に直接データを公開できます。 MQTT ブローカーは必要ありません。
* * 流暢なセキュリティプラグイン。 * 流暢なセキュリティプラグインは、各種の流暢なプラットフォームツールや製品にセキュリティ機能を追加するために使用されます。現在、 Conluent REST プロキシ用のプラグインが用意されており、受信要求の認証に役立ち、認証されたプリンシパルを要求に Kafka に伝播できます。これにより、 Con裕福 な REST プロキシクライアントでは、 Kafka ブローカーのマルチテナントセキュリティ機能を利用できます。


link:confluent-kafka-confluent-kafka-certification.html["次に、 ConFluent Kafka の認定資格を取得します。"]
