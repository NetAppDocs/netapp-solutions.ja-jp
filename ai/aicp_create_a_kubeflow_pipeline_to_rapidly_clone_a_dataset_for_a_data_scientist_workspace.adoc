---
sidebar: sidebar 
permalink: ai/aicp_create_a_kubeflow_pipeline_to_rapidly_clone_a_dataset_for_a_data_scientist_workspace.html 
keywords: Kubeflow, ONTAP, Pipeline, SDK, Flexclone, 
summary: データサイエンティストや開発者のワークスペースを作成するために、 NetApp FlexClone テクノロジを活用してデータセットボリュームのクローンを迅速かつ効率的に作成する新しい Kubeflow Pipeline を定義して実行するには、このページに記載されているタスクを実行します。 
---
= Kubeflow パイプラインを作成して、のデータセットを迅速にクローニングします データサイエンティストのワークスペース
:hardbreaks:
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
データサイエンティストや開発者のワークスペースを作成するために、データセットボリュームのクローンを迅速かつ効率的に作成するために NetApp FlexClone テクノロジを活用する新しい Kubeflow Pipeline を定義して実行するには、次のタスクを実行します。Kubeflow パイプラインの詳細については、を参照してください https://www.kubeflow.org/docs/components/pipelines/pipelines/["Kubeflow の公式ドキュメント"^]。このセクションで示すパイプラインの例は、 ONTAP ストレージシステムまたはソフトウェア定義インスタンス上にあるボリュームのみで機能します。

. まだ作成していない場合は、ボリュームが配置されている ONTAP クラスタのクラスタ管理者アカウントのユーザ名とパスワードを含む Kubernetes シークレットを作成します。このシークレットは ' パイプラインが実行される名前空間であるため 'kubeflow' 名前空間に作成する必要がありますこれらのコマンドを実行するときは 'userName' と 'password' をユーザ名とパスワードに置き換える必要がありますまた 'base64 コマンドの出力 ( 強調表示されたテキストを参照 ) を ' それに応じてシークレット定義で使用する必要があります
+
....
$ echo -n 'username' | base64
dXNlcm5hbWU=
$ echo -n 'password' | base64
cGFzc3dvcmQ=
$ cat << EOF > ./secret-ontap-cluster-mgmt-account.yaml
apiVersion: v1
kind: Secret
metadata:
  name: ontap-cluster-mgmt-account
  namespace: kubeflow
data:
  username: dXNlcm5hbWU=
  password: cGFzc3dvcmQ=
EOF
$ kubectl create -f ./secret-ontap-cluster-mgmt-account.yaml
secret/ontap-cluster-mgmt-account created
....
. まだインストールしていない場合は、 Kubeflow Pipelines SDK をインストールする必要があります。を参照してください https://www.kubeflow.org/docs/pipelines/sdk/install-sdk/["Kubeflow の公式ドキュメント"^] を参照してください。
. Kubeflow Pipelines SDK を使用して、 Python で Kubeflow パイプラインを定義します。以下のコマンド例では、実行時に以下のパラメータを受け入れるパイプラインのパイプライン定義を作成し、次の手順を実行します。特定のプロセスに応じて、必要に応じてパイプライン定義を変更します。
+
* ランタイムパラメータ： *

+
** ONTAP_cluster_mgmt_hostname ：データセットとモデルボリュームが格納されている ONTAP クラスタのホスト名 / IP アドレス。
** ONTAP_cluster_admin_acct_k8s_secret ：手順 1 で作成した Kubernetes シークレットの名前
** ONTAP_verify_ssl_cert ： ONTAP API との通信時にクラスタの SSL 証明書を検証するかどうかを指定します（ True または False ）。
** Workspace_name ：新しいワークスペースに付ける名前。
** jupyter_namespace ： Jupyter Notebook ワークスペースを作成する予定の名前空間。Jupyter Notebook ワークスペースの作成の詳細については、「 aicp_provision a_jupyter_notebooker_workspace_for _data_yer_or_developer_use.html [Provision a Jupyter Notebook Workspace^] 」を参照してください。このパイプラインで作成されるデータセットクローンは、 Jupyter Notebook ワークスペースにマウント可能になります。
** dataset_volume_pv_existing ：クローニングするボリュームに関連付けられているデータセットボリューム PVC に対応する Kubernetes PersistentVolume （ PV ）オブジェクトの名前。PV の名前を取得するには、 'kubectl-n <namespace> get pvc' を実行します。指定された PVC に対応する PV の名前は 'volume' 列に表示されますこれは、インポートされたボリュームである可能性があります をクリックします link:aicp_provision_a_jupyter_notebook_workspace_for_data_scientist_or_developer_use.html["Jupyter Notebook Workspace のプロビジョニング"]、手順 1 、または別のボリュームを指定します。
** Trident _Storage_class ：このクローンの作成に使用する Kubernetes StorageClass 。これは通常、で作成した StorageClass です を参照してください link:aicp_example_kubernetes_storageclasses_for_ontap_ai_deployments.html["ONTAP AI 導入向けの Kubernetes StorageClasses の例"]。
** Trident ネームスペース： Trident がインストールされているネームスペース。デフォルトでは、 Trident は trident' 名前空間にインストールされます。
** Trident バックエンド：このクローンの作成に使用する Trident バックエンド。通常は、で作成したバックエンドです を参照してください link:aicp_example_kubernetes_storageclasses_for_ontap_ai_deployments.html["ONTAP AI 導入向けの Kubernetes StorageClasses の例"]。
+
* パイプラインステップ： *

+
... NetApp FlexClone テクノロジを使用して、データセットボリュームのクローンを作成します。
... データセットクローンにアクセスできる対話型 Jupyter Notebook ワークスペースの導入手順を出力します。
+
....
$ cat << EOF > ./create-data-scientist-workspace.py
# Kubeflow Pipeline Definition: Create Data Scientist Workspace
import kfp.dsl as dsl
import kfp.components as comp
from kubernetes import client as k8s_client
# Define function that triggers the creation of a NetApp snapshot
def netappClone(
    ontapClusterMgmtHostname: str,
    sourcePvName: str,
    verifySSLCert: bool = True
) -> str :
    # Install netapp_ontap package
    import sys, subprocess;
    subprocess.run([sys.executable, '-m', 'pip', 'install', 'netapp_ontap'])

    # Import needed functions/classes
    from netapp_ontap import config as netappConfig
    from netapp_ontap.host_connection import HostConnection as NetAppHostConnection
    from netapp_ontap.resources import Volume, Snapshot
    from datetime import datetime
    import json
    # Retrieve ONTAP cluster admin account details from mounted K8s secrets
    usernameSecret = open('/mnt/secret/username', 'r')
    ontapClusterAdminUsername = usernameSecret.read().strip()
    passwordSecret = open('/mnt/secret/password', 'r')
    ontapClusterAdminPassword = passwordSecret.read().strip()

    # Configure connection to ONTAP cluster/instance
    netappConfig.CONNECTION = NetAppHostConnection(
        host = ontapClusterMgmtHostname,
        username = ontapClusterAdminUsername,
        password = ontapClusterAdminPassword,
        verify = verifySSLCert
    )

    # Convert pv name to ONTAP volume name
    # The following will not work if you specified a custom storagePrefix when creating your
    #   Trident backend. If you specified a custom storagePrefix, you will need to update this
    #   code to match your prefix.
    sourceVolumeName = 'trident_%s' % sourcePvName.replace("-", "_")
    print('\nSource pv name: ', sourcePvName)
    print('Source ONTAP volume name: ', sourceVolumeName)
    # Create clone
    sourceVolume = Volume.find(name = sourceVolumeName)
    timestamp = datetime.today().strftime("%Y%m%d_%H%M%S")
    cloneVolumeName = 'kfp_clone_%s' % timestamp
    cloneVolume = Volume.from_dict({
        'name': cloneVolumeName,
        'svm': sourceVolume.to_dict()['svm'],
        'clone': {
            'is_flexclone':'true',
            'parent_volume': sourceVolume.to_dict()
        },
        'nas': {
            'path': '/%s' % cloneVolumeName
        }
    })
    response = cloneVolume.post()
    print("\nAPI Response:")
    print(response.http_response.text)
    # Retrieve clone volume details
    cloneVolume.get()
    # Convert clone volume details to JSON string
    cloneVolumeDetails = cloneVolume.to_dict()
    print("\nClone Volume Details:")
    print(json.dumps(cloneVolumeDetails, indent=2))
    # Return name of new clone volume
    return cloneVolumeDetails['name']
# Convert netappClone function to Kubeflow Pipeline ContainerOp named 'NetappCloneOp'
NetappCloneOp = comp.func_to_container_op(netappClone, base_image='python:3')
# Define Kubeflow Pipeline
@dsl.pipeline(
    name="Create Data Scientist Workspace",
    description="Template for cloning dataset volume in order to create data scientist/developer workspace"
)
def create_data_scientist_workspace(
    # Define variables that the user can set in the pipelines UI; set default values
    ontap_cluster_mgmt_hostname: str = "10.61.188.40",
    ontap_cluster_admin_acct_k8s_secret: str = "ontap-cluster-mgmt-account",
    ontap_api_verify_ssl_cert: bool = True,
    workspace_name: str = "dev",
    jupyter_namespace: str = "admin",
    dataset_volume_pv_existing: str = "pvc-db963a53-abf2-4ffa-9c07-8815ce78d506",
    trident_storage_class: str = "ontap-ai-flexvols-retain",
    trident_namespace: str = "trident",
    trident_backend: str = "ontap-ai"
) :
    # Pipeline Steps:
    # Create a clone of the source dataset volume
    dataset_clone = NetappCloneOp(
        ontap_cluster_mgmt_hostname,
        dataset_volume_pv_existing,
        ontap_api_verify_ssl_cert
    )
    # Mount k8s secret containing ONTAP cluster admin account details
    dataset_clone.add_pvolumes({
        '/mnt/secret': k8s_client.V1Volume(
            name='ontap-cluster-admin',
            secret=k8s_client.V1SecretVolumeSource(
                secret_name=ontap_cluster_admin_acct_k8s_secret
            )
        )
    })
    # Retrieve clone volume name from op output
    clone_volume_Name = dataset_clone.output
    # Convert clone volume name to allowed pvc name (for user instructions)
    workspace_pvc_name = 'dataset-workspace-' + str(workspace_name)
    # Define user instructions
    user_instructions = '''
1) Execute the following commands against your Kubernetes cluster:
cat << EOD > import-pvc-pipeline-clone.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: %s
  namespace: %s
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: %s
EOD
tridentctl -n %s import volume %s %s -f ./import-pvc-pipeline-clone.yaml
2) From Kubeflow "Notebook Servers" dashboard, provision a new Jupyter workspace in namespace, "%s", and mount dataset pvc, "%s".
''' % (workspace_pvc_name, jupyter_namespace, trident_storage_class, trident_namespace, trident_backend, clone_volume_Name, jupyter_namespace, workspace_pvc_name)
    # Print instructions for deploying an interactive workspace
    print_instructions = dsl.ContainerOp(
        name="print-instructions",
        image="ubuntu:bionic",
        command=["sh", "-c"],
        arguments=["echo '%s'" % user_instructions]
    )
    # State that instructions should be printed after clone is created
    print_instructions.after(dataset_clone)
if __name__ == '__main__' :
    import kfp.compiler as compiler
    compiler.Compiler().compile(create_data_scientist_workspace, __file__ + '.yaml')
EOF
$ python3 create-data-scientist-workspace.py
$ ls create-data-scientist-workspace.py.yaml
create-data-scientist-workspace.py.yaml
....




. Kubeflow 中央ダッシュボードで、メインメニューのパイプライン（ Pipelines ）をクリックし、 Kubeflow Pipelines 管理ページに移動します。
+
image:aicp_image29.png["エラー：グラフィックイメージがありません"]

. パイプラインのアップロードをクリックして ' パイプライン定義をアップロードします
+
image:aicp_image30.png["エラー：グラフィックイメージがありません"]

. 手順 3 で作成したパイプライン定義を含む '.yaml ファイルを選択し ' パイプラインに名前を付けて ' アップロードをクリックします
+
image:aicp_image45.png["エラー：グラフィックイメージがありません"]

. パイプライン管理ページのパイプラインのリストに ' 新しいパイプラインが表示されますパイプラインの名前をクリックすると、その名前が表示されます。
+
image:aicp_image46.png["エラー：グラフィックイメージがありません"]

. パイプラインを見直し、正しく見えることを確認します。
+
image:aicp_image47.png["エラー：グラフィックイメージがありません"]

. Create run をクリックしてパイプラインを実行します[+]image:aicp_image48.png["エラー：グラフィックイメージがありません"]
. パイプラインの実行を開始できる画面が表示されます。ランの名前を作成し、概要を入力し、ランをファイルする実験を選択して、 1 回限りのランを開始するか、定期的なランをスケジュールするかを選択します。
+
image:aicp_image49.png["エラー：グラフィックイメージがありません"]

. 実行のパラメータを定義し、 [ 開始 ] をクリックします。次の例では、ほとんどのパラメータにデフォルト値が適用されます。「 dataset_volume_pv_exist'd 」には、既存の PV の名前が入力されます。値「 admin 」は「 jupyter_namespace 」に入力されます。これは、で新しい Jupyter Notebook ワークスペースをプロビジョニングするネームスペースです。パイプライン定義内でパラメータのデフォルト値を定義したことに注意してください ( 手順 3 を参照 )
+
image:aicp_image50.png["エラー：グラフィックイメージがありません"]

. これで、特定の実験の下にあるすべてのランを一覧表示する画面が表示されます。開始したランの名前をクリックして表示します。
+
image:aicp_image51.png["エラー：グラフィックイメージがありません"]

+
この時点では、実行中である可能性があります。

+
image:aicp_image52.png["エラー：グラフィックイメージがありません"]

. 実行が正常に完了したことを確認します。実行が完了すると、パイプラインのすべてのステージに緑色のチェックマークアイコンが表示されます。
+
image:aicp_image53.png["エラー：グラフィックイメージがありません"]

. 「 netappclone 」ステージをクリックし、 Logs をクリックしてそのステージの出力を表示します。
+
image:aicp_image54.png["エラー：グラフィックイメージがありません"]

. 「 print-instructions 」段階をクリックし、ログをクリックして出力された命令を表示します。を参照してください link:aicp_provision_a_jupyter_notebook_workspace_for_data_scientist_or_developer_use.html["Jupyter Notebook Workspace のプロビジョニング"] Jupyter Notebook ワークスペースの作成の詳細については、を参照してください。


image:aicp_image55.png["エラー：グラフィックイメージがありません"]

link:aicp_create_a_kubeflow_pipeline_to_trigger_a_snapmirror_volume_replication_update.html["次のステップ： SnapMirror Volume Replication Update をトリガーする Kubeflow パイプラインを作成します"]
