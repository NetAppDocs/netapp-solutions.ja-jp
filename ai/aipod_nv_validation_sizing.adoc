---
sidebar: sidebar 
permalink: ai/aipod_nv_validation_sizing.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX 
summary: NVIDIA DGXシステムを搭載したNetApp AIPod -終わりに 
---
= NetApp AIPodとNVIDIA DGXシステム-解決策の検証とサイジングに関するガイダンス
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:aipod_nv_architecture.html["以前：NVIDIA DGXシステムを使用したNetApp AIPod -解決策アーキテクチャ"]



== 解決策の検証

この解決策のストレージ構成は、オープンソースツールfioを使用した一連の統合ワークロードを使用して検証されました。テストには、ディープラーニングトレーニングジョブを実行するDGXシステムで生成されるストレージワークロードをシミュレートするI/Oパターンの読み取りと書き込みが含まれます。ストレージ構成は、FIOワークロードを同時に実行する2ソケットCPUサーバのクラスタを使用して検証され、DGXシステムのクラスタをシミュレートしました。各クライアントは、前述したのと同じネットワーク構成で設定され、次の詳細が追加されました。

この検証で使用したマウントオプションは次のとおりです-
•バージョン= 4.1 # pNFSで複数のストレージノードへの並列アクセスを実現
•proto = RDMA #転送プロトコルをデフォルトのTCPではなくRDMAに設定する
•ポート=20049 # RDMA NFSサービスの正しいポートを指定してください
•max_connect = 16 #ストレージポートの帯域幅を集約するためのNFSセッショントランキングを有効にする
•write = eager #バッファ書き込みの書き込みパフォーマンスを向上
•rsize=262144、wsize=262144#はI/O転送サイズを256Kに設定

さらに、クライアントにはNFS max_session_slots値1024を設定しました。解決策では、RDMA経由のNFSを使用してテストしたため、ストレージネットワークポートにはアクティブ/パッシブボンドを設定しました。この検証で使用したボンドパラメータは次のとおりです-
•モード=アクティブバックアップ #ボンディングをアクティブ/パッシブモードに設定します。
•プライマリ=<interface name> #すべてのクライアントのプライマリインターフェイスがスイッチ全体に分散されている
•MII-MONITOR-INTERVAL = 100 #モニタリング間隔を100msに指定します。
•fail-over-mac-policy=active #は、アクティブリンクのMACアドレスがボンドのMACであることを示します。これは、ボンディングされたインターフェイス上でRDMAが適切に動作するために必要です。

2つのA900 HAペア（4台のコントローラ）と1.9TB NVMeディスクドライブを24本搭載したNS224ディスクシェルフをそれぞれのHAペアに接続して、説明のとおりにストレージシステムを構成しました。アーキテクチャのセクションで説明したように、すべてのコントローラのストレージ容量をFlexGroupボリュームを使用して結合し、すべてのクライアントのデータをクラスタ内のすべてのコントローラに分散しました。



== ストレージシステムのサイジングに関するガイダンス

上記のテストに基づき、NVDIIAは、テスト済みのストレージ構成で8台のDGX H100システムのクラスタを容易にサポートできることを認定しました。ストレージパフォーマンス要件の高い大規模な環境では、AFFシステムをNetApp ONTAPクラスタに追加し、1つのクラスタに最大12のHAペア（24ノード）を追加できます。この解決策で説明するFlexGroupテクノロジを使用すると、24ノードクラスタで40PBを超える容量と最大300Gbpsのスループットを単一のネームスペースで実現できます。AFF A400、A250、C800などの他のNetAppストレージシステムは、低パフォーマンスまたは大容量のオプションを提供し、小規模な導入に低コストで対応します。ONTAP 9は混在モデルのクラスタをサポートしているため、最初は小規模な設置面積から始めて、容量やパフォーマンスの要件が増大したときに、クラスタにストレージシステムを追加したり、大容量のストレージシステムを追加したりすることができます。次の表に、各AFFモデルでサポートされるA100およびH100 GPUの概算数を示します。

image:aipod_nv_sizing.png["エラー：グラフィックイメージがありません"]

link:aipod_nv_conclusion_add_info.html["次の記事：NVIDIA DGXシステムを使用したNetApp AIPod -まとめと追加情報"]
