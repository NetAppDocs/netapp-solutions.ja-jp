---
sidebar: sidebar 
permalink: ai/aks-anf_training_time_comparison.html 
keywords: training, time, comparison, pandas, dask, 
summary: このページでは、従来の Pandas を使用したモデルのトレーニング時間を Dask と比較します。Pandas では、メモリオーバーフローを回避するために、処理時間が遅くなるため、より少量のデータをロードしました。そのため、結果を補間して公平な比較を行いました。 
---
= トレーニング時間の比較
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:aks-anf_monitor_dask_using_native_task_streams_dashboard.html["前の手順：ネイティブタスクストリームダッシュボードを使用して Dask を監視します。"]

このセクションでは、従来の Pandas を使用したモデルのトレーニング時間を Dask と比較します。Pandas では、メモリオーバーフローを回避するために、処理時間が遅くなるため、より少量のデータをロードしました。そのため、結果を補間して公平な比較を行いました。

次の表は、 Pandas ランダムフォレストモデルに使用されるデータが大幅に少ない場合の、生のトレーニング時間の比較を示しています ( データセットの 1 日あたりの 2000 億行のうち、 5,000 万行 ) 。このサンプルでは、使用可能なすべてのデータの 0.25% 未満しか使用されていません。DASK cuML の場合は '20 億行すべての使用可能なローについてランダムフォレストモデルをトレーニングしましたこの 2 つのアプローチでは、同等のトレーニング時間が得られました

|===
| アプローチ | トレーニング時間 


| Scikit - Learn ：トレーニングデータとして day15 の 50 M 行のみを使用します | 47 分 21 秒 


| Rapids-DASK ：トレーニングデータとして、 Day15 のすべての 20B 行を使用します | 1 時間 12 分 11 秒 
|===
次の表に示すように、トレーニング時間の結果を直線的に補間する場合、 Dask を使用した分散型トレーニングを使用すると大きな利点があります。従来の Pandas の scikit 学習アプローチでは、クリックログ 1 日あたり 45 GB のデータを処理してトレーニングするのに 13 日かかりますが、 Rapids-Dask アプローチでは同じ量のデータを処理するのにかかる時間は 262.39 倍になります。

|===
| アプローチ | トレーニング時間 


| Scikit - Learn ：トレーニングデータとして day15 のすべての 20B 行を使用します | 13 日、 3 時間、 40 分、 11 秒 


| Rapids-DASK ：トレーニングデータとして、 Day15 のすべての 20B 行を使用します | 1 時間 12 分 11 秒 
|===
前の表では、 Dask と Rapids を使用してデータ処理とモデルトレーニングを複数の GPU インスタンスに分散することで、従来の Pandas DataFrame 処理と比較して、 scikit 学習モデルトレーニングでの実行時間が大幅に短縮されたことを確認できます。このフレームワークを使用すると、マルチノードのマルチ GPU クラスタ内だけでなく、クラウド内でもオンプレミスでのスケールアップとスケールアウトが可能です。

link:aks-anf_monitor_dask_and_rapids_with_prometheus_and_grafana.html["次の例： Prometheus と Grafana で Dask と Rapids を監視します。"]
