---
sidebar: sidebar 
permalink: ai/aipod_nv_architecture.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX 
summary: NVIDIA DGXシステムを搭載したNetApp AIポッド-アーキテクチャ 
---
= NVIDIA DGXシステムを搭載したNetApp AIポッド-アーキテクチャ
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:aipod_nv_sw_components.html["以前：ONTAP AI -ソフトウェアコンポーネント"]

このリファレンスアーキテクチャでは、コンピューティングクラスタのインターコネクトとストレージアクセスに別 々 のファブリックを利用します。コンピューティングノード間のInfiniBand（IB）接続にNDR200とHDR200を使用するオプションもあります。DGX H100システムにはNDR IB接続用にConnectX-7カードがあらかじめ搭載されていますが、DGX A100システムでは、HDRまたはNDR接続用にConnectX-6カードまたはConnectX-7カードをそれぞれ使用できます。



== ONTAP AIとDGX H100システム

次の図は、ONTAP AIでDGX H100システムを使用している場合の解決策トポロジ全体を示しています。

image:oai_H100_topo.png["エラー：グラフィックイメージがありません"]

この構成では、コンピューティングクラスタネットワークでQM9700 NDR IBスイッチのペアを使用します。これらのスイッチは、高可用性を実現するために接続されています。各DGX H100システムは、8つのNDR200接続を使用してスイッチに接続されます。一方のスイッチには偶数番のポートが接続され、もう一方のスイッチには奇数番のポートが接続されています。

ストレージシステムへのアクセス、インバンド管理、およびクライアントアクセスには、SN4600イーサネットスイッチのペアを使用します。スイッチはスイッチ間リンクで接続され、さまざまなトラフィックタイプを分離するために複数のVLANで設定されます。大規模な展開では、スパイン用にスイッチペアを追加し、必要に応じてリーフを追加することで、イーサネットネットワークをリーフスパイン構成に拡張できます。各DGX A100システムには、イーサネットおよびストレージのトラフィック用に2つのデュアルポートConnectX-6カードがプロビジョニングされています。この解決策では、4つのポートすべてが200GbpsでSN4600イーサネットスイッチに接続されています。各カードの1つのポートがLACP MLAGボンドに構成され、各スイッチに1つのポートが接続されます。このボンドでは、インバンド管理、クライアントアクセス、およびユーザレベルのストレージアクセス用のVLANがホストされます。各カードのもう一方のポートは、AFF A800ストレージシステムへの接続用に別 々 に専用のRoCEストレージVLANで使用されます。これらのポートは、NFS v3、pNFSを使用したNFSv4.x、およびRDMA経由のNFSを使用したハイパフォーマンスストレージアクセスをサポートします。

コンピューティングインターコネクトと高速イーサネットネットワークに加えて、すべての物理デバイスを1つ以上のSN2201イーサネットスイッチに接続し、アウトオブバンド管理を行います。  DGX A100システムの接続の詳細については、 link:https://nvdam.widen.net/s/nfnjflmzlj/nvidia-dgx-basepod-reference-architecture["NVIDIA BasePODドキュメント"]。



== ONTAP AIとDGX A100システム

次の図は、DGX A100システムとHDRコンピューティングファブリックとONTAP AIを使用している場合の解決策トポロジ全体を示しています。

image:oai_A100_topo.png["エラー：グラフィックイメージがありません"]

この構成では、コンピューティングクラスタネットワークがQM8700 HDR IBスイッチのペアを使用します。これらのスイッチは、高可用性を実現するために相互に接続されています。各DGX A100システムは、4つのシングルポートConnectX-6カードを使用して200Gbpsでスイッチに接続されます。一方のスイッチには偶数番のポートが接続され、もう一方のスイッチには奇数番のポートが接続されます。

ストレージシステムへのアクセス、インバンド管理、およびクライアントアクセスには、SN4600イーサネットスイッチのペアを使用します。スイッチはスイッチ間リンクで接続され、さまざまなトラフィックタイプを分離するために複数のVLANで設定されます。大規模な展開では、スパイン用にスイッチペアを追加し、必要に応じてリーフを追加することで、イーサネットネットワークをリーフスパイン構成に拡張できます。各DGX A100システムには、イーサネットおよびストレージのトラフィック用に2つのデュアルポートConnectX-6カードがプロビジョニングされています。この解決策では、4つのポートすべてが200GbpsでSN4600イーサネットスイッチに接続されています。各カードの1つのポートがLACP MLAGボンドに構成され、各スイッチに1つのポートが接続されます。このボンドでは、インバンド管理、クライアントアクセス、およびユーザレベルのストレージアクセス用のVLANがホストされます。各カードのもう一方のポートは、AFF A800ストレージシステムへの接続用に別 々 に専用のRoCEストレージVLANで使用されます。これらのポートは、NFS v3、pNFSを使用したNFSv4.x、およびRDMA経由のNFSを使用したハイパフォーマンスストレージアクセスをサポートします。

コンピューティングインターコネクトと高速イーサネットネットワークに加えて、すべての物理デバイスを1つ以上のSN2201イーサネットスイッチに接続し、アウトオブバンド管理を行います。  DGX A100システムの接続の詳細については、 link:https://nvdam.widen.net/s/nfnjflmzlj/nvidia-dgx-basepod-reference-architecture["NVIDIA BasePODドキュメント"]。



== 管理プレーンサーバ

このリファレンスアーキテクチャには、管理プレーン用に5台のCPUベースのサーバも含まれています。これらのシステムのうち2つは、クラスタの導入と管理のためのBase Command Managerのヘッドノードとして使用されます。他の3つのシステムは、ジョブのスケジューリングにSlurmを利用する導入環境向けに、Kubernetesマスターノードやログインノードなどの追加のクラスタサービスを提供するために使用されます。Kubernetesを活用した導入では、NetApp Astra Trident CSIドライバを活用して、AFF A800ストレージシステム上の管理ワークロードとAIワークロードの両方に永続的ストレージを使用した自動プロビジョニングとデータサービスを提供できます。

各サーバは、クラスタの導入と管理を可能にするためにIBスイッチとイーサネットスイッチの両方に物理的に接続されます。また、前述したクラスタ管理アーティファクトの保存用に、管理SVMを介したストレージシステムへのNFSマウントが設定されます。

link:aipod_nv_storage.html["次の記事：NVIDIA DGXシステムを搭載したNetApp AIポッド-ストレージシステムの設計とサイジングのガイダンス"]
