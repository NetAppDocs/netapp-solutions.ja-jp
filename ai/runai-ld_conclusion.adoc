---
sidebar: sidebar 
permalink: ai/runai-ld_conclusion.html 
keywords: azure, lane, detection, run, ai, workloads 
summary: ネットアップの Run AI は、このテクニカルレポートの作成時にパートナー関係を結び、 Azure NetApp Files 独自の機能と、 AI ワークロードのオーケストレーションを簡易化する Run AI プラットフォームを実証しています。 
---
= まとめ
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


ネットアップと Run ： AI は、このテクニカルレポートの作成時にパートナー関係を結び、 Azure NetApp Files 独自の機能と、 AI ワークロードのオーケストレーションを簡易化する AI プラットフォームを、 RUN の手法で実証しています。このテクニカルレポートでは、分散レーン検出トレーニングのためにデータパイプラインとワークロードオーケストレーションのプロセスを合理化するリファレンスアーキテクチャを提供します。

その結果、大規模な分散トレーニング（特にパブリッククラウド環境）に関しては、リソースのオーケストレーションとストレージのコンポーネントは解決策の重要な要素となります。データ管理によって複数の GPU 処理が妨げられることがないようにすることで、 GPU サイクルの利用率を最適化できます。そのため、大規模な分散トレーニングのために、システムをできるだけ費用対効果の高いものにすることができます。

ネットアップが提供するデータファブリックを使用すると、データサイエンティストやデータエンジニアは、手動操作なしでオンプレミスとクラウドを連携させ、同期データを保持できるため、この課題を克服できます。つまり、データファブリックによって、 AI ワークフローを複数の場所に分散して管理するプロセスがスムーズになります。また、コンピューティングと分析、トレーニング、検証に必要なときに必要な場所でデータを利用できるため、オンデマンドでのデータ可用性が容易になります。この機能により、データ統合だけでなく、データパイプライン全体の保護とセキュリティも実現できます。
