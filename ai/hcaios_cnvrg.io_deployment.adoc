---
sidebar: sidebar 
permalink: ai/hcaios_cnvrg.io_deployment.html 
keywords: cnrvg.io, Deployment, Kubernetes 
summary:  
---
= cnvrg.io の展開
:hardbreaks:
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/




== Helm を使用して cnvrg コアを導入します

Helm は、任意のクラスタ、オンプレミス、 Minikube 、または任意のクラウドクラスタ（ AKS 、 EKS 、 GKE など）を使用して、 cnvrg を迅速に導入する最も簡単な方法です。このセクションでは、 Kubernetes がインストールされたオンプレミス（ DGX-1 ）インスタンスに cnvrg がインストールされた方法について説明します。



=== 前提条件

インストールを完了する前に、ローカルマシンに次の依存関係をインストールして準備する必要があります。

* Kubectl のように入力する
* Helm 3.x
* Kubernetes クラスタ 1.15 以降




=== Helm を使用して展開します

. 最新の cnvrg Helm チャートをダウンロードするには、次のコマンドを実行します。
+
....
helm repo add cnvrg https://helm.cnvrg.io
helm repo update
....
. cnvrg を導入する前に、クラスタの外部 IP アドレス、および cnvrg を導入するノードの名前が必要です。オンプレミスの Kubernetes クラスタに cnvrg を導入するには、次のコマンドを実行します。
+
....
helm install cnvrg cnvrg/cnvrg --timeout 1500s  --wait \ --set global.external_ip=<ip_of_cluster> \ --set global.node=<name_of_node>
....
. 「 helm install 」コマンドを実行します。すべてのサービスとシステムがクラスタに自動的にインストールされます。この処理には最大 15 分かかることがあります。
. 「 helm install 」コマンドの所要時間は最大 10 分です。展開が完了したら、新しく展開した cnvrg の URL に移動するか、新しいクラスタを組織内のリソースとして追加します。「 helm' 」コマンドは正しい URL を通知します。
+
....
Thank you for installing cnvrg.io!
Your installation of cnvrg.io is now available, and can be reached via:
Talk to our team via email at
....
. すべてのコンテナのステータスが「 Running 」または「 Complete 」の場合、 cnvrg は正常に展開されています。次のような出力が表示されます。


....
NAME                            READY   STATUS      RESTARTS   AGE
cnvrg-app-69fbb9df98-6xrgf              1/1     Running     0          2m cnvrg-sidekiq-b9d54d889-5x4fc           1/1     Running     0          2m controller-65895b47d4-s96v6             1/1     Running     0          2m init-app-vs-config-wv9c4                0/1     Completed   0          9m init-gateway-vs-config-2zbpp            0/1     Completed   0          9m init-minio-vs-config-cd2rg              0/1     Completed   0          9m minio-0                                 1/1     Running     0          2m postgres-0                              1/1     Running     0          2m redis-695c49c986-kcbt9                  1/1     Running     0          2m seeder-wh655                            0/1     Completed   0          2m speaker-5sghr                           1/1     Running     0          2m
....


== ResNet50 および胸部 X 線を使用したコンピュータビジョンモデルトレーニング データセット

NVIDIA DGX システムを基盤とする NetApp ONTAP AI アーキテクチャ上の Kubernetes セットアップに、 cnvrg.io AI OS が導入されました。検証には、胸部 X 線の匿名画像からなる NIH 胸部 X 線データセットを使用しました。画像は PNG 形式でした。このデータは NIH クリニカルセンタおよびによって提供された は、から使用できます https://nihcc.app.box.com/v/ChestXray-NIHCC["NIH ダウンロードサイト"^]。250 GB のサンプルデータを 15 クラスの 627 、 615 イメージで使用しました。

データセットは cnvrg プラットフォームにアップロードされ、 NetApp AFF A800 ストレージシステムからの NFS エクスポートにキャッシュされました。



== コンピューティングリソースをセットアップする

cnvrg アーキテクチャおよびメタスケジューリング機能により、エンジニアおよび IT プロフェッショナルは、異なるコンピューティングリソースを 1 つのプラットフォームに接続できます。今回のセットアップでは、ディープラーニングワークロードの実行用に導入されたクラスタ cnvrg を使用しました。追加のクラスタを接続する必要がある場合は、次のスクリーンショットに示すように、 GUI を使用してください。

image:hcaios_image7.png["エラー：グラフィックイメージがありません"]



== データをロードします

cnvrg プラットフォームにデータをアップロードするには、 GUI または cnvrg CLI を使用します。大規模なデータセットの場合は、 CLI の使用を推奨します。 CLI は、多数のファイルを処理できる、拡張性と信頼性に優れた強力なツールです。

データをアップロードするには、次の手順を実行します。

. をダウンロードします https://app.cnvrg.io/docs/cli/install.html["cnvrg CLI"^]。
. X 線ディレクトリに移動します。
. 「 cnvrg data init 」コマンドを使用して、プラットフォーム内のデータセットを初期化します。
. 「 cnvrg data sync 」コマンドを使用して、ディレクトリのすべての内容を中央のデータレイクにアップロードします。データが中央のオブジェクトストア（ StorageGRID 、 S3 、またはその他）にアップロードされたら、 GUI で参照できます。次の図は、ロードされた胸部 X 線線維症画像 PNG ファイルを示しています。さらに、 cnvrg は、ビルドしたすべてのモデルをデータバージョンに複製できるように、データをバージョン化します。


image:hcaios_image8.png["エラー：グラフィックイメージがありません"]



== マッハデータ

トレーニングを高速化し、モデルのトレーニングや実験ごとに 600k 以上のファイルをダウンロードしないようにするために、データを最初に中央のデータレイクオブジェクトストアにアップロードしたあとにデータキャッシュ機能を使用しました。

image:hcaios_image9.png["エラー：グラフィックイメージがありません"]

ユーザーが Cache をクリックすると、 cnvrg はリモートオブジェクトストアから特定のコミットでデータをダウンロードし、 ONTAP NFS ボリュームにキャッシュします。完了すると、データをすぐにトレーニングに利用できるようになります。さらに、データが数日間使用されていない場合（たとえば、モデルのトレーニングや探索など）、 cnvrg は自動的にキャッシュをクリアします。



== キャッシュデータで ML パイプラインを構築

cnvrg フローを使用すると、本番 ML パイプラインを簡単に構築できます。フローは柔軟性が高く、あらゆる種類の ML ユースケースに対応し、 GUI またはコードを使用して作成できます。フロー内の各コンポーネントは、異なる Docker イメージを使用して異なるコンピューティングリソース上で実行できるため、ハイブリッドクラウドを構築し、 ML パイプラインを最適化できます。

image:hcaios_image10.png["エラー：グラフィックイメージがありません"]



=== 胸部 X 線フローの構築：データの設定

新しく作成したフローにデータセットを追加しました。データセットを追加する際には、特定のバージョン（ commit ）を選択し、キャッシュされたバージョンが必要かどうかを指定できます。この例では、キャッシュされたコミットを選択しました。

image:hcaios_image11.png["エラー：グラフィックイメージがありません"]



=== 胸部 X 線フローの構築：トレーニングモデルの設定： ResNet50

パイプラインでは、任意の種類のカスタムコードを追加できます。cnvrg には、再利用可能な ML コンポーネントコレクションである AI ライブラリもあります。AI ライブラリには、アルゴリズム、スクリプト、データソースなど、あらゆる ML やディープラーニングフローで使用できるソリューションがあります。この例では、 ResNet50 の事前ビルドモジュールを選択しました。batch_size ： 128 、 epochs ： 10 などのデフォルトパラメータを使用しました。これらのパラメータは AI ライブラリのドキュメントで確認できます。次のスクリーンショットは、 X 線データセットが ResNet50 に接続された新しいフローを示しています。

image:hcaios_image12.png["エラー：グラフィックイメージがありません"]



== ResNet50 の計算リソースを定義します

cnvrg フロー内の各アルゴリズムまたはコンポーネントは、異なる Docker イメージを使用して、異なるコンピューティングインスタンス上で実行できます。セットアップでは、 NetApp ONTAP AI アーキテクチャを採用した NVIDIA DGX システムでトレーニングアルゴリズムを実行したいと考えていました。次の図では、「 GPU - REAL 」を選択しました。これは、オンプレミスクラスタのコンピューティングテンプレートであり、仕様です。また、テンプレートのキューを作成し、複数のテンプレートを選択しました。このようにして 'GPU 実数のリソースを割り当てることができない場合 ( たとえば ' 他のデータ・サイエンティストがリソースを使用している場合 ) は ' クラウド・プロバイダ・テンプレートを追加して ' 自動クラウド・バーストを有効にできます次のスクリーンショットは、 ResNet50 のコンピューティングノードとしての GPU 実数の使用を示しています。

image:hcaios_image13.png["エラー：グラフィックイメージがありません"]



=== 結果の追跡と監視

フローが実行されると、 cnvrg はトラッキングおよびモニタリングエンジンをトリガーします。フローの各実行は自動的に文書化され、リアルタイムで更新されます。ハイパーパラメータ、指標、リソース使用率（ GPU 利用率など）、コードバージョン、アーティファクト、ログ また、次の 2 つのスクリーンショットに示すように、 ［ テスト ］ セクションで自動的に使用できるようになります。

image:hcaios_image14.png["エラー：グラフィックイメージがありません"]

image:hcaios_image15.png["エラー：グラフィックイメージがありません"]

link:hcaios_conclusion.html["次は終わりです"]
