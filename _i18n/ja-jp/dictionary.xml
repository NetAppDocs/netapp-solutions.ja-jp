<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="750b570f7c6cacf7b9f43c1c7919ad96" category="inline-link">thePub に掲載された AI に関するブログ</block>
  <block id="183754618306c7f8d7df04f981d234f0" category="list-text"><block ref="183754618306c7f8d7df04f981d234f0" category="inline-link-rx"></block></block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="1cf7e301510c711b73d2b182b9dcf084" category="doc">ユースケース</block>
  <block id="ad54e6f7d665098e981d7e41732ce4c2" category="inline-link-macro">次の例は、アーキテクチャです</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">エラー：グラフィックイメージがありません</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">こちらをご覧ください</block>
  <block id="be5acbec67071810913f6782071a73eb" category="section-title">ストレージ設計</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">アーキテクチャ</block>
  <block id="9a50201aa3bf66a7a0337ccf29d20c90" category="section-title">解決策テクノロジ</block>
  <block id="2b0d957e4ad1bdfd446155ff5bb8a9b2" category="section-title">アーキテクチャ図</block>
  <block id="b831e128b8fd177e9c80396ed741b7c1" category="section-title">ハードウェアとソフトウェアの要件</block>
  <block id="a623a8d0366bf079411aa30be45b2d10" category="section-title">コンピューティング</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">ハードウェア</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">モデル</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">数量</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">ソフトウェア</block>
  <block id="261addf78c7b2c961032b3dd08ba0b1f" category="cell">目的</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">バージョン</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="cell">仮想化</block>
  <block id="c73bbd3786350b0a8d3577d82afdf489" category="cell">Red Hat Enterprise Linux の場合</block>
  <block id="80e910f35b12e9c61335fa88de36edd0" category="cell">Red Hat 仮想化</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="section-title">ストレージ</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4.</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2.</block>
  <block id="fcda5b98e8c212807dc088477e802757" category="cell">NetApp Element</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="3a3a5cd068731551120f43f37950768b" category="cell">ONTAP Select の場合</block>
  <block id="f82f50748d06cc9643330a4a8297ba43" category="cell">9.7</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="section-title">ネットワーキング</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3.</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">追加情報の検索場所</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">このドキュメントに記載されている情報の詳細については、以下のドキュメントや Web サイトを参照してください。</block>
  <block id="1b214ce6b630c9ad822fc984e20f3675" category="inline-link"><block ref="1b214ce6b630c9ad822fc984e20f3675" category="inline-link-rx"></block></block>
  <block id="91fe04078e98f81bd39430c985bba713" category="paragraph"><block ref="91fe04078e98f81bd39430c985bba713" category="inline-link-rx"></block></block>
  <block id="8887a9a417a1629326acdb917d224337" category="list-text">VMware vSphere の場合</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="list-text">NetApp Interoperability Matrix Tool で確認できます</block>
  <block id="930dd6e7cbd550494f96b487d9d38ec8" category="section-title">ハードウェア要件</block>
  <block id="9d273bd32c1fceb91b7d6a4d40e98bdd" category="section-title">ソフトウェア要件</block>
  <block id="d9ae1ecd6158beb6acd24c9f59d0498e" category="paragraph">次の表に、解決策の実装に必要なソフトウェアコンポーネントを示します。解決策の実装で使用されるソフトウェアコンポーネントは、お客様の要件に応じて異なる場合があります。</block>
  <block id="5eed1e48d8861a1192e8694a3d24021b" category="inline-link-macro">次：ユースケース</block>
  <block id="0cdff7d38ef496f6b5510c5034fedf15" category="list-text">パフォーマンスを保証するマルチテナンシー</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="section-title">テクノロジの概要</block>
  <block id="16600c3602f9acbaa2286f34135f6bb8" category="paragraph">NetApp Element ソフトウェアクラスタでは、 QoS をボリューム単位で動的に設定できます。ボリュームごとの QoS 設定を使用して、定義した SLA に基づいてストレージパフォーマンスを制御できます。QoS は、次の 3 つの設定可能なパラメータで定義されます。</block>
  <block id="d91a826908d0c27cf5d21d2152292ab0" category="list-text">* 最小 IOPS 。 * NetApp Element ソフトウェアクラスタがボリュームに提供する平常時の最小 IOPS 。ボリュームに設定された最小 IOPS は、そのボリュームに対して最低限保証されるパフォーマンスレベルです。ボリュームごとのパフォーマンスがこのレベルを下回ることはありません。</block>
  <block id="827b5871d6ce8f2203a567ef3024f072" category="list-text">* Burst IOPS 。 * 短時間のバースト時に許容される最大 IOPS 。バースト期間の設定は、デフォルトの 1 分に設定できます。ボリュームが最大 IOPS レベル未満で動作しているときは、バーストクレジットが蓄積されます。パフォーマンスレベルが非常に高くなってプッシュされると、ボリュームで IOPS が最大 IOPS を超えた短時間のバーストが許容されます。</block>
  <block id="e95bb6f1e85d1ffe0eb983fd5e0fbde8" category="section-title">マルチテナンシー</block>
  <block id="086d1eacd91102f734387f0266326344" category="paragraph">セキュアマルチテナンシーには、次の機能があります。</block>
  <block id="78712bd6b2d8e5531e122b5e849fb842" category="paragraph">NetApp Element ソフトウェアクラスタを使用すると、全体的なストレージ効率とパフォーマンスが向上します。次の機能はインラインで実行されます。常時有効であり、ユーザによる手動設定は必要ありません。</block>
  <block id="7adf04762320f012179ffe68fb0aeb9f" category="paragraph">RHV は以下の機能を提供します。</block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">概要</block>
  <block id="87495e311a3944910e3cc0c7bee3d754" category="cell">VLAN</block>
  <block id="b7dff125c9fce628900142990708436f" category="cell">アウトオブバンド管理ネットワーク</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="7b9993fac4b9a60605aa2884eb40f4a3" category="cell">インバンド管理ネットワーク</block>
  <block id="36a1694bce9815b7e38a9dad05ad42e0" category="cell">1172</block>
  <block id="cd3718e8610b820344c9a0284fe84f90" category="cell">ストレージネットワーク</block>
  <block id="21c5bba1dd6aed9ab48c2b34c1a0adde" category="cell">3343</block>
  <block id="3de18ffc25309bd0755d8543a30ded78" category="cell">移行用ネットワーク</block>
  <block id="38a77aa456fc813af07bb428f2363c8d" category="cell">3345</block>
  <block id="9335616a8b7dc0e6f94fd0c6aa720efe" category="list-text">インバンド管理ネットワークと VM ネットワークからアクセス可能な完全なホスト名解決を提供する DNS サーバが少なくとも 1 台必要です。</block>
  <block id="905a394004d9055ec4708e53880cac66" category="list-text">インバンド管理ネットワークおよび VM ネットワークからアクセスできる NTP サーバが少なくとも 1 台必要です。</block>
  <block id="729d72c073b607d370c067152cc53a10" category="doc">検証結果</block>
  <block id="1b21b0d71706897b69f108572c444d40" category="cell">ハイパーバイザー</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">該当なし</block>
  <block id="b872d0389acf826cc7cf1939cd17a05d" category="inline-link-macro">次へ：追加情報の検索場所</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="doc">概要</block>
  <block id="1ddf333c6654f7f89c739dddfb4cc429" category="section-title">アプリケーション</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">前提条件</block>
  <block id="794df3791a8c800841516007427a2aa3" category="section-title">使用許諾</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="section-title">導入</block>
  <block id="1be465260df7c846768e06c988594a6a" category="paragraph">このドキュメントに記載されている情報の詳細については、次の Web サイトを参照してください。</block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="cell">NetApp Trident</block>
  <block id="7cd95c816f8a04ff858a857e3e5a484d" category="cell">20.04</block>
  <block id="b175d08ac03101cd40f077848d436e1f" category="cell">Red Hat OpenShift のサービスです</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">コンテナオーケストレーション</block>
  <block id="93b3852e5c67975dd33b1769b24a4a85" category="paragraph">Jenkins アプリケーションの導入に必要なリソースを作成するには、次の手順に従います。</block>
  <block id="9fd493573e73cb0e5e55e97306249596" category="list-text">Jenkins という名前の新しいプロジェクトを作成します。</block>
  <block id="5690195262fb589b6021733b4a5a4432" category="paragraph"><block ref="5690195262fb589b6021733b4a5a4432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d256abce3dbdfed83e337956e42f60f" category="list-text">この例では、永続的ストレージを使用して Jenkins を導入しています。Jenkins ビルドをサポートするには、 PVC を作成します。[ ストレージ ] &gt; [ 永続的ボリューム要求 ] の順に選択し、 [ 永続的ボリューム要求の作成 ] をクリックします。作成したストレージクラスを選択し、永続ボリューム要求名が Jenkins であることを確認し、適切なサイズとアクセスモードを選択して、作成をクリックします。</block>
  <block id="f9db9f308c8ed7f5d0ed0851d8d605cb" category="paragraph"><block ref="f9db9f308c8ed7f5d0ed0851d8d605cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9272f40a21ca3dad814c4e3886b40776" category="section-title">永続的ストレージを使用して Jenkins を導入する</block>
  <block id="939a7b51bfb262627185af768c3c1024" category="paragraph">永続ストレージを使用して Jenkins を導入するには、次の手順を実行します。</block>
  <block id="bc5512ef7a17a0cfb58cb1ede30a6137" category="paragraph"><block ref="bc5512ef7a17a0cfb58cb1ede30a6137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="949381804bf1e16ca04ba9ac5fabc6a4" category="paragraph"><block ref="949381804bf1e16ca04ba9ac5fabc6a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc9a211dac876290bd6ed039cf1afdcf" category="paragraph"><block ref="cc9a211dac876290bd6ed039cf1afdcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="274c247b7612630006e3d87d5ed5d46f" category="paragraph"><block ref="274c247b7612630006e3d87d5ed5d46f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da33835bff86a0b0c8be6c67dcf677bb" category="list-text">ポッドがインスタンス化されたら、ネットワーキング &gt; ルートと進みます。Jenkins の Web ページを開くには、 Jenkins ルート用の URL をクリックします。</block>
  <block id="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="paragraph"><block ref="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="paragraph"><block ref="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9359288fc248319fa9acef62e4686d1c" category="paragraph"><block ref="9359288fc248319fa9acef62e4686d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00713894c16827219fd5ab50c5fc3794" category="paragraph"><block ref="00713894c16827219fd5ab50c5fc3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24f99be3c7033ab08c3baec1cdf32702" category="paragraph"><block ref="24f99be3c7033ab08c3baec1cdf32702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b6fc174a3fad5c396413febe1d4ba50" category="list-text">[ 項目の作成 ] ページで、任意の名前を入力し、 [ パイプライン ] を選択して、 [OK] をクリックします。</block>
  <block id="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="paragraph"><block ref="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dedbf53849830e8b275b69e9b98159ce" category="paragraph"><block ref="dedbf53849830e8b275b69e9b98159ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0191ad3b841f8db403ec4749d571eb4b" category="list-text">「今すぐビルド」をクリックして、準備、ビルド、テストの各フェーズで開発を開始します。ビルドプロセス全体が完了してビルドの結果が表示されるまでに数分かかることがあります。</block>
  <block id="1d11f84feef51515ab9fdaafb3f02f3a" category="paragraph"><block ref="1d11f84feef51515ab9fdaafb3f02f3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b04b355d9fc6a2e23965649ebdd0aa31" category="list-text">コードが変更された場合は、必ずパイプラインを再構築して新しいバージョンのソフトウェアにパッチを適用することで、継続的な統合と継続的な提供を実現できます。[ 最近の変更 ] をクリックして、前のバージョンからの変更を追跡します。</block>
  <block id="43d9a2fc4d89e82c869a466778811ab3" category="paragraph"><block ref="43d9a2fc4d89e82c869a466778811ab3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="648bdcd0b9a0f83d7b068dbed3c21c07" category="doc">設計上の考慮事項</block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">ネットワーク設計</block>
  <block id="f1744781b12c15ad3b748bea44d9582b" category="section-title">VLAN の要件</block>
  <block id="e8e0dd181e4ee545195120626098bfba" category="cell">3480</block>
  <block id="3fb04953d95a94367bb133f862402bce" category="cell">3481</block>
  <block id="b7fede84c2be02ccb9c77107956560eb" category="cell">3487</block>
  <block id="35b5078b5953437a59ffd4f77c464800" category="section-title">ネットワークインフラストラクチャサポートリソース</block>
  <block id="c2ffe02d76c4f089648f1647b43e4ee5" category="section-title">ベストプラクティス</block>
  <block id="2d52bcd2e896c32a66c9fe10fed38e0f" category="inline-link-macro">次の手順：ハードウェアとソフトウェアの要件</block>
  <block id="6e16409ed6038c106c7fa1dfbfb9da0f" category="admonition">また、適切なフラグを指定して「 OC debug 」コマンドを実行することにより、 MachineConfig が正常に適用され、サービスが正常に開始されたことを確認することもできます。</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">ハードウェア要件</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">ソフトウェア要件</block>
  <block id="9c295b8302ac546bb93a346b68089f50" category="cell">6.7U3</block>
  <block id="bfd15aa26ba0ced782240c4a8b7e517e" category="cell">ストレージ管理</block>
  <block id="59a703e67b19adc4bdb1373c25fbca94" category="inline-link-macro">次：導入手順</block>
  <block id="98f770b0af18ca763421bac22b4b6805" category="section-title">の機能</block>
  <block id="f95d0437e813349fa018b7f0e68e9a7d" category="paragraph">導入したユーザクラスタに Trident をインストールし、永続ボリュームをプロビジョニングするには、次の手順を実行します。</block>
  <block id="422269f9bb560b76869cbd586b8370d5" category="list-text">ダウンロードしたバンドルから Trident のインストールを解凍します。</block>
  <block id="68602d0447fae81afa9d0528ef0c6420" category="list-text">Trident にはこのファイルを渡すオプションがないため、まず、ユーザクラスタの「 kubeconfig 」ファイルの場所を環境変数として設定します。</block>
  <block id="5d710ec7d521df428edd75c1885ee89b" category="list-text">'trident-installer' ディレクトリには ' 必要なすべてのリソースを定義するマニフェストが含まれています適切なマニフェストを使用して、「 TridentOrchestrator 」カスタムリソース定義を作成します。</block>
  <block id="0ac11186fb38b2e9d4acd38d03f61b5c" category="list-text">存在しない場合は、指定されたマニフェストを使用して、クラスタ内に Trident ネームスペースを作成します。</block>
  <block id="004c51fe71b5c654f88a31270ec6c8e9" category="list-text">トライデントオペレータの配備に必要なリソースを作成しますたとえば ' オペレータ用のサービスアカウント 'ClusterRole' および 'ClusterRoleBind' を 'ServiceAccount' 専用の 'PodSecurityPolicy' またはオペレータ自体に割り当てます</block>
  <block id="f7b9c678b684e969a3ee5ac971514f48" category="list-text">次のコマンドを使用すると、展開後にオペレータのステータスを確認できます。</block>
  <block id="b34dd67c198ad4cf0088bd29c7ef4658" category="list-text">オペレータが導入したら、 Trident をインストールできます。これには 'TridentOrchestrator を作成する必要があります</block>
  <block id="64e437a845e5de3c8e50925ebdfce295" category="list-text">Trident が正しくインストールされていることを確認するには、ネームスペースで実行されているポッドを確認するか、 tridentctl バイナリを使用してインストールされているバージョンを確認します。</block>
  <block id="dd7f72325e6f60ea7163b071e4d5e2cc" category="list-text">このバックエンドファイルを設定したら、次のコマンドを実行して最初のバックエンドを作成します。</block>
  <block id="d8f188eff4c16fa87dd87f51db847f73" category="list-text">バックエンドを作成したら、次にストレージクラスを作成する必要があります。バックエンドと同様に、 sample_inputs フォルダにある環境用に編集可能なサンプルのストレージクラスファイルがあります。作業ディレクトリにコピーし、作成したバックエンドを反映するために必要な編集を行います。</block>
  <block id="eb22c0d536e50f388da6dfd91ba4c0b6" category="list-text">このファイルに対して行う必要がある唯一の編集は ' バックエンドタイプの値を ' 新しく作成されたバックエンドのストレージドライバの名前に定義することですまた、名前フィールドの値もメモしておきます。この値は、以降の手順で参照する必要があります。</block>
  <block id="cc66c30273a9be504b88d3239e65516b" category="paragraph"><block ref="cc66c30273a9be504b88d3239e65516b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86b43786316d35748685c4f7abc4145b" category="paragraph"><block ref="86b43786316d35748685c4f7abc4145b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05808f0e86c04c2a062c2e041f9e0827" category="cell">VLAN ID</block>
  <block id="c87f7de78a1912f53050e58df90e1445" category="cell">仮想ゲスト移行用のネットワーク</block>
  <block id="447cb4a01965e3df01476db3576e0399" category="list-text">（オプション）インバンド管理ネットワークと VM ネットワークの両方のアウトバウンドインターネット接続。</block>
  <block id="0f19aa91cffca51fd061e34dee1e5c79" category="paragraph">このセクションでは、この解決策を本番環境に導入する前に考慮する必要があるベストプラクティスをいくつか紹介します。</block>
  <block id="5c00bc5cb1bdae240d18551e77806abd" category="inline-link">Red Hat 6.11アフィニティグループのドキュメント</block>
  <block id="1050f3dc9e3ee559789e3b25f2e4f77e" category="inline-link">Red Hat OpenShift カスタマイズを使用した RHV へのクラスタのインストール</block>
  <block id="3f4b17e041e63192875c654812122484" category="paragraph">ネットアップ、 Alan Cowles 氏と Nikhil M Kulkarni 氏</block>
  <block id="932ba7da1da9b241bfc5ddbb10e49da2" category="paragraph">企業は、新しい製品の作成、リリースサイクルの短縮、新機能の迅速な追加を目的として、 DevOps の手法を採用する傾向に迫られています。即応性に優れた本来の性質から、コンテナやマイクロサービスは、 DevOps の実践を支援するうえで重要な役割を果たします。しかし、エンタープライズ環境で本番環境規模で DevOps を実践する場合、独自の課題が生じ、基盤となるインフラに次のような一定の要件が課せられます。</block>
  <block id="43ee156205e7f74e32a02d556537fe90" category="list-text">スタック内のすべてのレイヤで高可用性を実現します</block>
  <block id="b59807af538b77fee1fb3d1d3c81f9a8" category="list-text">導入手順の簡易化</block>
  <block id="1a4af279491c72d7c36b4c9767ae712f" category="list-text">API ベースのプログラム可能なインフラで、マイクロサービスの即応性を維持します</block>
  <block id="8ca11bfd783c730b04c0c77fc7574406" category="list-text">仮想ワークロードとコンテナ化されたワークロードを同時に実行できます</block>
  <block id="0111977afdb7fa380f806edbe8438163" category="list-text">ワークロードのニーズに応じてインフラを個別に拡張できる</block>
  <block id="ecfb2402c181e98da49a5d763378b116" category="paragraph"><block ref="ecfb2402c181e98da49a5d763378b116" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb8e8e87ec9c630a0a27910fe29abceb" category="paragraph">RHV は、 Red Hat Enterprise Linux （ RHEL ）上で動作し、 KVM ハイパーバイザーを使用するエンタープライズ仮想データセンタープラットフォームです。</block>
  <block id="603bc85f6f6f4d9e5095745d9252f1d3" category="inline-link">Red Hat Virtualization の Web サイト</block>
  <block id="8a961382f0c47dc86706f0aa8bb93fb4" category="paragraph">RHV の詳細については、を参照してください<block ref="ac07861257bcab0c21d310fa00cb324b" category="inline-link-rx"></block>。</block>
  <block id="0178ef6806a57586f6c66dde7e0e86d2" category="list-text">* 仮想マシンとホストの一元管理。 * RHV マネージャは、導入環境内で物理マシンまたは仮想マシン（ VM ）として動作し、中央インターフェイスから解決策を管理するための Web ベースの GUI を提供します。</block>
  <block id="01b0ee840ef208c283c3f4e959aa9427" category="paragraph"><block ref="01b0ee840ef208c283c3f4e959aa9427" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd89bb4228981d3b22187eb451421cd6" category="section-title">Red Hat OpenShift Container Platform</block>
  <block id="16c321ec2744799f0acef92ce84d06ca" category="paragraph"><block ref="16c321ec2744799f0acef92ce84d06ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="doc">解決策コンポーネント</block>
  <block id="bd4ffcaabbe4a4f83fbfaaa2e34dc8a3" category="section-title">iSCSI ログインのリダイレクト機能と自己回復機能</block>
  <block id="5c8e89de2b8e6e2f103d858b59e5aca0" category="section-title">NetApp Element ソフトウェアクラスタの QoS</block>
  <block id="97bee3e8d0db89b2cd19eba861763e7a" category="list-text">* セキュアな認証。 * Challenge Handshake Authentication Protocol （ CHAP ；チャレンジハンドシェイク認証プロトコル）は、ボリュームへのセキュアなアクセスに使用されます。Lightweight Directory Access Protocol （ LDAP ）は、管理とレポートのためのクラスタへのセキュアなアクセスに使用されます。</block>
  <block id="3918507b16aa3cc38274c29da446d90f" category="list-text">* ボリュームアクセスグループ（ VAG ）。 * 必要に応じて、任意の数の iSCSI イニシエータ固有の iSCSI Qualified Name （ IQN ）を 1 つ以上のボリュームにマッピングし、認証の代わりに VAG を使用できます。VAG 内のボリュームにアクセスするには、イニシエータの IQN がボリュームグループの許可された IQN リストに含まれている必要があります。</block>
  <block id="28328e0db9c18c9ada207997f806124f" category="list-text">* テナント仮想 LAN （ VLAN ）。 * ネットワークレベルでは、 iSCSI イニシエータと NetApp Element ソフトウェアクラスタ間のエンドツーエンドのネットワークセキュリティは、 VLAN を使用することで容易になります。ワークロードまたはテナントを分離するために作成された VLAN については、 NetApp Element ソフトウェアが、特定の VLAN 経由でのみアクセス可能な iSCSI ターゲット SVIP アドレスを別途作成します。</block>
  <block id="fca8436836d48525b8d98babbfd68518" category="list-text">* テナント SVIP アドレスへの L3 ルーティング。 * この機能を使用すると、 iSCSI イニシエータを、 NetApp Element ソフトウェアクラスタとは別のネットワークまたは VLAN に配置できます。</block>
  <block id="c08531651ee4977d5020da1b84003631" category="section-title">エンタープライズクラスのストレージ効率化</block>
  <block id="2e5dd3a69ccb3f04d7814fc742318204" category="list-text">* 圧縮。 * 圧縮は、データが NVRAM に書き込まれる前にインラインで実行されます。データは 4K ブロック単位で圧縮され、システム内で圧縮されたままとなります。この圧縮により、クラスタ全体での容量消費、書き込み処理数、および帯域幅消費が大幅に削減されます。</block>
  <block id="95f1b89c8e9c330fcfdc8ec84633bfe6" category="list-text">* Helix 。 * 個々のボリュームのメタデータはメタデータドライブに格納され、セカンダリメタデータドライブにレプリケートされて冗長性が確保されます。</block>
  <block id="ea2625d89edeb5ba9cb41ca58df54e93" category="paragraph">Anthos には次のような機能があります。</block>
  <block id="c10e0a21a04a29dfca9609b3ec4bab76" category="list-text">* Anthos の構成管理。 * ハイブリッド Kubernetes 環境のポリシーとセキュリティを自動化します。</block>
  <block id="e8c4d5cbaf3932ffa3fa7a097bff923e" category="list-text">* Anthos サービスメッシュ * は、 Istio 電源のサービスメッシュにより、アプリケーションのオブザーバビリティ、セキュリティ、および制御を強化します。</block>
  <block id="844236b21d302f8c93eda00636abfff8" category="list-text">* セキュリティー要件。 * セキュリティーの懸念が高まるお客様や、パブリッククラウドに保存できない機密データセットをお持ちのお客様は、自社のデータセンターのセキュリティーからアプリケーションを実行できるため、組織の要件を満たすことができます。</block>
  <block id="ae6f5747bf29f889c1d28208afab2a1a" category="doc">アプリケーションの展開</block>
  <block id="cef52206f11ced919c8d0dd4b2c791a4" category="paragraph">次のセクションでは、アプリケーションのインストールと展開の方法について説明します。</block>
  <block id="d0954433c0b62861850b87d9cba7599f" category="inline-link-macro">次の手順： GitHub からコードを取得します</block>
  <block id="255a6bf7e1d34563f76daaf2b6cd6184" category="paragraph"><block ref="26e27ac56fb4c03c9632ab9bd4fc068b" category="inline-link-macro-rx"></block>。</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">Kubeflow の公式ドキュメント</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="summary">ネットアップストレージシステム / プラットフォーム上に Kubernetes クラスタ内のコンテナにマウントする必要のある既存のボリュームがあり、クラスタ内の PVC に関連付けられていない場合は、それらのボリュームをインポートする必要があります。これらのボリュームは、 Trident のボリュームインポート機能を使用してインポートできます。</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="doc">既存のボリュームをインポートします</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">Kubernetes の公式ドキュメント</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link">Trident のドキュメント</block>
  <block id="3429b7e0331de8d2f8d377b034ca6855" category="inline-link-macro">Trident の導入と設定</block>
  <block id="c701c7fe143bef79cc6eebc32606262e" category="paragraph">このドキュメントに記載されている情報の詳細については、次のリソースを参照してください。</block>
  <block id="c7c082299876892b4274ecfb3c3f7bcd" category="list-text">NVIDIA DGX-1 サーバ：</block>
  <block id="d2647f7d8e79758eea27c6cdcf636638" category="list-text">NVIDIA DGX-1 サーバ</block>
  <block id="45a310b0e4b087b75cb073303044f6f9" category="inline-link"><block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="af828c56c03364ebbde4c582adeb8de3" category="paragraph"><block ref="af828c56c03364ebbde4c582adeb8de3" category="inline-link-rx"></block></block>
  <block id="65d1be94e9f29dc4af77bef169d5be14" category="list-text">NVIDIA Tesla V100 Tensor コア GPU</block>
  <block id="fad8218d69ce01748faed5492aa5d3ef" category="inline-link"><block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="a724832176ce84a9d4be5c34e44891d3" category="paragraph"><block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="list-text">NVIDIA GPU Cloud （ NGC ）</block>
  <block id="5c75bfead88762783d54deaaa3d62735" category="inline-link"><block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="839d9b8469a8d9554891a7515a2b9be7" category="paragraph"><block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="64ba1593b4427fb62b53b007d4a1c26e" category="list-text">NetApp AFF システム：</block>
  <block id="584122d1d5e8c2c4232e029a6896ba40" category="list-text">AFF データシート</block>
  <block id="9a84c14d2692222552174943486e7136" category="inline-link"><block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="0d9d8991a05834f0e52a99b37ce360b8" category="paragraph"><block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="b4199ce9c494dec10c6ee051ddb413e2" category="list-text">AFF 向け NetApp FlashAdvantage プログラム</block>
  <block id="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link"><block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="72cf25e9f1e13167cd0dde6f285552ea" category="paragraph"><block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="30df7f622635480ab538fb3016f9c36a" category="list-text">ONTAP 9.x のドキュメント</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="35d8efcf211e40a836698bff14ed0ff6" category="list-text">NetApp FlexGroup テクニカルレポート</block>
  <block id="1ab29fc7fde3319a82a477ec308cf820" category="inline-link"><block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="7a26d62dac2be507dcc3e5b9da0ed765" category="paragraph"><block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="de1e4a3a0cae539a34678546eb6e91b3" category="list-text">コンテナ向けのネットアップの永続的ストレージ：</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="1cb9a8619999ebc0a2d9c07624d76166" category="list-text">NetApp Interoperability Matrix を参照してください</block>
  <block id="d51c982ce98a1e197c234ea0b9a5e7d9" category="inline-link"><block ref="d51c982ce98a1e197c234ea0b9a5e7d9" category="inline-link-rx"></block></block>
  <block id="7a211d267d46c5b44662098f9234fcd0" category="list-text">ONTAP AI ネットワーク：</block>
  <block id="b8a60c56690ddfc62bd735d0b212c396" category="list-text">Cisco Nexus 3232C スイッチ</block>
  <block id="bb31172f259c591005fd4cbcdbfadd11" category="inline-link"><block ref="bb31172f259c591005fd4cbcdbfadd11" category="inline-link-rx"></block></block>
  <block id="96eb8aa0e86d101fdf87284d7d6f1bc7" category="paragraph"><block ref="96eb8aa0e86d101fdf87284d7d6f1bc7" category="inline-link-rx"></block></block>
  <block id="926dc08a3a3a3946402bb1beab6545cc" category="list-text">Mellanox Spectrum 2000 シリーズスイッチ</block>
  <block id="193721fbb9ea3851cafcea43a4d95f73" category="list-text">ML フレームワークとツール：</block>
  <block id="edb7d6728a9813b505cb306367d453e3" category="list-text">大理</block>
  <block id="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="inline-link"><block ref="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="inline-link-rx"></block></block>
  <block id="1b2766572fa1896116e3c218eb697113" category="list-text">TensorFlow ：あらゆる環境に対応するオープンソースの機械学習フレームワーク</block>
  <block id="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link"><block ref="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link-rx"></block></block>
  <block id="26909d0380bdba02e2fcf7f7157cd78b" category="list-text">Horovod ： Uber が開発したオープンソースの TensorFlow 用分散学習フレームワーク</block>
  <block id="3ffa9619031400d374ed5c0860d434ab" category="inline-link"><block ref="3ffa9619031400d374ed5c0860d434ab" category="inline-link-rx"></block></block>
  <block id="c9cbaff7c173f4b7bc923573ca753577" category="list-text">コンテナランタイムエコシステムでの GPU の有効化</block>
  <block id="b3a776c1e64d267ebe62a7bf45c6c1b7" category="inline-link"><block ref="b3a776c1e64d267ebe62a7bf45c6c1b7" category="inline-link-rx"></block></block>
  <block id="c5fd214cdd0d2b3b4272e73b022ba5c2" category="list-text">Docker です</block>
  <block id="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link"><block ref="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link-rx"></block></block>
  <block id="60ea9e9ecbf839c413c5e977002eabf4" category="paragraph"><block ref="60ea9e9ecbf839c413c5e977002eabf4" category="inline-link-rx"></block></block>
  <block id="30136395f01879792198317c11831ea4" category="list-text">Kubernetes</block>
  <block id="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link"><block ref="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link-rx"></block></block>
  <block id="6bd14be39aedfe96ceacec2caaac0532" category="paragraph"><block ref="6bd14be39aedfe96ceacec2caaac0532" category="inline-link-rx"></block></block>
  <block id="142f782bb2b326679982208fe40cec31" category="list-text">NVIDIA DeepOps のことです</block>
  <block id="ccd09fd9430cf2df88a137dbec97676b" category="inline-link"><block ref="ccd09fd9430cf2df88a137dbec97676b" category="inline-link-rx"></block></block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="list-text">クビフロー</block>
  <block id="a33d91971f7757996ab0eb8eb0362814" category="inline-link"><block ref="a33d91971f7757996ab0eb8eb0362814" category="inline-link-rx"></block></block>
  <block id="6771540ad76dbed724cb9025978b8510" category="paragraph"><block ref="6771540ad76dbed724cb9025978b8510" category="inline-link-rx"></block></block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="list-text">Jupyter Notebook Server の 2 つのツールを使用</block>
  <block id="c90a0598d42425e6ec2dfb3058534b35" category="inline-link"><block ref="c90a0598d42425e6ec2dfb3058534b35" category="inline-link-rx"></block></block>
  <block id="ef9e62eeb81c0987fbe61de48635886a" category="paragraph"><block ref="ef9e62eeb81c0987fbe61de48635886a" category="inline-link-rx"></block></block>
  <block id="22d149e351657eac5bd1db4934498bbe" category="list-text">データセットとベンチマーク：</block>
  <block id="b318879f822314efe94c2f096d06465c" category="list-text">ImageNet</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="doc">謝辞</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">ネットアップテクニカルマーケティングエンジニア、 Mike Oglesby 氏</block>
  <block id="94a8512f59eafd68b470105fc3269fd4" category="list-text">ネットアップシニアテクニカルディレクター Santosh Rao 氏</block>
  <block id="17e1dd6389643aeecf567ba08bf1df2c" category="paragraph"><block ref="17e1dd6389643aeecf567ba08bf1df2c" category="inline-link-macro-rx"></block></block>
  <block id="bd3114e9e2000f42e265a067e98b0d25" category="doc">フルフィルメントエンジンとしてサードパーティ API に接続します</block>
  <block id="1aea646cd3c044dd0758af18e73cfef3" category="paragraph">次のサードパーティ API を欠品補充エンジンとして回答の質問に関連付けました。</block>
  <block id="94c494471216991658782a32f1e3ef37" category="inline-link">WeatherStack API</block>
  <block id="f7eb24e530470f21243c27770bd2c549" category="list-text"><block ref="c8600f69e922164a09610e481537b92d" category="inline-link-rx"></block>: 指定された場所の天候、温度、降雨および雪を返す。</block>
  <block id="1c96228fa1453bf3f691d5081cbd6adb" category="inline-link">Yelp Fusion API</block>
  <block id="55a3b552be8202b066ea237b831186f4" category="list-text"><block ref="8af0de0530d799485b6d6a2d146ab784" category="inline-link-rx"></block>: 指定された場所で最も近いストア情報を返します。</block>
  <block id="114e8180b93cb1b21cd00067e446e5f0" category="inline-link">eBay Python SDK</block>
  <block id="da6816adc86546982065d9aef78845e5" category="list-text"><block ref="3d046b40b6d382ee41dd02d3b6ab007c" category="inline-link-rx"></block>: 指定されたアイテムの価格を返します。</block>
  <block id="3f7ba19f5b656e6cf8db9c69330a6d6e" category="inline-link-macro">次のステップ： NetApp Retail Assistant のデモ</block>
  <block id="23e96dc8693037c8fa1d7c0587a2d5eb" category="paragraph"><block ref="23e96dc8693037c8fa1d7c0587a2d5eb" category="inline-link-macro-rx"></block></block>
  <block id="37e875b843ef9539c02d09d3bbee6668" category="doc">セクション 4.8 のテストの詳細</block>
  <block id="638c2d891d4e85bcfae409499fba817c" category="inline-link-macro">オーバークォータの GPU 割り当てによる高いクラスタ利用率の達成</block>
  <block id="d9ed812c8dd9083f1fb345425b8ce100" category="paragraph">ここでは、のテストの詳細について説明します <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>。</block>
  <block id="f354c9a7a0a52e7a5a3514252ea5f8b7" category="paragraph">次の順序でジョブを送信します。</block>
  <block id="9e727fdd3aec8274f46685441900280d" category="cell">プロジェクト</block>
  <block id="be53a0541a6d36f6ecb879fa2c584b08" category="cell">イメージ（ Image ）</block>
  <block id="b3428404a5be1cf95d4e53b2ddc8288a" category="cell">GPU の数</block>
  <block id="96b0141273eabab320119c467cdcaf17" category="cell">合計</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">コメント（ Comment ）</block>
  <block id="9320270de4ff6824ae7a21f729fb7d44" category="cell">チーム A</block>
  <block id="c6e328a3639bc00374d81e681f89f609" category="cell">Jupyter</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1.</block>
  <block id="ff8bed43ac09b1148fc7648f5845f698" category="cell">1/4</block>
  <block id="37ce74088416f28dc9bb04355c2e5a28" category="cell">–</block>
  <block id="cfaa375bf6c7f9fcc1bc04d4f30c9154" category="cell">ネットアップ</block>
  <block id="6408e079aefee9702aa00f77228dd941" category="cell">2/4</block>
  <block id="00833fac70036c049bd75443869cacb5" category="cell">実行： AI</block>
  <block id="36d2df43ead992a1e3c86acd0cec69f9" category="cell">4 月 4 日</block>
  <block id="d2313e844e73fe4a8f63d93f4df355fc" category="cell">すべてのクォータを使用しています</block>
  <block id="238ff8d9192e9c01e50a8d6d21f1607b" category="cell">チーム - b</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="e4275e3860ed32f489dbb6a5d4a10f5f" category="cell">0.6/2</block>
  <block id="8457d97e0a0f74a5926d1dee27e53541" category="cell">フラクショナル GPU</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="975ca8804565c1a569450d61090b2743" category="cell">1/2</block>
  <block id="867c7d7d65c50ae3679fabce2eab87a3" category="cell">2/2.</block>
  <block id="c3a4885d143dc5b306446fb380c6cfda" category="cell">4 月 2 日</block>
  <block id="411472b1216ec08457e653eac42d7bbd" category="cell">クォータに 2 つ</block>
  <block id="3b40d1328b825dda4b761a8e534669b7" category="cell">チーム -c</block>
  <block id="d310cb367d993fb6fb584b198a2fd72c" category="cell">0.5</block>
  <block id="76169512ef5ca1abe70b32c0993856af" category="cell">0.5/2</block>
  <block id="e85b79abfd76b7c13b1334d8d8c194a5" category="cell">0.3</block>
  <block id="5c2b079fc9750c2995852b8fb354aae3" category="cell">0.8/2.</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="00fd1da21e8b4ef31d987665dc575099" category="cell">3/2</block>
  <block id="0375b76ff57435094e28e94015a5f052" category="cell">クォータに 1 つ</block>
  <block id="ae7ccf7b1a6a1a023f611a294572a900" category="cell">チーム -d</block>
  <block id="ecdb9acc2db02134680a9c49abe3e991" category="cell">4/8</block>
  <block id="30c006c71ada68e2273b128bc2e6831b" category="cell">クォータの半分を使用します</block>
  <block id="36cf0dc9f04c54214fa577ec66ff53fc" category="paragraph">コマンドの構造：</block>
  <block id="7b3a4ccf5e0cc7918cd458f7e46b9c8e" category="paragraph">テストで使用する実際のコマンドシーケンス：</block>
  <block id="3bf38f884fd74f6e6f1ec3d80018edd8" category="paragraph">この時点で、次の状態になります。</block>
  <block id="e55f05703a3e04fbd9e10f76ae925cc9" category="cell">GPU が割り当てられました</block>
  <block id="26cc9c6ccae01f319282379c339cd90b" category="cell">ワークロードキュー</block>
  <block id="478eb1c4e698b325048b6bccfb8974f6" category="cell">4/4 （ソフトクォータ / 実際の割り当て）</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="cell">なし</block>
  <block id="2df6f557cc57e6d4044b9611b1f56439" category="inline-link-macro">「 Achieving High Cluster Utilization With over-uota 」 GPU 割り当て</block>
  <block id="3667ebc7f28f59fc13bfcf314c67de05" category="paragraph">を参照してください <block ref="dee5d16c649661a62d3a765af5b1a963" category="inline-link-macro-rx"></block> 進行中のテストシナリオについてのディスカッションにご参加ください。</block>
  <block id="ac8466404b94a669f51a3d2db2401cf0" category="inline-link-macro">次は、セクション 4.9 のテストの詳細です</block>
  <block id="84b7d04f598931bc149a92c543d3146f" category="paragraph"><block ref="84b7d04f598931bc149a92c543d3146f" category="inline-link-macro-rx"></block></block>
  <block id="1e92efa8f46c28a3c3a1c03ababfa7be" category="doc">NetApp Retail Assistant のデモ</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">リンクをクリックしてください</block>
  <block id="bb07f1ff94c6f99bf48a403706bea4ca" category="paragraph">NetApp Retail Assistant （奈良）のデモビデオを録画しました。をクリックします<block ref="c1305d6e7f2e06345748f63e36abba33" category="inline-link-rx"></block> 次の図を開き、ビデオデモを再生します。</block>
  <block id="088070f65f454d6b38e8e40e332e70a8" category="paragraph"><block ref="088070f65f454d6b38e8e40e332e70a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d81ccbd202a60c621000abca3f6f3de" category="inline-link-macro">次のスライド： NetApp Cloud Sync を使用して会話履歴をアーカイブ</block>
  <block id="a165baa9089720dc90e8baf16267821f" category="paragraph"><block ref="a165baa9089720dc90e8baf16267821f" category="inline-link-macro-rx"></block></block>
  <block id="6f7f6c0b1054487e622896990b1d6d55" category="doc">TR-4841 ：『 Hybrid Cloud AI Operating System with Data Caching 』</block>
  <block id="1b55e21d5b19a6ba57ae9bbd6f3a0630" category="paragraph">ネットアップ Yochay Ettun 、 cnvrg.io 、 David Arnette 、 Rick Huang 氏</block>
  <block id="28d9fd6fa10254fdcc59aa182ae32dc9" category="paragraph">データの急増と ML と AI の急激な成長により、独自の開発と実装の課題を抱えるゼタバイト経済が生まれました。</block>
  <block id="eb35f773ff882afb6d6d67613a4701ee" category="paragraph">ML モデルは大量のデータを必要とし、コンピューティングリソースにはハイパフォーマンスのデータストレージが必要であることは広く知られていますが、実際には、このモデルを実装するのはそれほど簡単ではありません。特にハイブリッドクラウドインスタンスや柔軟なコンピューティングインスタンスを使用する場合はそうです。一般に、大量のデータが低コストのデータレイクに保存されます。このデータレイクでは、 GPU などのハイパフォーマンスな AI コンピューティングリソースは効率的にアクセスできません。この問題は、一部のワークロードがクラウドで動作し、一部のワークロードがオンプレミス環境または別の HPC 環境に完全に配置されているハイブリッドクラウドインフラにさらに悪化しています。</block>
  <block id="2b8ab86ccf473cca225e50ddb8c47e25" category="paragraph">このドキュメントでは、 IT プロフェッショナルやデータエンジニアがトポロジに対応したデータハブで真のハイブリッドクラウド AI プラットフォームを構築できる、新しい解決策を紹介します。これにより、データサイエンティストは、コンピューティングリソースに近接してデータセットのキャッシュを瞬時に自動作成できます。 どこにいても、その結果、高性能なモデルトレーニングを実施できるだけでなく、データセットバージョンハブ内のデータセットキャッシュ、バージョン、リネージにすぐにアクセスできる複数の AI 専門家のコラボレーションなど、さらなるメリットが得られます。</block>
  <block id="3bc3b194b0ef70e2e6ce113f819619c4" category="inline-link-macro">次の手順：ユースケースの概要と問題点</block>
  <block id="3eb8a6b81400ec3a497fb59a7e6f4360" category="paragraph"><block ref="3eb8a6b81400ec3a497fb59a7e6f4360" category="inline-link-macro-rx"></block></block>
  <block id="1d22ea3c852f35081a408a42b1caa719" category="doc">cnvrg.io の展開</block>
  <block id="e1d91df1cfd0e5839c45e06d0504c9d6" category="section-title">Helm を使用して cnvrg コアを導入します</block>
  <block id="7e9e2a4317009b27ebfc0b4cd222ba30" category="paragraph">Helm は、任意のクラスタ、オンプレミス、 Minikube 、または任意のクラウドクラスタ（ AKS 、 EKS 、 GKE など）を使用して、 cnvrg を迅速に導入する最も簡単な方法です。このセクションでは、 Kubernetes がインストールされたオンプレミス（ DGX-1 ）インスタンスに cnvrg がインストールされた方法について説明します。</block>
  <block id="ea6de3fdf29035cd2d521949527c2a44" category="paragraph">インストールを完了する前に、ローカルマシンに次の依存関係をインストールして準備する必要があります。</block>
  <block id="6f49e891fdb1bb11823492f4d315b2fd" category="list-text">Kubectl のように入力する</block>
  <block id="5e6cef7c129d4703b20be420ac32145c" category="list-text">Helm 3.x</block>
  <block id="93fafc2be5db6c259030d6d8dc989752" category="list-text">Kubernetes クラスタ 1.15 以降</block>
  <block id="116efea8faeef9714de76fe9f81d9b82" category="section-title">Helm を使用して展開します</block>
  <block id="237800170a9b824a7de8c08766ea114e" category="list-text">最新の cnvrg Helm チャートをダウンロードするには、次のコマンドを実行します。</block>
  <block id="9b821098b02043dada6b07b924f4ef5f" category="list-text">cnvrg を導入する前に、クラスタの外部 IP アドレス、および cnvrg を導入するノードの名前が必要です。オンプレミスの Kubernetes クラスタに cnvrg を導入するには、次のコマンドを実行します。</block>
  <block id="1d1eb4e0da8bac1b4eaa79c1f0be9e04" category="list-text">「 helm install 」コマンドを実行します。すべてのサービスとシステムがクラスタに自動的にインストールされます。この処理には最大 15 分かかることがあります。</block>
  <block id="e269e5751f8883222b6d2f55da7ed811" category="list-text">「 helm install 」コマンドの所要時間は最大 10 分です。展開が完了したら、新しく展開した cnvrg の URL に移動するか、新しいクラスタを組織内のリソースとして追加します。「 helm' 」コマンドは正しい URL を通知します。</block>
  <block id="ac0cc75e8d4f0df818dd93a00041897a" category="list-text">すべてのコンテナのステータスが「 Running 」または「 Complete 」の場合、 cnvrg は正常に展開されています。次のような出力が表示されます。</block>
  <block id="3e82668da957bceb0d0c7024273ab624" category="section-title">ResNet50 および胸部 X 線を使用したコンピュータビジョンモデルトレーニング データセット</block>
  <block id="c9c734dfca60f137a58e1a5cb9c89b62" category="inline-link">NIH ダウンロードサイト</block>
  <block id="0c7f26c15912f9f5d0e0473bb21cb9a2" category="paragraph">NVIDIA DGX システムを基盤とする NetApp ONTAP AI アーキテクチャ上の Kubernetes セットアップに、 cnvrg.io AI OS が導入されました。検証には、胸部 X 線の匿名画像からなる NIH 胸部 X 線データセットを使用しました。画像は PNG 形式でした。このデータは NIH クリニカルセンタおよびによって提供された は、から使用できます<block ref="4e3f11b94ad47864cbd9c6049036ac93" category="inline-link-rx"></block>。250 GB のサンプルデータを 15 クラスの 627 、 615 イメージで使用しました。</block>
  <block id="de53b795a18176edb91a88632f621868" category="paragraph">データセットは cnvrg プラットフォームにアップロードされ、 NetApp AFF A800 ストレージシステムからの NFS エクスポートにキャッシュされました。</block>
  <block id="ec948f075c372d4beb7d19a5266f22d5" category="section-title">コンピューティングリソースをセットアップする</block>
  <block id="42af2f71dc8561eb9cfe43d45664ecb3" category="paragraph">cnvrg アーキテクチャおよびメタスケジューリング機能により、エンジニアおよび IT プロフェッショナルは、異なるコンピューティングリソースを 1 つのプラットフォームに接続できます。今回のセットアップでは、ディープラーニングワークロードの実行用に導入されたクラスタ cnvrg を使用しました。追加のクラスタを接続する必要がある場合は、次のスクリーンショットに示すように、 GUI を使用してください。</block>
  <block id="df25fca4c07e68ed339b0e1974a9d59f" category="paragraph"><block ref="df25fca4c07e68ed339b0e1974a9d59f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f541774a08fc687f6e2016c77a6ebca5" category="section-title">データをロードします</block>
  <block id="564bfd33ed32c02158989dfcee59ae89" category="paragraph">cnvrg プラットフォームにデータをアップロードするには、 GUI または cnvrg CLI を使用します。大規模なデータセットの場合は、 CLI の使用を推奨します。 CLI は、多数のファイルを処理できる、拡張性と信頼性に優れた強力なツールです。</block>
  <block id="41ad6001e0d3c17bd4a7957e18bd8bab" category="paragraph">データをアップロードするには、次の手順を実行します。</block>
  <block id="192b006166881688d04f398db712aaeb" category="inline-link">cnvrg CLI</block>
  <block id="8e9fbcfb57e26d7a14f0292c11fae122" category="list-text">をダウンロードします<block ref="d3ae4cf97b77cb5805c16205cd459ce4" category="inline-link-rx"></block>。</block>
  <block id="5cea56fcf2481a021f3d93843a22c319" category="list-text">X 線ディレクトリに移動します。</block>
  <block id="1c5a650f398227a4f97ed81accfbbb4b" category="list-text">「 cnvrg data init 」コマンドを使用して、プラットフォーム内のデータセットを初期化します。</block>
  <block id="5c48f13a3d988e0d618145098a829e3a" category="list-text">「 cnvrg data sync 」コマンドを使用して、ディレクトリのすべての内容を中央のデータレイクにアップロードします。データが中央のオブジェクトストア（ StorageGRID 、 S3 、またはその他）にアップロードされたら、 GUI で参照できます。次の図は、ロードされた胸部 X 線線維症画像 PNG ファイルを示しています。さらに、 cnvrg は、ビルドしたすべてのモデルをデータバージョンに複製できるように、データをバージョン化します。</block>
  <block id="935b6e25167b65d839bc1487ebb2fa6e" category="paragraph"><block ref="935b6e25167b65d839bc1487ebb2fa6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="308e9394a715dc64aa4e48e0054775ed" category="section-title">マッハデータ</block>
  <block id="556cde11a66a789acb7e62b934c1a88c" category="paragraph">トレーニングを高速化し、モデルのトレーニングや実験ごとに 600k 以上のファイルをダウンロードしないようにするために、データを最初に中央のデータレイクオブジェクトストアにアップロードしたあとにデータキャッシュ機能を使用しました。</block>
  <block id="3d163413cac9b6cc4726a9c83d37fed3" category="paragraph"><block ref="3d163413cac9b6cc4726a9c83d37fed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d006c100d76e7d21d64055ce3cfe6a24" category="paragraph">ユーザーが Cache をクリックすると、 cnvrg はリモートオブジェクトストアから特定のコミットでデータをダウンロードし、 ONTAP NFS ボリュームにキャッシュします。完了すると、データをすぐにトレーニングに利用できるようになります。さらに、データが数日間使用されていない場合（たとえば、モデルのトレーニングや探索など）、 cnvrg は自動的にキャッシュをクリアします。</block>
  <block id="53ad459d9bb7a65de3d1cc839b75c19f" category="section-title">キャッシュデータで ML パイプラインを構築</block>
  <block id="db226c80bcb6098ce2f47dd3982cca26" category="paragraph">cnvrg フローを使用すると、本番 ML パイプラインを簡単に構築できます。フローは柔軟性が高く、あらゆる種類の ML ユースケースに対応し、 GUI またはコードを使用して作成できます。フロー内の各コンポーネントは、異なる Docker イメージを使用して異なるコンピューティングリソース上で実行できるため、ハイブリッドクラウドを構築し、 ML パイプラインを最適化できます。</block>
  <block id="6b0eae96748d48b032362774a6467411" category="paragraph"><block ref="6b0eae96748d48b032362774a6467411" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1f18dfff2566b35d7d0e528565c43aa" category="section-title">胸部 X 線フローの構築：データの設定</block>
  <block id="adec555cb8cd4de3f288baed510d1163" category="paragraph">新しく作成したフローにデータセットを追加しました。データセットを追加する際には、特定のバージョン（ commit ）を選択し、キャッシュされたバージョンが必要かどうかを指定できます。この例では、キャッシュされたコミットを選択しました。</block>
  <block id="6dd780034ed574b328dbc16a6b485b79" category="paragraph"><block ref="6dd780034ed574b328dbc16a6b485b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13e0789c536fc18ddcdc32b4ca598b58" category="section-title">胸部 X 線フローの構築：トレーニングモデルの設定： ResNet50</block>
  <block id="fa3c48d58d8e9fd17365fd986906dd52" category="paragraph">パイプラインでは、任意の種類のカスタムコードを追加できます。cnvrg には、再利用可能な ML コンポーネントコレクションである AI ライブラリもあります。AI ライブラリには、アルゴリズム、スクリプト、データソースなど、あらゆる ML やディープラーニングフローで使用できるソリューションがあります。この例では、 ResNet50 の事前ビルドモジュールを選択しました。batch_size ： 128 、 epochs ： 10 などのデフォルトパラメータを使用しました。これらのパラメータは AI ライブラリのドキュメントで確認できます。次のスクリーンショットは、 X 線データセットが ResNet50 に接続された新しいフローを示しています。</block>
  <block id="defe5cc08faaa501eeb5fc5500664d29" category="paragraph"><block ref="defe5cc08faaa501eeb5fc5500664d29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf9bb479506589dfd719446fe3e054c7" category="section-title">ResNet50 の計算リソースを定義します</block>
  <block id="943cb3f5c7789c68e811b0accdb6c5d9" category="paragraph">cnvrg フロー内の各アルゴリズムまたはコンポーネントは、異なる Docker イメージを使用して、異なるコンピューティングインスタンス上で実行できます。セットアップでは、 NetApp ONTAP AI アーキテクチャを採用した NVIDIA DGX システムでトレーニングアルゴリズムを実行したいと考えていました。次の図では、「 GPU - REAL 」を選択しました。これは、オンプレミスクラスタのコンピューティングテンプレートであり、仕様です。また、テンプレートのキューを作成し、複数のテンプレートを選択しました。このようにして 'GPU 実数のリソースを割り当てることができない場合 ( たとえば ' 他のデータ・サイエンティストがリソースを使用している場合 ) は ' クラウド・プロバイダ・テンプレートを追加して ' 自動クラウド・バーストを有効にできます次のスクリーンショットは、 ResNet50 のコンピューティングノードとしての GPU 実数の使用を示しています。</block>
  <block id="27c8450e6f62877ec794262ae4c5a713" category="paragraph"><block ref="27c8450e6f62877ec794262ae4c5a713" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bee38713f37ae72239f6bda08384dfbb" category="section-title">結果の追跡と監視</block>
  <block id="546b7da7049f1d7fdf35cdb57fa96c7c" category="paragraph">フローが実行されると、 cnvrg はトラッキングおよびモニタリングエンジンをトリガーします。フローの各実行は自動的に文書化され、リアルタイムで更新されます。ハイパーパラメータ、指標、リソース使用率（ GPU 利用率など）、コードバージョン、アーティファクト、ログ また、次の 2 つのスクリーンショットに示すように、 ［ テスト ］ セクションで自動的に使用できるようになります。</block>
  <block id="8fabeb8b8d143d509bb92087cbbf953c" category="paragraph"><block ref="8fabeb8b8d143d509bb92087cbbf953c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdbd22304f732000189e44de22498da1" category="paragraph"><block ref="fdbd22304f732000189e44de22498da1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="254a4a0ddc892d6a01d7e7ef286fbb71" category="inline-link-macro">次は終わりです</block>
  <block id="debe391efc3dc12a7d87720a4cf068a5" category="paragraph"><block ref="debe391efc3dc12a7d87720a4cf068a5" category="inline-link-macro-rx"></block></block>
  <block id="c83553858a60514501e9751c0747dea0" category="doc">基本的な資源配分フェアネス</block>
  <block id="dc12a1ce34c0a7a264de91bc9b933a62" category="paragraph">このセクションでは 'team -d がより多くの GPU を要求した場合 ( それらは割り当ての下にあります ) ' システムは 'team -b' および 'team -c のワークロードを一時停止し ' 公正な共有方法で保留状態に移行することを示しています</block>
  <block id="ccc33823c0dc5e9ee0838a5eaa86f076" category="inline-link-macro">セクション 4.9 のテストの詳細</block>
  <block id="86bbd55ea7850716c0c192b19c86176a" category="paragraph">ジョブの送信、使用するコンテナイメージ、実行するコマンドシーケンスなどの詳細については、を参照してください <block ref="94d73a1896276f719be59227f0e93a14" category="inline-link-macro-rx"></block>。</block>
  <block id="b6ea2a2f48a443e7d027bd652ac84762" category="paragraph">次の図は、自動ロードバランシングとプリエンプティブスケジューリングにより、クラスタ使用率、チームごとに割り当てられた GPU 、保留中のジョブを示しています。すべてのチームワークロードが要求した GPU の総数が、クラスタ内で使用可能な合計 GPU 数を超えると、実行： AI の内部公正性アルゴリズムによって、「 team -b 」と「 team -c 」のそれぞれに 1 つのジョブが一時停止されます。これは、それらがプロジェクトの割り当て量を満たしているためです。これにより、クラスタ全体の利用率が向上しますが、データサイエンスチームは、管理者が設定したリソースの制約に基づいて引き続き作業できます。</block>
  <block id="d1a54cf8cb2a06c0715d2f042fbf44bd" category="paragraph"><block ref="d1a54cf8cb2a06c0715d2f042fbf44bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d52816ece2166f7a2e0eadf58d617df9" category="paragraph">このテストシナリオの結果は、次のことを示しています。</block>
  <block id="bce83ec0a92a5b10380007a1643b2fd0" category="list-text">* 自動ロードバランシング。 * システムは、各チームが割り当てを使用するように GPU の割り当て量を自動的に調整します。一時停止されていたワークロードは、そのクォータを超えていたチームに属しています。</block>
  <block id="f8be0d1ca354f8cb4aaa4c8aadcea80b" category="list-text">* 公正な共有の一時停止。 * システムは、ノルマを達成したチームのワークロードを停止してから、もう一方のチームのワークロードを停止します。実行： AI には内部的な公正性アルゴリズムがあります。</block>
  <block id="c088b6e407ba7f9c0274382acfa3eae0" category="inline-link-macro">次の例では、過剰割り当て（ over-Quota Fairness ）</block>
  <block id="8e015e1b989b11d70fcb778747b8c614" category="paragraph"><block ref="8e015e1b989b11d70fcb778747b8c614" category="inline-link-macro-rx"></block></block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">まとめ</block>
  <block id="4ac9fa791a6d1c7c97bbae134dd22586" category="paragraph">真の会話型 AI システムは、人間のような対話を行い、文脈を理解し、インテリジェントな応答を提供します。このような AI モデルは、多くの場合、巨大で非常に複雑です。NVIDIA GPU とネットアップストレージを使用することで、最新の大規模な言語モデルをトレーニングし、最適化して推論を迅速に実行できます。これは、大規模で複雑な AI モデルと比べて高速な AI モデルのトレードオフを終えるための大きなストライドです。GPU に最適化された言語理解モデルは、医療、小売、金融サービスなどの業界向け AI アプリケーションに統合でき、高度なデジタル音声アシスタントをスマートスピーカーやカスタマーサービスラインに搭載できます。これらの高品質な会話型 AI システムにより、さまざまな業種の企業が、お客様との取引においてこれまで達成できなかったパーソナライズされたサービスを提供できます。</block>
  <block id="45d5663acc501eba25058f8956035e9a" category="paragraph">Jarvis は、バーチャルアシスタント、デジタルアバター、マルチモーダルセンサー Fusion （ ASR/NLP/TTS とフュージョンされた CV ）、または ASR/NLP/TTS/CV スタンドアロンの使用例（転写など）の導入を可能にします。私たちは、天気、関心のあるポイント、在庫価格に関する回答の質問を行えるバーチャル小売アシスタントを開発しました。また、 Cloud Sync を使用して会話履歴をアーカイブし、 Nemo モデルを新しいデータにトレーニングすることで、会話型 AI システムの自然言語理解能力を向上させる方法についても説明しました。</block>
  <block id="c6a4d485e7c4cefa4c121ce6c59b28dc" category="inline-link-macro">次：謝辞</block>
  <block id="38a609a97a676f2cc28ccec3d3097d4b" category="paragraph"><block ref="38a609a97a676f2cc28ccec3d3097d4b" category="inline-link-macro-rx"></block></block>
  <block id="1d91c2c04b7f73cb59edb799d095c75c" category="paragraph">このホワイトペーパーでは、 NVIDIA Jarvis フレームワークを使用して会話型人工知能（ AI ）ソリューションを構築し、小売業などのユースケース向けに NetApp ONTAP AI および Cloud Sync を使用しているお客様向けのガイドラインを紹介します。このガイドには、バーチャルアシスタント用の自然言語処理（ NLP ）モデルの開発に使用される高レベルのワークフロー、検証済みのテストケース、および結果に関する情報が含まれています。</block>
  <block id="4c2588a1e3dbf6824a4f05095df75f83" category="paragraph">今日のアプリケーションはどれも AI 主導ではありませんが、 AI の大きなメリットにアクセスできるように進化を続けています。AI の導入をサポートするには、アプリケーションに最適なレベルで機能し、継続的な進化をサポートするために必要なリソースを提供するインフラが必要です。</block>
  <block id="31965de7c735983bb41a0b7e70361db2" category="paragraph">AI ベースのアプリケーションの場合、エッジの場所はデータの主要なソースとして機能します。利用可能なデータは、一定期間にわたって複数のエッジから収集したトレーニングに使用して、トレーニングデータセットを形成できます。その後、トレーニング済みモデルを、データが収集されたエッジに導入して戻すことで、本番環境のデータを専用の推論プラットフォームに繰り返し転送することなく高速な推論を実現できます。</block>
  <block id="9e53c147a93fed13d4349cba2a35e36b" category="paragraph">ネットアップと NVIDIA は、 NVIDIA T4 GPU およびネットアップのクラウド対応ストレージシステムを搭載した NetApp H615c コンピューティングノードを基盤とする NetApp HCI AI 推論解決策を開発および検証しました。NetApp HCI は、あいまいさの範囲に対処し、設計の複雑さを排除し、推測に基づく作業を排除することで、エッジデータセンターでの AI 推論ソリューションの導入を簡易化します。この解決策は、 IT 組織に次のような規範的アーキテクチャを提供します。</block>
  <block id="9c4a53996590c74a0de3bba81f878254" category="list-text">エッジデータセンターで AI 推論を実行できます</block>
  <block id="20c3f996d396cc8c92788bb3585a6e86" category="list-text">GPU リソースの消費を最適化します</block>
  <block id="06e81c54cb9157aa59541289f1163daf" category="list-text">Kubernetes ベースの推論プラットフォームを提供し、柔軟性と拡張性を実現します</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">設計の複雑さを解消</block>
  <block id="ba37c372c4a9119e45c7f525f4743cfc" category="paragraph">エッジデータセンターでは、生成ポイントに非常に近い場所でデータを管理および処理します。このように近接することで、効率が向上し、データの処理に関連するレイテンシが低減します。多くの業種では、エッジデータセンターのメリットが認識されており、この分散型アプローチを採用するデータ処理が多用されています。</block>
  <block id="b501a0f0a3e7d559cecfad08c330227e" category="paragraph">次の表に、エッジの垂直市場とアプリケーションを示します。</block>
  <block id="06ce2a25e5d12c166a36f654dbea6012" category="cell">垂直（ Vertical ）</block>
  <block id="077262cc53a1fb1b5f651d31b6bf81ba" category="cell">医療</block>
  <block id="9da98fbc1c3d290fefb743a2df8914b4" category="cell">コンピュータ支援診断は、医療スタッフによる早期疾患検出を支援します</block>
  <block id="fa0a7aa1622ad105e9cdf5a706058333" category="cell">石油およびガス</block>
  <block id="55dae4e2e7f267e43e5768e66c7c3771" category="cell">遠隔地の生産施設、ビデオ、画像分析の自動検査</block>
  <block id="252ddb15657f2c60bddc73633a7bf8c0" category="cell">航空</block>
  <block id="7a84f6faf76fd3533ae6ca65d28c53eb" category="cell">エアトラフィック制御支援とリアルタイムビデオフィード分析</block>
  <block id="81ea9456adf225bcf11b668b427fd4f2" category="cell">メディアとエンターテイメント</block>
  <block id="5015819e58d425b19f8acc93866e76fa" category="cell">音声 / ビデオコンテンツフィルタリングにより、家族向けのコンテンツを提供します</block>
  <block id="616e90f12cb95950bc1c75396902393a" category="cell">ビジネス分析</block>
  <block id="3e4c06851690089d4952320e9df36dc2" category="cell">テレビ番組のライブ配信イベントでブランドの外観を分析するためのブランド認知</block>
  <block id="a9f7ecebb493e129aafb4cbfd73e85df" category="cell">E コマース</block>
  <block id="5df4fc692c9317012855d6935bf10310" category="cell">理想的な商人およびを見つけるための供給のスマートなバンドル 倉庫の組み合わせ</block>
  <block id="053e0bc8b9627b28e2ed8029a34b35bd" category="cell">小売</block>
  <block id="7cf7816e39e6e0c259a79dc29c5a5e7c" category="cell">自動チェックアウトにより、お客様がカートに入れたアイテムを認識します デジタル決済を促進します</block>
  <block id="165f5687ea9050fba239731810d0abe8" category="cell">スマートシティ</block>
  <block id="a47b360ffbe39c5a39c7e12e2ae8fdf5" category="cell">交通の流れを改善し、駐車を最適化し、歩行者と自転車の安全性を高めます</block>
  <block id="e86883c7cfc07afcf1e5ad8dffd7e1cc" category="cell">製造</block>
  <block id="f4d790a35097fa97c2687ac573b25338" category="cell">品質管理、組み立てラインの監視、欠陥の識別</block>
  <block id="2273d1167a6212812d95dc8fadbae78e" category="cell">カスタマーサービス</block>
  <block id="bf4948e47ea0d77a86e639979879262d" category="cell">カスタマーサービスの自動化による問い合わせの分析と優先順位付け（電話、 E メール、ソーシャルメディア）</block>
  <block id="8e54e9aa508ea37f7fe734e86ba9da27" category="cell">農業</block>
  <block id="7fb956270d49b22c3226bc1db2b0269f" category="cell">肥料や除草剤の使用を最適化するための、農場の運用と活動計画のインテリジェント化</block>
  <block id="3190a811a89bc9da4384152bc43d1b94" category="section-title">対象読者</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">解決策の対象となるグループは次のとおりです。</block>
  <block id="134481f7bea652a34fa2ada120d250e5" category="list-text">データサイエンティスト</block>
  <block id="8d26f0555c7ace3d4b297da8c12fb31b" category="list-text">IT アーキテクト</block>
  <block id="c114d2813b0041352b49187ebc28b62b" category="list-text">フィールドコンサルタント</block>
  <block id="2d6d0cc18609f97853f883c1891397d2" category="list-text">プロフェッショナルサービス</block>
  <block id="467f739adb5605167109d76676b44696" category="list-text">IT マネージャ</block>
  <block id="dcfa1c08d3b0126217af0b8690305c08" category="list-text">IT のイノベーションをもたらすインフラを必要としている他のユーザ エッジに配置された堅牢なデータサービスとアプリケーションサービス</block>
  <block id="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="paragraph"><block ref="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="inline-link-macro-rx"></block></block>
  <block id="3bb420314fa4b29837c4b0528524000f" category="doc">NetApp ONTAP AI と AI のコントロールプレーン</block>
  <block id="1b85c0e7f381bd6f8c3150cafe56a9f0" category="paragraph">NVIDIA DGX システムとネットアップのクラウド対応ストレージシステムを基盤とする NetApp ONTAP AI アーキテクチャこのリファレンスアーキテクチャには、 IT 組織に次のようなメリットがあります。</block>
  <block id="5116c5071beb9f4f5b673c988c417c71" category="list-text">コンピューティングとストレージを個別に拡張できます</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">小規模構成から始めて、シームレスに拡張できます</block>
  <block id="bae698d3cdcc290d6a0048c7b786446c" category="list-text">さまざまなパフォーマンスとコストポイントに対応する幅広いストレージオプションを提供 NetApp ONTAP AI は、 DGX システムと NetApp AFF A800 ストレージシステムを最先端のネットワーク機能と緊密に統合します。NetApp ONTAP AI システムと DGX システムでは、設計の複雑さと推測に頼らず、 AI 導入を簡易化できます。お客様は小規模構成から始めて、システムを中断なく拡張できます。同時に、エッジ、コア、クラウドにわたってデータをインテリジェントに管理できます。</block>
  <block id="c729dcbcad9e1c72ae15d4b823e9f311" category="paragraph">ネットアップの AI コントロールプレーンは、データサイエンティストとデータエンジニアを対象とした、フルスタックの AI 、 ML 、ディープラーニング（ DL ）のデータと実験管理解決策です。AI の利用が拡大するにつれて、ワークロードの拡張性やデータの可用性など、さまざまな課題が生じています。NetApp AI コントロールプレーンは、データネームスペースの迅速なクローニングなどの機能を通じて、これらの課題に対処します。たとえば、 Git リポジトリをはじめ、トレーサビリティとバージョン管理のためにデータやモデルのベースラインをほぼ瞬時に作成する AI トレーニングワークフローを定義および実装します。NetApp AI コントロールプレーンを使用すると、サイトやリージョン間でデータをシームレスにレプリケートし、 Jupyter Notebook ワークスペースをすばやくプロビジョニングして、大規模なデータセットにアクセスできます。</block>
  <block id="42cac0fcbbddfc99b31ff898d7902c83" category="inline-link-macro">次のステップ： AI ワークロードのオーケストレーション向けの AI プラットフォームを実行</block>
  <block id="e3683938a3c34e6a7cf5b3896258e91e" category="paragraph"><block ref="a8dcbc617641d20db42fd66f3a42caae" category="inline-link-macro-rx"></block>。</block>
  <block id="6b4330df9a37bcfef1faecd1e8973464" category="inline-link-macro">オーバークォータフェアネス</block>
  <block id="5648f06cc2dff861e557e088190ccbe2" category="paragraph">を参照してください <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>および <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>また、高度なテストシナリオを考案し、複雑なワークロード管理、自動プリエンプティブスケジューリング、オーバークォータ GPU プロビジョニングを実現する Run ： AI オーケストレーション機能をデモしました。これにより、 ONTAP AI 環境でクラスタリソースの利用率を高め、エンタープライズレベルのデータサイエンスチームの生産性を最適化できました。</block>
  <block id="fed09193953a2a2d15bfba4063981f8c" category="paragraph">これらの 3 つのセクションで、次のプロジェクトとクォータを設定します。</block>
  <block id="d2d5c3e087f684e56b5b81d6212d7ccb" category="cell">クォータ</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8.</block>
  <block id="207b738b6cd0e1cf6ac4a405dc72102f" category="paragraph">また、この 3 つのセクションでは、次のコンテナを使用します。</block>
  <block id="cc6f12794ea24a191cb4f699f1b95036" category="list-text">Jupyter Notebook ： "jupyter/base-notebook</block>
  <block id="b8d0bb7e356bfdd7e018a7c62f9343fa" category="list-text">「 GCR.IO/run-ai-demo/QuickStart 」を実行します</block>
  <block id="c9582d103b2fe8050364d3e629c4e80e" category="paragraph">このテストシナリオでは、次の目標を設定します。</block>
  <block id="c2d51205301247cd0aa0eca284d3889b" category="list-text">リソースのプロビジョニングの簡易性と、リソースの使用方法を説明します ユーザから抽象化されます</block>
  <block id="dfd4af458e74e30246827532e692dca7" category="list-text">ユーザが GPU のフラクションを簡単にプロビジョニングする方法を説明します GPU の数を整数で指定します</block>
  <block id="d7bf7c7f0d7884bd8fe07da4f6a8aba3" category="list-text">チームを編成してコンピューティングのボトルネックを解消する方法を説明します リソースクォータがある場合は、ユーザがそのリソースクォータを確認します クラスタ内に GPU が搭載されている</block>
  <block id="f93609e9c7f7c826e6c83bb1f8416207" category="list-text">ネットアップコンテナなどの大量の計算処理を行うジョブを実行する際に、 NetApp 解決策を使用してデータパイプラインのボトルネックを解消する方法を説明する</block>
  <block id="8ac218f5a62c8021756a192ac737a7f2" category="list-text">を使用して複数のタイプのコンテナを実行する方法を説明します システム</block>
  <block id="802125395813e0bec35472d0403ab94e" category="list-text">Jupyter ノートブック</block>
  <block id="91c4a4ef606f959264719f8d084aab0e" category="list-text">実行： AI コンテナ</block>
  <block id="23edbe937c996eb973ab4c69f9648893" category="list-text">クラスタがフルの状態のときに高い利用率を表示します</block>
  <block id="815a27a2c38741e36d920cbea5587384" category="paragraph">テスト中に実行される実際のコマンドシーケンスの詳細については、を参照してください <block ref="3a65193f11bb9f699d19b0e9a996cd93" category="inline-link-macro-rx"></block>。</block>
  <block id="9d020ce52f8e9ff0d2f2defe3942d660" category="paragraph">13 個のワークロードすべてが送信されると、次の図に示すように、コンテナ名と割り当てられている GPU のリストが表示されます。7 つのトレーニングと 6 つの対話型ジョブが用意されており、 4 つのデータサイエンスチームをシミュレーションして、それぞれに独自のモデルを実行しているか開発中であるかを確認していますインタラクティブなジョブの場合、個々の開発者は Jupyter Notebook を使用してコードの書き込みやデバッグを行っています。そのため、クラスタリソースをあまり使用せずに GPU フラクションをプロビジョニングすることをお勧めします。</block>
  <block id="5deafc9e56279ca519f1e3c351856aa8" category="paragraph"><block ref="5deafc9e56279ca519f1e3c351856aa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa04853a58b1b9ab0033c7e24b9d929" category="paragraph">このテストシナリオの結果は次のようになります。</block>
  <block id="dbaf41fcdcf0aa8cd93bfdf0e7f916f2" category="list-text">クラスタがいっぱいである必要があります。 16 基の GPU が使用されています。</block>
  <block id="25421e793bda820f3023762c547a2495" category="list-text">クラスタの利用率が高い。</block>
  <block id="fdf3de6e0502b5404d2e0b379421f759" category="list-text">フラクショナル割り当てにより、 GPU よりも多くの実験が行われています。</block>
  <block id="68cf93a70e0f0fe62bc0428ce8a8b348" category="list-text">「 team -d 」では、すべてのクォータが使用されているわけではありません。したがって、「 team -b 」と「 team -c 」では、実験に追加の GPU を使用することができるため、イノベーションにかかる時間が短縮されます。</block>
  <block id="9083e59932e59a6f85524ab956fcf772" category="inline-link-macro">次は、基本的な資源配分フェアネスです</block>
  <block id="654c44d69d64b0a5a656dd7b1375ac03" category="paragraph"><block ref="654c44d69d64b0a5a656dd7b1375ac03" category="inline-link-macro-rx"></block></block>
  <block id="39cf3ca3e5dbe56d6eade7cbe3cc40e6" category="doc">例： Kubeflow の操作とタスク</block>
  <block id="e40030fd64108859627c7a126638f0e6" category="list-text">NetApp AI コントロールプレーン：</block>
  <block id="63178726ae501745b3914ec3aa50969e" category="list-text">ネットアップの AI コントロールプレーンテクニカルレポートでご確認ください</block>
  <block id="3ce56c027572d1908d65b63056be024f" category="inline-link"><block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="445a4d3400bdde832e8898d8349696c0" category="paragraph"><block ref="445a4d3400bdde832e8898d8349696c0" category="inline-link-rx"></block></block>
  <block id="9a8ec45d909b996af4c042e44b5c5f29" category="list-text">TensorFlow ：あらゆる環境に対応するオープンソースの機械学習フレームワーク<block ref="db3465122fd83ad1dc4cff7e67d794df" category="inline-link-rx"></block></block>
  <block id="3bc4d41311862190a8fd0d6c8f661971" category="list-text">Iguazio データサイエンスプラットフォーム</block>
  <block id="737d4d1e81ff236001338f46d1623aaa" category="list-text">Iguazio Data Science Platform のドキュメント</block>
  <block id="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link"><block ref="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link-rx"></block></block>
  <block id="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="paragraph"><block ref="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="inline-link-rx"></block></block>
  <block id="4f0f362becf6baf6e08f490115d76d98" category="list-text">Nuclio サーバーレス関数</block>
  <block id="89aa84cdf5db1bece2993801c78914de" category="inline-link"><block ref="89aa84cdf5db1bece2993801c78914de" category="inline-link-rx"></block></block>
  <block id="93eac034cc1c1aaedaf6ed41063825ee" category="paragraph"><block ref="93eac034cc1c1aaedaf6ed41063825ee" category="inline-link-rx"></block></block>
  <block id="b5266d58998338015b5e02ee7e84a833" category="list-text">MLRun オープンソースパイプラインオーケストレーションフレームワーク</block>
  <block id="b96a861dccea968edc0b7a9ff96203e9" category="inline-link"><block ref="b96a861dccea968edc0b7a9ff96203e9" category="inline-link-rx"></block></block>
  <block id="70a8a001358e056f435199da7e17e427" category="paragraph"><block ref="70a8a001358e056f435199da7e17e427" category="inline-link-rx"></block></block>
  <block id="b3f90aaddad391963c2090db8f1b727e" category="list-text">NVIDIA DGX-1 システム</block>
  <block id="d6a377b23d0f4dbe3f5bf91d5f6abf74" category="list-text">NVIDIA Tesla V100 Tensor コア GPU</block>
  <block id="0df7621d860637a2e6e462c56322edab" category="list-text">NVIDIA GPU Cloud</block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="list-text">NetApp AFF システム</block>
  <block id="5f662f6dc276dd5a2a83440d0fe63e9b" category="list-text">AFF 向けのネットアップのフラッシュソリューションの利点</block>
  <block id="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link"><block ref="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link-rx"></block></block>
  <block id="a5d59e86f09bafae4247836d5135b6a3" category="paragraph"><block ref="a5d59e86f09bafae4247836d5135b6a3" category="inline-link-rx"></block></block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="list-text">NetApp ONTAP AI</block>
  <block id="47c991332229e0cbfe947beaa428ea61" category="list-text">DGX-1 と Cisco Networking Design Guide による ONTAP AI</block>
  <block id="b141781260425e95eee945147e2f0d99" category="inline-link"><block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="9fbee18519e76388280bc1f8e3fd6c7e" category="paragraph"><block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="0be3b0697a0ffdfe9065df24ec1d3e16" category="list-text">DGX-1 と Cisco Networking Deployment Guide を使用した ONTAP AI</block>
  <block id="921f17c41dea89b0a711f380e9864e09" category="inline-link"><block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="aef3d0752148699921f8a251537d5ff3" category="paragraph"><block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="205a4f16a51f3acd6dbba76dbeb10818" category="list-text">DGX-1 と Mellanox のネットワーキング設計ガイドで構成される ONTAP AI</block>
  <block id="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link"><block ref="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link-rx"></block></block>
  <block id="0a9e1455c4a5a9965867a5efd6b8cc9b" category="paragraph"><block ref="0a9e1455c4a5a9965867a5efd6b8cc9b" category="inline-link-rx"></block></block>
  <block id="913c29df09bcb5715ed7a48c12f3a0da" category="list-text">ONTAP AI ネットワーク</block>
  <block id="ae2703e9b1dff6da048c786142c2e7db" category="list-text">Cisco Nexus 3232C シリーズスイッチ</block>
  <block id="8a27a2062df55e0aa73964ea8ec2ab55" category="list-text">Mellanox Scale-out SN2000 イーサネットスイッチシリーズ</block>
  <block id="87a849c2f3c412a491f97674d5e27ed1" category="inline-link"><block ref="fd77c1cd25d650110f7047fa02f8327d" category="inline-link-rx"></block></block>
  <block id="a6c16c720941d75800533dedd69929cc" category="paragraph"><block ref="ad90d1952f7d0f85370461937e4484b7" category="inline-link-rx"></block></block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="doc">新しいボリュームをプロビジョニングします</block>
  <block id="117bdbda976fe8b3212bc3b6327a0a1b" category="list-text">Cloud Volumes ONTAP</block>
  <block id="7450cfde7058dc5e1f7909d0280fd7ae" category="list-text">Azure NetApp Files の特長</block>
  <block id="337f05fad2de58e4a8b74cb25536b52d" category="doc">セットアップの概要</block>
  <block id="666f45aef7a28ef5ba6e4bfb2f71bcee" category="section-title">Iguazio の取り付け</block>
  <block id="b681b0e4b3576aa1cd854e2b66c16dcd" category="paragraph">Iguazio は、オンプレミスまたはクラウドプロバイダにインストールできます。プロビジョニングはサービスとして実行でき、 Iguazio またはお客様による管理が可能です。どちらの場合も、 Iguazio はクラスタの導入と管理に使用する導入アプリケーション（ Provazio ）を提供します。</block>
  <block id="3b31e2e4387e938056251a113831e6da" category="inline-link">NVA-1121.</block>
  <block id="8334797b9b3383d4f48d98178b8845ea" category="inline-link">このページです</block>
  <block id="ade8a7efee71036d2ca57676a54b31e3" category="paragraph">オンプレミスでのインストールについては、を参照してください<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> コンピューティング、ネットワーク、ストレージのセットアップに使用できます。イグアスのオンプレミス導入は、顧客に追加料金なしで提供されます。を参照してください<block ref="d273dd0a16e6003b56381a70823807f7" category="inline-link-rx"></block> DNS サーバおよび SMTP サーバの設定Provazio のインストールページは次のとおりです。</block>
  <block id="8e72dced5918c4009ff80044ba6f44db" category="paragraph"><block ref="8e72dced5918c4009ff80044ba6f44db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c16d8d5e717cd029389f76abddf769b7" category="inline-link-macro">次： Kubernetes クラスタの設定</block>
  <block id="1d42e0b2a8893ff00a35554162554936" category="paragraph"><block ref="1d42e0b2a8893ff00a35554162554936" category="inline-link-macro-rx"></block></block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">詳細</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="cell">NFS</block>
  <block id="ed4a202c34987f40d5e245e76a65a243" category="paragraph">次の図は、提案された会話型 AI システムアーキテクチャを示しています。システムは、音声信号またはテキスト入力で操作できます。音声入力が検出された場合、 Jarvis As-as-a-Service （ AIaaS ）は ASR を実行して、 Dialog Manager 用のテキストを生成します。Dialog Manager は、会話の状態を記憶し、テキストを対応するサービスにルーティングし、 Fulfillment Engine にコマンドを渡します。Jarvis NLP サービスは、テキストを受け取り、インテントとエンティティを認識し、それらのインテントとエンティティスロットをダイアログマネージャーに出力します。ダイアログマネージャーは、アクションをフルフィルメントエンジンに送信します。フルフィルメントエンジンは、回答ユーザーが照会するサードパーティ API または SQL データベースで構成されています。フルフィルメントエンジンから結果を受け取った後、 Dialog Manager はテキストを Jarvis TTS AIaaS にルーティングして、エンドユーザーの音声応答を生成します。NLP サービスがシステムとの対話をより多くのユーザが行うように改善されるように、会話履歴をアーカイブし、インテントや Nemo トレーニング用のスロットに注釈を付けることができます。</block>
  <block id="308a0722262fbc3adde5d5d900ad0c36" category="paragraph"><block ref="308a0722262fbc3adde5d5d900ad0c36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="863eef2617ffc374c485389aabdd8a24" category="paragraph">この解決策は、 1 台の DGX ステーションと 1 台の AFF A220 ストレージシステムで検証済みです。Jarvis では、ディープニューラルネットワークの計算に T4 GPU または V100 GPU のいずれかが必要です。</block>
  <block id="6c4fbfa85e86ba1acd8a66b367a3b2c4" category="paragraph">次の表に、テストで解決策を実装するために必要なハードウェアコンポーネントを示します。</block>
  <block id="71c9e70899509bff35197ba9da10dafc" category="cell">T4 または V100 GPU</block>
  <block id="8f452959667e7665cddf2484ddca1724" category="cell">NVIDIA DGX ステーション</block>
  <block id="f7a05af899e536cde0a9c8476c2da0a1" category="paragraph">次の表に、テストで解決策を実装するために必要なソフトウェアコンポーネントを示します。</block>
  <block id="5acec1d6c6e07042eb0c19bc926d2633" category="cell">バージョンまたはその他の情報</block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="cell">NetApp ONTAP データ管理ソフトウェア</block>
  <block id="eaf2f97729e8d5e4d205672da8afc9a5" category="cell">9.6</block>
  <block id="efdec37786e687a58664ebd4ef6bdba4" category="cell">Cisco NX-OS スイッチのファームウェア</block>
  <block id="976d6c35e21478ef03ca2cec2a74dc71" category="cell">7.0 （ 3 ） I6 （ 1 ）</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">NVIDIA DGX OS</block>
  <block id="4a5be8fea83a32ad5c7fc31b02ef1028" category="cell">4.0.4 - Ubuntu 18.04 LTS</block>
  <block id="0664d9eb73230b2a0b514b0facae8ade" category="cell">NVIDIA Jarvis フレームワーク</block>
  <block id="cc5f21cb121669006a19c9fde049f048" category="cell">EA v0.2 の 1 つです</block>
  <block id="dfcc0491fc5a6e738ca8b5ef3a258093" category="cell">NVIDIA Nemo</block>
  <block id="317fe32bf712dffb43ddc0ee8dde8c3c" category="cell">nvcr.io/nvidia / Nemo ： v0.10</block>
  <block id="44769dc982b2126503d2d014bcf7c15a" category="cell">Docker コンテナプラットフォーム</block>
  <block id="0cc9a8e76e0a79d0e0072e0a0d675fe5" category="cell">18.06.1-CE [e68fc7a]</block>
  <block id="3032d0de2852f0bb1e13142c2c47cd5b" category="inline-link-macro">次の例： Jarvis 、 Cloud Sync 、 Nemo の概要を使用して仮想アシスタントを構築します</block>
  <block id="5cefb81f0324c44ec13c02fa7700924b" category="paragraph"><block ref="5cefb81f0324c44ec13c02fa7700924b" category="inline-link-macro-rx"></block></block>
  <block id="9783bbad26249ed7f40d89e12ba42020" category="doc">実行： AI ワークロードのオーケストレーション向けの AI プラットフォーム</block>
  <block id="cb39fb629a91fdf37928a15d38e05318" category="list-text">イノベーションにかかる時間を短縮使用方法： AI リソースのプール化、キューイング、優先付けのメカニズムをネットアップストレージシステムと組み合わせることで、インフラ管理の面倒な作業から研究者を排除し、データサイエンスに専念させることができます。実行： AI とネットアップのお客様は、コンピューティングやデータパイプラインのボトルネックを発生させることなく、必要な数のワークロードを実行することで生産性を向上できます。</block>
  <block id="8df86cf2931aab70fd9ad1f919f40449" category="list-text">チームの生産性の向上。実行： AI 公正性アルゴリズムは、すべてのユーザとチームが公平なリソースを獲得できることを保証します。優先度の高いプロジェクトを中心としたポリシーをあらかじめ設定しておくことで、あるユーザチームから別のユーザチームへリソースを動的に割り当てることができ、ユーザが切望された GPU リソースにタイムリーにアクセスできるようになります。</block>
  <block id="c835378d4be1896f62ef5d2760340909" category="list-text">GPU 利用率の向上：Run ： AI スケジューラを使用すると、 Kubernetes での分散トレーニング用に、フラクショナルな GPU 、整数型 GPU 、複数の GPU ノードを簡単に利用できます。このように、 AI ワークロードは容量ではなくニーズに基づいて実行されます。データサイエンスチームは、 1 つのインフラでより多くの AI 実験を実行できるようになりました。</block>
  <block id="5960deb1522a82336a7a31213acea4b0" category="inline-link-macro">次は、解決策テクノロジです</block>
  <block id="dde440f8f7c47863e65c2d82a820b8a5" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block>。</block>
  <block id="fa752e98365b630341b8478c89a6757f" category="doc">Kubernetes クラスタを設定しています</block>
  <block id="f12c340e651d989970371432778f9be2" category="paragraph">このセクションは、クラウドとオンプレミスのそれぞれの導入について、 2 つの部分に分かれています。</block>
  <block id="ee06675a624f2ec74e8b71b5a57f8f9e" category="section-title">Cloud Deployment Kubernetes Configuration を参照してください</block>
  <block id="b513a0297a0d2efdebed8ce18e2f1715" category="paragraph">NetApp Cloud Manager を使用して、イグアス Kubernetes クラスタへの接続を定義できます。Trident では、ボリュームを使用できるようにするために、クラスタ内の複数のリソースにアクセスする必要があります。</block>
  <block id="2d5bc331cc722113dd483838e908804c" category="list-text">アクセスを有効にするには、 1 つの Iguazio ノードから Kubernetes 構成ファイルを取得します。ファイルは、「 /home/Iguazio/.kube/config. 」の下にあります このファイルをデスクトップにダウンロードします。</block>
  <block id="17c6b0de5b91c5c06a0d8173c89110d8" category="list-text">設定するクラスタの検出に進みます。</block>
  <block id="df37cca51036f4c5b59db211df5354bc" category="paragraph"><block ref="df37cca51036f4c5b59db211df5354bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b848e07dc3f62b4307419421d844f123" category="list-text">Kubernetes 構成ファイルをアップロードします。次の図を参照してください。</block>
  <block id="5bcc42d0a2624f1586064488c3484529" category="paragraph"><block ref="5bcc42d0a2624f1586064488c3484529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63de24a45facebf9f65cb6578847f2b4" category="list-text">Trident を導入し、ボリュームをクラスタに関連付けます。Iguazio クラスタへの持続ボリュームの定義と割り当てについては、次の図を参照してください。このプロセスにより、 Iguazio の Kubernetes クラスタに永続ボリューム（ PV ）が作成されます。使用する前に、永続的ボリューム要求（ PVC ）を定義する必要があります。</block>
  <block id="eee185b539f0e52d8b64916066463222" category="paragraph"><block ref="eee185b539f0e52d8b64916066463222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8b69025b2efa1b2ccb917bc911d30ccd" category="section-title">オンプレミス導入の Kubernetes 構成</block>
  <block id="31bbf80f0649d07d3e8340123f1a6963" category="inline-link">TR-4798</block>
  <block id="5be8900878997a404baf02b07ff271c6" category="paragraph">NetApp Trident のオンプレミスインストールについては、を参照してください<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> を参照してください。Kubernetes クラスタを設定して NetApp Trident をインストールしたら、 Trident を Iguazio クラスタに接続して、データやモデルの Snapshot コピーの作成などのネットアップのデータ管理機能を利用できます。</block>
  <block id="50af1dc10d66589053fc82292fe61444" category="inline-link-macro">次のステップ：永続的ボリューム要求を定義します</block>
  <block id="bb0c0300eb362a15d2d6480d832ecfbe" category="paragraph"><block ref="bb0c0300eb362a15d2d6480d832ecfbe" category="inline-link-macro-rx"></block></block>
  <block id="677b450634b1a6a563206526cb4d9075" category="doc">TR-4858 ：『 NetApp Orchestration 解決策 with Run ： AI 』</block>
  <block id="0959ee1db60e15d1e8e42d1206ca6a19" category="paragraph">ネットアップの Yaron Goldberg 、 Run ： AI 、 David Arnette 、 Sung-Han Lin</block>
  <block id="c87cafeb37457343ef978bbf8cad88b5" category="paragraph">NetApp AFF ストレージシステムは、卓越したパフォーマンスと業界をリードするハイブリッドクラウドデータ管理機能を提供します。ネットアップと Run ： AI は、 NetApp ONTAP AI 解決策の独自の機能である人工知能（ AI ）と機械学習（ ML ）のワークロードに対応し、エンタープライズクラスのパフォーマンス、信頼性、サポートを提供していることを実証するために提携しました。実行： AI ワークロードの AI オーケストレーションにより、 Kubernetes ベースのスケジュールとリソース利用プラットフォームが追加され、研究者が GPU 利用率を管理、最適化できるようになります。ネットアップ、 NVIDIA 、 Run ： AI の解決策を組み合わせた NVIDIA DGX システムは、エンタープライズ AI ワークロードに特化したインフラスタックを提供します。このテクニカルレポートでは、さまざまなユースケースや業種に対応した会話型 AI システムを構築するお客様向けのガイダンスを提供します。Run の導入に関する情報、 AI と NetApp AFF A800 ストレージシステムが記載されています。 AI イニシアチブを短期間で成功に導くためのリファレンスアーキテクチャとして機能します。</block>
  <block id="cae36004793b7131e0fc2323f598e7bb" category="list-text">AI 開発のためのソリューションを設計するエンタープライズアーキテクト コンテナ化などの Kubernetes ベースのユースケース向けのモデルとソフトウェア マイクロサービス</block>
  <block id="5d138e1f42e31fb645a3e3f5a8d37929" category="list-text">データサイエンティストは、効率的なモデルを実現するための効率的な方法を探しています 複数のチームとで構成されるクラスタ環境における開発目標 プロジェクト</block>
  <block id="0d43a0c7aeec219a746e836746c0b208" category="list-text">本番モデルの保守と実行を担当するデータエンジニア</block>
  <block id="00d764d2e91381a99d6f2c7b108e7c8e" category="list-text">エグゼクティブや IT の意思決定者、ビジネスリーダー Kubernetes クラスタのリソース利用率を最適化する方法をご確認ください AI 導入の市場投入までの時間を短縮できます</block>
  <block id="7a83f363d45e73d7915a600e1bbc92ba" category="inline-link-macro">次の手順：解決策の概要</block>
  <block id="29d90e44a805022079f5ad8bc748f89f" category="paragraph"><block ref="29d90e44a805022079f5ad8bc748f89f" category="inline-link-macro-rx"></block></block>
  <block id="6631bf64346739a9880a9789a941a8d6" category="inline-link-macro">ONTAP AI 導入向けの Kubernetes StorageClasses の例</block>
  <block id="01360221b637a04fa184dc6b9355fa46" category="summary">この解決策の作成の一環として、パフォーマンスを簡単に比較しました。ネットアップの標準的なベンチマークジョブをいくつか実行しましたが、 Kubernetes を使用して実行した場合と、ベンチマークの結果を単純な Docker run コマンドを使用して実行した場合を比較しました。</block>
  <block id="0e2f0f77407bfd956f621e13b8c1be34" category="doc">パフォーマンステスト</block>
  <block id="74575b23d5305310e904f87eb02ff980" category="cell">ベンチマーク</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">データセット</block>
  <block id="c269688995d2959579fca276425898b8" category="cell">Docker Run （イメージ / 秒）</block>
  <block id="b3acbf223e2bb7a3a796e3b698a7748d" category="cell">Kubernetes （画像 / 秒）</block>
  <block id="6de4dbc350a60fb9d5ea80ac7854681d" category="cell">シングルノード TensorFlow</block>
  <block id="2ec7cdace40d8a092e842288dfe854f7" category="cell">統合データ</block>
  <block id="a5ee9f5535788c17b947b7f2d8354351" category="cell">6,667.2475</block>
  <block id="b573d76a35b8d44de29524f11e873c60" category="cell">6,661.93125</block>
  <block id="f9622443c76d58838af97acd4f0c12ed" category="cell">6,570.2025</block>
  <block id="f93ed9c22230ae6e2ed85323e8d3dff7" category="cell">6,530.59125</block>
  <block id="83817408eae44458daefc1a9516ad170" category="cell">2 ノードの同期分散 TensorFlow</block>
  <block id="d4b63997154f30598f823403bb4df7ba" category="cell">13,213.70625</block>
  <block id="a328a929a422e4b69be5bbe94694282e" category="cell">13,218.288125</block>
  <block id="209f721713f475a9a0f4ba2743b40853" category="cell">12,941.69125</block>
  <block id="1f07dab13107a813c6d35bb76648ec48" category="cell">12,881.33875</block>
  <block id="66bc9494be0116470b223f2e07873f77" category="summary">このページでは、 NetApp AI コントロールプレーン解決策を実装する Kubernetes クラスタを導入するために実行する必要があるタスクについて説明します。Kubernetes クラスタをすでにお持ちの場合は、 Kubeflow と NetApp Trident でサポートされるバージョンの Kubernetes を実行していれば、このセクションをスキップできます。</block>
  <block id="2034cc978abb3057c4cf27e92b16ee74" category="doc">Kubernetes の導入</block>
  <block id="7c1ab988344d6a8d8cd9a30d6240955a" category="paragraph">このセクションでは、 NetApp AI コントロールプレーン解決策を実装する Kubernetes クラスタを導入するために完了しておく必要があるタスクについて説明します。Kubernetes クラスタをすでにお持ちの場合は、 Kubeflow と NetApp Trident でサポートされるバージョンの Kubernetes を実行していれば、このセクションをスキップできます。Kubeflow でサポートされる Kubernetes バージョンの一覧については、を参照してください<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>。Trident でサポートされている Kubernetes のバージョンのリストについては、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="ef8333b35fd982099a6ca0c7799b5618" category="paragraph">NVIDIA GPU を搭載したベアメタルノードを統合したオンプレミスの Kubernetes 環境では、 NVIDIA の DeepOps Kubernetes 導入ツールの使用を推奨します。このセクションでは、 DeepOps を使用した Kubernetes クラスタの導入について説明します。</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">このセクションで説明する導入の演習を行う前に、次の作業をすでに実行していることを前提としています。</block>
  <block id="612cba744b0eac9a7f153d2c4b8975da" category="list-text">標準的な構成手順に従って、ベアメタルの Kubernetes ノード（ ONTAP AI ポッドに含まれる NVIDIA DGX システムなど）を設定済みであること。</block>
  <block id="5a881e8e37e19924ac592136b5e7cfd3" category="inline-link">DeepOps GitHub サイト</block>
  <block id="452f5f6e8da4512f6cce223a76ae3558" category="list-text">すべての Kubernetes マスターノードとワーカーノード、および導入ジャンプホストに、サポートされているオペレーティングシステムをインストールしておきます。DeepOps でサポートされているオペレーティングシステムのリストについては、を参照してください<block ref="253a2cf380d7db7eaadb375aa91e2221" category="inline-link-rx"></block>。</block>
  <block id="a711e4ccced882d1762a8c653be8e921" category="section-title">NVIDIA DeepOps を使用して Kubernetes をインストールおよび設定します</block>
  <block id="47302a7393e0a038a150e679c9b3e80d" category="paragraph">NVIDIA DeepOps で Kubernetes クラスタを導入および設定するには、導入ジャンプホストから次のタスクを実行します。</block>
  <block id="5c51dc3fcfdd9653809e90fa3948c2f4" category="inline-link">「はじめに」ページ</block>
  <block id="21f937997adb0cac073e2458491f2c2f" category="list-text">の手順に従って、 NVIDIA DeepOps をダウンロードします<block ref="a94c3c17b923443c927cfa8fe7a2482a" category="inline-link-rx"></block> NVIDIA DeepOps GitHub サイトで入手できます。</block>
  <block id="2ed5978807d3da780c60a19b3f38a293" category="inline-link">Kubernetes 導入ガイドのページ</block>
  <block id="2dfe8bb84d94f23030d91e315d7899bc" category="paragraph">DeepOps Kubernetes 環境を使用するには、 Kubernetes マスターノードとワーカーノードがすべて同じユーザである必要があります。</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="doc">デフォルトの Kubernetes StorageClass を設定します</block>
  <block id="e1be30d98edccc10974d5d339832197c" category="paragraph">Kubeflow を導入する前に、 Kubernetes クラスタ内でデフォルトの StorageClass を指定する必要があります。Kubeflow の導入プロセスでは、デフォルトの StorageClass を使用して新しい永続ボリュームのプロビジョニングが試行されます。StorageClass がデフォルトの StorageClass として指定されていない場合、導入は失敗します。クラスタ内のデフォルトの StorageClass を指定するには、導入ジャンプホストから次のタスクを実行します。クラスタ内ですでにデフォルトの StorageClass を指定している場合は、この手順を省略できます。</block>
  <block id="e3e4fbe325df2b20670ca04ad0c2a517" category="list-text">既存のストレージクラスの 1 つをデフォルトのストレージクラスとして指定します。以降のコマンド例では、「 ontap/ai-sFLEXs-retain 」という名前の StorageClass がデフォルトの StorageClass として指定されています。</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">解決策の概要</block>
  <block id="4ed0a51bc1c995651eec6f50591eec1a" category="section-title">NetApp ONTAP AI と Cloud Sync</block>
  <block id="bff183f31dd9706bece9767f4388a819" category="paragraph">ネットアップと NVIDIA は、 NVIDIA DGX システムとネットアップのクラウド対応ストレージシステムを基盤とする NetApp ONTAP AI アーキテクチャを開発、検証しました。このリファレンスアーキテクチャには、 IT 組織に次のようなメリットがあります。</block>
  <block id="88acd7d612f76d7928b6b0448806e1ea" category="list-text">さまざまなパフォーマンスとコストの観点から、幅広いストレージオプションを提供 NetApp ONTAP AI は、 DGX システムと NetApp AFF A220 ストレージシステムを最先端のネットワーク機能と緊密に統合します。NetApp ONTAP AI システムと DGX システムでは、設計の複雑さと推測に頼らず、 AI 導入を簡易化できます。お客様は小規模構成から始めて、システムを中断なく拡張できます。同時に、エッジ、コア、クラウドにわたってデータをインテリジェントに管理できます。</block>
  <block id="69be3bc10a1ad78dbe823def1907c730" category="paragraph">NetApp Cloud Sync を使用すると、 2 つの NFS 共有、 2 つの CIFS 共有、 1 つのファイル共有と Amazon S3 、 Amazon Elastic File System （ EFS ）、 Azure BLOB ストレージの間で、さまざまなプロトコルを介してデータを簡単に移動できます。アクティブ / アクティブ処理とは、ソースとターゲットの両方と同時に作業を継続し、必要に応じてデータの変更を段階的に同期することを意味します。オンプレミスでもクラウドベースでも、ソースシステムとデスティネーションシステム間でデータを移動して段階的に同期できるため、 Cloud Sync では、データを使用できる新しい方法がさまざまに提供されます。オンプレミスのシステム間でのデータ移行、クラウドへのオンボーディングやクラウドへの移行、コラボレーションとデータ分析などのすべての作業を容易に実現できます。次の図は、使用可能なソースとデスティネーションを示しています。</block>
  <block id="1e01782ef13699818c9eb9eab796bffc" category="paragraph">会話型 AI システムでは、 Cloud Sync を活用してクラウドからデータセンターまでの会話履歴をアーカイブし、 NLP （ Natural Language Processing ）モデルのオフライントレーニングを可能にできます。より多くのインテントを認識するためのトレーニングモデルによって、会話型 AI システムは、エンドユーザーからのより複雑な質問にも対応できるようになります。</block>
  <block id="45f2cdf50f8bb89b245e814009b4244c" category="section-title">NVIDIA Jarvis マルチモーダルフレームワーク</block>
  <block id="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="paragraph"><block ref="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ad66827309f61fd22dc58cbbb2f8273" category="inline-link">NVIDIA Jarvis</block>
  <block id="241d985aedf9124840f9adfa9496755d" category="paragraph"><block ref="9f89431954623c8e5c580e4350b427e7" category="inline-link-rx"></block> 会話型 AI サービスを構築するためのエンドツーエンドのフレームワークです。GPU 向けに最適化された次のサービスが含まれています。</block>
  <block id="bb3e7af8136880e3a92118c172aed302" category="list-text">自動音声認識（ ASR ）</block>
  <block id="3c07089a439435a2998f14ea97f90825" category="list-text">自然言語理解（ NLU ）</block>
  <block id="8375cc1d63ce172363c4ed9c3cddd508" category="list-text">ドメイン固有のフルフィルメントサービスとの統合</block>
  <block id="84fb561f92aa70d5e118f429e98ee99b" category="list-text">テキスト / スピーチ（ TTS ）</block>
  <block id="9478a4e1be70e1be0fdd56f3929bbdc2" category="list-text">コンピュータビジョン（ CV ）ジャービスベースのサービスは、最先端のディープラーニングモデルを使用して、リアルタイムの会話型 AI の複雑で困難なタスクに対処します。エンドユーザーとのリアルタイムかつ自然な対話を可能にするには、モデルが 300 ミリ秒未満で計算を完了する必要があります。自然な相互作用は困難であり、マルチモーダル感覚を統合する必要があります。モデルパイプラインも複雑で、上記のサービス全体で調整が必要です。</block>
  <block id="c29efa8b1d5c9d6d647a8ce72bef1b74" category="paragraph">Jarvis は、エンドツーエンドのディープラーニングパイプラインを使用する、マルチモーダル会話型 AI サービスを構築するための、完全に高速化されたアプリケーションフレームワークです。Jarvis フレームワークには、音声、ビジョン、および NLU タスク向けに、事前にトレーニングされた会話型 AI モデル、ツール、最適化されたエンドツーエンドサービスが含まれます。AI サービスに加えて、 Jarvis ではビジョン、オーディオ、およびその他のセンサー入力を同時に融合し、仮想アシスタント、マルチユーザーのディアゼーション、コールセンターアシスタントなどのアプリケーションでマルチコンテキスト会話などの機能を提供できます。</block>
  <block id="dc3652fc64a2a6ea2a3cfd5c40443b16" category="paragraph"><block ref="4282ee73b9eecd67e90ed51f4f36b077" category="inline-link-rx"></block> は、使いやすいアプリケーションプログラミングインターフェイス（ API ）を使用して、 GPU によって高速化された最先端の会話型 AI モデルを構築、トレーニング、微調整するためのオープンソース Python ツールキットです。Nemo は、 NVIDIA GPU で Tensor コアを使用して精度の高いコンピューティングを実行し、複数の GPU に簡単にスケールアップして、トレーニングのパフォーマンスを最大限に高めることができます。Nemo は、医療、金融、小売、通信など、さまざまな業界のさまざまな業界で、ビデオ通話の文字変換、インテリジェントビデオアシスタント、自動コールセンターサポートなどのリアルタイム ASR 、 NLP 、 TTS アプリケーションのモデルを構築するために使用されます。</block>
  <block id="4e5ae683e2a399c166a1724b0aa6952e" category="paragraph">Nemo を使用して、アーカイブされた会話履歴のユーザ質問から複雑なインテントを認識するモデルをトレーニングしました。このトレーニングは、 Jarvis が提供したもの以外にも、小売バーチャルアシスタントの機能を拡張します。</block>
  <block id="053bc62e92a61e44afd338bcb27c422f" category="section-title">小売業のユースケースの概要</block>
  <block id="e1196fc000d661461f32bcaab7319c6a" category="inline-link">小売ユースケースの状態とフローをカスタマイズします</block>
  <block id="8b6b761738b93e745ffa4f73dd233c08" category="paragraph">NVIDIA Jarvis を使用して、スピーチやテキスト入力を受け付け、天気、関心のあるポイント、在庫価格に関する質問に回答できる仮想小売アシスタントを構築しました。会話型 AI システムでは、たとえば、天気や関心のある場所を指定していない場合は、フォローアップの質問をして会話の流れを記憶することができます。また、「タイ料理」や「ノートパソコンのメモリ」などの複雑なエンティティも認識します。 「ロサンゼルスで来週雨が降るだろうか？」など、自然言語の質問を理解しています。 小売バーチャルアシスタントのデモンストレーションは、にあります<block ref="0ba395e7fb59bace5ff35ab3c02ad737" category="inline-link-rx"></block>。</block>
  <block id="af8f881c5074e5e10cd7a34ccbaa9e57" category="paragraph"><block ref="af8f881c5074e5e10cd7a34ccbaa9e57" category="inline-link-macro-rx"></block></block>
  <block id="c755c33dca37a8aaffbf190bdf3f5fef" category="paragraph">この解決策は、 1 台の NetApp AFF A800 システム、 2 台の DGX-1 サーバ、 2 台の Cisco Nexus 3232C 100GbE スイッチで実装されました。DGX-1 サーバはそれぞれ 4 本の 100GbE 接続で Nexus スイッチに接続されます。この接続は、 Converged Ethernet （ RoCE ）を介したリモートダイレクトメモリアクセス（ RDMA ）を使用する GPU 間通信に使用されます。NFS ストレージアクセス用の従来の IP 通信も、これらのリンクで行われます。各ストレージコントローラは、 4 つの 100GbE リンクを使用してネットワークスイッチに接続されています。次の図に、このテクニカルレポートですべてのテストシナリオに使用した ONTAP AI 解決策アーキテクチャを示します。</block>
  <block id="782c9fdc3f29358987c2f5b99fe9e6b9" category="paragraph"><block ref="782c9fdc3f29358987c2f5b99fe9e6b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf8b135ff3c775c5b9bbba1b2f7a61ce" category="section-title">この解決策で使用されているハードウェア</block>
  <block id="a4ec49885c617f2b2500789af7e6eebf" category="paragraph">この解決策は、 ONTAP AI リファレンスアーキテクチャ DGX 1 ノードと AFF A800 ストレージシステム 1 台を使用して検証されました。を参照してください<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> を参照してください。</block>
  <block id="fe59cdcdefd7c53625e1e745b9c5be09" category="cell">DGX-1 システム</block>
  <block id="53270fbfda62583949b287e08ae3d063" category="cell">AFF A800</block>
  <block id="6da64488bfb7f3216610e30ced34ff23" category="cell">Nexus 3232C スイッチ</block>
  <block id="8e926487edd9348114ada5fa88a732df" category="paragraph">この解決策は、 Run ： AI オペレータがインストールされた基本的な Kubernetes 環境で検証されました。Kubernetes はを使用して導入されました<block ref="1c894f7463797b81796e78efc8345fb0" category="inline-link-rx"></block> 導入エンジン：本番環境に必要なすべてのコンポーネントを導入します。DeepOps は自動的に導入されます<block ref="ca1c90879f9a0e8dc4ff805fb398f7ff" category="inline-link-rx"></block> Kubernetes 環境との永続的なストレージ統合のために、デフォルトのストレージクラスが作成されました。これにより、コンテナは AFF A800 ストレージシステムのストレージを活用できます。Trident と ONTAP AI の Kubernetes の詳細については、を参照してください<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block>。</block>
  <block id="a2525584dd9d2a9522ddea95841c06b3" category="cell">9.6p4</block>
  <block id="80afba45eb055fc9bdc48c90d1debd06" category="cell">Kubernetes のバージョン</block>
  <block id="4bbe90408850f459864a71c8054732f1" category="cell">1.17</block>
  <block id="f1112223b41fddc71fd6a626582dfb78" category="cell">Trident のバージョン</block>
  <block id="43d66966083b0e0feac8fb9be14ba5b8" category="cell">20.04.0</block>
  <block id="e993176eed424766bc6bd4758eaf2cb6" category="cell">AI CLI を実行</block>
  <block id="5e6305186adf6e7dcf03f5cbfc802c49" category="cell">v2.1.13</block>
  <block id="f3eeed8e4b2791f80e2f123c4720aef5" category="cell">実行： AI Orchestration Kubernetes Operator バージョン</block>
  <block id="bf8c2933a2f54ce25fe986f66d3bffa3" category="cell">1.0.39</block>
  <block id="076ca75e2fc5b6ea85d72b0a9adc8844" category="inline-link">AI GPU クラスタの前提条件を実行します</block>
  <block id="eaec7f01752b17abf6125d8f29a8543c" category="paragraph">実行に必要なその他のソフトウェア要件： AI は、から入手できます<block ref="98bb21d82bcd499a183c82dcfc9b02f3" category="inline-link-rx"></block>。</block>
  <block id="cc352f05f03c970b081b8afa29693b60" category="inline-link-macro">次のステップ： AI を実行することでクラスタと GPU の利用率を最適化</block>
  <block id="b1b09355c9538fe149372d3728c98bb1" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block></block>
  <block id="dbb4dd9a11f48db13d63eedaae717fe5" category="doc">データサイエンスチームのプロジェクトを作成し、 GPU を割り当てる</block>
  <block id="22d09d229a06f294b0f45804f8e639d3" category="paragraph">研究者は、 AI CLI や Kubeflow などのプロセスを使ってワークロードを送信できます。リソースの割り当てを合理化して優先順位を設定するために、 Run ： AI では「プロジェクト」という概念が導入されています。プロジェクトは、プロジェクト名を GPU 割り当てと優先設定に関連付けるクォータエンティティです。複数のデータサイエンスチームを管理するシンプルで便利な方法です。</block>
  <block id="c0bd05e9d88cf015eac684873bfd14c7" category="paragraph">ワークロードを送信する研究者は、プロジェクトをワークロード要求に関連付ける必要があります。Run ： AI スケジューラは、リクエストを現在の割り当てとプロジェクトと比較して、ワークロードにリソースを割り当てることができるかどうか、またはワークロードを保留中の状態にするかどうかを判断します。</block>
  <block id="800f40fa67f69116bf6f38cd07456608" category="paragraph">システム管理者は、実行： AI プロジェクトタブで次のパラメータを設定できます。</block>
  <block id="9c429f2284a95aaa299c7d85ccb16734" category="list-text">* モデルプロジェクト。 * ユーザーごとにプロジェクトを設定し、ユーザーのチームごとにプロジェクトを設定し、実際の組織プロジェクトごとにプロジェクトを設定します。</block>
  <block id="b2f1422cf0d082a495bbf865b9a5621d" category="list-text">* プロジェクトの割り当て量。 * 各プロジェクトは、このプロジェクトに同時に割り当てることができる GPU の割り当て量に関連付けられています。これは、このプロジェクトを使用している研究者が、クラスタ内のどの状態であっても、この数の GPU を取得できることが保証されるという意味で、保証されたクォータです。原則として、プロジェクトの割り当ての合計は、クラスタ内の GPU の数と等しくなければなりません。さらに、このプロジェクトのユーザは、過剰割り当てを受け取ることができます。GPU が使用されていない限り、このプロジェクトを使用する研究者は GPU を増やすことができます。に、クォータ超過テストのシナリオと公平性に関する考慮事項を示します<block ref="9563fd9ab6978412dc97d80a70e51786" category="inline-link-rx"></block>、<block ref="a8ad108feafc827856baa28b0b9070ed" category="inline-link-rx"></block>および<block ref="be867f64efefe193012b1dfc6c82f783" category="inline-link-rx"></block>。</block>
  <block id="20a3a45fbbd9502add12fd216350d569" category="list-text">新しいプロジェクトを作成し、既存のプロジェクトを更新して、既存のプロジェクトを削除します。</block>
  <block id="3bf13b237342258b6ddb3f167d679a3b" category="inline-link">「 AI Documentation 」を実行します</block>
  <block id="77332641abf52ec5dc1af8b23b2339f3" category="list-text">* 特定のノードグループで実行するジョブを制限 * 。特定のプロジェクトを割り当てて、特定のノードでのみ実行することができます。これは、プロジェクトチームが十分なメモリを備えた特殊なハードウェアを必要とする場合などに便利です。また、プロジェクトチームは、特別な予算で取得された特定のハードウェアの所有者になる場合もあります。また、パフォーマンスが低いハードウェアで作業したり、長いトレーニングや無人ワークロードを高速ノードに誘導したりするために、ビルドや対話型のワークロードを処理する必要がある場合もあります。ノードをグループ化し、特定のプロジェクトにアフィニティを設定するコマンドについては、を参照してください <block ref="eae60ce89b8727160634b52e7654bf73" category="inline-link-rx"></block>。</block>
  <block id="2bd802cca9bf193b441123437f5d39ca" category="list-text">* 対話型ジョブの期間を制限します * 。研究者たちは、対話型の仕事を閉じることを忘れがちだ。これにより、リソースの無駄が発生する可能性があります。一部の組織では、対話型ジョブの期間を制限し、自動的に終了することを希望しています。</block>
  <block id="10c2495ded559d79de96be22751712dc" category="paragraph">次の図は、 4 つのチームが作成されたプロジェクトビューを示しています。各チームには、異なるワークロードに対応するために異なる数の GPU が割り当てられます。 GPU の総数は、 2 台の DGX-1 で構成されるクラスタ内の使用可能な GPU の総数と同じです。</block>
  <block id="9ba047faa1d241a6153be986be27097f" category="paragraph"><block ref="9ba047faa1d241a6153be986be27097f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4804b15e4766599ceade052b5ca8af9" category="inline-link-macro">次の例は、 Run AI CLI でジョブを送信しています</block>
  <block id="9c6088fad9917e07026030c1d3eaad09" category="paragraph"><block ref="9c6088fad9917e07026030c1d3eaad09" category="inline-link-macro-rx"></block></block>
  <block id="9e40fd8f5f0e113c758dfa63adc1221d" category="summary">Kubeflow は、データサイエンティストのワークスペースとして機能する、新しい Jupyter Notebook サーバの迅速なプロビジョニングを可能にします。Kubeflow を使用して新しい Jupyter Notebook サーバをプロビジョニングするには、このページに記載されているタスクを実行します。</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">データサイエンティストまたは開発者向けに Jupyter Notebook Workspace をプロビジョニングします 使用</block>
  <block id="5e82e4aa94a53b3b50acf347914be197" category="list-text">Kubeflow 中央ダッシュボードのメインメニューで Notebook Servers をクリックして、 Jupyter Notebook サーバ管理ページに移動します。</block>
  <block id="358d18b5a42ec1d80b04e767298ea372" category="paragraph"><block ref="358d18b5a42ec1d80b04e767298ea372" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208feb7a4d57f0afc49e53fe1fe8b978" category="list-text">新しい Jupyter Notebook サーバをプロビジョニングするには、 New Server をクリックします。</block>
  <block id="3541a3b25823fa3b302c686b6fe2a212" category="paragraph"><block ref="3541a3b25823fa3b302c686b6fe2a212" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f95069a2e81949b101427e1fa4afddf" category="list-text">新しいサーバに名前を付け、サーバのベースにする Docker イメージを選択し、サーバで予約する CPU と RAM の容量を指定します。[ 名前空間 ] フィールドが空白の場合は、ページヘッダーの [ 名前空間の選択 ] メニューを使用して名前空間を選択します。選択したネームスペースがネームスペースフィールドに自動的に入力されます。</block>
  <block id="4fbbbc4aaa49d653f486738eed12357a" category="paragraph">次の例では 'kubeflow-anonymous' ネームスペースが選択されていますまた、 Docker イメージ、 CPU 、 RAM のデフォルト値も使用できます。</block>
  <block id="69bc8b3ae7667985c27ce3ef5de0e6ca" category="paragraph"><block ref="69bc8b3ae7667985c27ce3ef5de0e6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c44927b0124469511a724e179c80bfb5" category="paragraph"><block ref="c44927b0124469511a724e179c80bfb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c73069b282d8e99ecbd8feb39164d40" category="paragraph"><block ref="0c73069b282d8e99ecbd8feb39164d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b120f9006af3d27ef70eb256c99c6617" category="list-text">* オプション： * 希望する数の GPU をノートブックサーバーに割り当てるよう要求します。次の例では、 GPU が 1 つ要求されています。</block>
  <block id="c969e6364e4561a959d1ce20f7187723" category="paragraph"><block ref="c969e6364e4561a959d1ce20f7187723" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8da2142543d647576288d71dddabb01" category="list-text">[ 起動 ] をクリックして、新しいノートブックサーバーをプロビジョニングします。</block>
  <block id="417a2eafac6842560d3900cf9d12b5bb" category="paragraph"><block ref="417a2eafac6842560d3900cf9d12b5bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0463a63e8059055e703ecd9ffa72e106" category="list-text">[ 接続 ] をクリックして、新しいサーバー Web インターフェイスに接続します。</block>
  <block id="4fbf21602f4888216386998d62f1defd" category="list-text">手順 6 で指定したデータセットボリュームがサーバにマウントされていることを確認します。デフォルトでは、このボリュームはデフォルトのワークスペース内にマウントされます。ユーザーの観点から見ると、これはワークスペース内の別のフォルダーにすぎません。データサイエンティストで、インフラのエキスパートではないユーザは、このボリュームを使用するためにストレージの専門知識を持っている必要はありません。</block>
  <block id="c4b6acc44505864a5dccae2571b74f6a" category="paragraph"><block ref="c4b6acc44505864a5dccae2571b74f6a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7d375154397ce9358d2234ec578ff7e" category="paragraph"><block ref="a7d375154397ce9358d2234ec578ff7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="479d03862d87da58784e60e5cfcec977" category="list-text">ターミナルを開き、手順 5 で新しいボリュームが要求された場合は、「 d f -h 」を実行して、 Trident でプロビジョニングされた新しい永続ボリュームがデフォルトのワークスペースとしてマウントされていることを確認します。</block>
  <block id="68f39a4f77e618e6617c3830fb47de7c" category="paragraph">デフォルトのワークスペースディレクトリは、サーバーの Web インターフェイスに最初にアクセスしたときに表示されるベースディレクトリです。そのため、 Web インターフェイスを使用して作成したアーティファクトは、 Trident でプロビジョニングされた永続ボリュームに保存されます。</block>
  <block id="d3e91c75db0cb717734224e6eb72e201" category="paragraph"><block ref="d3e91c75db0cb717734224e6eb72e201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d739fe0e421e9cb4d6315f0021cc5eb" category="paragraph"><block ref="1d739fe0e421e9cb4d6315f0021cc5eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8c20de15cf5efa2297f9d40d899450e" category="list-text">ターミナルを使用して「 nvidia-smi 」を実行し、ノートブックサーバーに正しい数の GPU が割り当てられていることを確認します。次の例では、手順 7 で要求されたように、 1 つの GPU がノートブックサーバーに割り当てられています。</block>
  <block id="ed4e7225349e5c6cd33dfd15ad878438" category="paragraph"><block ref="ed4e7225349e5c6cd33dfd15ad878438" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a37acabf89826767b5a5fcb8dacffa3" category="summary">このページでは、 Kubernetes クラスタに Kubeflow を導入するために完了しなければならないタスクについて説明します。</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">このセクションでは、 Kubernetes クラスタに Kubeflow を導入するために実行する必要のあるタスクについて説明します。</block>
  <block id="f48269a81318d4bd2dd9e57a8239fe56" category="list-text">Kubernetes クラスタはすでに稼働しており、 Kubeflow でサポートされるバージョンの Kubernetes を実行しているとします。サポートされているバージョンの一覧については、を参照してください<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>。</block>
  <block id="9fc644d78f21555decceeddf5b691fa4" category="list-text">内に NetApp Trident のインストールと設定が完了している必要があります Kubernetes クラスタ（を参照） <block ref="ec7700e2b8d95edf2f2700b590eab273" category="inline-link-macro-rx"></block>。</block>
  <block id="48c4dc7fbfa1197490124f13eb565bd2" category="doc">ONTAP AI の導入</block>
  <block id="70d5c23ad68d59b2546133efdd1c3267" category="inline-link">NVA-1121-deploy ： NetApp ONTAP AI 、 Powered by NVIDIA</block>
  <block id="b393f072bc6b17085b75486a2abbcf97" category="paragraph">ONTAP AI を導入するには、ネットワーク、コンピューティング、ストレージハードウェアのインストールと設定が必要です。ONTAP AI インフラの導入手順については、本ドキュメントでは説明していません。導入の詳細については、を参照してください<block ref="8c03c9c25bc6aba17e86c510148a3423" category="inline-link-rx"></block>。</block>
  <block id="03e335ae74b1356b294af55e07eb6b70" category="paragraph">この解決策検証では、 1 つのボリュームを作成して DGX-1 システムにマウントしました。その後、そのマウントポイントをコンテナにマウントして、トレーニング用のデータにアクセスできるようにしました。大規模な環境では、 NetApp Trident によってボリュームの作成とマウントが自動化されるため、管理上のオーバーヘッドが発生しないとともに、エンドユーザによるリソースの管理が可能になります。</block>
  <block id="328d9c8854162b6d9dae70c57baa7505" category="inline-link-macro">次： Kubernetes の導入</block>
  <block id="5102c02ef61bdeaa79904c17f58ca7e3" category="paragraph"><block ref="5102c02ef61bdeaa79904c17f58ca7e3" category="inline-link-macro-rx"></block></block>
  <block id="74c071ff3c1d6d6fc39b72d617aefdf8" category="doc">解決策の導入と検証の詳細</block>
  <block id="b122830b8b8edd9e76690ea23b0c4cbd" category="paragraph">以降のセクションでは、解決策の導入と検証の詳細について説明します。</block>
  <block id="ebe48d794d8ada5d4e067cd5993bdd3e" category="inline-link-macro">次のステップ： ONTAP AI の導入</block>
  <block id="3b103491115e62f2388d69086a2eff9d" category="paragraph"><block ref="3b103491115e62f2388d69086a2eff9d" category="inline-link-macro-rx"></block></block>
  <block id="f7235eb2146d800446cbbbac3a57548c" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block>。</block>
  <block id="d052a88935efadcc9eebf94684d52e19" category="doc">高いクラスタ利用率の達成</block>
  <block id="27d597678185c0988ffb2dbb0c1b941d" category="inline-link-macro">ResNet-50 と ImageNet データセットベンチマークの概要</block>
  <block id="8d46742dbd21a217f738a9ca6a31f634" category="paragraph">このセクションでは、 4 つのデータサイエンスチームがそれぞれ独自のワークロードを送信して実行： AI オーケストレーション解決策を実証する現実的なシナリオをエミュレートしています。このシナリオでは、 GPU リソースの優先順位付けとバランシングを維持しながら、クラスタの利用率を高めることができますまず、で説明した ResNet-50 ベンチマークを使用します セクション <block ref="5872a8c23866a6bf186843724ee58ad7" category="inline-link-macro-rx"></block>：</block>
  <block id="14f48338822299bdf82bb4528d3c9e07" category="paragraph">ResNet-50 ベンチマークを実行しました（を参照）<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block>。パブリック Docker リポジトリに存在しないコンテナには、フラグ「 --local-image 」を使用しました。ディレクトリ「 /mnt/' 」と「 /tmp' 」をホスト DGX-1 ノード上の「 /mnt/' 」と「 /tmp' 」にそれぞれコンテナにマウントしました。データセットは、ディレクトリを指す「 dataset_dir 」引数を持つ NetApp AFFA800 にあります。どちらの場合も '--num_devices =1' と '-g 1' は ' このジョブに 1 つの GPU を割り当てていることを意味します前者は「 run.py 」スクリプトの引数で、後者は「 runai submit 」コマンドのフラグです。</block>
  <block id="bccb844975c2eec86eb25c0d8e2a989b" category="paragraph">次の図は、 97% の GPU 利用率を備え、 16 個の使用可能な GPU が割り当てられたシステム概要ダッシュボードを示しています。GPU / プロジェクトの棒グラフでは、各チームに割り当てられている GPU の数を簡単に確認できます。[ 実行中のジョブ ] ウィンドウ枠には、現在実行中のジョブ名、プロジェクト、ユーザー、タイプ、ノード、 GPU の消費、実行時間、進捗状況、利用率の詳細。キューに登録されているワークロードとその待機時間のリストが「保留中のジョブ」に表示されます。さらに、 Nodes ボックスは、クラスタ内の個々の DGX-1 ノードの GPU 番号と利用率を表示します。</block>
  <block id="1acc627e7c9d8002628b2e12c91ac683" category="paragraph"><block ref="1acc627e7c9d8002628b2e12c91ac683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5d3b5670d9303fddfb021e681546c0" category="inline-link-macro">次の例：要件の低いワークロードやインタラクティブなワークロードに適した、フラクショナルな GPU 割り当て</block>
  <block id="3d9997e0f8b3b6a279c8779455e7c760" category="paragraph"><block ref="3d9997e0f8b3b6a279c8779455e7c760" category="inline-link-macro-rx"></block></block>
  <block id="639ce1b23959b4470d67802f0e5e412a" category="doc">ONTAP AI 導入向けハイパフォーマンスジョブの例</block>
  <block id="fbe29309a183681bc26203d4c65853a2" category="paragraph">このセクションでは、従来のデータサイエンスパイプラインとその欠点について説明します。また、提案するデータセットキャッシング解決策のアーキテクチャについても説明します。</block>
  <block id="1f14aecc1193f646e0005e27fbc6e63d" category="section-title">従来のデータサイエンスパイプラインと欠点</block>
  <block id="17fb7d0ba5495199d3e18fe23dff7b59" category="paragraph">ML モデルの開発と導入の一般的な手順には、次のような反復的な手順が含まれます。</block>
  <block id="63e1ded7e3ae73253b5c287bc9bdef02" category="list-text">データの取り込み</block>
  <block id="52e028dc7ac82e9d4b7b1ae588fecc9a" category="list-text">データの前処理（データセットの複数のバージョンを作成）</block>
  <block id="33cd0fcdd9ee7e650043133b12516155" category="list-text">HyperParameter の最適化、さまざまなモデルなどを含む複数の実験を実行する</block>
  <block id="b85c416c94e0c5314a1e6fcc21d4139e" category="list-text">Monitoringcnvrg.io は、研究から導入までのすべてのタスクを自動化する包括的なプラットフォームを開発しました。次の図に、パイプラインに関するダッシュボードのスクリーンショットのごく一部を示します。</block>
  <block id="5a5ade85e7f7478bcba59e8c3891c914" category="paragraph"><block ref="5a5ade85e7f7478bcba59e8c3891c914" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26d6a4638ffd0b7779f1353f5fe54f0d" category="paragraph">パブリックリポジトリやプライベートデータから複数のデータセットを使用するのは非常に一般的です。また、データセットのクリーンアップやフィーチャーエンジニアリングによって、各データセットに複数のバージョンが生成されることもよくあります。次の図に示すように、データセットハブとバージョンハブを提供するダッシュボードは、コラボレーションツールと整合性ツールをチームで確実に使用できるようにするために必要です。</block>
  <block id="e884d73b6a4214bea010ec3bbfdad8b6" category="paragraph"><block ref="e884d73b6a4214bea010ec3bbfdad8b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93661dde7027bf31b3d007740a3d4648" category="paragraph">パイプラインの次のステップではトレーニングを行います。トレーニングモデルには複数の並行インスタンスが必要で、それぞれがデータセットと特定のコンピューティングインスタンスに関連付けられている必要があります。データセットを特定のコンピューティングインスタンスと特定の実験にバインドすることは、一部の実験は Amazon Web Services （ AWS ）の GPU インスタンスによって実行され、それ以外の実験は DGX-1 インスタンスまたは DGX-2 インスタンスによってオンプレミスで実行される可能性があるため、難しい課題です。GCP の CPU サーバーでは他の実験が実行され、データセットの場所がトレーニングを実行するコンピューティングリソースにあまり近接していない場合があります。合理的なプロキシミティには、データセットストレージからコンピューティングインスタンスへの完全な 10GbE 以上の低レイテンシ接続が必要です。</block>
  <block id="ba4f5ee1b0d01d3416723cfc3ec296ec" category="paragraph">データサイエンティストが、トレーニングを実行し、実験を実行するコンピューティングインスタンスにデータセットをダウンロードするのは、一般的に行われます。ただし、この方法にはいくつかの潜在的な問題があります。</block>
  <block id="90b6a1c5b483f6c6b399bc17c5e1af9a" category="list-text">データサイエンティストがデータセットをコンピューティングインスタンスにダウンロードした場合、統合コンピューティングストレージのパフォーマンスが高くても保証はありません（ハイパフォーマンスシステムの例としては ONTAP AFF A800 NVMe 解決策が挙げられます）。</block>
  <block id="5713a88504bb65e3808faac627a6a0fc" category="list-text">ダウンロードしたデータセットが 1 つのコンピューティングノードに存在する場合、複数のノードで分散モデルを実行すると（ NetApp ONTAP のハイパフォーマンス分散ストレージとは異なり）ストレージがボトルネックになることがあります。</block>
  <block id="299b9ae5439d32ed932f51f3b3aa92d6" category="list-text">トレーニング実験の次の反復は、キューの競合や優先順位のために別のコンピューティングインスタンスで実行される場合もあります。これも、データセットから計算場所へのネットワーク距離が大幅に大きくなります。</block>
  <block id="30e37003024e85518a26760a7ab58f4e" category="list-text">同じコンピューティングクラスタ上でトレーニング実験を実行する他のチームメンバーは、このデータセットを共有できません。各チームメンバーは、任意の場所からデータセットの（高価な）ダウンロードを実行します。</block>
  <block id="9e5d53150336efb0446a063309805f01" category="list-text">後続のトレーニングジョブで同じデータセットの他のデータセットまたはバージョンが必要な場合、データサイエンティストは、 training.NetApp および cnvrg.io を実行しているコンピューティングインスタンスにデータセットの（高価な）ダウンロードを再度実行する必要があります。これにより、これらの障害を解消する新しいデータセットキャッシング解決策が作成されます。解決策は、ホットデータセットを ONTAP ハイパフォーマンスストレージシステムにキャッシュすることで、 ML パイプラインの実行を高速化します。ONTAP NFS では、ネットアップが提供するデータファブリック（ AFF A800 など）にデータセットが 1 回だけ（一度だけ）キャッシュされ、コンピューティングと一緒に配置されます。NetApp ONTAP NFS 高速ストレージが複数の ML コンピューティングノードに対応できるようになるため、トレーニングモデルのパフォーマンスが最適化され、コスト削減、生産性、運用効率が向上します。</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">解決策アーキテクチャ</block>
  <block id="a63af1f206939a3c956a2e8b6ab53103" category="paragraph">この解決策は、次の図に示すように、ネットアップおよび cnvrg.io から提供されます。データセットのキャッシングにより、データサイエンティストは必要なデータセットまたはデータセットのバージョンを選択し、 ML コンピューティングクラスタのすぐ近くにある ONTAP NFS キャッシュに移動できます。データサイエンティストは、遅延やダウンロードを発生させることなく、複数の実験を実行できるようになりました。さらに、コラボレーションするすべてのエンジニアは、データレイクから追加のダウンロードを行うことなく、接続されたコンピューティングクラスタ（任意のノードを自由に選択できる）で同じデータセットを使用できます。データサイエンティストは、すべてのデータセットとバージョンを追跡および監視するダッシュボードを提供し、キャッシュされたデータセットを確認します。</block>
  <block id="612eaee91b23ecc385c1b402d44c081f" category="paragraph">cnvrg.io プラットフォームは、一定の期間使用されていない古いデータセットを自動検出し、キャッシュから削除します。これにより、使用頻度の高いデータセット用に NFS キャッシュの空きスペースが維持されます。ONTAP を使用したデータセットのキャッシングは、クラウドとオンプレミスで機能するため、最大限の柔軟性が得られることに注意してください。</block>
  <block id="0cb5e14601fcf39745352a9556939aa3" category="paragraph"><block ref="0cb5e14601fcf39745352a9556939aa3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="810aceabf729ffa8c2dfd61a3aaeafaa" category="inline-link-macro">次の手順：概念とコンポーネント</block>
  <block id="0a01ff9defa9120e928e7e306e3e3234" category="paragraph"><block ref="0a01ff9defa9120e928e7e306e3e3234" category="inline-link-macro-rx"></block></block>
  <block id="fb1290be14b9bc3c64a2c3c9ace6c065" category="doc">ユースケースの概要と問題点</block>
  <block id="aa04a8198c7c60df7adcd6cd49bec6f8" category="paragraph">データセットとデータセットのバージョンは通常、 NetApp StorageGRID オブジェクトベースストレージなどのデータレイクに配置されるため、コストの削減やその他の運用上のメリットが得られます。データサイエンティストは、これらのデータセットを取得して複数の手順でエンジニアを配置し、特定のモデルを使用したトレーニングに備えます。多くの場合、途中で複数のバージョンが作成されます。次のステップとして、データサイエンティストは、モデルを実行するために最適化されたコンピューティングリソース（ GPU 、ハイエンド CPU インスタンス、オンプレミスクラスタなど）を選択する必要があります。次の図は、 ML コンピューティング環境にデータセットの距離がないことを示しています。</block>
  <block id="cc054601488581e80cc1d19c227126f6" category="paragraph"><block ref="cc054601488581e80cc1d19c227126f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88515fca547c502286d6f2a9081fc734" category="paragraph">ただし、複数のトレーニング実験を異なるコンピューティング環境で並行して実行する必要があります。それぞれの環境では、データレイクからデータセットをダウンロードする必要があります。これはコストと時間のかかるプロセスです。データセットがコンピューティング環境（特にハイブリッドクラウド）に近接していることは保証されません。また、同じデータセットで独自の実験を行う他のチームメンバーも、同じ複雑なプロセスを実行する必要があります。データアクセスが遅いことが明らかなだけでなく、データセットのバージョン、データセットの共有、コラボレーション、再現性の追跡にも困難が伴います。</block>
  <block id="30b64502c0cb2f8a9bf951993e0abbac" category="section-title">お客様の要件</block>
  <block id="5243f720d7e440d7746f03df97ef885f" category="paragraph">リソースを効率的に使用しながら、高パフォーマンスの ML を実行するためには、お客様の要件が異なる場合があります。たとえば、次のような場合があります。</block>
  <block id="1735cf11ce0034dbb80c297fb204bc21" category="list-text">を実行する各コンピューティングインスタンスからデータセットに高速アクセス 高額なダウンロードやデータアクセスの複雑さを伴わないトレーニングモデル</block>
  <block id="80085a846f90523080cf086e66561d52" category="list-text">は任意のコンピューティングインスタンス（ GPU または CPU ）を使用する クラウドでもオンプレミスでも、場所を気にする必要はありません 」と入力します</block>
  <block id="de79912b1ab8764406a232888aab85e5" category="list-text">で複数のトレーニング実験を実行することで、効率と生産性が向上します を使用せずに、同一データセット上の異なるコンピューティングリソースと並行して実行できます 不要な遅延とデータ遅延</block>
  <block id="5211203793a223f02322b88b2e698a82" category="list-text">コンピューティングインスタンスのコストを最小限に抑えます</block>
  <block id="6a6fcee71b4e22ac6a4afdfdb5940b67" category="list-text">データセット、そのリネージ、バージョン、およびその他のメタデータの詳細の記録を保持するツールにより、再現性が向上しました</block>
  <block id="930d18875813298018f8364069441eee" category="list-text">共有とコラボレーションを強化して、の権限を持つすべてのメンバーをサポートします チームはデータセットにアクセスして実験を実行できます</block>
  <block id="5f700d00ad72470694a5aa06cd515c8b" category="paragraph">NetApp ONTAP データ管理ソフトウェアにデータセットのキャッシングを実装するには、次のタスクを実行する必要があります。</block>
  <block id="41fac0272180c0141b5cd7ad6ad85a44" category="list-text">コンピューティングリソースに最も近い NFS ストレージを構成して設定します。</block>
  <block id="25a3a7ee3cfbb4afc291cd5b94dec000" category="list-text">キャッシュするデータセットとバージョンを決定します。</block>
  <block id="dbffd2a20c35c06fbb6ba0cd17e54ef6" category="list-text">キャッシュされたデータセットにコミットされた合計メモリと、追加のキャッシュコミットに使用できる NFS ストレージの量（キャッシュ管理など）を監視します。</block>
  <block id="61d5e7050cbe037ad5adeaf246e6be19" category="list-text">特定の時間内に使用されなかったデータセットは、キャッシュ内でエージングアウトします。デフォルトは 1 日で、その他の設定オプションも使用できます。</block>
  <block id="36691dc48fac4774974c970e3bfa1a7d" category="paragraph"><block ref="36691dc48fac4774974c970e3bfa1a7d" category="inline-link-macro-rx"></block></block>
  <block id="0a1bc6b4024485ff9b55c99c1237e175" category="doc">クラスタと GPU の利用率を最適化して実行： AI</block>
  <block id="b8b025dc1895637326d2420e912751e0" category="summary">Trident を使用して Kubernetes クラスタ内のストレージリソースを動的にプロビジョニングするには、 Trident バックエンドを 1 つ以上作成する必要があります。このページの例は、 ONTAP AI ポッドにネットアップ AI コントロールプレーン解決策を導入する場合に作成するバックエンドのタイプを表しています。</block>
  <block id="f363c1a10e150fdee0f4f310a06acb5e" category="doc">ONTAP AI 導入向け Trident バックエンドの例</block>
  <block id="c0fe00dd01499e23426b850b65782c77" category="paragraph">Trident を使用して Kubernetes クラスタ内のストレージリソースを動的にプロビジョニングするには、 Trident バックエンドを 1 つ以上作成する必要があります。以下に示す例は、 ONTAP AI ポッドにネットアップ AI コントロールプレーン解決策を導入する場合に作成するバックエンドのタイプを表しています。バックエンドの詳細については、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="327a3876126e4773cfcc5e30649c9483" category="paragraph">以下のコマンド例は、同じ ONTAP Storage Virtual Machine （ SVM ）に関連付けられている 2 つの異なるデータ LIF を対象に、 FlexGroup 対応の Trident バックエンドを 2 つ作成する方法を示しています。これらのバックエンドは 'ONTAP-NAS-flexgroup ストレージ・ドライバを使用しますONTAP では、 FlexVol と FlexGroup の 2 つの主要なデータボリュームタイプがサポートされます。FlexVol ボリュームのサイズは限られています（現時点では、最大サイズは環境によって異なります）。一方、 FlexGroup ボリュームは最大 20PB 、 4 、 000 億ファイルまでリニアに拡張でき、データ管理を大幅に簡易化する単一のネームスペースを提供します。そのため、 FlexGroup ボリュームは、大量のデータに依存する AI や ML のワークロードに最適です。</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">少量のデータを処理していて、 FlexGroup ボリュームではなく FlexVol ボリュームを使用する場合は、「 ONTAP-NAS-flexgroup 」ストレージドライバの代わりに「 ONTAP-NAS' ストレージドライバ」を使用する Trident バックエンドを作成できます。</block>
  <block id="d04adbc45ec06c05c1826745b8f4ddf2" category="list-text">また、 FlexVol 対応の Trident バックエンドも 1 つ以上作成することを推奨します。FlexGroup ボリュームをデータセットストレージのトレーニングに使用する場合は、結果、出力、デバッグ情報などの格納に FlexVol ボリュームを使用できます。FlexVol ボリュームを使用する場合は、 FlexVol 対応の Trident バックエンドを 1 つ以上作成する必要があります。次に示すコマンド例は、単一のデータ LIF を使用する、 FlexVol 対応の Trident バックエンドの作成例を示しています。</block>
  <block id="e2b5e920360785877a1831ff4b128520" category="summary">ネットアップのセットアップ</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">セットアップ（ Setup ）</block>
  <block id="9af8334f3fca73145524498c2f49ee10" category="inline-link-macro">次の手順：概要</block>
  <block id="02e8a07ffc2e2c5240049e5214d70427" category="paragraph"><block ref="02e8a07ffc2e2c5240049e5214d70427" category="inline-link-macro-rx"></block></block>
  <block id="9dc7cfc5bd8fb85bad9fdab5cdded288" category="doc">「 AI Installation 」を実行します</block>
  <block id="c1b7d088e01f6ec6ec89bf69437e4bb1" category="paragraph">Run ： AI をインストールするには、次の手順を実行します。</block>
  <block id="7ad0483bc07dbde29ffd404af83f8305" category="list-text">DeepOps を使用して Kubernetes クラスタをインストールし、ネットアップのデフォルトストレージクラスを設定します。</block>
  <block id="16d20d34f759cd25fd7486bbc4046a50" category="list-text">GPU ノードの準備：</block>
  <block id="d3eff3861b26ba61222bacaa41bc0fa7" category="list-text">NVIDIA ドライバが GPU ノードにインストールされていることを確認します。</block>
  <block id="3683aa7fe695a205b8e40e9589c94a2e" category="list-text">「 nvidia - Docker 」がインストールされ、デフォルトの Docker ランタイムとして設定されていることを確認します。</block>
  <block id="cef990020518a58fb1e70a90b5df80fe" category="list-text">インストール実行： AI ：</block>
  <block id="e2d6778a342979b567501f951e36118a" category="inline-link">AI 管理 UI を実行</block>
  <block id="6fc7ea9b01c6028f691aac2aeac528f1" category="list-text">にログインします<block ref="668d940d94d02be49a88c4cfd2736fa9" category="inline-link-rx"></block> クラスタを作成できます。</block>
  <block id="fe8f08cfda6726e2dcc5d0b85ed2c67d" category="list-text">作成した「 runai-operator-&lt;clustername&gt; .yaml 」ファイルをダウンロードします。</block>
  <block id="b428155da5c27d208abd6c179c7669d3" category="list-text">オペレータ設定を Kubernetes クラスタに適用します。</block>
  <block id="fac4447e0ea2e4cd1a2d9e2fefeab694" category="list-text">インストールを確認します。</block>
  <block id="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link"><block ref="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link-rx"></block></block>
  <block id="2d14c64dc5dfa79a68cd6965fbf9e4b7" category="list-text">に進みます<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>。</block>
  <block id="feb48a27d95fc7a7e0c6db496c54d2fa" category="list-text">概要ダッシュボードに移動します。</block>
  <block id="09fa3891e2b39bb62217c6d097310577" category="inline-link">Run ： AI をオンプレミスの Kubernetes クラスタにインストール</block>
  <block id="45d7be937e1eddf966adaf68562966d4" category="inline-link">Run ： AI CLI のインストール</block>
  <block id="728f8fd776de1dc47f318473052286db" category="list-text">右上の GPU の数が、想定される GPU の数と GPU ノードの数をすべてサーバのリストに表示していることを確認します。実行： AI 導入の詳細については、を参照してください<block ref="089aa48f8d7b3b135b035765dd1e17ba" category="inline-link-rx"></block> および<block ref="f2f48a2074c9edc0c2dea174863a4f6e" category="inline-link-rx"></block>。</block>
  <block id="db9d1f740f050b1d20ab43a459bb225a" category="inline-link-macro">次の手順： AI ダッシュボードとビューを実行します</block>
  <block id="c56b5d251d18e9b020f95696fef9f0b9" category="paragraph"><block ref="c56b5d251d18e9b020f95696fef9f0b9" category="inline-link-macro-rx"></block></block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">ネットアップの概要</block>
  <block id="d30aa8861afaf98888c2367f107a8bc6" category="paragraph">ネットアップは、ハイブリッドクラウド環境におけるデータ管理のオーソリティです。ネットアップは、クラウド環境とオンプレミス環境全体でアプリケーションとデータの管理を簡易化し、デジタル変革を加速する、幅広いハイブリッドクラウドデータサービスを提供しています。グローバル企業がデータのポテンシャルを最大限に引き出し、お客様とのコンタクトの強化、イノベーションの促進、業務の最適化を図れるよう、パートナー様とともに取り組んでいます。</block>
  <block id="ee86473f0dbd191846077276ce455778" category="paragraph">NVIDIA DGX システムとネットアップのクラウド対応オールフラッシュストレージを基盤とする NetApp ONTAP AI は、データの信頼性を高め、エッジからコア、クラウドにわたるデータファブリックで分析、トレーニング、推論を高速化します。IT 組織には、次のようなメリットをもたらすアーキテクチャが提供されます。</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">コンピューティングとストレージを個別に拡張できます</block>
  <block id="6cb062d50ca0d4a2bfa0caec33fea16f" category="list-text">さまざまなパフォーマンスとコストの観点から、幅広いストレージオプションを提供 NetApp ONTAP AI は、 NVIDIA DGX-1 、ペタフロップス規模の AI システム、 NVIDIA Mellanox ハイパフォーマンスイーサネットスイッチを統合したコンバージドインフラスタックを提供し、 AI ワークロードの統合、導入の簡易化、 ROI の向上を実現します。このテクニカルレポートでは、 ONTAP AI を DGX-1 と NetApp AFF A800 ストレージシステムの 1 つに活用しました。次の図は、この検証で使用した DGX-1 システムを使用した ONTAP AI のトポロジを示しています。</block>
  <block id="3eedc2d7451e7ff0440f17c9e61227dc" category="paragraph"><block ref="3eedc2d7451e7ff0440f17c9e61227dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="section-title">NetApp AI コントロールプレーン</block>
  <block id="e1fc355cf7f97dbf25407695f8852241" category="paragraph">ネットアップの AI コントロールプレーンは、卓越した拡張性、合理的な導入、ノンストップのデータ可用性を備えた解決策で、 AI と ML を最大限に活用できます。AI コントロールプレーン解決策は、 Kubernetes と Kubeflow をネットアップのデータファブリックと統合します。クラウドネイティブ環境向けの業界標準のコンテナオーケストレーションプラットフォームである Kubernetes は、ワークロードの拡張性とモビリティを実現します。Kubeflow はオープンソースの機械学習プラットフォームで、管理と導入を簡易化し、開発者がより多くのデータサイエンスをより短時間で行えるようにします。ネットアップのデータファブリックは、エッジからコア、クラウドまで、パイプライン全体でデータに確実にアクセスできるよう、データの可用性とモビリティを妥協することなく提供します。このテクニカルレポートでは、 MLRun パイプラインで NetApp AI コントロールプレーンを使用しています。次の図は、 Kubernetes クラスタ管理ページを示しています。各クラスタに異なるエンドポイントを割り当てることができます。NFS Persistent Volume を Kubernetes クラスタに接続し、次の図に示すように、クラスタに接続された永続的ボリュームが表示されます<block ref="33155b45dbdad2f412212744fbe6f8dc" category="inline-link-rx"></block> 永続的ストレージのサポートとデータ管理機能を提供します。</block>
  <block id="b058638c35435549e77a90b91abd3305" category="paragraph"><block ref="b058638c35435549e77a90b91abd3305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d371ade9f9702601a7e2f8f57c8b013" category="paragraph"><block ref="7d371ade9f9702601a7e2f8f57c8b013" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1dc271f7d3ae88e2a019314b7e4fd8e" category="section-title">Iguazio の概要</block>
  <block id="0c9fe13fe6a660070e99a54151edd7c3" category="paragraph">Iguazio Data Science Platform は、開発の簡素化、パフォーマンスの向上、コラボレーションの促進、運用上の課題への対処を可能にする、完全に統合された安全なデータサイエンスプラットフォームサービス（ PaaS ）です。このプラットフォームには以下のコンポーネントが組み込まれており、 Iguazio データサイエンスプラットフォームを次の図に示します。</block>
  <block id="2137518d79f0a3dfe335e8c02312cf96" category="list-text">Jupyter Notebook 、統合分析エンジン、 Python パッケージを含むデータサイエンスワークベンチ</block>
  <block id="68ed19bfa85e4c4677e50979864e169b" category="list-text">実験追跡機能と自動化されたパイプライン機能を使用したモデル管理</block>
  <block id="37a28d84cd653345f1f2c036cb732f2d" category="list-text">拡張性に優れた Kubernetes クラスタでデータサービスと ML サービスを管理</block>
  <block id="77fdda1a79199ac02cde44b4249cb509" category="list-text">サーバレス関数のリアルタイムフレームワークである Nuclio</block>
  <block id="96a6f4a99a7526e82a294d44ed005701" category="list-text">SQL 、 NoSQL 、時系列データベース、ファイル（シンプルなオブジェクト）、ストリーミングをサポートする、きわめて高速でセキュアなデータレイヤです</block>
  <block id="00a48f02675717eaf6082c4ba536a366" category="list-text">ネットアップ、 Amazon S3 、 HDFS 、 SQL データベース、ストリーミングプロトコルやメッセージングプロトコルなどのサードパーティ製データソースとの統合</block>
  <block id="901630ad39a688431a68dc119f5378a3" category="list-text">Grafana に基づくリアルタイムダッシュボード</block>
  <block id="887fce38ef8ddd8546748bb746ed7e5a" category="paragraph"><block ref="887fce38ef8ddd8546748bb746ed7e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="961027a0ac9a1d9515fa54a5d5372c79" category="inline-link-macro">次の手順：ソフトウェアとハードウェアの要件</block>
  <block id="a10e3ee0949323f601d4c9624980eb47" category="paragraph"><block ref="a10e3ee0949323f601d4c9624980eb47" category="inline-link-macro-rx"></block></block>
  <block id="7c4090c7fa7a91e8c7fed182401dbf6b" category="doc">NetApp Trident の導入と設定</block>
  <block id="7c0ea3e86521674f72e056d148d4f2ce" category="paragraph">ネットアップと Run ：このテクニカルレポートでは、 AI と、 NetApp ONTAP AI 解決策の独自機能と、 Run ： AI プラットフォームを組み合わせることで、 AI ワークロードのオーケストレーションを簡易化できることを紹介しています。前の手順では、ディープラーニングのためのデータパイプラインとワークロードオーケストレーションのプロセスを合理化するリファレンスアーキテクチャを示します。これらのソリューションの導入を検討しているお客様には、ネットアップと Run ： AI の活用で詳細を確認することをお勧めします。</block>
  <block id="f797637684ff1290d12e5495dac050a6" category="inline-link-macro">次のセクション 4.8 のテストの詳細</block>
  <block id="bbe251d46ac2a6899a2a4d5d0e331a43" category="paragraph"><block ref="bbe251d46ac2a6899a2a4d5d0e331a43" category="inline-link-macro-rx"></block></block>
  <block id="8383a1cf96c028a0986b7371049c8495" category="doc">ネットワークデバイスの障害予測ユースケースの概要</block>
  <block id="dea416ff04e558b0d76cce896b618880" category="paragraph">この使用例は、アジアの通信空間における Iguazio の顧客をベースにしています。100 万社の企業顧客と年間 125 万件のネットワーク停止イベントに対応しているため、ネットワーク障害による顧客への影響を防止するために、事前に対処する必要がありました。この解決策には、次のような利点があります。</block>
  <block id="feb68271e6d14db0b1ff524f3eb47a27" category="list-text">ネットワーク障害の予測分析</block>
  <block id="70e00676492bea584fb8e7d551515eb5" category="list-text">チケット発行システムとの統合</block>
  <block id="6de8d1444549249c0161228a7b7c1d27" category="list-text">このような Iguazio の実装により、ネットワーク障害を予防するための予防的措置を講じ、障害の 60% を予防しました。</block>
  <block id="fd80dbb606385d62c59605ec96147d3f" category="inline-link-macro">次の手順：セットアップの概要</block>
  <block id="d31627f0c8fea1236773b2420ab9cd39" category="paragraph"><block ref="d31627f0c8fea1236773b2420ab9cd39" category="inline-link-macro-rx"></block></block>
  <block id="8fcbbd73e86fa0b56d72d6127c318c85" category="paragraph">データの急増と機械学習（ ML ）と人工知能（ AI ）の急激な成長により、独自の開発と実装の課題を抱える新たな経済が生まれています。一般に、大量のデータが低コストのデータレイクに保存されます。このデータレイクでは、 GPU などのハイパフォーマンスな AI コンピューティングリソースは効率的にアクセスできません。このレポートでは、データサイエンスの実践者がデータハブを導入し、ワンクリックで、コンピューティングリソースに近い場所にデータセットのキャッシュを作成する新しい解決策を紹介します。その結果、 AI の実践者は、新しいデータセットバージョンハブによって強化されたコラボレーションを活用して、パフォーマンスに優れたモデルトレーニングをより簡単に実施できるようになります。</block>
  <block id="0c8a89e4d7937b03d3adc0f1d6530b08" category="paragraph"><block ref="0c8a89e4d7937b03d3adc0f1d6530b08" category="inline-link-macro-rx"></block></block>
  <block id="321cf11d6ad313e01614cfa7817893fb" category="doc">Jarvis の展開</block>
  <block id="24a0684c018bf0ed5e7001773d8df2c5" category="inline-link">Jarvis Early Access プログラム</block>
  <block id="55ce258288b89404cc493de8c839e20a" category="paragraph">にサインアップできます<block ref="de4a7b23900edb1996cbcb27f4a65904" category="inline-link-rx"></block> NVIDIA GPU Cloud （ NGC ）のジャービスコンテナにアクセスするため。NVIDIA から資格情報を受け取った後、以下の手順を使用して Jarvis を展開できます。</block>
  <block id="e5a6dabbbe3f9144d9f6e72b568893cd" category="list-text">NGC へのサインオン</block>
  <block id="a668e3da095eca41ef93e0c494a6ebad" category="list-text">NGC に組織を設定します :'ea -2- ジャービス '.</block>
  <block id="f3b0315f8d213517a6076eb7aff49cb6" category="list-text">Jarvis EA v0.2 資産の検索 : Jarvis コンテナは「プライベートレジストリ」＞「組織コンテナ」にあります。</block>
  <block id="6db8e9899d42bcac6aeb824da5e952ef" category="list-text">「 Jarvis 」を選択します。「 Model Scripts 」に移動し、「 Jarvis Quick Start 」をクリックします</block>
  <block id="737af365257800065a6412e56d652acc" category="list-text">すべてのアセットが正しく動作していることを確認します。</block>
  <block id="8a5fd124171d01a74b1af73e73ab7761" category="list-text">独自のアプリケーションを構築するためのドキュメントを検索します。 PDF は「 M odel Scripts 」 &gt; 「 Jarvis Documentation 」 &gt; 「ファイルブラウザ」にあります。</block>
  <block id="f3e3b1e7550f6cf9fe883b01695163b7" category="inline-link-macro">次のステップ：リテールのユースケースのステートとフローをカスタマイズします</block>
  <block id="3ae7e712d75bd01d43546679548a28a1" category="paragraph"><block ref="3ae7e712d75bd01d43546679548a28a1" category="inline-link-macro-rx"></block></block>
  <block id="f68b67869778246b8f0d8a98ed043512" category="paragraph">このセクションでは、仮想小売アシスタントの実装について詳しく説明します。</block>
  <block id="02216530e0245f79b0b7448e14bffbce" category="inline-link-macro">次の例は、 Jarvis の導入です</block>
  <block id="a9ca2532d8607b5827969961f314249e" category="paragraph"><block ref="a9ca2532d8607b5827969961f314249e" category="inline-link-macro-rx"></block></block>
  <block id="e7446d382d8184be0a342a2fc45d4394" category="doc">WP-7328 ：『 NetApp Conversational AI Using NVIDIA Jarvis 』</block>
  <block id="5dabc617366db74ce2a9fa3915f6af5a" category="paragraph">ネットアップ、 Rick Huang 、 Sung-Han Lin 、 NVIDIA 、 Davide Onofrio</block>
  <block id="018aacc6ea95e20996bf57b319fd037a" category="paragraph">NVIDIA DGX システムファミリーは、エンタープライズ AI に特化した世界初の人工知能（ AI ）ベースシステムで構成されます。NetApp AFF ストレージシステムは、卓越したパフォーマンスと業界をリードするハイブリッドクラウドデータ管理機能を提供します。ネットアップと NVIDIA は提携を通じて、 NetApp ONTAP AI リファレンスアーキテクチャを構築しました。このリファレンスアーキテクチャは、 AI と機械学習（ ML ）のワークロード向けのターンキー解決策であり、エンタープライズクラスのパフォーマンス、信頼性、サポートを提供します。</block>
  <block id="1a76c739ce37834495a22c5db663d24b" category="paragraph">このホワイトペーパーでは、さまざまな業種のさまざまなユースケースに対応した会話型 AI システムを構築するお客様にガイダンスを提供します。これには、 NVIDIA Jarvis を使用したシステムの導入に関する情報が含まれています。テストは NVIDIA DGX ステーションと NetApp AFF A220 ストレージシステムを使用して実施しました。</block>
  <block id="f813bd56d696cb8de386a53a37eed6f6" category="list-text">AI 開発のためのソリューションを設計するエンタープライズアーキテクト などの会話型 AI のユースケースに適したモデルとソフトウェア バーチャル・リテール・アシスタント</block>
  <block id="0497dfe9ff978e87977c978d3443e206" category="list-text">データサイエンティストは、言語モデリングを効率的に実現する方法を探しています 能力開発の目標</block>
  <block id="e84c345e30f668aa19a041e2e12bc9fe" category="list-text">テキストデータの保守と処理を担当するデータエンジニア お客様からの質問や会話の記録など</block>
  <block id="00101e6b2bf526b1ee79d39389f461fa" category="list-text">エグゼクティブや IT の意思決定者、および関心のあるビジネスリーダー 会話型 AI のエクスペリエンスを変革し、最速の時間を実現できます AI への取り組みから市場に投入</block>
  <block id="88851610d9d91a7b78ab814276bebba7" category="paragraph"><block ref="88851610d9d91a7b78ab814276bebba7" category="inline-link-macro-rx"></block></block>
  <block id="b682eee68510f6de72c9f48b832fba3c" category="inline-link"><block ref="b682eee68510f6de72c9f48b832fba3c" category="inline-link-rx"></block></block>
  <block id="3e5d8230d86c09995fcd8e9ccf335813" category="list-text">Cnvrg.io （<block ref="0691e14f48847a7f13eaf800c0f5813a" category="inline-link-rx"></block>）：</block>
  <block id="6536b07bf755c64528073e655a567c32" category="list-text">Cnvrg コア（無償の ML プラットフォーム）</block>
  <block id="0a16af2994c8e10c6c5976d774430a92" category="paragraph"><block ref="0a16af2994c8e10c6c5976d774430a92" category="inline-link-rx"></block></block>
  <block id="1b21ae34f592a7f2ca92d4a44122475d" category="list-text">Cnvrg のドキュメント</block>
  <block id="0730c44e9dc233c7fce5d95816294f52" category="inline-link"><block ref="0730c44e9dc233c7fce5d95816294f52" category="inline-link-rx"></block></block>
  <block id="f3a2f110576ed38849e70a6bb9794ae8" category="paragraph"><block ref="f3a2f110576ed38849e70a6bb9794ae8" category="inline-link-rx"></block></block>
  <block id="092940c9deac7c0f10a0ed36613c28c2" category="paragraph"><block ref="092940c9deac7c0f10a0ed36613c28c2" category="inline-link-rx"></block></block>
  <block id="492f548658890a1d2495b8af5cebef8c" category="paragraph"><block ref="11ff6f8fb3928ea5c0863401e5e79d17" category="inline-link-rx"></block></block>
  <block id="717108fd0999828c4a6d8290d419733b" category="list-text">NIH 胸部 X 線データセット</block>
  <block id="4eb7427d14327fa86230f324870dc6b8" category="paragraph"><block ref="4eb7427d14327fa86230f324870dc6b8" category="inline-link-rx"></block></block>
  <block id="f249b6ce18772b83efb8a6e58ac09d47" category="list-text">Xiaosong Wang 、 Yifan Peng 、 Le Lu 、 Zhiyong Lu 、 Mohammadhadi Bagheri 、 ロナルド・サマーズ、 ChestX-Ray8 ：『 Hospital scale Chest X-ray Database and Benchmarks on weakly Supervised Classification and Localization of Common Thorax Diseases 、 IEEE CVR 、 pp3462-3471 、 2017TR-4841-0620</block>
  <block id="1e3ecab57c1572b4a25412b1e395562a" category="paragraph">特定のユースケースに合わせてダイアログマネージャーの状態とフローをカスタマイズできます。小売業の例では、次の 4 つの YAML ファイルを使用して、異なるインテントに従って会話を誘導します。</block>
  <block id="608f6d7dfd7bc98630446f0c601cc730" category="paragraph">各ファイルについて、次のファイル名と概要のリストを用意します。</block>
  <block id="77d10e2958e3d21f89adae8647e8d0d2" category="list-text">`main_flow.yml`: 主な会話の流れと状態を定義し、必要に応じて他の 3 つの YAML ファイルにフローを指示します。</block>
  <block id="96b445ea5c6b049dfc1250466b6bdf2e" category="list-text">`retail_flow.yml`: 小売業または関心のある点に関する質問に関連する状態を含みます。システムは最も近い店の情報、または与えられた項目の価格を提供する。</block>
  <block id="17a0ea5055e6be908d7e2f6f983aa471" category="list-text">`weater_flow.yml`: 天気に関する質問に関連する州を含みます。場所を特定できない場合は、フォローアップの質問をして明確にします。</block>
  <block id="ade7d8cc2b23f24add45c4096dd41795" category="list-text">`error_flow.yml`: ユーザのインテントが上記の 3 つの YAML ファイルに入っていないケースを処理します。エラーメッセージを表示した後、システムはユーザーの質問を受け入れるように再経路化します。次のセクションでは、これらの YAML ファイルの詳細な定義を示します。</block>
  <block id="ef7c28f5093b59a07761555c8914df26" category="section-title">main_flow.yml</block>
  <block id="dfc9a806326d590aa4ccf49aa6909cda" category="section-title">retail _flow.yml</block>
  <block id="6e08d9d65c68d5f447f4fd239052c12e" category="section-title">weater_flow.yml</block>
  <block id="b7dc1d2ced2caa9352158983c5ffeda1" category="section-title">ERROR_FLOW.yml</block>
  <block id="c6496825f1a87696b60935af9416283a" category="inline-link-macro">次の手順：サードパーティの API に欠品補充エンジンとして接続します</block>
  <block id="3a9d38bca913120b9d3638cb194cd7e6" category="paragraph"><block ref="3a9d38bca913120b9d3638cb194cd7e6" category="inline-link-macro-rx"></block></block>
  <block id="368c8f521d74a015b7a3e1a46c8847b1" category="paragraph">このセクションでは、 Kubeflow を使用して実行したいさまざまな操作とタスクの例を示します。</block>
  <block id="33204bfa9ee287508f03782fd7ad512e" category="summary">Trident を使用して Kubernetes クラスタ内のストレージリソースを動的にプロビジョニングするには、 Kubernetes StorageClasses を 1 つ以上作成する必要があります。このページの例は、 ONTAP AI ポッドにネットアップ AI コントロールプレーン解決策を導入する場合に作成する、さまざまなタイプのストレージクラスを表しています。</block>
  <block id="d9206a5144976221af82df78ad3d7977" category="paragraph">Trident を使用して Kubernetes クラスタ内のストレージリソースを動的にプロビジョニングするには、 Kubernetes StorageClasses を 1 つ以上作成する必要があります。以下に示す例は、 ONTAP AI ポッドにネットアップ AI コントロールプレーン解決策を導入する場合に作成する、さまざまなタイプのストレージクラスを表しています。StorageClasses の詳細については、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Kubernetes のドキュメント</block>
  <block id="a596fcc71d1c43e3ba86b1557ac7af81" category="paragraph">対応する PersistentVolumeClaim （ PVC ）が削除されたときに永続ボリュームが削除されないようにするため、次の例では「 Retain 」の「 ReclaimPolicy 」の値を使用しています。「 ReclaimPolicy 」フィールドの詳細については、公式を参照してください<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block>。</block>
  <block id="99608a01905f0e69895bbb864a0deba3" category="paragraph">次の例では、 FlexVol 対応の Trident バックエンドが 1 つしか作成されていないため、 StorageClass 定義ファイルで特定のバックエンドが指定されていません。Kubernetes を使用してこの StorageClass を使用するボリュームを管理すると、 Trident は「 ONTAP-NAS' 」ドライバを使用するバックエンドで利用可能なものを使用しようとします。</block>
  <block id="ee1d27a4ae3e30ff30ef72e305b029e7" category="list-text">また、 FlexGroup ボリューム用の汎用の StorageClass を作成することを推奨します。次のコマンド例は、 FlexGroup ボリューム用の汎用の StorageClass を 1 つ作成する方法を示しています。</block>
  <block id="d4a43a35c5d5a5ce3aefe77ceaa73a5c" category="paragraph">特定のバックエンドが StorageClass 定義ファイルで指定されていないことに注意してください。したがって、 Kubernetes を使用してこのストレージクラスを使用するボリュームを管理する場合、 Trident は「 ONTAP-NAS-flexgroup 」ドライバを使用する利用可能なバックエンドを使用しようとします。</block>
  <block id="2732cb29fe3befd83c06e7c220b5456d" category="doc">セクション 4.10 のテストの詳細</block>
  <block id="273936fc522fd7dbe4473de8a0b2a985" category="paragraph">ここでは、のテストについて詳しく説明します <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>。</block>
  <block id="cf46f9264bb33ef7576cf671194a0275" category="paragraph">「 team -a 」、「 team -b 」、「 team -c 」の順にジョブを送信します。</block>
  <block id="fac80c1054e849e1ec88244c017978e7" category="cell">1 個のワークロードをキューに登録</block>
  <block id="eefc99cd833e14811fb22b758cbc62e5" category="cell">2 個のワークロードがキューに登録</block>
  <block id="be46ffa9e65cb964fc3236de02c41e4e" category="paragraph">実行される次のコマンドシーケンスを参照してください。</block>
  <block id="001f9003205f670658ffc60b1e4d62d8" category="cell">2 つのワークロードがそれぞれ 2 つの GPU を必要とします</block>
  <block id="f0f10ddbe8f00433aad17626c8d96a73" category="cell">2 つのワークロードがそれぞれ 2 つの GPU を必要とします</block>
  <block id="f82056dbbe3376b10ac622b0bdaae914" category="cell">8 月 8 日</block>
  <block id="61b8291124bff8ee36a1c799e35395e9" category="paragraph">次に 'team -d のすべてのワークロードを削除します</block>
  <block id="ed9cf33d84548b5953f8b042c72faef4" category="paragraph">を参照してください <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>を参照してください。</block>
  <block id="543cdcd352596e4ad69b4597a2188c02" category="paragraph"><block ref="543cdcd352596e4ad69b4597a2188c02" category="inline-link-macro-rx"></block></block>
  <block id="5b7a8a379330d9d43907b47a6d7ee306" category="doc">Nemo トレーニングを使用してインテントモデルを拡張する</block>
  <block id="a7fbadb37067070a61a3da62b548ba3c" category="paragraph">NVIDIA Nemo は、会話型 AI アプリケーションを作成するために NVIDIA が開発したツールキットです。このツールキットには、 ASR 、 NLP 、 TTS 用のトレーニング済みモジュールのコレクションが含まれています。これにより、研究者やデータサイエンティストは複雑なニューラルネットワークアーキテクチャを簡単に構築し、独自のアプリケーションの設計に集中できるようになります。</block>
  <block id="1a56a4858eeec63d31bc890d38325b84" category="paragraph">前の例で示したように、奈良は限られたタイプの質問しか処理できない。これは、トレーニング済みの NLP モデルでは、これらのタイプの質問についてのみトレーニングを受けているためです。奈良がより幅広い質問に対応できるようにするには、独自のデータセットを使って再トレーニングする必要があります。ここでは、 Nemo を使用して NLP モデルを拡張し、要件を満たす方法を示します。まず、奈良から収集したログを Nemo の形式に変換し、 NLP モデルを強化するためのデータセットを使って学習します。</block>
  <block id="4e19d1e300ea3cd63472939c24caf65d" category="paragraph">私たちの目標は、ユーザーの好みに基づいてアイテムを並べ替えることです。たとえば、奈良に最高級の寿司レストランを提案したり、奈良に最も安い価格のジーンズを探してもらうようにしたりすることができます。このためには、 Nemo で提供されているインテント検出とスロット充填モデルをトレーニングモデルとして使用します。このモデルにより、奈良は検索の好みを理解することができる。</block>
  <block id="5cb83e5ef3cd25eb53fa55d635a7758f" category="section-title">データの準備</block>
  <block id="807cace7b07fcded06b9d106c4dd4d2d" category="paragraph">モデルをトレーニングするには、このタイプの質問のデータセットを収集し、 Nemo 形式に変換します。ここでは、モデルのトレーニングに使用するファイルをリストしました。</block>
  <block id="dc1d3747ed1059f234cbe4a104700abd" category="section-title">dict.intents.csv</block>
  <block id="e803005a5c3a99889733e9c8e8bba406" category="paragraph">このファイルには、 Nemo に理解してもらいたいすべてのインテントが一覧表示されます。ここでは、主なインテントが 2 つあり、 1 つのインテントは、主なインテントのどれにも当てはまらない質問を分類するために使用されます。</block>
  <block id="ce2440c5074ba6a1e30fa2ec906dafb4" category="section-title">dict.slots.csv</block>
  <block id="a3fc542c51797c85b30365ba9b2d12c5" category="paragraph">このファイルには、トレーニングの質問にラベルを付けることができるすべてのスロットが記載されています。</block>
  <block id="795cab38744084526a62914e47789fbe" category="section-title">鉄道 .tsv</block>
  <block id="8a5ae45ea3762f79d1a520bcf61275d5" category="paragraph">これが主なトレーニングデータセットです。各行は、 dict.intent.csv ファイルのインテントカテゴリのリストに続く質問から始まります。ラベルはゼロから列挙されます。</block>
  <block id="db487d8daea13e36203f660d46b3cdfc" category="section-title">train slots.tsv</block>
  <block id="73ade6fc5004174d2abe822c85cdfbef" category="section-title">モデルのトレーニング</block>
  <block id="c764142480a5daa39ac98125503352e8" category="paragraph">次に、次のコマンドを使用してコンテナを起動します。このコマンドでは、軽量なトレーニング用の演習であるため、コンテナで使用する GPU は 1 つに制限されます（ GPU ID = 1 ）。また、ローカルワークスペース / ワークスペース /Nemo/ をコンテナ /Nemo 内のフォルダにマッピングします。</block>
  <block id="a712c52af847db1e143ca43fdd44bd39" category="paragraph">コンテナ内では、事前にトレーニングされたオリジナルの BERT モデルから開始する場合、次のコマンドを使用してトレーニング手順を開始できます。data_dir は、トレーニングデータのパスを設定する引数です。work_dir では ' チェックポイント・ファイルを保存する場所を設定できます</block>
  <block id="9e654b2215e90d20951b3ddd67a15bc6" category="paragraph">新しいトレーニングデータセットがあり、以前のモデルを改善したい場合は、次のコマンドを使用して停止した時点から続行できます。checkpoint_dir は ' 前のチェックポイント・フォルダへのパスを取得します</block>
  <block id="87eea49f703666c49da2d7987ba093b2" category="section-title">モデルを推論します</block>
  <block id="484c4e9e4a0a20bf41551f65663fa9d2" category="paragraph">トレーニング済みモデルのパフォーマンスは、一定の期間の経過後に検証する必要があります。次のコマンドを使用すると、 1 つずつクエリをテストできます。たとえば、このコマンドでは、モデルがクエリの意図を正しく識別できるかどうかを確認します。クエリの目的は、「ここで最高のパスタを取得できる」です。</block>
  <block id="de558a28e6333ac9f453a42631f44c12" category="paragraph">次に、推論からの出力を示します。出力では、トレーニング済みモデルが意図を正しく予測し、関心のあるキーワードを返すことができます。これらのキーワードを使うことで、奈良はユーザが欲しいものを検索し、より正確な検索を行うことができるようになります。</block>
  <block id="5b7f09a1d5da38512130330f4d38fd32" category="paragraph"><block ref="5b7f09a1d5da38512130330f4d38fd32" category="inline-link-macro-rx"></block></block>
  <block id="84860cc77161e23e44eccd05430c00ea" category="doc">実行中のジョブの送信： AI CLI</block>
  <block id="68c9d249f35c91dfcc4a11e209ccbdba" category="paragraph">このセクションでは、 Kubernetes ジョブの実行に使用できる基本的な Run ： AI コマンドについて詳しく説明します。ワークロードの種類に応じて 3 つの要素に分割されます。AI / ML / DL のワークロードは、次の 2 つの汎用タイプに分けることができます。</block>
  <block id="754edd5bae16b4a2ed8e6673821d3339" category="list-text">* 無人トレーニングセッション * 。このようなタイプのワークロードを扱うことで、データサイエンティストは自己実行ワークロードを準備し、実行のためにワークロードを送信します。実行中に、お客様は結果を確認できます。このタイプのワークロードは、多くの場合、本番環境で使用されます。また、モデル開発が段階で行われるため、手動操作は必要ありません。</block>
  <block id="fdfda155b7c1021ae5e73d2ab01c0129" category="list-text">* インタラクティブビルドセッション * 。このようなワークロードの場合、データサイエンティストは Bash 、 Jupyter Notebook 、リモート PyCharm などの IDE を使用した対話型セッションを開始し、 GPU リソースに直接アクセスします。次に、対話型のワークロードを実行してポートを接続し、コンテナユーザに内部ポートを表示するシナリオを紹介します。</block>
  <block id="6ec08732676824c58d76b0ecdc2aed24" category="section-title">無人トレーニングのワークロード</block>
  <block id="18cb2734d0533ff093ddcb1b3005e216" category="paragraph">プロジェクトをセットアップして GPU を割り当てたら、コマンドラインで次のコマンドを使用して Kubernetes のワークロードを実行できます。</block>
  <block id="68e667063c4711033bbf6b7f8b312e1f" category="paragraph">このコマンドは、単一の GPU を割り当てたチーム A の無人トレーニングジョブを開始します。このジョブは、サンプルの Docker イメージである「 gcr.io/run-ai-demo/QuickStart 」に基づいています。私たちはジョブ「 hyper1 」と名付けました。その後、次のコマンドを実行して、ジョブの進捗状況を監視します。</block>
  <block id="cbae10285b6d282e740369a59fd25aaf" category="paragraph">次の図に 'runai list' コマンドの結果を示します一般的なステータスは次のとおりです。</block>
  <block id="e749e4e3bf7ed6d5368f336ba6ceeead" category="list-text">「 ContainerCreating 」を参照してください。Docker コンテナをクラウドリポジトリからダウンロードしています。</block>
  <block id="f5231f23820da3ad520bb16a9dfe97a7" category="list-text">「保留中」。ジョブはスケジュールされるのを待っています。</block>
  <block id="411497b40a902afd2813d3c7af137ffb" category="list-text">「ランニング」。ジョブが実行中です。</block>
  <block id="c0801feb8216aa6b36a769e14c3bc138" category="paragraph"><block ref="c0801feb8216aa6b36a769e14c3bc138" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4f5f0c8fb5ec5bccf18cfd167b1d3bc5" category="paragraph">ジョブのステータスをさらに表示するには、次のコマンドを実行します。</block>
  <block id="db0b192c9c9b9885b435e466b9ac861c" category="paragraph">ジョブのログを表示するには、「 runai logs &lt;job-name&gt; 」コマンドを実行します。</block>
  <block id="280782f59c990a941b600c998427a52c" category="paragraph">この例では、現在のトレーニングエポック、 ETA 、損失関数値、精度、および各ステップの経過時間を含む、実行中の DL セッションのログを確認する必要があります。</block>
  <block id="848ad760ae00e3eca33445cd09cfdf34" category="paragraph">クラスタのステータスは、 Run ： AI UI で確認できます から<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>。[ ダッシュボード ]&gt;[ 概要 ] で、 GPU 利用率を監視できます。</block>
  <block id="f899123d07ffe99c3d97952ae96017ed" category="paragraph">このワークロードを停止するには、次のコマンドを実行します。</block>
  <block id="1f979b6140776c287d458036805ad8aa" category="inline-link">無人トレーニングワークロードの開始</block>
  <block id="637552715214e8c0c87022bac459e824" category="paragraph">このコマンドを実行すると、トレーニングワークロードが停止します。このアクションを確認するには 'runai list' をもう一度実行します詳細については、を参照してください<block ref="e5fbbc266c1fd3a9a029581f5747622d" category="inline-link-rx"></block>。</block>
  <block id="7afece97948db40e546138d81dd343e1" category="section-title">ワークロードを対話型に構築</block>
  <block id="30330792601ba24e9ad5f4f5ee0d5151" category="paragraph">プロジェクトをセットアップして GPU を割り当てたら、コマンドラインで次のコマンドを使用して対話型ビルドワークロードを実行できます。</block>
  <block id="ca57038d87e3f48eb98329e6fd449824" category="paragraph">このジョブは、サンプルの Docker イメージ Python に基づいています。ジョブ build1 という名前を付けました。</block>
  <block id="39fd96ce47a2aa757eb5cc98cd910730" category="admonition">「 --interactive 」フラグは、ジョブが開始または終了していないことを意味します研究者の責任で業務を終了してください。管理者は、対話型ジョブがシステムによって終了されるまでの時間制限を定義できます。</block>
  <block id="d39d9c693980c2af510d4a58be6f2620" category="paragraph">--g 1' フラグは ' このジョブに 1 つの GPU を割り当てます与えられたコマンドと引数は、「 --command sleep -- args インフィニティ」です。コマンドを指定するか、コンテナを開始してすぐに終了する必要があります。</block>
  <block id="aedc6bf8e3cb52af4a660584c69353ca" category="paragraph">次のコマンドは、で説明したコマンドと同様に機能します <block ref="a09c3ced87a580a4004dfa2429aba9c7" category="inline-xref-macro-rx"></block>：</block>
  <block id="1d2bac5ee25c12c0ee793df98c1b4d49" category="list-text">runai list` ：名前、ステータス、経過時間、ノード、イメージ、 プロジェクト、ユーザ、 GPU によるジョブの処理</block>
  <block id="6b5b5fdb13c8b8af02a41b296af91a2e" category="list-text">runai get build1`: ジョブ build1 の追加ステータスを表示します。</block>
  <block id="9c1e129aa488b11d05275f016f42dda5" category="list-text">runai delete build1`: 対話型のワークロード build1 を停止しますコンテナに bash シェルを取得するには ' 次のコマンドを実行します</block>
  <block id="ac97b61bdc50cfc22ffd507de190d00c" category="paragraph">これにより、コンピュータにシェルが直接挿入されます。データサイエンティストは、コンテナ内でモデルを開発または微調整できます。</block>
  <block id="5051a9eb1fad38f876a260ba0a4850af" category="inline-link"><block ref="5051a9eb1fad38f876a260ba0a4850af" category="inline-link-rx"></block></block>
  <block id="c7fdd5fcf033fb9395c27ecbf2e54fc9" category="inline-link">対話型ビルドワークロードの開始と使用</block>
  <block id="ff53dc42327d97c7410a6ac241222ffe" category="paragraph">クラスタのステータスは、 Run ： AI UI で確認できます から<block ref="29f2b88109b12c4db8e875d3f5ba7aae" category="inline-link-rx"></block>。詳細については、を参照してください<block ref="f3d6ab8050b43c83f452779c7622ab1d" category="inline-link-rx"></block>。</block>
  <block id="1028c65994f7201e0f43b3bf5d3c6b41" category="section-title">ポートが接続された対話型のワークロード</block>
  <block id="7d05c708b92b4809bfe9bf66edf8f765" category="inline-link">入力</block>
  <block id="34274fcc13408f06acfe43c4065c3f3b" category="paragraph">Run ： AI CLI でコンテナを開始する際に、対話型ビルドワークロードを拡張することで、コンテナユーザに内部ポートを公開できます。これは、クラウド環境、 Jupyter Notebook の操作、その他のマイクロサービスへの接続に役立ちます。<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> Kubernetes クラスタの外部から Kubernetes サービスへのアクセスを許可します。アクセスを設定するには、どのインバウンド接続がどのサービスに到達するかを定義する一連のルールを作成します。</block>
  <block id="e7f72a2c9a0cb7337eb00a3093f846da" category="paragraph">クラスタ内のサービスへの外部アクセスを適切に管理するには、クラスタ管理者がインストールすることを推奨します<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> ロードバランサを設定します。</block>
  <block id="16d79943625573d5b80809fe2a7ddbdd" category="paragraph">入力をサービスタイプとして使用するには、次のコマンドを実行して、ワークロード送信時にメソッドタイプとポートを設定します。</block>
  <block id="79fcc0299f1a85ebab053926e2222bca" category="paragraph">コンテナが正常に起動したら、「 runai list 」を実行して、 Jupyter Notebook にアクセスする「サービス URL (S) 」を確認します。URL は、入力エンドポイント、ジョブ名、およびポートで構成されます。たとえば、を参照してください<block ref="0309fbe8f364c8f6dfe6f383da8c46c2" category="inline-link-rx"></block>。</block>
  <block id="451b08ed1bf6f7f0a8931cff52c4c45e" category="inline-link">ポートが接続されている対話型のビルドワークロードを起動する</block>
  <block id="b524842923f8cb1e38064fadc680893f" category="paragraph">詳細については、を参照してください<block ref="414875add8a18a03ddddfb14fb1c47f4" category="inline-link-rx"></block>。</block>
  <block id="5bb97c2dd089da990a792356c72a6128" category="inline-link-macro">次は、高いクラスタ利用率を達成することです</block>
  <block id="8f87de13e6ff3dd2fc164bdb930759bb" category="paragraph"><block ref="8f87de13e6ff3dd2fc164bdb930759bb" category="inline-link-macro-rx"></block></block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">ネットアップ、 Mike Oglesby</block>
  <block id="9f1cc947f3e0236f8d5bc32d8d33509a" category="inline-link">cloud.netapp.com</block>
  <block id="1f39acb56ba2a8669371819a64348c74" category="paragraph"><block ref="1f39acb56ba2a8669371819a64348c74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed8e4613850a4014b0e6ef830982caf2" category="paragraph">ここでは、のテストについて詳しく説明します <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>。</block>
  <block id="17b3673d5c28fb72e7cc48549f489dd4" category="cell">6 月 8 日</block>
  <block id="ffe090618e54b7916fa47cf8881019b1" category="cell">team -b/c ワークロードが一時停止し、「 pending 」に移動します。</block>
  <block id="bccfe4ac65004fb31c146d17003d00e8" category="cell">他のチーム (b/c) のワークロードは一時停止し、「保留中」に移動します。</block>
  <block id="3b099141b6a7e4e8804c3fda5ed4f440" category="paragraph">を参照してください <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="5d52789e4f8028aca21d5650bed8273b" category="inline-link-macro">次のセクション 4.10 のテストの詳細</block>
  <block id="61a1556247485f1d0fbb34dbe36d1503" category="paragraph"><block ref="61a1556247485f1d0fbb34dbe36d1503" category="inline-link-macro-rx"></block></block>
  <block id="aa364e0963e38930007df2b60bdba067" category="doc">Trident でプロビジョニングされた永続的ボリュームにデータを保存する</block>
  <block id="ef1fb51957f2aa894de5476a9a0112a2" category="paragraph">NetApp Trident は、コンテナ化されたアプリケーションが求める高度な永続性のニーズに対応できるように設計された、完全にサポートされているオープンソースプロジェクトです。Trident でプロビジョニングされた Kubernetes PersistentVolume （ PV ）に対してデータの読み取りと書き込みを行うことができ、データ階層化、暗号化、 NetApp Snapshot テクノロジ、コンプライアンス、 NetApp ONTAP データ管理ソフトウェアが提供する高パフォーマンスといったメリットも活用できます。</block>
  <block id="a821f368daf439d909bfed3c8e95d4b9" category="section-title">既存の名前空間での PVC の再利用</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link">NetApp Trident のドキュメント</block>
  <block id="15040fc521e7fa5e8ef42694ca89e53d" category="paragraph">大規模な AI プロジェクトでは、異なるコンテナで同じ Kubernetes PV に対してデータの読み取りや書き込みを行う方が効率的な場合があります。Kubernetes Persistent Volume Claim （ PVC ；永続ボリューム要求）を再利用するには、ユーザが PVC を作成しておく必要があります。を参照してください<block ref="5b6274adc29653ed1820027957bdb4e2" category="inline-link-rx"></block> PVC 作成の詳細については、を参照してください。次に、既存の PVC を再利用する例を示します。</block>
  <block id="743520c366f0d11ca817811dda85fcf1" category="paragraph">次のコマンドを実行して ' プロジェクト 'team -a' のジョブ pvc-test' のステータスを表示します</block>
  <block id="7d4c508442c775f946e3d9318b75b1a0" category="paragraph">'team -a' ジョブ 'pvctest' にマウントされた PV /tmp/pvc1mount が表示されますこのようにして、複数のコンテナが同じボリュームから読み取ることができるため、開発中または本番環境で競合する複数のモデルが存在する場合に便利です。データサイエンティストは、モデルのアンサンブルを構築し、大多数の投票またはその他の技術によって予測結果を組み合わせることができます。</block>
  <block id="dae81aa45b8ce281aabbd1402afe277b" category="paragraph">次のコマンドを使用してコンテナシェルにアクセスします。</block>
  <block id="bc63da8fa87210da818596598e359427" category="paragraph">その後、マウントされたボリュームを確認し、コンテナ内のデータにアクセスできます。</block>
  <block id="fc180b17e3fccb2beb46854f71d31406" category="paragraph">PVC の再利用というこの機能は、 NetApp FlexVol ボリュームと NetApp ONTAP FlexGroup ボリュームと連携します。そのため、データエンジニアは、より柔軟で堅牢なデータ管理オプションを利用して、ネットアップのデータファブリックを活用できます。</block>
  <block id="2e203cb5454e63a32bcdb87dc9cb77ad" category="paragraph"><block ref="2e203cb5454e63a32bcdb87dc9cb77ad" category="inline-link-macro-rx"></block></block>
  <block id="52c7321ea4e3d5b264fdc8639a65e280" category="doc">Grafana ダッシュボードを導入します</block>
  <block id="c843fc0ceca9c58b409cab519799c125" category="paragraph">すべてのデータを導入したら、新しいデータに対して推論を実行します。このモデルは、ネットワークデバイス機器の障害を予測します。予測の結果は、 Iguazio 時系列テーブルに格納されます。Iguazio のセキュリティおよびデータアクセスポリシーと統合されたプラットフォームで、 Grafana を使用して結果を表示できます。</block>
  <block id="ae93e86067cc1d0e7bb1ec8fdca6fbc3" category="paragraph">ダッシュボードを導入するには、指定した JSON ファイルをクラスタ内の Grafana インターフェイスにインポートします。</block>
  <block id="213977705fe35a4cb0cfc9365088fc87" category="list-text">Grafana サービスが実行されていることを確認するには、 Services の下を参照してください。</block>
  <block id="b426c25dbb35de6b9c6bff0b10b8bef9" category="paragraph"><block ref="b426c25dbb35de6b9c6bff0b10b8bef9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b6e0cc0a098260878a0e8fa4eb7766" category="list-text">インスタンスが存在しない場合は、 [ サービス ] セクションからインスタンスを展開します。</block>
  <block id="cd40a7a2e0a86f4a0283af5999a050db" category="list-text">[ 新しいサービス ] をクリックします。</block>
  <block id="59c4bcb990174489660974167376a50a" category="list-text">リストから Grafana を選択します。</block>
  <block id="7e280ecf88737f34a1972ac94f9ae2a1" category="list-text">デフォルトを受け入れます。</block>
  <block id="9e47b36567e5001dea59ffee81456737" category="list-text">次のステップをクリックします。</block>
  <block id="4fa350b43dd079673b6fca4852841147" category="list-text">ユーザ ID を入力します。</block>
  <block id="af81385be6cef15b54f8c8c126c0eab0" category="list-text">[ サービスの保存 ] をクリックします</block>
  <block id="568c8b6f668936384414e470f9ddd939" category="list-text">上部の [Apply Changes] をクリックします。</block>
  <block id="b5be50b376063d6c3ffaa3be10d4a9d3" category="list-text">ダッシュボードを展開するには、 Jupyter インターフェイスから「 NetopsPredictions - Dashboard.json 」ファイルをダウンロードします。</block>
  <block id="587b311a501585c3a1d9260d4f147990" category="paragraph"><block ref="587b311a501585c3a1d9260d4f147990" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ad16c6527a3abd13b6864b8b078586b" category="list-text">Services セクションで Grafana を開き、ダッシュボードをインポートします。</block>
  <block id="0b78dd574d02d72071845d040fdde57c" category="paragraph"><block ref="0b78dd574d02d72071845d040fdde57c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3ce0bca8ff75db7ff2bbc3e76532b2" category="list-text">Upload `*.json ’ File をクリックして、以前にダウンロードしたファイル (`NetopsPredictions - Dashboard.json ') を選択します。アップロードが完了すると、ダッシュボードが表示されます。</block>
  <block id="7cd4d06091771aa3f16d2759a067e18c" category="paragraph"><block ref="7cd4d06091771aa3f16d2759a067e18c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0258dc4515b0e18ecd4b55651e27671" category="section-title">デプロイクリーンアップ機能</block>
  <block id="ff4bdefb3ddd7532393d08c8df14d786" category="paragraph">大量のデータを生成する場合は、すべてをクリーンで整理することが重要です。これを行うには 'cleanup.ipynb' ノートブックを使用してクリーンアップ機能を配備します</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="section-title">利点</block>
  <block id="6d0f7ccc9b17bcabb743cabdfb56e0da" category="paragraph">ネットアップと Iguazio は、 Kubeflow 、 Apache Spark 、 TensorFlow などの必須フレームワークや、 Docker や Kubernetes などのオーケストレーションツールを構築することで、 AI アプリケーションや ML アプリケーションの導入を迅速化し、簡易化します。ネットアップと Iguazio は、エンドツーエンドのデータパイプラインを統合することで、多くの高度なコンピューティングワークロードに固有のレイテンシと複雑さを軽減し、開発と運用のギャップを効果的に解消します。データサイエンティストは、大規模なデータセットに対してクエリを実行し、トレーニングフェーズ中にデータやアルゴリズムのモデルを権限のあるユーザと安全に共有できます。コンテナ化されたモデルを本番環境で使用できるようになったら、開発環境から運用環境に簡単に移行できます。</block>
  <block id="daee7e425c63dff416cde0a8932a8483" category="paragraph"><block ref="daee7e425c63dff416cde0a8932a8483" category="inline-link-macro-rx"></block></block>
  <block id="612edeb05f6d237e20f3d843d6e7eba4" category="paragraph">以下のセクションでは、この検証で実行した AI のインストール、テストシナリオ、結果について詳しく説明します。</block>
  <block id="2df14da3d7db15550e8eafc892e89d8e" category="paragraph">TensorFlow ベンチマークを含む業界標準のベンチマークツールを使用して、このシステムの動作とパフォーマンスを検証しました。ImageNet データセットを使用して ResNet-50 をトレーニングしました。これは、画像分類のための有名な Convolutional Neural Network （ CNN ；畳み込みニューラルネットワーク） DL モデルです。ResNet-50 は、処理時間を短縮して正確なトレーニング結果を提供します。これにより、ストレージに対する十分な需要を喚起することができました。</block>
  <block id="a89cd2a9c8244dab756ec04aeb8247e9" category="inline-link-macro">次の手順： AI インストールを実行します</block>
  <block id="13bb3aa52565b3e3f517764c0e88c324" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block>。</block>
  <block id="afee48a46dd68b9618cec81a8ee5ba86" category="paragraph">このセクションでは、 ONTAP AI 解決策のテクノロジ要件について説明します。</block>
  <block id="e96b7604f8b75ae786c6c0e1016e46fd" category="inline-link">ONTAP AI Web サイト</block>
  <block id="929f5f13d86d1be55b96dba26e773c6f" category="paragraph">ハードウェア要件はお客様のワークロードによって異なりますが、 ONTAP AI は、大規模な ML/DL 運用向けに、単一の GPU からラックスケール構成まで、あらゆる規模のデータエンジニアリング、モデルトレーニング、本番環境推論に導入できます。ONTAP AI の詳細については、を参照してください<block ref="7ec9b089c41da1b986bad97e1099df1c" category="inline-link-rx"></block>。</block>
  <block id="41e840b508d9e839f95d16dd582af8d6" category="paragraph">この解決策は、コンピューティングには DGX-1 システム、ネットワーク接続には NetApp AFF A800 ストレージシステム、 Cisco Nexus 3232C を使用して検証しました。この検証で使用される AFF A800 は、ほとんどの ML/DL ワークロードで最大 10 台の DGX-1 システムをサポートできます。次の図に、この検証でモデルのトレーニングに使用する ONTAP AI トポロジを示します。</block>
  <block id="bc2eb92d1e1797a759b677c38f619a8f" category="paragraph"><block ref="bc2eb92d1e1797a759b677c38f619a8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d98e5c43e7b3be89fe8a9076f89f1e99" category="paragraph">この解決策をパブリッククラウドに拡張するために、 Cloud Volumes ONTAP をクラウド GPU コンピューティングリソースと一緒に導入し、ハイブリッドクラウドデータファブリックに統合することで、お客様は特定のワークロードに適したリソースを自由に使用できます。</block>
  <block id="4dc70b997a39a64b2def3ef74a96fdb4" category="paragraph">次の表に、この解決策検証で使用されるソフトウェアのバージョンを示します。</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">コンポーネント</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="d173e10eb6a0fc7969fe540c987e0c7d" category="cell">18.04.4 LTS</block>
  <block id="9b4bffa460105781f82b1d463bde8200" category="cell">4.4.0</block>
  <block id="3c1d47ba5c1ada327abd4532ff9f4437" category="cell">20.02.1</block>
  <block id="0083e57a258edd18b949d3afbf6cfc2a" category="cell">1.15</block>
  <block id="152090ff5e9a05ea7e1cf0c248449638" category="cell">Helm</block>
  <block id="232de5556d4148d75b55012e1230616c" category="cell">3.1.0</block>
  <block id="e5e8ab661917b89b4161959c7dc28442" category="cell">cnvrg.io</block>
  <block id="272f0a04b740763e0a29316bc4af89a4" category="cell">3.0.0</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="cell">NetApp ONTAP</block>
  <block id="d8a31094f88724af6834c47a6697dc56" category="cell">9.6P4</block>
  <block id="9909115a4f9fe32731077286c367501c" category="paragraph">この解決策検証では、 Kubernetes を DGX-1 システム上にシングルノードクラスタとして導入しました。大規模な導入の場合は、管理サービスの高可用性を実現し、 ML ワークロードと DL ワークロードに貴重な DGX リソースを確保するために、独立した Kubernetes マスターノードを導入する必要があります。</block>
  <block id="1c428dd76324aae91879799ae73fbc37" category="inline-link-macro">次のステップ：解決策の導入と検証の詳細</block>
  <block id="5e5761a91dc25c881f4ca86678634b1b" category="paragraph"><block ref="5e5761a91dc25c881f4ca86678634b1b" category="inline-link-macro-rx"></block></block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">追加情報</block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">ネットアップの製品マニュアル</block>
  <block id="7661400c51b9fc184bdec46eb5577ff9" category="doc">GitHub からコードを取得します</block>
  <block id="1a3652d661d6b73b6aa57aff1fa5e4d4" category="paragraph">これで、 Iguazio クラスタおよび開発者環境で NetApp Cloud Volume または NetApp Trident ボリュームを使用できるようになりました。アプリケーションの確認を開始できます。</block>
  <block id="ae53ae826cc9a587fbaee0e834dd75ca" category="paragraph">ユーザは独自のワークスペース（ディレクトリ）を持ちます。すべてのノートブックで ' ユーザー・ディレクトリへのパスは '/User' ですIguazio プラットフォームは、ディレクトリを管理します。上記の手順に従った場合、 NetApp Cloud ボリュームは「 /NetApp 」ディレクトリにあります。</block>
  <block id="754e85a9ea7f4fbb718080a73790abdb" category="paragraph">Jupyter 端子を使用して GitHub からコードを取得します。</block>
  <block id="1d706cc291efb1d79274befd6f9dd64c" category="paragraph"><block ref="1d706cc291efb1d79274befd6f9dd64c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12d0e4b8ba8db4e6a7aa1dda942a1ed4" category="paragraph">Jupyter ターミナルのプロンプトで、プロジェクトのクローンを作成します。</block>
  <block id="d4095d9e0ab52b6d683ace00b5cbea55" category="paragraph">Jupyter ワークスペースのファイルツリーには、「 NetOps - NetApp 」フォルダが表示されます。</block>
  <block id="f8161ff446bbd6f76b0d99d6f34a1d7f" category="inline-link-macro">次の手順：作業環境を構成します</block>
  <block id="48dd929a2f5f248856ce2768950aff4e" category="paragraph"><block ref="48dd929a2f5f248856ce2768950aff4e" category="inline-link-macro-rx"></block></block>
  <block id="2e52c56d063752bbfeda9c8f9d2fee41" category="summary">このページでは、 Kubernetes クラスタに NetApp Trident をインストールして設定するために必要な作業について説明します。</block>
  <block id="e539ec743b02403b5ba74b884d117a5a" category="paragraph">このセクションでは、 Kubernetes クラスタに NetApp Trident をインストールして設定するために必要な作業について説明します。</block>
  <block id="b8b9eab8c1ed7b79387652490f5724ec" category="section-title">Trident をインストール</block>
  <block id="984b69562391cb8032fd50ded03a29a6" category="paragraph">Kubernetes クラスタに NetApp Trident をインストールして設定するには、導入ジャンプホストから次のタスクを実行します。</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">導入手順</block>
  <block id="f12aad36b1ab9194dd8bc67542366bff" category="doc">NVIDIA DeepOps を使用して Kubeflow を導入します</block>
  <block id="3e1922d78dd7bdb1e8d7e7bd8f5aa92c" category="paragraph">NVIDIA DeepOps が提供する Kubeflow 導入ツールを使用することを推奨します。DeepOps 導入ツールを使用して Kubernetes クラスタに Kubeflow を導入するには、導入ジャンプホストから次のタスクを実行します。</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">インストール手順</block>
  <block id="3ede8bc1f55c95b9a16b2429e0b9bbcc" category="admonition">または、を使用して手動で Kubeflow を導入することもできます<block ref="c75d7e23bc80ca81cea11fe427173cb3" category="inline-link-rx"></block> Kubeflow の公式ドキュメントにあります</block>
  <block id="a73d6d865f72179145299c720c53d39c" category="inline-link">Kubeflow の導入手順</block>
  <block id="2efdbab31c5d41a149e5092f4b8d7e48" category="list-text">Kubeflow Dashboard URL をメモしてください。 DeepOps Kubeflow 導入ツールによって出力されます。</block>
  <block id="d6049afd6b1943d1e98ca6347dd907c5" category="list-text">Web ブラウザで、手順 2 でメモした URL に移動して Kubeflow 中央ダッシュボードにアクセスします。</block>
  <block id="2d84920115f9dc91fe2d35c4dc07eaf0" category="paragraph"><block ref="2d84920115f9dc91fe2d35c4dc07eaf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13e8f52d7e19f83d3e64003c58ea220b" category="doc">NDE を使用して NetApp HCI に VMware 仮想インフラストラクチャを導入する （導入の自動化）</block>
  <block id="2635318d9bf1ea76c73bfab7f3eeafb7" category="section-title">NDE 導入の前提条件</block>
  <block id="f6ec2c1aa5118cb19e89af5a10ecb65c" category="inline-link">NetApp HCI 前提条件チェックリスト</block>
  <block id="2187fc20798cda55150d8c067fac10be" category="paragraph">を参照してください<block ref="c760383d1767df51ab118e6ffc289894" category="inline-link-rx"></block> 導入を開始する前に、 NetApp HCI の要件と推奨事項を確認してください。</block>
  <block id="cd02d0868a7414dd1e76924b30b82b52" category="list-text">ネットワークおよびスイッチの要件と構成</block>
  <block id="1d8b6c167080876dff9ad2e74e70fecf" category="list-text">必要な VLAN ID を準備します</block>
  <block id="17cec09f14c225b5f27dc73542e9077a" category="list-text">スイッチの設定</block>
  <block id="4d40082ed807aa2fb7e1d2f03921e4d4" category="list-text">NetApp HCI および VMware の IP アドレス要件</block>
  <block id="2e8e4792043f43cb4b34a84b8dcd909b" category="list-text">DNS と時間管理の要件</block>
  <block id="829710d6ec2a8e59e7a69fb3537ec494" category="list-text">最終準備</block>
  <block id="fb720b4ad7c03710e0e5771c9fb58b44" category="section-title">NDE 実行</block>
  <block id="cf50c81e30d1d64fcb4992a9792abedb" category="paragraph">NDE を実行する前に、すべてのコンポーネントのラックとスタック、ネットワークスイッチの設定、およびすべての前提条件の確認を完了しておく必要があります。NDE ですべてのアドレスを自動的に設定できるようにする場合は、 1 つのストレージノードの管理アドレスに接続して NDE を実行できます。</block>
  <block id="130c61c344b6fbf262b6f63818eab7e4" category="paragraph">NDE は、 HCI システムをオンラインにするために次のタスクを実行します。</block>
  <block id="d89f68a2ec388fe5d72fb6fe024a0176" category="list-text">少なくとも 2 つのストレージノードにストレージノード（ NetApp Element ソフトウェア）をインストールします。</block>
  <block id="f6f86c1086573c7daeb1f48535041576" category="list-text">VMware ハイパーバイザーを少なくとも 2 つのコンピューティングノードにインストールします。</block>
  <block id="0718265bec3e2ee6fc9d5e0773b5ff60" category="list-text">NetApp HCI スタック全体を管理するために VMware vCenter をインストールします。</block>
  <block id="e09575b9713329ebe2480dbf404b2b1b" category="list-text">ネットアップストレージ管理ノード（ mNode ）と NetApp Monitoring Agent をインストールして設定します。</block>
  <block id="dddc28f734d0bcb367638f51ef8b4dfa" category="admonition">この検証では、 NDE を使用してすべてのアドレスが自動的に設定されます。環境で DHCP を設定したり、ストレージノードとコンピューティングノードごとに IP アドレスを手動で割り当てたりすることもできます。これらの手順については、このガイドでは説明していません。</block>
  <block id="dd9cd526f5753b79bda6de19f1a66fe9" category="paragraph">前述したように、この検証ではコンピューティングノードにケーブルを 2 本使用する構成を使用します。</block>
  <block id="32691d86c49e682187776e0262b732d7" category="paragraph">NDE の詳細な手順については、このドキュメントでは説明していません。</block>
  <block id="968a3687be335c74374e73712c63e2e4" category="inline-link">導入ガイド</block>
  <block id="8b6e1a3a9d21ff63520793416432cd56" category="paragraph">基本の NetApp HCI プラットフォームの導入を完了するための詳細な手順については、を参照してください<block ref="7742239770a3accee30f01673a1a43a5" category="inline-link-rx"></block>。</block>
  <block id="61ef02ded53524d506cd714c5821cd86" category="list-text">NDE が終了したら、 vCenter にログインし、 NetApp HCI およびアプリケーションで使用する NFS ネットワーク用の分散ポートグループ「 ONTAP Select VDS 01-NFS_Network 」を作成します。</block>
  <block id="9fb27fdce8d8c70b2c7b741958c8ac6e" category="inline-link-macro">次： NetApp H615c の設定（手動導入）</block>
  <block id="6623698128b1c14d8639f2404306f783" category="paragraph"><block ref="6623698128b1c14d8639f2404306f783" category="inline-link-macro-rx"></block></block>
  <block id="bd9091c7320e4b1069eed28f04839354" category="paragraph">独自の AI / ML パイプラインを構築する場合、アーキテクチャ内のコンポーネントの統合、管理、セキュリティ、およびアクセス性の設定は困難な作業です。開発者に環境へのアクセスと管理を許可することには、もう 1 つの課題があります。</block>
  <block id="820423ca1ad0e872ef04cbb366b6e3de" category="paragraph">ネットアップと Iguazio を組み合わせることで、これらのテクノロジをマネージドサービスとして統合し、テクノロジの採用を促進し、新しい AI / ML アプリケーションの市場投入期間を短縮できます。</block>
  <block id="b0a9c7dc36cb18f93679b833533b9936" category="paragraph"><block ref="b0a9c7dc36cb18f93679b833533b9936" category="inline-link-macro-rx"></block></block>
  <block id="2fb227f90ebf269423fe0cf1a15b8111" category="doc">永続的ボリューム要求を定義</block>
  <block id="8f5da11015f2baf835f0e8b421c1cfe9" category="list-text">次の YAML をファイルに保存して、 Basic タイプの PVC を作成します。</block>
  <block id="04c58cdb1d0c073dd558caf87f2b8ed1" category="list-text">Iguazio Kubernetes クラスタに YAML ファイルを適用します。</block>
  <block id="f685fdfcc5aedb3ccc237a4020b69cd8" category="section-title">NetApp ボリュームを Jupyter Notebook に接続します</block>
  <block id="dc4b8e255a77b2c73f89b702dbb7acc5" category="inline-link">Iguazio アプリケーションサービスおよびツールの概要</block>
  <block id="11eb1e24a14c1d15ee5e287b4338b764" category="paragraph">Iguazio は、データサイエンティストが AI / ML アプリケーションの開発と導入のための完全なエンドツーエンドスタックを提供するための、複数のマネージドサービスを提供します。これらのコンポーネントの詳細については、を参照してください<block ref="2cf4dcc22fda31f66959754df93d6196" category="inline-link-rx"></block>。</block>
  <block id="3591be3d07a4f8a37d218b9e92bea432" category="paragraph">マネージドサービスの 1 つに Jupyter Notebook があります。開発者はそれぞれ、開発に必要なリソースを備えたノートブックコンテナを独自に導入します。NetApp Cloud Volume へのアクセスを許可するには、コンテナにボリュームを割り当て、リソースの割り当て、ユーザの実行、および永続ボリュームに関する環境変数の設定を次の図に示します。</block>
  <block id="e0d870d503aeb797f7626b14c9acb4ae" category="paragraph">オンプレミス構成の場合は、を参照してください<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> Trident のセットアップでは、データの Snapshot コピーの作成やバージョン管理のためのモデルなど、 NetApp ONTAP のデータ管理機能を有効にできます。Trident バックエンド構成ファイルに次の行を追加すると、 Snapshot ディレクトリが表示されます。</block>
  <block id="12ce9751e0e6d2a7d593d46e19211984" category="inline-link">Trident コマンド</block>
  <block id="71f8fa2d01d0c5a2d9af72f90f65e379" category="paragraph">Trident バックエンド構成ファイルを JSON 形式で作成し、次のコマンドを実行する必要があります<block ref="1dce3ee9e9ff2b59caf27104be259d37" category="inline-link-rx"></block> 参照するには：</block>
  <block id="2842c07cfacaf614e63dc1f2afef93b2" category="paragraph"><block ref="2842c07cfacaf614e63dc1f2afef93b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d47cd04a0ddb5c3e6a2d9b9bc5c6a120" category="inline-link-macro">次の手順：アプリケーションの展開</block>
  <block id="fafac2eb9a7c4fcf46778865a22a00d2" category="paragraph"><block ref="fafac2eb9a7c4fcf46778865a22a00d2" category="inline-link-macro-rx"></block></block>
  <block id="34d54070f7d06f04159ffbc3d9a3e082" category="doc">作業環境を構成します</block>
  <block id="8302b607de31151e5500de556070d9b9" category="paragraph">「 Notebook `````````s_env-example.ipynb` を 'et_env.ipynb` としてコピーします。「 et_env.ipynb 」を開き、編集します。このノートブックでは、資格情報、ファイルの場所、および実行ドライバの変数を設定します。</block>
  <block id="3dc3cffc26096b89061a452cc7d16b6a" category="paragraph">上記の手順を実行すると、次の手順だけが変更されます。</block>
  <block id="26448fec50e405fb230427686eeb11f4" category="list-text">この値は、 Iguazio サービスダッシュボード「 dOcker_registry 」から取得します</block>
  <block id="837784ac15c5cac463a4d016bac63db1" category="paragraph">例：「 ocker-registry.default-tenant.app.clusterq.iguaziodev.com:80` 」</block>
  <block id="04dca9f72f7dfc6f87034c574f821a12" category="list-text">「 admin 」を Iguazio のユーザ名に変更します。</block>
  <block id="b2dea33f1195135f6905b7dd0ee58713" category="paragraph">'IGZ_container_path='/users/admin'</block>
  <block id="0ddaf8f981ee966dc3533de490c7ee4e" category="paragraph">ONTAP システムの接続の詳細を次に示します。Trident のインストール時に生成されたボリューム名も指定します。オンプレミスの ONTAP クラスタの場合、次の設定が適用されます。</block>
  <block id="dada97be0cb81e6518d92aa7112fa356" category="paragraph">Cloud Volumes ONTAP の設定は次のとおりです。</block>
  <block id="586d20125924bc57624aaacc07973d5a" category="section-title">ベースとなる Docker イメージを作成</block>
  <block id="0ab24923db4855b821917446711104c9" category="paragraph">ML パイプラインの構築に必要なものはすべて、 Iguazio プラットフォームに含まれています。開発者は、パイプラインの実行に必要な Docker イメージの仕様を定義し、 Jupyter Notebook からイメージの作成を実行できます。ノートブック 'create-images .ipynb' を開き、すべてのセルを実行します。</block>
  <block id="3dc4e8abb0e99c6cf29451a16a891524" category="paragraph">このノートブックでは、パイプラインで使用する 2 つのイメージが作成されます。</block>
  <block id="5446cc82e4c165e2700af830f8428d63" category="list-text">「 iguazio/NetApp. 」を参照してください ML タスクの処理に使用されます。</block>
  <block id="61145f9d17e187b69bc41525b10aafe6" category="paragraph"><block ref="61145f9d17e187b69bc41525b10aafe6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62e9956426227f62abc9692954a5ad39" category="list-text">「 NetApp/pipeline. 」。NetApp Snapshot コピーを処理するユーティリティが含まれています。</block>
  <block id="4050f795a12d7f83a545999c8a0d1905" category="paragraph"><block ref="4050f795a12d7f83a545999c8a0d1905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6677daf583d4c0cf5860927a024f278d" category="section-title">Jupyter ノートブックを個別に確認します</block>
  <block id="6414e1c23e017075a375d3a531eab90c" category="paragraph">次の表に、このタスクの構築に使用したライブラリとフレームワークを示します。これらのコンポーネントはすべて、 Iguazio のロールベースアクセスおよびセキュリティ制御と完全に統合されています。</block>
  <block id="da292beca00e0b352eade7a070855fd3" category="cell">ライブラリ / フレームワーク</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">説明</block>
  <block id="124d604ba0d3fd8e3d31c821b2a332f5" category="cell">MLRun （ MLRun ）</block>
  <block id="1c1491d01d96c08951ae2ac55fadf443" category="cell">Iguazio によって管理され、 ML / AI パイプラインのアセンブリ、実行、および監視を可能にします。</block>
  <block id="a2580bd6e044f86f4e39be2f59ee91da" category="cell">Nuclio</block>
  <block id="2d753cbb7762fe25d15a2cda2ff84790" category="cell">Iguazio と統合されたサーバーレス機能フレームワーク。Iguazio が管理するオープンソースプロジェクトとしても利用できます。</block>
  <block id="0bbee378f2697a1d0c184e76d2b206c6" category="cell">パイプラインを導入するための Kubernetes ベースのフレームワーク。これは、イグアスが寄与するオープンソースのプロジェクトでもあります。Iguazio と統合されているため、他のインフラストラクチャとのセキュリティおよび統合が強化されています。</block>
  <block id="849efb47ec760eb7c3c6b5848e740c3b" category="cell">Iguazio プラットフォームでは、 Docker レジストリがサービスとして実行されます。レジストリに接続するように変更することもできます。</block>
  <block id="a38f73277b7341a709cf0cb57ebc4434" category="cell">NetApp Cloud Volume の略</block>
  <block id="7279bb663993b77e219b4ca813326d77" category="cell">AWS で Cloud Volume を実行すると、大量のデータにアクセスでき、トレーニングに使用するデータセットのバージョンに Snapshot コピーを作成することもできます。</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="cell">Trident</block>
  <block id="9953e13b783f3ad45d99187c955cb9f9" category="cell">Trident は、ネットアップが管理するオープンソースプロジェクトです。Kubernetes でのストレージリソースやコンピューティングリソースとの統合を簡易化します。</block>
  <block id="5fa4506d691373039fd2834939e582b3" category="paragraph">複数のノートブックを使用して ML パイプラインを構築しました。各ノートブックを個別にテストしてから、パイプラインにまとめてテストすることができます。このデモアプリケーションの導入フローに従って、各ノートブックについて個別に説明します。</block>
  <block id="06a86c2506db8ef5fdac675c1352e3cf" category="paragraph">望ましい結果は、データの Snapshot コピーに基づいてモデルをトレーニングし、推論のためにモデルを導入するパイプラインです。完成した MLRun パイプラインのブロック図を次の図に示します。</block>
  <block id="1d79eb753e06f2122a118408a14d6c51" category="paragraph"><block ref="1d79eb753e06f2122a118408a14d6c51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51b666fe429f998144ea4f2ce818cd60" category="section-title">データ生成機能を導入します</block>
  <block id="034015442bf8bf34c0e7e8149d35dae6" category="paragraph">このセクションでは、ネットワークデバイスデータの生成に Nuclio サーバーレス関数を使用する方法について説明します。この使用例は、パイプラインを展開し、イグアスのサービスを使用してネットワークデバイスの障害を監視および予測する Iguazio クライアントに適しています。</block>
  <block id="2d024dd4dc0601ff2e4d0b81fcaec60a" category="inline-link">Nuclio の Web サイト</block>
  <block id="59009d367371847f2042c59338282f4b" category="paragraph">ネットワークデバイスからのデータをシミュレートしました。Jupyter ノートブック「 d ata-generator.ipynb 」を実行すると、 10 分ごとに実行されるサーバーレス関数が作成され、新しいデータが保存された寄木細工のファイルが生成されます。この機能を配備するには、このノートブックのすべてのセルを実行します。を参照してください<block ref="a9d48e85369982160b96d90770d878d1" category="inline-link-rx"></block> このノートブックの構成部品を確認します。</block>
  <block id="fa0c06ebcd647f13ce81472307615ee3" category="paragraph">関数の生成時に、次のコメントを持つセルは無視されます。ノートブック内のすべてのセルは、機能の一部であると見なされます。Nuclio モジュールをインポートして '%nuclio magic を有効にします</block>
  <block id="c2b253a6bc491b37027772dba5f0b4e7" category="paragraph">関数の仕様では、関数が実行される環境、関数がどのようにトリガされるか、および関数が消費するリソースを定義しました。</block>
  <block id="95b0eb5f892f7b0bcb3ec7dbb9058c02" category="paragraph">「 init_context 」関数は、関数の初期化時に Nuclio フレームワークによって呼び出されます。</block>
  <block id="1aab9637db54631d95ec5901bfda0947" category="paragraph">関数内にないコードは、関数が初期化されるときに呼び出されます。この関数を呼び出すと、ハンドラ関数が実行されます。ハンドラの名前を変更し、関数仕様で指定できます。</block>
  <block id="94be7a657ecb54ef7337030d9dd78b70" category="paragraph">この機能は、導入前にノートブックからテストできます。</block>
  <block id="01237c05459839293bfcd5a3beb1364f" category="paragraph">この機能は、ノートブックから導入することも、 CI / CD パイプラインから導入することもできます（このコードを使用）。</block>
  <block id="c697561ec27606d29683f7fc5fb3846d" category="section-title">ノートブックをパイプライン化します</block>
  <block id="83041c5547fb0ad965936febfc41508d" category="paragraph">これらのノートブックは、このセットアップで個別に実行することを意図したものではありません。これは、各ノートブックを確認するためのものです。ネットアップは、このような案件をパイプラインの一部として呼び出しました。個別に実行するには、 MLRun のドキュメントを参照して、これらを Kubernetes ジョブとして実行します。</block>
  <block id="c16b208e4ffb938f4008373dea5fb4ec" category="section-title">snap_CV.ipynb</block>
  <block id="eeb06194a969eee5616e56b449a99306" category="paragraph">このノートブックでは、パイプラインの最初にあるクラウドボリュームの Snapshot コピーを処理します。ボリュームの名前をパイプラインコンテキストに渡します。このノートブックは、スナップショットコピーを処理するシェルスクリプトを呼び出します。パイプラインでの実行中、実行コンテキストには、実行に必要なすべてのファイルを見つけるのに役立つ変数が含まれています。このコードを記述する際、開発者は、このコードを実行するコンテナ内のファイルの場所を気にする必要はありません。後で説明したように、このアプリケーションはすべての依存関係とともに配置され、実行コンテキストを提供するパイプラインパラメータの定義です。</block>
  <block id="dc82b570ec10aa261c20bf4828af24c1" category="paragraph">作成された Snapshot コピーの場所は、 MLRun コンテキストに配置され、パイプラインの各ステップで使用されます。</block>
  <block id="7f609b3599e86a8f1b83bde97709ba37" category="paragraph">次の 3 つのノートブックは並行して実行されます。</block>
  <block id="d1839287f93e09936af234173d03d6b7" category="section-title">データの前処理 ipynb</block>
  <block id="dbe6ca7c47e3dc8cbd3a4956e684b761" category="paragraph">モデルのトレーニングを有効にするには、生の指標を機能に変換する必要があります。このノートでは、 Snapshot ディレクトリから生の指標を読み取り、モデルトレーニングの機能をネットアップボリュームに書き込みます。</block>
  <block id="dab65fbdf0ed5ce626558d99e83c618f" category="paragraph">パイプラインのコンテキストで実行する場合、「 Data ATA_DIR 」という入力には Snapshot コピーの場所が含まれます。</block>
  <block id="4636df8c7ba383c5f135c7ae8f2ef772" category="section-title">.ipynb を説明する</block>
  <block id="43099d46867c7c0cc922fdd3e026d029" category="paragraph">受信メトリックを視覚化するために、 Kubeflow UI と MLRun UI で使用できるプロットとグラフを提供するパイプラインステップを導入します。各実行には、この表示ツールの独自のバージョンがあります。</block>
  <block id="7fd47125b80c0e6241052a47dcb41b98" category="section-title">deploy-feature-function.ipynb</block>
  <block id="684eb641c7a322c328f8ea91cd482b0d" category="paragraph">ネットアップでは、異常を検出している指標を継続的に監視してこのノートブックは、受信メトリックの予測を実行するために必要な機能を生成するサーバーレス機能を作成します。このノートブックは関数の作成を呼び出します。ファンクションコードはノートブック「 ata-prep . ipynb 」にあります。この目的のために、パイプラインのステップとして同じノートブックを使用していることに注意してください。</block>
  <block id="1c475141d16ada0e53ddb14047963024" category="section-title">train.ipynb</block>
  <block id="43b6984a9b2a7863061833c96be2b851" category="paragraph">フィーチャーを作成した後、モデルトレーニングを開始します。このステップの出力は、推論に使用するモデルです。また、統計を収集して各実行を追跡します（実験）。</block>
  <block id="a6858cae929a8eed6e9c9d6cfa9befac" category="paragraph">たとえば、次のコマンドは、その測定条件のコンテキストに精度スコアを入力します。この値は Kubeflow および MLRun で確認できます。</block>
  <block id="9d1126b5d7690c0eb46dd7713822680e" category="section-title">deploy-inion-function.ipynb を展開します</block>
  <block id="827ebf8bb3ee1798b5394ecd2a8bb3ae" category="paragraph">パイプラインの最後のステップは、継続的な推論のためのサーバーレス機能としてモデルを導入することです。このノートブックでは、「 nuclio-increation-function.ipynb 」で定義されたサーバーレス関数の作成を呼び出します。</block>
  <block id="4d2c908b5247626d682903dc9527bd05" category="section-title">パイプラインのレビューと構築</block>
  <block id="6c8673acfb6249793bed69954ca16a9b" category="paragraph">パイプラインですべてのノートブックを実行するという組み合わせにより ' テストを継続的に実行して ' モデルの精度を新しいメトリックと比較して再評価することができますまず 'pipeline.ipynb' ノートブックを開きますネットアップと Iguazio が ML パイプラインの導入をどのように簡易化しているかを詳しく説明します。</block>
  <block id="50d4decae4f0f08e83a1bd8342bd6ef1" category="paragraph">MLRun を使用して、パイプラインの各ステップにコンテキストを提供し、リソースの割り当てを処理します。MLRun API サービスは、 Iguazio プラットフォームで動作し、 Kubernetes リソースとのやり取りのポイントです。各開発者はリソースを直接要求できません。 API は要求を処理し、アクセス制御を有効にします。</block>
  <block id="c7c5ccf69a87e301b134dcfdf46ab307" category="paragraph">パイプラインは、 NetApp Cloud Volume やオンプレミスのボリュームと連携できます。このデモでは Cloud Volume を使用するように設計しましたが、オンプレミスで実行できるオプションをコードに示しています。</block>
  <block id="ce16d064e13fffda0ff2a07c50276f33" category="paragraph">Jupyter ノートブックを Kubeflow ステップにするために必要な最初のアクションは、コードを関数に変換することです。関数には、ノートブックを実行するために必要なすべての仕様が含まれています。ノートブックを下にスクロールすると、パイプラインのすべてのステップに対応する関数が定義されていることがわかります。</block>
  <block id="8bbbd384e919f705f071525a96cdfaec" category="cell">ノートブックの一部</block>
  <block id="5d75cd50687084d681964f5c6ee8a73a" category="cell">&lt;code_to _function&gt; （ MLRun モジュールの一部）</block>
  <block id="eef456f018469b2d403742d05e33a5dd" category="cell">関数の名前：プロジェクト名。すべてのプロジェクトアーティファクトの編成に使用されます。これは MLRun UI に表示されます。種類：この場合は Kubernetes ジョブ。これには、 Dask 、 MPI 、 spark8s などがあります。詳細については、 MLRun のマニュアルを参照してください。ファイル。ノートブックの名前。これは Git （ HTTP ）の場所にすることもできます。</block>
  <block id="78805a221a988e79ef3f42d7c5bfd418" category="cell">イメージ（ Image ）</block>
  <block id="d0161cbbc56081c803c919679b76b846" category="cell">この手順で使用する Docker イメージの名前。先ほど 'create-image.ipynb ノートブックを作成しました</block>
  <block id="28bb8862d962b462f621d9098de311cd" category="cell">volume_mounts と volumes</block>
  <block id="a6841da965bfb59838d367b9fdc30a8c" category="cell">実行時に NetApp Cloud Volume をマウントするための詳細情報。</block>
  <block id="5d9261bc63dfeef8d26c807e36a9daa4" category="paragraph">また、ステップのパラメーターも定義します。</block>
  <block id="fcd242cd0d87d4de3be34f843180bdb0" category="paragraph">すべてのステップの関数定義が完了したら、パイプラインを構築できます。この定義には 'kfp' モジュールを使用しますMLRun を使用することと、独自に構築することの違いは、コーディングの簡素化と短縮です。</block>
  <block id="f02b57d2fbd61d7629e76438ba68f7a1" category="paragraph">定義した関数は、 MLRun の「 As _ step 」関数を使用してステップコンポーネントになります。</block>
  <block id="8859e75c5bfd3a8ea5a783296d71b795" category="section-title">スナップショットステップの定義</block>
  <block id="dabb827ac33da3a8d8a2384874221aab" category="paragraph">Snapshot 機能を開始し、 v3io をソースとしてマウントします。</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">パラメータ</block>
  <block id="422ac26927e8ad3d6b30617226e26c2a" category="cell">新しいタスクです</block>
  <block id="b954691c9a06ef7281bf4c836e7684f1" category="cell">newtask は、実行される関数の定義です。</block>
  <block id="7871261404e7a8d93339696184b243b9" category="cell">（ MLRun モジュール）</block>
  <block id="4522319a8fbbe0a85c82e604047dfe6c" category="cell">ハンドラ。呼び出す Python 関数の名前。ノートブックでは name ハンドラーを使用しましたが、必須ではありません。パラメータ実行に渡されたパラメータ。このコードでは、 context.get_param （「パラメータ」）を使用して値を取得します。</block>
  <block id="6cebb60f71d9de65143ade7a8388e27a" category="cell">ステップとして（ _STEP. ）</block>
  <block id="070faabab806ce863279f5bd38452cc4" category="cell">名前Kubeflow パイプラインステップの名前。出力：これらは、完了時にステップが辞書に追加する値です。SNAP_CV.ipynb ノートブックを参照してください。mount_v3io()これにより、パイプラインを実行しているユーザーの /User をマウントするステップが構成されます。</block>
  <block id="a8aff967e1649a1c82ea607c881e8091" category="cell">入力</block>
  <block id="6f1ba99c8ee685047e0fa3c32349a01f" category="cell">前の手順の出力に渡すことができます。この場合、 snap.outputs['napVolumeDetails'] は、スナップステップで作成した Snapshot コピーの名前です。</block>
  <block id="a399d9e54dd5dc35c6b455d995702175" category="cell">out_path</block>
  <block id="026446ea82508e4c9f41609b3484b4cb" category="cell">MLRun モジュール LOG_Artifacts を使用して生成するアーティファクトを配置する場所。</block>
  <block id="2fe8889e7fb9545ea383ff3c0451cabf" category="paragraph">上から下に 'pipeline.ipynb' を実行できます次に、 Iguazio ダッシュボードの Pipelines タブに移動して、 Iguazio ダッシュボードの Pipelines タブに示すように、進捗状況を監視できます。</block>
  <block id="74dec5a93e3c1ccb06f26ebc6f9401fb" category="paragraph"><block ref="74dec5a93e3c1ccb06f26ebc6f9401fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f47db69a9e60b47a1c8f7800753f6b57" category="paragraph">トレーニングステップの精度はすべての実行で記録されているため、トレーニングの正確性の記録に示されているように、各テストの精度の記録があります。</block>
  <block id="5bb7a1a5b810ce843cd4d41a7137ce26" category="paragraph"><block ref="5bb7a1a5b810ce843cd4d41a7137ce26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9ebd260b4ed60a239b8228fe68b2dbc" category="paragraph">Snapshot ステップを選択すると、この実験を実行するために使用された Snapshot コピーの名前が表示されます。</block>
  <block id="1d231b2e1da6122607105ce52f87a763" category="paragraph"><block ref="1d231b2e1da6122607105ce52f87a763" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc578a2d3b019d646da18c9172282dc" category="paragraph">ここで説明する手順には、使用した指標を確認するための視覚的なアーティファクトがあります。を展開すると、次の図のように全プロットを表示できます。</block>
  <block id="ffb599ed438d33d337e7cca9a1fbaf07" category="paragraph"><block ref="ffb599ed438d33d337e7cca9a1fbaf07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89238f00748675db057567546f67c2c5" category="paragraph">MLRun API データベースは、プロジェクトごとに編成された各ランの入力、出力、およびアーティファクトも追跡します。各ランの入力、出力、およびアーティファクトの例を次の図に示します。</block>
  <block id="a8baa83f88edfb0fceafeda75819cb5f" category="paragraph"><block ref="a8baa83f88edfb0fceafeda75819cb5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c6050fe85d7b5528bc8356c88eab725" category="paragraph">各ジョブについて、追加の詳細情報が保存されます。</block>
  <block id="8683624a37c6626765321b5cc2f60954" category="paragraph"><block ref="8683624a37c6626765321b5cc2f60954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f02f72c9470e67a8b3c5f9054b0a32c" category="inline-link">MLRun GitHub サイト</block>
  <block id="01661b1e0825da7434573266df1672e0" category="paragraph">MLRun の詳細については、このドキュメントで説明している内容を参照してください。ステップと関数の定義を含むアルアーティファクトは、 API データベースに保存したり、バージョン管理したり、個別に呼び出すことも、完全なプロジェクトとして呼び出すこともできます。プロジェクトを保存して Git にプッシュし、後で使用することもできます。詳細については、を参照してください<block ref="92ae596fd8e402850e22f59a73ed3a44" category="inline-link-rx"></block>。</block>
  <block id="43486dfb907f148e40f3719f314caeb4" category="inline-link-macro">次： Grafana ダッシュボードを導入します</block>
  <block id="0670d6ac4e77f5862afcc2fde43bcc72" category="paragraph"><block ref="0670d6ac4e77f5862afcc2fde43bcc72" category="inline-link-macro-rx"></block></block>
  <block id="0b7e964d1176d21b9ba3eceec8ed95ac" category="doc">コンセプトとコンポーネント</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">人工知能</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">AI とは、人間の心の認識機能を模倣するためにコンピュータが訓練されているコンピュータ科学分野です。AI 開発者は、人間に似た方法、または人間に比べて優れた方法で、コンピュータをトレーニングして問題を解決します。ディープラーニングと機械学習は AI のサブフィールドです。組織は、重要なビジネスニーズに対応するために、 AI 、 ML 、 DL を導入する傾向に迫られています。次に例を示します。</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">未知のビジネスに大量のデータを分析しています 分析</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">自然言語処理を使用して顧客と直接やり取りする</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="section-title">コンテナ</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">コンテナは、共有ホストオペレーティングシステムカーネル上で実行される独立したユーザスペースインスタンスです。コンテナの採用が急速に増加しています。コンテナは、仮想マシン（ VM ）が提供するものと同じアプリケーションのサンドボックス化のメリットの多くを提供します。ただし、 VM が依存するハイパーバイザーレイヤとゲストオペレーティングシステムレイヤが排除されているため、コンテナの軽量化が大幅に向上しています。次の図に、仮想マシンとコンテナを視覚的に示します。</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Docker Web サイト</block>
  <block id="da28cd415837c7f3d1d6221ff490b84b" category="paragraph">コンテナを使用すると、アプリケーションの依存関係や実行時間などをアプリケーションで直接効率的にパッケージングできます。最も一般的に使用されるコンテナパッケージ形式は Docker コンテナです。Docker コンテナ形式でコンテナ化されたアプリケーションは、 Docker コンテナを実行できる任意のマシンで実行できます。これは、アプリケーションの依存関係がマシンに存在しない場合でも当てはまります。これは、すべての依存関係がコンテナ自体にパッケージ化されているためです。詳細については、を参照してください<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block>。</block>
  <block id="9c3d617029ed075512781527983e01e4" category="paragraph"><block ref="9c3d617029ed075512781527983e01e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Kubernetes Web サイト</block>
  <block id="7a1446916a360f9c8ae3b94a97ad8c86" category="paragraph">Kubernetes は、 Google が当初設計した、オープンソースの分散型コンテナオーケストレーションプラットフォームであり、 Cloud Native Computing Foundation （ CNCF ）によって管理されています。Kubernetes を使用すると、コンテナ化されたアプリケーションの導入、管理、拡張の機能を自動化できます。近年、 Kubernetes は主要なコンテナオーケストレーションプラットフォームとして登場しています。他のコンテナパッケージ化形式や実行時間もサポートされていますが、 Kubernetes は Docker コンテナ用のオーケストレーションシステムとして最もよく使用されます。詳細については、を参照してください<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block>。</block>
  <block id="6ea70a0ecace7daa9dfbbc8ff3282de1" category="inline-link">Trident の Web サイト</block>
  <block id="f9b736ec48694a34e744a1a0309602bd" category="paragraph">Trident は、ネットアップが開発および管理しているオープンソースのストレージオーケストレーションツールで、 Kubernetes ワークロード向けの永続的ストレージの作成、管理、使用を大幅に簡易化します。Trident は Kubernetes ネイティブのアプリケーションであり、 Kubernetes クラスタ内で直接実行されます。Trident を使用すると、 Kubernetes のユーザ（開発者、データサイエンティスト、 Kubernetes 管理者など）は、使い慣れた標準的な Kubernetes 形式で永続ストレージボリュームを作成、管理、操作できます。同時に、ネットアップの高度なデータ管理機能と、ネットアップテクノロジを基盤とするデータファブリックを活用できます。Trident は、複雑な永続的ストレージを抽象化して、消費を簡易化します。詳細については、を参照してください<block ref="ad5406ed69f3fe0de810f757310402c9" category="inline-link-rx"></block>。</block>
  <block id="47bbe104ad41e6af2ee0dba5dc76d74d" category="inline-link">DeepOps の Web サイト</block>
  <block id="b1c5aef0d1e7ec0339ca5caa48c1b3e3" category="paragraph">DeepOps は NVIDIA が開発したオープンソースプロジェクトです。 Ansible を使用することで、ベストプラクティスに従って GPU サーバクラスタの導入を自動化できます。DeepOps はモジュール方式であり、さまざまな導入タスクに使用できます。このドキュメントとこの検証の演習では、 DeepOps を使用して、 GPU サーバワーカーノードで構成される Kubernetes クラスタを導入します。詳細については、を参照してください<block ref="640792bfd91bad987ba8fd5d776a2824" category="inline-link-rx"></block>。</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Kubeflow の Web サイト</block>
  <block id="ea77b50ef31a778a66411b993d6cb7d1" category="paragraph">Kubeflow は Kubernetes 向けのオープンソースの AI / ML ツールキットで、 Google が開発したものです。Kubeflow プロジェクトでは、 Kubernetes での AI ワークフローと ML ワークフローの導入を、シンプル、ポータブル、拡張性に優れた方法で実施します。Kubeflow は Kubernetes の複雑さを抽象化し、データサイエンティストがデータサイエンスのベストプラクティスに集中できるようにします。表示については、次の図を参照してください。Kubernetes で企業の IT 部門の標準化が進むにつれて、 Kubeflow は大きな牽引力を発揮してきました。詳細については、を参照してください<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block>。</block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Kubeflow パイプライン</block>
  <block id="384873a621d99250018cd7ce1768f8af" category="paragraph">Kubeflow Pipelines は Kubeflow の主要コンポーネントです。Kubeflow Pipelines は、移植性と拡張性に優れた AI および ML ワークフローを定義、導入するためのプラットフォームと標準です。詳細については、を参照してください<block ref="6de5a235a0c43df48d05588e1b69b959" category="inline-link-rx"></block>。</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Jupyter のウェブサイト</block>
  <block id="3cecf3b7bbdb1a67a537c65bfd6fd529" category="paragraph">Jupyter Notebook Server はオープンソースの Web アプリケーションで、データサイエンティストは Jupyter Notebook と呼ばれる Wiki 形式のドキュメントを作成できます。このドキュメントには、ライブコードと説明的なテストが含まれています。Jupyter Notebook は、 AI プロジェクトと ML プロジェクトを文書化、保存、共有する手段として、 AI と ML のコミュニティで広く使用されています。Kubeflow を使用すると、 Kubernetes での Jupyter Notebook Server のプロビジョニングと導入が簡単になります。Jupyter Notebook の詳細については、を参照してください<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block>。Kubeflow のコンテキスト内の Jupyter Notebook の詳細については、を参照してください<block ref="c5d2218884acd101e6deb4d8c7d39370" category="inline-link-rx"></block>。</block>
  <block id="a2b0a43dcae6386929654b652393e691" category="paragraph"><block ref="a2b0a43dcae6386929654b652393e691" category="inline-image-macro-rx" type="image"></block></block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="section-title">Apache の通気</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9.</block>
  <block id="0b83cba78e13ee67f3ada794b1e8edb8" category="paragraph">NetApp ONTAP 9 はネットアップが提供する最新世代のストレージ管理ソフトウェアです。お客様のような企業がインフラを刷新し、クラウド対応のデータセンターに移行できるようにします。業界をリードするデータ管理機能を備えた ONTAP では、データの格納場所に関係なく、単一のツールセットでデータの管理と保護を行うことができます。エッジ、コア、クラウドなど、必要な場所に自由にデータを移動することもできます。ONTAP 9 には、データ管理を簡易化し、重要なデータを高速化、保護し、ハイブリッドクラウドアーキテクチャ全体で将来のニーズに対応できるインフラを実現する、多数の機能が搭載されています。</block>
  <block id="849f9e6e3176f7bb2abaf1dfdda6f4de" category="section-title">データ管理を簡易化</block>
  <block id="5d0a72b50313f5f3615263a7d19ee676" category="paragraph">データ管理は、アプリケーションやデータセットに適切なリソースを使用できるようにするために、企業の IT 運用にとって非常に重要です。ONTAP には、運用を合理化および簡易化し、総運用コストを削減するための次の機能が含まれています。</block>
  <block id="30490e1b1bd18c329c3b28df91914ffe" category="list-text">* インラインデータコンパクションと重複排除の強化。 * データコンパクションはストレージブロック内の無駄なスペースを削減し、重複排除は実効容量を大幅に増やします。</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">* 最小、最大、アダプティブの Quality of Service （ QoS ；サービス品質）。 * きめ細かい QoS 管理機能により、高度に共有された環境で重要なアプリケーションのパフォーマンスレベルを維持できます。</block>
  <block id="d9a5709ce7afa0856dd86539f75c8087" category="list-text">* StorageGRID 。 * この機能は、 Amazon Web Services （ AWS ）、 Azure 、 NetApp ONTAP FabricPool オブジェクトベースストレージなどのパブリックおよびプライベートクラウドストレージオプションへのコールドデータの自動階層化を提供します。</block>
  <block id="ddb2f8d78c57d5743fdee9e17ae053c9" category="section-title">データの高速化と保護</block>
  <block id="4994fe58be1734616de0863809040200" category="paragraph">ONTAP は、卓越したパフォーマンスとデータ保護を実現し、以下の機能を通じてこれらの機能を拡張します。</block>
  <block id="b109ecc7b4570bf3dbb9f8d082595075" category="list-text">* ハイパフォーマンスと低レイテンシ。 * ONTAP は、可能な限り低いレイテンシで最高のスループットを提供します。</block>
  <block id="9e184f7b8847a390232c0163d45ab461" category="list-text">* NetApp ONTAP FlexGroup テクノロジ。 * FlexGroup ボリュームは、最大 20PB と 4 、 000 億ファイルまでリニアに拡張可能な高性能データコンテナで、データ管理を簡易化する単一のネームスペースを提供します。</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">* データ保護。 * ONTAP は、組み込みのデータ保護機能を提供し、すべてのプラットフォームで共通の管理を実現します。</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* NetApp Volume Encryption* ONTAP は、オンボードと外部の両方のキー管理をサポートし、ボリュームレベルのネイティブ暗号化を実現します。</block>
  <block id="0950833529b7822458a242631cce3b3b" category="section-title">将来のニーズにも対応できるインフラ</block>
  <block id="ba5b61620e18b71a8644dbc382c0c4f1" category="paragraph">ONTAP 9 は、要件が厳しく、絶えず変化するビジネスニーズに対応します。</block>
  <block id="d9d73747d25ab5e9c5de8f1f61c9ec7c" category="list-text">* シームレスな拡張とノンストップオペレーション。 * ONTAP は、既存のコントローラとスケールアウトクラスタに無停止で容量を追加できます。NVMe や 32Gb FC などの最新テクノロジへのアップグレードも、コストのかかるデータ移行やシステム停止を行わずに実行できます。</block>
  <block id="512a65c054e8b5d06216e0eae55abedb" category="list-text">* クラウドへの接続。 * ONTAP は、すべてのパブリッククラウドで Software-Defined Storage （ ONTAP Select ）とクラウドネイティブインスタンス（ NetApp Cloud Volumes Service ）を選択できる、最もクラウドに接続されたストレージ管理ソフトウェアの 1 つです。</block>
  <block id="5ca60f373401802dfa44501cfa4f5cc7" category="list-text">* 新しいアプリケーションとの統合。 * 既存のエンタープライズアプリケーションをサポートする同じインフラを使用して、 ONTAP は、 OpenStack 、 Hadoop 、 MongoDB などの次世代プラットフォームやアプリケーションにエンタープライズクラスのデータサービスを提供します。</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">NetApp Snapshot コピー</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">NetApp Snapshot コピーは、ボリュームの読み取り専用のポイントインタイムイメージです。次の図に示すように、イメージには Snapshot コピーが最後に作成されたあとに作成されたファイルへの変更だけが記録されるため、ストレージスペースは最小限しか消費せず、パフォーマンスのオーバーヘッドもわずかです。</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Snapshot コピーの効率性は、 ONTAP の中核的なストレージ仮想化テクノロジである Write Anywhere File Layout （ WAFL ）によって実現します。WAFL は、データベースと同様に、メタデータを使用してディスク上の実際のデータブロックを参照します。ただし、データベースとは異なり、 WAFL は既存のブロックを上書きしません。更新されたデータは新しいブロックに書き込まれ、メタデータが変更されます。ONTAP では、 Snapshot コピーの作成時にデータブロックをコピーするのではなくメタデータを参照するため、非常に効率的です。他のシステムと違ってコピーするブロックを探すシーク時間もなければ、コピー自体を作成するコストもかかりません。</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">Snapshot コピーを使用して、個々のファイルまたは LUN をリカバリしたり、ボリュームの内容全体をリストアしたりできます。ONTAP は、 Snapshot コピーのポインタ情報をディスク上のデータと比較することで、ダウンタイムや多大なパフォーマンスコストなしで損失オブジェクトや破損オブジェクトを再構築します。</block>
  <block id="9787a3a5983c64cfaf3029a721aab4f0" category="paragraph"><block ref="9787a3a5983c64cfaf3029a721aab4f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">NetApp FlexClone テクノロジ</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">NetApp FlexClone テクノロジは、 Snapshot メタデータを参照してボリュームの書き込み可能なポイントインタイムコピーを作成します。コピーと親でデータブロックが共有されるため、次の図に示すように、コピーに変更が書き込まれるまではメタデータに必要な分しかストレージは消費されません。従来の手法でコピーを作成すると数分から数時間かかりますが、 FlexClone ソフトウェアを使用すれば大規模なデータセットのコピーもほぼ瞬時に作成できます。そのため、同じデータセットのコピーが複数必要な状況（開発用ワークスペースなど）や一時的にデータセットのコピーが必要な状況（本番環境のデータセットでアプリケーションをテストする場合など）に適しています。</block>
  <block id="423c2edb645c178257ba9d79bd9ac684" category="paragraph"><block ref="423c2edb645c178257ba9d79bd9ac684" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">NetApp SnapMirror データレプリケーションテクノロジ</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">NetApp SnapMirror ソフトウェアは、データファブリック全体にわたる、コスト効率に優れた使いやすいユニファイドレプリケーション解決策です。LAN または WAN 経由でデータを高速で複製します。仮想環境と従来の環境の両方でビジネスクリティカルなアプリケーションを含む、あらゆるタイプのアプリケーションに対し、高いデータ可用性と高速なデータレプリケーションを提供します。1 つ以上のネットアップストレージシステムにデータをレプリケートし、セカンダリデータを継続的に更新すると、データが最新の状態に保たれ、必要なときにいつでも使用できます。外部レプリケーションサーバは必要ありません。SnapMirror テクノロジを利用したアーキテクチャの例については、次の図を参照してください。</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">SnapMirror ソフトウェアは、変更されたブロックのみをネットワーク経由で送信することで、 NetApp ONTAP の Storage Efficiency 機能を活用します。SnapMirror ソフトウェアには、組み込みのネットワーク圧縮機能も使用して、データ転送を高速化し、ネットワーク帯域幅の使用量を最大 70% 削減します。SnapMirror テクノロジを使用すると、 1 つのシンレプリケーションデータストリームを利用して単一のリポジトリを作成し、アクティブなミラーと以前のポイントインタイムコピーの両方を保持できるため、ネットワークトラフィックを最大 50% 削減できます。</block>
  <block id="423eee692f81241addaf586841d0c66a" category="paragraph"><block ref="423eee692f81241addaf586841d0c66a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroup Volume の略</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">トレーニングデータセットは、数十億に及ぶ可能性のあるファイルの集まりです。ファイルには、テキスト、オーディオ、ビデオなどの形式の非構造化データを含めることができます。これらのデータは、並行して読み込まれるように保存して処理する必要があります。ストレージシステムは、多数の小さなファイルを格納し、シーケンシャル I/O とランダム I/O でそれらのファイルを並行して読み取る必要があります</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">FlexGroup ボリュームは、次の図に示すように、複数のコンスティチュエントメンバーボリュームで構成される単一のネームスペースです。ストレージ管理者の視点で見ると、 FlexGroup ボリュームは管理され、 NetApp FlexVol ボリュームのように機能します。FlexGroup ボリューム内のファイルは、個々のメンバーボリュームに割り当てられ、複数のボリュームやノードにまたがってストライプされることはありません。次の機能が有効になります。</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">FlexGroup ボリュームは、数ペタバイトの容量と、メタデータ比率の高いワークロード向けの予測可能な低レイテンシを提供します。</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">同じネームスペースで最大 4 、 000 億個のファイルをサポートします。</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">CPU 、ノード、アグリゲート、コンスティチュエント FlexVol ボリューム全体で NAS ワークロードの並列処理をサポートします。</block>
  <block id="07e40bce6e02494c0af7b6a5f2aeaad8" category="paragraph"><block ref="07e40bce6e02494c0af7b6a5f2aeaad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="doc">Kubeflow の導入</block>
  <block id="28b9eb1a9ba550cf23239eb33610203e" category="doc">ソフトウェアとハードウェアの要件</block>
  <block id="dce011ea921230b4e3061bb70569c598" category="section-title">ネットワーク構成：</block>
  <block id="5c56d5a342310a4d1ead67adc85adcab" category="paragraph">クラウドにセットアップするためのネットワーク構成の要件は次のとおりです。</block>
  <block id="df97d4ea35e2febbb06b9bd1ba29b50e" category="list-text">Iguazio クラスタと NetApp Cloud Volume は、同じ仮想プライベートクラウドに存在する必要があります。</block>
  <block id="a8f3c1a7fc956bcddef483bc8797e742" category="list-text">クラウドマネージャは、 Iguazio アプリノードのポート 443 にアクセスできる必要があります。</block>
  <block id="0d1562d43d3c0d4c52eef4a841896eba" category="list-text">本テクニカルレポートでは Amazon Web Services を使用しました。ただし、任意のクラウドプロバイダに解決策を導入することもできます。 ONTAP AI で NVIDIA DGX-1 を使用したオンプレミステストの場合は、便宜のために Iguazio ホスト DNS サービスを使用しました。</block>
  <block id="820de5e74a90f4dbc17e37b78258c35b" category="paragraph">クライアントは、動的に作成される DNS ドメインにアクセスできる必要があります。お客様は必要に応じて独自の DNS を使用できます。</block>
  <block id="43ad77bf4f253415b4e90ea4aa41a2d7" category="paragraph">イグアスは、ご使用のクラスタにオンプレミスでインストールできます。ネットアップでは、 NVIDIA DGX-1 システムで NetApp ONTAP AI の解決策を検証しました。次の表に、この解決策のテストに使用したハードウェアを示します。</block>
  <block id="7b6f2acc1b4489fd971965be635ea987" category="cell">NetApp AFF A800 システム</block>
  <block id="55552614d2dd18f2d6c40759f2de9e22" category="cell">ハイアベイラビリティ（ HA ）ペア × 1 、コントローラ × 2 、 NVMe SSD × 48 （ 3.8TB 以上）</block>
  <block id="413400218c4c262991ad8483b3be0a04" category="cell">Cisco Nexus 3232C ネットワークスイッチ</block>
  <block id="72f23e74ab545a9064f74aca4d904bf4" category="paragraph">次の表に、オンプレミステストに必要なソフトウェアコンポーネントを示します。</block>
  <block id="751601035b4077a9c6f7280ab1d3369c" category="cell">4.4 - Ubuntu 18.04 LTS</block>
  <block id="bb3121464976ef0c6b6b2b81fc75f3c5" category="cell">19.03.5</block>
  <block id="2a820a07d05055e147221622557f34b9" category="cell">コンテナバージョン</block>
  <block id="6f3d0f773f6be20d70e6bbbafca93de9" category="cell">20.01-tF1 - py2</block>
  <block id="46b6cc5d90605df4689002387db99128" category="cell">機械学習フレームワーク</block>
  <block id="f060e908e90b13cff9447e18fbb6bb20" category="cell">TensorFlow 1.15.0</block>
  <block id="4ec1f03a0b910370451392d8af8cd05a" category="cell">イグアテオ</block>
  <block id="80b1aaf85493db4117fca57135bec077" category="cell">バージョン 2.8 以降</block>
  <block id="20de768bd6142b858c4e99c64e19f37b" category="cell">ESX サーバ</block>
  <block id="f884cc5c56f9c9a8d4d61568ff64db9c" category="cell">6.5</block>
  <block id="95b4a53c1023a65c982b077b13be4b96" category="paragraph">この解決策は、 Iguazio バージョン 2.5 および NetApp Cloud Volumes ONTAP for AWS で完全にテストされています。Iguazio クラスタとネットアップのソフトウェアは、どちらも AWS で実行されています。</block>
  <block id="efbef76fea5d52b17e66f66b7fbdb1be" category="cell">[ バージョン ] または [ タイプ ]</block>
  <block id="1f2c90c0f9931b94eab6d9d2d3a640c9" category="cell">アプリケーションノード</block>
  <block id="8f33b30dd333b320c87f038f61e17523" category="cell">m5.mc</block>
  <block id="b8f3b98512c841c7f30ce704570ac0b6" category="cell">データノード</block>
  <block id="ea93f0324aaeaa177497ea41b52cb9ff" category="cell">I3.と は、および</block>
  <block id="870032d2d605939c0c8a813ac8534e80" category="inline-link-macro">次の例：ネットワークデバイスの障害予測ユースケースの概要</block>
  <block id="6b90a2e4861b0a6faf4f640ece131282" category="paragraph"><block ref="6b90a2e4861b0a6faf4f640ece131282" category="inline-link-macro-rx"></block></block>
  <block id="232abf87aa3028a990e94f6bb51fe8bd" category="summary">Kubernetes クラスタでシングルノードの AI ジョブと ML ジョブを実行するには、導入ジャンプホストからこのページのタスクを実行します。</block>
  <block id="46300fa439cc237919f854816fc89fc2" category="doc">シングルノードの AI ワークロードを実行</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">このセクションでは、 Kubernetes クラスタで実行しようとしている特定の AI および ML ワークロードを（ Docker コンテナ形式で）コンテナ化済みであることを前提としています。</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">ImageNet の Web サイト</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">次のコマンド例は、 ImageNet データセットを使用する TensorFlow ベンチマークワークロード用の Kubernetes ジョブを作成する方法を示しています。ImageNet データセットの詳細については、を参照してください<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block>。</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">このジョブ例では、 8 個の GPU を要求するため、 8 個以上の GPU を搭載した 1 つの GPU ワーカーノードで実行することができます。このジョブ例は、 8 個以上の GPU を搭載したワーカーノードが存在しない、または現在別のワークロードを使用しているクラスタで送信できます。その場合、そのようなワーカーノードが使用可能になるまで、ジョブは保留状態のままになります。</block>
  <block id="225e66547943a27f429558dce4e639e2" category="paragraph">「 M emory 」の値が「 emory 」である「 emptyDir 」ボリュームは、この例のジョブで作成されるポッド内の「 /dev/shm 」にマウントされます。Docker コンテナランタイムによって自動的に作成される「 /dev/shm 」仮想ボリュームのデフォルトサイズが、 TensorFlow のニーズに十分でない場合があります。次の例のように 'emptyDir' ボリュームをマウントすると '/dev/shm' 仮想ボリュームが十分に大きくなります「 emptyDir 」ボリュームの詳細については、を参照してください<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block>。</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">この例のジョブ定義で指定されている単一のコンテナには 'ecurityContext&gt; 特権値 'true' が与えられますこの値は、コンテナにホスト上のルートアクセス権があることを意味します。このアノテーションは、実行中の特定のワークロードにルートアクセスが必要なために使用されます。具体的には、ワークロードで実行されるクリアキャッシュ処理にはルートアクセスが必要です。これが特権 : true の注釈であるかどうかは ' 実行している特定のワークロードの要件によって異なります</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">手順 1 で作成したジョブが正しく実行されていることを確認します。次のコマンド例では、ジョブ定義で指定したとおりにジョブ用にポッドが 1 つ作成され、このポッドが GPU ワーカーノードの 1 つで現在実行されていることを確認します。</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">手順 1 で作成したジョブが正常に完了したことを確認します。次のコマンド例は、ジョブが正常に完了したことを確認します。</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">* オプション： * ジョブアーティファクトをクリーンアップします。次のコマンド例は、手順 1 で作成したジョブオブジェクトの削除を示しています。</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">ジョブオブジェクトを削除すると、関連付けられているポッドは Kubernetes によって自動的に削除されます。</block>
  <block id="65f63f96295566cd4278775eef1b4c8c" category="doc">パフォーマンスの低いワークロードやインタラクティブなワークロードに適した、フラクショナルな GPU 割り当て</block>
  <block id="1b3d285072ee60a98cde2f66b6e47fde" category="paragraph">開発、ハイパーパラメータチューニング、デバッグのどの段階であっても、研究者や開発者が自分のモデルに取り組んでいる場合、このようなワークロードに必要なコンピューティングリソースは通常少なくなります。したがって、フラクショナル GPU とメモリをプロビジョニングして、同じ GPU を他のワークロードに同時に割り当てることがより効率的です。実行： AI のオーケストレーション解決策は、 Kubernetes 上のコンテナ化されたワークロード向けのフラクショナル GPU 共有システムを提供します。CUDA プログラムを実行するワークロードをサポートするシステムで、推論やモデル構築などの軽量な AI タスクに特に適しています。フラクショナル GPU システムを使用すると、データサイエンスチームや AI エンジニアリングチームは、 1 つの GPU で複数のワークロードを同時に実行できます。これにより、コンピュータビジョン、音声認識、自然言語処理など、より多くのワークロードを同じハードウェア上で実行できるようになり、コストが削減されます。</block>
  <block id="5db1fcd5bb529fa2475aaf893414d2e4" category="paragraph">実行： AI のフラクショナル GPU システムは、仮想化された論理 GPU を独自のメモリとコンピューティングスペースで効率的に作成します。このスペースは、コンテナが自己完結型のプロセッサであるかのように使用およびアクセスできます。これにより、複数のワークロードを同じ GPU 上で並行して実行でき、互いに影響することはありません。解決策は透過的でシンプル、かつ移植可能であり、コンテナ自体に変更を加える必要はありません。</block>
  <block id="71cdf780e37cc9571b5fcd0bf89958b1" category="paragraph">一般的な usecase では、同じ GPU 上で 2 ～ 8 個のジョブが実行されていることがわかります。つまり、同じハードウェアで作業を 8 倍行うことができます。</block>
  <block id="0a1f69603a47f75f701f92ad7d94e3c5" category="paragraph">次の図のプロジェクト「 team -d 」に属するジョブ「分割 05 」については、割り当てられた GPU の数が 0.50 であることがわかります。さらに 'nvidia-smi コマンドによって確認されますこのコマンドは ' コンテナに使用できる GPU メモリが 'DGX-1 ノードの V100 GPU あたりの 32GB の半分である 16,255MB であることを示します</block>
  <block id="e6d9743072cdc6867ea2980c7db7e7fd" category="paragraph"><block ref="e6d9743072cdc6867ea2980c7db7e7fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9afb11deef37d75cf56adc6e1a2f4020" category="inline-link-macro">次の例：クォータ超過の GPU 割り当てによる高いクラスタ利用率の実現</block>
  <block id="15968f671ef08561726e3064358c707b" category="paragraph"><block ref="15968f671ef08561726e3064358c707b" category="inline-link-macro-rx"></block></block>
  <block id="3642f282b12269091ab196a3aabf0858" category="doc">Trident の運用例</block>
  <block id="ff9caff469d56a572a569942ca24c8b4" category="list-text">NVIDIA DGX システム</block>
  <block id="b69073c22b4269568fd577ea090ce638" category="list-text">NVIDIA DGX-1 システム<block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="fe287c518b9b1345defadacdc6a9ecbf" category="list-text">NVIDIA V100 Tensor コア GPU<block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="d6a8716635a5681cde357a465953bc72" category="list-text">NVIDIA NGC<block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="11bdb18e1c5e7d1e4362c9d2f6956fc8" category="list-text">実行： AI コンテナオーケストレーション解決策</block>
  <block id="5afc85c81e76f427a293dd861e0109a3" category="list-text">実行： AI 製品の概要<block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="9acfbb098f0d9b45b5897b44ae347ee9" category="list-text">実行： AI インストールドキュメント<block ref="cb05a776556ca5a25aec417185ef6863" category="inline-link-rx"></block>
<block ref="b2e8533fae57aa9047d7731db51b6dfe" category="inline-link-rx"></block></block>
  <block id="b0d8a6d0eebdc42ac243c16f9137118d" category="list-text">実行時のジョブの送信： AI CLI<block ref="97ec6c214f99d7e6a39194a167aeecc8" category="inline-link-rx"></block>
<block ref="d75350381b5fda5cc9c9a1ce34c24299" category="inline-link-rx"></block></block>
  <block id="9bd35f4f3f6faa9e9330c54fd2086967" category="list-text">実行時の GPU フラクションの割り当て： AI CLI<block ref="e343516de5fb56c6a0d652bcdfceaab7" category="inline-link-rx"></block></block>
  <block id="ddb27cb97146c8f5964eaf368feb4ce0" category="list-text">テクニカルレポートをご参照ください<block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="2273cd603e277bb35f96881a557b0608" category="list-text">簡単なデモ<block ref="61e3673018126d9a106032d9ff691322" category="inline-link-rx"></block></block>
  <block id="45f26b752dfae88ec8c7def446162521" category="list-text">GitHub リポジトリ<block ref="f9a4909739179bedfa8ba1d225598979" category="inline-link-rx"></block></block>
  <block id="c36e36ff8b7edf8dd17781148ed57337" category="list-text">NetApp AFF A シリーズのデータシート<block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="ffc4c8e8bc10afc438d9c590f44e3b51" category="list-text">ネットアップの All Flash FAS 向けフラッシュソリューションの利点<block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="7843ce52c43038d88c2f54d85f3f764d" category="list-text">ONTAP 9 情報ライブラリ<block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="5f1b8a708e16776ca4372c71dc377653" category="list-text">NetApp ONTAP FlexGroup Volume テクニカルレポート<block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="062d7e5979c653f33e03cb0aaeaec6e9" category="list-text">DGX-1 と Cisco Networking Design Guide による ONTAP AI<block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="59086e50189644b7c19947dfa68f8395" category="list-text">DGX-1 と Cisco Networking Deployment Guide を使用した ONTAP AI<block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="062afad089226e62b53e77ba2af24574" category="list-text">DGX-1 と Mellanox のネットワーキング設計ガイドで構成される ONTAP AI<block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="e6b737f0513721f0a8024f538058333e" category="list-text">DGX-2 を使用した ONTAP AI 設計ガイド<block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="1f9a7430deed674d394796eaea14138f" category="paragraph">本テクニカルレポートでは、小規模から大規模のデータサイエンス / エンジニアリングチームのお客様向けに、 Run ： AI CLI と NetApp ONTAP AI のシステムダッシュボードを使用して Kubernetes クラスタと GPU の使用を最適化するためのガイドラインを紹介します。また、実行： AI プラットフォームのインストール情報、テストシナリオ、検証済みのテストケース用の詳細なコマンドも記載されています。Run ： AI オーケストレーション解決策とネットアップの AI コントロールプレーンを組み合わせることで、最適なリソース利用率で開発者の生産性を向上させ、イノベーションを加速できます。</block>
  <block id="892726726d592ee18c9ee8ad25a088ae" category="inline-link-macro">次はエグゼクティブサマリーです</block>
  <block id="e6c479abab08e982bd2f0efd6e3e405a" category="paragraph"><block ref="e6c479abab08e982bd2f0efd6e3e405a" category="inline-link-macro-rx"></block></block>
  <block id="f23c532f744716d23270b963c3eca570" category="summary">Kubernetes の上で Apache の通気を確保することを推奨します。このセクションでは、 Kubernetes クラスタ内に通気を導入するために完了しておく必要のあるタスクについて説明します。</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Apache Airflow の導入</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Kubernetes クラスタをすでに使用している。</block>
  <block id="e59b39fd5c122dde3747561247eb2888" category="list-text">「 NetApp Trident の導入と構成」のセクションに記載されているように、 Kubernetes クラスタに NetApp Trident をインストールし、設定しておきます。</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Helm をインストールします</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">エアフローは、 Kubernetes の一般的なパッケージマネージャである Helm を使用して導入されます。エアーフローを導入する前に、導入ジャンプホストに Helm をインストールする必要があります。Helm を配置ジャンプホストにインストールするには、に従ってください<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> Helm の公式ドキュメントを参照してください。</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Helm を使用してエアフローを展開します</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Helm を使用して Kubernetes クラスタに通気を導入するには、導入ジャンプホストから次のタスクを実行します。</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">手順 1 の Helm を使用してエアーフローを導入したときにコンソールに出力された指示に従って、エアーフロー Web サービスの URL を取得します。</block>
  <block id="1e48409a293254dced52407be3dbb722" category="doc">Jarvis 、 Cloud Sync 、 Nemo を使用して仮想アシスタントを構築します</block>
  <block id="68dc442228015e015ca6272edb5994e4" category="inline-link-macro">次の例： Jarvis 、 Cloud Sync 、 Nemo の概要を使用して仮想アシスタントを構築します</block>
  <block id="f308b9afc8e29196ebb4fe535e29fc51" category="paragraph"><block ref="f308b9afc8e29196ebb4fe535e29fc51" category="inline-link-macro-rx"></block></block>
  <block id="3ad0505876550699ce505845f96683a7" category="doc">会話履歴をアーカイブするには、 NetApp Cloud Sync を使用します</block>
  <block id="a7e4c14a726c28e6cb4b935701ac2899" category="paragraph">会話履歴を 1 日に 1 回 CSV ファイルにダンプすることで、 Cloud Sync を利用してログファイルをローカルストレージにダウンロードできます。次の図は、オンプレミスとパブリッククラウドにジャービスを導入し、 Cloud Sync を使用して Nemo トレーニングの会話履歴を送信するアーキテクチャを示しています。Nemo の訓練の詳細はセクションで見つけることができる <block ref="14a0a4dd1a1c18cba42b2036fe4dfc33" category="inline-link-macro-rx"></block>。</block>
  <block id="e60c4461b2b4dcf3aa8535e3aab780b3" category="paragraph"><block ref="e60c4461b2b4dcf3aa8535e3aab780b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00717575e300ae9f18fa0a24d97bcca5" category="inline-link-macro">次 : Nemo の訓練を使用して設計モデルを展開しなさい</block>
  <block id="7ee8a10f8da0d566f0c5cccb9528b186" category="paragraph"><block ref="7ee8a10f8da0d566f0c5cccb9528b186" category="inline-link-macro-rx"></block></block>
  <block id="c4e7b8572218b2c9421122c7ab76be25" category="paragraph">NetApp と cnvrg.io はパートナーとして提携し、 ML および DL ソフトウェア開発向けの包括的なデータ管理解決策をお客様に提供しています。ONTAP AI は、あらゆる規模の運用に対応できる高性能なコンピューティングとストレージを提供します。 cnvrg.io ソフトウェアは、データサイエンスのワークフローを合理化し、リソース利用率を向上させます。</block>
  <block id="8537de5688b6b855ec8b5465eca4e8f6" category="list-text">NVIDIA DGX Station 、 V100 GPU 、 GPU Cloud</block>
  <block id="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link"><block ref="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link-rx"></block></block>
  <block id="432a0462f3a215c89d6067d01ac9fee8" category="list-text">NVIDIA DGX ステーション<block ref="00e84bc2760804fd15a292583676639b" category="inline-link-rx"></block></block>
  <block id="a8135dcfdfd9c1074b55895b8d51f9be" category="list-text">NVIDIA V100 Tensor コア GPU<block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="f3e44b157fa7ead37042e8a6f3b14071" category="list-text">NVIDIA NGC<block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="944c1fe2317541350506cecb6131b857" category="inline-link"><block ref="944c1fe2317541350506cecb6131b857" category="inline-link-rx"></block></block>
  <block id="d3ceb6166da1ada512f22bc7832ec047" category="list-text">NVIDIA Jarvis<block ref="34ae4389dc7afcada801d63c08e322b9" category="inline-link-rx"></block></block>
  <block id="21ce987b6ba4d344f1427dc72d497669" category="inline-link"><block ref="21ce987b6ba4d344f1427dc72d497669" category="inline-link-rx"></block></block>
  <block id="7bf7a8db8c3809766aa2579c2eadf37d" category="list-text">NVIDIA Jarvis Early Access<block ref="2daee9604c6a07f74e6776847d2ee61e" category="inline-link-rx"></block></block>
  <block id="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link"><block ref="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link-rx"></block></block>
  <block id="852c7bf0a8f3b30a5a001dbf642dbebe" category="list-text">NVIDIA Nemo<block ref="fa9e246f0ef36a285adacc70507ae974" category="inline-link-rx"></block></block>
  <block id="299a4717590cda2cfe1db321802b4995" category="inline-link"><block ref="299a4717590cda2cfe1db321802b4995" category="inline-link-rx"></block></block>
  <block id="dfc2ce4fd02d20052bebaa2e6b8cd029" category="list-text">開発者ガイド<block ref="9940ba67713949ce4f2fc05d3a37bd8c" category="inline-link-rx"></block></block>
  <block id="5467c9d1c07a7d1786936650b3c2d52a" category="list-text">NetApp AFF A シリーズのデータシート<block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="6bb399f406fc5ac4150ad21c6aa05ab2" category="list-text">ネットアップの All Flash FAS 向けフラッシュソリューションの利点<block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="9415aef2732728cc097fbbc9ab96b2fe" category="list-text">ONTAP 9 情報ライブラリ<block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="d106dc348953acc0500f03a25379282e" category="list-text">NetApp ONTAP FlexGroup Volume テクニカルレポート<block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="05dbc5885d3bec70d2317a4b51526d96" category="list-text">DGX-1 と Cisco Networking Design Guide による ONTAP AI<block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="af5797305db370f4f59d77bf7c73160b" category="list-text">DGX-1 と Cisco Networking Deployment Guide を使用した ONTAP AI<block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="f2345b2674d3976c091d4af042c36a8f" category="inline-link"><block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="f63c45f352478237d0d0fe7c5a26d6bf" category="list-text">DGX-1 と Mellanox のネットワーキング設計ガイドで構成される ONTAP AI<block ref="459df3a4bfb1f89f6920196001257745" category="inline-link-rx"></block></block>
  <block id="b38db7c217c396412f601b87dfc58a8c" category="inline-link"><block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="da8009e462fd2ec5eeb41b4cf3721f7a" category="list-text">DGX-2 を使用した ONTAP AI 設計ガイド<block ref="86d70269673ee41c37a2673f7d3655ce" category="inline-link-rx"></block></block>
  <block id="3ff1a758f526c5ceb434059efe27020a" category="doc">Apache の通気ワークフローの例</block>
  <block id="1a7fa7cc4c79d5163f691ff60e6fc34d" category="doc">「 AI Dashboards and Views 」を実行します</block>
  <block id="3473dab452c5446b1a01a923e9879461" category="paragraph">Run ： AI を Kubernetes クラスタにインストールし、コンテナを正しく設定したら、次のダッシュボードとビューが表示されます<block ref="2af90fde6f4d8ae5947b005d1208e742" category="inline-link-rx"></block> 次の図に示すように、ブラウザで設定します。</block>
  <block id="f977554b7762214959db36c20484c697" category="paragraph"><block ref="f977554b7762214959db36c20484c697" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dfd99441ce89d4be896e4fc9757f7d2" category="paragraph">2 つの DGX-1 ノードによってクラスタ内に提供される GPU は合計 16 個です。ノード数、使用可能な GPU の総数、ワークロードに割り当てられている GPU の数、実行中のジョブの総数、保留中のジョブ、およびアイドル状態に割り当てられている GPU の数を確認できます。右側のバー図は、プロジェクトごとの GPU を示しています。これは、各チームがどのようにクラスタリソースを使用しているかをまとめたものです。中央には、ジョブ名、プロジェクト、ユーザー、ジョブタイプなど、現在実行中のジョブとジョブの詳細のリストが表示されます。 各ジョブが実行されているノード、そのジョブに割り当てられている GPU の数、ジョブの現在の実行時間、ジョブの進捗状況、およびそのジョブの GPU 利用率。1 つのチーム（「 TEAM 」）から送信された実行中のジョブは 3 つしかないため、クラスタの使用率が低いことに注意してください（ GPU 使用率は 23% ）。</block>
  <block id="67545e2efac33412706ff883eff2e1c4" category="paragraph">次のセクションでは、「プロジェクト」タブで複数のチームを作成し、各チームに GPU を割り当てることで、クラスタあたりのユーザ数が多いときにクラスタの使用率を最大限に高め、リソースを管理する方法を説明します。テストシナリオは、トレーニング、推論、対話型のワークロードでメモリリソースと GPU リソースが共有されているエンタープライズ環境をシミュレートしたものです。</block>
  <block id="73eea118e4762640a7f60136f3e5c1a0" category="inline-link-macro">次のセクションでは、データサイエンスチームのプロジェクトを作成し、 GPU を割り当てる方法について説明します</block>
  <block id="7c2c470385b4f61a9e9b5b0881d2f061" category="paragraph"><block ref="7c2c470385b4f61a9e9b5b0881d2f061" category="inline-link-macro-rx"></block></block>
  <block id="efbb4ade01a09771413f4c09880e800a" category="paragraph">このセクションでは、複数のチームがワークロードを送信し、クォータを超過するシナリオを拡張します。この方法では、 Run ： AI の公正性アルゴリズムが、事前設定されたクォータの比率に従ってクラスタリソースを割り当てる方法を説明します。</block>
  <block id="3bd5af2e3a75651c4b9c45d26400fbaa" category="paragraph">このテストシナリオの目標：</block>
  <block id="cc9e23eb4fe1626d97a5dfeab7cf0d25" category="list-text">複数のチームがクォータを介して GPU を要求しているときのキューイングメカニズムを示します。</block>
  <block id="050060785f2852b203c9e82254f2946a" category="list-text">システムが、クォータの比率に従って、クォータを超過した複数のチーム間にクラスタの適正な共有を分散し、クォータが大きいチームがスペア容量の大部分を占めるようにする方法を示します。</block>
  <block id="9e06f625a31670e60f0a8a09917c3ba0" category="paragraph">の末尾 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>では、キューに入れられるワークロードは 2 つあります。 1 つは「 team -b 」用、もう 1 つは「 team -c 」用です。このセクションでは、追加のワークロードをキューに登録します。</block>
  <block id="286cda6cf9e9438a2cff2827773cfe7a" category="inline-link-macro">セクション 4.10 のテストの詳細</block>
  <block id="0e7a9992269080ceaf2b90c188cbb861" category="paragraph">ジョブの送信、使用されるコンテナイメージ、実行されるコマンドシーケンスなどの詳細については、を参照してください <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>。</block>
  <block id="b1df8ade330dd8e3c0962d87a58c1ba9" category="paragraph">すべてのジョブがセクションに従って送信される場合 <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>システム・ダッシュボードには 'team a`'team -b'および 'team -c` のすべての GPU の数が ' 事前設定されたクォータよりも多くなっていることが示されています「 team -a 」は、初期設定のソフトクォータ（ 4 ）よりも 4 基の GPU を占有し、「 team -b 」と「 team -c 」はソフトクォータ（ 2 つ）よりも 2 つの GPU を占有します。割り当てられたクォータ超過 GPU の比率は、事前設定されたクォータの比率と同じです。これは、システムが優先順位の基準として事前設定されたクォータを使用し、複数のチームがクォータを超えて GPU を追加するように要求した場合に応じてプロビジョニングされるためです。このような自動ロードバランシングは、企業のデータサイエンスチームが AI モデルの開発と運用に積極的に関与している場合に、公平性と優先順位付けを提供します。</block>
  <block id="6effcb49094093af4699b050b9994a58" category="paragraph"><block ref="6effcb49094093af4699b050b9994a58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3be1869ca88e0b5881bc6d1da583426" category="list-text">他のチームのワークロードのキュー解除が開始されます。</block>
  <block id="d2325970b5cec6b47eb2c10267e3a599" category="list-text">キュー解除の順序は ' 公正性アルゴリズムに従って決定されますたとえば 'team -b と 'team -c は ' 同等のクォータを持つため ' 同じ量のオーバークォータ GPU を取得します また 'team -a は 'team -b と 'team -c のクォータの 2 倍のクォータを備えているため 'GPU の量が 2 倍になります</block>
  <block id="e2cc28c61aaa6ca7e38bd7ed9de398f1" category="list-text">すべての割り当てが自動的に行われます。</block>
  <block id="c21d5f3e7c1336258c406bddcde6e0f8" category="paragraph">したがって、システムは次の状態で安定します。</block>
  <block id="8f2185cd998019e76038f11669cfbfb0" category="cell">GPU が割り当てられました</block>
  <block id="3b55c08436be9e1008bb19488c139c88" category="cell">8/4</block>
  <block id="f532ced5959572a93091758c821d7ff1" category="cell">クォータを介した 4 基の GPU空のキューです。</block>
  <block id="b0713292a73176f9754bd528cecde2d1" category="cell">クォータを介した 2 つの GPU 。1 つのワークロードがキューに登録</block>
  <block id="1f0189591d8d7dc1d3db367398fb49c5" category="cell">0/8</block>
  <block id="7c0de9de98eb6577a96694238e533915" category="cell">GPU をまったく使用しないので、キューに登録されているワークロードはありません</block>
  <block id="948c32bf5f56f7dd6f3b2baab5f6d89d" category="paragraph">次の図は、プロジェクトごとの GPU 割り当てを示しています Run ：セクションの AI Analytics ダッシュボードに表示される時間 <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>、 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>および <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>。図の各行は、特定のデータサイエンスチーム用にプロビジョニングされた GPU の数を常に表しています。システムは、送信されたワークロードに応じて GPU を動的に割り当てることがわかります。これにより、クラスタ内に使用可能な GPU がある場合はクォータを超過し、公平性に従ってジョブをプリエンプトしてから、 4 つのチームすべてが最終的に安定した状態に到達することができます。</block>
  <block id="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="paragraph"><block ref="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e94097f9836d70dc64016728992696a0" category="inline-link-macro">次の例： Trident でプロビジョニングされた永続的ボリュームにデータを保存する</block>
  <block id="14718f3c808034f0e3239dbaf832a478" category="paragraph"><block ref="14718f3c808034f0e3239dbaf832a478" category="inline-link-macro-rx"></block></block>
  <block id="3c97b4929008c9f4091a8070f570ccd4" category="paragraph">業界標準のベンチマークツール TensorFlow ベンチマークを使用して、このシステムの動作とパフォーマンスを検証しました。ResNet-50 のトレーニングに使用される ImageNet データセット。これは、画像分類のための有名な Convolutional Neural Network （ CNN ；畳み込みニューラルネットワーク） DL モデルです。ResNet-50 は、処理時間を短縮して正確なトレーニング結果を提供し、ストレージに対する十分な需要を喚起できます。</block>
  <block id="123704fec3ddad892d7c2ae5c4de301b" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block></block>
  <block id="56dfbb2acffcc994819cbad5ec450617" category="paragraph">このセクションでは、 ML ワークフローのデータキャッシングに関連する概念とコンポーネントについて説明します。</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="section-title">機械学習</block>
  <block id="d3f18dede1775f82df24232095090253" category="paragraph">ML は、世界中の多くの企業や組織にとって急速に不可欠になっています。そのため、 IT チームと DevOps チームは、 ML ワークロードの標準化や、 ML のジョブやパイプラインで求められる動的で負荷の高いワークフローをサポートするクラウド、オンプレミス、ハイブリッドコンピューティングリソースのプロビジョニングという課題に直面しています。</block>
  <block id="f71dfff263d05c18171dcf4b8c538ebf" category="section-title">コンテナベースの機械学習と Kubernetes</block>
  <block id="002f314c3c41ffb741f8c91d2274af9a" category="paragraph">コンテナは、共有ホストオペレーティングシステムカーネル上で実行される独立したユーザスペースインスタンスです。コンテナの採用が急速に増加しています。コンテナは、仮想マシン（ VM ）が提供するものと同じアプリケーションのサンドボックス化のメリットの多くを提供します。ただし、 VM が依存するハイパーバイザーレイヤとゲストオペレーティングシステムレイヤが排除されているため、コンテナの軽量化が大幅に向上しています。</block>
  <block id="ce8bb3a31abf8bfcdcdacb34d96b010a" category="paragraph">コンテナを使用すると、アプリケーションの依存関係や実行時間などをアプリケーションで直接効率的にパッケージングできます。最も一般的に使用されるコンテナパッケージ形式は Docker コンテナです。Docker コンテナ形式でコンテナ化されたアプリケーションは、 Docker コンテナを実行できる任意のマシンで実行できます。これは、アプリケーションの依存関係がマシンに存在しない場合でも当てはまります。これは、すべての依存関係がコンテナ自体にパッケージ化されているためです。詳細については、を参照してください<block ref="5b5112034c22f544bc19c7a568afbfcb" category="inline-link-rx"></block>。</block>
  <block id="cfbe31a3e8ac3348240670510232ed8f" category="paragraph">人気のあるコンテナオーケストレーションツールである Kubernetes を使用すると、データサイエンティストは柔軟なコンテナベースのジョブとパイプラインを開始できます。また、インフラチームは、管理された単一のクラウドネイティブ環境で ML ワークロードを管理および監視できます。詳細については、を参照してください<block ref="45556eaecf73275e38fa694031a104a3" category="inline-link-rx"></block>。</block>
  <block id="371ac536e4099ad82f6080b713ce9647" category="paragraph">cnvrg.io は、企業が AI やデータサイエンスの開発を研究から生産に至るまで管理、拡張、高速化する方法を変革する AI オペレーティングシステムです。コードファーストのプラットフォームは、データサイエンティストがデータサイエンティストのために構築し、オンプレミスとクラウドのどちらでも実行できる柔軟性を提供します。モデル管理、 MLOps 、継続的な ML ソリューションを備えた cnvrg.io は、データサイエンスチームに最先端のテクノロジを提供します。そのため、 DevOps に費やす時間を短縮し、真の魔法のアルゴリズムに集中できます。cnvrg.io を使用して以来、さまざまな業界のチームが生産モデルを増やし、ビジネス価値を高めてきました。</block>
  <block id="ffb1d184fa3790eda48f1fc2d9c2f821" category="section-title">cnvrg.io メタスケジューラ</block>
  <block id="55fdc117823776b1ebb2170b4adfadf6" category="paragraph">cnvrg.IO には独自のアーキテクチャがあり、 IT エンジニアは異なるコンピューティングリソースを同じコントロールプレーンに接続し、すべてのリソースにわたって cnvrg.io で ML ジョブを管理できます。つまり、次の図に示すように、複数のオンプレミス Kubernetes クラスタ、 VM サーバ、クラウドアカウントを接続し、すべてのリソースで ML ワークロードを実行できます。</block>
  <block id="3c7fcf7e73eda18d7277b14914857f38" category="paragraph"><block ref="3c7fcf7e73eda18d7277b14914857f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cfff0196a077e92a8fe9326f97cb7fc5" category="section-title">cnvrg.io データキャッシング</block>
  <block id="ad693e5ee82f0e0486a136821d0a0779" category="paragraph">cnvrg.io を使用すると、データサイエンティストは、データキャッシングテクノロジを使用して、ホットデータセットとコールドデータセットのバージョンを定義できます。デフォルトでは、データセットは一元化されたオブジェクトストレージデータベースに格納されます。データサイエンティストは、選択したコンピューティングリソースに特定のデータバージョンをキャッシュして、ダウンロード時間を節約し、 ML の開発と生産性を向上させることができます。数日間キャッシュされていないデータセットは、選択した NFS から自動的に消去されます。キャッシュのキャッシュとクリアはワンクリックで実行でき、コーディング、 IT 、 DevOps の作業は必要ありません。</block>
  <block id="42cf1b27f88752e1e98918981aa76e41" category="section-title">cnvrg.io フローと ML パイプライン</block>
  <block id="1bc2ab6c98ec5b23a8a384861da1c6ca" category="paragraph">cnvrg.io フローは、本番 ML パイプラインを構築するためのツールです。フロー内の各コンポーネントは、ベースとなる Docker イメージを使用して選択したコンピューティング上で実行されるスクリプト / コードです。この設計により、データサイエンティストとエンジニアは、オンプレミスとクラウドの両方で実行できる単一のパイプラインを構築できます。cnvrg.io は、データ、パラメータ、およびアーティファクトが異なるコンポーネント間で移動していることを確認します。さらに、各フローを監視して追跡することで、再現性の高い 100% のデータサイエンスを実現します。</block>
  <block id="87cd11047488d3aa87eb2829eeb02305" category="section-title">cnvrg.io コア</block>
  <block id="526c8ebff3057ce85f47160f32e15556" category="paragraph">cnvrg.io コアは、データサイエンスコミュニティが DevOps よりもデータサイエンスに集中できるようにするための無償プラットフォームです。コアの柔軟なインフラストラクチャにより、データサイエンティストは、オンプレミスでもクラウドでも、あらゆる言語、 AI フレームワーク、コンピューティング環境を使用することができます。これにより、最適な処理を実行し、アルゴリズムを構築できます。cnvrg.io コアは、任意の Kubernetes クラスタ上で 1 つのコマンドを使用して簡単にインストールできます。</block>
  <block id="f92894a2a2633c488de71d74ace474d7" category="paragraph">ONTAP AI は、 ML ワークロードとディープラーニング（ DL ）ワークロード向けのデータセンターリファレンスアーキテクチャであり、 Tesla V100 GPU を搭載した NetApp AFF ストレージシステムと NVIDIA DGX システムを使用します。ONTAP AI は、業界標準の NFS ファイルプロトコルである 100Gb イーサネットを基盤としており、標準的なデータセンターテクノロジを使用して実装や管理のオーバーヘッドを軽減する、ハイパフォーマンスな ML / DL インフラを提供します。標準化されたネットワークとプロトコルを使用することで、 ONTAP AI をハイブリッドクラウド環境に統合しながら、運用の一貫性と簡易性を維持できます。解決策 AI は、事前検証済みのインフラ ONTAP として、導入にかかる時間とリスクを削減し、管理オーバーヘッドを大幅に削減することで、お客様はより短期間で価値を実現できます。</block>
  <block id="c2148c4c14a795b271b67f662900da4e" category="paragraph">Trident は、ネットアップが開発および管理しているオープンソースのストレージオーケストレーションツールで、 Kubernetes ワークロード向けの永続的ストレージの作成、管理、使用を大幅に簡易化します。Trident 自体は Kubernetes ネイティブのアプリケーションであり、 Kubernetes クラスタ内で直接実行されます。Trident を使用すると、 Kubernetes のユーザ（開発者、データサイエンティスト、 Kubernetes 管理者など）は、使い慣れた標準的な Kubernetes 形式で永続ストレージボリュームを作成、管理、操作できます。同時に、ネットアップの高度なデータ管理機能と、ネットアップテクノロジを基盤とするデータファブリックを活用できます。Trident は、複雑な永続的ストレージを抽象化して、消費を簡易化します。詳細については、を参照してください<block ref="c98bfcab9052a99136f8752a5ac8ed0b" category="inline-link-rx"></block>。</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetApp StorageGRID</block>
  <block id="ecfefbd82f34239e668be7aac3762226" category="paragraph">NetApp StorageGRID は、ユーザが S3 プロトコルを使用してアクセスできるシンプルなクラウド型ストレージを提供することで、これらのニーズを満たすように設計された Software-Defined オブジェクトストレージプラットフォームです。StorageGRID は、距離に関係なく、インターネットに接続されたサイト全体で複数のノードをサポートするように設計されたスケールアウトシステムです。StorageGRID のインテリジェントポリシーエンジンを使用すると、サイト間でイレイジャーコーディングオブジェクトを選択して地理的な耐障害性を確保したり、リモートサイト間でオブジェクトレプリケーションを行ったりすることで、 WAN アクセスのレイテンシを最小限に抑えることができます。StorageGRID は、この解決策にある優れたプライベートクラウドプライマリオブジェクトストレージデータレイクを提供します。</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="section-title">NetApp Cloud Volumes ONTAP の略</block>
  <block id="c060a6548f860aa739b76c0178ac7c5c" category="paragraph">NetApp Cloud Volumes ONTAP データ管理ソフトウェアは、 AWS 、 Google Cloud Platform 、 Microsoft Azure などのパブリッククラウドプロバイダの柔軟性を活かして、ユーザデータの制御、保護、効率化を実現します。Cloud Volumes ONTAP は、 NetApp ONTAP ストレージソフトウェアを基盤としたクラウドネイティブなデータ管理ソフトウェアで、クラウドデータのニーズに対応する、汎用性に優れた優れたストレージプラットフォームをユーザに提供します。クラウドとオンプレミスで同じストレージソフトウェアを使用することで、ユーザはデータファブリックの価値を活用できます。まったく新しいデータ管理方法について IT 担当者をトレーニングする必要はありません。</block>
  <block id="e16f1943a363dfa46a958bd450c2ecf8" category="paragraph">ハイブリッドクラウドの導入モデルに関心があるお客様は、 Cloud Volumes ONTAP を使用することで、ほとんどのパブリッククラウドで同じ機能とクラス最高のパフォーマンスを実現し、一貫したシームレスなユーザエクスペリエンスをあらゆる環境で実現できます。</block>
  <block id="82ac5cdab15b3954389238dddbc12168" category="paragraph"><block ref="82ac5cdab15b3954389238dddbc12168" category="inline-link-macro-rx"></block></block>
  <block id="d993b502abe38cef7c7256291e3ffa8e" category="paragraph">次の表に、解決策の実装に必要なハードウェアコンポーネントを示します。解決策の特定の実装で使用されるハードウェアコンポーネントは、お客様の要件に応じて異なる場合があります。</block>
  <block id="4c2db3e48f4f33a355c8e493453b53c2" category="inline-link-macro">次の手順：ソフトウェア要件</block>
  <block id="54870296c311c566be3a76b4a4df8e8c" category="paragraph"><block ref="43a6574de87222e6a8a22c8138fc4c45" category="inline-link-macro-rx"></block>。</block>
  <block id="48fe531f68f98f9f6afcf79da6d3b1b3" category="doc">TR-4834 ：『 NetApp and Iguazio for MLRun Pipeline 』</block>
  <block id="a0e5bba9c75f65c1d58c6a238316bd2b" category="paragraph">Rick Huang 氏、 David Arnette 氏、 NetApp Marcelo Litovsky 氏、 Iguazio 氏</block>
  <block id="dd9508a891c15cc4bb34f03dc870ab6c" category="paragraph">本ドキュメントでは、 NetApp ONTAP AI 、 NetApp AI コントロールプレーン、 NetApp Cloud Volume ソフトウェア、 Iguazio データサイエンスプラットフォームを使用した MLRun パイプラインの詳細について説明します。サーバレス機能の Nuclio 、 Kubernetes Persistent Volume 、 NetApp Cloud Volume 、 NetApp Snapshot コピー、 Grafana ダッシュボード、 および Iguazio プラットフォーム上のその他のサービスにより、ネットワーク障害検出のシミュレーション用のエンドツーエンドのデータパイプラインを構築できます。イグアスとネットアップのテクノロジを統合し、オンプレミスだけでなくクラウドでも、迅速なモデル導入、データレプリケーション、本番環境の監視を実現しました。</block>
  <block id="d431a0ad3e0e99cf99c08fda529884bd" category="paragraph">データサイエンティストの仕事は、機械学習（ ML ）モデルと人工知能（ AI ）モデルのトレーニングと調整に集中する必要があります。しかし、 Google の調査によると、データサイエンティストは、 AI / ML ワークフローでのモデル開発を示す次の図に示すように、モデルをエンタープライズアプリケーションで使用し、大規模に実行する方法を検討する時間の約 80% を費やしています。</block>
  <block id="f08b641e59dba6d999dc1bc2085bcd2c" category="paragraph"><block ref="f08b641e59dba6d999dc1bc2085bcd2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eec0363d19df86d30ecefc2e44170fa" category="paragraph">エンドツーエンドの AI / ML プロジェクトを管理するには、エンタープライズコンポーネントについてより広範な理解が必要です。DevOps ではこのような種類のコンポーネントの定義、統合、導入が引き継がれていますが、機械学習の運用では、 AI / ML プロジェクトを含む同様のフローがターゲットとなります。エンドツーエンドの AI / ML パイプラインが企業内でどのように影響するかを知るには、次の必要なコンポーネントのリストを参照してください。</block>
  <block id="ea2ef9b0d095bf991f4973633b485340" category="list-text">データベース</block>
  <block id="3b18b13f059019d19211f8a9f36f7e4e" category="list-text">ファイルシステム</block>
  <block id="d6c823008f20bbfce5f39b30ec9fa918" category="list-text">継続的統合 / 継続的導入（ CI / CD ）パイプライン</block>
  <block id="52681719ec1296447ae0e357c4781415" category="list-text">開発統合開発環境（ IDE ）</block>
  <block id="2fae32629d4ef4fc6341f1751b405e45" category="list-text">セキュリティ</block>
  <block id="bd0992d43bb2d0ca676184502e14754e" category="list-text">データアクセスポリシー</block>
  <block id="c8e2277ecfb1427838c488c217f99466" category="list-text">クラウド</block>
  <block id="a9353b1bd1eeedb788a74090b5f8d0bc" category="list-text">データサイエンスのツールセットとライブラリ</block>
  <block id="2f0ff7df4fd6fa99bbf249af2ea4c3a5" category="paragraph">本書では、ネットアップと Iguazio のパートナーシップによってエンドツーエンドの AI / ML パイプラインの開発が大幅に簡易化されたことを紹介します。この簡易化により、 AI / ML アプリケーションの市場投入までの時間が短縮されます。</block>
  <block id="253411380ba9cde08bcfafbd516ad585" category="paragraph">データサイエンスの世界は、情報技術とビジネスのさまざまな分野に影響をもたらしています。</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">データサイエンティストは、選択したツールとライブラリを柔軟に使用できる必要があります。</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">データエンジニアは、データの流れと配置場所を把握する必要があります。</block>
  <block id="c12281f5ea7b17e370414efbf3f26c30" category="list-text">DevOps エンジニアは、新しい AI / ML アプリケーションを CI / CD パイプラインに統合するためのツールを必要としています。</block>
  <block id="f1a4e0eca545ebe9e3c32f1fde407410" category="list-text">ビジネスユーザは、 AI / ML アプリケーションにアクセスしたいと考えています。ネットアップと Iguazio がどのようにしてプラットフォームのビジネスに価値をもたらすかを説明します。</block>
  <block id="00cc9e5c959e62a9132baca479060db3" category="paragraph">この解決策は、 AI / ML アプリケーションのライフサイクルに従います。まず、データサイエンティストの仕事から始めて、データの前処理やモデルのトレーニングと導入に必要なさまざまな手順を定義します。成果物の追跡、実行の実験、 Kubeflow への導入が可能な、完全なパイプラインの構築に必要な作業をフォローしています。このサイクルを完了するには、パイプラインと NetApp Cloud Volume を統合し、次の図に示すようにデータのバージョン管理を可能にします。</block>
  <block id="ddd4a11ec23c52d3f0831809bc4d7c8f" category="paragraph"><block ref="ddd4a11ec23c52d3f0831809bc4d7c8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7c8cd7998e5c4a67923acf8580d94e2" category="inline-link-macro">次のステップ：テクノロジの概要</block>
  <block id="b9023dede6231d8f57593d31db930bf6" category="paragraph"><block ref="b9023dede6231d8f57593d31db930bf6" category="inline-link-macro-rx"></block></block>
  <block id="2e4fd4a404800f52299c132a3403dc72" category="cell">インフラストラクチャコンポーネント</block>
  <block id="64d354dc5879cf570ce7b4ef676e75bd" category="cell">オペレーティングシステム</block>
  <block id="4152ac69f367cb5f64dfbc247dd41db0" category="cell">展開ジャンプホスト</block>
  <block id="583a65df9db4119165f5ea0abaa50281" category="cell">VM</block>
  <block id="f341fd2fe180518e152be2d6fb4ec20b" category="cell">Kubernetes マスターノード</block>
  <block id="a89c263b82f7c7f61c9b6c93080f8425" category="cell">Kubernetes ワーカーノード</block>
  <block id="f89b34b046a8d6e3137c95861fa3cf8a" category="cell">NVIDIA DGX-1 （ベアメタル）</block>
  <block id="eba551f3f972830c55b1c9bef15b5f26" category="cell">NVIDIA DGX OS 4.0.5 （ Ubuntu 18.04.2 LTS に基づく）</block>
  <block id="0911ffdbb76c891f964e39a07eb6b697" category="cell">1 つの HA ペア</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">ソフトウェアコンポーネント</block>
  <block id="9ba69bd971d430b368ce3f0286c8e77c" category="cell">Apache Airflow Helm チャート</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">サポート</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link">ネットアップにお問い合わせください</block>
  <block id="a1773dfa99aa26853e90886d55e0d05a" category="paragraph">ネットアップは、 Apache Airflow 、 Docker 、 Kubeflow 、 Kubernetes 、 NVIDIA DeepOps のエンタープライズサポートを提供していません。ネットアップの AI コントロールプレーン解決策と同様の機能を備えた、完全にサポートされている解決策に関心がある場合： <block ref="103a4ac9affe57bb7edb7796bfdeb684" category="inline-link-rx"></block> ネットアップがパートナー様と共同で提供する、完全にサポートされている AI / ML ソリューションについて説明します。</block>
  <block id="3cfbc3bac23f6bb9e7ebdc6deefeaf1d" category="paragraph">ネットアップと NVIDIA が開発、検証した NetApp ONTAP AI アーキテクチャは、 NVIDIA DGX システムとネットアップのクラウド対応ストレージシステムを基盤としています。このリファレンスアーキテクチャには、 IT 組織に次のようなメリットがあります。</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">は、さまざまなパフォーマンスとに対応するさまざまなストレージオプションを提供します コストポイント</block>
  <block id="6fa0f6cc1d5d12069641e73217a17be2" category="paragraph">NetApp ONTAP AI は、 DGX システムと NetApp AFF A800 ストレージシステムを最先端のネットワークと緊密に統合します。NetApp ONTAP AI システムと DGX システムでは、設計の複雑さと推測に頼らず、 AI 導入を簡易化できます。お客様は小規模構成から始めて、システムを中断なく拡張できます。同時に、エッジ、コア、クラウドにわたってデータをインテリジェントに管理できます。</block>
  <block id="bdc094a519f73076386a8bf2948832a6" category="paragraph">ネットアップの AI コントロールプレーンは、データサイエンティストとデータエンジニアを対象とした、フルスタックの AI 、 ML 、ディープラーニング（ DL ）のデータと実験管理解決策です。AI の利用が拡大するにつれて、ワークロードの拡張性やデータの可用性など、さまざまな課題が生じています。NetApp AI コントロールプレーンは、データネームスペースの迅速なクローニングを Git レポジトリと同様に行う機能や、トレーサビリティとバージョン管理のためにデータやモデルベースラインをほぼ瞬時に作成する AI トレーニングワークフローを定義して実装するなど、これらの課題に対処します。NetApp AI コントロールプレーンを使用すると、サイトやリージョン間でデータをシームレスにレプリケートし、 Jupyter Notebook ワークスペースをすばやくプロビジョニングして、大規模なデータセットにアクセスできます。</block>
  <block id="22101b8498dea1c2e2e35bd4868847a4" category="paragraph">実行： AI は、世界初の AI インフラストラクチャのオーケストレーションおよび仮想化プラットフォームを構築しました。基盤となるハードウェアからワークロードを抽象化することで、 Run ： AI は、 GPU リソースの共有プールを作成します。この共有プールを動的にプロビジョニングし、 AI ワークロードの効率的なオーケストレーションと GPU の使用の最適化を実現します。データサイエンティストは、大量の GPU パワーをシームレスに消費して研究を向上させ、加速させることができます。一方、 IT チームは、リソースのプロビジョニング、キューイング、利用率に関する一元化されたクロスサイト管理とリアルタイムの可視性を維持します。Run ： AI プラットフォームは Kubernetes を基盤として構築されているため、既存の IT ワークフローやデータサイエンスワークフローと簡単に統合できます。</block>
  <block id="ae00256db8d45ecdaf9c364a96821417" category="paragraph">Run ： AI プラットフォームには、次のようなメリットがあります。</block>
  <block id="d472807c15e94ef6053e95521ff7e838" category="list-text">* イノベーションにかかる時間を短縮 * Run ： AI リソースのプール化、キューイング、優先付けのメカニズムをネットアップストレージシステムと組み合わせることで、研究者たちはインフラ管理の苦労から取り取り除かれ、データサイエンスに専念することができます。実行： AI とネットアップのお客様は、コンピューティングやデータパイプラインのボトルネックを発生させることなく、必要な数のワークロードを実行することで生産性を向上できます。</block>
  <block id="2707d068deb9b46967615c70c806e0d8" category="list-text">* チームの生産性向上。 * 実行： AI 公正性アルゴリズムにより、すべてのユーザーとチームが公平なリソースを共有できるようになります。優先度の高いプロジェクトを中心としたポリシーをあらかじめ設定しておくことで、あるユーザやチームから別のユーザやチームにリソースを動的に割り当てることができ、誰もが切望した GPU リソースにタイムリーにアクセスできるようになります。</block>
  <block id="faa5854c7e84507b88cba1c0ec1a9aaf" category="list-text">* GPU 利用率の向上。 * 実行： AI スケジューラを使用すると、 Kubernetes での分散トレーニング用に、フラクショナルな GPU 、整数型 GPU 、複数の GPU ノードを簡単に利用できます。このように、 AI ワークロードは容量ではなくニーズに基づいて実行されます。データサイエンスチームは、 1 つのインフラでより多くの AI 実験を実行できるようになります。</block>
  <block id="d9533ea5c6cb975dff314dace88f2aa4" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block></block>
  <block id="9abac747d764180a5fe55920e00e887d" category="section-title">お客様にもたらされる価値</block>
  <block id="45ce76bfe721ca13d37ca15fdbebd391" category="paragraph">このホワイトペーパーに貢献したことを、 NVIDIA の著名な同僚によって認められたことに感謝の意を表します。 Davide Onfrio 、 Alex Qi 、 Sicong Ji 、 Marty Jain 、 Robert Sohigian 。また、ネットアップの主要チームメンバーである Santosh Rao 、 David Arnette 、 Michael Oglesby 、 Brent Davis 、 Andy Sayare の協力も感謝しています。 Erik Mulder 氏、 Mike McNamara 氏。</block>
  <block id="81fbc4247f2c3a990b090cef6b9ebe03" category="paragraph">本ホワイトペーパーの作成に大きく貢献した洞察と専門知識を提供したすべての方々に心から感謝します。</block>
  <block id="bc2f62a5c14dc9d16f38cc32c304164c" category="paragraph"><block ref="bc2f62a5c14dc9d16f38cc32c304164c" category="inline-link-macro-rx"></block></block>
  <block id="25edd21a28cb2fca00ab6f30e47c6d79" category="paragraph">サンプルの推論要求を実行するには、次の手順を実行します。</block>
  <block id="cb11a85322b32a7615367d2523718b49" category="list-text">クライアントコンテナ / ポッドへのシェルを取得します。</block>
  <block id="b489ec265fd981ff7aa78a7721bd3101" category="list-text">サンプルの推論要求を実行します。</block>
  <block id="15c5e1ffe753f0365f39e7b508ce5ae0" category="paragraph"><block ref="15c5e1ffe753f0365f39e7b508ce5ae0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5bf2ae3a2d0d1dd1e0740744c9ebb1b" category="paragraph">この推論要求は、イメージ認識に使用される「 re snet50_netdef」 モデルを呼び出します。他のクライアントも、同様のアプローチに従って適切なモデルを発信することで、推論要求を同時に送信できます。</block>
  <block id="a301641e2c9595a0c9c39ee7986f7ca8" category="paragraph"><block ref="a301641e2c9595a0c9c39ee7986f7ca8" category="inline-link-macro-rx"></block></block>
  <block id="76ada3ea43b0e44772967793fe69b1bd" category="inline-link">Kubernetes 導入ガイド</block>
  <block id="03628142cdc704dd6ffe5d7d13573999" category="list-text">の手順に従って、クラスタに Kubernetes を導入します 。<block ref="cdf0a6d71dcbe898357c0e37010d30de" category="inline-link-rx"></block> NVIDIA DeepOps GitHub サイトで入手できます。</block>
  <block id="c6fff1434177c1b95244b5300314f730" category="paragraph">配備に失敗した場合は 'kubectl_localhost' の値を 'd eepops/config/group_vars/k8s-cluster.yml' で false に変更し ' 手順 2 を繰り返します'Copy kubectl binary to Ansible host' タスクは 'kubectl_localhost' の値が true の場合にのみ実行され ' メモリ使用に関する既知の問題がある FETCH Ansible モジュールに依存しますこのようなメモリ使用の問題により、原因がタスクを失敗させることがあります。メモリ問題が原因でタスクが失敗した場合は、以降の導入処理は正常に完了しません。</block>
  <block id="24e1fa4c913dcdc975e022f921d4d603" category="paragraph">「 kubectl_localhost 」の値を「 false 」に変更した後で展開が正常に完了した場合、「 kubectl binary 」を Kubernetes マスターノードから配備ジャンプホストに手動でコピーする必要があります。特定のマスター・ノード上で 'kubectl binary' の場所を確認するには 'which kubectl' コマンドをそのノード上で直接実行します</block>
  <block id="a185054da23018c3578742c41141312b" category="inline-link-macro">次の例： Cnvrg.io の導入</block>
  <block id="c18b567a6a5397941715c30a00a97395" category="paragraph"><block ref="c18b567a6a5397941715c30a00a97395" category="inline-link-macro-rx"></block></block>
  <block id="d7cd7846436814deb26b0df06d7a4b2a" category="summary">Kubernetes クラスタでマルチノードの AI と ML の同期ジョブを実行するには、導入ジャンプホストでこのページにリストされているタスクを実行します。このプロセスにより、ネットアップボリュームに格納されているデータを活用し、 1 つのワーカーノードで提供されるものよりも多くの GPU を使用することができます。</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">分散型 AI の同期ワークロードを実行します</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Kubernetes クラスタでマルチノードの AI と ML の同期ジョブを実行するには、導入ジャンプホストで次のタスクを実行します。このプロセスにより、ネットアップボリュームに格納されているデータを活用し、 1 つのワーカーノードで提供されるものよりも多くの GPU を使用することができます。同期分散 AI ジョブの説明については、次の図を参照してください。</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">同期分散ジョブを使用すると、非同期分散ジョブに比べてパフォーマンスとトレーニングの精度が向上します。同期ジョブと非同期ジョブの長所と短所については、本ドキュメントでは説明していません。</block>
  <block id="262523fcbe6eb0ec96ea58299e58f65c" category="paragraph"><block ref="262523fcbe6eb0ec96ea58299e58f65c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a9af10e4883efa64de927027b5b0ffa" category="list-text">次のコマンド例は、 1 つのワーカーの作成を示しています これは、同じの同期分散実行に関与します 1 つのノードで実行された TensorFlow ベンチマークジョブ を参照してください <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>。この例では、 2 つのワーカーノードでジョブが実行されるため、導入されるワーカーは 1 つだけです。</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">この例のワーカー導入では、 8 個の GPU を要求し、 8 個以上の GPU を搭載した 1 つの GPU ワーカーノードで実行できます。GPU ワーカーノードが 8 個以上の GPU を搭載している場合、パフォーマンスを最大化するには、この数をワーカーノードが機能する GPU の数と同じにすると便利です。Kubernetes の導入の詳細については、を参照してください<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block>。</block>
  <block id="bfe89db11adc9a38165e670f3062d398" category="paragraph">この例では、このコンテナ化された特定のワーカーが自分で完了することはないため、 Kubernetes 環境が作成されます。そのため、 Kubernetes のジョブ構造を使用して導入することは理にかなっていません。従業員が自分で設計または作成した場合、作業構成を使用して従業員を配置することが理にかなっている場合があります。</block>
  <block id="05bdf5435b916b7b205f448788324f2b" category="paragraph">この配置例の仕様で指定されているポッドには 'hostNetwork' の値が true に設定されていますこの値は、ポッドが、 Kubernetes が各ポッドに通常作成する仮想ネットワーキングスタックではなく、ホストワーカーノードのネットワークスタックを使用することを意味します。このアノテーションは、特定のワークロードが Open MPI 、 NCCL 、 Horovod を使用して同期分散方法でワークロードを実行するために使用されます。そのため、ホストネットワークスタックにアクセスする必要があります。Open MPI 、 NCCL 、および Horovod についての説明は、本ドキュメントの範囲外です。この hostNetwork:true' 注釈が必要かどうかは ' 実行している特定のワークロードの要件によって決まります「 hostNetwork 」フィールドの詳細については、を参照してください<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block>。</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">手順 1 で作成したワーカー導入が正常に起動したことを確認します。次のコマンド例は、導入定義に示すように、単一のワーカーポッドが導入用に作成されたこと、およびこのポッドが GPU ワーカーノードの 1 つで現在実行されていることを確認します。</block>
  <block id="3ba975f6a7389af18602f0e938bcc37b" category="list-text">マルチノード同期ジョブの実行を開始して参加させ、追跡するマスター用の Kubernetes ジョブを作成します。次のコマンド例では、 1 つのマスターを作成します。このマスターは、セクションの例で 1 つのノード上で実行された、同じ TensorFlow ベンチマークジョブの同期分散実行を追跡し、開始します <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>。</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">この例では、マスタージョブは 8 個の GPU を要求するため、 8 個以上の GPU を搭載した 1 つの GPU ワーカーノードで実行できます。GPU ワーカーノードが 8 個以上の GPU を搭載している場合、パフォーマンスを最大化するには、この数をワーカーノードが機能する GPU の数と同じにすると便利です。</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">この例のジョブ定義で指定されているマスターポッドには、手順 1 でワーカーポッドに「 hostNetwork 」の値「 true 」が与えられたのと同様に、「 hostNetwork 」の値が「 true 」に設定されます。この値が必要な理由については、手順 1 を参照してください。</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">手順 3 で作成したマスタージョブが正しく実行されていることを確認します。次のコマンド例では、ジョブ定義に示されているように、ジョブに対して単一のマスターポッドが作成され、このポッドが GPU ワーカーノードの 1 つで現在実行されていることを確認します。また、手順 1 で最初に確認したワーカーポッドがまだ実行中で、マスターポッドとワーカーポッドが別々のノードで実行されていることも確認する必要があります。</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">手順 3 で作成したマスタージョブが正常に完了したことを確認します。次のコマンド例は、ジョブが正常に完了したことを確認します。</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">不要になったワーカー配置を削除します。次のコマンド例は、手順 1 で作成したワーカー配置オブジェクトの削除を示しています。</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">ワーカー導入オブジェクトを削除すると、関連付けられているワーカーポッドは Kubernetes によって自動的に削除されます。</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">* オプション： * マスタージョブアーティファクトをクリーンアップします。次のコマンド例は、手順 3 で作成したマスタージョブオブジェクトの削除を示しています。</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">マスタージョブオブジェクトを削除すると、関連付けられているマスターポッドは Kubernetes によって自動的に削除されます。</block>
  <block id="89447eb7454239e11376250fa04a88f7" category="inline-link">Windows 環境で clustered Data を使用して SAP と Microsoft SQL Server を運用 ONTAP</block>
  <block id="3d45b043c5518eca1e47fb4ba8a813da" category="inline-link-macro">RHEL に CLI を導入するための Ansible Control Node をセットアップします /CentOS</block>
  <block id="2afb5cc3404c6c8162722fd41895c2de" category="inline-link-macro">Ubuntu で CLI 環境に Ansible Control Node をセットアップします /Debian</block>
  <block id="6b8c64be0bad88fb867c6576ac777b25" category="inline-link-macro">タワー / AWX 環境用の Ansible タワーまたは AWX をセットアップします</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="inline-link">ネットアップの AI ソリューション</block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link">MLOps の 1 つです</block>
  <block id="fcf140abed196b8eba71c45f21312bce" category="doc">ネットアップのソリューション</block>
  <block id="c6aaad7e04b9605d83a2a2aa661fc1b4" category="summary">ネットアップの VDS を使用して、管理者はタスクを他のユーザに委譲できます。導入したサーバに接続して、トラブルシューティングを行ったり、ログを表示したり、監査レポートを実行したりできます。お客様をサポートしながら、ヘルプデスクまたはレベル 3 の技術者は、ユーザセッションのシャドウイング、プロセスリストの表示、必要に応じたプロセスの強制終了を行うことができます。</block>
  <block id="3a1e041969ddc2d8e0e399260d9159a7" category="doc">Login VSI を使用した単一サーバの負荷テスト</block>
  <block id="12d80b6f529069c8b2bc8d45947a0379" category="paragraph">NetApp Virtual Desktop Service は、 Microsoft Remote Desktop Protocol を使用して仮想デスクトップのセッションとアプリケーションにアクセスし、 Login VSI ツールは特定のサーバモデルでホストできるユーザの最大数を決定します。Login VSI は、特定の間隔でのユーザログインをシミュレートし、ドキュメントのオープン、メールの読み書き、 Excel および PowerPoint での作業、ドキュメントの印刷、ファイルの圧縮、ランダムな切断などのユーザ操作を実行します。その後、応答時間を測定します。サーバの使用率が低い場合はユーザの応答時間が短く、ユーザセッションが追加されると応答時間が長くなります。Login VSI は、初回のユーザログインセッションに基づいてベースラインを決定し、ベースラインからのユーザ応答が 2 秒を超えると最大ユーザセッション数を報告します。</block>
  <block id="481e9968651d6bd0d36d67a776a0f32a" category="paragraph">次の表に、この検証で使用したハードウェアを示します。</block>
  <block id="e93f994f01c537c4e2f7d8528c3eb5e9" category="cell">カウント</block>
  <block id="8417ade953d75aa6fa3c64813e005e17" category="cell">NetApp HCI H610C</block>
  <block id="ec1d568aa57f1e1231acef5759640fc6" category="cell">ランチャー、 AD 、 DHCP など用のクラスタ内に 3 つ1 台のサーバで負荷テストを実施します。</block>
  <block id="5b68b81817d64cfa84c65e2e185efe97" category="cell">NetApp HCI H615C</block>
  <block id="c36af9ab64be0b8bd4d5097f58b8a5ba" category="cell">2x24C Intel Xeon Gold 6282 @ 2.1GHz 。1.5TB の RAM 。</block>
  <block id="825c03a9f78635bec804883dde1bd6bf" category="paragraph">次の表に、この検証に使用するソフトウェアを示します。</block>
  <block id="f5bf48aa40cad7891eb709fcf1fde128" category="cell">プロダクト</block>
  <block id="f80ee94fe4a9c10f8d85e442e7521687" category="cell">NetApp VDS 5.4</block>
  <block id="d9cc1f843ea62c12a3e59afbbdc2f9ce" category="cell">オーケストレーション</block>
  <block id="bb15f84d3b96a9b33719b8a71bc62207" category="cell">VM テンプレート Windows 2019 1809</block>
  <block id="f6a3c0d463e2ae697b02a9893e2062a3" category="cell">RDSH のためのサーバ OS</block>
  <block id="5a264c4e5b7b75d4ead67bf3ff7988bc" category="cell">Login VSI</block>
  <block id="5227da0541209a94c7dc0a07cf3e0740" category="cell">4.1.32.1</block>
  <block id="123995603a5e237810bf85a8e3c73f2e" category="cell">VMware vSphere 6.7 Update 3</block>
  <block id="2752fcc90cb7cc7439b827d762e89166" category="cell">VMware vCenter 6.7 Update 3F</block>
  <block id="436bc441be68b676a199df5c1ea02263" category="cell">VMware 管理ツール</block>
  <block id="9ad541af6dac1be0c6655522128a386c" category="paragraph">Login VSI のテスト結果は次のとおりです。</block>
  <block id="17126aef3e415713552604218f448967" category="cell">VM の設定</block>
  <block id="084abcce930cefa047af15fc0836639a" category="cell">Login VSI のベースライン</block>
  <block id="8bb9799dff9f679e2305879f7dc1a9f0" category="cell">Login VSI の最大値</block>
  <block id="e49775052ecbe49b489c84d0b09e916e" category="cell">H610C</block>
  <block id="a9cc7da7b66d8162a44a176bb1109440" category="cell">vCPU 8 基、 48GB RAM 、 75GB ディスク、 8Q vGPU プロファイル</block>
  <block id="28267ab848bcf807b2ed53c3a8f8fc8a" category="cell">799</block>
  <block id="8f85517967795eeef66c225f7883bdcb" category="cell">178</block>
  <block id="bd40934d28717a37aa4087f1622d8f0b" category="cell">H615C</block>
  <block id="4052d2c7017812dc33333a4dc7e83dc9" category="cell">vCPU × 12 、 128GB の RAM 、 75GB のディスク</block>
  <block id="eefc9e10ebdc4a2333b42b2dbb8f27b6" category="cell">763.</block>
  <block id="7a614fd06c325499f1680b9896beedeb" category="cell">272</block>
  <block id="71c62dd6d64bb960471819c829a777fd" category="paragraph">NUMA サブ境界およびハイパースレッディングを考慮すると、 VM のテストと構成用に選択される 8 つの VM は、ホストで使用可能なコアによって異なります。</block>
  <block id="0f57e9c52f3aa2d44da0de48ac87443a" category="paragraph">H610C では 10 台のランチャー VM を使用し、 RDP プロトコルを使用してユーザセッションに接続しました。次の図は、 Login VSI の接続情報を示しています。</block>
  <block id="ad1351ac01d5fe0ac5546c8a2fd2d170" category="paragraph"><block ref="ad1351ac01d5fe0ac5546c8a2fd2d170" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dba4e8b5ffc06c0ccce673fd6f48159" category="paragraph">次の図は、 H610C の Login VSI の応答時間とアクティブなセッションを示しています。</block>
  <block id="8d58d21e6be9e4be37d3c42935a380b5" category="paragraph"><block ref="8d58d21e6be9e4be37d3c42935a380b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72cce33d21386089f9a521f893c14d41" category="paragraph"><block ref="72cce33d21386089f9a521f893c14d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d64755ae2a4094876fbaf88a161ddec2" category="paragraph"><block ref="d64755ae2a4094876fbaf88a161ddec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ab628831ed501803e9da2a64f12dd6e" category="inline-link-macro">次のページ：管理ポータル</block>
  <block id="20fcc4e371ed448b0d5ffee3f4aecb43" category="paragraph"><block ref="20fcc4e371ed448b0d5ffee3f4aecb43" category="inline-link-macro-rx"></block></block>
  <block id="0ccea8702c360d2d159b0e8477fe81d6" category="summary">H610C または H615C を使用している場合、 GPU のライセンスはライセンスの再販権を持つ NVIDIA パートナーから購入する必要があります。</block>
  <block id="1f26c520bd4eba393348dedea38da7b7" category="doc">NVIDIA ライセンス</block>
  <block id="b548ee560d6fa4ee980d777df0300d09" category="inline-link">パートナー検索機能</block>
  <block id="72d760f4e8266e660fa7126e42f63bbe" category="paragraph">H610C または H615C を使用している場合、 GPU のライセンスはライセンスの再販権を持つ NVIDIA パートナーから購入する必要があります。NVIDIA パートナーは、で検索できます<block ref="32da44153625c96a28e5bf10161bbc42" category="inline-link-rx"></block>。仮想 GPU （ vGPU ）や Tesla などで検索してください。</block>
  <block id="7709fb92e99b3458d440c5212792a0de" category="paragraph">NVIDIA vGPU ソフトウェアには、次の 4 つのエディションがあります。</block>
  <block id="31473f257c4cfabfcba0c506fefcf4ca" category="list-text">NVIDIA GRID Virtual PC （ GRID vPC ）</block>
  <block id="75cc5be2167cc23ca9d32aa78a164907" category="list-text">NVIDIA GRID 仮想アプリケーション（ GRID vApps ）</block>
  <block id="53b933a69a5adecaa6c8c8817d2d87a5" category="list-text">NVIDIA Quadro Virtual Data Center Workstation （ Quadro vDWS ）</block>
  <block id="2d655109b3aad5a539482617b4aa3b6b" category="list-text">NVIDIA Virtual ComputeServer （ vComputeServer ）</block>
  <block id="38f26d9fb2d58dd577140e84010a059d" category="section-title">GRID Virtual PC の場合</block>
  <block id="e43876de331b666ca7fd1c7bbb8a844d" category="paragraph">この製品は、 Microsoft Windows アプリケーション、ブラウザ、高解像度ビデオ、およびマルチモニタのサポートに優れたユーザエクスペリエンスを提供する仮想デスクトップを必要とするユーザに最適です。NVIDIA GRID Virtual PC は仮想環境でネイティブエクスペリエンスを実現し、すべての PC アプリケーションをフルパフォーマンスで実行できます。</block>
  <block id="06a4851adc711a27ef53d0577d69e210" category="section-title">Grid 仮想アプリケーション</block>
  <block id="2c20bf668630521a8f76995b0c04c398" category="paragraph">GRID vApps は、リモートデスクトップセッションホスト（ RDSH ）またはその他のアプリケーションストリーミングやセッションベースのソリューションを導入する組織向けの製品です。Microsoft Windows アプリケーションをフルパフォーマンスで実行できるように設計された Windows Server ホスト型の RDSH デスクトップも、 GRID vApps でサポートされています。</block>
  <block id="5de115addc6579e1d30075a2a92c9ae7" category="section-title">Quadro Virtual Data Center Workstation の略</block>
  <block id="74fec534073fb87750193748093ada5a" category="paragraph">このエディションは、 Dassault CATIA 、 SOLIDWORKS 、 3Dexite 、 Siemens NX 、 PTC Creo などの強力な 3D コンテンツ作成アプリケーションを使用するメインストリームおよびハイエンドのデザイナーに最適です。 Schlumberger Petrel または Autodesk Maya 。NVIDIA Quadro vDWS を使用すると、すべてのデバイスのすべての機能とパフォーマンスを使用して、プロフェッショナルなグラフィックスアプリケーションにアクセスできます。</block>
  <block id="fb5cc5533386fd1b00e6b986dec8cba1" category="section-title">NVIDIA Virtual ComputeServer のこと</block>
  <block id="087877c8284ea313c79d65cb22d48329" category="paragraph">多くの組織が、人工知能（ AI ）、ディープラーニング（ DL ）、データサイエンスなど、コンピューティング負荷の高いサーバワークロードを実行しています。このようなユースケースでは、 NVIDIA vComputeServer ソフトウェアが NVIDIA GPU を仮想化することで、エラー修正コード、ページのリタイアメント、 NVLink 経由のピアツーピア、マルチ vGPU などの機能を使用して、コンピューティング負荷の高いサーバワークロードを高速化します。</block>
  <block id="e1f54ed77362f191ac08c4db8d9c44cd" category="admonition">Quadro vDWS ライセンスで GRID vPC と NVIDIA vComputeServer を使用できます。</block>
  <block id="d685cba160011e42327272678904bcbc" category="inline-link-macro">次の手順：導入</block>
  <block id="fed95bc65003dcb3d5ee273e3926bb25" category="paragraph"><block ref="fed95bc65003dcb3d5ee273e3926bb25" category="inline-link-macro-rx"></block></block>
  <block id="56b4cb3c337694fdafc2164dddad87fa" category="summary">GPU は通常、反復演算を実行することでグラフィック表示（レンダリング）に使用されます。この反復的なコンピューティング機能は、多くの場合、 AI やディープラーニングのユースケースに使用されます。</block>
  <block id="1b31ca8ddb749644af37aa10b42e6930" category="doc">GPU に関する考慮事項</block>
  <block id="ceeb28ce3b9ce753f02856fffb7ba66c" category="paragraph">グラフィックを多用するアプリケーションの場合、 Microsoft Azure では、 NVIDIA Tesla M60 カードをベースとした NV シリーズを提供しており、 VM ごとに 1 ~ 4 個の GPU を搭載しています。それぞれの NVIDIA Tesla M60 カードには、 Maxwell ベースの GPU が 2 つ搭載されており、それぞれ 8GB の GDDR5 メモリを搭載しているため、合計 16GB になります。</block>
  <block id="cb433c3099845f0ac8f3ba53d162db7b" category="admonition">NVIDIA ライセンスは NV シリーズに含まれています。</block>
  <block id="0f0c98cc175dc7cda319a35afcd199e5" category="paragraph"><block ref="0f0c98cc175dc7cda319a35afcd199e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ead26a90008a32871b53cb37bbe8431a" category="paragraph">NetApp HCI を使用した H615C GPU には、 NVIDIA Tesla T4 カードが 3 枚搭載されています。各 NVIDIA Tesla T4 カードには、 16GB の GDDR6 メモリを搭載した Touring ベースの GPU が搭載されています。VMware vSphere 環境で使用する場合、仮想マシンは GPU を共有でき、各 VM は専用のフレームバッファメモリを使用します。NetApp HCI H615C 上の GPU では、光線トレースを含めたリアルな画像を作成するために、レイトレーシングを使用できます。GPU 機能のライセンスがある NVIDIA ライセンスサーバが必要です。</block>
  <block id="148811d448421f6a42c549400b7201c0" category="paragraph"><block ref="148811d448421f6a42c549400b7201c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc6992cca0b3d14a85c456d0890f3e37" category="paragraph">GPU を使用するには、適切なドライバをインストールする必要があります。ドライバは NVIDIA ライセンスポータルからダウンロードできます。Azure 環境では、 NVIDIA ドライバを GPU ドライバ拡張機能として使用できます。次に、次のスクリーンショットに示すグループポリシーを更新して、リモートデスクトップサービスセッションに GPU ハードウェアを使用する必要があります。H.264 グラフィックスモードの優先順位を設定し、エンコーダ機能を有効にする必要があります。</block>
  <block id="5b0ff68b017720dd46aa6d1923fdfa95" category="paragraph"><block ref="5b0ff68b017720dd46aa6d1923fdfa95" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7d3d3d6dd94c69620cd3edfb005691c" category="paragraph">タスクマネージャを使用するか、 WebGL サンプルを実行する際に NVidia - SMI CLI を使用して、 GPU のパフォーマンス監視を検証します。GPU 、メモリ、エンコーダのリソースが消費されていることを確認します。</block>
  <block id="d13ca37d387c1bb473c0343278d0477d" category="paragraph"><block ref="d13ca37d387c1bb473c0343278d0477d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f2b53ac98ef55a900849ead654ca636" category="paragraph">仮想デスクトップサービスを搭載した NetApp HCI H615C に仮想マシンが導入されていることを確認するために、 H615C ホストを含む vCenter クラスタリソースを含むサイトを定義します。VM テンプレートには必要な vGPU プロファイルが接続されている必要があります。</block>
  <block id="818fad61fba48977b2293819f37e950a" category="paragraph">共有マルチセッション環境の場合は、複数の同種の vGPU プロファイルを割り当てることを検討してください。ただし、ハイエンドのプロフェッショナル向けグラフィックスアプリケーションの場合は、各 VM を特定のユーザ専用にして分離することを推奨します。</block>
  <block id="a2db30df8af33b0e661aaed00ce2c1d3" category="paragraph">GPU プロセッサは QoS ポリシーで制御でき、各 vGPU プロファイルには専用のフレームバッファを設定できます。ただし、エンコーダとデコーダはカードごとに共有されます。GPU カードへの vGPU プロファイルの配置は、 vSphere ホストの GPU 割り当てポリシーで制御されます。このポリシーでは、パフォーマンス（ VM を分散）や統合（ VM をグループ化）を強化できます。</block>
  <block id="53cf9d36e61cc97b118ae4cc9589bac3" category="summary">NetApp VDS Cloud Workspace Management Suite ポータルでは、オンプレミス、管理ユーザ、アプリケーションカタログ、スクリプト化イベント用のサイトを含むさまざまな VDS 環境を一元的に管理できます。このポータルは、必要に応じてアプリケーションを手動でプロビジョニングしたり、トラブルシューティングのためにマシンに接続したりするために、管理者ユーザーも使用します。</block>
  <block id="e68a6dedaba6faaba6e7afd9197edc4f" category="doc">管理ポータル</block>
  <block id="76368893e7696218fc60d77f96235f35" category="paragraph">NetApp VDS Cloud Workspace Management Suite ポータルを使用できます<block ref="1640f4040bca8395064a2ee51cb5f0ae" category="inline-link-rx"></block> また、今後のバージョンも提供される予定です<block ref="b6375c31f2253ef964d998b5762ba440" category="inline-link-rx"></block>。</block>
  <block id="02655da204b103696191f5d52c33427f" category="paragraph">このポータルでは、オンプレミス、管理ユーザ、アプリケーションカタログ、スクリプト化イベント用に定義されたサイトを含むさまざまな VDS 環境を一元管理できます。このポータルは、必要に応じてアプリケーションを手動でプロビジョニングしたり、トラブルシューティングのためにマシンに接続したりするために、管理者ユーザーも使用します。</block>
  <block id="0499b0532cd51452b57a028f3973d9fa" category="paragraph">サービスプロバイダは、このポータルを使用して独自のチャネルパートナーを追加し、自社のクライアントを管理できます。</block>
  <block id="8af19d014b76fa90ffc0c0477bd47be5" category="inline-link-macro">次の例は、ユーザ管理です</block>
  <block id="631d677d75a0b47f9fe24a201cc8cb85" category="paragraph"><block ref="631d677d75a0b47f9fe24a201cc8cb85" category="inline-link-macro-rx"></block></block>
  <block id="b5ed404fa434aeee227f550cddf89892" category="inline-link">NetApp クラウド</block>
  <block id="d823edbaf98641c5959f3a596de3df66" category="list-text"><block ref="d823edbaf98641c5959f3a596de3df66" category="inline-link-rx"></block></block>
  <block id="b1eb0510d1bc6ffab71faa53637ecde2" category="inline-link">NetApp VDS 製品ドキュメント</block>
  <block id="c5b41ed257411dffc1cc80a4c00cf17c" category="list-text"><block ref="c5b41ed257411dffc1cc80a4c00cf17c" category="inline-link-rx"></block></block>
  <block id="272427e7f4e6650df3749f83086acde6" category="inline-link">VPN ゲートウェイを使用してオンプレミスネットワークを Azure に接続できます</block>
  <block id="c460b4e40e6d4709ed15a2e8dba39833" category="list-text"><block ref="c460b4e40e6d4709ed15a2e8dba39833" category="inline-link-rx"></block></block>
  <block id="440e11297e8634c052b1bfd29a90309c" category="inline-link">Azure ポータル</block>
  <block id="8284aff5fcde6ba43a0ca21712739cae" category="list-text"><block ref="8284aff5fcde6ba43a0ca21712739cae" category="inline-link-rx"></block></block>
  <block id="8867b143d669949d3948e3816324ec75" category="inline-link">Microsoft Windows 仮想デスクトップ</block>
  <block id="0db816b3393ed224b26131285b4e3dff" category="list-text"><block ref="0db816b3393ed224b26131285b4e3dff" category="inline-link-rx"></block></block>
  <block id="7c033f9cfba6e06ff2ee6cb852ce10f4" category="inline-link">Azure NetApp Files 登録</block>
  <block id="aff481c4855a001492901fbefcab7d17" category="list-text"><block ref="aff481c4855a001492901fbefcab7d17" category="inline-link-rx"></block></block>
  <block id="4725a4744390b735ea1bb4e3fc99b686" category="section-title">ストレージノード</block>
  <block id="0f66538edca95cf4d42667cfa5d6a362" category="section-title">コンピューティングノード</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="section-title">NetApp AFF</block>
  <block id="568483e9bd85504f3c9dcef24ecd3235" category="doc">データ管理</block>
  <block id="24e6e2f6171b43a847fe194a9a9b5cd0" category="section-title">グローバルファイルキャッシュ</block>
  <block id="ce29b83c61cdf6a56b49dbde9a4d57e0" category="paragraph">グローバルネームスペース内の複数のサイトにユーザが分散している場合、グローバルファイルキャッシュを使用すると、頻繁にアクセスされるデータのレイテンシを低減できます。グローバルファイルキャッシュの導入は、プロビジョニングコレクションとスクリプト化されたイベントを使用して自動化できます。グローバルファイルキャッシュは、読み取りキャッシュと書き込みキャッシュをローカルで処理し、場所を問わずファイルのロックを維持します。グローバルファイルキャッシュは、 Azure NetApp Files を含む任意の SMB ファイルサーバと連携できます。</block>
  <block id="87db7a122a37ab4a28f2223fa123a5be" category="paragraph"><block ref="87db7a122a37ab4a28f2223fa123a5be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d726de6a27bb533c6c8c44ea508dffa8" category="paragraph">グローバルファイルキャッシュには次のものが必要です。</block>
  <block id="2f28046ff208122796d51bafd8d4bc9c" category="list-text">管理サーバ（ライセンス管理サーバ）</block>
  <block id="83168e6cb289d732cc78427b51f93153" category="list-text">コア</block>
  <block id="e7704357fe6a312ecafae725be93b8c2" category="list-text">データをキャッシュするための十分なディスク容量を備えたエッジ</block>
  <block id="d70c88e6a13ca1af40b966d8d7d831c4" category="inline-link">GFC のドキュメント</block>
  <block id="154c48fd725e7207d36baa74bba5fd7a" category="paragraph">ソフトウェアをダウンロードして、 Edge 用のディスクキャッシュ容量を計算するには、を参照してください<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>。</block>
  <block id="a51a182b58a11b12770fbd2bd9643852" category="paragraph"><block ref="a51a182b58a11b12770fbd2bd9643852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d666527802938c89b9f895300aea220b" category="paragraph">グローバルファイルキャッシュに使用するサービスアカウントを指定します。このアカウントに必要な権限については、を参照してください<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>。</block>
  <block id="ab698dd081619e8f6dc264df6c99b73e" category="paragraph"><block ref="ab698dd081619e8f6dc264df6c99b73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b1486d5cfb9e0c5394a50e2515b53c" category="paragraph">新しいバックエンドファイルサーバを追加し、ファイルサーバ名または IP を指定します。</block>
  <block id="ffeac1f6b14ca75f608539cb6c673f37" category="paragraph"><block ref="ffeac1f6b14ca75f608539cb6c673f37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="643c94b6eb5664ed3cca98d31d7dbd39" category="paragraph">エッジでは、キャッシュドライブのドライブ文字は D にする必要があります表示されない場合は、 diskpart.exe を使用してボリュームを選択し、ドライブレターを変更します。エッジとしてライセンスサーバーに登録します。</block>
  <block id="e9b41aa1ac49113064748a9c6e0f48a9" category="paragraph"><block ref="e9b41aa1ac49113064748a9c6e0f48a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="156666d997fd17a94bed67fe95334273" category="paragraph">コアの自動構成が有効になっている場合は、コア情報がライセンス管理サーバから自動的に取得されます。</block>
  <block id="891d862f33aaeafcd8ecc43e102febd3" category="paragraph"><block ref="891d862f33aaeafcd8ecc43e102febd3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a08e5ca253097ac5ad7741e20d9dd090" category="paragraph">管理者は、世界中のユーザーに透過的なアクセスを提供するために、ファイルサーバーの共有とエッジの場所を指すリンクを使用して、 Microsoft Distributed Filesystem (DFS) を設定できます。</block>
  <block id="0c9f570b7b5b34f0fbdab873e122d432" category="paragraph"><block ref="0c9f570b7b5b34f0fbdab873e122d432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9e8ad2bf50c8da3a637a8858d3a1391" category="paragraph">ユーザがサイトに関連付けられたサブネットに基づいて Active Directory クレデンシャルでログインすると、 DFS クライアントがデータにアクセスするために適切なリンクが使用されます。</block>
  <block id="6a6b2107f2b5daadfd13df04f769a587" category="paragraph"><block ref="6a6b2107f2b5daadfd13df04f769a587" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8aabec6a7d3f54b83478824808357c91" category="paragraph">ファイルアイコンは、ファイルがキャッシュされているかどうかに応じて変化します。キャッシュされていないファイルの場合は、アイコンの左下隅にグレーの X が表示されます。エッジの場所にいるユーザーがファイルにアクセスすると、そのファイルがキャッシュされ、アイコンが変化します。</block>
  <block id="1014b6d5d432758e9041c845e4da7830" category="paragraph"><block ref="1014b6d5d432758e9041c845e4da7830" category="inline-image-macro-rx" type="image"></block></block>
  <block id="610eee89db61eda57b4b6da39d799845" category="paragraph">ファイルが開いているときに、別のユーザーがエッジの場所から同じファイルを開こうとすると、次の選択を求めるプロンプトが表示されます。</block>
  <block id="5a31b6c180e91d3c3d3c1053bbab642c" category="paragraph"><block ref="5a31b6c180e91d3c3d3c1053bbab642c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c6f3b21447f91b42ceee404afc53720" category="paragraph">ユーザが元のコピーが使用可能になったときに通知を受け取るオプションを選択した場合、ユーザには次のように通知されます。</block>
  <block id="922c6f30fa0f74f32df2fac11a3bf378" category="paragraph"><block ref="922c6f30fa0f74f32df2fac11a3bf378" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b9bc3a03a8ae9cef2c5a66238e5ab25" category="inline-link">Talon と Azure NetApp Files の導入に関するビデオ</block>
  <block id="e725329a19c23f541a0bdbead9c9b1e7" category="paragraph">詳細については、を参照してください<block ref="92818ea025c5b78ace999366164c2c46" category="inline-link-rx"></block>。</block>
  <block id="fc95bd8bc19564339fe05c7bad1b7662" category="section-title">SaaS バックアップ</block>
  <block id="482cadbeebfa6f9c4f062c1f2724d546" category="paragraph">NetApp VDS は、 Exchange 、 SharePoint 、 Microsoft OneDrive など、 Salesforce と Microsoft Office 365 のデータ保護を提供します。次の図は、これらのデータサービス用に NetApp VDS で SaaS Backup を提供する方法を示しています。</block>
  <block id="0e3aff181138166393e5e5e698c994d2" category="paragraph"><block ref="0e3aff181138166393e5e5e698c994d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="201e09e85ad81db8a19ef9f20c05d1a5" category="inline-link">このビデオでは</block>
  <block id="4cde65566156674196c087d89ded5c3b" category="paragraph">Microsoft Office 365 のデータ保護のデモについては、を参照してください<block ref="158107d7e819a2ef8c2e8f24519fc9a9" category="inline-link-rx"></block>。</block>
  <block id="2cb2b89213bccd89f81cfbb17b2e070b" category="inline-link-macro">次：運用管理</block>
  <block id="1f3d3eae36241941c6f7a1eaf3615eac" category="paragraph"><block ref="1f3d3eae36241941c6f7a1eaf3615eac" category="inline-link-macro-rx"></block></block>
  <block id="7b0f97bc4856c6b0645650d13b53acb5" category="summary">オンプレミスのリソースとクラウドリソース間の接続が確立されていれば、 NetApp Virtual Desktop Service をオンプレミスに拡張できます。企業は、 Express Route またはサイト間 IPSec VPN 接続を使用して、 Microsoft Azure へのリンクを確立できます。専用リンクまたは IPsec VPN トンネルを使用して、他のクラウドへのリンクを同様の方法で作成することもできます。</block>
  <block id="995d0ae58fc48c0007c3a45046221736" category="doc">ハイブリッドクラウド環境</block>
  <block id="610e3513c7222cae8d2a7c450741211a" category="paragraph">解決策の検証では、次の図に示す環境を使用しました。</block>
  <block id="0d9e9a129d4eb3389af12248eb017ef1" category="paragraph"><block ref="0d9e9a129d4eb3389af12248eb017ef1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60ca94382604fd3deb8a198feed31f1b" category="paragraph">オンプレミスでは、管理ホスト、リモートデスクトップセッションホストなど用に複数の VLAN がありました。これらは 172.21.146-150.0/24 サブネット上にあり、 Microsoft Remote Routing Access Service を使用して企業ネットワークにルーティングされています。また、次のタスクも実行しました。</block>
  <block id="b613a58cb27d96b09550b74a616e43d8" category="list-text">Microsoft Routing and Remote Access Server （ RRAS ； IPchicken.com で識別）のパブリック IP に注目しました。</block>
  <block id="b0aa9d967a62cfeb9427c31c3968fb31" category="list-text">Azure サブスクリプション上に Virtual Network Gateway リソース（ルートベースの VPN ）を作成しました。</block>
  <block id="2db3e884a3b1d82162c06df081b8e8f0" category="list-text">Microsoft RRAS サーバーのパブリック IP のローカルネットワークゲートウェイアドレスを提供する接続を作成しました。</block>
  <block id="ac7b5e31749488bdca809cc69e83bcec" category="list-text">RRAS で VPN 設定を完了し、 VPN ゲートウェイの作成時に提供された事前共有認証を使用して仮想インターフェイスを作成しました。正しく設定されている場合、 VPN は Connected 状態になっている必要があります。Microsoft RRAS の代わりに、 pfSense などの関連ツールを使用して、サイト間 IPsec VPN トンネルを作成することもできます。トンネルはルートベースであるため、設定された特定のサブネットに基づいてトラフィックをリダイレクトします。</block>
  <block id="064b2713bd54ad7c04715d629ea8d77e" category="paragraph">Microsoft Azure Active Directory は、 OAuth に基づいて ID 認証を提供します。通常、エンタープライズクライアント認証には、 NTLM または Kerberos ベースの認証が必要です。Microsoft Azure Active Directory ドメインサービスは、 ADConnect を使用して、 Azure Active Directory とオンプレミスのドメインコントローラ間でパスワードハッシュの同期を実行します。</block>
  <block id="c9ced395d02e614104c13dc687b8d960" category="paragraph">今回のハイブリッド VDS 解決策の検証では、最初に Microsoft Azure に導入し、 vSphere で追加のサイトを追加しました。このアプローチの長所は、プラットフォームサービスが Microsoft Azure に導入され、ポータルを使用してすぐにバックアップできることです。サイト間 VPN リンクがダウンしている場合でも、サービスにはどこからでも簡単にアクセスできます。</block>
  <block id="759e5787427ba679d146727a04400c46" category="paragraph">別のサイトを追加するには、 DCConfig というツールを使用しました。このアプリケーションへのショートカットは、 Cloud Workspace Manager （ CWMgr ） VM のデスクトップで使用できます。このアプリケーションを起動したら、 [ データセンターサイト ] タブに移動し、新しいデータセンターサイトを追加して、必要な情報を次のように入力します。URL は vCenter IP を示します。設定を追加する前に、 CWMgr VM が vCenter と通信できることを確認してください。</block>
  <block id="ae5bd963078c278284e2aabaefb99232" category="admonition">VMware vSphere 環境との通信を有効にするために、 CloudWorkspace マネージャーの vSphere PowerCLI 5.1 がインストールされていることを確認します。</block>
  <block id="e0072a2f037098ba3ee9ec9e1113f1ee" category="paragraph">次の図は、オンプレミスのデータセンターサイトの構成を示しています。</block>
  <block id="30efb5f8dd999c0f737bf30327346d6f" category="paragraph"><block ref="30efb5f8dd999c0f737bf30327346d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f823fddfaa31c0b2b910c651849fe1e0" category="paragraph">コンピューティングリソースには、特定のクラスタ、ホスト名、または空き RAM スペースに基づくフィルタリングオプションが用意されています。ストレージリソースのフィルタリングオプションには、データストア上の最小空きスペースまたはデータストアあたりの最大 VM 数が含まれます。データストアは、正規表現を使用して除外できます。[Save] ボタンをクリックして、設定を保存します。</block>
  <block id="40cf95c01dfbdb8adc110507697330bf" category="paragraph">設定を検証するには、 Test ボタンをクリックするか、 Load Hypervisor をクリックし、 vSphere セクションのドロップダウンを確認します。適切な値が入力されている必要があります。プライマリハイパーバイザーは、デフォルトのプロビジョニングサイトで yes に設定しておくことを推奨します。</block>
  <block id="b081b97ab471a870119bb85e196c0d63" category="paragraph">VMware vSphere で作成された VM テンプレートは、 VDS でプロビジョニングコレクションとして使用されます。プロビジョニング収集には、共有と VDI の 2 つの形式があります。共有プロビジョニングコレクションタイプは、すべてのサーバに 1 つのリソースポリシーが適用されるリモートデスクトップサービスに使用されます。VDI タイプは、リソースポリシーが個別に割り当てられている WVD インスタンスに使用されます。Provisioning Collection 内のサーバには、次の 3 つのロールのいずれかを割り当てることができます。</block>
  <block id="9a0b479d2d7eaed435c14e20818841d9" category="list-text">*TSDATA/* ターミナルサービスとデータサーバの役割の組み合わせ。</block>
  <block id="286b69ba39f77189135fbf4c39786e12" category="list-text">*TS.* ターミナルサービス ( セッションホスト )</block>
  <block id="0b39ab3df8d28606b4bb8f5891022692" category="list-text">* data.* ファイルサーバーまたはデータベースサーバー。サーバロールを定義する際には、 VM テンプレートとストレージ（データストア）を選択する必要があります。選択できるデータストアは特定のデータストアに制限することも、データの使用量に基づいてデータストアが選択される最も使用率の低いオプションを使用することもできます。</block>
  <block id="fb89cc64fafb0e1626269bc00c07ae73" category="paragraph">各導入環境では、アクティブユーザ、固定、サーバ負荷、またはユーザ数に基づいて、クラウドリソース割り当ての VM リソースがデフォルトで設定されます。</block>
  <block id="d00f03f39f8119980cb5240353d345b1" category="inline-link-macro">次のセクションでは、 Login VSI での単一サーバの負荷テストについて説明します</block>
  <block id="af5c949297d5415f4710bd1af3f1e7a7" category="paragraph"><block ref="af5c949297d5415f4710bd1af3f1e7a7" category="inline-link-macro-rx"></block></block>
  <block id="18dbdef148da0fb68861cf1b6aeeeb40" category="summary">NetApp VDS を使用したハイブリッド VDI により、サービスプロバイダとエンタープライズ仮想デスクトップ管理者は、ユーザに影響を与えることなく、簡単にリソースを他のクラウド環境に拡張できます。NetApp HCI 上にオンプレミスリソースを配置すると、 GPU リソースをより細かく制御でき、コンピューティングノードやストレージノードをオンデマンドで拡張できます。</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">この解決策環境のユースケースは次のとおりです。</block>
  <block id="f9bfa55b1c8ab8884a1452fa3c9cb975" category="list-text">クラウドにバーストして、リモートの需要急増に対応します デスクトップとアプリケーション</block>
  <block id="6b53dc409ecc50a533e93345ddf1f2ee" category="list-text">長時間のリモートデスクトップおよびアプリケーションの運用における TCO を削減 フラッシュストレージと GPU リソースをオンプレミスでホストできます</block>
  <block id="f1de7e15d0b0c3caaafa1a47204338c7" category="list-text">クラウド全体にわたるリモートデスクトップとアプリケーションの管理が容易 環境</block>
  <block id="f9ce5b54f5428c82364a39f17156cc4f" category="list-text">ソフトウェアサービスを使用して、リモートデスクトップとリモートアプリケーションを体験できます オンプレミスのリソースを使用するモデル</block>
  <block id="675ee473db5bbe3911c19a4e43f8ec3f" category="list-text">の要件を理解したい EUC / VDI アーキテクト ハイブリッド VDS</block>
  <block id="a7f381741a2ff77b61bc4b7bc2e3d04f" category="list-text">ネットアップのパートナーが、お客様の支援を希望しています リモートデスクトップとアプリケーションのニーズ</block>
  <block id="efa648658230830c2b9ac1a0647002d7" category="list-text">リモートデスクトップに対応したい既存の NetApp HCI ユーザ アプリケーションのニーズも高まります</block>
  <block id="2fa4089eb34d18d2b64eaab8eed9692d" category="inline-link-macro">次のページ： NetApp Virtual Desktop Service の概要</block>
  <block id="bf817f81e35d1d9f2620def86f22dcc3" category="paragraph"><block ref="bf817f81e35d1d9f2620def86f22dcc3" category="inline-link-macro-rx"></block></block>
  <block id="b4f83b03956523a39e8bbbd0895f0f29" category="section-title">Cloud Insights の機能です</block>
  <block id="52f9ec21735243ad9917cda3ca077d32" category="section-title">GPU</block>
  <block id="3d564c1c20cf4265a5094ead9dc937f6" category="paragraph">ネットアップ Suresh Thoppay</block>
  <block id="64241e0b33fb869cb12ff8e1ec74f806" category="summary">NetApp VDS では、 ID 認証に Azure Active Directory 、 NTLM / Kerberos 認証に Azure Active Directory ドメインサービスを使用します。ADConnect ツールを使用すると、オンプレミスの Active Directory ドメインを Azure Active Directory と同期できます。</block>
  <block id="92726ab5faeb2cb9208eaac9af0346bd" category="doc">ユーザ管理</block>
  <block id="c758de7e1477d6707c6709441d41a5e9" category="paragraph">ポータルから新しいユーザを追加することも、既存のユーザに対してクラウドワークスペースを有効にすることもできます。ワークスペースとアプリケーションサービスの権限は、個々のユーザまたはグループによって制御できます。管理ポータルでは、ポータルやワークスペースなどの権限を制御する管理ユーザを定義できます。</block>
  <block id="b1bb3db86aec5efef6f7cc0d0d7c6331" category="paragraph">次の図は、 NetApp VDS のユーザ管理を示しています。</block>
  <block id="ed5018356119de97fa1ab09c0eeab65a" category="paragraph"><block ref="ed5018356119de97fa1ab09c0eeab65a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1350c851c78a6cdb31c6fe46ddb499c2" category="paragraph">各ワークスペースは、次の図に示すように、 Cloud Workspace OU の下にある専用の Active Directory 組織単位（ OU ）に存在します。</block>
  <block id="a5484d6de39aa020af1aa382d6d52c5e" category="paragraph"><block ref="a5484d6de39aa020af1aa382d6d52c5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3fad2f68853fae9ef870ed5535896790" category="paragraph">詳細については、を参照してください<block ref="b5d59c719b42a4e7d2b711482aa2f54d" category="inline-link-rx"></block> NetApp VDS のユーザ権限とユーザ管理。</block>
  <block id="48a8649f1ce9d97848d70480ce7fea9c" category="paragraph">データセンターの API 呼び出しを使用して Active Directory グループを CRAUserGroup として定義すると、そのグループ内のすべてのユーザーが、 UI を使用して管理するために CloudWorkspace にインポートされます。クラウドワークスペースがユーザに対して有効になっている場合、 VDS はユーザのホームフォルダ、設定権限、ユーザプロパティの更新などを作成します。</block>
  <block id="9e30d1bf5e5278a123ad0ddab43066b7" category="paragraph">VDI ユーザー使用可能を選択した場合、 VDS はそのユーザー専用のシングルセッション RDS マシンを作成します。プロビジョニングするテンプレートとデータストアを指定するよう求められます。</block>
  <block id="093d2ddf98cacaf853b6f986ca9bd647" category="paragraph"><block ref="093d2ddf98cacaf853b6f986ca9bd647" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46bccf4889fab263d6edc63e631883a7" category="inline-link-macro">次の手順：ワークスペース管理</block>
  <block id="e98fdb0b8697a2cf005527be51872d0d" category="paragraph"><block ref="e98fdb0b8697a2cf005527be51872d0d" category="inline-link-macro-rx"></block></block>
  <block id="57eae0e26c1c0bbaec9110d010f68f7a" category="summary">NetApp HCI は、ストレージノードとコンピューティングノードが混在するハイブリッドクラウドインフラです。モデルに応じて、 2 ラックユニットまたはシングルラックユニットのいずれかとして使用できます。VM の導入に必要なインストールと設定は、 NetApp Deployment Engine （ NDE ）で自動化されています。コンピューティングクラスタは VMware vCenter で管理され、ストレージクラスタは NDE で導入された vCenter Plug-in で管理されます。</block>
  <block id="855faa205a8f23993f1a0fe1ac2cde2f" category="doc">NetApp HCI の概要</block>
  <block id="b6ab683d50d83f639ae697569117a54b" category="paragraph">NetApp HCI は次の機能を処理します。</block>
  <block id="d15278d453245d004f8fd55cff421171" category="list-text">バージョンのアップグレード</block>
  <block id="b783caf332f2c3190dcb6ced64290f5a" category="list-text">イベントを vCenter にプッシュしています</block>
  <block id="79adeb760f6909dd746e1e7adae6cd58" category="list-text">vCenter Plug-in の管理</block>
  <block id="a45e04274259a13dff2a10641a0fd97f" category="list-text">サポート用の VPN トンネル</block>
  <block id="227590ca6f7ff3f3cc72e49cf277625f" category="list-text">NetApp Active IQ コレクタ</block>
  <block id="b0088ee645cccd0951013eb53d0b3816" category="list-text">NetApp クラウドサービスをオンプレミスに拡張し、ハイブリッドクラウドインフラを実現次の図は、 HCI のコンポーネントを示しています。</block>
  <block id="1a811712e3bea62b6f5bd1851b149fc3" category="paragraph"><block ref="1a811712e3bea62b6f5bd1851b149fc3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65f0d96af236e344bd739fd20df1fa5d" category="paragraph">ストレージノードは、半幅または全幅サイズのラックユニットとして使用できます。ストレージノードは最低 4 つ必要で、クラスタは最大 40 ノードまで拡張できます。ストレージクラスタは、複数のコンピューティングクラスタ間で共有できます。すべてのストレージノードには、書き込みパフォーマンスを向上させるためにキャッシュコントローラが搭載されています。1 つのノードで、 4K ブロックサイズで 5 万または 10 万 IOPS を実現します。</block>
  <block id="d31f04e865057f7055f2d8287b92ba2d" category="paragraph">NetApp HCI ストレージノードでは、最小、最大、バーストの QoS 制限を定めた NetApp Element ソフトウェアが実行されます。ストレージクラスタにはタイプの異なるストレージノードを混在させることができますが、 1 つのストレージノードの容量は合計容量の 1/3 以下にする必要があります。</block>
  <block id="bc1a52314ab38efacf0a83e9df0b01cc" category="paragraph">コンピューティングノードには、半幅、全幅、 2 ラックサイズのラックユニットを使用できます。NetApp HCI H410C と H610C には拡張性に優れた Intel Skylake プロセッサが採用されています。H615C には、拡張性に優れた第 2 世代 Intel Cascade Lake プロセッサが搭載されています。GPU を搭載したコンピューティングモデルは 2 つあります。 H610C は NVIDIA M10 カードを 2 基、 H615C は NVIDIA T4 カードを 3 基搭載しています。</block>
  <block id="683876986e8fe1045fa768b4a8675ea9" category="paragraph"><block ref="683876986e8fe1045fa768b4a8675ea9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9667ae1b4be7e4c088e175844fd675e6" category="paragraph">NVIDIA T4 には RT コアが 40 基搭載されており、リアルタイムレイトレーシングに必要なコンピューティング能力を提供します。デザイナーやエンジニアと同じサーバモデルをアーティストが使用して、水面に反射する光を現実のように表現したリアルな画像を作成できるようになりました。この RTX 対応 GPU は、毎秒最大 5 ギガレイのリアルタイムレイトレーシングパフォーマンスを実現します。NVIDIA T4 を Quadro Virtual Data Center Workstation （ Quadro vDWS ）ソフトウェアと組み合わせて使用することで、アーティストは影、反射、屈折を正確に再現した、写真のようにリアルなデザインをあらゆる場所のすべてのデバイス上に作成できます。</block>
  <block id="bee5034948808ff859affdc8ba03b52c" category="paragraph">Tensor コアは、ディープラーニング推論ワークロードの実行を可能にします。これらのワークロードを実行している場合、 Quadro vDWS を搭載した NVIDIA T4 のパフォーマンスは、 CPU のみのサーバを搭載した VM の最大 25 倍です。1 ラックユニットに NVIDIA T4 カードを 3 基搭載した NetApp H615C は、グラフィックスとコンピューティングの負荷の高いワークロードに最適な解決策です。</block>
  <block id="1f99f286804bf2f5a91a1cdd1733decf" category="paragraph">次の図に、 NVIDIA GPU カードとその機能の比較を示します。</block>
  <block id="67c0c3f98979352a9ed10f0de3d551f3" category="paragraph"><block ref="67c0c3f98979352a9ed10f0de3d551f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b4fc2931642829391b479ea5fb1e9d" category="paragraph">M10 GPU は、現在でもナレッジワーカーのユースケースに最適な TCO 解決策です。ただし、仮想ワークステーション、グラフィックスパフォーマンス、リアルタイムのインタラクティブレンダリング、推論など、さまざまなユースケースに使用できる GPU での標準化を希望する場合には、 T4 が最良の代替ソリューションです。T4 では、同じ GPU リソースを使用して異なるワークロードを実行できます。たとえば、日中は VDI を実行し、同じリソースを使用して夜間にコンピューティングワークロードを実行できます。</block>
  <block id="fe046fc197d12a64da1ea78423a2a809" category="paragraph">コンピューティングクラスタ内のノード数は VMware によって決まります。現在は VMware vSphere 7.0 Update 1 で 96 です。Enhanced vMotion Compatibility （ EVC ）が有効な場合、クラスタ内に異なるモデルのコンピューティングノードを混在させることができます。</block>
  <block id="f0bee2b90db3a99440b1a724c49ce1a2" category="inline-link-macro">次は NVIDIA ライセンスです</block>
  <block id="e0bca2831f4cccfcaebc75e9555a1719" category="paragraph"><block ref="e0bca2831f4cccfcaebc75e9555a1719" category="inline-link-macro-rx"></block></block>
  <block id="868ab86f19065016e9a2f077c5ec1ede" category="summary">タスクワーカーは、利用可能なアプリケーションのリストからアプリケーションをすばやく起動できます。アプリケーションサービスは、リモートデスクトップサービスセッションホストからアプリケーションをパブリッシュします。WVD を使用すると、アプリケーショングループは、複数セッションの Windows 10 ホストプールから同様の機能を提供します。</block>
  <block id="aa08bd8b0522ea3a5e9ace598db7162c" category="doc">アプリケーション管理</block>
  <block id="f83a66a518ff3f3f44725a09d9666710" category="paragraph">オフィスワーカーがユーザに給電する場合は、サービスボードを使用して手動でプロビジョニングするか、または NetApp VDS のスクリプト化されたイベント機能を使用して自動でプロビジョニングすることができます。</block>
  <block id="546d3f7d3bb8a664a6ba4a3fb2f68c30" category="inline-link">ネットアップのアプリケーション使用資格ページ</block>
  <block id="175ba74f5b7d0ecd3f531c5fce21a240" category="paragraph">詳細については、を参照してください<block ref="03e02ecfc967e94041a86f599e14ac44" category="inline-link-rx"></block>。</block>
  <block id="ba5e495048f0fa35302184aa505386a9" category="inline-link-macro">次のステップ：データ管理</block>
  <block id="51688bc4609022e20e8c1cb051fb4489" category="paragraph"><block ref="51688bc4609022e20e8c1cb051fb4489" category="inline-link-macro-rx"></block></block>
  <block id="91af64270656f51ceebeabc4b79ecb07" category="summary">ネットアップ VDS は、必要なコードベースに基づいて利用可能なセットアップアプリケーションを使用して Microsoft Azure に導入できます。</block>
  <block id="c4e1987e3c1416cefd772fd61f28dfb4" category="paragraph">を参照してください<block ref="f8270911b627accef36841f0608bc58d" category="inline-link-rx"></block> 導入手順については、を参照して</block>
  <block id="4c9affd9b517fc81a601ea0861dc5399" category="inline-link-macro">次のステップ：ハイブリッドクラウド環境</block>
  <block id="2045518eb8a77a5284f073d0387f9a58" category="paragraph"><block ref="2045518eb8a77a5284f073d0387f9a58" category="inline-link-macro-rx"></block></block>
  <block id="bf6d8e47240024519d1dbb6f5582ce66" category="summary">グラフィックス・ワークステーションは通常、製造、医療、エネルギー、メディアおよびエンターテイメント、教育、教育などの業界で使用されています。 アーキテクチャなど。モバイル性は、グラフィックスを多用するアプリケーションには限定されることがよくあります。</block>
  <block id="942cd85feff07ce32d619d2f724254a8" category="doc">業界向けソリューション</block>
  <block id="fb987436787e4263bfee440b93703026" category="paragraph">問題のモビリティに対応するため、仮想デスクトップサービスは、タスクワーカーからエキスパートユーザまで、クラウドまたは NetApp HCI でハードウェアリソースを使用して、あらゆるタイプの従業員にデスクトップ環境を提供します。 には、柔軟な GPU 構成のオプションも含まれます。VDS を使用すると、ラップトップ、タブレット、その他のモバイルデバイスを使用して、どこからでも作業環境にアクセスできます。</block>
  <block id="68ae3286d2356ff8dd51c2a397ca20eb" category="paragraph">ANSYS Fluent'ANSYS Mechanical 'Autodesk AutoCAD'Autodesk Inventor'Autodesk 3ds Max などのソフトウェアを使用して製造ワークロードを実行するには ' 次の手順に従います Dassault Syst è mes SOLIDWORKS 、 Dassault Syst è mes CATIA 、 PTC Creo 、 Siemens PLM NX など さまざまなクラウド（ 2021 年 1 月現在）で利用可能な GPU を次の表に示します。</block>
  <block id="f5168df5bb95078acdfb440f5975a601" category="cell">GPU モデル</block>
  <block id="1668ca1bd914c1d847f23b491319ac91" category="cell">Microsoft Azure</block>
  <block id="b314ebdba178173db01ffda8d3a5af67" category="cell">Google Compute （ GCP ）</block>
  <block id="943ca3782b28d89aff2f86a50b332b3c" category="cell">Amazon Web Services （ AWS ）</block>
  <block id="8df8a98ff17d4d77329f5da80da051e8" category="cell">オンプレミス（ NetApp HCI ）</block>
  <block id="aaba9e920b39aa997c69800a9e589cd4" category="cell">NVIDIA M60</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">はい。</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">いいえ</block>
  <block id="e095ad80d900786110d53ecd5cbd3e3e" category="cell">NVIDIA T4</block>
  <block id="c909ed1507c6d5537f0cc0966e83d3f1" category="cell">NVIDIA P100</block>
  <block id="c015c1cc95335d3b867c145c056df10b" category="cell">NVIDIA P4</block>
  <block id="e8130bb14c9382769c22861fb54683b3" category="paragraph">他のユーザとの共有デスクトップセッションや、専用の個人用デスクトップも利用できます。仮想デスクトップには、 1 ～ 4 台の GPU を搭載することも、 NetApp HCI で部分的な GPU を利用することもできます。NVIDIA T4 は汎用性に優れた GPU カードで、幅広いユーザワークロードのニーズに対応できます。NetApp HCI H615C の各 GPU カードには、 16GB のフレームバッファメモリとサーバあたり 3 枚のカードが搭載されています。1 台の H615C サーバでホストできるユーザの数は、ユーザワークロードによって異なります。</block>
  <block id="4d8b78a5288c49df59136421211718c9" category="cell">ユーザ / サーバ</block>
  <block id="704316eb872cbca84a8b30d74c2708a4" category="cell">ライト（ 4GB ）</block>
  <block id="6f3a945a32dd8eba9f2fae42715f7246" category="cell">メディア（ 8GB ）</block>
  <block id="adb5e5b63d256f3854fc7276b3e8d14a" category="cell">重量（ 16GB ）</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12.</block>
  <block id="8938ba807f25f2cd88559b9f84bbc3de" category="paragraph">ユーザタイプを確認するには、アプリケーションで一般的なタスクを実行している間に GPU プロファイラツールを実行します。GPU プロファイラは、メモリ要求、表示数、およびユーザが必要とする解像度をキャプチャします。その後、要件を満たす vGPU プロファイルを選択できます。</block>
  <block id="1b014a2b6e4c329b9696aae7afac88db" category="paragraph">GPU を搭載した仮想デスクトップでは、最大 8K の表示解像度がサポートされます。また、ユーティリティ nView では、 1 つのモニタを複数の領域に分割して、異なるデータセットで動作させることができます。</block>
  <block id="30f1a84c728d67b9606115a1531aa9c3" category="paragraph">ONTAP ファイルストレージでは、次のメリットを実現できます。</block>
  <block id="826f3d14d0c34cd0f8ced37e07a1537d" category="list-text">4 、 000 億個のファイルを含むストレージで最大 20PB まで拡張可能な単一のネームスペース。管理情報は必要ありません</block>
  <block id="1d7ab3c9a162bc81b216bdc0948094f2" category="list-text">グローバルを使用して世界中にまたがることができるネームスペースです ファイルキャッシュ</block>
  <block id="2d4169e0cb52db60fd11576990b38a54" category="list-text">管理対象のネットアップストレージでセキュアマルチテナンシーを実現</block>
  <block id="a44c13ec320997e84b87b0fef150c39f" category="list-text">ネットアップを使用したオブジェクトストアへのコールドデータの移行 FabricPool</block>
  <block id="3749fba0ca78e5e5c70f899da89be2c3" category="list-text">ファイルシステム分析によるクイックファイル統計</block>
  <block id="63d0ec819ea12b4e83e0ef4a1cd2bb1c" category="list-text">ストレージクラスタの容量を最大 24 ノードまで拡張可能 パフォーマンスの向上を実現</block>
  <block id="818a13118ddb0908ba00c1b7ca18dc2c" category="list-text">クォータを使用してストレージスペースを制御し、保証する機能 パフォーマンスと QoS 制限</block>
  <block id="ef94cd0a62341c72316393b1044582f8" category="list-text">暗号化によるデータの保護</block>
  <block id="c1e36bb7dca3b0da98164eb5956e3f0f" category="list-text">データ保護とコンプライアンスに関する幅広い要件に対応</block>
  <block id="6a632279908ad5d56ab46a826de6c9f2" category="list-text">柔軟なビジネス継続性オプションを提供</block>
  <block id="3c2622109ae4dc55b73e9bb6516e5616" category="paragraph"><block ref="3c2622109ae4dc55b73e9bb6516e5616" category="inline-link-macro-rx"></block></block>
  <block id="0581202e42d61d6dfe4875c70d00cdac" category="summary">NetApp Virtual Desktop Service は、仮想デスクトップおよびアプリケーション環境を消費しやすくするだけでなく、ビジネス上の課題にも重点的に対応します。NetApp HCI で VDS を拡張することで、インラインの重複排除、コンパクション、シンプロビジョニング、圧縮など、 VDS 環境でネットアップの強力な機能を使用できます。</block>
  <block id="df6f0981c6f92ef3adb9059f5b387e4a" category="paragraph"><block ref="df6f0981c6f92ef3adb9059f5b387e4a" category="inline-link-macro-rx"></block></block>
  <block id="a3af49b9146a6a36e8bea4c525797782" category="summary">このページでは、 DCConfig Tool 、 TestVdc Tools 、およびログファイルについて説明します。</block>
  <block id="d56ee3058d1c4ab634cd3e1e606f2064" category="doc">ツールとログ</block>
  <block id="626b1761e15913fc6f955e1d76a0ac10" category="section-title">DCConfig ツール</block>
  <block id="65bbb1c25836b86f699bd2141a545958" category="paragraph">DCCconfig ツールは、サイトを追加するための次のハイパーバイザーオプションをサポートしています。</block>
  <block id="2c76e52255da65e5fcf88143f91aa431" category="paragraph"><block ref="2c76e52255da65e5fcf88143f91aa431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da2595b668536baaea606e674ade5181" category="paragraph"><block ref="da2595b668536baaea606e674ade5181" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8688a5dde644921ea673f5bc2dde55c3" category="paragraph"><block ref="8688a5dde644921ea673f5bc2dde55c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b462233b13790bce7e4c6449d02cf930" category="list-text">ワークスペースの SMB パスを変更します。</block>
  <block id="ee347a7998de9774369e6853f1ed7bcc" category="paragraph"><block ref="ee347a7998de9774369e6853f1ed7bcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c524c01ee30f2f1597bb3e90c721dd8c" category="list-text">プロビジョニングコレクションのサイトを変更します。</block>
  <block id="ccb9931a262a0b169576103526fa2ab2" category="paragraph"><block ref="ccb9931a262a0b169576103526fa2ab2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af6ba12de0b8c93d5f768c83143c7d99" category="section-title">ログファイル</block>
  <block id="881784d32d0ec795e6fd477e7c0fe8f7" category="paragraph"><block ref="881784d32d0ec795e6fd477e7c0fe8f7" category="inline-link-macro-rx"></block></block>
  <block id="21a1e68164f738b8be1dae11d5a694b3" category="section-title">データ保護</block>
  <block id="6abbceca4793ffe4b329045f63b4d219" category="doc">運用管理</block>
  <block id="787e198d8fa4e242ef62df0a63fc0f5d" category="inline-link">[Troubleshooting Failed VDA Actions] ページ</block>
  <block id="8086a7a818fcf045c7b05845b97629ed" category="paragraph">VDS ログファイルの詳細については、を参照してください<block ref="0ecc734e7dc5f9a5685babbaab9faaa5" category="inline-link-rx"></block>。</block>
  <block id="88a80237ffcd0c20f5f4d4e7f9eda875" category="inline-link">VDA Components and Permissions （ VDA コンポーネントと権限）ページ</block>
  <block id="000ea3efdd5a83f774a0c189fa2dcdc3" category="paragraph">必要な最小権限の詳細については、を参照してください<block ref="573c5bde2dc73c6cb4f63bbc5571c0e2" category="inline-link-rx"></block>。</block>
  <block id="81bb80b99b1ba5d80f9ba049cbd0c42f" category="inline-link">仮想マシンのクローニングページ</block>
  <block id="91aa73f3df8edb27ce6b20c984ff5d3e" category="paragraph">サーバのクローンを手動で作成する場合は、を参照してください<block ref="837d5521d53fff809b7ef3ad6b17ecfa" category="inline-link-rx"></block>。</block>
  <block id="7d71ba8ea6767ea10d7cd61cbd787f89" category="inline-link">ディスク容量の自動拡張機能ページ</block>
  <block id="abf872062b9eb23bdf6d671c27508d96" category="paragraph">VM ディスクのサイズを自動的に増やす方法については、を参照してください<block ref="627eb07506141f4255cfbedd7fe89646" category="inline-link-rx"></block>。</block>
  <block id="cc6d8546c611bac5ab11fa1a5948ac1d" category="inline-link">End User Requirements ページ</block>
  <block id="e148ddcb2ae92c77834ae7f48df04786" category="paragraph">クライアントを手動で設定するゲートウェイアドレスを指定するには、を参照してください<block ref="3a5e891ac91af8fef1ca1458249fe76e" category="inline-link-rx"></block>。</block>
  <block id="efb9afc2e01262d41bf1fa60ddc36414" category="paragraph">NetApp Cloud Insights は、 Web ベースの監視ツールです。ネットアップやその他のサードパーティインフラコンポーネントで実行されているインフラやアプリケーションを完全に可視化できます。Cloud Insights は、リソースの監視、トラブルシューティング、最適化のためにプライベートクラウドとパブリッククラウドの両方をサポートしています。</block>
  <block id="4894eb73d4d2ad7eaebb0968e871cb70" category="paragraph">データコレクタからの指標をエージェントなしで収集するには、 Acquisition Unit VM （ Windows または Linux ）だけをプライベートクラウドにインストールする必要があります。エージェントベースのデータコレクタを使用すると、 Windows パフォーマンスモニタまたは Tegraf がサポートする入力エージェントからカスタムメトリックを取得できます。</block>
  <block id="32e49e2645f559763ede8e346bbcb816" category="paragraph">次の図は、 Cloud Insights VDS ダッシュボードを示しています。</block>
  <block id="cb9ecf4f0010c9ec12b73a00e06a9237" category="paragraph"><block ref="cb9ecf4f0010c9ec12b73a00e06a9237" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3bd1406c323c740b5b2f2a7615ad62ca" category="paragraph">NetApp Cloud Insights の詳細については、を参照してください<block ref="5fdb6e8524eb99916602753c65f2f24e" category="inline-link-rx"></block>。</block>
  <block id="48a2bc9c10adbea95074594015793272" category="summary">ワークスペースはデスクトップ環境で構成されます。この環境は、オンプレミスまたは任意のサポートクラウド環境でホストされる共有リモートデスクトップセッションにすることができます。Microsoft Azure では、 Windows 仮想デスクトップを使用してデスクトップ環境を永続化できます。各ワークスペースは、特定の組織またはクライアントに関連付けられます。</block>
  <block id="1da2374b50f497e208c8dab11e6b2c98" category="doc">ワークスペース管理</block>
  <block id="42a6c6312ce8b92836d9e74d89998e89" category="paragraph"><block ref="42a6c6312ce8b92836d9e74d89998e89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d49083c2604eac2881e01b4acea428e" category="admonition">各ワークスペースは、特定の配置に関連付けられます。</block>
  <block id="2a1fdca12b05c0f5292a8670b24cb478" category="paragraph">ワークスペースには、関連するアプリケーションとアプリケーションサービス、共有データフォルダ、サーバ、 WVD インスタンスが含まれます。各ワークスペースでは、パスワードの複雑さの適用、多要素認証、ファイル監査などのセキュリティオプションを制御できます。</block>
  <block id="f29490b04a344e19674ee8d1db337d14" category="paragraph">ワークスペースでは、追加のサーバの電源投入、サーバあたりのユーザ数の制限、または特定の期間に使用可能なリソースのスケジュールの設定（常にオン / オフ）を行うためのワークロードスケジュールを制御できます。リソースは、オンデマンドでウェイクアップするように設定することもできます。</block>
  <block id="421b47ffd946ca083b65cd668c6b17e6" category="inline-link">ビデオ</block>
  <block id="ff13351bb4dc0c877064ec1672d6723f" category="inline-link-macro">次の例は、アプリケーション管理です</block>
  <block id="bb974af58c318849f0fce8f7c3ecdf37" category="paragraph"><block ref="bb974af58c318849f0fce8f7c3ecdf37" category="inline-link-macro-rx"></block></block>
  <block id="7d37fde7375502ef1013412159477502" category="summary">ネットアップは、 WVD やリモートアプリケーションによる仮想デスクトップの高速プロビジョニングなどの多くのクラウドサービスを提供し、 Azure NetApp Files との迅速な統合も実現しています。</block>
  <block id="28850fd0c108cc5f990fc4b4b52ab60d" category="doc">ネットアップ仮想デスクトップサービスの概要</block>
  <block id="0276a1f5f692f2e9635f3733b371cf70" category="paragraph">Microsoft Azure Windows Virtual Desktop サービスを使用すると、リモートデスクトップサービスコンポーネントのメンテナンスを Microsoft が行い、お客様はクラウド内でのワークスペースのプロビジョニングに集中できます。お客様は、 VDI 環境を管理するために特別なスキルを必要とする完全なスタックをプロビジョニングして管理する必要があります。</block>
  <block id="51db16f7b26a08952beb43836ad3f31d" category="paragraph">NetApp VDS を使用すると、ブローカー、ゲートウェイ、エージェントなどのアーキテクチャコンポーネントのインストール場所を気にすることなく、仮想デスクトップを迅速に導入できます。環境を完全に管理する必要があるお客様は、プロフェッショナルサービスチームと協力して目標を達成できます。お客様は VDS をサービスとして利用するため、主なビジネス上の課題に注力できます。</block>
  <block id="139562ef7df2deed82d586ebe297a082" category="paragraph">ネットアップの VDS は、 AWS 、 Azure 、 GCP 、プライベートクラウド環境の複数の導入を一元管理するソフトウェアサービスです。Microsoft Windows Virtual Desktop は、 Microsoft Azure でのみ使用できます。NetApp VDS は、他の環境で Microsoft リモートデスクトップサービスのオーケストレーションを行います。</block>
  <block id="416feb9f77def2ffedaab40a538d47e5" category="paragraph">次の図に、導入トポロジの例を示します。</block>
  <block id="e377917f3505cdb9fc72b74164df5928" category="paragraph"><block ref="e377917f3505cdb9fc72b74164df5928" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d271ca257d56879fcc9ed95d82aabaa7" category="paragraph">各展開は、 Active Directory ドメインに関連付けられ、ワークスペースおよびアプリケーションのアクセスエントリポイントをクライアントに提供します。複数の Active Directory ドメインを持つサービスプロバイダまたは企業は、通常、より多くの導入環境を持っています。複数のリージョンにまたがる単一の Active Directory ドメインには、通常、複数のサイトを含む単一の導入環境があります。</block>
  <block id="3e8cd47ad0ab71d0b3891f85212ccdbc" category="paragraph">各導入環境には独自のプラットフォームサービスがあり、 Cloud Workspace Manager （ REST API エンドポイント）、 HTML 5 ゲートウェイ（ VDS 管理ポータルから VM に接続）、 RDS ゲートウェイ（クライアントのアクセスポイント）、およびドメインコントローラで構成されます。次の図は、 RDS 実装用の VDS コントロールプレーンアーキテクチャを示しています。</block>
  <block id="38606818aeffd06d174e51013afc23a1" category="paragraph"><block ref="38606818aeffd06d174e51013afc23a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58cad6a2c8c8ff1a585bf8d6ca94560" category="paragraph">RDS 環境では、 Windows とブラウザから NetApp VDS にクライアントソフトウェアを使用して簡単にアクセスできます。クライアントソフトウェアを使用して、顧客のロゴとイメージを含めるようにカスタマイズできます。ユーザーの資格情報に基づいて、承認されたワークスペースとアプリケーションへのユーザーアクセスを提供します。ゲートウェイの詳細を設定する必要はありません。</block>
  <block id="c2dcf4d443be38a737d1e580fb4b86ec" category="paragraph">次の図は、 NetApp VDS クライアントを示しています。</block>
  <block id="8e7d56f1d99fdc8080a747bf8b1eda75" category="paragraph"><block ref="8e7d56f1d99fdc8080a747bf8b1eda75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e4318c1c6ae62544ba67e7c0fe55649" category="paragraph">次の図は、 Azure WVD 実装用の VDS コントロールプレーンアーキテクチャを示しています。</block>
  <block id="ba9e4c82a95db68279bffa8ca8a8803f" category="paragraph"><block ref="ba9e4c82a95db68279bffa8ca8a8803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d648a5d4acf66674fb86cc7be05bd5e" category="paragraph">必要なコンポーネントの導入と構成に加えて、ネットアップ VDS はユーザ管理、アプリケーション管理、リソースの拡張、最適化も行います。</block>
  <block id="3ea30729e0e7f0d666400ccc1a6f7bc3" category="paragraph">ネットアップの VDS では、ユーザを作成したり、既存のユーザアカウントにクラウドワークスペースやアプリケーションサービスへのアクセスを許可したりできます。ポータルは、パスワードのリセットや、一部のコンポーネントの管理の委譲にも使用できます。ヘルプデスク管理者またはレベル 3 の技術者は、トラブルシューティングのためのユーザーセッションをシャドウイングしたり、ポータル内からサーバーに接続したりすることができます。</block>
  <block id="91d75bd7e517ef4b563021e6d23d8cb9" category="inline-link-macro">次の手順： NetApp HCI の概要</block>
  <block id="3806ab54895f78b6c34b626314f84e6e" category="paragraph"><block ref="3806ab54895f78b6c34b626314f84e6e" category="inline-link-macro-rx"></block></block>
  <block id="2cdacde3c74a59c779ff64324954b86f" category="summary">ネットアップの仮想デスクトップサービス（ VDS ）は、主要なパブリッククラウドとプライベートクラウドで Remote Desktop Services （ RDS ）のオーケストレーションを実現します。VDS は、 Microsoft Azure で Windows Virtual Desktop （ WVD ）をサポートします。VDS は、 WVD または RDS の導入後に実行する必要がある多くのタスクを自動化します。たとえば、 SMB ファイル共有（ユーザプロファイル、共有データ、およびユーザホームドライブ用）の設定、 Windows の機能、アプリケーションとエージェントのインストール、ファイアウォール、ポリシーなどを有効にします。</block>
  <block id="acb7add6e3cf0ca01c52e60466c321ca" category="doc">TR-4861 ：『 Hybrid Cloud VDI with Virtual Desktop Service 』</block>
  <block id="bb6a5b934db24610665e58e743983ae4" category="paragraph">ユーザは専用デスクトップ、共有デスクトップ、およびリモートアプリケーション用の VDS を使用します。VDS では、デスクトップのアプリケーション管理を自動化するスクリプト化されたイベントが提供され、管理するイメージの数が削減されます。</block>
  <block id="38e3c8e108e8e361d0712cdfe23e0b38" category="paragraph">VDS では、パブリッククラウド環境とプライベートクラウド環境の導入を処理するための単一の管理ポータルが提供されます。</block>
  <block id="07d07e20c1ad9bd1a3e99e2303879ff9" category="paragraph">2020 年のリモートワーカーの急増により、ビジネス継続性の要件が変化しています。IT 部門は、仮想デスクトップを迅速にプロビジョニングするという新たな課題に直面しています。そのためには、オンプレミスとクラウドのリソースのプロビジョニングを簡単に行えるハイブリッドクラウドのプロビジョニング即応性、リモート管理、 TCO のメリットが必要です。次のようなハイブリッドクラウド解決策が必要です。</block>
  <block id="44ff202cbab5f506b48c6021b19c4b1c" category="list-text">新型コロナウイルス感染症ワークスペースの実際の状況に対処して、柔軟なワークモデルを実現します グローバルダイナミクスを備えています</block>
  <block id="53f994926861d0a62f2893b66d8b2025" category="list-text">タスクワーカーからパワーユーザまで、すべての従業員の作業環境の導入を簡素化し、迅速化することで、シフトワークを可能にします</block>
  <block id="831955bd9eabf6724f4e4b01acbb833c" category="list-text">物理的な場所に関係なく、リッチでセキュアな VDI リソースを提供することで、従業員をモバイル化します</block>
  <block id="ab02aa4712e65c237e92874eeef51ecd" category="list-text">ハイブリッドクラウドの導入を簡易化</block>
  <block id="074890ea8810b95d9b381027ff9baef2" category="list-text">リスク軽減管理を自動化して簡素化します</block>
  <block id="60e1de201d0c183e889577e990975f1a" category="paragraph"><block ref="60e1de201d0c183e889577e990975f1a" category="inline-link-macro-rx"></block></block>
  <block id="49fc376ed35249f3841846ede4dab884" category="inline-link">NetApp Cloud Central</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">追加情報の参照先</block>
  <block id="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link"><block ref="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link-rx"></block></block>
  <block id="bc0f3321a29c580fa0e3cca0c00ee7cd" category="list-text">VMware 製品ドキュメント<block ref="3bdcd80def6a1e2849d8b38049a04af9" category="inline-link-rx"></block></block>
  <block id="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link"><block ref="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link-rx"></block></block>
  <block id="0f185ccd88416daec4eee0a846d110b8" category="list-text">ネットアップの製品マニュアル<block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="doc">推奨される ESXi ホストとその他の ONTAP 設定</block>
  <block id="0416d04b345b434b120840c30ddaf0a1" category="paragraph">ネットアップでは、 ONTAP を使用する際に適切に動作する ESXi ホストのマルチパスと HBA タイムアウトの設定を、テスト結果に基づいて作成しました。これらは、 VMware vSphere 用の ONTAP ツールを使用して簡単に設定できます。サマリダッシュボードで、ホストシステムポートレットの設定の編集をクリックするか、 vCenter でホストを右クリックして、 ONTAP ツール &gt; 推奨値の設定を選択します。9.8 リリースで現在推奨されているホスト設定は次のとおりです。</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3.HardwareAcceleratedLocking</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete の 2 つのオプションがあります</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">Net.TcpipHeapSize の場合</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">Net.TcpipHeapMax</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes の場合</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.MaxVolumes の場合</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">vSphere 6.0 以降では、 256 に設定されます。</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures の略</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">nfs.HeartbeatFrequency</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">nfs.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">すべての NFS 設定について、 5 に設定されます。</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">SunRPC.MaxConnPerIP</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">vSphere 7.0 以降では 128 に設定されます。</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">パス選択ポリシー</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.qFullThreshold</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Emulex FC HBA タイムアウト</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">デフォルト値を使用します。</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">QLogic FC HBA タイムアウト</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">ONTAP ツールでは、 ONTAP FlexVol および LUN の作成時に特定のデフォルト設定も指定されます。</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">Snapshot リザーブ（ -percent-snapshot-space ）</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">フラクショナルリザーブ（ -fractional-reserve ）</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">アクセス時間の更新（ -atime-update ）</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">いいえ</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">最小限の先読み（ -min-readahead ）</block>
  <block id="eee57b9c7d333899f3df6ffd10ec50df" category="cell">スケジュールされた Snapshot コピー</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">ストレージ効率</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">有効</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">ボリュームギャランティ</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">なし（シンプロビジョニング）</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">ボリュームのオートサイズ</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">grow_shrink</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">LUN のスペースリザベーション</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">無効</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">LUN スペースの割り当て</block>
  <block id="0464f851d84d05f0a9db9051354e5581" category="section-title">その他のホストマルチパス構成に関する考慮事項</block>
  <block id="5fcb3de72ca1920517439049153d961d" category="paragraph">現在使用可能な ONTAP ツールで設定されていませんが、以下の設定オプションを検討することを推奨します。</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">ハイパフォーマンスな環境で、または単一の LUN データストアでパフォーマンスをテストする場合は、ラウンドロビン（ VMW_PSP_RR ）パス選択ポリシー（ PSP ）の負荷分散設定をデフォルトの IOPS 設定 1000 から 1 に変更することを検討します。VMware の技術情報を参照<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> 詳細については、</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">パス選択プラグインとポリシー</block>
  <block id="249afbf456bd04d574e8d362d5bf133c" category="list-text">vSphere 6.7 Update 1 では、 VMware がラウンドロビン PSP 用に新しいレイテンシの負荷分散メカニズムを導入しました。新しいオプションでは、 I/O に最適なパスを選択する際に、 I/O 帯域幅とパスレイテンシが考慮されます1 つのパスに別のパスよりも多くのネットワークホップがある場合や、 NetApp All SAN Array システムを使用している場合など、パス接続に同等でない環境では、この方法を使用するとメリットが得られます。を参照してください<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> を参照してください。</block>
  <block id="3b2287aeb862e195f44c02694fff89fe" category="summary">SnapCenter では、複数のジョブに適用可能なバックアップポリシーを作成できます。これらのポリシーでは、スケジュール、保持、レプリケーションなどの機能を定義できます。VMware スナップショットを作成する前に、ハイパーバイザの機能を活用して I/O を休止する、オプションの VM 整合性スナップショットを選択できます。</block>
  <block id="b1c93d491ba776d955eb2e3b90908fb9" category="doc">vSphere 向けのその他の機能</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="section-title">データ保護</block>
  <block id="343775d7b18c4ca0af9b7fad57690839" category="paragraph">VM のバックアップと迅速なリカバリは、 ONTAP for vSphere の大きな特長の 1 つです。この機能は、 SnapCenter Plug-in for VMware vSphere を使用して vCenter 内で簡単に管理できます。Snapshot コピーを使用すると、パフォーマンスに影響を与えることなく VM やデータストアのコピーをすばやく作成し、 SnapMirror を使用してセカンダリシステムに送信し、長期にわたるオフサイトでのデータ保護を実現できます。このアプローチでは、変更された情報のみを格納することで、ストレージスペースとネットワーク帯域幅を最小限に抑えます。</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">（推奨）</block>
  <block id="8cc688149346249b3a92e59282755f3e" category="paragraph">SnapCenter では、複数のジョブに適用可能なバックアップポリシーを作成できます。これらのポリシーでは、スケジュール、保持、レプリケーションなどの機能を定義できます。VMware スナップショットを作成する前に、ハイパーバイザの機能を活用して I/O を休止する、オプションの VM 整合性スナップショットを選択できます。ただし、 VMware スナップショットはパフォーマンスへの影響があるため、ゲストファイルシステムを休止する必要がないかぎり、一般には推奨されません。代わりに、 ONTAP の Snapshot コピーを使用して一般的な保護を行い、 SnapCenter プラグインなどのアプリケーションツールを使用して SQL Server や Oracle などのトランザクションデータを保護します。これらの Snapshot コピーは VMware （整合性） Snapshot とは別のものであり、長期的な保護に適しています。VMware スナップショットはのみです<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> パフォーマンスやその他の影響があるため、短期的な使用に適しています。</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">これらのプラグインは、物理環境と仮想環境の両方でデータベースを保護する拡張機能を提供します。vSphere では、これらのプロトコルを使用して、 RDM LUN 、ゲスト OS に直接接続された iSCSI LUN 、 VMFS または NFS データストア上の VMDK ファイルにデータが格納されている SQL Server または Oracle データベースを保護できます。プラグインでは、さまざまなタイプのデータベースバックアップを指定し、オンラインまたはオフラインのバックアップをサポートし、ログファイルとともにデータベースファイルを保護できます。プラグインは、バックアップとリカバリに加えて、開発やテスト目的でのデータベースのクローニングにも対応しています。</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">次の図は、 SnapCenter の導入例を示しています。</block>
  <block id="54ee9d8cd5db70a761321f3e7d168445" category="paragraph"><block ref="54ee9d8cd5db70a761321f3e7d168445" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">ディザスタリカバリ機能を強化するには、 ONTAP 用 NetApp SRA と VMware Site Recovery Manager の使用を検討してください。DR サイトへのデータストアのレプリケーションをサポートするだけでなく、レプリケートしたデータストアをクローニングすることで DR 環境を無停止でテストすることもできます。SRA に組み込まれている自動化機能を使用すると、災害からのリカバリや、システム停止が解決したあとの本番環境の再保護も簡単に実行できます。</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">最後に、最高レベルのデータ保護を実現するために、 NetApp MetroCluster を使用した VMware vSphere Metro Storage Cluster （ vMSC ）設定を検討してください。vMSC は、同期レプリケーションとアレイベースのクラスタリングを組み合わせた VMware 認定の解決策です。高可用性クラスタと同じメリットを提供しますが、複数のサイトに分散してサイト障害から保護します。NetApp MetroCluster は、同期レプリケーション向けの対費用効果の高い構成を提供します。ストレージコンポーネントのあらゆる単一障害から透過的にリカバリでき、サイト障害時にコマンド 1 つでリカバリできます。vMSC の詳細については、を参照してください<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>。</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">スペース再生</block>
  <block id="d490382851fbc5bd6720046bf9bc0c03" category="paragraph">VM がデータストアから削除されたときに、他の目的でスペースを再生することができます。NFS データストアを使用している場合、 VM が削除されるとすぐにスペースが再生されます（もちろん、このアプローチはボリュームがシンプロビジョニングされている場合、つまりボリュームギャランティが none に設定されている場合にのみ有効です）。ただし、 VM のゲスト OS 内でファイルが削除されても、 NFS データストアではスペースが自動的に再生されません。LUN ベースの VMFS データストアの場合、 ESXi およびゲスト OS は、問題 VAAI UNMAP プリミティブをストレージに（シンプロビジョニングを使用している場合に）再利用できます。リリースによっては、このサポートは手動と自動のどちらかになります。</block>
  <block id="6a2bff0a8d10ca0fc6c782e7978f696a" category="inline-link">2057513</block>
  <block id="8927aab76c49d1deb0b407fd261d5aa6" category="inline-link">ストレージスペースの再生</block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="section-title">VM とデータストアのクローニング</block>
  <block id="d355cf5d1a16095124a54902f7cf49db" category="paragraph">ストレージオブジェクトをクローニングすると、追加の VM のプロビジョニングやバックアップ / リカバリ処理などの用途に使用できるコピーを簡単に作成できます。vSphere では、 VM 、仮想ディスク、 VVOL 、またはデータストアをクローニングできます。クローニングされたオブジェクトは、多くの場合、自動化されたプロセスによってさらにカスタマイズできます。vSphere では、フルコピークローンとリンククローンの両方がサポートされます。リンククローンでは、元のオブジェクトとは別に変更が追跡されます。</block>
  <block id="78f8f8d69825dfe8e6085151fa565f28" category="paragraph">リンククローンはスペースを節約するのに適していますが、 vSphere が VM に対して処理する I/O 量が増えるため、その VM のパフォーマンスや場合によってはホスト全体のパフォーマンスに影響します。そのため、 NetApp のお客様は、ストレージシステムベースのクローンを使用して、ストレージの効率的な使用とパフォーマンスの向上という両方のメリットを得ることがよくあります。</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">次の図は、 ONTAP クローニングを示しています。</block>
  <block id="8ee3cd3dba25fb32f1bc38cb528ac998" category="paragraph"><block ref="8ee3cd3dba25fb32f1bc38cb528ac998" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">クローニングは、 ONTAP ソフトウェアを実行するシステムに複数のメカニズムを使用してオフロードできます。通常は、 VM 、 VVol 、データストアのレベルでオフロードします。これには次のものが含まれます。</block>
  <block id="3b6d066ffdecb2beb542ef68e773d4ae" category="list-text">NetApp vSphere APIs for Storage Awareness （ VASA ） Provider を使用した VVol のクローニング。ONTAP クローンは、 vCenter で管理される VVol Snapshot コピーをサポートするために使用されます。 VVol Snapshot コピーはスペース効率に優れており、作成や削除の I/O の影響を最小限に抑えることができます。VM のクローニングは vCenter を使用して行うこともでき、 1 つのデータストア / ボリューム内かデータストア / ボリューム間かに関係なく、 ONTAP にオフロードされます。</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">vSphere APIs – Array Integration （ VAAI ）を使用した vSphere のクローニングと移行：SAN 環境と NAS 環境の両方で、 VM のクローニング処理を ONTAP にオフロードできます（ネットアップでは、 NFS 用の VAAI を有効にするために ESXi プラグインを提供しています）。vSphere は、 NAS データストア内のコールド（電源オフ） VM にのみオフロードします。一方、ホット VM （クローニングと Storage vMotion ）の処理も SAN にオフロードされます。ONTAP では、ソース、デスティネーション、インストールされている製品ライセンスに基づいて最も効率的なアプローチを採用しています。この機能は VMware Horizon View でも使用されています。</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA （ VMware Site Recovery Manager で使用）。ここでは、クローンを使用して、 DR レプリカのリカバリを無停止でテストします。</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">SnapCenter などのネットアップのツールを使用したバックアップとリカバリVM クローンは、バックアップ処理の検証や VM バックアップのマウントに使用され、個々のファイルをコピーできるようにします。</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">ONTAP オフロードクローニングは、 VMware 、ネットアップ、サードパーティのツールから実行できます。ONTAP にオフロードされたクローンには、いくつかのメリットがあります。ほとんどの場合、スペース効率に優れており、オブジェクトの変更にのみ対応するストレージが必要です。読み取りや書き込みのパフォーマンスには影響しません。また、高速キャッシュでブロックを共有することでパフォーマンスが向上する場合もあります。また、 CPU サイクルとネットワーク I/O も ESXi サーバからオフロードされます。FlexVol を使用する従来のデータストア内でのコピーオフロードは、 FlexClone ライセンスを使用すると高速かつ効率的ですが、 FlexVol 間のコピーの方が低速になる可能性があります。VM テンプレートをクローンのソースとして管理する場合は、スペース効率に優れた高速クローンを作成するために、テンプレートをデータストアボリューム内に配置することを検討してください（フォルダやコンテンツライブラリを使用してテンプレートを整理します）。</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">ONTAP 内で直接ボリュームまたは LUN をクローニングして、データストアをクローニングすることもできます。NFS データストアの場合は、 FlexClone テクノロジでボリューム全体をクローニングし、 ONTAP からクローンをエクスポートして、別のデータストアとして ESXi にマウントできます。VMFS データストアの場合は、ボリューム内の LUN 、または 1 つ以上の LUN を含むボリューム全体を ONTAP でクローニングできます。VMFS を含む LUN を通常のデータストアとしてマウントして使用するためには、 LUN を ESXi igroup にマッピングし、 ESXi から再署名を受ける必要があります。ただし一部の一時的なユースケースでは、クローニングされた VMFS を再署名なしでマウントすることができます。クローニングしたデータストア内の VM は、個別にクローニングした VM と同様に登録、再設定、およびカスタマイズすることができます。</block>
  <block id="1c12a8dd266e356901d22c0b7711369d" category="paragraph">バックアップや FlexClone 用の SnapRestore など、追加のライセンス機能を使用してクローニングを強化できる場合があります。これらのライセンスは、追加コストなしでライセンスバンドルに含まれていることがよくあります。FlexClone ライセンスは、 VVOL のクローニング処理、および VVOL の管理対象 Snapshot コピー（ハイパーバイザーから ONTAP にオフロード）をサポートするために必要です。FlexClone をデータストア / ボリューム内で使用すると、特定の VAAI ベースのクローンの品質を向上させることもできます（ブロックコピーではなく、スペース効率に優れたコピーが瞬時に作成されます）。また、 DR レプリカのリカバリをテストする際に SRA で使用され、クローニング処理用に SnapCenter でバックアップコピーを参照して個々のファイルをリストアする際にも使用されます。</block>
  <block id="6d30b2619de7fa18e965516b291a1937" category="section-title">ストレージ効率とシンプロビジョニング</block>
  <block id="616c027f14ee5f1bbc866171c4017141" category="paragraph">ネットアップは、プライマリワークロードに初めて重複排除を適用するなどの Storage Efficiency の革新的なテクノロジを業界でリードしてきました。インラインデータコンパクションは、圧縮機能を強化し、小さなファイルと I/O を効率的に格納する機能です。ONTAP は、インライン重複排除とバックグラウンド重複排除のほか、インライン圧縮とバックグラウンド圧縮の両方をサポートしています。</block>
  <block id="8f105eeb6dc3fc4ce0d4758aeab4a256" category="paragraph">次の図は、 ONTAP の Storage Efficiency 機能の効果を組み合わせたものです。</block>
  <block id="4b7a9b58ab55917c054d5a636481a8b8" category="paragraph"><block ref="4b7a9b58ab55917c054d5a636481a8b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e89f9787f44321e33f85595321efc66" category="paragraph">vSphere 環境で ONTAP の Storage Efficiency 機能を使用する際の推奨事項を次に示します。</block>
  <block id="c2eea4e122397fa75d749bdbdcd4302d" category="list-text">重複排除によって削減されるデータ量は、データにどれくらい共通部分があるかによって異なります。ONTAP 9.1 以前では、データ重複排除はボリュームレベルで機能しましたが、 ONTAP 9.2 以降のアグリゲート重複排除では、 AFF システムのアグリゲート内のすべてのボリュームのデータが重複排除されます。削減効果を最大化するために、類似するオペレーティングシステムやアプリケーションを 1 つのデータストア内にグループ化する必要はなくなりました。</block>
  <block id="59eb554aa77d0e4dfdc304b3b914dd76" category="list-text">ブロック環境で重複排除のメリットを実現するには、 LUN をシンプロビジョニングする必要があります。VM 管理者からは引き続き LUN がプロビジョニング済み容量として認識されますが、重複排除による削減効果は他のニーズに使用できるようにボリュームに戻されます。これらの LUN は、シンプロビジョニングされた FlexVol ボリュームに導入することを推奨します（ VMware vSphere 用の ONTAP ツールでは、ボリュームのサイズが LUN よりも約 5% 大きくなるように設定しています）。</block>
  <block id="1e84230a4e75abc233d64344b14fd511" category="list-text">NFS FlexVol ボリュームにはシンプロビジョニングも推奨されます（デフォルトです）。NFS 環境では、シンプロビジョニングされたボリュームを使用しているストレージ管理者と VM 管理者の両方に、重複排除による削減効果がすぐに反映されます。</block>
  <block id="b26ed63d0f1199652537e2c4b6752130" category="list-text">シンプロビジョニング環境 VM も同様です。ネットアップでは、一般にシックプロビジョニングではなくシンプロビジョニングされた VMDK を推奨しています。シンプロビジョニングを使用する場合は、スペース不足の問題を回避するために、 VMware vSphere 、 ONTAP 、またはその他の使用可能なツール用の ONTAP ツールで利用可能なスペースを監視してください。</block>
  <block id="041f3a2c9d939c181dbd2a95595455d0" category="list-text">ONTAP システムでシンプロビジョニングを使用した場合はパフォーマンスが低下しないことに注意してください。データは使用可能なスペースに書き込まれるため、書き込みパフォーマンスと読み取りパフォーマンスが最大限に高まります。この事実にもかかわらず、 Microsoft フェイルオーバークラスタリングやその他の低レイテンシアプリケーションなどの一部の製品では、保証されたプロビジョニングや固定プロビジョニングが必要になる場合があります。また、サポートの問題を回避するには、これらの要件に従うことを推奨します。</block>
  <block id="473c8efc5f9b8640820a9cc1f9c84862" category="list-text">重複排除による削減効果を最大限に高めるために、ハードディスクベースのシステムでのバックグラウンド重複排除または AFF システムでの自動バックグラウンド重複排除のスケジュールを設定することを検討してください。ただし、スケジュールされたプロセスは実行時にシステムリソースを使用するため、非アクティブな時間帯（週末など）にスケジュールを設定するか、より頻繁に実行して処理される変更データの量を減らすことが理想的です。AFF システムでの自動バックグラウンド重複排除は、フォアグラウンドアクティビティへの影響を大幅に軽減します。バックグラウンド圧縮（ハードディスクベースのシステムの場合）でもリソースが消費されるため、パフォーマンス要件が限定されたセカンダリワークロードでのみ考慮する必要があります。</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">こちらの技術情報アーティクル</block>
  <block id="ac2fab512a521d04e53c7257ef490187" category="list-text">NetApp AFF システムは、主にインラインの Storage Efficiency 機能を使用します。7-Mode Transition Tool 、 SnapMirror 、ボリューム移動などのブロックレプリケーションを使用するネットアップのツールを使用してデータを移動する場合は、圧縮スキャナやコンパクションスキャナを実行して、効率化による削減効果を最大限に高めると効果的です。このネットアップサポートを確認してください<block ref="a24ae202a787a3e4695f02339b72bb57" category="inline-link-rx"></block> を参照してください。</block>
  <block id="af21d2d4e0d0faaa6435e780ed7fbc49" category="list-text">圧縮や重複排除によって削減できるブロックが Snapshot コピーによってロックされる場合があります。スケジュールされたバックグラウンドの効率化スキャナまたはワンタイムスキャナを使用する場合は、次の Snapshot コピーが作成される前に、それらの効率化処理が実行および完了していることを確認してください。Snapshot コピーと保持設定を確認して、特にバックグラウンドジョブやスキャナジョブを実行する前に、必要な Snapshot コピーだけを保持していることを確認してください。</block>
  <block id="8f4468ee9f4f074a9f705cd8240de3d9" category="paragraph">次の表に、さまざまなタイプの ONTAP ストレージ上にある仮想ワークロードのストレージ効率化のガイドラインを示します。</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">ワークロード</block>
  <block id="84f3306d313cbbe707b0df3807aa77ef" category="cell">Storage Efficiency に関するガイドライン</block>
  <block id="5325da9878854628027602da18e5fc14" category="cell">Flash Pool の機能です</block>
  <block id="9aa1187640093122ffdb7e1c18f8586d" category="cell">ハードディスクドライブ</block>
  <block id="9bbf225892f3ce69fc504d145abe3ded" category="cell">VDI および SVI</block>
  <block id="1be6174441cf80d01c59eb7a9c004498" category="paragraph">プライマリワークロードとセカンダリワークロード：</block>
  <block id="738b6df06bc30a1f2fa6d500095bfceb" category="list-text">アダプティブインライン圧縮</block>
  <block id="f801303ba7009e27cce2fe9a73dc5ebe" category="list-text">インライン重複排除</block>
  <block id="f94a70bfe4407315e07db5e64706e531" category="list-text">バックグラウンド重複排除</block>
  <block id="95f3762d2d933ff2c0f6e30ef2c767c9" category="list-text">インラインデータコンパクション</block>
  <block id="22be9b04282591df89574efb0e9d2315" category="paragraph">プライマリワークロードには次の機能を使用：</block>
  <block id="e37f23785e68eb0a9d5afd7457b0903e" category="paragraph">セカンダリワークロードの場合：</block>
  <block id="7901e1160498e7aff40dc0f858411c54" category="list-text">バックグラウンドアダプティブ圧縮</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="section-title">サービス品質（ QoS ）</block>
  <block id="f437881fa7e42bf0e4563bbec8176f81" category="paragraph">ONTAP ソフトウェアを実行するシステムでは、 ONTAP ストレージ QoS 機能を使用して、ファイル、 LUN 、ボリューム、 SVM 全体などの異なるストレージオブジェクトに対するスループットを MBps や IOPS （ 1 秒あたりの I/O 数）で制限できます。</block>
  <block id="fb4aa9631cd742ae8a88f672b4464b37" category="paragraph">スループット制限は、他のワークロードに影響しないように、導入前に不明なワークロードやテストワークロードを制御するのに役立ちます。また、 Bully ワークロードが特定された場合に、この 2 つを使用して抑制することもできます。ONTAP 9.2 では SAN オブジェクトに、 ONTAP 9.3 では NAS オブジェクトに一貫したパフォーマンスを提供するために、 IOPS に基づく最小サービスレベルもサポートされています。</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">NFS データストアの場合は、 QoS ポリシーを FlexVol 全体またはボリューム内の個々の VMDK ファイルに適用できます。ONTAP LUN を使用する VMFS データストアでは、 LUN を含む FlexVol ボリュームには QoS ポリシーを適用できますが、 ONTAP が VMFS ファイルシステムを認識しないため、個々の VMDK ファイルには適用できません。VVol を使用する場合は、ストレージ機能プロファイルと VM ストレージポリシーを使用して、個々の VM に最小 QoS と最大 QoS を設定できます。</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">オブジェクトに対する QoS の最大スループット制限は、 MBps と IOPS のいずれかまたは両方で設定できます。両方を使用する場合は、最初に到達した制限が ONTAP によって適用されます。ワークロードには複数のオブジェクトを含めることができ、 QoS ポリシーは 1 つ以上のワークロードに適用できます。ポリシーを複数のワークロードに適用した場合は、ポリシーの制限はワークロード全体に適用されます。ネストされたオブジェクトはサポートされません（たとえば、ボリューム内のファイルには個別のポリシーを設定することはできません）。QoS の最小値は IOPS 単位でのみ設定できます。</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">ONTAP QoS ポリシーの管理とオブジェクトへの適用に現在使用できるツールは次のとおりです。</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">ONTAP CLI</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">ONTAP システムマネージャ</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation のサポートを利用できます</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">NetApp PowerShell Toolkit for ONTAP 』を参照してください</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">VMware vSphere VASA Provider 用の ONTAP ツール</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">NFS 上の VMDK に QoS ポリシーを割り当てる場合は、次のガイドラインに注意してください。</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">ポリシーは 'vmname.vmdk （仮想ディスク記述子ファイル）や 'vmname.vmx （ VM 記述子ファイル）ではなく ' 実際の仮想ディスクイメージを含む 'vmname-flat.vmdk に適用する必要があります</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">仮想スワップ・ファイル（「 vmname.vswp 」）などの他の VM ファイルにはポリシーを適用しないでください。</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">vSphere Web クライアントを使用してファイルパスを検索する場合は、「 -flat.vmdk 」と「」の情報が結合されていることに注意してください。VMDK とは ' という名前のファイルを 1 つだけ示しますVMDK ですが '-flat.vmdk のサイズです正しいパスを取得するには、ファイル名に「 -flat」 を追加します。</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">VMFS と RDM 、 ONTAP SVM （ SVM として表示）、 LUN パス、シリアル番号などの LUN に QoS ポリシーを割り当てるには、 ONTAP Tools for VMware vSphere のホームページのストレージシステムメニューから QoS ポリシーを取得します。ストレージシステム（ SVM ）を選択し、 Related Objects &gt; SAN の順に選択します。この方法は、いずれかの ONTAP ツールを使用して QoS を指定する場合に使用します。</block>
  <block id="8ce0096ff26ebe0a38466de6a64f461d" category="paragraph">VVol ベースの VM には、 VMware vSphere または Virtual Storage Console 7.1 以降の ONTAP ツールを使用して、最大 QoS と最小 QoS を簡単に割り当てることができます。VVol コンテナのストレージ機能プロファイルを作成するときは、パフォーマンス機能の下に最大 IOPS または最小 IOPS の値を指定し、この SCP を VM のストレージポリシーで参照します。このポリシーは VM を作成するときに使用するか、ポリシーを既存の VM に適用します。</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">FlexGroup データストアでは、 ONTAP ツールを VMware vSphere 9.8 以降で使用する場合に、 QoS 機能が強化されています。QoS は、データストア内のすべての VM 、または特定の VM に簡単に設定できます。詳細については、本レポートの「 FlexGroup 」セクションを参照してください。</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">ONTAP の QoS と VMware の SIOC</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">ONTAP の QoS と VMware vSphere の Storage I/O Control （ SIOC ）は、 vSphere 管理者とストレージ管理者が組み合わせて、 ONTAP ソフトウェアを実行するシステムでホストされる vSphere VM のパフォーマンスを管理できる、相互に補完するテクノロジです。各ツールには、次の表に示すようにそれぞれの長所があります。VMware vCenter と ONTAP ではスコープが異なるため、一部のオブジェクトは一方のシステムで認識および管理でき、もう一方のシステムではできません。</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">プロパティ（ Property ）</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">ONTAP QoS</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">VMware SIOC</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">アクティブになっている場合</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">ポリシーは常にアクティブです</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">競合が発生している（データストアのレイテンシがしきい値を超えている）場合</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">単位のタイプ</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS 、 MBps</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS 、共有数</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">対象となる vCenter またはアプリケーション</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">複数の vCenter 環境、その他のハイパーバイザーとアプリケーションがあります</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">単一の vCenter サーバ</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">VM に QoS を設定？</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">NFS 上の VMDK のみ</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">NFS 上または VMFS 上の VMDK です</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">LUN （ RDM ）で QoS を設定？</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">LUN （ VMFS ）への QoS の設定</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">ボリューム（ NFS データストア）への QoS の設定</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">SVM （テナント）に QoS を設定？</block>
  <block id="86aad9b5d177180a5b9e828a8e05e819" category="cell">ポリシーベースのアプローチ</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">はい。ポリシー内のすべてのワークロードで共有することも、ポリシー内の各ワークロードにフルに適用することもできます。</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">はい。 vSphere 6.5 以降が必要です。</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">ライセンスが必要です</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">ONTAP に付属しています</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise Plus</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="section-title">VMware Storage Distributed Resource Scheduler の略</block>
  <block id="06604b0172f4ae639ffe8c44fa7c77d8" category="paragraph">VMware Storage Distributed Resource Scheduler （ SDRS ）は、現在の I/O レイテンシとスペース使用量に基づいて VM をストレージに配置する vSphere の機能です。その後、 VM や VMDK の配置先として最適なデータストアをデータストアクラスタ内から選択し、システムを停止することなくデータストアクラスタ（ポッドとも呼ばれます）内のデータストア間で VM や VMDK を移動します。データストアクラスタとは、類似したデータストアを vSphere 管理者の観点から単一の消費単位に集約したものです。</block>
  <block id="5735cfd4d72f50fd28717ac30361b503" category="paragraph">SDRS を NetApp ONTAP Tools for VMware vSphere と併用する場合は、まずプラグインを使用してデータストアを作成し、 vCenter を使用してデータストアクラスタを作成し、そこにデータストアを追加する必要があります。データストアクラスタを作成したら、プロビジョニングウィザードの詳細ページからデータストアクラスタにデータストアを直接追加できます。</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">SDRS に関するその他の ONTAP のベストプラクティスは、次のとおりです。</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">クラスタ内のすべてのデータストアで同じタイプのストレージ（ SAS 、 SATA 、 SSD など）を使用し、すべて VMFS データストアまたは NFS データストアとし、レプリケーションと保護の設定を同じにします。</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">デフォルト（手動）モードでは SDRS の使用を検討してください。このアプローチでは、推奨事項を確認し、適用するかどうかを決定できます。VMDK の移行による影響を次に示します。</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">SDRS がデータストア間で VMDK を移動すると、 ONTAP のクローニングや重複排除によるスペース削減効果は失われます。重複排除機能を再実行すれば、削減効果を取り戻すことができます。</block>
  <block id="cc1aa351f771fc36d1542fa93e1fac8e" category="list-text">SDRS で VMDK を移動したあとに、移動された VM によってスペースがロックされないように、ソースデータストアで Snapshot コピーを再作成することを推奨します。</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">同じアグリゲート上のデータストア間で VMDK を移動してもメリットはほとんどなく、 SDRS はアグリゲートを共有する可能性のある他のワークロードを可視化できません。</block>
  <block id="a30850531baecbfbe4486d4be9e79e30" category="section-title">ストレージポリシーベースの管理と VVOL</block>
  <block id="f2606439d8a3fed353e38254458c0a32" category="paragraph">VMware vSphere APIs for Storage Awareness （ VASA ）を使用すると、ストレージ管理者は、明確に定義された機能を使用してデータストアを簡単に設定でき、 VM 管理者は、相互にやり取りすることなく、いつでも VM をプロビジョニングするためのこれらの機能を使用できます。仮想化ストレージの運用を合理化し、複雑な作業を回避する方法を確認するには、このアプローチを検討することをお考えください。</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">VASA が導入される前は、 VM 管理者が VM ストレージポリシーを定義することもできましたが、適切なデータストアを特定するには、多くの場合、ドキュメントや命名規則を使用する必要がありました。VASA を使用すると、ストレージ管理者は、パフォーマンス、階層化、暗号化、レプリケーションなど、さまざまなストレージ機能を定義できます。1 つのボリュームまたはボリュームセットの一連の機能を、ストレージ機能プロファイル（ SCP ）と呼びます。</block>
  <block id="a3af04d147e48682c8be6bd0c1b66520" category="paragraph">SCP は、 VM のデータ VVOL の最小および最大 QoS をサポートします。最小 QoS は AFF システムでのみサポートされます。VMware vSphere 用の ONTAP ツールには、 ONTAP システム上の VVOL の VM の詳細なパフォーマンスと論理容量を表示するダッシュボードがあります。</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">次の図は、 VMware vSphere 9.8 VVol ダッシュボード用の ONTAP ツールを示しています。</block>
  <block id="d3fcb217aa8b45eb8a95f8958c1f7746" category="paragraph"><block ref="d3fcb217aa8b45eb8a95f8958c1f7746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6257d346f635c1b16a2f39df0830a48" category="paragraph">ストレージ機能プロファイルを定義したら、そのプロファイルを使用して要件を定義するストレージポリシーを使用して VM をプロビジョニングできます。vCenter では、 VM ストレージポリシーとデータストアストレージ機能プロファイルのマッピングに基づいて、互換性があるデータストアのリストを選択対象として表示できます。この方法のことをストレージポリシーベースの管理と呼びます。</block>
  <block id="ca100a4ba1d4641f17806479f93c8b1a" category="paragraph">VASA は、ストレージを照会して一連のストレージ機能を vCenter に返すためのテクノロジを提供します。VASA ベンダープロバイダは、ストレージシステムの API およびコンストラクトと、 vCenter が認識可能な VMware API との間の変換機能を提供します。ネットアップの VASA プロバイダ for ONTAP は、 VMware vSphere アプライアンス VM 用の ONTAP ツールの一部として提供されます。 vCenter プラグインは、 VVol データストアのプロビジョニングと管理のインターフェイスと、ストレージ機能プロファイル（ SCP ）の定義機能を提供します。</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="79f0d5feb7ec25a16c407f3f585eabb2" category="paragraph">ONTAP は、 VMFS データストアと NFS データストアの両方をサポートしています。SAN データストアで VVOL を使用すると、 VM レベルのきめ細かさなど、 NFS のメリットの一部を活用できます。ここでは考慮すべきベストプラクティスをいくつか示します。また、追加情報はにあります<block ref="4f23d4db151ca74200684ac8aef53fed" category="inline-link-rx"></block>：</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">VVOL データストアは、複数のクラスタノードにある複数の FlexVol で構成できます。ボリュームごとに機能が異なる場合でも、最もシンプルなアプローチは 1 つのデータストアです。SPBM により、互換性のあるボリュームが VM に使用されています。ただし、すべてのボリュームが 1 つの ONTAP SVM に含まれていて、単一のプロトコルでアクセスできる必要があります。各プロトコルでノードごとに 1 つの LIF で十分です。1 つの VVOL データストアで複数の ONTAP リリースを使用することは避けてください。リリースによってストレージ機能が異なる場合があります。</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">VVol データストアの作成と管理には、 VMware vSphere プラグインの ONTAP ツールを使用します。データストアとそのプロファイルの管理に加え、必要に応じて、 VVOL にアクセスするためのプロトコルエンドポイントが自動的に作成されます。LUN を使用する場合、 LUN PE は 300 以上の LUN ID を使用してマッピングされます。ESXi ホストの詳細システム設定「 Disk .MaxLUN 」で 300 より大きい LUN ID 番号が許可されていることを確認します（デフォルトは 1 、 024 ）。この手順を実行するには、 vCenter で ESXi ホストを選択し、次に Configure タブを選択して、 Advanced System Settings のリストから「 Disk .MaxLUN 」を探します。</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">VASA Provider 、 vCenter Server （アプライアンスまたは Windows ベース）、または VMware vSphere 用の ONTAP ツールは相互に依存するため、 VVOL データストアにインストールしたり移行したりしないでください。これらのツールは、停電やその他のデータセンターの停止が発生した場合に管理しなくなるためです。</block>
  <block id="27bd00c8827fc3d77d1b5650103b676f" category="list-text">VASA Provider VM を定期的にバックアップします。VASA Provider が格納された従来のデータストアの Snapshot コピーを少なくとも 1 時間に 1 回は作成してください。VASA Provider の保護とリカバリの詳細については、こちらを参照してください<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>。</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">次の図は、 VVOL のコンポーネントを示しています。</block>
  <block id="6aadcb77504dae1dbfed2e4d1c969158" category="paragraph"><block ref="6aadcb77504dae1dbfed2e4d1c969158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">クラウドへの移行とバックアップ</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">ONTAP のもう 1 つの強みは、ハイブリッドクラウドを幅広くサポートすることで、オンプレミスのプライベートクラウドのシステムとパブリッククラウドの機能を統合できることです。vSphere と組み合わせて使用できるネットアップのクラウドソリューションには、次のものがあります。</block>
  <block id="67464b4510c09197c8a5e16ba6702435" category="list-text">* Cloud Volume 。 * NetApp Cloud Volumes Service for AWS または GCP と Azure NetApp Files for ANF は、主要なパブリッククラウド環境でハイパフォーマンスなマルチプロトコルマネージドストレージサービスを提供します。VMware Cloud VM ゲストで直接使用できます。</block>
  <block id="0ac7b95ec26051fb8842ae35427ecc22" category="list-text">* Cloud Volumes ONTAP 。 * NetApp Cloud Volumes ONTAP データ管理ソフトウェアは、お客様が選択したクラウド上のデータを管理、保護、柔軟性、効率性で保護します。Cloud Volumes ONTAP は、 NetApp ONTAP ストレージソフトウェアを基盤としたクラウドネイティブのデータ管理ソフトウェアです。Cloud Volumes ONTAP インスタンスをオンプレミスの ONTAP システムと一緒に導入、管理する際には、 Cloud Manager と組み合わせて使用できます。NAS および iSCSI SAN の高度な機能に加え、 Snapshot コピーや SnapMirror レプリケーションなどの統合データ管理機能も利用できます。</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">* Cloud Backup Service * 。クラウドサービスまたは SnapMirror クラウドを使用して、パブリッククラウドストレージを使用してオンプレミスシステムからデータを保護します。Cloud Sync を使用すると、 NAS 、オブジェクトストア、 Cloud Volumes Service ストレージ間でデータを移行し、同期を維持できます。</block>
  <block id="fa9b5353337118a51ced7968bccc02a0" category="inline-link">より多くの VM Snapshot コピーを格納する</block>
  <block id="c79f1f00e1e3c8f100e8604eec888859" category="list-text">* ONTAP * FabricPool は、 FabricPool データの階層化を迅速かつ容易にします。Snapshot コピーのコールドブロックは、パブリッククラウドまたはプライベート StorageGRID オブジェクトストアのオブジェクトストアに移行でき、 ONTAP データが再びアクセスされると自動的にリコールされます。または、 SnapVault ですでに管理されているデータの第 3 レベルの保護としてオブジェクト階層を使用することもできます。この方法を使用すると、を実行できます<block ref="1d0add9d2d81e2d7e790f727021e53aa" category="inline-link-rx"></block> プライマリおよびセカンダリ ONTAP ストレージシステム。</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">* ONTAP Select * 。ネットアップの Software-Defined Storage を使用して、インターネット経由でプライベートクラウドをリモートの施設やオフィスに拡張できます。 ONTAP Select を使用すれば、ブロックサービスやファイルサービスのほか、エンタープライズデータセンターと同じ vSphere データ管理機能をサポートできます。</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">VM ベースのアプリケーションを設計する際は、将来のクラウドのモビリティを考慮してください。たとえば、アプリケーションファイルとデータファイルを一緒に配置するのではなく、データ用に別の LUN または NFS エクスポートを使用します。これにより、 VM とデータを別々にクラウドサービスに移行できます。</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">vSphere データの暗号化</block>
  <block id="eb969673f581d94df982f8e2a6001f30" category="paragraph">現在、保管データを暗号化で保護する必要性はますます高まっています。最初は財務情報と医療情報に重点を置いていましたが、ファイル、データベース、その他の種類のデータに保存されているすべての情報を保護することに関心が高まっています。</block>
  <block id="77652ecf0c76f1d4194171dc720320be" category="paragraph">ONTAP ソフトウェアを実行するシステムでは、保存データの暗号化を使用してあらゆるデータを簡単に保護できます。NetApp Storage Encryption （ NSE ）は、 ONTAP を備えた自己暗号化ディスクドライブを使用して、 SAN と NAS のデータを保護します。また、 NetApp Volume Encryption と NetApp Aggregate Encryption も、シンプルなソフトウェアベースの手法として、ディスクドライブ上のボリュームを暗号化します。このソフトウェア暗号化は、特殊なディスクドライブや外部キー管理ツールを必要とせず、 ONTAP のお客様は追加料金なしで利用できます。クライアントやアプリケーションを停止することなくアップグレードして使用を開始でき、オンボードキーマネージャなどの FIPS 140-2 レベル 1 標準で検証されます。</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">VMware vSphere 上で実行される仮想アプリケーションのデータを保護する方法はいくつかあります。1 つは、 VM 内のソフトウェアをゲスト OS レベルで使用してデータを保護する方法です。別の方法として、 vSphere 6.5 などの新しいハイパーバイザーでは VM レベルの暗号化がサポートされるようになりました。ただし、ネットアップのソフトウェア暗号化はシンプルで使いやすく、次のようなメリットがあります。</block>
  <block id="92fbd315c4413db381567a775570b78c" category="list-text">* 仮想サーバの CPU には影響しません。 * 仮想サーバ環境によっては、アプリケーションに使用可能なすべての CPU サイクルが必要ですが、ハイパーバイザーレベルの暗号化では最大 5 倍の CPU リソースが必要です。暗号化ソフトウェアがインテルの AES-NI 命令セットをサポートして暗号化ワークロードをオフロードしている場合でも（ NetApp ソフトウェアの暗号化がサポートされているため）、古いサーバと互換性のない新しい CPU の要件が原因でこのアプローチが実現できない場合があります。</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">* オンボードキーマネージャを含む。 * ネットアップのソフトウェア暗号化機能には、追加料金なしでオンボードキーマネージャが含まれているため、購入や使用が複雑な高可用性キー管理サーバなしで簡単に利用を開始できます。</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">* ストレージ効率への影響はありません。 * 重複排除や圧縮などの Storage Efficiency テクノロジは現在広く使用されており、フラッシュディスクメディアをコスト効率よく使用する上で鍵となります。ただし、一般に、暗号化されたデータは重複排除も圧縮もできません。ネットアップのハードウェアとストレージの暗号化は下位レベルで動作し、他のアプローチとは異なり、業界をリードするネットアップの Storage Efficiency 機能を最大限に活用できます。</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">* データストアのきめ細かい暗号化が容易。 * NetApp Volume Encryption を使用すると、各ボリュームに専用の AES 256 ビットキーが設定されます。変更が必要な場合は、 1 つのコマンドで変更できます。このアプローチは、テナントが複数ある場合や、さまざまな部門やアプリケーションに対して個別に暗号化を証明する必要がある場合に適しています。この暗号化はデータストアレベルで管理されるため、個々の VM の管理よりもはるかに簡単です。</block>
  <block id="088124cfa6d59c647e63177c5a4af318" category="paragraph">ソフトウェアの暗号化を簡単に開始できます。ライセンスのインストールが完了したら、パスフレーズを指定してオンボードキーマネージャを設定し、新しいボリュームを作成するかストレージ側のボリューム移動を実行して暗号化を有効にします。ネットアップでは、 VMware ツールの今後のリリースで、暗号化機能のサポートをさらに統合する予定です。</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager を使用すると、仮想インフラ内の VM を可視化し、仮想環境内のストレージやパフォーマンスの問題を監視してトラブルシューティングすることができます。</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">ONTAP の一般的な仮想インフラ環境には、さまざまなコンポーネントがコンピューティングレイヤ、ネットワークレイヤ、ストレージレイヤに分散して配置されています。VM アプリケーションのパフォーマンス低下は、各レイヤのさまざまなコンポーネントでレイテンシが生じていることが原因である可能性があります。</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">次のスクリーンショットは、 Active IQ Unified Manager の仮想マシンビューを示しています。</block>
  <block id="8aa017c9f67ad32dd7301ecf52b61d72" category="paragraph"><block ref="8aa017c9f67ad32dd7301ecf52b61d72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager のトポロジビューには、仮想環境の基盤となるサブシステムが表示され、コンピューティングノード、ネットワーク、またはストレージでレイテンシ問題が発生したかどうかが確認されます。また、修復手順を実行して基盤となる問題に対応するために、パフォーマンス低下の原因となっているオブジェクトが強調表示されます。</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">次のスクリーンショットは、 AIQUM の拡張トポロジを示しています。</block>
  <block id="e9659be2b7d3d69eccdb443ed2acec75" category="paragraph"><block ref="e9659be2b7d3d69eccdb443ed2acec75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d336a329d910c32fb90337a372f596fc" category="summary">NetApp ONTAP ソフトウェアは、 VMware vSphere 環境向けのストレージ解決策を約 20 年にわたって業界をリードしてきました。また、コストを削減しながら管理を簡易化する革新的な機能を継続的に追加しています。このドキュメントでは、導入の合理化、リスクの軽減、管理の簡易化を実現するために、最新の製品情報とベストプラクティスを含む ONTAP 解決策 for vSphere について説明します。</block>
  <block id="952fd691754e388c7b7ba473cf410aff" category="doc">TR-4597 ：『 VMware vSphere for ONTAP 』</block>
  <block id="b4191f5f6b40e39be6030dbbc9052330" category="paragraph">ネットアップ Karl Konnerth</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">ベストプラクティスは、ガイドや互換性リストなどの他のドキュメントを補うものです。ラボテストに基づいて開発されており、ネットアップのエンジニアやお客様は広範な現場経験を積んでいます。すべての環境で機能する唯一のサポート対象となるわけではありませんが、一般に、ほとんどのお客様のニーズを満たす最もシンプルなソリューションです。</block>
  <block id="737453909be77692f8cfdf08a17cee61" category="inline-link-macro">ONTAP および vSphere のリリース固有の情報</block>
  <block id="18b198d3d2381f05dd78bab3c8cec60c" category="paragraph">本ドキュメントでは、 vSphere 6.0 以降で実行される最近のリリースの ONTAP （ 9.x ）の機能について説明します。を参照してください <block ref="4c9a6d8ccb9dfca3b5ae6e43e9663c99" category="inline-link-macro-rx"></block> 特定のリリースに関する詳細については、を参照してください。</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">ONTAP for vSphere を選ぶ理由</block>
  <block id="4b401b0a40ae220c77961312c8238cdb" category="paragraph">数万人のお客様が、 SAN と NAS の両方のプロトコルをサポートするユニファイドストレージシステム、スペース効率に優れたネットアップの Snapshot コピーを使用した堅牢なデータ保護機能など、 vSphere のストレージ解決策として ONTAP を選択した理由は数多くあります。 アプリケーションデータの管理に役立つ豊富なツールを備えています。ハイパーバイザーとは別のストレージシステムを使用すると、さまざまな機能をオフロードして、 vSphere ホストシステムへの投資を最大限に活用できます。このアプローチにより、ホストリソースをアプリケーションワークロードに集中できるだけでなく、ストレージ運用によるアプリケーションのランダムなパフォーマンスへの影響も回避できます。</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">vSphere と ONTAP を併用すると、ホストハードウェアと VMware ソフトウェアのコストを削減できます。また、一貫した高パフォーマンスを維持しながら、低コストでデータを保護することもできます。仮想化されたワークロードはモバイル対応であるため、 Storage vMotion を使用して、 VMFS 、 NFS 、または VVOL データストア間で VM を移動するさまざまなアプローチを、すべて同じストレージシステム上で検討できます。</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">お客様が現在重視している主な要因は次のとおりです。</block>
  <block id="dc4489aacb3c4d74b8253c49732b73e9" category="list-text">* ユニファイド・ストレージ。 * ONTAP ソフトウェアを実行するシステムは、いくつかの重要な方法で統合されています。当初、このアプローチは NAS プロトコルと SAN プロトコルの両方を指していましたが、 ONTAP は業界をリードする SAN プラットフォームであり続けており、 NAS における従来の強みもあります。vSphere 環境では、このアプローチは仮想デスクトップインフラ（ VDI ）向けのユニファイドシステムと仮想サーバインフラ（ VSI ）の組み合わせを意味する場合もあります。ONTAP ソフトウェアを実行するシステムは一般に、従来のエンタープライズアレイに比べて VSI の方が安価ですが、同じシステムで VDI を処理するための高度な Storage Efficiency 機能も備えています。また、 ONTAP は、 SSD から SATA までさまざまなストレージメディアを統合し、クラウドへの拡張を容易にします。パフォーマンスのためにフラッシュアレイを 1 台、アーカイブ用の SATA アレイ、クラウド用のシステムを 1 台購入する必要はありません。ONTAP は、これらすべてを 1 つにまとめます。</block>
  <block id="ec8cd066c60323f007135b1f083b64de" category="list-text">* 仮想ボリュームとストレージポリシーベースの管理。 * ネットアップは、 vSphere Virtual Volumes （ VVol ）の開発において VMware との早期設計パートナーであり、アーキテクチャに関する情報提供と、 VVol および VMware vSphere APIs for Storage Awareness （ VASA ）の早期サポートを提供しています。このアプローチにより、きめ細かな VM ストレージ管理が VMFS にもたらされるだけでなく、ストレージポリシーベースの管理によるストレージプロビジョニングの自動化もサポートされています。このアプローチにより、ストレージアーキテクトは、 VM 管理者が簡単に利用できるさまざまな機能を備えたストレージプールを設計できます。ONTAP は VVOL 規模でストレージ業界をリードし、 1 つのクラスタで数十万もの VVol をサポートします。一方、エンタープライズアレイや小規模なフラッシュアレイベンダーは、アレイあたり数千の VVol をサポートします。ネットアップは、 VVOL 3.0 のサポートに向けて、今後追加される機能で、きめ細かな VM 管理の進化も推進しています。</block>
  <block id="fd5311fb87e61b58d3c3d278df26af4f" category="list-text">* ストレージ効率。 * ネットアップは、本番環境のワークロードに重複排除を提供した最初のベンダーでしたが、この分野の最初または最後のイノベーションではありませんでした。まずは、パフォーマンスに影響を与えない、スペース効率に優れたデータ保護メカニズムである ONTAP Snapshot コピーと、本番環境やバックアップ用に VM の読み取り / 書き込みコピーを瞬時に作成する FlexClone テクノロジからスタートしました。ネットアップは、重複排除、圧縮、ゼロブロック重複排除などのインライン機能を提供し、高価な SSD のストレージを最後まで絞ります。ONTAP は最近、圧縮機能を使用して、より小さな I/O 処理とファイルをディスクブロックに圧縮する機能を追加しました。これらの機能を組み合わせることで、 VSI では最大 5 分の 1 、 VDI では最大 30 分の 1 のコストを削減できました。</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">* ハイブリッド・クラウド。 * オンプレミスのプライベート・クラウド、パブリック・クラウド・インフラストラクチャー、または両方の利点を組み合わせたハイブリッド・クラウドのいずれに使用しても、 ONTAP ソリューションはデータ管理を合理化し、最適化するためのデータ・ファブリックの構築を支援します。まずハイパフォーマンスのオールフラッシュシステムを導入し、データ保護とクラウドコンピューティングのためにディスクストレージシステムとクラウドストレージシステムのどちらかと組み合わせます。Azure 、 AWS 、 IBM 、 Google のクラウドから選択して、コストを最適化し、ロックインを回避できます。必要に応じて、 OpenStack とコンテナテクノロジの高度なサポートを活用できます。ネットアップ ONTAP では、クラウドベースのバックアップ（ SnapMirror クラウド、 Cloud Backup Service 、 Cloud Sync ）やストレージ階層化 / アーカイブツール（ FabricPool ）も提供しており、運用コストの削減とクラウドの幅広いリーチの活用を支援します。</block>
  <block id="0c157ce4e4fd6289dbf0b282993c2f80" category="list-text">* その他。 * NetApp AFF A シリーズアレイの卓越したパフォーマンスを活用して、コストを管理しながら仮想インフラを高速化できます。スケールアウト ONTAP クラスタを使用して、ストレージシステムのメンテナンスからアップグレード、完全な交換まで、完全なノンストップオペレーションを実現します。ネットアップの暗号化機能を追加コストなしで使用して、保存データを保護できます。きめ細かいサービス品質機能により、パフォーマンスがビジネスサービスレベルを満たしていることを確認します。これらはすべて、業界をリードするエンタープライズデータ管理ソフトウェアである ONTAP に付属する幅広い機能の一部です。</block>
  <block id="7be2e69e5d19c282db8d81c60a51c862" category="summary">このページでは、 VMware vSphere 環境に NetApp ONTAP ストレージ解決策を実装するためのベストプラクティスについて説明します。</block>
  <block id="ff53ee8001042abcefe5c912d0b5012f" category="section-title">vSphere のデータストアとプロトコルの機能</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="list-text">iSCSI</block>
  <block id="0f2f72ef3f176b98134caf100a06cf5f" category="inline-link">VMware 構成の最大数</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">機能 / 特徴</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC / FCoE</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">の形式で入力し</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">VMFS または raw デバイスマッピング（ RDM ）</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS または RDM</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">データストアまたは LUN の最大数</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256 でデフォルトの NFS がマウントされます。MaxVolumes は 8 です。VMware vSphere 用の ONTAP ツールを使用して 256 まで増やす。</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">データストアの最大サイズ</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64TB</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">100TB 以上の FlexVol ボリュームと FlexGroup ボリューム</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62TB</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">LUN またはファイルシステムごとのキューの深さの最適値</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">次の表に、サポートされる VMware ストレージ関連機能を示します。</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">容量 / 機能</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">vMotion</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">Storage vMotion の機能です</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">VMware HA</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">ストレージ分散リソーススケジューラ（ SDRS ）</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">VMware vStorage APIs for Data Protection （ VADP ）対応のバックアップソフトウェア</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">VM 内の Microsoft Cluster Service （ MSCS ）またはフェイルオーバークラスタリング</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">はい *</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">サポート対象外</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">フォールトトレランス</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">Site Recovery Manager の略</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">シンプロビジョニングされた VM （仮想ディスク）</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">はい VAAI を使用しない場合、 NFS 上のすべての VM に対してこの設定がデフォルトです。</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">VMware 標準マルチパス</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Windows Server フェールオーバークラスタリングのセットアップ</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">次の表に、サポートされる ONTAP ストレージ管理機能を示します。</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">データ重複排除</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">アレイ内での容量削減</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">データストア内での容量削減</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">シンプロビジョニング</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">データストアまたは RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">データストア</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">データストアのサイズを変更</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">拡張のみ</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">拡張、自動拡張、縮小</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Windows 、 Linux アプリケーション用の SnapCenter プラグイン（ゲスト内）</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">VMware vSphere 用の ONTAP ツールを使用した監視とホストの設定</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">VMware vSphere 用の ONTAP ツールを使用したプロビジョニング</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">次の表に、サポートされるバックアップ機能を示します。</block>
  <block id="1208a2df45bea7d2edea13f0b0cbc686" category="cell">ONTAP の Snapshot コピー</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">複製バックアップでサポートされる SRM</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">Volume SnapMirror の略</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">VMDK イメージアクセス</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">VADP 対応のバックアップソフトウェア</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">VADP 対応のバックアップソフトウェア、 vSphere Client 、 vSphere Web Client データストアブラウザ</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">VMDK のファイルレベルアクセス</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">VADP 対応のバックアップソフトウェア、 Windows のみ</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">VADP 対応のバックアップソフトウェアとサードパーティ製アプリケーション</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">NDMP の単位</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">データストアまたは VM</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">ストレージプロトコルを選択</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">ONTAP ソフトウェアを実行するシステムは、主要なストレージプロトコルをすべてサポートしているため、既存および計画されているネットワークインフラやスタッフのスキルに応じて、お客様は環境に最適なものを選択できます。ネットアップのテストでは、一般に、ほぼ同じ速度の回線で実行されているプロトコル間の違いはほとんど見られませんでした。そのため、物理プロトコルのパフォーマンスよりもネットワークインフラとスタッフの能力に重点を置くことを推奨します。</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">プロトコルの選択を検討する際には、次の要素が役立ちます。</block>
  <block id="c0ab9c6170165211885267a562d057a2" category="list-text">* 現在のお客様の環境。 * 一般に、 IT チームはイーサネット IP インフラの管理のスキルを持っていますが、すべてのチームが FC SAN ファブリックの管理のスキルを持っているわけではありません。ただし、ストレージトラフィック用に設計されていない汎用 IP ネットワークを使用すると、うまく機能しない場合があります。現在利用しているネットワークインフラストラクチャ、計画的な改善点、およびそれらを管理するためのスタッフのスキルと可用性を考慮します。</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">* セットアップの容易さ * FC ファブリックの初期構成（追加のスイッチとケーブル配線、ゾーニング、 HBA とファームウェアの相互運用性の検証）に加えて、ブロックプロトコルを使用するには、 LUN の作成とマッピング、ゲスト OS による検出とフォーマットも必要です。作成およびエクスポートされた NFS ボリュームは、 ESXi ホストによってマウントされ、使用可能な状態になります。NFS では、ハードウェアの認定や管理に関する特別なファームウェアはありません。</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">* 管理の容易さ。 * SAN プロトコルでは、より多くのスペースが必要な場合、 LUN の拡張、新しいサイズの検出のための再スキャン、ファイルシステムの拡張など、いくつかの手順が必要です。LUN の拡張は可能ですが、 LUN のサイズを縮小することはできず、未使用スペースのリカバリには追加の作業が必要になる場合があります。NFS を使用すると、簡単なサイジングが可能です。このサイズ変更は、ストレージシステムで自動化できます。SAN では、ゲスト OS のトリム / マッピング解除コマンドを使用してスペース再生が可能で、削除されたファイルのスペースをアレイに戻すことができます。NFS データストアでは、このようなスペース再生がより困難になります。</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">* ストレージスペースの透過性。 * シンプロビジョニングによって削減効果が即座に現れるため、 NFS 環境では一般にストレージ利用率が見やすくなります。同様に、重複排除とクローニングによる削減効果は、同じデータストア内の他の VM や他のストレージシステムボリュームで即座に利用できます。一般に、 VM の密度は NFS データストア内でも高くなります。管理するデータストアが少ないため、重複排除による削減効果が向上すると同時に管理コストも削減されます。</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">データストアのレイアウト</block>
  <block id="066ed1c180617b2f9028c1f789078de4" category="paragraph">ONTAP ストレージシステムは、 VM および仮想ディスク用のデータストアを柔軟に作成できます。を使用する場合、 ONTAP の多くのベストプラクティスが適用されますが vSphere 用のデータストアをプロビジョニングする VSC （を参照） <block ref="311a0f5ed21de3c81d57d9c08f2ace49" category="inline-link-macro-rx"></block>) 、考慮すべきその他のガイドラインを次に示します。</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">FlexVol ボリュームデータストアの適切なサイズは 4~8TB です。このサイズは、パフォーマンス、管理のしやすさ、データ保護のバランスが取れた適切なサイズです。小規模構成から開始して（ 4TB など）、必要に応じてデータストアを拡張します（最大 100TB まで）。小規模なデータストアは、バックアップや災害からのリカバリにかかる時間が短く、クラスタ間で迅速に移動できます。使用済みスペースの変化に応じてボリュームを自動的に拡張または縮小するには、 ONTAP のオートサイズを使用することを検討してください。VMware vSphere データストアプロビジョニングウィザードの ONTAP ツールでは、新しいデータストアに対してデフォルトでオートサイズが使用されます。拡張および縮小のしきい値と最大および最小サイズは、 System Manager またはコマンドラインを使用して追加でカスタマイズできます。</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">古いゲストオペレーティングシステム（ OS ）では、パフォーマンスとストレージ効率を最大化するために、ストレージシステムとのアライメントが必要でした。しかし、 Microsoft や Linux ディストリビュータ（ Red Hat など）が提供する、ベンダーがサポートする最新の OS では、ファイルシステムのパーティションを仮想環境の基盤となるストレージシステムのブロックにアライメントするように調整する必要はありません。アライメントが必要な古い OS を使用している場合は、ネットアップサポートの技術情報で「 VM のアライメント」に関する記事を検索するか、ネットアップの営業担当者またはパートナー担当者に TR-3747 のコピーを請求してください。</block>
  <block id="3c8b400142a84af9ebe6262bce512ccb" category="list-text">パフォーマンス上のメリットはなく、ストレージ効率と Snapshot コピーのスペース使用量にも影響するため、ゲスト OS でのデフラグユーティリティの使用は避けてください。また、仮想デスクトップのゲスト OS で検索インデックスを無効にすることを検討してください。</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP は、革新的な Storage Efficiency 機能で業界をリードし、使用可能なディスクスペースを最大限に活用できるようにしています。AFF システムでは、デフォルトのインライン重複排除機能と圧縮機能により、この効率性がさらに向上しています。データはアグリゲート内のすべてのボリュームにわたって重複排除されるため、類似するオペレーティングシステムやアプリケーションを 1 つのデータストア内にまとめて、最大限の削減効果を得る必要はありません。</block>
  <block id="154cd001dd3ef8eabdf209f4faf2ddde" category="inline-link">TR-3633 ：『 Data ONTAP を基盤にした Oracle データベース』 Data ONTAP</block>
  <block id="8f2f733fd8f32e7aaa1ee62e48a55117" category="list-text">場合によっては、データストアが不要なこともあります。パフォーマンスと管理性を最大限に高めるためには、データベースや一部のアプリケーションなどの高 I/O アプリケーションにはデータストアを使用しないでください。代わりに、ゲストが管理する NFS や iSCSI ファイルシステムなど、ゲスト所有のファイルシステムや RDM を使用することを検討してください。アプリケーションに関する具体的なガイダンスについては、ご使用のアプリケーションに関するネットアップのテクニカルレポートを参照してください。例：<block ref="8cb1dd6561aaa08584e14e742f429a3e" category="inline-link-rx"></block> 仮想化に関するセクションと役立つ詳細情報が記載されています。</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">第 1 クラスのディスク（または強化された仮想ディスク）を使用すると、 vSphere 6.5 以降を搭載した VM に関係なく、 vCenter で管理されるディスクを使用できます。主に API で管理されますが、 VVol では特に OpenStack ツールや Kubernetes ツールで管理する場合に便利です。ONTAP および VMware vSphere 用の ONTAP ツールでサポートされています。</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">データストアと VM 移行</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">別のストレージシステム上の既存のデータストアから ONTAP に VM を移行する際は、いくつか注意しておくべきプラクティスがあります。</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Storage vMotion を使用して、仮想マシンの大部分を ONTAP に移動します。このアプローチでは、実行中の VM を停止する必要がなくなるだけでなく、インラインの重複排除や圧縮などの ONTAP の Storage Efficiency 機能を使用して、移行時にデータを処理できます。vCenter 機能を使用してインベントリリストから複数の VM を選択し、適切なタイミングで移行をスケジュール（ Ctrl キーを押しながら [ アクション ] をクリック）することを検討します。</block>
  <block id="008116a0d875d0de070d1a10314abbaa" category="list-text">適切なデスティネーションデータストアへの移行を慎重に計画することもできますが、多くの場合、一括で移行して必要に応じてあとから整理する方が簡単です。Snapshot スケジュールの変更など、データ保護に関する特定のニーズがある場合は、このアプローチを使用して別のデータストアへの移行を実施できます。</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">ほとんどの VM とそのストレージは、実行中（ホット）に移行できますが、 ISO 、 LUN 、 NFS ボリュームなどの接続されたストレージ（データストア内にない）を別のストレージシステムから移行する場合は、コールドマイグレーションが必要になることがあります。</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">TR-4534</block>
  <block id="282806c282d96fdf15b71278587f2bfe" category="list-text">より慎重な移行が必要な仮想マシンには、接続されたストレージを使用するデータベースやアプリケーションなどがあります。一般に、移行を管理するためのアプリケーションのツールの使用を検討します。Oracle の場合は、 RMAN や ASM などの Oracle ツールを使用してデータベース・ファイルを移行することを検討してください。を参照してください<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> を参照してください。同様に、 SQL Server の場合は、 SQL Server Management Studio を使用するか、 SnapManager for SQL Server や SnapCenter などのネットアップのツールを使用することを検討します。</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="section-title">VMware vSphere 用の ONTAP ツール</block>
  <block id="00f47a68ebd81ba943b17dbc30d78db6" category="paragraph">ONTAP ソフトウェアを実行しているシステムで vSphere を使用する際に最も重要なベストプラクティスは、 VMware vSphere プラグイン（旧 Virtual Storage Console ）用の ONTAP ツールをインストールして使用することです。この vCenter プラグインは、 SAN と NAS のどちらを使用している場合でも、ストレージ管理を簡易化し、可用性を向上させ、ストレージコストと運用オーバーヘッドを削減します。データストアのプロビジョニングのベストプラクティスを使用して、マルチパスと HBA タイムアウト（これらは付録 B で説明）用の ESXi ホスト設定を最適化します。vCenter プラグインであるため、 vCenter サーバに接続するすべての vSphere Web Client で使用できます。</block>
  <block id="21eddd0bd26d119e0602b3ceb65aff45" category="paragraph">このプラグインは、 vSphere 環境で他の ONTAP ツールを使用する場合にも役立ちます。このプラグインでは、 NFS Plug-in for VMware VAAI をインストールできます。これにより、 VM のクローニング処理、シック仮想ディスクファイルのスペースリザベーション、および ONTAP Snapshot コピーオフロードで、 ONTAP へのコピーオフロードが可能になります。</block>
  <block id="80303385ad0f7147caa1af6d2162852b" category="paragraph">VASA Provider for ONTAP の多くの機能を使用するための管理インターフェイスでもあり、 VVol でのストレージポリシーベースの管理がサポートされています。VMware vSphere 用の ONTAP ツールを登録したら、ストレージ機能プロファイルを作成してストレージにマッピングし、データストアがプロファイルに一定期間にわたって準拠していることを確認します。VASA Provider には、 VVol データストアの作成と管理を行うためのインターフェイスも用意されています。</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">一般に、 vCenter 内で VMware vSphere インターフェイス用の ONTAP ツールを使用して、従来のデータストアと VVol データストアをプロビジョニングし、ベストプラクティスに従っていることを確認することを推奨します。</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">一般的なネットワーク</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">ONTAP ソフトウェアを実行しているシステムで vSphere を使用する場合のネットワーク設定の構成は簡単で、他のネットワーク構成と同様です。考慮すべき点をいくつか挙げます。</block>
  <block id="9600865cce7d923667012211ddac46de" category="list-text">ストレージネットワークのトラフィックを他のネットワークから分離します。専用の VLAN を使用するか、ストレージ用に別個のスイッチを使用することで、別のネットワークを実現できます。ストレージネットワークがアップリンクなどの物理パスを共有している場合は、十分な帯域幅を確保するために QoS または追加のアップリンクポートが必要になることがあります。ホストをストレージに直接接続しないでください。スイッチを使用すると冗長パスが確保され、 VMware HA が自動で機能します。</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">ジャンボフレームは、必要に応じてネットワークでサポートされていれば、特に iSCSI を使用している場合に使用できます。使用する場合は、ストレージと ESXi ホストの間のパスにあるすべてのネットワークデバイスや VLAN で設定が同じであることを確認してください。そうしないと、パフォーマンスや接続の問題が発生する可能性があります。MTU は、 ESXi 仮想スイッチ、 VMkernel ポート、および各 ONTAP ノードの物理ポートまたはインターフェイスグループでも同一の設定にする必要があります。</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">ネットワークフロー制御は、 ONTAP クラスタ内のクラスタネットワークポートでのみ無効にすることを推奨します。データトラフィックに使用される残りのネットワークポートについては、推奨されるベストプラクティスはありません。必要に応じて有効または無効にしてください。を参照してください<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> を参照してください。</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">ESXi および ONTAP ストレージアレイをイーサネットストレージネットワークに接続するときは、接続先のイーサネットポートを Rapid Spanning Tree Protocol （ RSTP ；高速スパニングツリープロトコル）のエッジポートとして設定するか、 Cisco の PortFast 機能を使用して設定することを推奨します。ネットアップでは、 Cisco の PortFast 機能を使用していて、 ESXi サーバまたは ONTAP ストレージアレイへの 802.1Q VLAN トランキングが有効になっている環境では、 Spanning-Tree PortFast trunk 機能を有効にすることを推奨します。</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">リンクアグリゲーションのベストプラクティスとして次を推奨します。</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">次の表に、ネットワーク設定項目とその適用先をまとめます。</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">項目</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">スイッチ</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">ノード</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">IP アドレス</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">いいえ **</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">リンクアグリゲーション</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">仮想スイッチ</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">いいえ *</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">VMkernel と VM ポートグループ</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">フロー制御</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">スパニングツリー</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU （ジャンボフレーム用）</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">仮想スイッチと VMkernel ポート（ 9000 ）</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">○（最大に設定）</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">○（ 9000 ）</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">フェイルオーバーグループ</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">○（作成）</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">○（選択）</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">** これらのデバイスには管理用に独自の IP アドレスがありますが、 ESXi ストレージネットワークのコンテキストでは使用されません。</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN （ FC 、 FCoE 、 NVMe/FC 、 iSCSI ）、 RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">vSphere では、ブロックストレージ LUN を 3 通りの方法で使用します。</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">VMFS データストアを使用する場合</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">raw デバイスマッピング（ RDM ）で使用</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">ソフトウェアイニシエータがアクセスおよび制御する LUN として使用 VM ゲスト OS から作成します</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS は、共有ストレージプールであるデータストアを提供する、高性能なクラスタファイルシステムです。VMFS データストアは、 NVMe/FC プロトコルによってアクセスされる FC 、 iSCSI 、 FCoE 、または NVMe ネームスペースを使用してアクセスする LUN で構成できます。VMFS を使用すると、クラスタ内の各 ESX サーバから同時に従来型の LUN にアクセスすることができます。ONTAP の最大 LUN サイズは通常 16TB であるため、最大サイズの 64TB （このセクションの最初の表を参照）の VMFS 5 データストアは、 4 つの 16TB LUN を使用して作成されます（すべての SAN アレイシステムが最大 VMFS LUN サイズ 64TB をサポート）。ONTAP LUN アーキテクチャでは個々のキュー深度が小さくないため、 ONTAP の VMFS データストアは、比較的簡単な方法で従来のアレイアーキテクチャよりも大規模に拡張できます。</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">vSphere は、ストレージデバイスへの複数のパスを標準でサポートします。この機能はネイティブマルチパス（ NMP ）と呼ばれます。NMP は、サポートされるストレージシステムのストレージタイプを検出し、使用中のストレージシステムの機能をサポートするように NMP スタックを自動的に設定できます。</block>
  <block id="6bf646772584de04f877d166e564b5ff" category="paragraph">NMP と NetApp ONTAP はどちらも、 Asymmetric Logical Unit Access （ ALUA ；非対称論理ユニットアクセス）による最適パスと非最適パスのネゴシエーションをサポートします。ONTAP では、アクセス対象の LUN をホストするノード上のターゲットポートを使用する直接データパスが、 ALUA の最適パスとなります。ALUA は、 vSphere と ONTAP の両方でデフォルトで有効になっています。NMP は ONTAP クラスタを ALUA として認識し、 ALUA ストレージアレイタイププラグイン（ VMW_SATP_ALUA ）を使用し、ラウンドロビンパス選択プラグイン（「 VMW_PSP_RR 」）を選択します。</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6 は、最大 256 個の LUN と、 LUN への最大 1 、 024 個の合計パスをサポートします。これらの制限を超える LUN やパスは、 ESXi で認識されません。最大数の LUN を使用した場合、 LUN あたりのパス数は最大 4 つです。大規模な ONTAP クラスタでは、 LUN 数の上限に達する前にパス数の制限に達する可能性があります。この制限に対処するため、 ONTAP では、リリース 8.3 以降の選択的 LUN マップ（ SLM ）がサポートされています。</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM はデフォルトでは有効になっています。ポートセットを使用しないかぎり、これ以上の設定は必要ありません。</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Data ONTAP 8.3 より前のバージョンで作成した LUN の場合、 lun mapping remove-reporting-nodes コマンドを実行して SLM を手動で適用し、 LUN レポートノードを削除し、 LUN へのアクセスを LUN の所有者ノードとその HA パートナーに制限します。</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">ブロックプロトコル（ iSCSI 、 FC 、 FCoE ）は、一意の名前に加え、 LUN ID とシリアル番号を使用して LUN にアクセスします。FC と FCoE は Worldwide Name （ WWNN および WWPN ）を使用し、 iSCSI は iSCSI Qualified Name （ IQN ）を使用します。ストレージ内での LUN へのパスはブロックプロトコルにとっては意味がないため、どこにも表示されません。したがって、 LUN のみが含まれるボリュームは内部でマウントする必要がなく、データストアで使用される LUN を含むボリュームのジャンクションパスも必要ありません。ONTAP の NVMe サブシステムも同様に機能します。</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">考慮すべきその他のベストプラクティス：</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">可用性と移動性を最大限に高めるために、 ONTAP クラスタ内の各ノード上の各 SVM に論理インターフェイス（ LIF ）が作成されていることを確認します。ONTAP SAN では、各ファブリックに対して 1 つずつ、ノードごとに 2 つの物理ポートと LIF を使用することを推奨します。ALUA を使用してパスが解析され、アクティブな最適化（直接）パスとアクティブな非最適化パスが特定されます。ALUA は FC 、 FCoE 、および iSCSI に使用されます。</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">iSCSI ネットワークの場合、複数の仮想スイッチがある場合は、 NIC チーミングを使用して、異なるネットワークサブネット上の複数の VMkernel ネットワークインターフェイスを使用します。また、複数の物理スイッチに接続された複数の物理 NIC を使用して、 HA を実現し、スループットを向上させることもできます。次の図に、マルチパス接続の例を示します。ONTAP では、 2 つ以上のスイッチに接続された 2 つ以上のリンクでフェイルオーバーするシングルモードインターフェイスグループを設定するか、 LACP または他のリンクアグリゲーションテクノロジをマルチモードインターフェイスグループと併用して HA を実現し、リンクアグリゲーションのメリットを活かすことができます。</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">Challenge Handshake Authentication Protocol （ CHAP ）が ESXi でターゲット認証に使用されている場合には、 CLI （「 vserver iscsi security create 」）または System Manager （ Storage &gt; SVMs &gt; SVM Settings &gt; Protocols &gt; iSCSI ）を使用して ONTAP にも設定する必要があります。</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">LUN と igroup の作成と管理には、 VMware vSphere の ONTAP ツールを使用します。プラグインによってサーバの WWPN が自動的に判別され、適切な igroup が作成されます。また、ベストプラクティスに従って LUN を設定し、正しい igroup にマッピングします。</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">物理互換モードと仮想互換モード</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">RDM は管理が難しくなり、前述のように制限されたパスを使用するため、使用には注意が必要です。ONTAP LUN は両方をサポートします<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM ：</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">『 ONTAP NVMe/FC Host Configuration Guide 』を参照してください</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">vSphere 7.0 での NVMe/FC の使用については、以下を参照してください<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> および<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>次の図に、 vSphere ホストから ONTAP LUN へのマルチパス接続を示します。</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">vSphere を使用すると、エンタープライズクラスの NFS アレイを使用して、 ESXi クラスタ内のすべてのノードへのデータストアへの同時アクセスを提供できます。データストアのセクションで説明したように、 vSphere で NFS を使用すると、使いやすさが向上し、ストレージ効率を可視化できるというメリットがあります。</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">vSphere で ONTAP NFS を使用する際に推奨されるベストプラクティスは次のとおりです。</block>
  <block id="265e673c00294cf97a90c3b0d4fcb076" category="list-text">ONTAP クラスタ内の各ノードの各 SVM で、 1 つの論理インターフェイス（ LIF ）を使用します。データストアごとの LIF の過去の推奨事項は不要になりました。直接アクセス（同じノード上の LIF とデータストア）は最適ですが、パフォーマンスへの影響は一般に最小（マイクロ秒）であるため、間接アクセスを考慮しないでください。</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">NFSv3 と NFSv4.1 間ではデータストアが自動変換されないため、新しい NFSv4.1 データストアを作成し、 Storage vMotion を使用して新しいデータストアに VM を移行します。</block>
  <block id="822366735aef72f1a9429ac86dda7338" category="list-text">Access Protocol ： nfs3</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">クライアント一致仕様： 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">RO アクセスルール： sys</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">RW アクセスルール： sys</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">superuser ： sys</block>
  <block id="c184ce6b86d2e6fbf8681d61637c101b" category="list-text">NetApp NFS Plug-in for VMware VAAI を使用する場合、エクスポートポリシールールの作成時または変更時にプロトコルを「 nfs 」に設定する必要があります。VAAI コピーオフロードが機能するためには NFSv4 プロトコルが必要です。プロトコルを「 nfs 」に指定すると、 NFSv3 バージョンと NFSv4 バージョンの両方が自動的に組み込まれます。</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">VMware vSphere 用の ONTAP ツール（最も重要なベストプラクティス）を使用：</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">VMware vSphere 用の ONTAP ツールを使用してデータストアをプロビジョニングすると、エクスポートポリシーの自動管理が簡易化されます。</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">プラグインのマウント機能を使用して、既存のデータストアを新しいサーバに適用します。</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">VMware vSphere 用の ONTAP ツールを使用しない場合は、すべてのサーバ、または追加のアクセス制御が必要なサーバクラスタごとに、 1 つのエクスポートポリシーを使用します。</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">ONTAP にはフレキシブルボリュームのネームスペース構造が用意されており、ジャンクションを使用してボリュームをツリーにまとめることができますが、このアプローチは vSphere には価値がありません。ストレージのネームスペース階層に関係なく、データストアのルートに各 VM 用のディレクトリが作成されます。そのため、単に SVM のルートボリュームに vSphere のボリュームのジャンクションパスをマウントすることがベストプラクティスです。これは、 VMware vSphere 用の ONTAP ツールでデータストアをプロビジョニングする方法です。ジャンクションパスがネストされていないと、ルートボリューム以外のボリュームに依存しているボリュームがないこと、またボリュームをオフラインにするか破棄するかによって意図的に他のボリュームへのパスに影響が及ぶこともありません。</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">NFS データストアの NTFS パーティションのブロックサイズは 4K で十分です。次の図は、 vSphere ホストから ONTAP NFS データストアへの接続を示しています。</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">次の表に、 NFS のバージョンとサポートされる機能を示します。</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">vSphere の機能</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">vMotion と Storage vMotion</block>
  <block id="05807e454c19f244770adae059b3c330" category="cell">高可用性</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">フォールトトレランス</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">ホストプロファイル</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">Storage DRS</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">ストレージ I/O の制御</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM の場合</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">仮想ボリューム</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">ハードウェアアクセラレーション（ VAAI ）</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Kerberos 認証</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">○（ vSphere 6.5 以降で拡張して、 AES 、 krb5i ）</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">マルチパスのサポート</block>
  <block id="54452390cac5f65f3bcec580ba079531" category="section-title">FlexGroup</block>
  <block id="f203949f2e35204098b66b9c1519b66e" category="paragraph">ONTAP 9.8 では、 vSphere で FlexGroup データストアがサポートされるようになり、 VMware vSphere 9.8 リリース用の ONTAP ツールも追加されています。FlexGroup を使用すると、大容量のデータストアを簡単に作成でき、複数のコンスティチュエントボリュームを自動的に作成して、 ONTAP システムのパフォーマンスを最大限に高めることができます。フル機能の ONTAP クラスタを利用して、拡張性に優れた単一の vSphere データストアで FlexGroup を使用できます。</block>
  <block id="6829bc8d3038be0130fd2b409ad5e560" category="paragraph">ONTAP 9.8 では、 vSphere のワークロードを使用した広範なシステムテストに加えて、 FlexGroup データストアのコピーオフロードメカニズムも新たに追加されました。強化されたコピーエンジンを使用して、バックグラウンドのコンスティチュエント間でファイルをコピーすると同時に、ソースとデスティネーションの両方でアクセスを許可します。複数のコピーを使用すると、構成要素内で、スペース効率に優れた使用可能なファイルクローンを、大規模に応じて即座に利用できます。</block>
  <block id="760383437e8e5cbe4a2560753da783fb" category="paragraph">ONTAP 9.8 では、 FlexGroup ファイルの新しいファイルベースのパフォーマンス指標（ IOPS 、スループット、レイテンシ）も追加されました。これらの指標は、 VMware vSphere ダッシュボードや VM レポート用の ONTAP ツールで確認できます。VMware vSphere プラグイン用の ONTAP ツールでは、最大 IOPS と最小 IOPS の組み合わせを使用してサービス品質（ QoS ）ルールを設定することもできます。これらは、データストア内のすべての VM に対して個別に設定することも、特定の VM に対して個別に設定することもできます。</block>
  <block id="50783a97403d748762dff691da2d3723" category="paragraph">ネットアップが新たに開発したベストプラクティスをいくつかご紹介します。</block>
  <block id="d190c5fcdf8146c1dd7aad1140be4e64" category="list-text">FlexGroup プロビジョニングのデフォルトを使用する。VMware vSphere 用の ONTAP ツールは vSphere 内で FlexGroup を作成およびマウントするため推奨されますが、 ONTAP System Manager やコマンドラインを使用すると特別なニーズを満たすことができます。さらに、ノードあたりのコンスティチュエントメンバー数などのデフォルトも使用します。これは、 vSphere でテスト済みの構成メンバー数であるためです。</block>
  <block id="9f3fa65c2cc36eabd2228b984c30c5e1" category="list-text">FlexGroup データストアのサイジングを行う場合、 FlexVol は、より大容量のネームスペースを作成する複数の小さい FlexGroup で構成されることに注意してください。そのため、最大の仮想マシンの 8 倍以上のサイズのデータストアに設定してください。たとえば、使用している環境に 6TB の VM がある場合、 FlexGroup データストアのサイズは 48TB 以上にする必要があります。</block>
  <block id="5fbee6b763967c822bb1e4a31665b11d" category="list-text">FlexGroup によるデータストアスペースの管理を許可します。オートサイズと Elastic サイジングは、 vSphere データストアでテスト済みです。データストアの容量がフルに近くなった場合は、 VMware vSphere 用の ONTAP ツールまたは別のツールを使用して、 FlexGroup ボリュームのサイズを変更します。FlexGroup は、容量と inode をコンスティチュエント間で分散して維持し、容量が許容される場合はフォルダ（ VM ）内のファイルに同じコンスティチュエントへの優先順位を付けます。</block>
  <block id="f5f11bb6aa98d02453eca36d5d1d2e19" category="list-text">FlexGroup vSphere データストアのサポートは、 9.8 リリースで最大 1500 台の VM でテスト済みです。</block>
  <block id="f48591b3ae898f29a551a2995a7dcfe8" category="list-text">コピーオフロードには、 NFS Plug-in for VMware VAAI を使用します。クローニングは FlexGroup データストア内で強化 ONTAP されますが、 FlexVol ボリュームと FlexGroup ボリュームの間で VM をコピーする場合に、 ESXi ホストコピーと比べてパフォーマンス面で大きなメリットはありません。</block>
  <block id="57a0d1deb8da99d321814990d26d21ed" category="list-text">VMware vSphere 9.8 用の ONTAP ツールを使用すると、 ONTAP メトリック（ダッシュボードと VM レポート）を使用して FlexGroup VM のパフォーマンスを監視し、個々の VM の QoS を管理できます。現時点では、これらの指標は ONTAP コマンドや API では使用できません。</block>
  <block id="ad971da24ec0a38449ebf31e4e2c9332" category="list-text">QoS （最大 / 最小 IOPS ）は、個々の VM に対して、またはデータストア内のすべての VM に対して設定できます。すべての VM に QoS を設定すると、 VM ごとに個別に設定する必要がなくなります。今後は、新規または移行された VM には適用されません。新しい VM に QoS を設定するか、データストア内のすべての VM に QoS を再適用してください。</block>
  <block id="3c9d41390700cbdfb2c273f00df0d6fd" category="list-text">SnapCenter Plug-in for VMware vSphere リリース 4.4 では、プライマリストレージシステム上の FlexGroup データストア内の VM のバックアップとリカバリがサポートされています。SnapMirror を手動で使用して FlexGroup をセカンダリシステムにレプリケートできるが、 SCV 4.4 ではセカンダリコピーが管理されない。</block>
  <block id="c0ddbacfe0f703e62904558059e40001" category="summary">ここでは、 ONTAP および vSphere の特定のリリースでサポートされる機能について説明します。リリースの特定の組み合わせについては、 NetApp Interoperability Matrix で確認することを推奨します。</block>
  <block id="bc8be72fdc9d6054f356bb2b7f80fd12" category="inline-link">NetApp Interoperability Matrix を参照してください</block>
  <block id="2f6ae9fa35fbcb0ec3205505ee027642" category="paragraph">ここでは、 ONTAP および vSphere の特定のリリースでサポートされる機能について説明します。ネットアップでは、リリースの特定の組み合わせをで確認することを推奨します<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block>。</block>
  <block id="7912c2100fd9b3b96b0b03e7a068fc9a" category="section-title">ONTAP リリース</block>
  <block id="8ee2892e0fb10cc58205a3d682abdb58" category="paragraph">本ドキュメントの発行時点で、ネットアップは、以下のリリースファミリーを完全にサポートしています。</block>
  <block id="0fcf2ee62acd9eae83b609a0e7ecaa72" category="list-text">ONTAP 9.5</block>
  <block id="7dd2a92fd3f41a5334edf46f95d77e71" category="list-text">ONTAP 9.6</block>
  <block id="3447b91e516e4fc6b5dba827fcb68bee" category="list-text">ONTAP 9.7</block>
  <block id="2abfff2974f589f7a217325f304e0ec5" category="list-text">ONTAP 9.8</block>
  <block id="ee4651b72d795faf25a1382eb1315a95" category="section-title">vSphere および ESXi のサポート</block>
  <block id="c3123497dcfdcdf46908ad18a51928ca" category="paragraph">NetApp ONTAP は、 vSphere ESXi ホストを幅広くサポートしています。上記の 4 つのメジャーリリースファミリー（ 9.5 、 9.6 、 9.7 、および 9.8 ）は、 6.0 、 6.5 、 7.0 （これらのリリースの更新を含む）を含む最近の vSphere リリースのデータストレージプラットフォームとして完全にサポートされています。NFS v3 の相互運用性は幅広く、ネットアップではハイパーバイザーを含むすべてのクライアントをサポートしていますが、これらのクライアントには NFS v3 標準に準拠しています。NFSv4.1 のサポートは vSphere 6.0 から 7.0 までに制限されています。</block>
  <block id="8276b4666ec9fee7d71b01f6ee2b9955" category="paragraph">SAN 環境については、ネットアップでは SAN コンポーネントの広範なテストを実施しています。一般に、ネットアップは標準の x86-64 ラックサーバと Cisco UCS サーバを、 iSCSI 接続用の標準イーサネットアダプタと組み合わせてサポートしています。FC 環境、 FCoE 環境、 NVMe / FC 環境では、 HBA ファームウェアやドライバの必要性が原因で、より具体的にサポートが定義されています。</block>
  <block id="a9854fb3ed44e3b8e9236c5b70405101" category="paragraph">必ずをチェックしてください<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block> 特定のハードウェアとソフトウェアの設定のサポートを確認するため。</block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">NFS Plug-in for VMware VAAI のこと</block>
  <block id="eb3ac5aa51c1cacfa31cee70ac6586f0" category="paragraph">ESXi ホスト向けのこのプラグインは、 VAAI を使用して ONTAP に処理をオフロードします。最新リリースの 1.1.2 では、 Kerberos （ krb5 と krb5i ）のサポートなど、 NFSv4.1 データストアがサポートされます。ESXi 6.0 、 6.5 、および 7.0 と ONTAP 9.5-9.8 を併用できます。</block>
  <block id="b2dd36bd4918e00f8b2e15e6d62a4b94" category="section-title">VASA Provider</block>
  <block id="15c15a65e1486d45a44c6f61927ef836" category="paragraph">NetApp VASA プロバイダは VVol のプロビジョニングと管理をサポートします（セクション 3.7 を参照）。最近の VASA Provider リリースでは、 ESXi 6.0 、 6.5 、 7.0 と ONTAP 9.5-9.8 がサポートされています。</block>
  <block id="c13550c8bc0f9b77e92bd2533221de9d" category="paragraph">VMware vSphere 用の ONTAP ツールは、 ONTAP ストレージと vSphere を一緒に管理するための鍵です（これを使用することがベストプラクティスです）。最新リリース 9.8 は、 vSphere 6.5 および 7.0 と ONTAP 9.5-9.8 でサポートされています。</block>
  <block id="02d4482d332e1aef3437cd61c9bcc624" category="doc">お問い合わせください</block>
  <block id="3dd3a0a8eebc543e239dc4af5d76b322" category="paragraph">このテクニカルレポートに関するご意見やご要望はありますか？</block>
  <block id="93b698fac9d8f378474fb0765494c4e6" category="doc">vSphere 向けの ONTAP 機能</block>
  <block id="9985b4390c40137573e6da05caf85874" category="section-title">プロトコル</block>
  <block id="99dd82c3472eab7ec4ea64a848fe032d" category="paragraph">仮想ワークロードの管理に役立つ ONTAP の機能が多数あります。追加の製品ライセンスが必要な製品も、次のセクションで説明します。スタンドアロンツールとしてパッケージ化されたものもあれば、 ONTAP 向けのものもあれば、ネットアップポートフォリオ全体のパッケージ化されたものもあります。</block>
  <block id="671534601eb09388581f095632f815b2" category="paragraph">ONTAP の基本機能の詳細は、以下のとおりです。</block>
  <block id="dbef3659822e80f91a3a561ed6d0b0cd" category="list-text">* Storage Efficiency 。 * ONTAP は、インラインおよびバックグラウンドの重複排除と圧縮、ゼロブロック重複排除、データコンパクションをサポートしています。</block>
  <block id="287c4830bc87771bdf2b3ae9880ab67e" category="list-text">* ボリュームと LUN の移動。 * ONTAP クラスタ内の vSphere データストアと VVOL をサポートするボリュームや LUN を無停止で移動できます。これにより、パフォーマンスと容量のバランスを取り、無停止での保守とアップグレードをサポートできます。</block>
  <block id="ba96d4d48c1ff15e2732b37e2e7a435c" category="list-text">* QoS により、個々の LUN 、ボリューム、またはファイルのパフォーマンスを管理できます。この機能を使用すると、不明な VM や Bully VM を制限したり、重要な VM に十分なパフォーマンスリソースを確保したりできます。</block>
  <block id="28f638810590337576cbbe9979329c21" category="list-text">* FabricPool 。 * この機能は、コールドデータをブロックレベルで自動的に別のオブジェクトストアに階層化し、高価なフラッシュストレージを解放します。</block>
  <block id="ff8a0108cd7cd5019bfee6b6be672b17" category="inline-link">ONTAP REST API</block>
  <block id="9455a10ec937dafee664ae1e0e4fd98c" category="inline-link">Ansible モジュール</block>
  <block id="85402a535d923d0511a02d404893d1ba" category="section-title">ONTAP ライセンス</block>
  <block id="4a9fdcb14826a67d38a7b84170c54ea9" category="paragraph">仮想ワークロードの管理に役立つ ONTAP の一部の機能には、追加コストなし、ライセンスバンドル内、個別選択のいずれでも、追加ライセンスが必要です。多くのお客様にとって、最もコスト効率の高いアプローチはライセンスバンドルです。vSphere と関連する主なライセンスとその使用方法は次のとおりです。</block>
  <block id="c598be4d4f9f8c476e7f51d6ef5ff139" category="list-text">* FlexClone 。 * FlexClone を使用すると、 ONTAP のボリュームやファイルのクローンを、スペース効率に優れた方法で瞬時に作成できます。このクローニングは、 VMware vSphere Storage API – Array Integration （ VAAI ）によって処理がストレージシステムにオフロードされる場合、バックアップ検証とリカバリ（ SnapCenter ソフトウェア）、および VVOL のクローニングと Snapshot コピーに使用されます。使用方法は次のとおりです。</block>
  <block id="25d6e9f6ac28ecf0d97aaf9f6609f4d4" category="list-text">VAAI はオフロードコピー用の ONTAP でサポートされており、 vSphere のクローニング処理と移行（ Storage vMotion ）処理をサポートしています。FlexClone ライセンスは NetApp FlexVol ボリューム内に高速クローンを作成できますが、ライセンスがない場合でも、低速のブロックコピーを使用してクローンを作成できます。</block>
  <block id="6f9f0acae1b8d33078f1c061dcc662a3" category="list-text">VVol 機能を使用するには、 FlexClone ライセンスが必要です。この機能を使用すると、 1 つのデータストア内またはデータストア間で VVol をクローニングできます。また、 vSphere で管理される VVol の Snapshot コピーを、ストレージシステムにオフロードして実行できます。</block>
  <block id="4370ed35c8063100f2a5b8da39b82668" category="list-text">ストレージレプリケーションアダプタ（ SRA ）は VMware Site Recovery Manager で使用されます。また、 NAS 環境と SAN 環境の両方でリカバリをテストするには、 FlexClone ライセンスが必要です。検出、リカバリ、再保護のワークフローについては、 FlexClone なしで SRA を使用できます。</block>
  <block id="3117cf0d132cfe6180ee3db3d5250f7f" category="list-text">* SnapRestore 。 * SnapRestore テクノロジにより、データをコピーすることなく、ボリュームをインプレースで瞬時にリカバリできます。この機能は、 SnapCenter などのネットアップのバックアップおよびリカバリツールで必要です。 を使用して、検証およびリストア処理用にデータストアをマウントします。</block>
  <block id="a30ea87a20e5dd5b267ec41f29219a1d" category="list-text">* SnapMirror 。 * SnapMirror テクノロジにより、オンプレミスとクラウドの ONTAP システム間で、シンプルで高速なデータレプリケーションを実現できます。SnapMirror は、バージョンに依存しない論理レプリケーションをサポートしています。ブロックレプリケーションのパフォーマンスにより、変更されたデータのみがセカンダリシステムに送信されます。データはミラーポリシーやバックアップポリシーで保護できるため、ディザスタリカバリだけでなく、バックアップの長期データ保持にも対応できます。SnapMirror は、非同期関係と同期関係をサポートしています。 ONTAP 9.8 では、 SnapMirror のビジネス継続性機能を使用して、透過的なアプリケーションフェイルオーバーが実現します。</block>
  <block id="23862d7fc14d71369b9feaeb8d7f98b9" category="paragraph">SnapMirror は Site Recovery Manager を使用した SRA レプリケーションに必要です。また、 SnapCenter でセカンダリストレージシステムに Snapshot コピーをレプリケートするためにも必要です。</block>
  <block id="0fdef6775eeade832499deceb497e1d8" category="list-text">* SnapCenter * SnapCenter ソフトウェアは、アプリケーションと整合性のあるデータ保護とクローン管理を実現する、拡張性に優れたユニファイドプラットフォームとプラグインのスイート製品です。AFF ライセンスは、 FAS システムと SnapCenter システムのデータ保護ライセンスバンドルに含まれています。SnapCenter Plug-in for VMware vSphere は、 FAS 、 AFF 、 Cloud Volumes ONTAP 、 ONTAP Select のいずれかのストレージシステムを使用している場合に無償で提供されます。ただし、 SnapRestore と FlexClone のライセンスが必要です。</block>
  <block id="a20c69bb9262b2ab09ca5248996e7d63" category="list-text">* MetroCluster 。 * NetApp MetroCluster は、キャンパスエリアまたはメトロポリタンエリアにおける高可用性とディザスタリカバリを組み合わせた同期レプリケーション解決策で、サイト障害とハードウェア停止の両方からシステムを保護します。データ損失ゼロ（ RPO ゼロ）と高速リカバリ（ RTO が数分以内）で、障害からの透過的なリカバリを実現します。vSphere 環境では、 vSphere Metro Storage Cluster 構成の一部として使用されます。</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="section-title">ONTAP の仮想化ツール</block>
  <block id="7b0abbba24b3ff594f013e524b352ef1" category="paragraph">ネットアップでは、 ONTAP および vSphere と組み合わせて使用し、仮想環境を管理できるスタンドアロンのソフトウェアツールをいくつか提供しています。ONTAP ライセンスには、追加コストなしで次のツールが含まれています。vSphere 環境でこれらのツールがどのように連携するかについては、図 1 を参照してください。</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">次の図は、 vSphere 用の ONTAP ツールを示しています。</block>
  <block id="f7e876d450acee7c9ed7b18438440fb2" category="paragraph"><block ref="f7e876d450acee7c9ed7b18438440fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a123daaac5749e4d0965aca160f0adfd" category="doc">NetApp 解決策の自動化</block>
  <block id="d1029167179320d8b6d70b11c3d01bd3" category="list-text">Ansible コントロールノードの要件：</block>
  <block id="9ced761647f5d80fe615526ffff63937" category="list-text">次のパッケージがインストールされた Ubuntu / Debian マシン：</block>
  <block id="ca60b3698dd3d27a5f91e4dc0a1a2546" category="list-text">Python3</block>
  <block id="4ce3ea126bb844d4f8c4ce1a65cbe3ae" category="list-text">Pip3</block>
  <block id="881cbd1ce3fdb52f73a82f8674a2a364" category="list-text">Ansible （バージョン 2.10.0 より前）</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="list-text">Git</block>
  <block id="6e3d8a0ff7934b777031953fe936bac8" category="paragraph">上記の要件がインストールされていない新しい Ubuntu / Debian マシンを使用している場合は、次の手順に従ってそのマシンを Ansible の制御ノードとしてセットアップします。</block>
  <block id="532d3723890df934cc5c2c39477405a2" category="list-text">.sh ファイルを作成します</block>
  <block id="e95a2c08843a70246648b7107a26cec4" category="list-text">以下の内容をファイルに貼り付けます</block>
  <block id="86c8310d98a974adb7ac7c4025dd8b5c" category="list-text">ファイルを実行可能にします</block>
  <block id="22db3e24628482683b9bf06c38e497ee" category="list-text">スクリプトの実行（ルートとして）</block>
  <block id="d82dd9b3245382b365106db0568113e8" category="summary">ネットアップのソリューションを自動化すれば、多くの一般的なインフラタスクやアプリケーションタスクの導入、設定、実行を自動化できます。</block>
  <block id="90305bb6fba97091f683e8b82f9bf805" category="summary">ネットアップのソリューションを自動化すれば、多くの一般的なインフラタスクやアプリケーションタスクの導入、設定、実行を自動化できます。</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">はじめに</block>
  <block id="d78228187c1a83d3bb4d8e97cd657807" category="paragraph">自動化によってネットアップのソリューションの利用が簡易化されます。</block>
  <block id="5c263f30899f93ff7ccd457ad3eb956f" category="list-text">次のパッケージがインストールされた RHEL / CentOS マシン：</block>
  <block id="7b643b0eef9cf1199195fa05b77fc3c8" category="paragraph">上記の要件がインストールされていない新しい RHEL / CentOS マシンがある場合は、次の手順に従ってそのマシンを Ansible の制御ノードとしてセットアップします。</block>
  <block id="d2052f202108defaf6afc7831ba59362" category="list-text">RHEL-8/RHEL-7 の Ansible リポジトリを有効にします</block>
  <block id="61fbc2f21db84f17551fda6893429d16" category="list-text">RHEL-8 （ root として次のコマンドを実行）</block>
  <block id="77cd42f765e6b40764459a64a979f90c" category="list-text">RHEL-7 （ root として次のコマンドを実行）</block>
  <block id="3fa16e80574aff03c27de1253474a20f" category="list-text">インベントリ変数がある場合は、その変数を変数フィールドに貼り付けます。</block>
  <block id="c7fa74fb4cbaab9d336a8e55bf164684" category="list-text">名前と概要を入力します</block>
  <block id="dca91c3343cc0ad062506cdd14eb7d41" category="summary">ハイブリッドクラウド、デスクトップ仮想化、およびコンテナソリューションの関連資料に追加された最新情報</block>
  <block id="07e257430bade6bc5bce1c2170c6fc0d" category="paragraph">最新のハイブリッドクラウド、デスクトップ仮想化、コンテナソリューションとソリューションの資料の概要</block>
  <block id="2bdc87f51d413e6d2fa23dd26238501f" category="inline-link-macro">VMware vSphere for ONTAP の略</block>
  <block id="4b47c65474ab7fae9b08ddf38d598971" category="inline-link-macro">ネットアップの仮想デスクトップサービス（ VDS ）を使用したハイブリッドクラウド VDI</block>
  <block id="dea91bec9e85387a496bb2c228fc7dc3" category="list-text"><block ref="dea91bec9e85387a496bb2c228fc7dc3" category="inline-link-macro-rx"></block></block>
  <block id="da38226e07ff21f147182bb08be38f6f" category="inline-link">ネットアップを使用したベアメタル環境での Anthos</block>
  <block id="ac1da2af455fc001ba8b58af0e62d151" category="list-text"><block ref="ac1da2af455fc001ba8b58af0e62d151" category="inline-link-rx"></block></block>
  <block id="e7f098b026755d10f2c3f16d0ff0b1db" category="inline-link">設計ガイド</block>
  <block id="1027b152cc3e8165ce099ede9548be95" category="list-text"><block ref="1027b152cc3e8165ce099ede9548be95" category="inline-link-rx"></block></block>
  <block id="dfb1e9c5f4c5835e6e1a4173130a49c9" category="inline-link">導入ガイド</block>
  <block id="983044e3ba861493c43c08b9285c3125" category="list-text"><block ref="983044e3ba861493c43c08b9285c3125" category="inline-link-rx"></block></block>
  <block id="d91f70a15d40fe5795af6ded9555e095" category="list-text"><block ref="d91f70a15d40fe5795af6ded9555e095" category="inline-link-rx"></block></block>
  <block id="8e9465b5d4318c8ef9039dfe684619d5" category="list-text"><block ref="8e9465b5d4318c8ef9039dfe684619d5" category="inline-link-rx"></block></block>
  <block id="4725a75839c620bb95363c5f7f2ee9bc" category="cell">VMware Horizon</block>
  <block id="33be49f7ebc56eb7d336a201f7ac0df6" category="inline-link">Azure NetApp Files を使用して SAP を運用</block>
  <block id="e131204502a58630f2f72937238604c8" category="section-title">ビデオ / デモ</block>
  <block id="2b1dd692c0da980c4ec2ad9fd523c47d" category="inline-link">Azure NetApp Files 上の SQL 高可用性クラスタ</block>
  <block id="46b8f9361fae73f13467cd1aaff186ba" category="summary">ネットアップソリューション資料に対する最近の変更点のログ</block>
  <block id="679ce0aa9d3d54bfddd37e1b78b802de" category="doc">ネットアップソリューションの変更ログ</block>
  <block id="aceacf14369d872e8cb00f62613f52c6" category="paragraph">ネットアップソリューション資料に対する最近の変更点。最新の変更が最初に表示されます。</block>
  <block id="408649df4ac74ae19e47eef7d060c5cb" category="cell">解決策の自動化</block>
  <block id="cf04feec36847ba9c9671b28661cd1fc" category="sidebar">ネットアップソリューションのドキュメント</block>
  <block id="6174d88cc7c0409df3e035a5c9d089cb" category="sidebar">変更ログ</block>
  <block id="91770f038cd944a1d3b9b347edeb2b10" category="sidebar">新機能</block>
  <block id="17c3771ed0b6c1ae15740eff715e9922" category="sidebar">ビデオとデモ</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="sidebar">ブログ</block>
  <block id="0333ddced253ee1c6929eda5612dea92" category="sidebar">自動化をリクエスト</block>
  <block id="b0ac6120dada9135114784db22a59940" category="sidebar">最新のデータ分析</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">Splunk SmartStore を使用した NetApp StorageGRID</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E シリーズ E5700 および Splunk Enterprise</block>
  <block id="4549cdf15178a5f0535be7f0f86cdb4d" category="sidebar">エンタープライズデータベース</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="sidebar">Oracle データベース</block>
  <block id="c880b35e02dbb5854452c86028138e2a" category="sidebar">NetApp ONTAP への Oracle データベースの導入</block>
  <block id="bc113eb23aa0579a5e1d93e97ca13635" category="sidebar">NetApp EF シリーズを基盤にした Oracle データベース</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server の場合</block>
  <block id="7c02456b91ace7501ea6f18d1657dcf7" category="sidebar">Microsoft SQL Server の刷新</block>
  <block id="5c008a8422e884d74da1d4b50a7ada55" category="sidebar">NetApp EF シリーズでの Microsoft SQL Server のベストプラクティスガイド</block>
  <block id="9a9891facf2fa1c878c0fc18c6638005" category="sidebar">AI 統合インフラ</block>
  <block id="2967ab4748573d0cb6f2c4084c4fd70f" category="sidebar">NetApp E シリーズリファレンスアーキテクチャを使用した BeeGFS</block>
  <block id="1db760587a86f5c1b9ab39aa8cf8cf3d" category="sidebar">NetApp E シリーズストレージによる IBM Spectrum Scale の導入</block>
  <block id="08479c0355c887a02e772206b0d5d7f5" category="sidebar">AI および ML 向けの NetApp ONTAP および Lenovo ThinkSystem SR670 トレーニングワークロードのモデル化</block>
  <block id="e648dd2d4df65a903e9c1204d81abaed" category="sidebar">用 NetApp AFF A800 および富士通サーバ PRIMERGY GX2570 M5 AI と ML モデルのトレーニングワークロード</block>
  <block id="6a571fb799acb43b64f874729f838e2a" category="sidebar">データパイプライン、データレイク、管理</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">自動運転ワークロード向けの NetApp StorageGRID データレイク</block>
  <block id="ce3b746194cb1fb7d96dfe14187115e0" category="sidebar">データキャッシング機能を備えたハイブリッドクラウド AI オペレーティングシステム</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">ビッグデータ環境から AI へのデータの移動 環境</block>
  <block id="f1e7c981dec3bcee348bda96c55363c4" category="sidebar">NVIDIA を使用した会話型 AI</block>
  <block id="d5c1931461d1e204a84a486796df2cca" category="sidebar">実行： AI を使用したネットアップオーケストレーション解決策</block>
  <block id="c0a0f5bbb431dea70000d73b29e50249" category="sidebar">AI を実行することでクラスタと GPU の利用率を最適化</block>
  <block id="09c995632f33d1ee4a581eb951793f35" category="sidebar">AI インストールを実行</block>
  <block id="5c9e37e6d7e6f5e3a76854d8343d626b" category="sidebar">AI ダッシュボードとビューを実行します</block>
  <block id="29ebede332931243e314d8a3f333c1a7" category="sidebar">Run AI CLI でのジョブの送信</block>
  <block id="2943702718c42a5063e0c70598cebdc6" category="sidebar">自動運転ワークロード向けの NetApp ONTAP AI 解決策設計</block>
  <block id="d11813566a7c636e892d384601baf2c3" category="sidebar">ヘルスケア向け NetApp ONTAP AI リファレンスアーキテクチャ：診断イメージング</block>
  <block id="ab8526a90cc9cc979ddd23c87fff57bd" category="sidebar">金融サービスのワークロード向けの NetApp ONTAP AI リファレンスアーキテクチャ</block>
  <block id="6efd886c994d37b6577e22359be2310e" category="sidebar">NetApp E シリーズと BeeGFS を使用した AI 導入</block>
  <block id="3863e8a73e226ce0c0a6ad02b90ee75b" category="sidebar">Quantum StorNext with NetApp E-Series Systems Design Guide 』を参照してください</block>
  <block id="7891972f4586e6ee183ea541991ebe9f" category="sidebar">Quantum StorNext with NetApp E-Series Systems Deployment Guide 』を参照してください</block>
  <block id="f27edcc7a209983dc37cbcdb0df49ce7" category="sidebar">仮想デスクトップ</block>
  <block id="a87e5ca19422686ef96f1e6799e9111d" category="sidebar">仮想デスクトップサービス（ VDS ）</block>
  <block id="dede82866780d163734b443c5f4d484e" category="sidebar">ネットアップの仮想デスクトップサービスによるハイブリッドクラウド VDI</block>
  <block id="b89c617ff394cc85df3935994baa194b" category="sidebar">Login VSI を使用した単一サーバの負荷テスト</block>
  <block id="a1da2a2d050a6b61256020afd015a056" category="sidebar">業界向けソリューション</block>
  <block id="739169d2451850e6df7246db70c28cc7" category="sidebar">ESG テクニカル検証：『 VDI at Enterprise Scale with NetApp Virtual Desktop Service 』</block>
  <block id="3acc5e85d752378c6f1b9154f379b475" category="sidebar">VMware によるエンドユーザコンピューティング（設計ガイド）</block>
  <block id="87e25a8d0e462ac8d7158e587f376605" category="sidebar">VMware と NVIDIA GPU を使用したエンドユーザコンピューティング（設計ガイド）</block>
  <block id="d840a196af6c9e07c3ac3b20b15fb724" category="sidebar">VMware と NVIDIA GPU を使用したエンドユーザコンピューティング（導入ガイド）</block>
  <block id="f93781578174ca3309bd3ac126884af4" category="sidebar">VMware for 3D Graphics によるエンドユーザコンピューティング</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">自動化を申請</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">『 Apache Spark Workload with NetApp Storage 解決策』（導入ガイド）</block>
  <block id="b278438874f41a76068d02368e65aa3e" category="doc">このリポジトリについて</block>
  <block id="404af48e0cb5f84306fbd93fac2ff8be" category="paragraph">ネットアップソリューションリポジトリの簡単な紹介 - 特定のソリューションの参照先と、このリポジトリの使用方法</block>
  <block id="45ac6b09a3b8f5ea07ca656ca8dea987" category="section-title">リポジトリのナビゲーション</block>
  <block id="c28e40ef527e43509a0fcd3b114ff824" category="paragraph">リポジトリのナビゲーションは、ページの左側に表示されるメインのサイドバーで管理されます。ソリューションは、ネットアップソリューションの「テクノロジタワー」と定義された上位レベルの技術領域に分類されます。</block>
  <block id="e9982e506e30915713c7485a2e77633b" category="section-title">技術タワーの概要</block>
  <block id="d67372be0bd12a2ddbcf795ccfacc7de" category="cell">* セクション *</block>
  <block id="f14c276c07197ebef1394a5a219087a1" category="cell">* 概要 *</block>
  <block id="d83d094e8e3ce7450bf099061814d148" category="cell">Red Hat Ansible による解決策自動化の開始方法の概要</block>
  <block id="a0067ab2420cbaebc335efc5c2433c45" category="inline-link-macro">変更ログ</block>
  <block id="bea4c2c8eb82d05891ddd71584881b56" category="section-title">フィードバック</block>
  <block id="3523ec156cfc8217bb64d1273e5663fa" category="sidebar">ネットアップのソリューションについて</block>
  <block id="4be1d7a9b1a8d85ed7d1cf5c72b23928" category="paragraph">ネットアップの仮想デスクトップサービスは、 Microsoft のリモートデスクトッププロトコルを使用して仮想デスクトップのセッションとアプリケーションにアクセスします。特定のサーバモデルでホストできる最大ユーザ数を決定するために、 Login VSI ツールを使用しました。Login VSI は、特定の間隔でのユーザログインをシミュレートし、ドキュメントのオープン、メールの読み書き、 Excel や PowerPoint での作業、ドキュメントの印刷、ファイルの圧縮、ランダムな休憩などのユーザ操作を実行します。また、応答時間も測定します。サーバの使用率が低い場合はユーザの応答時間が短く、ユーザセッションが追加されると応答時間が長くなります。Login VSI は、初回のユーザログインセッションに基づいてベースラインを決定し、ベースラインからのユーザ応答が 2 秒を超えると最大ユーザセッション数を報告します。</block>
  <block id="65f671ed80b2c6f0cc371ab295230a3a" category="paragraph">次の図は、 H615C の Login VSI の応答時間とアクティブなセッションを示しています。</block>
  <block id="5c29ae1e9123280c1975dbc407f3eca3" category="paragraph">次の図に、 vSphere ホストおよび VM に対する H615C Login VSI テスト中の Cloud Insights のパフォーマンス指標を示します。</block>
  <block id="ca32c5a534baaf5f6dc3e6e6fed62450" category="doc">GPU に関する考慮事項</block>
  <block id="aaca2e6fe88c6861582a8d1a20acfd4f" category="summary">仮想デスクトップサービスの ONTAP 機能。</block>
  <block id="bc9c47c8423d4537fdbf118b09a80084" category="doc">仮想デスクトップサービスの ONTAP 機能</block>
  <block id="472986236003195075a1428fe6103f4c" category="paragraph">次の ONTAP 機能は、仮想デスクトップサービスでの使用に適しています。</block>
  <block id="6128a47ce6baa55dbad9293234f2f65c" category="list-text">* スケールアウトファイルシステム。 * ONTAP FlexGroup ボリュームは 20PB 以上のサイズに拡張でき、 1 つのネームスペースに 4 、 000 億を超えるファイルを格納できます。クラスタには最大 24 個のストレージノードを含めることができ、各ノードには、使用するモデルに応じた柔軟な数のネットワークインターフェイスカードを使用できます。</block>
  <block id="960f11687b64143d44db7f4ffcb33ef2" category="paragraph">ユーザの仮想デスクトップ、ホームフォルダ、ユーザプロファイルコンテナ、共有データなどは、ファイルシステムの制限を気にせずに、必要に応じて拡張できます。</block>
  <block id="ab7ad572d2251b9b27fa0213fde8531f" category="list-text">* ファイルシステム分析。 * XCP ツールを使用して、共有データの分析情報を取得できます。ONTAP 9.8+ と ActiveIQ の Unified Manager を使用すると、ファイルのメタデータ情報の照会と取得、コールドデータの特定を簡単に実行できます。</block>
  <block id="885f3e34ca03dc8ff35c0bac51b384f7" category="list-text">* クラウドの階層化。 * コールドデータをクラウド内のオブジェクトストアや、データセンター内の任意の S3 互換ストレージに移行できます。</block>
  <block id="fb38ee94b865e67571a08316a3baac38" category="list-text">* ファイルバージョン。 * ユーザは、 NetApp ONTAP Snapshot コピーで保護されているファイルをリカバリできます。ONTAP の Snapshot コピーでは変更されたブロックのみが記録されるため、スペース効率に優れています。</block>
  <block id="9b7db1dd6f422e5f07ded1d3b7b04d90" category="list-text">* グローバル・ネームスペース。 * ONTAP FlexCache テクノロジーにより、ファイル・ストレージのリモート・キャッシュが可能になり、 ONTAP ストレージ・システムを含む複数の場所で共有データを容易に管理できます。</block>
  <block id="827aa7cb1ad6ddbf99e040efe34725a8" category="list-text">* セキュアマルチテナンシーのサポート。 * 1 つの物理ストレージクラスタを、それぞれ独自のボリューム、ストレージプロトコル、論理ネットワークインターフェイス、 ID および認証ドメイン、管理ユーザなどを持つ複数の仮想ストレージアレイとして提供できます。そのため、テスト、開発、本番環境など、複数のビジネスユニットや環境でストレージアレイを共有することができます。</block>
  <block id="6c36afe01468d888b334a4432dcac4b2" category="paragraph">パフォーマンスを保証するために、アダプティブ QoS を使用して使用済みスペースまたは割り当て済みスペースに基づいてパフォーマンスレベルを設定し、クォータを使用してストレージ容量を制御することができます。</block>
  <block id="b1a678f5f86de8ff8a5b9b1c4b3772b8" category="list-text">* VMware 統合。 * VMware vSphere 用 ONTAP ツールは、データストアのプロビジョニング、 vSphere ホストのベストプラクティスの実装、および ONTAP リソースの監視を行うための vCenter プラグインを提供します。</block>
  <block id="9b12997ae1d332c9003c444a6ff8918a" category="paragraph">ONTAP は、 SCSI / ファイルの処理をストレージアレイにオフロードするための vStorage API for Array Integration （ VAAI ）をサポートしています。ONTAP は、 vStorage APIs for Storage Awareness （ VASA ）もサポートしており、ブロックプロトコルとファイルプロトコルの両方をサポートしています。</block>
  <block id="025e05e390f2d7ef7708bb42d81e1eeb" category="paragraph">SnapCenter Plug-in for VMware vSphere を使用すると、ストレージアレイの Snapshot 機能を使用して仮想マシンのバックアップとリストアを簡単に実行できます。</block>
  <block id="3452f822915108b5d640f3288959e7fd" category="paragraph">ActiveIQ Unified Manager は、 vSphere 環境でストレージネットワークをエンドツーエンドで可視化できる機能を提供します。管理者は、 ONTAP でホストされている仮想デスクトップ環境で発生する可能性のあるレイテンシの問題を簡単に特定できます。</block>
  <block id="c9559fb9abb51cf76cc973d06c7e730c" category="list-text">* セキュリティコンプライアンス。 * ActiveIQ Unified Manager では、複数の ONTAP システムを監視し、ポリシー違反のアラートを通知できます。</block>
  <block id="875c0a88cb08e888c642bbcc19cb33a2" category="list-text">* マルチプロトコル対応。 * ONTAP はブロック（ iSCSI 、 FC 、 FCoE 、 NVMe/FC ）、ファイル（ NFSv3 、 NFSv4.1 、 SMB2.x 、および smb3.x ）のストレージプロトコル、およびオブジェクト（ S3 ）ストレージプロトコル。</block>
  <block id="4ac79aa8e1431a96a08ba58c1e17a104" category="list-text">* 自動化のサポート。 * ONTAP は、 VDS 管理ポータルでタスクを自動化する REST API 、 Ansible 、 PowerShell モジュールを提供します。</block>
  <block id="60ece3fee8421729100872ec44f1cda9" category="summary">導入の一環として、ユーザプロファイル、共有データ、およびホームドライブフォルダをホストするファイルサービス方式を選択できます。使用可能なオプションは、ファイルサーバ、 Azure ファイル、 Azure NetApp Files です。ただし、導入後に、 Command Center ツールを使用してこの選択を変更し、任意の SMB 共有を参照することができます。NetApp ONTAP を使用してホストすると、さまざまなメリットがあります。</block>
  <block id="ef9fd867f3eaed93e0806bd027825218" category="inline-link">データ層を変更します</block>
  <block id="1b8c33cc721641b8b0555f2d7b5c2773" category="inline-link-macro">NetApp ONTAP を使用してホストすると、さまざまなメリットがあります。</block>
  <block id="698e77d7e678617a2ae27ca2525bfbf7" category="paragraph">導入の一環として、ユーザプロファイル、共有データ、およびホームドライブフォルダをホストするファイルサービス方式を選択できます。使用可能なオプションは、ファイルサーバ、 Azure ファイル、 Azure NetApp Files です。ただし、導入後に、 Command Center ツールを使用してこの選択を変更し、任意の SMB 共有を参照することができます。 <block ref="50056d02f0a90e2e837160c093f1b22b" category="inline-link-macro-rx"></block>。SMB 共有を変更する方法については、を参照してください<block ref="336429df384a16f14c12cbc8dba62525" category="inline-link-rx"></block>。</block>
  <block id="1afc494dd7d35016d9524e06b68dbf2a" category="paragraph">今回の検証では、コアリソースと管理リソースを Azure 上の同じ VM に導入し、エッジリソースを NetApp HCI 上に配置しました。コアは大量のデータアクセスが必要な領域であり、エッジはコアのサブセットであることに注意してください。ソフトウェアをインストールしたら、使用前にライセンスをアクティブ化する必要があります。これには、次の手順を実行します。</block>
  <block id="70366038f1d44fef6c71f615b677b9cf" category="list-text">[ ライセンスの設定 ] セクションで、 [ ここをクリックしてライセンスの有効化を完了します ] リンクを使用します。次に、コアを登録します。</block>
  <block id="a2184b1f206fd35eeb448e9937bdabe7" category="paragraph">任意のクライアントマシンから、ファイルサーバ上の共有にアクセスするために使用した管理者は、 UNC パス \\&lt;edge サーバ名 &gt;\FASTDATA\&lt;core サーバ名 &gt;\&lt; バックエンドファイルサーバ名 &gt;\&lt; 共有名 &gt;` を使用して GFC エッジからアクセスできます。管理者は、このパスをエッジロケーションのユーザードライブマッピング用のユーザーログオンスクリプトまたは GPO に含めることができます。</block>
  <block id="a067b7082c28e7dbf856ab55b29d1acb" category="paragraph">Salesforce のデータ保護のデモについては、を参照してください<block ref="dd6e5767407887626a36af7b68defda9" category="inline-link-rx"></block>。</block>
  <block id="0fe8a299bf61a0d1bbca5d975dc94fcc" category="paragraph">NetApp VDS を使用したハイブリッド VDI により、サービスプロバイダとエンタープライズ仮想デスクトップ管理者は、ユーザに影響を与えることなく、簡単にリソースを他のクラウド環境に拡張できます。オンプレミスのリソースを使用することで、リソースをより効率的に管理でき、需要に応じて幅広い選択肢（コンピューティング、 GPU 、ストレージ、ネットワーク）を選択できます。</block>
  <block id="95404d16cb98456e438a61d79a0a31d9" category="paragraph">NetApp HCI は、ストレージノードとコンピューティングノードが混在するハイブリッドクラウドインフラです。モデルに応じて、 2 ラックユニットまたはシングルラックユニットのいずれかとして使用できます。VM の導入に必要なインストールと設定は、 NetApp Deployment Engine （ NDE ）で自動化されています。コンピューティングクラスタは VMware vCenter で管理され、ストレージクラスタは NDE で導入された vCenter Plug-in で管理されます。mNode と呼ばれる管理 VM が NDE の一部として導入されます。</block>
  <block id="449aaf51a6dfa9c0e17423ae5938d674" category="inline-link">VMware との互換性ガイド</block>
  <block id="1046a3e2377d26c40f75eb2cd2f268da" category="admonition">ネットアップでは、表示されているコンピューティングサーバに接続されたストレージをサポートしてい を参照してください<block ref="72cc7e3e2b2d7f777e05aa309ef5f733" category="inline-link-rx"></block>。</block>
  <block id="bdced20c33601e0149aecb44114cfdc5" category="paragraph">H610C コンピューティングノードは 2 ラックユニットで、 H615C は 1 ラックユニットのサイズで、消費電力は少なくなります。H615C は、 H.264 および H.265 （ High Efficiency Video Coding [HEVC] ） 4 ： 4 ： 4 のエンコードとデコードをサポートします。また、 VP9 デコーダの主流化が進む中、 YouTube が提供する WebM コンテナパッケージでもビデオに VP9 コーデックを使用しています。</block>
  <block id="29707848401dd26f02baed07b9a416c1" category="paragraph">ネットアップ VDS は、必要なコードベースに基づいて利用可能なセットアップアプリケーションを使用して Microsoft Azure に導入できます。現在のリリースが利用可能です<block ref="deb5bc0c1293f06a53a77d04b921abbd" category="inline-link-rx"></block> また、今後リリースされる製品のプレビュー版もご用意しています<block ref="b5073644bfe6db36c388c6bdbca64b49" category="inline-link-rx"></block>。</block>
  <block id="33491606222aecbfbdfa3fc8f13ffded" category="paragraph">NetApp Virtual Desktop Service は、仮想デスクトップおよびアプリケーション環境を消費しやすくするだけでなく、ビジネス上の課題にも重点的に対応します。VDS をオンプレミスの ONTAP 環境で拡張することで、高速クローン、インライン重複排除、コンパクション、シンプロビジョニングなど、 VDS 環境でネットアップの強力な機能を使用できます。 圧縮機能を使用できます。これらの機能により、オールフラッシュストレージでストレージコストを削減し、パフォーマンスを向上させることができます。VMware vSphere ハイパーバイザーでは、仮想ボリュームと vSphere API を使用してアレイを統合することで、サーバのプロビジョニング時間を最小限に抑えることができます。お客様は、ハイブリッドクラウドを使用して、要件の厳しいワークロードに適した環境を選択し、コストを削減できます。オンプレミスで実行されるデスクトップセッションは、ポリシーに基づいてクラウドリソースにアクセスできます。</block>
  <block id="2eb34c5311117b56d2c8eb33494052a3" category="paragraph">共有データのワークスペース固有のドライブレターマッピングは、 GPO を使用して処理できます。プロフェッショナルサービスまたはサポートチームは、 Active Directory OU 名、 FSLogix の導入を有効または無効にするオプション、さまざまなタイムアウト値などの詳細タブを使用して設定をカスタマイズできます。</block>
  <block id="f6c93f3609bb3be799ed32b6a601d5fc" category="section-title">コマンドセンター（以前は TestVdc ツールと呼ばれていました）</block>
  <block id="46433f623976c5af8ebdc7ab92816a48" category="inline-link">コマンドセンターの概要</block>
  <block id="bf69b43c185864d35a461d8f1c3ea56e" category="paragraph">Command Center と必要なロールを起動するには、を参照してください <block ref="d7ce3bd63a8a34b9b1630abb82acb951" category="inline-link-rx"></block>。</block>
  <block id="b425cca2998cc4a7041a0baf7681e912" category="paragraph">次の操作を実行できます。</block>
  <block id="017b9aa293da801da252c728736f02db" category="inline-link">自動ログ</block>
  <block id="580acc766c3f0e464b462d271028dc32" category="paragraph"><block ref="5f6615a18cd0f2f0bcfb7578db5d1c9e" category="inline-image-macro-rx" type="image"></block>チェックしてください <block ref="11597d7347faee3da56e0e01d5ba1de2" category="inline-link-rx"></block> 詳細については、</block>
  <block id="d1c59e5cbf684efb4f69f300e72a4ac9" category="doc">運用管理</block>
  <block id="8a883bd6e43add9d94d923704bc177a7" category="inline-link-macro">次の手順：ツールとログ</block>
  <block id="28f1e69837c0c21f4dcb8260d6ab5e97" category="paragraph"><block ref="28f1e69837c0c21f4dcb8260d6ab5e97" category="inline-link-macro-rx"></block></block>
  <block id="fb67e63246489555a7e8929a138ced4c" category="paragraph">ワークスペースはデスクトップ環境で構成されます。これは、オンプレミスでホストされている共有リモートデスクトップセッションや、サポートされている任意のクラウド環境で構成されます。Microsoft Azure では、 Windows 仮想デスクトップを使用してデスクトップ環境を永続化できます。各ワークスペースは、特定の組織またはクライアントに関連付けられます。新しいワークスペースを作成するときに使用できるオプションを次の図に示します。</block>
  <block id="5a70681d968007936b9d092ba1a93313" category="paragraph">必要に応じて、導入 VM リソースのデフォルト設定をワークスペースで上書きできます。WVD の場合、 WVD ホストプール（セッションホストとアプリケーショングループを含む）および WVD ワークスペースは、クラウドワークスペース管理スイートポータルから管理することもできます。WVD ホストプールの詳細については、こちらを参照してください<block ref="283c24f69dac0d05b60b041138870b19" category="inline-link-rx"></block>。</block>
  <block id="c70675dc3857ae45ab2475f60c0f1f85" category="paragraph">ネットアップは、 WVD またはリモートアプリケーションによる仮想デスクトップの高速プロビジョニング、 Azure NetApp Files との迅速な統合など、多数のクラウドサービスを提供します。</block>
  <block id="8b32dee3fc7d9223248420cb828c5527" category="paragraph">従来、 IT 部門はリモートデスクトップサービスのプロビジョニングと顧客への提供に数週間かかっていました。プロビジョニングとは別に、アプリケーション、ユーザプロファイル、共有データ、グループポリシーオブジェクトを管理してポリシーを適用することは困難です。ファイアウォールルールは複雑さを増し、別のスキルセットとツールを必要とします。</block>
  <block id="fd9a0083b0a0e084ce6fb8d2ca64272f" category="paragraph">Microsoft では、 Windows 10 のマルチセッションを、 Azure 上の Windows Virtual Desktop 環境専用に提供しています。認証と ID は仮想デスクトップテクノロジによって処理されます。 WVD を使用するには、 Azure Active Directory と（ AD Connect との間で）同期された Azure Active Directory と、 Active Directory に参加したセッション VM が必要です。RDS では、ユーザ ID と認証、および VM ドメインの参加と管理に Active Directory が必要</block>
  <block id="9ea3c4f34057d91531ae286e3efe62c3" category="paragraph">Azure の WVD の場合、 Microsoft は NetApp VDS で消費されるプラットフォームサービスを提供します。他の環境では、 NetApp VDS は Microsoft リモートデスクトップサービスの導入と構成をオーケストレーションします。NetApp VDS は、 WVD Classic と WVD ARM の両方をサポートし、既存のバージョンのアップグレードにも使用できます。</block>
  <block id="71110c8ffc8b198bc951f6e587fbcddf" category="paragraph">Azure WVD の実装では、 Microsoft がクライアントのアクセスエントリポイントを処理し、さまざまな OS でネイティブに使用できる Microsoft WVD クライアントによって使用できます。Web ベースのポータルからもアクセスできます。クライアントソフトウェアの構成は、グループポリシーオブジェクト (GPO) または顧客が優先するその他の方法で処理する必要があります。</block>
  <block id="061d5215d4dd8b8e2b7d9f2498a4a8c3" category="paragraph">ネットアップの VDS では、作成したイメージテンプレートを使用することも、クラウドベースのプロビジョニングの市場にある既存のテンプレートを使用することもできます。管理するイメージの数を減らすために、ベースイメージを使用できます。また、付属のフレームワークを使用して、必要な追加アプリケーションをプロビジョニングし、 chocolatey 、 MSIX アプリケーションアタッチ、 PowerShell などのコマンドラインツールを含めることができます。カスタムスクリプトでも、マシンライフサイクルイベントの一部として使用できます。</block>
  <block id="fd324b11a163d2dae6bf3f9654381d16" category="inline-link-macro">次の手順：仮想デスクトップサービスの ONTAP 機能</block>
  <block id="25838148a81bcaa2b7e931ef8cd65a13" category="paragraph"><block ref="25838148a81bcaa2b7e931ef8cd65a13" category="inline-link-macro-rx"></block></block>
  <block id="93e14ba37d069eff22130cf694c451c1" category="summary">NetApp AFF は、低レイテンシのパフォーマンス、統合データプロテクション、マルチプロトコルサポート、ノンストップオペレーションを実現する堅牢なオールフラッシュストレージプラットフォームです。NetApp ONTAP データ管理ソフトウェアを搭載した NetApp AFF は、ストレージシステムのメンテナンスからアップグレード、完全な交換に至るまで、ノンストップオペレーションを実現します。</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">解決策の概要</block>
  <block id="9ecccbf5710194af15cca545b567957a" category="section-title">NetApp ONTAP on NetApp AFF / FAS</block>
  <block id="13a74472f5a5018f40319d30a728d03e" category="paragraph">NetApp ONTAP は、わかりやすい GUI 、自動化統合機能を備えた REST API 、 AI に基づく予測分析と修正措置、ハードウェアの無停止アップグレード、ストレージ間インポートなどの機能を備えた強力なストレージソフトウェアツールです。</block>
  <block id="3716516b242be48f15f8cbce6557a296" category="paragraph">ONTAP は以下の機能を提供します。</block>
  <block id="3e23168685787e9deffccb3bdb29d98a" category="list-text">NFS 、 CIFS 、 iSCSI 、 FC 、 FCoE を同時にデータアクセスと管理できるユニファイドストレージシステム FC-NVMe プロトコルが必要です。</block>
  <block id="11927aa24f71bc959d85115c8dd8c3a9" category="list-text">導入モデルには、オンプレミスのオールフラッシュ、ハイブリッド、オール HDD のハードウェア構成、 ONTAP Select などのサポートされるハイパーバイザーを使用する VM ベースのストレージプラットフォーム、 Cloud Volumes ONTAP などのクラウドがあります。</block>
  <block id="65c42edcb28a34e276f92dd9b2172613" category="list-text">ONTAP システムでは、データの自動階層化、インラインデータ圧縮、重複排除、コンパクションがサポートされ、データストレージ効率が向上しています。</block>
  <block id="f0a8a62c8d7ea4d12a7f1c95b40d3cb3" category="list-text">ワークロードベースの QoS 制御ストレージ：</block>
  <block id="1e16ebc829d46d68a51d55ac22293b1e" category="list-text">パブリッククラウドとのシームレスな統合により、データの階層化と保護を実現ONTAP は、あらゆる環境に対応する堅牢なデータ保護機能も備えています。</block>
  <block id="613db5a747bd15eeccbcbedce5bd8888" category="list-text">* NetApp Snapshot コピー。 * 最小限のディスク・スペースでデータをポイント・イン・タイムで高速バックアップし、パフォーマンス・オーバーヘッドを追加する必要はありません。</block>
  <block id="8f666d296151faf9c472110831227243" category="list-text">* NetApp SnapMirror 。 * 1 つのストレージ・システムから別のストレージ・システムへデータの Snapshot コピーをミラーリングします。ONTAP では、他の物理プラットフォームやクラウドネイティブのサービスへのデータのミラーリングもサポートされています。</block>
  <block id="5685b3f13393b751231ff096f77e6747" category="list-text">* NetApp SnapLock 。 * 指定された期間にわたって上書きまたは消去できない特殊なボリュームに書き込むことにより、書き換え不可能なデータを効率的に管理します。</block>
  <block id="dff1063d1e007396b7fb75f266dd48b7" category="list-text">* NetApp SnapVault 。 * は、複数のストレージ・システムのデータを、指定されたすべてのシステムのバックアップとして機能する中央の Snapshot コピーにバックアップします。</block>
  <block id="779cb4084f09228e9562ca3bedc5555c" category="list-text">* NetApp SyncMirror 。 * 同じコントローラに物理的に接続された 2 つの異なるディスクプレックスに対して、データをリアルタイムで RAID レベルでミラーリングします。</block>
  <block id="929a0581ca4b2982313e21e51effbc10" category="list-text">* NetApp SnapRestore * を使用すると、 Snapshot コピーからオンデマンドでバックアップされたデータを迅速にリストアできます。</block>
  <block id="774a065cb3548cc61fb0ec3bc1494fbe" category="inline-link">ONTAP 9 ドキュメンテーション・センター</block>
  <block id="fce4095b40c80c8632028b9837563736" category="list-text">* NetApp FlexClone 。 * Snapshot コピーに基づいて、ネットアップボリュームの読み書き可能なフルコピーを瞬時にプロビジョニングできます。ONTAP の詳細については、を参照してください<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>。</block>
  <block id="c389369b80a8ce8ead607b4c7088682e" category="paragraph">NetApp ONTAP は、オンプレミス、仮想環境、クラウド環境で利用できます。</block>
  <block id="75714c8168a0c2a2594249ece5acf44c" category="paragraph"><block ref="75714c8168a0c2a2594249ece5acf44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dad787ba7494eee7d6dbd3cef7e5900e" category="paragraph">永続ボリューム（ PVS ）は、 Kubernetes 環境で定義されたストレージクラスに基づいてプロビジョニングされます。ストレージ管理者が作成したストレージバックエンド（プロジェクトのニーズに応じてカスタマイズ可能）とストレージシステムモデルを使用して、圧縮、特定のディスクタイプ、 QoS レベルなど、パフォーマンスを保証する高度なストレージ機能をいくつでも実行できます。</block>
  <block id="3068002de1b5d66a6a163ddc9883ad94" category="paragraph">Trident は、ネットアップポートフォリオの各システムとサービスでストレージをオーケストレーションします。</block>
  <block id="6d906f4c160e6416d4f0c02a0fb9696c" category="paragraph"><block ref="6d906f4c160e6416d4f0c02a0fb9696c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c572f7c92d4b91543f94621d03cf993" category="section-title">Google Cloud の Anthos</block>
  <block id="885a32398324f13cbf847894ab05bb41" category="paragraph">Google Cloud の Anthos は、クラウドベースの Kubernetes データセンター解決策で、アプリケーション開発に重点を置いたアジャイルワークフローを採用しながら、最新のハイブリッドクラウドインフラを構築、管理できます。ベアメタル上の Anthos は、オンプレミスの物理サーバ上で直接実行する Anthos の機能を拡張し、ハイパーバイザーレイヤーを必要とせずに Google Cloud の Anthos GKE クラスタと相互運用できます。</block>
  <block id="581adec598400d9d02114736724b28d3" category="paragraph">コンテナ、サービスメッシュ、その他の変革テクノロジを採用することで、ローカルおよびクラウドベースの環境で一貫したアプリケーション開発サイクルと本番環境対応のワークロードを体験できるようになります。</block>
  <block id="b7fd1509ff5472f08e8216f563c9c8af" category="list-text">* Google Cloud Marketplace for Kubernetes Applications 。 * キュレーションされたコンテナアプリケーションのカタログを利用して、簡単に導入できます。</block>
  <block id="5204c290ae3b1ebca311a7ca7d447791" category="list-text">* Anthos * に移行。オンプレミスからクラウドへの物理サービスと VM の自動移行を実現します。図 3 は、 Anthos 解決策と、オンプレミスのデータセンターに導入し、クラウドのインフラと相互接続する方法を示しています。</block>
  <block id="608fd0ec5cdb56ad3d3e6d9595ec6f19" category="inline-link">Anthos の Web サイト</block>
  <block id="1192e096cd21e1aa81d806fe9e5d2213" category="paragraph">Anthos の詳細については、を参照してください<block ref="717e02fd176ae4981315950f42bdf0a6" category="inline-link-rx"></block>。</block>
  <block id="70f64e61deea67473fb9951b8f5888b3" category="paragraph">次の図は、 Google Cloud の Anthos アーキテクチャを示しています。</block>
  <block id="99d1b69697dd97e963c0a8145277719d" category="paragraph"><block ref="99d1b69697dd97e963c0a8145277719d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa69ca65720dd2e4eef99ebfb7816268" category="section-title">ベアメタルの Anthos</block>
  <block id="761fffea4910d62111da90337e75abb5" category="paragraph">ベアメタル上の Anthos は、お客様のプライベートデータセンターに導入されている GKE の拡張機能です。オンプレミスの Anthos クラスタ内のコンテナで実行するように設計されたものと同じアプリケーションを導入できます。ベアメタル上の Anthos は、ユーザが選択した Linux オペレーティングシステムを使用して物理サーバ上で直接動作し、本格的なハイブリッドクラウド環境を提供します。この環境は、データセンターのコアまたはエッジで動作します。</block>
  <block id="9eb2eb227133ada575ae959b570e545c" category="paragraph">ベアメタル上の Anthos には次のようなメリットがあります。</block>
  <block id="d966dba0352f5bc4bd7cec115bb0f6f4" category="list-text">* ハードウェアに依存しません。 * お客様は、最適化されたハードウェアプラットフォームを選択して、既存のデータセンターで Anthos を実行できます。</block>
  <block id="69dd75c781331ee9a4c6b2b30d065262" category="list-text">* コスト削減。 * Google Cloud 環境でリソースをプロビジョニングする代わりに、アプリケーションの導入に独自の物理リソースを使用することで、大幅なコスト削減を実現できます。</block>
  <block id="22c97b10f741190427f7bf14aaa217c3" category="list-text">* 開発して公開 * アプリケーションの開発中にオンプレミス環境を使用できます。これにより、アプリケーションをクラウドで公開する前に、ローカルデータセンターのプライバシーでアプリケーションをテストできます。</block>
  <block id="0f9f68e8f2e2599804f40d8fc0861b6d" category="list-text">* パフォーマンスの向上。 * 低レイテンシと最高レベルのパフォーマンスを必要とする負荷の高いアプリケーションは、ハードウェアの近くで実行できます。</block>
  <block id="895cc29ffb809aaf615d5db487a23c7c" category="list-text">* 管理と運用。 * ベアメタルの Anthos には、ネットワーク機能、ライフサイクル管理機能、診断機能、ヘルスチェック、ロギング、 監視機能を提供します。</block>
  <block id="04b942b754be5e16fc9d5b114dd70bb7" category="inline-link-macro">次：解決策の要件</block>
  <block id="dea54f5c884510a9da9977e2655c0a5a" category="paragraph"><block ref="dea54f5c884510a9da9977e2655c0a5a" category="inline-link-macro-rx"></block></block>
  <block id="6de80120fa9469d052fc37775d89d5ca" category="doc">WP-7337 ：『 Anthos on Bare Metal 』</block>
  <block id="8310f10ba877c17b561c1119aa03a750" category="paragraph">この組み合わせにより、 Google Cloud が提供するサポート、サービスレベル、月額課金、オンデマンドの柔軟性と組み合わせることで、サーバ、ストレージ、ネットワークの潜在的な可能性を最大限に引き出すことができます。独自のハードウェア、ネットワーク、ストレージを使用しているため、アプリケーションの規模、セキュリティ、ネットワークのレイテンシを直接制御でき、管理対象アプリケーションとコンテナ化されたアプリケーションをベアメタルの Anthos で利用できます。</block>
  <block id="5cb451e1c66a533348d9c913d8c630e3" category="inline-link-macro">次の手順：解決策の概要</block>
  <block id="7133ec6c94c3cb3dd5d77dce10f8fd70" category="paragraph"><block ref="7133ec6c94c3cb3dd5d77dce10f8fd70" category="inline-link-macro-rx"></block></block>
  <block id="4d7f7f28f54da25e8386b6cfbcbda861" category="summary">この解決策の現在の展開は、 Google Cloud チームが提供するツールを使用して、 2 つの厳格な検証プロセスを実施しました。</block>
  <block id="9fc7e91d0cfa196bee652e5b3ab8991b" category="doc">解決策の検証</block>
  <block id="1bee22d71e0dda5649b05ac8074a7994" category="paragraph">この解決策の現在の展開は、 Google Cloud チームが提供するツールを使用して、 2 つの厳格な検証プロセスを実施しました。これらの検証には、次のテストのサブセットが含まれます。</block>
  <block id="9ce4b6121b9169f9a57e370bc063e43a" category="list-text">Anthos 対応プラットフォームのパートナー検証：</block>
  <block id="b490ae83108f0a60d2d464f37aed5b33" category="list-text">ベアメタルプラットフォームサービス上のすべての Anthos がインストールされ、実行中であることを確認します。</block>
  <block id="132b0b7921ef1247c2db8a06ebb68fa0" category="list-text">ベアメタルクラスタ上の物理 Anthos を 4 つのワーカーノードから 3 つにスケールダウンし、さらに 4 つに戻します。</block>
  <block id="5d80842c7c4c549fffd35b71989523c6" category="list-text">カスタムネームスペースを作成および削除します。</block>
  <block id="bd4534ff45d2d6e71d15c4133153f039" category="list-text">Nginx Web サーバーの配置を作成し、レプリカの数を増やして展開を拡大します。</block>
  <block id="afdfab7c351a97a8f8e386c8c07eead0" category="list-text">Nginx アプリケーションの入力を作成し、 index.html をクリックして接続を確認します。</block>
  <block id="e093cbb18731dc9a857dff2a5a9c5b0d" category="list-text">すべてのテストスイートアクティビティを正常にクリーンアップし、クラスタをテスト前の状態に戻す。</block>
  <block id="6c91e0c5fc919c3ee9adc7909c3331b7" category="list-text">Anthos 対応ストレージのパートナー検証：</block>
  <block id="5aacb1c1d8ec3130c7bfc91d7678968c" category="list-text">永続的ボリューム要求を使用して導入を作成します。</block>
  <block id="7c14d31217a85dc93c1505315501ef24" category="list-text">オフラインボリュームのサイズ変更処理を検証します。</block>
  <block id="b6ab6f9d0bc58a79facf618d65db092c" category="list-text">クラスタの拡張処理が永続的ボリュームに実行されていることを確認します。</block>
  <block id="4b774a4819b60036fd16dae7b1618fe7" category="inline-link-macro">次は終わりです</block>
  <block id="fa789d11a4863ab2ab7271940566105a" category="paragraph"><block ref="fa789d11a4863ab2ab7271940566105a" category="inline-link-macro-rx"></block></block>
  <block id="c12328be87e4d79e79b3db80bd6ff03f" category="list-text">NetApp ONTAP ドキュメントセンター</block>
  <block id="0b98c026ddf9e406d439373d2dab724b" category="inline-link"><block ref="0b98c026ddf9e406d439373d2dab724b" category="inline-link-rx"></block></block>
  <block id="63d46b0efa85a58196faf13e5aa20d7d" category="paragraph"><block ref="63d46b0efa85a58196faf13e5aa20d7d" category="inline-link-rx"></block></block>
  <block id="712cab3570d004ba67a47d7ff8df208b" category="inline-link"><block ref="712cab3570d004ba67a47d7ff8df208b" category="inline-link-rx"></block></block>
  <block id="a5526c10a9a8b42f6aab833b33a57eaf" category="paragraph"><block ref="a5526c10a9a8b42f6aab833b33a57eaf" category="inline-link-rx"></block></block>
  <block id="a3df86c144842761b9bcb0b540edbefe" category="inline-link"><block ref="a3df86c144842761b9bcb0b540edbefe" category="inline-link-rx"></block></block>
  <block id="8d3014f959efddffaea116898b063218" category="paragraph"><block ref="8d3014f959efddffaea116898b063218" category="inline-link-rx"></block></block>
  <block id="50465c19760e2a5476479f1f4a464119" category="summary">ネットアップのベアメタル環境に導入された Anthos は、インフラをカスタマイズできるため、コンテナベースのワークロードを効率的に実行できる堅牢なプラットフォームを提供します。</block>
  <block id="40a15e6807b47955e7b7a9b1bd330b01" category="inline-link-macro">次へ：追加情報の検索場所。</block>
  <block id="3ae752a47170fdc4f7ff5ed3204c1fb5" category="paragraph"><block ref="3ae752a47170fdc4f7ff5ed3204c1fb5" category="inline-link-macro-rx"></block></block>
  <block id="9f9077091d74fb2c701c8c8c4a837c16" category="summary">この解決策の初期検証では、 WWT のアドバンスト・テクノロジー・センター（ ATC ）で環境を構築するために、ネットアップはワールド・ワイド・テクノロジー（ WWT ）と提携しました。Anthos は、 Google Cloud が提供する bmctl ツールを使用してベアメタルインフラに導入されています。次のセクションでは、検証に使用する導入環境について詳しく説明します。</block>
  <block id="06dc93ff20817f0d5fb8a07f8e43d6cb" category="doc">導入の概要</block>
  <block id="195d9c1693fc10788ad8da5d4d9d2402" category="paragraph">NetApp 解決策を搭載したベアメタル環境の Anthos は、 3 台の Anthos コントロールプレーンノードと 4 台の Anthos ワーカーノードを備えた、可用性に優れたハイブリッドクラスタとして構築されました。</block>
  <block id="d0236eb3bd180706e0eaca7d726c66e6" category="paragraph">使用されているコントロールプレーンノードは、シャーシ内にホストされている Cisco UCS B200M3 ブレードサーバであり、それぞれに 1 つの仮想ネットワークインターフェイスカード（ vNIC ）を使用して設定されていました。これにより、耐障害性を実現するために、 Cisco UCS プラットフォームレベルで A/B フェールオーバーが可能になります。Cisco UCS シャーシは、アップストリームで Cisco UCS 6248 ファブリックインターコネクトのペアに接続され、ファブリック A とファブリック B に沿ってトラフィックを分離するための異なるパスを提供しますこれらのファブリックインターコネクトは、アップストリームで Cisco Nexus 5548 データセンタースイッチのペアに接続され、 WWT のコアネットワークに接続されます。</block>
  <block id="3753f99ef321c354828532bad11422ec" category="paragraph">ワーカーノードは、 HP ProLiant DL360 ノードで、それぞれベアメタルの Anthos でサポートされている Linux ディストリビューションの 1 つである Red Hat Enterprise Linux 8.2 、 CentOS 8.2 、 Ubuntu 20.04 LTS 、または Ubuntu 18.04 LTS を実行していました。Red Hat Enterprise Linux 8 および CentOS 8 のノードは、 LACP モードで NIC チームを実行し、フォールトトレランスを実現するために Nexus 9K C93180YC-FX スイッチ 2 つにケーブル接続しました。Ubuntu サーバを LACP モードでネットワークボンディング用に設定し、フォールトトレランスを実現するために、同じ Nexus 9K スイッチペアに接続しました。</block>
  <block id="e5b1fecda3d68cda9e216e0e73b26dec" category="paragraph">次の図は、解決策と上部のラックデータセンタースイッチを物理的にケーブル接続した図です。</block>
  <block id="aa5914d8b6d8a27fd4df86fef0c0395a" category="paragraph"><block ref="aa5914d8b6d8a27fd4df86fef0c0395a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7a105940efa6ed6c71004ff40b8347" category="paragraph">次の図は、ネットアップパートナーの WWT のラボでハードウェアの導入と検証に使用されている解決策の論理ビューを示しています。</block>
  <block id="ff8f4395cfa334d6d144e3a2426e7b96" category="paragraph"><block ref="ff8f4395cfa334d6d144e3a2426e7b96" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8d3f61f51562ad245b65242dc92c0da" category="inline-link-macro">次の例は、解決策の検証です。</block>
  <block id="b1d15269d6e9cabdf17337c73e6a5f07" category="paragraph"><block ref="b1d15269d6e9cabdf17337c73e6a5f07" category="inline-link-macro-rx"></block></block>
  <block id="b2f35a84b813ef160b585d350d2fcd58" category="summary">ハードウェアに依存しないベアメタル上の Anthos 機能により、ユースケースに最適化されたコンピューティングプラットフォームを選択できます。したがって、既存のインフラに合わせて、設備投資を削減できます。</block>
  <block id="5f95fbda20eeb9ce0859afe2ac6f42fa" category="doc">解決策の要件</block>
  <block id="7d4009b9254a61f6afd71a2656a3a78f" category="section-title">コンピューティング：お客様所有のサーバを使用</block>
  <block id="dee41946d9d6ca32131352cb4374f12b" category="paragraph">次の表に、この解決策の実装に必要なコンピューティングハードウェアコンポーネントの最小数を示します。ただし、使用されるハードウェアモデルはお客様の要件に応じて異なる場合があります。</block>
  <block id="c64518704ce0c0d5501a45763f464276" category="cell">使用方法</block>
  <block id="602f72fff77475a16eff159759656261" category="cell">ハードウェアおよびモデル</block>
  <block id="06e9950a2c1bb489cf54d03d4547e913" category="cell">管理ノード</block>
  <block id="b349dcffed4594674c8ce6c91e72e42f" category="cell">Cisco UCS B200</block>
  <block id="fcb81a84511da525a1581c4ccc00d0fb" category="cell">ワーカーノード</block>
  <block id="4867cc2ab4385d91c3a36d6ace67a984" category="cell">HP ProLiant DL360</block>
  <block id="2c0b20f0fbc047d58ca10a50c6a32bc7" category="section-title">ストレージ： NetApp ONTAP</block>
  <block id="eb8440af98c502b8095408e970297e6b" category="cell">NetApp AFF A300</block>
  <block id="e8d610d6c2d243856beaade33b5aa123" category="cell">2 （ HA ペア × 1 ）</block>
  <block id="b6ce11f078022a4ab598b8016db52a13" category="paragraph">次の表に示したソフトウェアバージョンは、ネットアップとパートナー様による解決策の検証に使用されています。ただし、使用されるソフトウェアコンポーネントはお客様の要件に応じて異なる場合があります。</block>
  <block id="128b9c7509f09d8ff4b08e87def0ac74" category="cell">3 人の管理者の OS</block>
  <block id="836a05a21ac6df3b6bcf9838895b017e" category="cell">Worker4 上の OS</block>
  <block id="bbd243e896202aa0eb00ce19d8a7fea8" category="cell">Worker3 上の OS</block>
  <block id="4077fabc9a8b0e761cfd9bf752e03c8a" category="cell">18.04</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS の場合</block>
  <block id="aaad0494526f271ca02ebd06a79e7382" category="cell">Worker2 上の OS</block>
  <block id="2a568439f8e6ff92daa9925ce8a03adf" category="cell">8.2</block>
  <block id="7ac53708026d8515ce15cc154e95f46b" category="cell">Worker1 上の OS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="7cf4fea896dee61293d729d9985621d7" category="cell">コンテナオーケストレーション</block>
  <block id="ca9f0d77f73d954e88e6ab43539ac7cb" category="cell">1.6.0</block>
  <block id="ea704238343d48baa3a08f039015185f" category="cell">Storage OS</block>
  <block id="f33749dd101d316dcf2e6953732629f9" category="cell">9.7P8.</block>
  <block id="8fe1ffd8f7dcf339dd4f34aabb6e1c99" category="cell">Container Storage Management （コンテナストレージ管理）</block>
  <block id="a84024ce06ef98519b3b51300b2c8fbf" category="cell">20.10</block>
  <block id="d94e09dc1956d9513e690f8d24852f05" category="inline-link">ベアメタルドキュメント上の Anthos</block>
  <block id="dea0bcd20b41ad5a5b5830e0facf5d5d" category="paragraph">ベアメタルハードウェアおよびソフトウェアの要件を満たす Anthos の場合は、を参照してください<block ref="39597b4f74e08019db4cace51500cfd6" category="inline-link-rx"></block> ページ</block>
  <block id="71196ec10a92c76a666a93f55523b96e" category="inline-link-macro">次の例は、導入の概要です。</block>
  <block id="1b8d67e147d4d9c532832778cca5fee8" category="paragraph"><block ref="1b8d67e147d4d9c532832778cca5fee8" category="inline-link-macro-rx"></block></block>
  <block id="9411dea29d318927759a55cff454b3dd" category="inline-link-macro">次は、業界向けソリューションです。</block>
  <block id="ee3f381f10f3f075a22913a348a89edf" category="paragraph"><block ref="ee3f381f10f3f075a22913a348a89edf" category="inline-link-macro-rx"></block></block>
  <block id="ec7f98a3714557d87968dc6a898f7912" category="inline-link">ONTAP で VMware Tanzu を活用して Kubernetes への移行を加速</block>
  <block id="32e124b0349f41e06bf1e03f11950665" category="list-text"><block ref="32e124b0349f41e06bf1e03f11950665" category="inline-link-rx"></block></block>
  <block id="526cee55e2936716b5481f8a933bd217" category="inline-link">VVOL をネットアップおよび VMware の Tanzu Basic で使用する方法、パート 1</block>
  <block id="c2240101c5a3a188541ce87c59265df9" category="list-text"><block ref="c2240101c5a3a188541ce87c59265df9" category="inline-link-rx"></block></block>
  <block id="2e933c421900ce4ed68883bfdf00a487" category="inline-link">VVOL をネットアップおよび VMware の Tanzu Basic で使用する方法、パート 2</block>
  <block id="fe72963b1d3021a9f6d8ae34414601c3" category="list-text"><block ref="fe72963b1d3021a9f6d8ae34414601c3" category="inline-link-rx"></block></block>
  <block id="e2a1b52ebd707739003f77464bbcaa80" category="sidebar">FlexPod デスクトップ仮想化ソリューション</block>
  <block id="9efcc0ad3c93b238cc0495e3c87b715f" category="inline-link">Ansible による FlexPod での Oracle 19C RAC の自動導入</block>
  <block id="14c4dbb7c61081eee1c499c4cf138c96" category="sidebar">FlexPod データセンター上の Oracle 19C RAC データベースと Cisco UCS FC 経由の NetApp AFF A800 をサポートしています</block>
  <block id="4c1c4ad5c7782eafb30ad4704dbf4419" category="inline-link">VVOL をネットアップおよび VMware の Tanzu Basic で使用する方法、パート 3</block>
  <block id="4d066173d8401c92a19650e99dcaae5d" category="list-text"><block ref="4d066173d8401c92a19650e99dcaae5d" category="inline-link-rx"></block></block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">このセクションでは、 Trident で実行したいさまざまな処理の例を紹介します。</block>
  <block id="4330c34147b36030c50afe1d04ec2213" category="paragraph">以降のコマンド例では、「 pb_fg_all 」という名前の同じボリュームを、セクションの例で作成した各 Trident バックエンドに対して 1 回ずつ、 2 回インポートしています <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>、手順 1.同じボリュームをこの 2 つの方法でインポートすると、（既存の FlexGroup ボリューム）を複数の LIF にまたがって複数回マウントできます。詳細については、セクションを参照してください <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>、手順 1.PVC の詳細については、を参照してください<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。ボリュームインポート機能の詳細については、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">「 accessModes 」の値「 ReadOnlyMany 」は、 PVC 仕様ファイルの例で指定されています。「 accessMode 」フィールドの詳細については、を参照してください<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。</block>
  <block id="e6d82e60d43fe02e01930addfe670e8f" category="admonition">次の例で指定するバックエンド名 インポートコマンドは、で作成されたバックエンドに対応します の例を参照してください <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>、手順 1.次の例で指定した StorageClass 名 PVC 定義ファイルは、作成された StorageClasses に対応しています を参照してください <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>、手順 1.</block>
  <block id="e149d2e1fdb31ad28f79dd3d2c7ee8ff" category="paragraph">Trident を使用して、ネットアップストレージシステムまたはプラットフォームで新しいボリュームをプロビジョニングできます。次のコマンド例は、新しい FlexVol ボリュームのプロビジョニングを表示します。この例では、セクションの例で作成した StorageClass を使用してボリュームがプロビジョニングされます <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>、ステップ 2 。</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">次の PVC 定義ファイル例では 'accessModes' の値 ReadWriteMany が指定されています「 accessMode 」フィールドの詳細については、を参照してください<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。</block>
  <block id="467941822b3a557a8db7197e12285f14" category="paragraph">この解決策の作成の一環として、パフォーマンスを簡単に比較しました。Kubernetes を使用して、 NetApp AI の標準ベンチマークジョブをいくつか実行しました。また、ベンチマークの結果を、単純な Docker run コマンドを使用して実行した実行結果と比較しました。パフォーマンスに顕著な違いは見られませんでした。このため、 Kubernetes を使用してコンテナ化された AI トレーニングジョブをオーケストレーションしても、パフォーマンスに悪影響が及ばないことがわかりました。パフォーマンス比較の結果については、次の表を参照してください。</block>
  <block id="0e91d2e60705ecb1730e9b96510019af" category="list-text">の手順に従って、 NVIDIA DeepOps をダウンロードします<block ref="6fb71807bf6999d2aec034d498e3ebf6" category="inline-link-rx"></block> NVIDIA DeepOps GitHub サイトで入手できます。</block>
  <block id="5c18e4efa8c5cc9efb26e3f748b4e26d" category="list-text">の手順に従って、クラスタに Kubernetes を導入します 。<block ref="b336a8bbad16f0e8d58bf87e261f51fa" category="inline-link-rx"></block> NVIDIA DeepOps GitHub サイトで入手できます。</block>
  <block id="52d84951381eb0ab7a285dd32b31702c" category="paragraph">Kubeflow は、データサイエンティストのワークスペースとして機能する、新しい Jupyter Notebook サーバの迅速なプロビジョニングを可能にします。Kubeflow を使用して新しい Jupyter Notebook サーバをプロビジョニングするには、次のタスクを実行します。Kubeflow コンテキスト内の Jupyter Notebook の詳細については、を参照してください<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block>。</block>
  <block id="095efbb867f01094d56c633d3337a412" category="list-text">ワークスペースボリュームの詳細を指定します。新しいボリュームを作成するように選択した場合は、そのボリュームまたは PVC がデフォルトの StorageClass を使用してプロビジョニングされます。Trident を利用するストレージクラスがデフォルトとして指定されているため StorageClass <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>を指定した場合、ボリュームまたは PVC は Trident でプロビジョニングされます。このボリュームは、 Jupyter Notebook Server コンテナ内のデフォルトワークスペースとして自動的にマウントされます。別のデータボリュームに保存されていないユーザーがサーバー上に作成したノートブックは、自動的にこのワークスペースボリュームに保存されます。そのため、ノートブックは再起動後も維持されます。</block>
  <block id="555e44b3745904843417371073338d08" category="list-text">データボリュームを追加次に、「 pb-fg-all 」という名前の既存の PVC を指定し、デフォルトのマウントポイントを受け入れる例を示します。</block>
  <block id="37a742c47c216725dd178d8c3c7a3f31" category="list-text">ノートブックサーバーが完全にプロビジョニングされるまで待ちます。指定した Docker イメージを使用してサーバをプロビジョニングしたことがない場合は、イメージのダウンロードが必要になるため、これには数分かかることがあります。サーバーが完全にプロビジョニングされると、 Jupyter Notebook サーバー管理ページの [ ステータス ] 列に緑色のチェックマークが表示されます。</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">「 ONTAP-NAS-flexgroup 」の Trident バックエンドタイプには、かなり大きな最小 PVC サイズがあります。デフォルトでは、 Kubeflow はサイズが数 GB しかない PVC のプロビジョニングを試みます。したがって、 Kubeflow の導入の目的で、「 ONTAP-NAS-flexgroup 」バックエンドタイプをデフォルトの StorageClass として使用する StorageClass を指定しないでください。</block>
  <block id="04e3c704baa1b4c23cd48a18c10fcf39" category="list-text">クラスタに Kubeflow を導入するには、に従ってください<block ref="5e7f04c1dfa70dd058d2720be031c44b" category="inline-link-rx"></block> NVIDIA DeepOps GitHub サイトで入手できます。</block>
  <block id="b714a06d49f16f8b7f988d95734d177f" category="list-text">Kubeflow ネームスペース内に展開されているすべてのポッドに「ステータス」が「実行中」であることを確認し、ネームスペース内に展開されているコンポーネントがエラー状態でないことを確認します。すべてのポッドが起動するまでに数分かかることがあります。</block>
  <block id="64f559cf2e77f73aca6bd3dc9649f62c" category="paragraph">デフォルトのユーザ名は「 admin@kubeflow.org 」で、デフォルトのパスワードは「 12341234 」です。追加ユーザを作成するには、の手順に従います<block ref="f529217f090b2c9cc3764f14abdec5f7" category="inline-link-rx"></block>。</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">NetApp Data Science Toolkit for Kubernetes</block>
  <block id="c5da96d7204df28dd9fdc33139c8a776" category="paragraph">。<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> エアーフローと組み合わせて使用できます。NetApp Data Science Toolkit とエアフローを組み合わせることで、エアフローによって自動化されたワークフローにネットアップのデータ管理操作を組み込むことができます。</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">通気の例</block>
  <block id="9fc322b3a5bb56d2d6ac18c15773d1c2" category="paragraph">を参照してください<block ref="c50bba54faf39c027cd571674d44a9c0" category="inline-link-rx"></block> ツールキットの通気と使用方法の詳細については、 NetApp Data Science Toolkit GitHub リポジトリのセクションを参照してください。</block>
  <block id="1e698f68960fb964df99e73068c9377c" category="list-text">ネットアップでは、 NetApp AFF システムで使用する各データ LIF （データアクセスを提供する論理ネットワークインターフェイス）に対して、 FlexGroup 対応の Trident バックエンドを作成することを推奨します。これにより、 LIF 間でボリュームマウントを分散させることができます</block>
  <block id="a905494ad30a6d54678a2122c04bfd54" category="summary">Jupyter Notebook と Kubeflow パイプラインの例</block>
  <block id="80e94617849fe0b057f3edcc76a6ac72" category="doc">ノートブック PC とパイプラインの例</block>
  <block id="3da57858cd6a76521b38784effc6a06f" category="paragraph">。<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> Kubeflow と組み合わせて使用できます。NetApp Data Science Toolkit と Kubeflow を使用すると、次のようなメリットがあります。</block>
  <block id="624a53dc5871ce49612a285ee2bf367e" category="list-text">データサイエンティストは、 Jupyter Notebook 内から、ネットアップの高度なデータ管理操作を直接実行できます。</block>
  <block id="1c7d37cb415e8b7777b071784911a77a" category="list-text">Kubeflow Pipelines フレームワークを使用すると、ネットアップの高度なデータ管理処理を自動化されたワークフローに組み込むことができます。</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Kubeflow の例</block>
  <block id="987823970c7b662272fb9e0058bf5ff1" category="paragraph">を参照してください<block ref="3eb5d4ffd5360858e22dfb9799f211d7" category="inline-link-rx"></block> ツールキットと Kubeflow を使用する場合の詳細については、 NetApp Data Science Toolkit GitHub リポジトリのセクションを参照してください。</block>
  <block id="1703cadf8e847114fb353feaaf03beb9" category="summary">このセクションでは、 ONTAP AI ポッドに Kubernetes を導入する際に実行可能なさまざまなハイパフォーマンスジョブの例を示します。</block>
  <block id="993143e7434e63409a07cf3e8c422505" category="list-text">FlexGroup が有効な Trident ごとに別々のストレージクラスを作成することを推奨します セクションで作成したバックエンド <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>、手順 1.これらの Granular StorageClasses を使用すると、 StorageClass 仕様ファイルで指定されている特定のバックエンドとして、特定の LIF （ Trident バックエンドの作成時に指定した LIF ）に対応する NFS マウントを追加できます。以降のコマンド例では、 2 つのを作成しています StorageClasses を使用して、バックエンドの 2 つの例に対応しています セクションで作成されます <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>、手順 1.StorageClasses の詳細については、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="f053cb3a491d2bc48d41230b10a9b164" category="list-text">に対応するストレージクラスを作成することも推奨します セクションで作成した FlexVol 対応の Trident バックエンド <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>、ステップ 2 。以下のコマンド例は、 FlexVol ボリューム用の単一のストレージクラスの作成を示しています。</block>
  <block id="86608a0b346f307c76f8ae00c9f6bcb9" category="summary">このレポートでは、データネームスペースを迅速にクローニングする方法について説明します。トレーサビリティとバージョン管理のためにデータやモデルのベースラインをほぼ瞬時に作成する AI トレーニングワークフローを定義および実装する方法を説明します。また、複数のサイトや地域間でデータをシームレスに複製し、 Jupyter Notebook ワークスペースをすばやくプロビジョニングして、大規模なデータセットにアクセスする方法も示します。</block>
  <block id="27114500e25aba7a27847b772d396575" category="paragraph">あらゆる規模の企業や組織が、多くの業界で、人工知能（ AI ）、機械学習（ ML ）、ディープラーニング（ DL ）を導入して、現実世界の問題を解決し、革新的な製品やサービスを提供し、競争が激化する市場で優位に立つことになりつつあります。AI 、 ML 、 DL の利用が増えるにつれ、ワークロードの拡張性やデータの可用性など、多くの課題に直面しています。このドキュメントでは、ネットアップのデータ管理機能と一般的なオープンソースのツールやフレームワークとのペアリングを行う解決策である NetApp AI コントロールプレーンを使用して、これらの課題に対処する方法について説明します。</block>
  <block id="98300151efa6f504dee4866e49cf2078" category="paragraph">このレポートでは、データネームスペースを迅速にクローニングする方法について説明します。また、サイトやリージョン間でデータをシームレスにレプリケートし、統合された AI / ML / DL データパイプラインを構築する方法も示します。さらに、トレーサビリティとバージョン管理のためにデータやモデルベースラインをほぼ瞬時に作成する AI 、 ML 、 DL トレーニングワークフローの定義と実装についても説明します。この解決策を使用すると、すべてのモデルトレーニングを、モデルのトレーニングや検証に使用したデータセットまでトレースできます。最後に、このドキュメントでは、 Jupyter Notebook ワークスペースを、大規模なデータセットにすばやくプロビジョニングする方法を説明します。</block>
  <block id="9d50c340b35848862ab6ecbdadc401ed" category="paragraph">ネットアップの AI コントロールプレーンは、データサイエンティストやデータエンジニアをターゲットとするため、ネットアップや ONTAP ® に関する専門知識は最小限に抑えられます。この解決策を使用すると、シンプルで使い慣れたツールやインターフェイスを使用してデータ管理機能を実行できます。ネットアップストレージがすでにある環境では、ネットアップの AI コントロールプレーンを今すぐテストできます。解決策のテストドライブを希望していても、ネットアップストレージがない場合は、にアクセスしてください<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>クラウドベースのネットアップストレージ解決策を使用すれば、数分で稼働を開始できます。次の図に、解決策を視覚的に示します。</block>
  <block id="14ede02439184c7c75e53410ffa40370" category="list-text">すでに稼働しているネットアップストレージアプライアンス、ソフトウェア定義インスタンス、クラウドストレージサービスで、 Trident でサポートされているものを使用している。</block>
  <block id="07d8795f785e6495307106596d07402e" category="list-text">Trident は、次のいずれかの方法で導入できます。</block>
  <block id="040d3466a6f1c45ca2e523c9354dfdc7" category="inline-link">Trident の導入手順</block>
  <block id="bb6989644edf59b8c5e0de0c25b6f8b6" category="list-text">NVIDIA DeepOps を使用して Kubernetes クラスタを導入した場合は、 NVIDIA DeepOps を使用して Kubernetes クラスタに Trident を導入することもできます。Trident で DeepOps を導入する方法については、を参照してください<block ref="77e542aaaac8c5d2482c94ca2d79c997" category="inline-link-rx"></block> NVIDIA DeepOps GitHub サイトで入手できます。</block>
  <block id="7cfdcb466d040b6c8f9c85e9981b9652" category="inline-link-macro">ONTAP AI 導入向けの Kubernetes StorageClasses の例</block>
  <block id="180b707bbdd9c2fc8001a966c6c7d029" category="admonition">解決策 AI ポッドにネットアップ AI コントロールプレーン ONTAP を導入する場合は、を参照してください <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block> さまざまな Trident バックエンドの例を紹介します とを作成します <block ref="d495c2f5a68f6923824470c0096419c8" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="10dedd24e41d2fa9b5a5e681dd5b4882" category="summary">このページには、コンテナ、 Kubernetes 、 NetApp Trident などの情報を含め、ネットアップが AI プロジェクトをどのように進められるかを理解するための背景情報が含まれています。</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">さまざまなビジネスプロセスと機能を自動化します。</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">最新の AI トレーニングと推論のワークロードには、超並列処理機能が必要です。そのため、 GPU の並列処理機能は汎用 CPU よりもはるかに優れているため、 GPU を使用した AI 処理も増えています。</block>
  <block id="c01fb6f699235f8c5d36bdda9e155c77" category="paragraph">Apache Airflow は、複雑なエンタープライズワークフローのプログラムによるオーサリング、スケジューリング、監視を可能にするオープンソースのワークフロー管理プラットフォームです。ETL やデータパイプラインのワークフローを自動化する目的でよく使用されますが、こうした種類のワークフローに限定されるわけではありません。Airflow プロジェクトは Airbnb が開始しましたが、業界で非常に人気があり、現在は Apache Software Foundation の後援を受けています。空気の流れは Python で書かれており、 Python スクリプトを使用して空気の流れが作られています。また、空気の流れは、「コードとしての設定」という原則に基づいて設計されています。 現在、多くの企業のエアフローユーザが Kubernetes の上で通気を実行しています。</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">ダイレクト非周期グラフ（ DAG ）</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">エアーフローでは、ワークフローは Directed Acyclic Graphs （ DAG ）と呼ばれます。DAG は、 DAG の定義に応じて、順番に実行されるタスク、並列タスク、またはその組み合わせで実行されるタスクで構成されます。エアーフロースケジューラは、 DAG 定義で指定されているタスクレベルの依存関係を維持しながら、一連のワーカーに対して個々のタスクを実行します。DAG は Python スクリプトを使用して定義および作成されます。</block>
  <block id="dc188738e6cc2e9f8314e1b95f18ebfd" category="section-title">NetApp Cloud Sync の略</block>
  <block id="2e386ef1ace3f8ea71edbaa6f9cbbd00" category="paragraph">Cloud Sync は、高速でセキュアなデータ同期を実現するネットアップのサービスです。オンプレミスの NFS または SMB ファイル共有、 NetApp StorageGRID 、 NetApp ONTAP S3 、 NetApp Cloud Volumes Service 、 Azure NetApp Files 、 AWS S3 、 AWS EFS 、 Azure Blob 、 Google Cloud Storage または IBM Cloud Object Storage を使用すると、 Cloud Sync は必要な場所に迅速かつ安全にファイルを移動できます。</block>
  <block id="c1bea6c8c836c6911127e6fe3fde762a" category="paragraph">転送されたデータは、ソースとターゲットの両方で完全に使用できます。Cloud Sync では、事前に定義されたスケジュールに基づいて、更新がトリガーされたときやデータの継続的な同期を行うときに、データをオンデマンドで同期できます。いずれにせよ、 Cloud Sync は差分のみを移動するため、データレプリケーションにかかる時間とコストを最小限に抑えることができます。</block>
  <block id="18c24ab391d7e12f4abcfea370fb4e81" category="paragraph">Cloud Sync は、セットアップや使用がきわめて簡単なソフトウェアサービス（ SaaS ）ツールです。Cloud Sync によって実行されるデータ転送は、データブローカーによって実行されます。Cloud Sync データブローカーは、 AWS 、 Azure 、 Google Cloud Platform 、オンプレミスに導入できます。</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="0e4fcaf78d0d4feda27a31ecb6944b58" category="paragraph">NetApp XCP は、ネットアップとネットアップ間のデータ移行およびファイルシステムに関する分析情報を提供するクライアントベースのソフトウェアです。XCP は、大量のデータセットとハイパフォーマンスな移行を処理するために、利用可能なすべてのシステムリソースを活用することで、最大限のパフォーマンスを実現するように設計されています。ファイルシステムを完全に可視化するために XCP を使用すると、レポート生成オプションが利用できます。</block>
  <block id="9a3914e340e4b09762f8231f9fd0ddaa" category="paragraph">NetApp XCP は、 NFS プロトコルと SMB プロトコルをサポートする単一パッケージで提供されます。NFS データセット用の Linux バイナリと SMB データセット用の Windows 実行可能ファイルが XCP に含まれています。</block>
  <block id="adc911d4d2f4e0008e765523cff39824" category="paragraph">NetApp XCP File Analytics は、ファイル共有を検出し、ファイルシステム上でスキャンを実行し、ファイル分析用のダッシュボードを提供するホストベースのソフトウェアです。XCP File Analytics は、ネットアップシステムと他社システムの両方に対応し、 Linux ホストまたは Windows ホストで動作して、 NFS および SMB エクスポートファイルシステムの分析を提供します。</block>
  <block id="ebbcd572ece7625ba24f2c3ecda6d5b5" category="paragraph">Kubernetes クラスタでシングルノードの AI ジョブと ML ジョブを実行するには、導入ジャンプホストから次のタスクを実行します。Trident を使用すると、数ペタバイトのデータが含まれる可能性のあるデータボリュームをすばやく簡単に作成し、 Kubernetes のワークロードからアクセスできます。Kubernetes ポッド内からこのようなデータボリュームにアクセスできるようにするには、ポッドの定義で PVC を指定します。このステップは Kubernetes ネイティブの運用であり、ネットアップの専門知識は不要です。</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">また、ストレージ帯域幅を最大限にするために、必要なトレーニングデータを含むボリュームが、このジョブで作成されるポッド内に 2 回マウントされます。ポッドには別のボリュームもマウントされています。この 2 つ目のボリュームには、結果と指標を格納します。これらのボリュームは、 PVC の名前を使用してジョブ定義内で参照されます。Kubernetes ジョブの詳細については、を参照してください<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block>。</block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="summary">このセクションでは、 Kubernetes クラスタ内に通気を導入するために完了しておく必要のあるタスクについて説明します。</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">Kubernetes 以外のプラットフォームに通気を導入することも可能です。Kubernetes 以外のプラットフォームに通気を導入することは、この解決策の範囲外です。</block>
  <block id="678c0949a1824bf54eba73ab0a2609d8" category="paragraph">通気を導入する前に、 Kubernetes クラスタ内にデフォルトのストレージクラスを指定する必要があります。エアフロー導入プロセスでは、デフォルトのストレージクラスを使用して新しい永続ボリュームのプロビジョニングが試行されます。StorageClass がデフォルトの StorageClass として指定されていない場合、導入は失敗します。クラスタ内でデフォルトの StorageClass を指定するには、の手順に従ってください <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>。クラスタ内ですでにデフォルトの StorageClass を指定している場合は、この手順を省略できます。</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Helm を使用してエアフローを導入します。に従ってください<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> アーティファクトハブの公式エアフロー図については、を参照してください。以下のコマンド例は、 Helm を使用したエアーフローの配置を示しています。必要に応じて 'custom-values/yaml ファイルの値を変更 ' 追加 ' または削除します</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">すべての通気ポッドが稼働中であることを確認します。すべてのポッドが起動するまでに数分かかる場合があります。</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">通気 Web サービスにアクセスできることを確認します。</block>
  <block id="6a8e19652a540e359304ba812d39ea8e" category="paragraph"><block ref="6a8e19652a540e359304ba812d39ea8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0de039e647bc53dcce6e7bceb8605cbf" category="paragraph">あらゆる規模の企業や組織が、あらゆる業界で、人工知能（ AI ）、機械学習（ ML ）、ディープラーニング（ DL ）を活用して、現実世界の問題を解決し、革新的な製品やサービスを提供し、競争が激化する市場で優位に立つことが求められています。AI 、 ML 、 DL の利用が増えるにつれ、ワークロードの拡張性やデータの可用性など、多くの課題に直面しています。これらの課題には、 NetApp AI コントロールプレーン解決策を使用して対処できます。</block>
  <block id="cae02473f4798da0fdd40f4f598b1d96" category="paragraph">この解決策を使用すると、データネームスペースのクローンを迅速に作成できます。さらに、トレーサビリティとバージョン管理のためにデータやモデルベースラインをほぼ瞬時に作成する AI 、 ML 、 DL のトレーニングワークフローを定義して実装できます。この解決策を使用すると、すべてのモデルトレーニングを、モデルがトレーニングされ、検証されたデータセットに戻すことができます。最後に、この解決策を使用すると、 Jupyter Notebook ワークスペースをすばやくプロビジョニングし、大規模なデータセットにアクセスできます。</block>
  <block id="696dba9a093d4ac7b67234745dd57835" category="paragraph">この解決策はデータサイエンティストとデータエンジニアを対象としているため、ネットアップまたは ONTAP に関する専門知識は最小限で済みます。この解決策を使用すると、シンプルで使い慣れたツールやインターフェイスを使用してデータ管理機能を実行できます。さらに、この解決策では、完全なオープンソースおよび無償のコンポーネントを使用しています。したがって、ネットアップストレージがすでにある環境では、この解決策を実装できます。この解決策でドライブをテストしたいが、ネットアップストレージはまだお持ちでない場合は、を参照してください<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>また、クラウドベースの NetApp Storage 解決策を使用すれば、いつでも稼働を開始できます。</block>
  <block id="3a607d0e3fa64fd7558e11352f751dd0" category="summary">NetApp AI コントロールプレーン解決策は、このような特定のハードウェアには依存しません。</block>
  <block id="976cf3edd8adeff2e75cd7a9dd0dae21" category="paragraph">NetApp AI コントロールプレーン解決策は、このような特定のハードウェアには依存しません。解決策は、 Trident でサポートされている、任意のネットアップ物理ストレージアプライアンス、ソフトウェア定義インスタンス、クラウドサービスと互換性があります。例としては、ネットアップ AFF ストレージシステム、 Azure NetApp Files 、ネットアップ Cloud Volumes Service 、ネットアップ ONTAP Select ソフトウェアで定義されるストレージインスタンス、ネットアップ Cloud Volumes ONTAP インスタンスなどがあります。また、使用する Kubernetes のバージョンが Kubeflow および NetApp Trident でサポートされていれば、どの Kubernetes クラスタにも解決策を実装できます。Kubeflow でサポートされる Kubernetes バージョンの一覧については、を参照してください<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>。Trident でサポートされている Kubernetes のバージョンのリストについては、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。解決策の検証に使用した環境の詳細については、次の表を参照してください。</block>
  <block id="204dd0a482d284a7fb87c908f713f9bd" category="cell">Ubuntu 20.04.2 LTS の場合は</block>
  <block id="76a7e6383604f84ace970ce86ba76a9f" category="cell">Kubernetes GPU ワーカーノード</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="cell">NetApp AFF A220</block>
  <block id="d1d73cf191d1afbd40e85644467cae8b" category="cell">NetApp ONTAP 9.7 P6</block>
  <block id="47354877541923135499c38a6606138a" category="cell">2.0.1</block>
  <block id="ecfa741d55b7b1a85bd61a2307877c8c" category="cell">8.0.8</block>
  <block id="fd99a7ef225418315b041ad631a5674c" category="cell">19.03.12</block>
  <block id="56765472680401499c79732468ba4340" category="cell">1/2</block>
  <block id="48d02190984e4f8526f99f9cd9550e08" category="cell">1.18.9</block>
  <block id="d58d49f83f534f5d71b20750bb7927c7" category="cell">21.01.2.</block>
  <block id="7a04e1f765218bcbfc633ef331b312b8" category="inline-link">61898cdfda</block>
  <block id="7855beff2fafbce2cf0df4d67f8dfed7" category="cell">コミット時点でマスターブランチから Trident 導入機能を利用できるようになりました <block ref="686ead03155c78694e1a59db0970fc1a" category="inline-link-rx"></block>; バージョン 21.03 の他のすべての機能</block>
  <block id="fad62e8b886e655813cc4ce635152f62" category="sidebar">Trident の導入</block>
  <block id="fb6b632cdd61e02434568081cbbf0fae" category="paragraph">使用してください <block ref="a5f81f398e43efd62a061a201309bfa7" category="inline-link-rx"></block> コンテンツの変更をリクエストしたり、コンテンツに関するフィードバックを提供したりすることができます。フィードバックが適切に処理されるよう、できるだけ具体的にご記入ください。</block>
  <block id="9e2c62f406d88ad1ee253efd74f593df" category="sidebar">新しい解決策を提案する</block>
  <block id="7fd861566be88364067d817b54a44688" category="sidebar">解決策に関するご意見・ご要望</block>
  <block id="12797522e94d75727dd0a05a4ed9f5ff" category="sidebar">NVIDIA を使用した ONTAP AI</block>
  <block id="687350c847aefbf978e16be26609d101" category="sidebar">NVIDIA DGX A100 システム搭載の ONTAP AI 設計ガイド</block>
  <block id="4c7a8c5b878fcdf733694f638b393b6b" category="sidebar">NVIDIA DGX A100 システムによる ONTAP AI 導入ガイド</block>
  <block id="74c684b866e5fcffcc9c5165a491d5b2" category="sidebar">NVIDIA DGX A100 システムと Mellanox Spectrum を搭載した ONTAP AI イーサネットスイッチ設計ガイド</block>
  <block id="f8363659ae3ab117a0afa4163ca69fc7" category="sidebar">NVIDIA DGX A100 システムと Mellanox Spectrum を搭載した ONTAP AI イーサネットスイッチ導入ガイド</block>
  <block id="0c3efd7c1aae12456ab9935ae5fd15e0" category="sidebar">NVIDIA DGX A100 システムと BeeGFS を搭載した EF シリーズ AI</block>
  <block id="c70e778edabe427cd2db90132a56e456" category="sidebar">NVIDIA DGX A100 システムと BeeGFS 設計を搭載した EF シリーズ AI</block>
  <block id="06aa576b3e3e95c5df800228d146af65" category="sidebar">NVIDIA DGX A100 システムと BeeGFS を搭載した EF シリーズ AI の導入</block>
  <block id="38d9ffc674675d65fbb8aabd7e47acd3" category="sidebar">FlexPod ソリューション</block>
  <block id="d4c96dcd516adf0c5bde093b0b7b7255" category="summary">このページでは、 NetApp ONTAP ストレージ上に Oracle19c を導入するための自動化方式について説明します。</block>
  <block id="cb59b87e00d11222bfd9159d0d23836f" category="doc">はじめに</block>
  <block id="def8ebf26c2dec5f6af5a00893fae037" category="paragraph">この解決策は、 AWX/Tower 環境または Ansible コントロールホストの CLI で実行されるように設計されています。</block>
  <block id="008ba800d97cb969def651e93f0d93fb" category="section-title">AWX ／タワー</block>
  <block id="a481f1841043d60245f18522a86731b1" category="paragraph">AWX / タワー環境の場合は、 ONTAP クラスタ管理と Oracle サーバ（ IP およびホスト名）のインベントリの作成、クレデンシャルの作成、 NetApp Automation Github から Ansible コードを取得するプロジェクトの設定、および自動化を開始するジョブテンプレートの設定を案内されます。</block>
  <block id="5055de7b9d28f88e537f99f34959c80c" category="list-text">環境に固有の変数を入力し、ジョブテンプレートのその他の VAR フィールドにコピーして貼り付けます。</block>
  <block id="d116f375db402ba471f519c0a4df15dc" category="list-text">ジョブテンプレートに変数を追加したら、自動化を起動できます。</block>
  <block id="8ca0a52cf9938328875e0a8803ae71dd" category="list-text">ジョブテンプレートは、 ontap/config 、 linux_config 、および ORACLE_config のタグを指定することで、 3 つのフェーズで実行されます。</block>
  <block id="da3d0d670ace8a327170aa25ee29f272" category="section-title">Ansible コントロールホストを介して CLI に接続します</block>
  <block id="6a5f01bc22c397ee84e04e48c178e980" category="inline-link-macro">RHEL 7/8 または CentOS 7/8 の場合は、こちらをクリックしてください</block>
  <block id="7946c3996884ee105962c5334bfd9fef" category="inline-link-macro">Ubuntu / Debian の場合はこちら</block>
  <block id="28e934ddab7714830f8afe8d3b641dc9" category="list-text">Ansible 制御ホストが設定されたら、 Ansible Automation リポジトリのクローンを Git で作成できます。</block>
  <block id="f667be8dac02593d217a02ac5bfb18de" category="list-text">ONTAP クラスタ管理 IP および Oracle サーバの管理 IP の IP またはホスト名を使用して hosts ファイルを編集してください。</block>
  <block id="95bd15e6b4a109de659c54c331c06284" category="list-text">環境に固有の変数を入力し ' 変数 .yml ファイルにコピーして貼り付けます</block>
  <block id="ca548be3e5f238d32286d43dc4c89f7b" category="list-text">各 Oracle ホストには、ホスト固有の変数を含むホスト名で識別される変数ファイルがあります。</block>
  <block id="87192ebbcab92216d25fd694a282971d" category="list-text">すべての変数ファイルが完了したら 'ONTAP_config' 'linux_config' および 'ORACLE_config' のタグを指定することで ' 3 つのフェーズでプレイブックを実行できます</block>
  <block id="5a2ebfb8baa378cfcfcba58bbb1380c2" category="section-title">要件</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">環境</block>
  <block id="9d5cfca4ad04b54536e5ad15210f7dc2" category="cell">* Ansible 環境 *</block>
  <block id="eebc1357e7d1e88ed4e4908d5ae86c0b" category="cell">AWX/Tower または Linux ホストを Ansible コントロールホストにします</block>
  <block id="3f0733e14ebf265f0abf4b32371043ac" category="cell">Ansible v.2.10 以上</block>
  <block id="3c91a74236fab100f024452f6df13b5e" category="cell">Python 3.</block>
  <block id="215b38d177939de20bbb7b7913ce32c1" category="cell">Python ライブラリ - NetApp-lib-xmltodict-jmespath</block>
  <block id="d911b17f4f4cdcca62a04ad77aa9403d" category="cell">* ONTAP *</block>
  <block id="0a928fe81d89083ed303ea3d9f1af8c9" category="cell">ONTAP バージョン 9.3-9.7</block>
  <block id="10aadda84b1b1da26c3757dfdb59379d" category="cell">データアグリゲート × 2</block>
  <block id="9f998f9668ffe69c62d78760d1c531f0" category="cell">NFS VLAN および ifgrp が作成されました</block>
  <block id="ba5f343281b90f0408008806c66bce86" category="cell">* Oracle サーバ *</block>
  <block id="6f1de5f0d7966ebf5f8d255fe28ebffe" category="cell">RHEL 7/8</block>
  <block id="aa596da3b79631d86c0d35e1c4b03aac" category="cell">Oracle Linux 7/8</block>
  <block id="814e8f57514db6134b6ffcd7a4ce20a6" category="cell">NFS 、パブリック、オプションの管理用のネットワークインターフェイス</block>
  <block id="515f291f3ecc550c5d13cf31fadba91d" category="cell">Oracle サーバ上の Oracle インストールファイル</block>
  <block id="ae9205dab0c26cca7762be5149a93923" category="section-title">自動化の詳細</block>
  <block id="ba0676e7ae183e2c0bbd54261818154f" category="paragraph">この自動導入は、 3 つのロールで構成される Ansible プレイブックを使用して設計されています。ロールは ONTAP 、 Linux 、 Oracle の各構成に対応しています。次の表に、自動化されるタスクを示します。</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">ロール</block>
  <block id="ef615563c8e8ea902c7fcac3cd2c4246" category="cell">タスク</block>
  <block id="9bb642814808cd0cab510ddfb9e5969c" category="cell">* ONTAP_CONFIG *</block>
  <block id="c0563eda0fb9d63778efe04a13a5d744" category="cell">ONTAP 環境の事前チェック</block>
  <block id="79b814c8267c6b7822e78ab4624db8e0" category="cell">Oracle 用の NFS ベースの SVM の作成</block>
  <block id="0c981d6164da0d8e69cdb199966316b0" category="cell">エクスポートポリシーが作成されました</block>
  <block id="99179ac01bbb0236fc540871377c55c4" category="cell">Oracle 用のボリュームの作成</block>
  <block id="db738705829d97db1e287ad8ea9e5400" category="cell">NFS LIF の作成</block>
  <block id="089c4c184b079d771501d8ceb0f3bb05" category="cell">*linux_config*</block>
  <block id="3ea572544d30a39d236496578f980d13" category="cell">マウントポイントを作成し、 NFS ボリュームをマウント</block>
  <block id="db6c0f994cc39fbf66d58eea6c627e6a" category="cell">NFS マウントを確認</block>
  <block id="6a882e7966e7869ab1d2112a0b1c0074" category="cell">OS 固有の設定</block>
  <block id="6e6d41d1398fafd8809de20e831c9ce3" category="cell">Oracle ディレクトリを作成します</block>
  <block id="6f965a5d44e1653dac9825f465f71c84" category="cell">hugepages を設定します</block>
  <block id="be577868fe0712b7bbb6d5cb5eae613c" category="cell">SELinux とファイアウォールデーモンを無効にする</block>
  <block id="bb6f16330211bf24baa83db38b11e4a9" category="cell">サービスを有効にして開始します</block>
  <block id="e9e5cefa281d2c696aac82ef9c756f51" category="cell">ファイル記述子のハードリミットを増やします</block>
  <block id="a4acc779f882208c081f943aedfeab5c" category="cell">pam.d セッションファイルを作成します</block>
  <block id="d03021f9e02b9fa9ebac591ad4bfea08" category="cell">* ORACLE_CONFIG *</block>
  <block id="5e706781d4bf141c80e249a244179235" category="cell">Oracle ソフトウェアのインストール</block>
  <block id="1a98fce6d77de1126bf3cb8247747621" category="cell">Oracle リスナーを作成します</block>
  <block id="841df7bfbef212936073c6d261d4dba9" category="cell">Oracle データベースを作成します</block>
  <block id="845a6e024025bb13aafdc167511e5e7d" category="cell">Oracle 環境構成</block>
  <block id="666113957f940ba4319b4f0d9c3e86c0" category="cell">PDB 状態を保存します</block>
  <block id="264bca6ddd5a16346460d9c21e8f926d" category="cell">インスタンスアーカイブモードを有効にします</block>
  <block id="620ca5ae835411d2031ca0fdbbbe61a1" category="cell">DNFS クライアントを有効にしてください</block>
  <block id="4d7e6c9b84f6f86cf4817262ad424eeb" category="cell">OS のリブート間のデータベースの自動起動とシャットダウンを有効にします</block>
  <block id="bf60025632dd0c4a2cf35e8b33e80619" category="section-title">デフォルトパラメータ</block>
  <block id="ebda2606845855cc07ce0ce15ecf8a00" category="paragraph">自動化を簡易化するために、必要な Oracle 導入パラメータが多数デフォルト値であらかじめ設定されています。通常、ほとんどの環境でデフォルトパラメータを変更する必要はありません。上級ユーザーは ' デフォルト・パラメータを変更する際に注意してくださいデフォルトのパラメータは、各ロールフォルダの defaults ディレクトリにあります。</block>
  <block id="452eff11ca6d680a279a3e81b8dc8974" category="section-title">導入手順</block>
  <block id="1cf7ad9cd74067dd3f4aee3c1690ea32" category="paragraph">開始する前に ' 次の Oracle インストール・ファイルとパッチ・ファイルをダウンロードし '/tmp/archive' ディレクトリに配置しますこのディレクトリには ' 展開する各 DB サーバ上のすべてのユーザに対する読み取り ' 書き込み ' および実行のアクセス権が含まれます自動化タスクは、その特定のディレクトリにある指定されたインストールファイルを検索して、 Oracle のインストールと構成を行います。</block>
  <block id="19adadc497199e16f07f9744d43b2899" category="paragraph">Github リポジトリに記載されているライセンス情報をお読みください。このリポジトリ内のコンテンツにアクセス、ダウンロード、インストール、または使用することにより、ライセンスの条項に同意したものとみなされます <block ref="07d15b3b85718d883b437fb3739e59a7" category="inline-link-rx"></block>。</block>
  <block id="87d624bc8a7f555a711e7214ee002eec" category="paragraph">このリポジトリ内のコンテンツの作成および / または派生著作物の共有に関しては、一定の制限事項があります。の条件を必ずお読みください <block ref="49480c711afcff6aca610d8294731030" category="inline-link-rx"></block> コンテンツを使用する前に。すべての条件に同意しない場合は、このリポジトリのコンテンツにアクセスしたり、コンテンツをダウンロードしたり、使用したりしないでください。</block>
  <block id="5abe869dd828ac1e4527f07db79841a8" category="inline-link-macro">AWX/Tower の導入手順の詳細については、こちらを参照してください</block>
  <block id="c3bcf861ccc9247a7c0a9b4749747e4e" category="inline-link-macro">CLI の導入については、こちらをご覧ください</block>
  <block id="f867ea86471dd6849f2c840cf13d1536" category="paragraph">準備ができたら、をクリックします <block ref="0ecf76284fbf596cdd030af085c16a3b" category="inline-link-macro-rx"></block> または <block ref="42cd9508ebf775e8df0efba80be76af7" category="inline-link-macro-rx"></block>。</block>
  <block id="13d13fda6fbfbd83ab30f9a5bee17b08" category="section-title">Oracle19c for ONTAP の NFS への自動導入</block>
  <block id="9ce6d30135c2644ff34390c65af4061b" category="paragraph">組織は環境を自動化して、効率を高め、導入を高速化し、手動作業を削減しています。Ansible などの構成管理ツールを使用して、エンタープライズデータベースの運用を合理化しています。この解決策では、 Ansible を使用して、 Oracle 19C のプロビジョニングと設定を NetApp ONTAP で自動化する方法を紹介します。ストレージ管理者、システム管理者、 DBA は、新しいストレージの一貫した迅速な導入、データベースサーバの構成、 Oracle 19C ソフトウェアのインストールを可能にすることで、次のようなメリットを得ることができます。</block>
  <block id="5291cb8e681983247b899ce2364188f2" category="list-text">設計の複雑さと人為的ミスを排除し、繰り返し実行可能な一貫した導入とベストプラクティスを実装する</block>
  <block id="a90516bf4597e04e1a97bd9cb37087d8" category="list-text">ストレージのプロビジョニング、 DB ホストの構成、 Oracle のインストールにかかる時間を短縮</block>
  <block id="a54e59b6b063d8a2bf18acffab877d09" category="list-text">データベース管理者、システム管理者、ストレージ管理者の生産性を向上</block>
  <block id="d18d76441366273feb36bde890ad5e1c" category="list-text">ストレージとデータベースを簡単に拡張できます</block>
  <block id="7d85c5a5f016aefeda6b89687f1307bb" category="paragraph">ネットアップは、検証済みの Ansible モジュールとロールをお客様に提供し、 Oracle データベース環境の導入、構成、ライフサイクル管理を迅速化します。この解決策では、以下の作業に役立つ Ansible の Playbook コードを提供しています。</block>
  <block id="547b893b7cd300d6a8335f5b179ad12e" category="list-text">Oracle データベース用の ONTAP NFS ストレージを作成して設定します</block>
  <block id="36bb01ec9f02292fb44b9f10f57ceae7" category="list-text">Oracle 19C を Red Hat Enterprise Linux 7/8 または Oracle にインストールします Linux 7/8.</block>
  <block id="548bf87c41c9d3bb76981decbd599c90" category="list-text">ONTAP NFS ストレージ上に Oracle 19C を設定します</block>
  <block id="0dd197c8abd1f3c3607887dbc615148f" category="doc">Oracle のインストールを検証します</block>
  <block id="f673434da0f39c1b4366cbc45f67da8a" category="admonition">インストールが正常に完了した場合は、 Oracle プロセスが一覧表示されます Oracle DB のサポートを開始しました</block>
  <block id="91bcd024d07cb33293902b287b0cc68c" category="paragraph">[oracle @localhost ~] $sqlplus / AS sysdba</block>
  <block id="b95bce10ef504692a6d971d3a30ac8c4" category="paragraph">SQL * Plus ：リリース 19.0.0.0.0 - 木曜日 5 月 6 日 12 ： 52 ： 51 2021 バージョン 19.8.0.0.0 の製造</block>
  <block id="a2494ba30f29d91ff6876152fc693ab3" category="paragraph">Copyright （ c ） 1982 、 2019 、 OracleAll rights reserved.</block>
  <block id="ce8b3f5af3f95d98bbbf478e4c37024f" category="paragraph">接続先： Oracle Database 19C Enterprise Edition Release 19.0.0.0.0 - Production Version 19.8.0.0.0</block>
  <block id="28a359e505158300600d776ae9347cac" category="paragraph">SQL&gt;</block>
  <block id="63102463594ac5bd274343651065779d" category="paragraph">SQL&gt; 名前の選択、 log_mode は V$ データベースから、名前 log_mode は ---- - - - - - - - - - - CDB2 ARCHIVELOG</block>
  <block id="7d8bf5a6b847068ff3c0eb0ca0892acf" category="paragraph">SQL&gt; PDB を表示</block>
  <block id="33c7676f0bdcf42bed62c146feaf485c" category="paragraph">SQL&gt; col svrname フォーム A30 SQL&gt; col dirname フォーム A30 SQL&gt; select svrname 、 dirname 、 nfsversion from v$dnfs_servers ；</block>
  <block id="d6bee2dc52f5708cd8af49c1c263c714" category="paragraph">SVRNAME NFSVERVERSION-------------------------------- -------------- - - - - - - - - - - - - - 172.21.126.200/rhelora03_u02 NFSv4 3.0 172.21.126.200/rhelora03_u03 NFSv4 3.0 172.21.126.200/rhelora03_u01 NFSv3.0 を NFSv4 3.00 に戻します</block>
  <block id="ea12870da72347cdd45bc11ae4d603dc" category="paragraph">[oracle @ localhost ~] $sqlplus システム @ // localhost ： 1523 / cdb2_pdb1.cie.netapp.com</block>
  <block id="aff680efe40afd832819af131e324051" category="paragraph">SQL * Plus ：リリース 19.0.0.0.0 - 木曜日 5 月 6 日 13 ： 19 ： 57 2021 バージョン 19.8.0.0.0 の製造</block>
  <block id="6c3d252188792733323cf879b5d196cf" category="paragraph">パスワード「 Last Successful login time ： Wed May 05 2021 17 ： 11 ： 11-04 ： 00 」を入力します</block>
  <block id="531fea2bb939d7c35cad66fde1640511" category="paragraph">SQL&gt; show user user is "system" SQL&gt; show con_name CON_name CDB2_PDB1</block>
  <block id="52320018ddc230fda7bdeccfda8b9f0a" category="section-title">サポートが必要な場所</block>
  <block id="1b6a5f8b328d3175066895d7ff5ea576" category="inline-link">ネットアップの解決策自動化コミュニティでは、余裕期間のチャネルがサポートさ</block>
  <block id="12f178498803c606c23e7166dcefb0cb" category="paragraph">ツールキットに関するサポートが必要な場合は、にご参加ください <block ref="f1bb21e2ce6888d898ae31a2098245a1" category="inline-link-rx"></block> また、ソリューション自動化チャネルを検索して、質問や問い合わせを投稿しましょう。</block>
  <block id="d0db3f5a4a306cff20be4187b3ef3445" category="doc">VAR</block>
  <block id="6551468cb4811e7add616eea103efea9" category="doc">ステップバイステップの導入手順</block>
  <block id="0e6b1c16527d2792d391c578bbf12efe" category="section-title">CLI による Oracle 19C データベースの導入</block>
  <block id="57daddd847cdbab22b7363630de48a2f" category="inline-link-macro">「はじめに」および「要件」セクション</block>
  <block id="82ba94e85d91493ea6c88423c0b34605" category="paragraph">このセクションでは、 CLI を使用して Oracle19c データベースを準備および導入するために必要な手順について説明します。を確認しておきます <block ref="598ea103507880273a5a1840cac102d8" category="inline-link-macro-rx"></block> それに応じて環境の準備を整えます。</block>
  <block id="0f2d7675188dbfc7b9df587588bff71b" category="section-title">Oracle19c repo をダウンロードします</block>
  <block id="4e2b619426350db7e7d5b09c96b8010b" category="section-title">hosts ファイルを編集します</block>
  <block id="b183e47af1fa85c93e4a4368205c3249" category="paragraph">導入前に、次の手順を実行します。</block>
  <block id="c4ab1530ffd8a3306d47c804ca88240c" category="list-text">hosts ファイル na_oracle19c_deploy ディレクトリを編集します。</block>
  <block id="bc1dd0e50a3c20e78cc2d680eaf32378" category="list-text">ONTAP で、 IP アドレスをクラスタ管理 IP に変更します。</block>
  <block id="6475f51ce7ff0a21a5635ea50b1f1a86" category="list-text">[Oracle] グループの下に、 Oracle ホスト名を追加します。DNS または hosts ファイルを使用してホスト名を IP アドレスに解決しておくか、ホストで指定する必要があります。</block>
  <block id="5c3f5e9dc815ca28c7cf1ff64cdc61a2" category="list-text">これらの手順を完了したら、変更を保存します。</block>
  <block id="b27994a7bba852ac9a8f1a262413e68b" category="paragraph">次の例は、ホストファイルを示しています。</block>
  <block id="1caa2eee0ed6a6c5c6edcbc0320e8671" category="paragraph">この例では、 Playbook を実行し、 Oracle 19C を 2 台の Oracle DB サーバに同時に導入しています。1 つの DB サーバでテストすることもできます。この場合、設定が必要なホスト変数ファイルは 1 つだけです。</block>
  <block id="d11927d6f93a4edaa78dc52c6e34fd5f" category="admonition">このプレイブックの内容は、導入する Oracle ホストとデータベースの数に関係なく同じです。</block>
  <block id="030c98564d5fbd7c8672a76e2a593b21" category="section-title">host_vars で host_name .yml ファイルを編集します</block>
  <block id="86c40bb4891f3e6b34a2eece7bb19532" category="paragraph">各 Oracle ホストには、ホスト固有の変数を含むホスト名で識別されるホスト変数ファイルがあります。ホストには任意の名前を指定できます。Host VAR Config セクションから「 host_vars 」を編集してコピーし、目的の「 host_name.yml 」ファイルに貼り付けます。</block>
  <block id="93be2ec6954884b83ac9df8117967949" category="admonition">青の項目は、環境に合わせて変更する必要があります。</block>
  <block id="5bbe8264b4d6c6787657c66d4017c183" category="section-title">ホスト VAR 構成</block>
  <block id="44505c1007599884b05c0148599ad1b0" category="section-title">vars.yml ファイルを編集します</block>
  <block id="41cdd95196e2753968e0d69375c41825" category="paragraph">変数 .yml` ファイルは 'Oracle の導入に向けて ' 環境固有のすべての変数（ ONTAP 'Linux'Oracle ）を統合します</block>
  <block id="271f9ccf9c8189bb1888d25c7f0e025b" category="list-text">変数を VAR セクションから編集してコピーし、変数を自分の「 vars.yml 」ファイルに貼り付けます。</block>
  <block id="78d77851709e21512097cee585c59d0c" category="section-title">プレイブックを実行します</block>
  <block id="8f42d9f703ada5b4f1374ca96a4f1cec" category="paragraph">必要な環境の前提条件を完了し ' 変数を vars.yml' および 'Your_host.yml' にコピーした後 ' プレイブックを導入する準備が整いました</block>
  <block id="6226590ec5d4a109e4b93317425994c1" category="admonition">&lt;username&gt; は、環境に合わせて変更する必要があります。</block>
  <block id="24b2767982b51deb19947fb3e94279c6" category="section-title">同じ Oracle ホストに追加のデータベースを導入します</block>
  <block id="5cc75d1029461de7ddcd02bbc784af26" category="paragraph">このプレイブックの Oracle 部分では、 1 回の実行につき Oracle サーバ上に Oracle コンテナデータベースが 1 つ作成されます。同じサーバ上に追加のコンテナデータベースを作成するには、次の手順を実行します。</block>
  <block id="b4a35a2d5c3a4f3efb7c77f6bcd2a905" category="list-text">host_vars 変数を改訂します。</block>
  <block id="5641cb71d4e10abef15918c2dd828917" category="list-text">ステップ 3 に戻ります - 'host_vars' の下の 'host_name.yml' ファイルを編集します</block>
  <block id="ffcc6e6df9c3839334c063a9223c65b3" category="list-text">Oracle SID を別の名前文字列に変更します。</block>
  <block id="a936a5fabc881eb3591658385409dfb8" category="list-text">リスナーポートを別の番号に変更します。</block>
  <block id="24f0029973c35b16fc49847b27215915" category="list-text">EM Express をインストールしている場合は、 EM Express ポートを別の番号に変更します。</block>
  <block id="365c64de6adc281d7f484029d1356855" category="list-text">変更したホスト変数を 'host_vars' の下の Oracle ホスト変数ファイルにコピーして貼り付けます</block>
  <block id="b64219fd8290ac8a154f733df0825dbb" category="list-text">上記のように 'ORACLE_CONFIG' タグを使用してプレイブックを実行します インチ <block ref="1c892654e23ff69bf71caefc702aa8b4" category="inline-xref-macro-rx"></block>。</block>
  <block id="c150393fd3b1bd9d801cbd062234f73d" category="section-title">AWX/Tower の導入 Oracle 19C データベース</block>
  <block id="32003b051ef9368756d1e9cd79796719" category="section-title">1. 環境のインベントリ、グループ、ホスト、およびクレデンシャルを作成します</block>
  <block id="2c8b94d570dd5a63a27d112e32a1c799" category="paragraph">このセクションでは、ネットアップの自動化ソリューションを使用する環境を準備するための AWX/Ansible タワーでのインベントリ、グループ、ホスト、アクセスクレデンシャルのセットアップについて説明します。</block>
  <block id="134d501fee5367069f0746f15302ce1f" category="list-text">インベントリを設定します。</block>
  <block id="af2c7dd4ecef5e42e9bc8f88213d51d9" category="list-text">リソース→インベントリ→追加と進み、インベントリの追加をクリックします。</block>
  <block id="56fc26ef1c8ae54dced3529eec65fa26" category="list-text">名前と組織の詳細を入力し、 [ 保存 ] をクリックします。</block>
  <block id="fe0981da08a8d2f4fed2006bafd9fb30" category="list-text">インベントリページで、作成されたインベントリをクリックします。</block>
  <block id="65d119ae335d9e7c9c798b3e6db1b2d0" category="list-text">[ グループ ] サブメニューに移動し、 [ 追加 ] をクリックします。</block>
  <block id="396641e01a7451ca821b5d7d1377b0c7" category="list-text">ONTAP のグループの名前を入力し、グループ変数（ある場合）を貼り付けて、 [ 保存 ] をクリックします。</block>
  <block id="a4f13b6e4100f2d5db093eb54a3ffe0c" category="list-text">Oracle の別のグループに対してこの手順を繰り返します。</block>
  <block id="6f29f21d5f3e40494291fb357b9f4f73" category="list-text">作成した ONTAP グループを選択し、 Hosts サブメニューに移動して、 Add New Host をクリックします。</block>
  <block id="8d92ffd9d0d2b033d05731ec4af50af8" category="list-text">ONTAP クラスタ管理 IP の IP アドレスを入力し、ホスト変数（存在する場合）を貼り付けて、 [ 保存 ] をクリックします。</block>
  <block id="f1254ecbe57ff98d850d541b8a1ab988" category="list-text">このプロセスは、 Oracle グループおよび Oracle ホストの管理 IP / ホスト名に対して繰り返す必要があります。</block>
  <block id="f11c5853bdca384314b28c9c59f2d6d0" category="list-text">クレデンシャルタイプを作成する。ONTAP を使用するソリューションでは、ユーザ名とパスワードのエントリを照合するようにクレデンシャルタイプを設定する必要があります。</block>
  <block id="c87e3da0a9f8d5eeacea4eac9bef80ea" category="list-text">[ 管理 ] → [ 資格情報の種類 ] に移動し、 [ 追加 ] をクリックします。</block>
  <block id="e6bf632438290fdf98265b2b18943118" category="list-text">名前と概要を指定します。</block>
  <block id="5f5a0974b600f86bd4e77595282fcf70" category="list-text">入力構成に次の内容を貼り付けます。</block>
  <block id="1616edbabbc3bbfd22afe144d1929386" category="list-text">次の内容をインジェクター設定に貼り付けます。</block>
  <block id="c4053f20c3fe50fe899484a64367439e" category="list-text">クレデンシャルを設定します。</block>
  <block id="41dcc8a8aaaa79a511ba0ab4e6bde225" category="list-text">[ リソース ] → [ 資格情報 ] に移動し、 [ 追加 ] をクリックします。</block>
  <block id="cc865c923bcb1c61acf9985311675b93" category="list-text">ONTAP の名前と組織の詳細を入力します。</block>
  <block id="ea314f484653e7f9f25144ea61d34888" category="list-text">ONTAP 用に作成したカスタム資格情報タイプを選択します。</block>
  <block id="179cae6336461d9f165e8fa87146362a" category="list-text">[ タイプの詳細 ] で、ユーザー名、パスワード、および vsadmin-readonly を入力します。</block>
  <block id="659fb4c811f1a73cf40492056e6d3c3f" category="list-text">[ 資格情報に戻る ] をクリックし、 [ 追加 ] をクリックします</block>
  <block id="3b9c90c4bf202563a3cdeda5ec78fac2" category="list-text">Oracle の名前と組織の詳細を入力します。</block>
  <block id="9ef3fcc446a5f500717f9b5e9291bce4" category="list-text">マシンクレデンシャルタイプを選択します。</block>
  <block id="9fadc5c4eed350a8a1423628227dad59" category="list-text">Type Details （タイプの詳細）に、 Oracle ホストのユーザー名とパスワードを入力します。</block>
  <block id="b4ca3125325138b1dbfc309e6bd67b80" category="list-text">適切な特権昇格方式を選択し、ユーザ名とパスワードを入力します。</block>
  <block id="51b04d83367483575e89740841d94262" category="section-title">2. プロジェクトを作成します</block>
  <block id="e56fa1e2655db1bc7664a00295bd62a2" category="list-text">[ リソース ] → [ プロジェクト ] に移動し、 [ 追加 ] をクリックします。</block>
  <block id="9c78f8d8687776e79018ded982e14c25" category="list-text">名前と組織の詳細を入力します</block>
  <block id="4096a1870a258e9d46585f08d4906f21" category="list-text">Source Control Credential Type フィールドで Git を選択します。</block>
  <block id="784148c4a03cf22250dddc5756684e39" category="list-text">入力するコマンド <block ref="4509731a8f0f86cf7d8a010739dfd7c5" category="inline-link-rx"></block> をソース管理 URL として指定します。</block>
  <block id="7557bd62e953fb4d48f07977151ea94f" category="list-text">[ 保存 ] をクリックします .</block>
  <block id="99bc2ea435ea8ae0ed38ef3051a4350a" category="list-text">ソースコードが変更されたときに、プロジェクトの同期が必要になることがあります。</block>
  <block id="14e017f358e18dd612a468713206093f" category="section-title">3. Oracle host_vars を設定します</block>
  <block id="05557c38b20e42173356b53f42c92152" category="paragraph">このセクションで定義した変数は、個々の Oracle サーバとデータベースに適用されます。</block>
  <block id="ac886b852fd1b481e9c7e68c217b5e21" category="list-text">次の組み込み Oracle ホスト変数または host_vars フォームに、環境固有のパラメータを入力します。</block>
  <block id="e1847b1a99378b07a0df71cf2baac5da" category="list-text">青のフィールドにすべての変数を入力します。</block>
  <block id="741c92ab2429ff59927918c7a07ad9a5" category="list-text">変数の入力が完了したら、フォームの [ コピー ] ボタンをクリックして、 AWX またはタワーに転送されるすべての変数をコピーします。</block>
  <block id="1e1ea51549ac2a644a3e965113c1d370" category="list-text">AWX またはタワーに戻って、 Resources （リソース）→ Hosts （ホスト）に移動し、 Oracle サーバ設定ページを選択して開きます。</block>
  <block id="0d630b14098a793ac4586173286d0805" category="list-text">[ 詳細 ] タブで、編集をクリックし、コピーした変数を手順 1 から YAML タブの [ 変数 ] フィールドに貼り付けます。</block>
  <block id="c6dca9e669d097298fc6059b27f96e09" category="list-text">システム内の他の Oracle サーバについても、この手順を繰り返します。</block>
  <block id="7890327bd98d1ec932e453254511754d" category="section-title">4. グローバル変数を設定します</block>
  <block id="e5cac740ce6bd43e6ff83881e150d0f3" category="paragraph">このセクションで定義する変数は、すべての Oracle ホスト、データベース、および ONTAP クラスタに適用されます。</block>
  <block id="87b55102ec2889891b0258253b739244" category="list-text">次の組み込みグローバル変数または変数フォームに環境固有のパラメータを入力します。</block>
  <block id="7d2a3c2ad9ee2eeb7547d205d30b9335" category="list-text">すべての変数を青のフィールドに入力します。</block>
  <block id="099f04b51539ed973890f1d1af2d5063" category="list-text">変数の入力が完了したら、フォームの [ コピー ] ボタンをクリックして、 AWX またはタワーに転送されるすべての変数を次のジョブテンプレートにコピーします。</block>
  <block id="c807b1735c1915c52547b9f7e917b55d" category="section-title">5. ジョブテンプレートを設定して起動します。</block>
  <block id="b1171f0b44b8d9b11ac555972ebc8c3b" category="list-text">ジョブテンプレートを作成します。</block>
  <block id="0fd181172a82ebe5219e9a30e5d97c0d" category="list-text">[ リソース ] → [ テンプレート ] → [ 追加 ] に移動し、 [ ジョブテンプレートの追加 ] をクリックします。</block>
  <block id="3dcca032e3328f54206079a87830aa27" category="list-text">ジョブタイプを選択します。 Run は、プレイブックに基づいてシステムを設定します。 Check は、実際にシステムを設定することなく、プレイブックの事前チェックを実行します。</block>
  <block id="daefcb84cec2b58089094a64cefb845f" category="list-text">対応するインベントリ、プロジェクト、プレイブック、およびクレデンシャルを選択します。</block>
  <block id="b01c6189ccdc531874f3442803680525" category="list-text">実行するデフォルトのプレイブックとして、 all_cplaybook.yml を選択します。</block>
  <block id="ce150ce9cfe145db199958e7cd2ecce0" category="list-text">手順 4 からコピーしたグローバル変数を YAML タブの Template Variables フィールドに貼り付けます。</block>
  <block id="e8f0426d97d09775fb78bdeb793b0b3e" category="list-text">[ ジョブタグ ] フィールドの [ 起動時にプロンプトを表示する ] チェックボックスをオンにします。</block>
  <block id="31e2568c13fbdaaad088eb3b665dea9d" category="list-text">ジョブテンプレートを起動します。</block>
  <block id="3624b34cb634949984bcb28c79fd327f" category="list-text">[ リソース ] → [ テンプレート ] に移動します。</block>
  <block id="56ae7378358ba2b1c55c47283f544991" category="list-text">目的のテンプレートをクリックし、 [ 起動 ] をクリックします。</block>
  <block id="ad7ad1bbc416fda1f9518ff4004d891c" category="list-text">ジョブタグの起動時にプロンプトが表示されたら、 requires_config と入力します。requires_config の下にある Create Job Tag 行をクリックして、ジョブタグを入力する必要がある場合があります。</block>
  <block id="b9ef793a3db3f07ed7dc808f4709c6ca" category="admonition">requireation_config により、他のロールを実行するための正しいライブラリが確保されます。</block>
  <block id="6ac039e55dcf8a249f5122b1fdbbf60e" category="list-text">[ 次へ ] をクリックし、 [ 起動 ] をクリックしてジョブを開始します。</block>
  <block id="06f392c8dfb4783859e67f16fed69bc7" category="list-text">ジョブの出力と進行状況を監視するには、表示→ジョブをクリックします。</block>
  <block id="7f6a02c24592bd309f31b5a72a0f8d6d" category="list-text">ジョブタグの起動を求めるプロンプトが表示されたら、「 ONTAP_config 」と入力します。ジョブタグを入力するには、 ONTAP_config の下にある「ジョブタグの作成」行をクリックする必要があります。</block>
  <block id="18c003af9ed29d295877baabf7b42ce1" category="list-text">ジョブ出力およびを監視するには、表示→ジョブをクリックします 進捗状況</block>
  <block id="c0029d5cdcaae1ceef3bed244b3ab3c6" category="list-text">ONTAP_CONFIG ロールの完了後、 linux_config のプロセスを再度実行します。</block>
  <block id="fc71758268fe1c3aba4b75df3ee0560f" category="list-text">目的のテンプレートを選択し、 [ 起動 ] をクリックします。</block>
  <block id="bbe073bafc2875db8b48e59284636931" category="list-text">linux_config でジョブタグタイプの起動時にプロンプトが表示されたら、 linux_config のすぐ下にある「ジョブタグの作成」行を選択して、ジョブタグを入力する必要があります。</block>
  <block id="bc43b7acafead2cdee67de733ae10b13" category="list-text">ジョブの出力と進行状況を監視するには、表示→ジョブを選択します。</block>
  <block id="e73718535637e07111f6a4925685c0bd" category="list-text">linux_config ロールが完了したら、 ORACLE_config のプロセスを再度実行します。</block>
  <block id="574f8726a5cc088da32ab84269c8e0f8" category="list-text">[ リソース ] → [ テンプレート ] に移動します。</block>
  <block id="252b85bc679cb8ecdccbcd127c65b795" category="list-text">ジョブタグの起動時にプロンプトが表示されたら、 ORACLE_config と入力します。ORACLE_config の直下にある「ジョブタグの作成」行を選択して、ジョブタグを入力する必要がある場合があります。</block>
  <block id="6757805f64ddba2566927ece0d9f30e1" category="section-title">6. 同じ Oracle ホストに追加のデータベースを配置します</block>
  <block id="4edc1d4492ab93edbbb0a67c0c265b84" category="paragraph">このプレイブックの Oracle 部分では、 1 回の実行につき Oracle サーバ上に Oracle コンテナデータベースが 1 つ作成されます。同じサーバ上に追加のコンテナデータベースを作成するには、次の手順を実行します。</block>
  <block id="a12a0fa7fe728658376da87df04fa7c2" category="list-text">host_vars 変数を改訂。</block>
  <block id="ba52bf2d165115d60675d61a4b84b0c6" category="list-text">手順 2 - Oracle host_vars の設定に戻ります。</block>
  <block id="d9fa63a6f267402d4cf6068165e04a38" category="list-text">EM Express をインストールする場合は、 EM Express ポートを別の番号に変更します。</block>
  <block id="23f5c9b4f57b3075f9890f1bc1896ebe" category="list-text">改訂されたホスト変数を Host Configuration Detail タブの Oracle Host Variables フィールドにコピーして貼り付けます。</block>
  <block id="4d4426a703dd8227727fef5758b680d8" category="list-text">ORACLE_config タグのみを使用して、導入ジョブテンプレートを起動します。</block>
  <block id="e9dcec3e531a3cec5ee733f23baab91d" category="inline-link-macro">NFS への Oracle 19C for ONTAP の自動導入</block>
  <block id="2aa17d37bd2483f97468ab7653396786" category="paragraph">このセクションでは、ネットアップの自動化ソリューションを使用する環境を準備する AWX/Ansible タワーのパラメータを設定するために必要な手順について説明します。</block>
  <block id="0fb1db9928d7fc107d96c13f1918b639" category="list-text">リソース→インベントリ→追加と進み、インベントリの追加をクリックします。</block>
  <block id="2623b8eb8fcaecc009c3b78cc6e7d391" category="list-text">名前と組織の詳細を入力し、 [ 保存 ] をクリックします。</block>
  <block id="cc243ac3e015aef331656a4bff40241c" category="list-text">インベントリページで、作成したインベントリリソースをクリックします。</block>
  <block id="b0ddb214e9aa4a84bc80e6af8c6b2adf" category="list-text">インベントリ変数がある場合は、その変数を変数フィールドに貼り付けます。</block>
  <block id="5d7863780eab69b6b968cfc9dc6e66bc" category="list-text">[ グループ ] サブメニューに移動し、 [ 追加 ] をクリックします。</block>
  <block id="ec51931bb91bc912d609f2099974dfd9" category="list-text">グループの名前を入力し、必要に応じてグループ変数にコピーして、 [ 保存 ] をクリックします。</block>
  <block id="8f9cbdc13fdcb31ff345f10ba333ac59" category="list-text">作成したグループをクリックし、 Hosts サブメニューに移動して、 Add New Host をクリックします。</block>
  <block id="98e7a99b463b825a87899d25486e46ea" category="list-text">ホストのホスト名と IP アドレスを入力し、必要に応じてホスト変数に貼り付けて、 Save をクリックします。</block>
  <block id="3caf9a56384a30eb8dee819e3abc14d6" category="list-text">クレデンシャルタイプを作成する。ONTAP 、 Element 、 VMware 、またはその他の HTTPS ベースの転送接続を使用するソリューションの場合は、ユーザ名とパスワードのエントリに一致するクレデンシャルタイプを設定する必要があります。</block>
  <block id="615b6214c17105ae4915a8c8a632025b" category="list-text">[ 管理 ] → [ 資格情報の種類 ] に移動して、 [ 追加 ] をクリックし</block>
  <block id="846bb9303e5cc4395e96eba0d4c7d50a" category="list-text">次の内容を入力構成に貼り付けます。</block>
  <block id="333a40c5632e0507a83f6a191f0b69b3" category="list-text">インジェクタの設定に次の内容を貼り付けます。</block>
  <block id="e31908e83a96aee8550446309c4ef7e0" category="list-text">クレデンシャルの設定</block>
  <block id="de06c7b54d4158f81a8c4d4a02b61eb0" category="list-text">リソース→資格情報に移動して、追加をクリックします。</block>
  <block id="e5b5f57b6910910a3f9a486e88088608" category="list-text">正しいクレデンシャルタイプを選択します。標準 SSH ログインを使用する場合は、「 Machine 」タイプを選択するか、作成したカスタムクレデンシャルタイプを選択します。</block>
  <block id="9256ee926473942ba849050ef0450b7f" category="list-text">対応するその他の詳細情報を入力し、 [ 保存 ] をクリックします。</block>
  <block id="29d192f714134f2e257058cfcf763722" category="list-text">プロジェクトを設定します。</block>
  <block id="1b892b7661c6a3ae2b57cbf4233c3af5" category="list-text">リソース→プロジェクトに移動し ' 追加をクリックします</block>
  <block id="936784ca62c93ca666e77fd10733247c" category="list-text">ソース管理資格情報タイプとして Git を選択します。</block>
  <block id="9f4fd9b4a4c75c02d1b469e8dd75d9fb" category="list-text">特定の解決策に対応するソース制御 URL （または git クローン URL ）を貼り付けます。</block>
  <block id="95acbbc0424478165cdbe3a62849cbc3" category="list-text">Git URL がアクセス制御されている場合は、必要に応じて、 Source Control Credential で対応するクレデンシャルを作成して添付します。</block>
  <block id="a934d780fa0cb0e8495a0a1cabd0f501" category="list-text">ジョブテンプレートを設定します。</block>
  <block id="10c610c9225adcc92ca1b284b5bbb04b" category="list-text">名前と概要を入力します</block>
  <block id="e33edf61d02fc69c2087dcc3c42177e1" category="list-text">ジョブタイプを選択します。 Run は、プレイブックに基づいてシステムを設定し、 Check は実際にシステムを設定することなく、プレイブックの事前チェックを実行します。</block>
  <block id="57cf64ce7890d12e5a41d18b83979ffd" category="list-text">このプレイブックに対応するインベントリ、プロジェクト、クレデンシャルを選択します</block>
  <block id="fc6b15b1dd73bb25477aed453b9a02f2" category="list-text">ジョブテンプレートの一部として実行するプレイブックを選択します。</block>
  <block id="9a7d90740af07bcdd2c628a6f6ae966c" category="list-text">通常、変数は実行時に貼り付けられます。そのため、実行時に変数を入力するように求めるプロンプトを表示するには、必ず [ 変数 ] フィールドに対応する [ 起動時にプロンプトを表示 ] チェックボックスをオンにしてください。</block>
  <block id="3454f07e6f81a48099e0d144ca38ec7a" category="list-text">必要に応じてその他の詳細情報を入力し、 [ 保存 ] をクリックします。</block>
  <block id="0b55c84dbc04b54418b0d507f7b8f669" category="list-text">起動時にプロンプトが表示されたら変数を入力し、 [ 再起動 ] をクリックします。</block>
  <block id="54d2cdd3035ca1cdff5803c30f2ed2e1" category="sidebar">Oracle データベースを導入しています</block>
  <block id="699700175d80778f1738d906ee9540d5" category="sidebar">設置と要件</block>
  <block id="210fdbe41d80b2e8690a970de86a7ffb" category="sidebar">Oracle 19C AWX/Tower の自動導入</block>
  <block id="13cf6478a61a7904a3062d587248fb75" category="sidebar">Oracle 19C CLI の自動導入</block>
  <block id="645198fb2e03205a7f761aeaff8ef26f" category="sidebar">NetApp 解決策の自動化と Ansible での作業を開始する方法について説明します</block>
  <block id="4a85fdd5a26454abc330a5ec2a46a326" category="paragraph">21.01 リリースでは、 Trident Operator のインストールを容易にするために Helm チャートを使用できるようになりました。</block>
  <block id="52d012c119e8e080d08f6a1592f8f9ec" category="section-title">Helm を使用して Trident Operator をインストールします</block>
  <block id="449774824d889f1d6ebc0bbcc4920493" category="list-text">Helm コマンドを実行し、ユーザークラスタに trident 名前空間を作成しながら、 Helball ディレクトリ内の tarball から Trident 演算子をインストールします。</block>
  <block id="615767b52353571ac174e22f1a984aa3" category="inline-link-macro">NetApp ONTAP NFS</block>
  <block id="c93e7ef2934826b1393251e9f7d9e331" category="inline-link-macro">NetApp ONTAP iSCSI の略</block>
  <block id="d0e0904111acb167badbf5f196ad1205" category="inline-link-macro">NetApp Element iSCSI の略</block>
  <block id="3605e05aa598ff405b5edffc1bf474f1" category="summary">ネットアップを使用した Red Hat OpenShift でのマルチテナンシーの構成</block>
  <block id="13148717f8faa9037f37d28971dfc219" category="doc">検証</block>
  <block id="12cdc5f68c3a0ca10544c0a57e866249" category="list-text">project-1 に割り当てられたストレージクラスを使用して 'project-1 に PVC を作成します</block>
  <block id="a345b6be662b316a3b3e3cfbc7566b31" category="list-text">project-1 にポッドを作成し、前の手順で作成した PVC をマウントします。</block>
  <block id="8e27501b578972bd7b65468deaa482ca" category="list-text">project-2 に割り当てられたストレージクラスを使用して 'project-1 に PVC を作成します</block>
  <block id="71bc5a6f1f0141981e0034b388233917" category="list-text">PROJECT -2 で PVC を作成します。</block>
  <block id="0d843e91c3b8f62457e19b2d32ecace3" category="list-text">プロジェクト 2 でポッドを作成します。</block>
  <block id="5d77fe4a6bb4c5e88c5c18510b3c4749" category="doc">NetApp Element ：ネットアップを使用した Red Hat OpenShift</block>
  <block id="8921c6e9843ba7487c77f4dce1467111" category="paragraph">NetApp Element ソフトウェアは、拡張性に優れたモジュラ型のパフォーマンスを提供し、ストレージノードごとに容量とスループットを保証します。NetApp Element システムは、 1 つのクラスタで 4~100 ノードまで拡張でき、高度なストレージ管理機能も多数備えています。</block>
  <block id="27765508a97a89684590658c3465fb70" category="inline-link">ネットアップの SolidFire Web サイト</block>
  <block id="d37eaafbb6dfb29673d63ff988ff4f41" category="paragraph">NetApp Element ストレージ・システムの詳細については、を参照してください<block ref="0d1d77e6774527457304fa15f73899a1" category="inline-link-rx"></block>。</block>
  <block id="dbafa7c074ef7efc3c778b69c0ad31b5" category="paragraph">NetApp Element ソフトウェアは、 iSCSI ストレージプロトコルを利用します。これは、従来の TCP/IP ネットワーク上で SCSI コマンドをカプセル化する標準的な方法です。SCSI 標準が変更された場合や、イーサネットネットワークのパフォーマンスが向上した場合、 iSCSI ストレージプロトコルには変更は必要ありません。</block>
  <block id="23e6b910b28346537f5696478fffe779" category="paragraph">すべてのストレージノードには管理 IP とストレージ IP が設定されますが、 NetApp Element ソフトウェアは、クラスタ内のすべてのストレージトラフィックについて、ストレージ仮想 IP アドレス（ SVIP アドレス）を 1 つアドバタイズします。iSCSI のログインプロセスでは、ストレージはターゲットボリュームが別のアドレスに移動されたことを応答するため、ネゴシエーションプロセスを続行できません。その後、ホスト側の再設定を必要としないプロセスで、ホストはログイン要求を新しいアドレスに再発行します。このプロセスは、 iSCSI ログインリダイレクトと呼ばれます。</block>
  <block id="f8cd3dfe225577e230dc2699ebbbfe34" category="list-text">* 最大 IOPS 。 * NetApp Element ソフトウェアクラスタが特定のボリュームに提供する平常時の最大 IOPS 。</block>
  <block id="5fec85270e969240cc769f429b9c8cdc" category="list-text">* VRF 対応 VLAN 。 * データセンターのセキュリティと拡張性をさらにサポートするため、 NetApp Element ソフトウェアを使用すると、 VRF に似た機能を持つテナント VLAN を有効にできます。この機能には、次の 2 つの主要機能が追加されて</block>
  <block id="eaea554ececf5b64515f0833c56b3de4" category="list-text">* IP サブネットの重複または重複 * 。この機能を使用すると、テナント環境にテンプレートを追加し、各テナント VLAN に同じ IP サブネットから IP アドレスを割り当てることができます。この機能は、 IPspace の拡張と保持が重要なサービスプロバイダ環境に役立ちます。</block>
  <block id="6893566c26b28e197cebdefdcc6af3ae" category="list-text">* 重複排除。 * システムには、一意の 4K ブロックのみが保存されます。重複する 4K ブロックは格納済みのデータバージョンに自動的に関連付けられます。データはブロックドライブに格納され、 NetApp Element ソフトウェアの Helix データ保護を使用してミラーリングされます。このシステムは、システム内の容量消費と書き込み処理数を大幅に削減します。</block>
  <block id="215de8162cb5ac909005881f92812fb0" category="list-text">* シンプロビジョニング。 * この機能は、必要なときに必要な量のストレージを提供し、オーバープロビジョニングされたボリュームや利用率の低いボリュームによる容量消費を排除します。</block>
  <block id="da9c9b2b4164632e569069fe1e7c53ee" category="admonition">Element は自動化を目的として設計されました。ストレージ機能はすべて API を使用して利用できます。これらの API は、システムの制御に UI で使用される唯一のメソッドです。</block>
  <block id="ec22e01e7cd5087ef746b3db5852da6e" category="doc">拡張：プロジェクトの追加</block>
  <block id="5790e2b8b367726e78500054d959d6f7" category="image-alt">拡張用の SVM を作成</block>
  <block id="c9e86337c7483c8d45e5e535829d2163" category="list-text">新しいプロジェクトを作成します。</block>
  <block id="8efa8222e644f71e636f98917439566d" category="list-text">プロジェクト 3 の開発者用に RoleBinding を作成します。これは、 developer-project-3 の役割を、 project-3 の対応するグループ (OCP-project-3) にバインドします。</block>
  <block id="e1f01c3341da15c9079bf5996c059811" category="list-text">Red Hat OpenShift クラスタにストレージ管理者としてログインします</block>
  <block id="55da75937cfedfe97c220c1e9d556d84" category="list-text">project-3 用のストレージクラスを作成し、 project-3 専用のバックエンドのストレージプールを使用するように設定します。</block>
  <block id="6efdcf6ed405066371d23375541816a1" category="list-text">ResourceQuota を作成して ' プロジェクト 3 のリソースを制限しますストレージを要求するストレージは ' 他のプロジェクト専用のストレージになります</block>
  <block id="68d13ef3d87e892878a6e6cbb44d1f21" category="doc">RHV への Red Hat OpenShift 導入：ネットアップを使用した Red Hat OpenShift</block>
  <block id="8fe3ce682e72fe87e56e5b11e1c2cd36" category="inline-link-macro">次のレポート：追加情報：ネットアップでの Red Hat OpenShift</block>
  <block id="5dbd13d011610e2b4d57bd4ca3fd685f" category="paragraph"><block ref="5dbd13d011610e2b4d57bd4ca3fd685f" category="inline-link-macro-rx"></block></block>
  <block id="122aacda8785e42ca8fd7bd6ebce84f8" category="paragraph">VMware vSphere は、 ESXi ハイパーバイザー上で実行される多数の仮想サーバとネットワークを一元管理するための仮想化プラットフォームです。</block>
  <block id="68bc8529d7c57946fe13e6b3399ee287" category="inline-link">VMware vSphere の Web サイト</block>
  <block id="80888e73d00a224bebfc22e8e4539b6d" category="paragraph">VMware vSphere の詳細については、を参照してください<block ref="8e822bbeb5824c0a05189bf9ff98da5c" category="inline-link-rx"></block>。</block>
  <block id="cb4d59b9004b7c584811a3d656f78bc5" category="section-title">VMware vSphere には次の機能があります。</block>
  <block id="cfb123c76f1c7a506310e1162d7ae235" category="paragraph"><block ref="cfb123c76f1c7a506310e1162d7ae235" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e75b582a8823d532f6022b43ac209538" category="paragraph">VMware vSphere 上の Red Hat OpenShift は、仮想ローカルエリアネットワーク（ VLAN ）を使用して、ネットワークトラフィックを論理的に分離するように設計されています。この構成は、お客様のニーズに合わせて拡張することも、特定のネットワークサービスをさらに分離することもできます。次の表に、ネットアップで解決策を検証する際に解決策を実装するために必要な VLAN を示します。</block>
  <block id="3c8c5d8387f173924ffeb2bf88084dba" category="cell">物理ノードと IPMI の管理</block>
  <block id="c61d980d5248923d65a5dfe7f8818011" category="cell">VM ネットワーク</block>
  <block id="fc221309746013ac554571fbd180e1c8" category="cell">181</block>
  <block id="c846a1f843522d592b784a66368abed3" category="cell">ONTAP NFS 用のストレージネットワーク</block>
  <block id="6cdd60ea0045eb7a6ec44c54d29ed402" category="cell">184</block>
  <block id="5e6094f6f2176409f469ee445fcf3f50" category="cell">ONTAP iSCSI 用のストレージネットワーク</block>
  <block id="eecca5b6365d9607ee5a9d336962c534" category="cell">185</block>
  <block id="45cf0331a91fdc3679a78fdd8f7c60a7" category="cell">ESXi ノード、 vCenter Server 、 ONTAP Select の管理</block>
  <block id="11967d5f57969ea4713204eace8fbf4e" category="cell">NetApp Element iSCSI 用のストレージネットワーク</block>
  <block id="0bad9231e1bf61bc343a986739f155c1" category="paragraph">OpenShift Container Platform を導入する前に、次のインフラを用意する必要があります。</block>
  <block id="9934283c0bf98610b4be1803b9ad3430" category="inline-link">vSphere 6.7 ドキュメント：「 DRS アフィニティルールの使用</block>
  <block id="291f24f63dc31f9f921b09c567fc963f" category="paragraph">アフィニティグループを設定するには、を参照してください<block ref="4b14049244eae7b3d11ef8e44785dd4e" category="inline-link-rx"></block>。</block>
  <block id="7b65abec68958867d7dd5f43b3b06e08" category="inline-link">Red Hat OpenShift カスタマイズを使用して vSphere にクラスタをインストールします</block>
  <block id="a0e01d06503f271c1de7acc0acd01733" category="doc">NVA-1160 ：ネットアップでの Red Hat OpenShift</block>
  <block id="44815e873492015d6a8ab6362de8da6c" category="list-text">ベアメタル、 Red Hat OpenStack Platform 、 Red Hat Virtualization 、 VMware vSphere に IPI （インストーラでプロビジョニングされたインフラ）を使用して導入した Red Hat OpenShift の導入と管理が容易です。</block>
  <block id="03bb323d052d033ea0b5b2cab17f1219" category="list-text">OSP 、 RHV 、 vSphere 、または OpenShift Virtualization を使用したベアメタルに導入された Red Hat OpenShift を使用して、エンタープライズコンテナと仮想化ワークロードのパワーを組み合わせたもの。</block>
  <block id="2748d7182409b378e23f62724be778fd" category="list-text">ノンストップオペレーションとアップグレード</block>
  <block id="42c487483a8feee3cc0365881a4cc265" category="paragraph">ネットアップとともに Red Hat OpenShift を導入することで、これらの課題に対応し、お客様が選択したデータセンター環境に RedHat OpenShift IPI を完全に自動で導入できるようになり、それぞれの問題に対処できる解決策が提供されます。</block>
  <block id="70240bc0debcb080aa08dbd9e7b9a525" category="paragraph">詳細については、 OpenShift の Web サイトを参照してください<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>。</block>
  <block id="aa4193984de53d2a6d8fcc2d77c09bda" category="paragraph">詳細については、ネットアップの Web サイトをご覧ください<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>。</block>
  <block id="e7e767d7c0e58b16e57d3ab16150db80" category="cell">テクノロジ</block>
  <block id="601712ded7a71b0842984ad41b6aad39" category="cell">12.3</block>
  <block id="765bb3744268ca0de607208bfdc8a37a" category="cell">ストレージオーケストレーション</block>
  <block id="2454407b9991c6c5f417a2feb8ea7970" category="cell">4.6 EUS 、 4.7</block>
  <block id="9c4e78a1b7e7b4981aced1e10d037c6d" category="cell">Red Hat OpenStack Platform</block>
  <block id="de45aa336111dfa1825c54726464307c" category="cell">プライベートクラウドインフラ</block>
  <block id="3c5825a0d4bdb85c67182ef89bc9c7eb" category="cell">16.1</block>
  <block id="f9a97ed4e88eeab44f2693afa0eb2089" category="cell">4 月 4 日</block>
  <block id="e690fa655ec589e6d0abb58164d5ccfd" category="doc">追加情報：ネットアップを使用した Red Hat OpenShift</block>
  <block id="6f4e4d9fbe846fd8bf7decf7dcffbd63" category="list-text">NetApp のドキュメント</block>
  <block id="1497398039e94eb756be9a3cff5649c7" category="inline-link"><block ref="1497398039e94eb756be9a3cff5649c7" category="inline-link-rx"></block></block>
  <block id="f2d3084aa0f70da5e15757ee3292cda7" category="paragraph"><block ref="f2d3084aa0f70da5e15757ee3292cda7" category="inline-link-rx"></block></block>
  <block id="21b11dbf6ab3c6d36a76f280fe8ec75d" category="list-text">Red Hat OpenShift のドキュメント</block>
  <block id="74201863479cf5c9b89330c920283301" category="inline-link"><block ref="74201863479cf5c9b89330c920283301" category="inline-link-rx"></block></block>
  <block id="3e10ed3875c45f9dc9064324660fc2b1" category="paragraph"><block ref="3e10ed3875c45f9dc9064324660fc2b1" category="inline-link-rx"></block></block>
  <block id="06fd33ae9f869a89e860634ec94b9793" category="list-text">Red Hat OpenStack Platform のドキュメント</block>
  <block id="647d438a62673b6a6c9830682f6bc128" category="inline-link"><block ref="647d438a62673b6a6c9830682f6bc128" category="inline-link-rx"></block></block>
  <block id="705a39bc1a12c50103a847633c3f7493" category="paragraph"><block ref="705a39bc1a12c50103a847633c3f7493" category="inline-link-rx"></block></block>
  <block id="8d79e9650a1f62f89d77743225e203c0" category="list-text">Red Hat Virtualization のドキュメント</block>
  <block id="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link"><block ref="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link-rx"></block></block>
  <block id="6d6038842b529e3d97aa9a8a9d81d866" category="paragraph"><block ref="6d6038842b529e3d97aa9a8a9d81d866" category="inline-link-rx"></block></block>
  <block id="4666fc2f640685636f115f8b2b6b8ce0" category="list-text">VMware vSphere のドキュメント</block>
  <block id="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link"><block ref="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link-rx"></block></block>
  <block id="71aa41fc980571d5a324adedae614f9c" category="paragraph"><block ref="71aa41fc980571d5a324adedae614f9c" category="inline-link-rx"></block></block>
  <block id="737c38dd225185612ac8fa148ae9583e" category="inline-link">Red Hat OpenStack Platform の Web サイト</block>
  <block id="19fb2090425be8f78441166e8f1d8d6f" category="paragraph">OSP の詳細については、を参照してください<block ref="9c79780f89511512bd5bf54ce21d04de" category="inline-link-rx"></block>。</block>
  <block id="f5fdcf6d68d437c59942a35d79b8c7b1" category="paragraph"><block ref="f5fdcf6d68d437c59942a35d79b8c7b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2ba7e785c49050f48da9aacc45c2b85" category="cell">サービス</block>
  <block id="2938c7f7e560ed972f8a4f68e80ff834" category="cell">ダッシュボード</block>
  <block id="85fb7708d989f936cb51ef53a8af080f" category="cell">地平線</block>
  <block id="d5a9efab6df20a9e132b774795775dde" category="cell">OpenStack サービスの管理に使用する Web ブラウザベースのダッシュボード。</block>
  <block id="c9c5c65fb4af9cf90eb99b3b84424189" category="cell">ID</block>
  <block id="1ce2096c300f78bbb8389ca2603e6dd9" category="cell">Keystone</block>
  <block id="91c68681aadba9c0e8308f7d0b3cc416" category="cell">OpenStack サービスの認証と許可、およびユーザ、プロジェクト、ロールの管理を一元化するサービスです。</block>
  <block id="88fac409baf592beb25e285d8663edcb" category="cell">中性子</block>
  <block id="0283e46fd80198d441eb742b88cf96f1" category="cell">OpenStack サービスのインターフェイス間の接続を提供します。</block>
  <block id="a7173cc5cdd0e31df00cd34f058b1d33" category="cell">Cinder の場合</block>
  <block id="597dab3a2b3c74e3c266b2f65ec28619" category="cell">仮想マシン（ VM ）の永続的なブロックストレージボリュームを管理します。</block>
  <block id="6e747c4965495f2e26bf17e647aa0083" category="cell">ノバ</block>
  <block id="f13c04e9c49274cd31bd8092c8f50304" category="cell">コンピューティングノードで実行されている VM を管理およびプロビジョニングします。</block>
  <block id="10ec3a0506fab7073649337ca7be7979" category="cell">Glance</block>
  <block id="d9ff71ddcb6bbbe8ad48ae8b678369d4" category="cell">VM イメージやボリューム Snapshot などのリソースを格納するためのレジストリサービス。</block>
  <block id="ae832e9b5bda2699db45f3fa6aa8c556" category="cell">Swift</block>
  <block id="41c380458dfcdc118ef573a2d98c6acb" category="cell">ユーザにファイルおよび任意のデータの格納および取得を許可します。</block>
  <block id="aa96a21412def0d916f43b639424f8e4" category="cell">テレメータ</block>
  <block id="8fb4b5e28f192236eaa9e4972f810dbd" category="cell">Ceilometer</block>
  <block id="ed622b9c64858cc66a01c58893b5d39d" category="cell">クラウドリソースの使用状況を測定できます。</block>
  <block id="7d486371bb65b0633535ceba4189d8ed" category="cell">熱</block>
  <block id="abaa6ebae60b74638c54a43f3341db8e" category="cell">リソーススタックの自動作成をサポートする、テンプレートベースのオーケストレーションエンジン。</block>
  <block id="5ddbd3cec63b14995bf6a5823b692de7" category="paragraph">NetApp 解決策を使用した Red Hat OpenShift では、 2 つのデータスイッチを使用して 25Gbps でプライマリデータ接続を提供します。また、ストレージノードのインバンド管理用に 1Gbps で接続を提供する管理スイッチをさらに 2 台使用し、 IPMI 機能のアウトオブバンド管理も行います。</block>
  <block id="c546b983b02d8654c5b245147d99dcf0" category="paragraph">ネットアップとともに Red Hat OpenShift を実装することで、仮想ローカルエリアネットワーク（ VLAN ）を使用してネットワークトラフィックを論理的に分離するように設計されています。この構成は、お客様のニーズに合わせて拡張することも、特定のネットワークサービスをさらに分離することもできます。次の表に、ネットアップで解決策を検証する際に解決策を実装するために必要な VLAN を示します。</block>
  <block id="414b4843c124e72b43bccf2948a53a41" category="cell">物理ノードの管理に使用するネットワークと、皮肉なことに IPMI サービス。</block>
  <block id="e8cbca2d71bd2aeff622a07b4ffad6c2" category="cell">Swift などのインフラサービスをサポートするためにボリュームを直接マッピングするためのコントローラノードのネットワーク。</block>
  <block id="757b505cfd34c64c85ca5b5690ee5293" category="cell">201</block>
  <block id="e103375dfc18f23e4fc072903e894fe9" category="cell">ストレージ Cinder</block>
  <block id="0bdfa6389eb47674a02f6049f342785d" category="cell">環境に導入された仮想インスタンスにブロックボリュームを直接マッピングして接続するためのネットワーク。</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202.</block>
  <block id="772d9a23b79ccb504fa0590644934c3b" category="cell">内部 API</block>
  <block id="e44f5f63400b0975b884dc2980ee3a61" category="cell">API 通信、 RPC メッセージ、データベース通信を使用する OpenStack サービス間の通信に使用するネットワーク。</block>
  <block id="34ed066df378efacc9b924ec161e7639" category="cell">301</block>
  <block id="6252d0571760e3d285e2e41a2b1e7743" category="cell">テナント</block>
  <block id="577bcc914f9e55d5e4e4f82f9f00e7d4" category="cell">302</block>
  <block id="cdc529b5e11a981e4597195c5f1c53b5" category="cell">OpenStack Object Storage （ Swift ）は、このネットワークを使用して、対象のレプリカノード間でデータオブジェクトを同期します。プロキシサービスは、ユーザ要求と基盤となるストレージレイヤの中間インターフェイスとして機能します。プロキシは受信要求を受信し、要求されたデータを取得するために必要なレプリカを検索します。</block>
  <block id="11b9842e0a271ff252c1903e7132cd68" category="cell">303</block>
  <block id="5214f1e2490f3878e307fd6f81f9f77f" category="cell">PXE</block>
  <block id="16d856c79e739181f35adfe5b791c650" category="cell">OpenStack Director は、 OSP Overcloud のインストールをオーケストレーションするための、皮肉なベアメタルプロビジョニングサービスの一部として PXE ブートを提供します。</block>
  <block id="966b6dfb6b0819cc10644bea3115cf20" category="cell">3484</block>
  <block id="b206a1b4ea1097761f78e8876f6da779" category="cell">外部</block>
  <block id="dfeb9598fbfb97cc6bbcc0aff2c785d6" category="cell">3485</block>
  <block id="32223320445c4cf46444e40ebde18b7e" category="cell">SSH アクセス、 DNS トラフィック、ネットワークタイムプロトコル（ NTP ）トラフィックなど、システム管理機能へのアクセスを提供します。このネットワークは、コントローラ以外のノードのゲートウェイとしても機能します。</block>
  <block id="ab4f2b5fd96ca65349119909c1eada2d" category="cell">3486</block>
  <block id="f2260a90424f1d412334d1b3467abd22" category="list-text">ホスト名の完全な解決を可能にする DNS サーバが少なくとも 1 つ必要です。</block>
  <block id="d70672769aa84f2a999291a645e67355" category="list-text">解決策内のサーバの時刻を同期できる NTP サーバが 3 台以上ある。</block>
  <block id="478a3526bd6097c6b7a330fd6aae410e" category="list-text">（オプション） OpenShift 環境でのアウトバウンドのインターネット接続。</block>
  <block id="9c0af999b760fac2aa82d9d105fa7a7e" category="paragraph">サーバグループには、配置を管理できる最大 10 個の仮想インスタンスがデフォルトで存在します。Nova のデフォルトクォータを更新することで変更できます。</block>
  <block id="8aea038e418642b1735131358c24a866" category="inline-link">OpenStack インスタンス用にアフィニティおよび非アフィニティを設定するにはどうすればよいですか？</block>
  <block id="47a822101acb11c74a4877a3d0b77093" category="inline-link">Red Hat OpenShift カスタマイズを使用した OpenStack へのクラスタのインストール</block>
  <block id="e38be1dc20a2b358b917b60fe2677b39" category="doc">NetApp Element iSCSI 構成</block>
  <block id="27ef1192cd037c8978195be045fa054e" category="list-text">エンドポイント行のユーザ、パスワード、および MVIP 値を編集します。</block>
  <block id="d1b7418d19df7144a98dfde725db068c" category="list-text">「仮想 IP 」の値を編集します。</block>
  <block id="3ae96676432caea17595a22525bd9660" category="admonition">このファイルに定義されているオプションのフィールド「 fsType 」があります。iSCSI バックエンドでは、この値を特定の Linux ファイルシステムタイプ（ XFS 、 ext4 など）に設定することも、 OpenShift が使用するファイルシステムを決定できるようにするために削除することもできます。</block>
  <block id="7183f006fd74d941c838f003380f3f46" category="list-text">oc` コマンドを実行して ' ストレージ・クラスを作成します</block>
  <block id="71cb54ab06aa16af27a0ec2157972648" category="list-text">ストレージクラスを作成したら、最初の永続的ボリューム要求（ PVC ）を作成する必要があります。sample_inputs にもあるこのアクションを実行するために使用できるサンプルの 'pvc-basicy.yaml ファイルがあります</block>
  <block id="afc499f2f95809cedce5c8922067065f" category="list-text">このファイルに対して行う必要がある唯一の編集は '`torageClassName` フィールドが作成したものと一致することを確認することですプロビジョニングするワークロードによって必要に応じて、 PVC 定義をさらにカスタマイズできます。</block>
  <block id="02eb9c3824b0b8eae9723daa7a2912d1" category="list-text">「 OC 」コマンドを発行して、 PVC を作成します。作成中の元のボリュームのサイズによっては作成にしばらく時間がかかることがあるため、作成が完了した時点でこのプロセスを監視できます。</block>
  <block id="9d312703c40c2d87b835076063682d59" category="paragraph">NetApp ONTAP は、わかりやすい GUI 、自動化統合機能を備えた REST API 、 AI に基づく予測分析と修正措置、無停止のハードウェアアップグレード、ストレージ間インポートなどの機能を備えた強力なストレージソフトウェアツールです。</block>
  <block id="48235fec2427a785c4a09d7150fc11fc" category="inline-link">ネットアップの ONTAP Web サイト</block>
  <block id="e65027864c84a42fc0799d878ffa0005" category="paragraph">NetApp ONTAP ストレージシステムの詳細については、を参照してください<block ref="be9464a7a83e639a645a801fff2791d9" category="inline-link-rx"></block>。</block>
  <block id="81bf516f5b38ea41d503a2670a9dc144" category="paragraph"><block ref="81bf516f5b38ea41d503a2670a9dc144" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a69e0f8303b40f9f4d56038d3d260c9" category="section-title">NetApp AFF/FAS</block>
  <block id="d4c312c600a949fb72436c2d10568a90" category="paragraph">どちらのシステムも、 NetApp ONTAP データ管理ソフトウェアを搭載しています。 NetApp は、可用性が高く、クラウドと統合されたシンプルなストレージ管理を実現する業界最先端のデータ管理ソフトウェアで、データファブリックのニーズに応じたエンタープライズクラスのスピード、効率性、セキュリティを提供します。</block>
  <block id="992c24be8f66e4259b38ce763c115251" category="paragraph">NetApp AFF / FAS プラットフォームの詳細については、をクリックしてください<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>。</block>
  <block id="b008e805d13d953ddb5cbb220d8ef9b6" category="paragraph">ONTAP Select は、お客様の環境のハイパーバイザーに導入できる、ソフトウェアで定義された NetApp ONTAP の導入です。VMware vSphere または KVM にインストールでき、ハードウェアベースの ONTAP システムの全機能とエクスペリエンスを提供します。</block>
  <block id="3f0bbee5abf3eed060d4147cb0d060b9" category="paragraph">ONTAP Select の詳細については、をクリックしてください<block ref="7c1424ed7be035c303f12b0763e38ece" category="inline-link-rx"></block>。</block>
  <block id="f0f4b6de2040d7dc57e7f4f6baee7ec3" category="paragraph">NetApp Cloud Volumes ONTAP は、クラウドで導入される NetApp ONTAP のバージョンで、 Amazon AWS 、 Microsoft Azure 、 Google Cloud などのさまざまなパブリッククラウドに導入できます。</block>
  <block id="c7fa0d52c3955385f084d0e67c59f963" category="paragraph">Cloud Volumes ONTAP の詳細については、をクリックしてください<block ref="75c9b0075008bbe40ac851ad7f6dda6a" category="inline-link-rx"></block>。</block>
  <block id="b2b7104a419a54dcb2763bddc6a0a47c" category="section-title">Red Hat OpenShift には次の機能があります。</block>
  <block id="ec55e5ffb2376dada4b2eb066c1fd9fd" category="section-title">Red Hat OpenShift の IPI インストール</block>
  <block id="a91a379e59fea6610134af1efa3dfe87" category="paragraph">OpenShift の Installer Provisioned Infrastructure （ IPI ）導入には、次の高度な手順が含まれます。</block>
  <block id="d1befa03c79ca0b84ecc488dea96bc68" category="inline-link">Web サイト</block>
  <block id="a07879007b1202a533ff3ef18bc0d197" category="list-text">Red Hat OpenShift をご覧ください<block ref="36af4d1b80928d398e137421c95a1013" category="inline-link-rx"></block> SSO クレデンシャルでログインします。</block>
  <block id="c9a2aa5906b4dad4a982c3a9c51d31f3" category="list-text">に従ってください<block ref="04512308a1627dc41acfeed51ef16ba3" category="inline-link-rx"></block> Red Hat が提供する、お客様の環境への導入サービスです。</block>
  <block id="aa9095c5ba77e3549672e5c4fae1fedc" category="inline-link-macro">ベアメタルで実装された OpenShift</block>
  <block id="fecab6277bc7322982f127ce83dee308" category="list-text"><block ref="fecab6277bc7322982f127ce83dee308" category="inline-link-macro-rx"></block></block>
  <block id="5f6a8f3661e7319797d4eab6792350e6" category="inline-link-macro">Red Hat OpenStack Platform 上の OpenShift</block>
  <block id="ff3de63c4917b45d20525986d5b29962" category="list-text"><block ref="ff3de63c4917b45d20525986d5b29962" category="inline-link-macro-rx"></block></block>
  <block id="f88eb30a75027b557910958c7306cb4e" category="inline-link-macro">Red Hat 仮想化を基盤とした OpenShift</block>
  <block id="92fb5c16a9f212d49c0c5fb48ebc9144" category="list-text"><block ref="92fb5c16a9f212d49c0c5fb48ebc9144" category="inline-link-macro-rx"></block></block>
  <block id="2772c11e552b243e60a34490c4174ff9" category="inline-link-macro">VMware vSphere 上の OpenShift</block>
  <block id="83fc4dbe543f82a9e50bc1bd4c74fb70" category="list-text"><block ref="83fc4dbe543f82a9e50bc1bd4c74fb70" category="inline-link-macro-rx"></block></block>
  <block id="3a374bfcdd912b5071f863e2b9f0eefa" category="list-text"><block ref="3a374bfcdd912b5071f863e2b9f0eefa" category="inline-link-macro-rx"></block></block>
  <block id="70b44fe3d3567f3f2a5ccd67ff8ac852" category="list-text"><block ref="70b44fe3d3567f3f2a5ccd67ff8ac852" category="inline-link-macro-rx"></block></block>
  <block id="eeaa3ef2816f113fd1978b036eefc4a4" category="doc">解決策の検証とユースケース：ネットアップを使用した Red Hat OpenShift</block>
  <block id="9e766e668731b912ea84be747f0d6b4b" category="paragraph">このページに記載する例は、ネットアップでの Red Hat OpenShift の解決策の検証と使用事例です。</block>
  <block id="6f60a8e202d6d4f297230695ffa9c1a6" category="inline-link-macro">永続的ストレージを使用した Jenkins CI/CD パイプラインの導入</block>
  <block id="20b131c747c2ab8c4c617107b04dfe76" category="list-text"><block ref="20b131c747c2ab8c4c617107b04dfe76" category="inline-link-macro-rx"></block></block>
  <block id="b830a759b7bbee23da50f11979fb8f27" category="doc">永続的ストレージを使用した Jenkins CI / CD パイプラインの導入：ネットアップでの Red Hat OpenShift</block>
  <block id="4d4480c77d84881f85763c51fb0a0ebb" category="doc">ビデオとデモ：ネットアップを使用した Red Hat OpenShift</block>
  <block id="051525dd6e814133d477a1812a4164c2" category="inline-link-macro">ビデオ： NetApp HCI for Red Hat OpenShift on Red Hat Virtualization Deployment</block>
  <block id="817cc3ec794caf508075034f1fa54315" category="list-text"><block ref="817cc3ec794caf508075034f1fa54315" category="inline-link-macro-rx"></block></block>
  <block id="92637d8d513510f7c1f5bfac6e1cce9b" category="paragraph">Trident を NetApp ONTAP ストレージシステムと統合するには、ストレージシステムとの通信を可能にするバックエンドを作成する必要があります。</block>
  <block id="3ca99f0e09d3b1ea097a113dd72c9317" category="list-text">ダウンロードしたインストールアーカイブのサンプルバックエンドファイルは、「 sample -input 」フォルダ階層にあります。iSCSI を提供している NetApp ONTAP システムの場合は、「 backend-ontap -san.json 」ファイルを作業ディレクトリにコピーし、ファイルを編集します。</block>
  <block id="fa346018b8222fdc195d0b73016cf5a0" category="list-text">このファイルで管理 LIF 、データ LIF 、 SVM 、ユーザ名、パスワードの値を編集します。</block>
  <block id="38ace6c607c7db13cd4cc319f9b0225b" category="list-text">このバックエンドファイルを設定した状態で、次のコマンドを実行して最初のバックエンドを作成します。</block>
  <block id="89441fb0b16307f49090afa2b479b9fa" category="list-text">ダウンロードしたインストールアーカイブのサンプルバックエンドファイルは、「 sample -input 」フォルダ階層にあります。NFS を提供している NetApp ONTAP システムの場合は、「 backend-ontap/nas.json 」ファイルを作業ディレクトリにコピーし、ファイルを編集します。</block>
  <block id="87f6ff6bf74013e1dfe6df49a1cf1986" category="list-text">backendName 、 managementLIF 、 dataLIF 、 SVM 、ユーザ名を編集します。 パスワードの値を入力します。</block>
  <block id="00d6947fd6a153943286b857dcd0f339" category="admonition">このファイルに定義されているオプションのフィールド「 fsType 」があります。この行は NFS バックエンドで削除できます。</block>
  <block id="254f642527b45bc260048e30704edb39" category="doc">設定</block>
  <block id="064dceba374668ef0734be5f9e182682" category="cell">* Cluster-admin*</block>
  <block id="e033ab3bea3b8a20afb5852070df0203" category="cell">Storage Admin 用の ClusterRoles および RoleBindings を作成します</block>
  <block id="293d08622718634a8518b6fcc6376617" category="cell">ロールとロールの作成特定のアクセス権を割り当てる開発者のためのバインド プロジェクト</block>
  <block id="3e97e469255cd3686174c371f50961f9" category="cell">[ オプション ] 特定のノードでポッドをスケジュールするようにプロジェクトを設定します</block>
  <block id="93ffd2b1215bc47cc78b020f89e922ef" category="cell">* ストレージ管理者 *</block>
  <block id="043ab42cdcbdacc4691c26ee52ed8ccd" category="cell">NetApp ONTAP に SVM を作成する</block>
  <block id="be09a24f118a66330a40633e9d5ebfca" category="cell">Trident バックエンドを作成</block>
  <block id="55995e8c220e05b3e75252cccf5752be" category="cell">ストレージクラスを作成します</block>
  <block id="4e00898ecc4e6640083ccff8d85fbe87" category="cell">* 開発者 *</block>
  <block id="67a3852a946bc539243cc1e5f8982d03" category="section-title">ベアメタル上の OpenShift には次の機能があります。</block>
  <block id="096e71732ebcd1f43544a7159596cb17" category="paragraph"><block ref="096e71732ebcd1f43544a7159596cb17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb18861dc375756df1a31b7ed3c03f38" category="paragraph"><block ref="bb18861dc375756df1a31b7ed3c03f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5a0639a1bbc3695e0ebaf4c3affe363" category="paragraph">ネットアップ解決策を使用した Red Hat OpenShift は、仮想ローカルエリアネットワーク（ VLAN ）を使用して、ネットワークトラフィックを論理的に分離するように設計されています。</block>
  <block id="3d9073c9e531118eb3aff0f20647c86f" category="cell">ベアメタルノードと IPMI の管理</block>
  <block id="44a94f76baabd05ab407f76c946326c8" category="cell">クラスタが使用可能になると、 OpenShift サービス用のネットワーク</block>
  <block id="846325c36d78e7582d8bfcab277ca67a" category="cell">Network for PXE boot and installation of bare metal nodes （ベアメタルノードの PXE ブートおよびインストール用ネットワーク IPI を使用</block>
  <block id="2d7e48e226974692ed3f522a2baef6db" category="paragraph">RHV 上の Red Hat OpenShift は、仮想ローカルエリアネットワーク（ VLAN ）を使用して、さまざまな目的でネットワークトラフィックを論理的に分離するように設計されています。この構成は、お客様のニーズに合わせて拡張することも、特定のネットワークサービスをさらに分離することもできます。次の表に、ネットアップで解決策を検証する際に解決策を実装するために必要な VLAN を示します。</block>
  <block id="3083202a936b7d0ef8b680d7ae73fa1a" category="cell">344</block>
  <block id="de4e964e7be880b328384cfedd5873d9" category="paragraph">このドキュメントで説明する検証済みのアーキテクチャは、 2 つの RHV-H ハイパーバイザーノードを導入し、ホスト型エンジンと導入済み VM を両方のホストで管理して 2 つのハイパーバイザー間で移行できるフォールトトレラントな構成を確保することによって、 HA 処理に適した最小限のハードウェア導入を示しています。</block>
  <block id="df1b58247681ba5f974a572d530dbdf9" category="paragraph">アフィニティとは、 VM やホストのセットに対してルールを定義する方法で、グループ内の同じホストで複数の VM が実行されるか、別々のホストで実行されるかを決定します。VM とホストで構成されるアフィニティグループを作成することで、 VM に適用されます。このアフィニティグループには同じパラメータと条件が設定されます。アフィニティグループ内の VM がグループ内の同じホストで実行されているのか、または別々のホストで実行されているのかに応じて、アフィニティグループのパラメータでは正のアフィニティまたは負のアフィニティを定義できます。</block>
  <block id="f38d8cd9caeb9a037c470b7d061392a0" category="paragraph">アフィニティグループを設定するには、を参照してください<block ref="eb1587f3cb611d53dba5bde41d49122a" category="inline-link-rx"></block>。</block>
  <block id="ff94444190436ee7694d15be2dde0f29" category="list-text">NetApp ONTAP ストレージクラスタ</block>
  <block id="b645e117fe786bf56128cde2dec3971a" category="list-text">Red Hat OpenShift クラスタ</block>
  <block id="0d46ef98dfe52c8d01c0c5ace93d8165" category="section-title">Red Hat OpenShift –クラスタリソース</block>
  <block id="3c73122271c9219b54ca745b732adc28" category="list-text">同様に、 project-2 の開発者ロールを作成します。</block>
  <block id="36e36b60ddb8f46fe0b9b4e8f4dce56f" category="list-text">ストレージ管理者用の ClusterRoleBindings を設定します。</block>
  <block id="ced38b1f1c19446862c601754b82b94c" category="list-text">ロールの作成 - developer-project-1 のロールを project-1 の対応するグループ (OCP-project-1) にバインドする開発者のバインディング。</block>
  <block id="2aa292f2ff8b13fe141ca55c27bc29c2" category="list-text">同様に、開発者の役割を project-2 の対応するユーザーグループにバインドする開発者の RoleBindings を作成します。</block>
  <block id="d008c60ddb28c0bbad1dfabdd77327fc" category="doc">設定：ストレージ管理者のタスク</block>
  <block id="3f8bc17bf8dd138aa2915235f0a9c0d3" category="image-alt">ONTAP での SVM の作成</block>
  <block id="4350d40426f8c94f6ca046609969adb2" category="list-text">同様に、 project-2 に対してストレージクラスを作成し、 project-2 に専用のバックエンドのストレージプールを使用するように設定します。</block>
  <block id="2ee847ebe129ae778860d6dd2da21cf6" category="list-text">ResourceQuota を作成して ' プロジェクト 1 内のリソースを制限し ' 他のプロジェクト専用のストレージを要求します</block>
  <block id="c689ae18a0f5e47541dcec4afb6e187a" category="list-text">同様に 'ResourceQuota を作成して 'project-2 内のリソースを制限し ' 他のプロジェクト専用のストレージを要求します</block>
  <block id="950496934d91d07bb089d6ed0999b5a9" category="paragraph">詳細または概要については、以下の概要ビデオをご覧ください。</block>
  <block id="b923f56ad2a53fa1a3ca1160e48f141e" category="section-title">AWX / タワー型の導入</block>
  <block id="ab81e47672e89830ec16c581f44cb23c" category="list-text">パート 1 ：はじめに、要件、自動化の詳細、 AWX/Tower の初期構成</block>
  <block id="cf7bbd18f18fdc73ee49ffea888126c7" category="list-text">パート 2 ：変数とプレイブックの実行</block>
  <block id="f5e227cfa54c5693c512c6adf41a3772" category="section-title">CLI の導入</block>
  <block id="0b8a09b5974336d1f5e510d18205c03c" category="list-text">パート 1 ：はじめに、要件、自動化の詳細、 Ansible Control Host Setup を確認する</block>
  <block id="c232cfc0ae9806d3ad6d34a51df58229" category="sidebar">ネットアップを利用した Red Hat OpenShift</block>
  <block id="cdc53c90644739ab9cb455ad8b663d7b" category="sidebar">Red Hat OpenShift の概要</block>
  <block id="f99e4eb05e28c150680cb72ca8410d93" category="sidebar">NetApp ONTAP を使用して Red Hat OpenShift にマルチテナンシーを設定します</block>
  <block id="51a25aff8c490f11d9be543c7af23a0d" category="sidebar">クラスタ管理者のタスク</block>
  <block id="244e9cd91466ef1240c125511568880a" category="sidebar">ストレージ管理者のタスク</block>
  <block id="bc967dc2d57e6eff184a821bf7577a80" category="sidebar">拡張性</block>
  <block id="0fd00a19fb12bb899dfe7cefbcbbcb79" category="inline-link">Red Hat OpenShift への NetApp Trident のインストール– Docker 「 toomanyrequests 」問題の解決方法</block>
  <block id="43e5d9153d1fc4a35be5f57189605919" category="list-text"><block ref="43e5d9153d1fc4a35be5f57189605919" category="inline-link-rx"></block></block>
  <block id="4b4d60be85b0c53c72ae4b8a05deacef" category="paragraph">ほとんどの Kubernetes ディストリビューションには、 Red Hat OpenShift など、デフォルトでインストールされる NFS バックエンドをマウントするパッケージとユーティリティが付属しています。</block>
  <block id="22f48c519a73ce4759edffb196331422" category="paragraph"><block ref="22f48c519a73ce4759edffb196331422" category="inline-image-macro-rx" type="image"></block></block>
  <block id="943dbb8750d636d9918af903ac016c0e" category="paragraph">ネットアップでは、 Red Hat OpenShift に導入されたアプリケーションのストレージプロビジョニング用に、ネットアップの Trident ストレージオーケストレーションツールで認定されているストレージプラットフォームを複数用意しています。</block>
  <block id="0186ffea1bd2c7ff6458a3a619d01ea2" category="paragraph"><block ref="0186ffea1bd2c7ff6458a3a619d01ea2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cc957c67b836ddc993931d8d2253032" category="paragraph">NetApp Cloud Volumes Service （ AWS / GCP ）と Azure NetApp Files は、クラウドでファイルベースのストレージを提供します。</block>
  <block id="faad8e024544c328d584c28118fb4102" category="paragraph">NetApp Element ストレージシステムは、拡張性に優れた環境でブロックベース（ iSCSI ）のユースケースに対応します。</block>
  <block id="85a240011ba49404bf70606e37c41c96" category="paragraph">以下のページでは、 Red Hat OpenShift with NetApp 解決策で検証されたネットアップストレージシステムに関する追加情報について説明します。</block>
  <block id="65cd53ff19e601ea00bf9688be4dd86a" category="summary">NetApp ONTAP を使用した Red Hat OpenShift Virtualization</block>
  <block id="ad3a2e9007d848afd0c15ffc402781bb" category="doc">ワークフロー： NetApp ONTAP を使用した Red Hat OpenShift Virtualization</block>
  <block id="55c7e45b50d0b012faf4bce31b6ad05d" category="section-title">Snapshot から VM を作成します</block>
  <block id="f991e1a54e399d272c7d968dcdfdb690" category="paragraph">OpenShift で Snapshot 処理を実行するには、リソース VolumeSnapshotClass 、 VolumeSnapshot 、および VolumeSnapshotContent を定義する必要があります。</block>
  <block id="0e2d1628ef03c4400cd293c3143cabb3" category="list-text">VolumeSnapshotContent は、クラスタ内のボリュームから作成された実際の Snapshot です。このデータストアは、 Storage 用の PersistentVolume に似た、クラスタ全体のリソースです。</block>
  <block id="8ca4876558d3675f7a3e2c452c62a215" category="list-text">ボリューム Snapshot は、ボリュームの Snapshot 作成要求です。これは、 PersistentVolumeClaim に似ています。</block>
  <block id="7f9fbed02a61699d31f7d9a0eb11bc81" category="list-text">VolumeSnapshotClass を使用すると、管理者はボリューム Snapshot のさまざまな属性を指定できます。これにより、同じボリュームから作成された異なる Snapshot に対して異なる属性を設定できます。</block>
  <block id="7f7858938c48bb9f08341c0e41c9162d" category="image-alt">Snapshot アーキテクチャの VM</block>
  <block id="99bf6e1ad41f7875d5b7ec9f857c4f0f" category="paragraph">VM の Snapshot を作成するには、次の手順を実行します。</block>
  <block id="52f0977d1e65469f01e2f290e637a8f1" category="list-text">スナップショットクラスの名前を入力し、ドライバの csi.trident.netapp.io を入力して、 Create をクリックします。</block>
  <block id="508073b07367d898823f1841627451d4" category="image-alt">Snapshot クラスを作成します</block>
  <block id="2bde7e02152796551174ea391bda0b60" category="list-text">ソース VM に接続されている PVC を特定し、その PVC の Snapshot を作成します。「ストレージ」＞「ボリュームスナップショット」と選択し、「ボリュームスナップショットの作成」をクリックします。</block>
  <block id="b9513caba1fba7b4291a9e22bc512de5" category="list-text">Snapshot を作成する PVC を選択し、 Snapshot の名前を入力するか、デフォルトを受け入れて、適切な VolumeSnapshotClass を選択します。[ 作成 ] をクリックします。</block>
  <block id="a7a384e6f13cae2ef877b4dd78fd48ad" category="image-alt">Snapshot を作成します</block>
  <block id="d8ae3e40f0f0dba0b7c7ba5b8eea845a" category="list-text">これにより、その時点で PVC のスナップショットが作成されます。</block>
  <block id="e9b3b34ca8f917d1968a106e682f1a97" category="section-title">スナップショットから新しい VM を作成します</block>
  <block id="5160cd070df38f982551c5fea6f1c844" category="list-text">新しい PVC の詳細を入力し、 Restore をクリックします。これにより、新しい PVC が作成されます。</block>
  <block id="0d695454ca10516a832452b6123c5bb5" category="image-alt">Snapshot を新しい PVC にリストアします</block>
  <block id="75b0d3500d81c7799a5b84eca57d6d04" category="list-text">Create をクリックして、新しい VM を作成します。</block>
  <block id="57dc3c96f32e4895e89eab4a248088f5" category="list-text">VM が正常に作成されたら、にアクセスして、新しい VM の状態が、スナップショット作成時に PVC を使用してスナップショットを作成した VM の状態と同じであることを確認します。</block>
  <block id="8bd534d3b6bc8d2541df052e053ed65d" category="section-title">Trident Operator を手動でインストールします</block>
  <block id="e32d70a13ba1767d9a373fe9a0535531" category="section-title">ワーカーノードをストレージ用に準備する</block>
  <block id="b09d268106fd9cbfffd1dc848382a150" category="section-title">ストレージシステムバックエンドを作成</block>
  <block id="7f3417590f5bba5cf5eb34fb288135f1" category="inline-link-macro">次：解決策の検証 / ユースケース：ネットアップを使用した Red Hat OpenShift 。</block>
  <block id="7a38916784a7216f98837f315958c175" category="paragraph"><block ref="7a38916784a7216f98837f315958c175" category="inline-link-macro-rx"></block></block>
  <block id="eed1ab12478f3384bfca66e2b382aefc" category="doc">NetApp ONTAP を使用して Red Hat OpenShift Virtualization を導入します</block>
  <block id="7dc3a10e876dbab2b177f35c0b436f3a" category="list-text">Red Hat OpenShift クラスタ（バージョン 4.6 以降） RHCOS ワーカーノードを使用するベアメタルインフラストラクチャにインストールします</block>
  <block id="b5762731ee8c7a3d9a7ce9abe3804cf0" category="list-text">OpenShift クラスタは、インストーラでプロビジョニングされたインフラを介してインストールする必要があります （ IPI ）</block>
  <block id="7ed0bc09bfa62b64806b6b5c2f4378c7" category="list-text">VM の HA を維持するには、マシンの健全性チェックを導入します</block>
  <block id="43b1ab0e04b8f87e603cc790967d2886" category="list-text">NetApp ONTAP クラスタ</block>
  <block id="d4c321b9edd8d817bdc7ca442e71e3af" category="list-text">ONTAP クラスタの SVM で設定された Trident バックエンド</block>
  <block id="cfcf3a62902e36f3d966271cc090b65c" category="list-text">Red Hat OpenShift クラスタへのクラスタ管理者アクセス</block>
  <block id="af91af16b4791d61bb2e9206807a658d" category="list-text">NetApp ONTAP クラスタへの管理者アクセス</block>
  <block id="e281839ef9ef6cb1eadcc2aa7d6d63be" category="list-text">tridentctl および OC ツールがインストールされている管理ワークステーション $PATH に追加されました</block>
  <block id="314f04ff1024e623d43e0cda9a9df410" category="paragraph">OpenShift Virtualization は、 OpenShift クラスタにインストールされたオペレータによって管理されるため、メモリ、 CPU 、およびストレージに追加のオーバーヘッドが発生します。このオーバーヘッドは、クラスタのハードウェア要件を計画する際に考慮する必要があります。のドキュメントを参照してください<block ref="f9421eaa4175c3e9f421a9acaf6f00d6" category="inline-link-rx"></block> 詳細：</block>
  <block id="be51a7d8687b0a6254a274c1e0100052" category="paragraph">ノード配置ルールを設定して、 OpenShift Virtualization オペレータ、コントローラ、 VM をホストする OpenShift クラスタノードのサブセットを指定することもできます。OpenShift Virtualization のノード配置ルールを設定するには、のドキュメントに従ってください<block ref="325820076f9012df5bb7261c397a527f" category="inline-link-rx"></block>。</block>
  <block id="a805b74dbb589c916a1ebf0e08601665" category="paragraph">OpenShift Virtualization を基盤とするストレージについては、特定の Trident バックエンドからストレージを要求する専用のストレージクラスを用意し、そのストレージクラスを専用の SVM でバックアップすることを推奨します。これにより、 OpenShift クラスタ上で VM ベースのワークロードに提供されるデータに関して、レベルのマルチテナンシーが維持されます。</block>
  <block id="adb787dc1bae0d1c8dee5bd61d49c235" category="inline-link-macro">次の例は、オペレータを介して導入します。</block>
  <block id="6166597c75dc82b2cc8c50a0d5d74400" category="paragraph"><block ref="6166597c75dc82b2cc8c50a0d5d74400" category="inline-link-macro-rx"></block></block>
  <block id="286c0d2f200233e63709210881b700c4" category="paragraph">前の手順で設定したマルチテナントアーキテクチャを検証するには、次の手順を実行します。</block>
  <block id="f4da6475fc7e97756adf2751840e077d" category="list-text">OCP-project-1-user として、 project-1 の開発者としてログインします。</block>
  <block id="2d7fbbcee3114769610fea6ef6f4cdf0" category="list-text">アクセス権をチェックして新しいプロジェクトを作成してください</block>
  <block id="145d2249af633a497182f76e714d1f2e" category="list-text">PVC に関連付けられている PV を確認します</block>
  <block id="d424ec829e7a6f56de4d74835b97103a" category="list-text">PV とそのボリュームが、 NetApp ONTAP 上のプロジェクト 1 専用の SVM に作成されていることを確認します。</block>
  <block id="7b929f9e235c85c6b73ed2ee867c5514" category="list-text">ポッドが実行中かどうか、およびボリュームがマウントされているかどうかを確認します。</block>
  <block id="1149bf04288dfa82d0e3b713a6e66aa1" category="list-text">PVC 「 test-pvc-project-1-sc-2 」および「 test-pvc-project-2-ssc-1 」が作成されていないことを確認します。</block>
  <block id="43700888cdcd166f379f95bd1751ae63" category="list-text">アクセス権をチェックして新しいプロジェクトを作成してください。</block>
  <block id="32579947c29f341292c3ce775140178b" category="list-text">アクセスを検証してプロジェクトを表示します</block>
  <block id="9e97a1398bb4a0499bb69bf1c9e67d6a" category="list-text">ユーザーがで ResourceQuotas を表示または編集できるかどうかを確認します プロジェクト 1</block>
  <block id="17a658c4329ed475a82d2e02c0406118" category="list-text">ユーザーがストレージクラスを表示するためのアクセス権を持っていることを確認します</block>
  <block id="aa177e49bfc4cc0182f57218ce6bdd4d" category="list-text">ストレージクラスについては ' アクセスを確認してください</block>
  <block id="997cef2cfb8ccc12d8739c63e69794f3" category="list-text">ストレージクラスを編集するためにユーザーのアクセス権を検証します</block>
  <block id="9eb6f7c0e27dd8274a30b43a4aee8d53" category="inline-link-macro">次のステップ：スケーリング</block>
  <block id="acd8a990c476bd6cb45a9044361ba723" category="paragraph"><block ref="acd8a990c476bd6cb45a9044361ba723" category="inline-link-macro-rx"></block></block>
  <block id="b8603f3d585261d0005c7c5e51108d19" category="paragraph">iSCSI ログインリダイレクトは、 NetApp Element ソフトウェアクラスタの重要な要素です。ホストログイン要求を受信すると、ノードは、 IOPS とボリュームの容量要件に基づいて、トラフィックを処理するクラスタのメンバーを決定します。ボリュームは NetApp Element ソフトウェアクラスタ全体に分散され、単一のノードがボリュームのトラフィックを大量に処理している場合や新しいノードが追加された場合に再配置されます。特定のボリュームの複数のコピーがアレイ全体に割り当てられます。</block>
  <block id="772db62cf9ecb837ed4f0a91a5963492" category="paragraph">この方法では、ノード障害のあとにボリュームの再配分が発生しても、ログアウトして新しい場所にリダイレクトしてログインした場合を超えてホスト接続には影響はありません。iSCSI ログインリダイレクションを使用する NetApp Element ソフトウェアクラスタは、無停止のアップグレードと運用が可能な自己回復型のスケールアウトアーキテクチャです。</block>
  <block id="0e4136a9f4ad3204c07db26d3c28a546" category="paragraph">マルチテナント構成でストレージリソースを使用する新しいプロジェクトを追加する場合、マルチテナンシーを違反しないように追加の設定が必要になります。マルチテナントクラスタでプロジェクトを追加するには、次の手順を実行します。</block>
  <block id="c8acb1fa89b1ec9d78799a2dd4aa8b59" category="list-text">NetApp ONTAP クラスタにストレージ管理者としてログインします。</block>
  <block id="d0ed0d7b81278233c852e4a0d8aa123b" category="list-text">「ストレージ -&gt; ストレージ VM 」に移動し、「追加」をクリックします。project-3 専用の新しい SVM を作成します。また、 SVM とそのリソースを管理するには vsadmin アカウントを作成します。</block>
  <block id="b0c67e9a89c7ece3169ab5849bb0e411" category="list-text">Red Hat OpenShift クラスタにクラスタ管理者としてログインします</block>
  <block id="46c82384780a492254c43d461363d9ac" category="list-text">project-3 の開発者ロールを作成します。</block>
  <block id="21ac9e9bbb2cfc707143311f4601af1c" category="admonition">ここで説明するロール定義は単なる例です。開発者ロールは、エンドユーザの要件に基づいて定義する必要があります。</block>
  <block id="2ca2d57f42208b6e7e9026b491595f41" category="list-text">Trident バックエンドを作成し、 project-3 専用の SVM にマッピングします。ONTAP クラスタ管理者を使用する代わりに、 SVM の vsadmin アカウントを使用してバックエンドを SVM に接続することを推奨します。</block>
  <block id="c4dcda95616fac9215b5dac3cde37220" category="admonition">この例では ONTAP と NAS のドライバを使用しています。ユースケースに基づいてバックエンドを作成するための適切なドライバを使用します。</block>
  <block id="8628ed29313534f54f01e0da36e66ab7" category="admonition">Trident が Trident プロジェクトにインストールされているとします。</block>
  <block id="1dea1d57247580b530335ec2d484f8a5" category="list-text">他のプロジェクトの ResourceQuotas にパッチを適用して ' プロジェクト内のリソースがプロジェクト 3 専用のストレージからストレージにアクセスするのを制限します</block>
  <block id="4e42a1e911325b5048e50f7b5ea73d1f" category="section-title">VM ライブマイグレーション</block>
  <block id="09e113cd46b4487f140ee07899ea3359" category="image-alt">VM ライブマイグレーションのアーキテクチャ</block>
  <block id="660b7fa756d01df7c4338afb9050abb1" category="paragraph">共有 ReadWriteAny アクセス権を持つ PVC にバインドされた VM を作成するには、次の手順を実行します。</block>
  <block id="416d6e9d0df33a74dd38603be60453c1" category="list-text">目的の OS を選択し、 Next （次へ）をクリックします。選択した OS には、すでに起動ソースが設定されているとしましょう。</block>
  <block id="e1b595d3037639bdea165dde4b1f3906" category="list-text">[Review and Create] ペインで、 VM を作成して VM の詳細を提供するプロジェクトを選択します。ブートソースがクローンとして選択されていることを確認し、選択した OS に適切な PVC が割り当てられた CD-ROM から起動します。</block>
  <block id="998a8df469c318f9cd606b44664cea5d" category="list-text">[ 仮想マシンのカスタマイズ ] をクリックし、 [ ストレージ ] をクリックします。</block>
  <block id="ef44ba6bf4a3e677b41b361628554b88" category="image-alt">ディスク RWX にアクセスできるようにします</block>
  <block id="2ae6b586f76075c7d71faff7ba9d2a41" category="list-text">[ 確認 ] をクリックして確定し、 [ 仮想マシンの作成 ] をクリックします。</block>
  <block id="18c830e61a7a92c60804118ef362933c" category="paragraph">OpenShift クラスタ内の別のノードに VM を手動で移行するには、次の手順を実行します。</block>
  <block id="cc58a226305ad2362de0317c1fd8261b" category="list-text">移行する VM の場合は、省略記号をクリックし、 Migrate the Virtual Machine （仮想マシンの移行）をクリックします。</block>
  <block id="b5839595a4132807edfc858d9f6d90ad" category="list-text">メッセージが表示されたら、 [ 移行 ] をクリックして確認します。</block>
  <block id="d0f501bd9588700bc91fe10b7d3f761a" category="admonition">OpenShift クラスタ内の VM インスタンスは、 evictionStrategy が LiveMigrate に設定されている場合、元のノードがメンテナンスモードになると、自動的に別のノードに移行します。</block>
  <block id="ca77161ad6ca11bca347f347b181c25f" category="inline-link-macro">次：ワークフロー： VM のクローニング</block>
  <block id="294f8e986041208286bb2300b191a2ff" category="paragraph"><block ref="294f8e986041208286bb2300b191a2ff" category="inline-link-macro-rx"></block></block>
  <block id="a181412a291a7d0ae8a71300abf746b8" category="section-title">本番環境の導入に関するベストプラクティス</block>
  <block id="bd690c49b77b8274786240fa94d9d880" category="section-title">少なくとも 3 つのボリュームからなる ESXi クラスタに OpenShift を導入します ノード</block>
  <block id="9dc31e1598f94b9476a025632cee3e19" category="section-title">仮想マシンとホストのアフィニティを設定します</block>
  <block id="ed3ecd4254cc054c70ddee702d7ed519" category="section-title">OpenShift 環境にカスタムインストールファイルを使用します</block>
  <block id="f5b3b6b5d5a71b2934abd61ddb561ce2" category="inline-link-macro">次：ネットアップストレージの概要</block>
  <block id="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="paragraph"><block ref="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="inline-link-macro-rx"></block></block>
  <block id="4711a0fd2fa3c3625080f399e5261ecd" category="paragraph">ネットアップ解決策を使用した Red Hat OpenShift は、次のユースケースでお客様に卓越した価値を提供するように設計されています。</block>
  <block id="aacc79f269e716528198eabb064b216b" category="inline-link-macro">次のレポートは、 Red Hat OpenShift の概要です</block>
  <block id="62857c2aca7eeae2c1f44104c3fc7dde" category="paragraph"><block ref="62857c2aca7eeae2c1f44104c3fc7dde" category="inline-link-macro-rx"></block></block>
  <block id="639813d9aa126816c3f9e9de2a45ce17" category="paragraph">OSP は、コンピューティング、ストレージ、ネットワークリソースを管理する一連の制御サービスによって実装される IaaS （インフラサービス）クラウドです。この環境の管理には Web ベースのインターフェイスを使用します。このインターフェイスを使用すると、管理者とユーザは OpenStack リソースの制御、プロビジョニング、自動化を行うことができます。さらに、 OpenStack インフラは、広範なコマンドラインインターフェイスと API を通じて管理者とエンドユーザにフルオートメーション機能を提供します。</block>
  <block id="e2ab8aafc6151adfa655ffd5d2425e7d" category="section-title">OpenStack サービス</block>
  <block id="9a14258452ea5da50d562e08e5b9291c" category="section-title">少なくとも 3 つのコンピューティングノードで構成された OSP プライベートクラウドに OpenShift を導入します。</block>
  <block id="7a595c63e0ebc069af3da46e3d1c8fee" category="section-title">仮想マシンとホストのアフィニティを設定します</block>
  <block id="d90e13a49726d9175649113d81f4caa7" category="paragraph">アフィニティグループを設定するには、を参照してください<block ref="f5b5be16184c5362a1ca218025e91581" category="inline-link-rx"></block>。</block>
  <block id="4e3f9a03501932f914205c4ad0e682ea" category="list-text">* NetApp FlexClone 。 * Snapshot コピーに基づいて、ネットアップボリュームの読み書き可能なフルコピーを瞬時にプロビジョニングできます。</block>
  <block id="96f474208f638efbbd85fac3a46a2ed4" category="paragraph">ONTAP の詳細については、を参照してください<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>。</block>
  <block id="e80842c9211bc376ee42d583c70ae408" category="section-title">ネットアップのプラットフォーム</block>
  <block id="14a9bacc4b197037f54eb0c4c7e1970c" category="paragraph">そのため、組織は、たとえば、すべてのワークロードを単一のクラスタで実行しながら、各ワークロードに専用のクラスタのメリットを提供することで、両方の世界で最も優れたソリューションを見つけることができます。</block>
  <block id="cde9f9f8fcae0cdc6624895868803d60" category="list-text">クラスタリソースを許可することで設備投資と運用コストを削減 を共有します</block>
  <block id="943a49720e6c85fa9692af2a5ebd8829" category="list-text">運用と管理のオーバーヘッドを軽減</block>
  <block id="f51a58b3ab19c778652fcff9dd39ca55" category="list-text">セキュリティ侵害のクロスコンタミネーションからワークロードを保護</block>
  <block id="181cfddfdb055879df4d55323a14c473" category="list-text">リソースの競合による予期しないパフォーマンスの低下からワークロードを保護</block>
  <block id="d463f48696e58e286e9c0d594169b395" category="inline-link-macro">次の例は、アーキテクチャです</block>
  <block id="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="paragraph"><block ref="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="inline-link-macro-rx"></block></block>
  <block id="482f4dddd14a12f4ece48aef54de313c" category="summary">Red Hat OpenShift Container Platform は、開発と IT の運用を単一のプラットフォーム上に統合し、オンプレミスとハイブリッドクラウドのインフラ全体でアプリケーションを一貫して構築、導入、管理します。Red Hat OpenShift は、コンテナベースのワークロード向けに設計された、世界をリードするエンタープライズ Linux ディストリビューションである Kubernetes や Red Hat Enterprise Linux CoreOS など、オープンソースのイノベーションと業界標準に基づいて構築されています。</block>
  <block id="e68e90b5707502c9f2fc1361ac071b3d" category="paragraph">Red Hat OpenShift Container Platform は、開発と IT の運用を単一のプラットフォーム上に統合し、オンプレミスとハイブリッドクラウドのインフラ全体でアプリケーションを一貫して構築、導入、管理します。Red Hat OpenShift は、コンテナベースのワークロード向けに設計された、世界をリードするエンタープライズ Linux ディストリビューションである Kubernetes や Red Hat Enterprise Linux CoreOS など、オープンソースのイノベーションと業界標準に基づいて構築されています。OpenShift は Cloud Native Computing Foundation （ CNCF ）認定 Kubernetes プログラムの一部であり、コンテナワークロードの移植性と相互運用性を提供します。</block>
  <block id="d383250f88949df87bac7768b697ccb6" category="list-text">* セルフサービスプロビジョニング * 開発者は、最も多くのツールを使用して、必要に応じてアプリケーションをすばやく簡単に作成できます。また、運用環境全体を完全に制御できます。</block>
  <block id="df45d857ed72e8e5ed370c6fdfd1e305" category="list-text">* 永続的ストレージ。 * 永続的ストレージをサポートすることにより、 OpenShift Container Platform はステートフルアプリケーションとクラウドネイティブステートレスアプリケーションの両方を実行できます。</block>
  <block id="29ee9790b817110f2303080d5b295946" category="list-text">* 継続的統合および継続的開発（ CI / CD ）。 * このソースコードプラットフォームは、大規模なビルドおよび展開イメージを管理します。</block>
  <block id="a0f0997dded25d9aa9c767f29c17c249" category="list-text">* オープンソース標準 * これらの標準は、オープンソース・テクノロジに加えて、コンテナオーケストレーションのための Open Container Initiative （ OCI ）および Kubernetes を組み込みます。お客様は、特定のベンダーのテクノロジやビジネスロードマップに制限されることはありません。</block>
  <block id="7dc3d12ecda66373091607ba18ef4434" category="list-text">* CI/CD パイプライン * OpenShift は、 CI/CD パイプラインをすぐに使用できるサポートを提供します。これにより、開発チームはアプリケーション配信プロセスのすべてのステップを自動化し、アプリケーションのコードまたは構成に加えられたすべての変更に対して実行することができます。</block>
  <block id="95e4c6a8e27cc92068d97ef795477714" category="list-text">* 役割ベースのアクセス制御 (RBAC) 。 * この機能は、大規模な開発者グループの編成を支援するチームとユーザーの追跡を提供します。</block>
  <block id="d565eddf8e07af916519ec07f8712204" category="list-text">* ビルドとデプロイを自動化。 * OpenShift により、開発者はコンテナ化されたアプリケーションを構築することも、プラットフォームでアプリケーションソースコードやバイナリからコンテナを構築することもできます。プラットフォームは、アプリケーションに定義された特性に基づいて、これらのアプリケーションのインフラストラクチャへの導入を自動化します。たとえば、割り当てられるリソースの量や、サードパーティのライセンスに準拠するために導入するインフラストラクチャ上の場所などです。</block>
  <block id="4fe0bdfd5a2ae34ba1a93860fd91d2fd" category="list-text">* 一貫性のある環境。 * OpenShift により、開発者やアプリケーションのライフサイクル全体でプロビジョニングされた環境が、オペレーティングシステムからライブラリ、ランタイムバージョン（ Java ランタイムなど）まで一貫していることを確認します。 また、一貫性のない環境から発生したリスクを除去するために、使用中のアプリケーションランタイム（ Tomcat など）も削除できます。</block>
  <block id="64f8957eb1a3bb6a1e9ebd391e76925a" category="list-text">* 構成管理。 * 構成と機密性の高いデータ管理はプラットフォームに組み込まれており、アプリケーションの構築に使用されるテクノロジーや導入される環境に関係なく、一貫性のある、環境に依存しないアプリケーション構成がアプリケーションに確実に提供されるようにします。</block>
  <block id="5efb308bdb8052c1aa3fe8333f459fe5" category="list-text">* アプリケーションログとメトリック。 * 迅速なフィードバックは、アプリケーション開発の重要な要素です。OpenShift に統合された監視機能とログ管理機能により、開発者はアプリケーションがどのように変化しても動作しているかを調査し、アプリケーションのライフサイクルの早い段階で問題を修正できるようになります。</block>
  <block id="fe8c2f8039053e077a0ca678496b72aa" category="section-title">Red Hat OpenShift の導入方法</block>
  <block id="220887aee59c37fa79fc366cba7dad4e" category="section-title">ネットアップが検証済みの OpenShift 環境</block>
  <block id="e85b6a5686bf01c916e1c3b442e8db44" category="inline-link-macro">ネットアップを使用して Red Hat OpenShift でマルチテナンシーを構成します</block>
  <block id="29a3155f4e27ac61f0e6d1e00866c981" category="list-text"><block ref="29a3155f4e27ac61f0e6d1e00866c981" category="inline-link-macro-rx"></block></block>
  <block id="781cf19a6329e508987456098cde8c79" category="list-text"><block ref="781cf19a6329e508987456098cde8c79" category="inline-link-macro-rx"></block></block>
  <block id="0b41ceffa053ec5210732b1f8d0f0c5d" category="inline-link-macro">次は、ビデオとデモです</block>
  <block id="232b127190e97018e70ee81d28e36117" category="paragraph"><block ref="232b127190e97018e70ee81d28e36117" category="inline-link-macro-rx"></block></block>
  <block id="3a724344bfc1b086a678d66814f20dd7" category="summary">このセクションでは、継続的インテグレーション、継続的デリバリー、またはデプロイメントパイプラインを Jenkins で展開し、解決策の動作を検証する手順について説明します。</block>
  <block id="ff587ce314d6f90660779e9d75cafe53" category="paragraph">このセクションでは、 Jenkins との継続的統合 / 継続的配信または導入（ CI / CD ）パイプラインを導入して解決策の動作を検証する手順について説明します。</block>
  <block id="9eb8af4dd2c3557a24b914601b6ae465" category="section-title">Jenkins の導入に必要なリソースを作成します</block>
  <block id="6baa4bd25992de2d17278ade0d3090ad" category="list-text">「テンプレートをインスタンス化」をクリックします。</block>
  <block id="c7b4a6da6ab2733552de61d67b38a39e" category="list-text">デフォルトでは、 Jenkins アプリケーションの詳細が入力されます。要件に基づいてパラメータを変更し、 [ 作成（ Create ） ] をクリックします。このプロセスでは、 OpenShift で Jenkins をサポートするために必要なリソースがすべて作成されます。</block>
  <block id="f913f3c8b073438c23eb36c9cf8237ac" category="section-title">VM を作成します</block>
  <block id="71dd19ec5a595517b0b57750ad1a6568" category="paragraph">VM は、オペレーティングシステムとデータをホストするボリュームを必要とするステートフルな導入です。CNV では、 VM がポッドとして実行されるため、 VM は Trident 経由で NetApp ONTAP にホストされた PVS によってバックアップされます。これらのボリュームはディスクとして接続され、 VM のブートソースを含むファイルシステム全体が格納されます。</block>
  <block id="e01cb9126428f7417091e42362dcb6cb" category="image-alt">VM アーキテクチャを作成する</block>
  <block id="51f24796fdd958a7a4ab9fb9a1086c9a" category="paragraph">OpenShift クラスタ上に仮想マシンを作成するには、次の手順を実行します。</block>
  <block id="9b992d4161d9af3e77a9c4e35f9d7652" category="image-alt">VM のブートソースを作成します</block>
  <block id="fe46fcd3bb2eadd55896f6a4e9af5b05" category="list-text">選択したオペレーティングシステムにすでにブートソースが設定されている場合は、前の手順を省略できます。</block>
  <block id="c119644bb97e69cc47555d48ff5ead07" category="list-text">仮想マシンをカスタマイズする場合は、 [ 仮想マシンのカスタマイズ ] をクリックし、必要なパラメータを変更します。</block>
  <block id="8b2c60e63de0927cca5bd9401cdd4647" category="list-text">[ 仮想マシンの作成 ] をクリックして仮想マシンを作成します。これにより、対応するポッドがバックグラウンドでスピンアップされます。</block>
  <block id="ba7734e1db4ae3c0a25330f01ced054d" category="paragraph">ブート・ソースが URL またはレジストリからテンプレートまたはオペレーティング・システム用に構成されている場合 'OpenShift Virtualization-os-images' プロジェクトに PVC を作成し 'KVM ゲスト・イメージを PVC にダウンロードしますテンプレート PVC に、対応する OS の KVM ゲストイメージを格納できるだけの十分なプロビジョニングスペースがあることを確認する必要があります。これらの PVC は、任意のプロジェクトでそれぞれのテンプレートを使用して作成されると、クローン作成され、ルートディスクとして仮想マシンに接続されます。</block>
  <block id="2188a3011c4ccaa5490bcaca14a05579" category="inline-link-macro">次のワークフロー： VM のライブマイグレーション</block>
  <block id="a997d50e238a53b066824f32046c10ab" category="paragraph"><block ref="a997d50e238a53b066824f32046c10ab" category="inline-link-macro-rx"></block></block>
  <block id="f64f81d4393ab1fc9545c35c8eb9f74d" category="paragraph">次のビデオでは、このドキュメントに記載されている機能の一部を紹介します。</block>
  <block id="5e217c79c499978721e658f868053d3f" category="inline-link-macro">次のレポート：追加情報：ネットアップでの Red Hat OpenShift</block>
  <block id="d2fb587a433995783f0688b22359272d" category="paragraph"><block ref="d2fb587a433995783f0688b22359272d" category="inline-link-macro-rx"></block></block>
  <block id="8e0bd613649f232fe1f718134898ea21" category="paragraph">Trident を NetApp ONTAP ストレージシステムと統合するには、ストレージシステムとの通信を可能にするバックエンドを作成する必要があります。</block>
  <block id="44b1200b793638d4a3aebd1bee591e12" category="paragraph">マルチテナント解決策では、必要以上に多くのクラスタリソースにアクセスすることはできません。つまり、マルチテナンシー構成の一部として構成するリソースセット全体が、クラスタ管理者、ストレージ管理者、および各プロジェクトに取り組む開発者に分けられます。</block>
  <block id="1ceba10f8902735a18e8c3bb3e8a3052" category="paragraph">次の表に、各ユーザが実行する各タスクを示します。</block>
  <block id="2a5eb41b2d7fd04d01836f89ab790852" category="cell">ストレージリソースクォータを作成します</block>
  <block id="4edd9914739183e9cb724a222261a01f" category="inline-link-macro">次の手順：前提条件</block>
  <block id="8013a47a037d25fa6d9671120cfc1ee5" category="paragraph"><block ref="8013a47a037d25fa6d9671120cfc1ee5" category="inline-link-macro-rx"></block></block>
  <block id="2c65eb4e4300c763b9d8ffcdc45660fc" category="paragraph">OpenShift Virtualization をインストールするには、次の手順を実行します。</block>
  <block id="bb761e1ed8ef4412cddb399e81488f83" category="list-text">クラスタ管理者アクセス権を持つ Red Hat OpenShift ベアメタルクラスタにログインします。</block>
  <block id="3f4b86cf3e8a535371d3937bd126d789" category="list-text">Perspective ドロップダウンから Administrator を選択します。</block>
  <block id="78146e6a44100deebbe276c19e6c437a" category="image-alt">OpenShift Operator Hub</block>
  <block id="016a229c1180d24870be44f7391c5678" category="list-text">OpenShift Virtualization タイルを選択し、 Install をクリックします。</block>
  <block id="fe87c9ebb6d1db5af643c2101dd83c2d" category="image-alt">OpenShift Virtualization Operator Tile を使用します</block>
  <block id="d2770f20a312c7d906cf3d8a97d335a2" category="list-text">Install Operator （オペレータのインストール）画面で、デフォルトのパラメータをすべてそのままにして、 Install （インストール）をクリックします。</block>
  <block id="66b5ae84d6c0a470bb131b7aeb63f734" category="image-alt">OpenShift Virtualization Operator Details （ OpenShift 仮想化オペレータ詳細</block>
  <block id="11458c333e4903e54ca46f822ba6a3b6" category="list-text">オペレータによるインストールが完了するまで待ちます。</block>
  <block id="5f27d84a5a158e75ab7ac4543ca7c1be" category="image-alt">OpenShift Virtualization Operator インストール</block>
  <block id="49598c5badb95e31a9894d5dc277f301" category="list-text">オペレータがインストールされたら、 Create HyperConverged をクリックします。</block>
  <block id="f63ea68253a91a92e8afb2e42bf0fb36" category="image-alt">OpenShift Virtualization Operator - ハイパーコンバージドを作成</block>
  <block id="0e4308133099865567bc6a19f0abcb88" category="list-text">[Create HyperConverged ( ハイパーコンバージドの作成 )] 画面で、 [Create ( 作成 )] をクリックし、すべてのデフォルトパラメータを受け入れます。このステップでは、 OpenShift Virtualization のインストールを開始します。</block>
  <block id="c57b56755457ec355801b1e17915fc47" category="image-alt">OpenShift Virtualization Operator - ハイパーコンバージドの詳細</block>
  <block id="ee0ffac6ee8f4e224a044d95e68aa30d" category="list-text">OpenShift CNV ネームスペースですべてのポッドが running 状態に移行し、 OpenShift Virtualization オペレータが Succeeded 状態になると、オペレータは使用可能な状態になります。これで、 OpenShift クラスタで VM を作成できるようになります。</block>
  <block id="423e88e20ace3dbca3f9d5bd3b109cef" category="image-alt">OpenShift Virtualization Operator のインストールが完了しました</block>
  <block id="46af5002087f682df1feb9b3339d1f68" category="inline-link-macro">次の手順：ワークフロー： VM を作成します。</block>
  <block id="066b9e10038ca1d47643166f151f910c" category="paragraph"><block ref="066b9e10038ca1d47643166f151f910c" category="inline-link-macro-rx"></block></block>
  <block id="7e4be32047fe5b09a23fd956cd4e82f0" category="section-title">少なくとも 3 つの RHV クラスタに OpenShift を導入します ノード</block>
  <block id="b98f17dd49fc6d1c2a9b58922fae2686" category="paragraph">VM とホストのアフィニティを有効にすると、 OpenShift マスターを複数のハイパーバイザーノードに分散できます。</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">テクノロジ要件</block>
  <block id="c4ff2177ae2f8ed9c3e5353068cf2195" category="section-title">Red Hat OpenShift –ストレージリソース</block>
  <block id="6c7eefdca8e3859011afa00995879a32" category="inline-link-macro">次へ：設定</block>
  <block id="0c86c0f2c0ad5b82864ef1b20a904132" category="paragraph"><block ref="0c86c0f2c0ad5b82864ef1b20a904132" category="inline-link-macro-rx"></block></block>
  <block id="7652dcfa1608f7891f4e5c9b462354be" category="paragraph">この課題に対処するために、 Red Hat は OpenShift バージョン 4.6 から始まる OpenShift Virtualization （以前のコンテナネイティブ仮想化）を導入しました。OpenShift Virtualization 機能を使用すると、同じ OpenShift Container Platform インストール上でコンテナとともに仮想マシンを実行および管理できるため、オペレータを介して VM の導入と管理を自動化するハイブリッド管理機能が提供されます。OpenShift Virtualization では、 OpenShift で VM を作成するだけでなく、 VMware vSphere 、 Red Hat Virtualization 、 Red Hat OpenStack Platform の各環境からの VM のインポートもサポートします。</block>
  <block id="269bac1ed5128eacc45c06318333642a" category="image-alt">OpenShift 仮想化</block>
  <block id="8a5bcb32f7cb878beee68d6f84b3ada7" category="paragraph">Red Hat OpenShift Virtualization の詳細については、のドキュメントを参照してください<block ref="3339eb5909b80aa35681f9f3f9478c17" category="inline-link-rx"></block>。</block>
  <block id="2bd77ae4e72f37c837a2da8cfa83e210" category="inline-link-macro">次の手順：導入の前提条件</block>
  <block id="3a86ddb85761278fa813d15edecbc2b1" category="paragraph"><block ref="3a86ddb85761278fa813d15edecbc2b1" category="inline-link-macro-rx"></block></block>
  <block id="ad8905a47eb465223ebe7acf569732b1" category="doc">Configuration ：クラスタ管理者のタスク</block>
  <block id="552eab1d1ea09d0d1733b97dee6609a1" category="paragraph">Red Hat OpenShift cluster-admin によって次のタスクが実行されます。</block>
  <block id="8a4ffd494b5e8af3ac1be2cd9ab254fb" category="list-text">Red Hat OpenShift クラスタに cluster-admin としてログインします。</block>
  <block id="7ccd4d72e4addf5c27c53bafaeb3fdbd" category="list-text">異なるプロジェクトに対応する 2 つのプロジェクトを作成します。</block>
  <block id="6c98bfb16f2e9bbebd943c1f8592306d" category="list-text">project-1 の開発者ロールを作成します。</block>
  <block id="7428df2e0e503f4cabb43a4667bc1983" category="list-text">すべての OpenShift およびネットアップストレージリソースは、通常はストレージ管理者が管理します。ストレージ管理者向けのアクセスは、 Trident のインストール時に作成された Trident オペレータロールによって制御されます。これに加えて、ストレージ管理者は ResourceQuotas にアクセスして、ストレージの消費方法を制御する必要があります。</block>
  <block id="7d03daab3e74958fc08ebc0c90e0a6a2" category="inline-link-macro">次：ストレージ管理者のタスク</block>
  <block id="f3d9bb76442ab5c11e6af4dd328b2559" category="paragraph"><block ref="f3d9bb76442ab5c11e6af4dd328b2559" category="inline-link-macro-rx"></block></block>
  <block id="6c0ed744c737f30af364d229639c8288" category="paragraph">ストレージ管理者が次のリソースを設定する必要があります。</block>
  <block id="64244866ddff81ded5e6aaa49055c6aa" category="list-text">NetApp ONTAP クラスタに admin としてログインします。</block>
  <block id="c9bd46366e9fb78552566f1e7a13633a" category="list-text">project-1 のバックエンドを作成し、プロジェクト専用の SVM にマッピングします。ONTAP クラスタ管理者を使用する代わりに、 SVM の vsadmin アカウントを使用してバックエンドを SVM に接続することを推奨します。</block>
  <block id="4a6c648106c1ff38316705bf986de601" category="list-text">同様に、 project-2 の Trident バックエンドを作成し、 project-2 に専用の SVM にマッピングします。</block>
  <block id="9a45d41277a2e8ce29709826a31fb482" category="list-text">次に、ストレージクラスを作成します。StoragePools パラメータを設定して、 project-1 専用のバックエンドのストレージプールを使用するように project-1 のストレージクラスを作成し、これを設定します。</block>
  <block id="7f9ddc8224f28e1481299160807c876d" category="inline-link-macro">次のステップ：検証</block>
  <block id="93a1440c4dcba82f234a9305a9445144" category="paragraph"><block ref="93a1440c4dcba82f234a9305a9445144" category="inline-link-macro-rx"></block></block>
  <block id="b917a2bfe0dd0160c3ad88751f355f5d" category="inline-link-macro">次：クラスタ管理者のタスク</block>
  <block id="7a9f102fda0e3438bff54da4acdbccbb" category="paragraph"><block ref="7a9f102fda0e3438bff54da4acdbccbb" category="inline-link-macro-rx"></block></block>
  <block id="4b6826f4f20a8e7e7a3b42ccb81d514f" category="section-title">VM のクローニング</block>
  <block id="0ea820e58acf3d0c3acac3f64518c517" category="image-alt">VM クローニングアーキテクチャ</block>
  <block id="a1dbf280b3b5da141010127710d68ba7" category="paragraph">CSI ボリュームクローニングには、次のような一定の制限事項があります。</block>
  <block id="7f8cb9ac957166d3d134bf9df8861f5b" category="list-text">送信元 PVC と宛先 PVC は同じプロジェクト内に存在する必要があります。</block>
  <block id="058d8141e417cb514573ba1a70e2e0cd" category="list-text">クローニングは、同じストレージクラス内でサポートされます。</block>
  <block id="611b1b227968093cc5c73e69f7ac0fda" category="list-text">クローニングを実行できるのは、ソースボリュームとデスティネーションボリュームで同じボリュームモード設定を使用している場合のみです。たとえば、ブロックボリュームは別のブロックボリュームにしかクローニングできません。</block>
  <block id="557d036c1a69ab0889c0820deb1e88de" category="paragraph">OpenShift クラスタ内の VM は、次の 2 つの方法でクローニングできます。</block>
  <block id="e1230e5b1f51d793ea14fb31df500399" category="list-text">ソース VM をシャットダウンします</block>
  <block id="29ec5d7b455e19c4f8141df877a9af0a" category="list-text">ソース VM を稼働させます</block>
  <block id="84d19f7437a8329c49099517eccd37dc" category="section-title">ソース VM をシャットダウンします</block>
  <block id="375000776ee4694734b1d066c46e7096" category="list-text">Clone Virtual Machine をクリックして、新しい VM の詳細を指定します。</block>
  <block id="b22c43b0906ef8ba78f3fbb7d5b1ff20" category="image-alt">VM をクローニングする</block>
  <block id="cf702a835a3fd4b019603d29ec402106" category="list-text">Clone Virtual Machine をクリックします。これにより、ソース VM がシャットダウンされ、クローン VM の作成が開始されます。</block>
  <block id="82cfb538b52ee01d4a9901d4d2cfad4d" category="list-text">この手順が完了すると、クローニングした VM のコンテンツにアクセスして確認できるようになります。</block>
  <block id="3c7aa222cd4c9ee079b31567a347c05f" category="paragraph">既存の VM は、ソース VM の既存の PVC をクローニングしてから、クローン PVC を使用して新しい VM を作成することによってもクローニングできます。この方法では、ソース VM をシャットダウンする必要はありません。シャットダウンせずに VM をクローニングするには、次の手順を実行します。</block>
  <block id="545ce69617c1c157be6073dcc63bfbae" category="list-text">Clone PVC をクリックして、新しい PVC の詳細を提供します。</block>
  <block id="e659422cf737778a2fb1cdd50cc8003e" category="image-alt">PVC を複製します</block>
  <block id="07c24ffdbaf9583216cca9f030058c11" category="list-text">次に、 Clone をクリックします。これにより、新しい VM の PVC が作成されます。</block>
  <block id="19e005e0709674157e554800d5ea7ef9" category="list-text">VM が作成されたら、にアクセスし、新しい VM がソース VM のクローンであることを確認します。</block>
  <block id="fdbfc131399a8776fecd30fa821de4d0" category="inline-link-macro">次：ワークフロー： Snapshot から VM を作成します。</block>
  <block id="c5c4205f35e83d4dc33cfa7821ceb5a7" category="paragraph"><block ref="c5c4205f35e83d4dc33cfa7821ceb5a7" category="inline-link-macro-rx"></block></block>
  <block id="b1c770f25b823d4453567c0ff9d7cf67" category="summary">このページでは、 VMware vSphere 環境に NetApp ONTAP NFS バージョン 3 データストアを導入する手順を説明します。</block>
  <block id="168dbfe414d4d4089585360152953a57" category="doc">vSphere NFS データストア - バージョン 3 と ONTAP</block>
  <block id="bbe48fb854ea022537208eeeff822f91" category="section-title">このタスクについて</block>
  <block id="2be27a78c84ba5629cd9f2c22983240a" category="paragraph">ONTAP NAS ストレージを使用した NFS バージョン 3 データストアの作成。</block>
  <block id="1563a554e82b055714efd37bc6d1fdd6" category="paragraph">自動プロビジョニングの場合は、次のいずれかのスクリプトを使用します。 <block ref="a45ba722ee80832fb205d0588df91e01" category="inline-xref-macro-rx"></block>、 <block ref="d9559d06f0afa5b213d78afb48b783e7" category="inline-xref-macro-rx"></block>または <block ref="e5e7d2f44064f3bfeddfdbea251f7835" category="inline-xref-macro-rx"></block>。</block>
  <block id="6ac65708de8f04eeb173ca99f3eb19fa" category="section-title">必要なもの</block>
  <block id="106a118b8a267220cb2c40a4bb68b684" category="list-text">vSphere 環境と ONTAP を管理するために必要な基本スキル。</block>
  <block id="00c46d0ea9cdf9a5a37b8af04896741f" category="list-text">ONTAP ストレージシステム（ FAS / AFF / CVO / ONTAP Select / Cloud Volume Service / Azure NetApp Files ） ONTAP 9.8 以降を実行している</block>
  <block id="d5ba6255ccf331629f7b1b4598223d33" category="list-text">ONTAP クレデンシャル（ SVM 名、ユーザ ID 、パスワード）</block>
  <block id="190ba592a6988abfd7566be9b5c8217a" category="list-text">NFS の ONTAP ネットワークポート、 SVM 、および LUN の情報</block>
  <block id="d5cb637f6500cfa77d4190ebdfd8cce0" category="inline-link-macro">完了した NFS 設定ワークシート</block>
  <block id="915142cb27ebec8265b54739a95840b5" category="list-text"><block ref="915142cb27ebec8265b54739a95840b5" category="inline-link-macro-rx"></block></block>
  <block id="24c066a87410cc7b08ad4b5ca45565d7" category="list-text">vCenter Server クレデンシャル</block>
  <block id="a9ab6317871b5547fc7bf0dd22151f00" category="list-text">vSphere 7.0 以降の vSphere ホスト情報</block>
  <block id="d7850596008b347e3797ad7dcb7252e5" category="list-text">NFS VMkernel アダプタの IP 情報</block>
  <block id="9068992a529de63b07b7c2250be12f87" category="list-text">ネットワークスイッチ</block>
  <block id="0675fa9a38b420775f29ec7a62d9a8a0" category="list-text">ONTAP システムのネットワークデータポートと接続された vSphere ホストで使用</block>
  <block id="a7fb6a7233e9c40554334921be362af1" category="list-text">NFS 用に設定されている VLAN</block>
  <block id="44786c36009327ad04469602f3f96832" category="list-text">（任意） ONTAP ネットワークデータポート用に設定されたリンクアグリゲーション</block>
  <block id="503023bddb3bd1c7803b35b4ace6aa7a" category="list-text">ONTAP ツール for VMware vSphere の導入、設定、利用可能な状態</block>
  <block id="f3a29486bed19a90f2da6d007818b427" category="section-title">手順</block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">Interoperability Matrix Tool （ IMT ）</block>
  <block id="4b18348d39655902cd0e183596a82856" category="list-text">との互換性を確認します<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="bc295a5edde99316e021476fd74118c6" category="inline-link-macro">NFS 構成がサポートされていることを確認します。</block>
  <block id="564210524eadeca61542a5680bf0afca" category="list-text"><block ref="564210524eadeca61542a5680bf0afca" category="inline-link-macro-rx"></block></block>
  <block id="e103d9cdc55ef0be25a4fd8054bc28bc" category="list-text">次の ONTAP および vSphere タスクを実行します。</block>
  <block id="cfa5eceb5ac37d5ebd3af6f265d9ce4c" category="section-title">ONTAP タスク</block>
  <block id="c54d1c547e26987b98af73634278c77a" category="inline-link-macro">NFS の ONTAP ライセンスを確認</block>
  <block id="8174503ab9e5dc2fe2f74068f651770d" category="list-text"><block ref="8174503ab9e5dc2fe2f74068f651770d" category="inline-link-macro-rx"></block></block>
  <block id="5d3f3e14f3096740cb085fa81836d595" category="list-text">「 system license show 」コマンドを使用して、 NFS がリストされていることを確認します。</block>
  <block id="8b3434ec0db76b4d537ae9c645aa913c" category="list-text">ライセンスを追加するには 'license add-license-code &lt;license code&gt; を使用します</block>
  <block id="135850bb72d05ca77b8b8f846429fe71" category="inline-link-macro">NFS の設定ワークフローに従います。</block>
  <block id="01a85c06aae02abe9083e7e02d90661f" category="list-text"><block ref="01a85c06aae02abe9083e7e02d90661f" category="inline-link-macro-rx"></block></block>
  <block id="722a3f8fc9c281f41b6ca7a69ca15ec0" category="section-title">VMware vSphere タスク</block>
  <block id="2281b9d958567868b171298a8df5cdee" category="inline-link-macro">vSphere 用の NFS クライアント設定のワークフローに従います。</block>
  <block id="c80c5160cfe2127b3ab167103b20488c" category="paragraph"><block ref="c80c5160cfe2127b3ab167103b20488c" category="inline-link-macro-rx"></block></block>
  <block id="63d5049791d9d79d86e9a108b0a999ca" category="section-title">参照</block>
  <block id="883a5adf98ba177c28c5bc7d95e28763" category="paragraph">これらのタスクが完了すると、 NFS データストアで仮想マシンのプロビジョニングを利用できるようになります。</block>
  <block id="53001b412ce4896686a413a19f6dcc5f" category="listing-title">Ansible の Playbook</block>
  <block id="5a44477fe5ac4beac2dc6574097cf079" category="summary">このページでは、 VMware vSphere 環境に NetApp ONTAP ストレージ iSCSI VMFS データストアを導入する手順を説明します。</block>
  <block id="6d5f52fb3cf097647a57da8b55e5b08f" category="doc">ONTAP を使用した vSphere 従来のブロックストレージプロビジョニング</block>
  <block id="7c2d57185437da757ecede58f5a842d4" category="paragraph">VMware vSphere では、 ONTAP SAN プロトコルをサポートする次の VMFS データストアオプションがサポートされています。</block>
  <block id="c90881491d716de5c0ed7f9f4b09a3ad" category="cell">VMFS データストアのオプション</block>
  <block id="a9181ef164a32ec0949c2cf63315ca31" category="cell">ONTAP SAN プロトコルのサポート</block>
  <block id="5903a917b575023b60264c602c220771" category="inline-link-macro">Fibre Channel （ FC ；ファイバチャネル）</block>
  <block id="a4bce6d7794ee38a14e6a6d3785039f9" category="cell"><block ref="a4bce6d7794ee38a14e6a6d3785039f9" category="inline-link-macro-rx"></block></block>
  <block id="a6105c0a611b41b08f1209506350279e" category="cell">はい。</block>
  <block id="8da5577a58a95e2ebe9c6dd4f19f6c11" category="inline-link-macro">Fibre Channel over Ethernet （ FCoE ）</block>
  <block id="40b814244a055d57c1af5fd02e4a8747" category="cell"><block ref="40b814244a055d57c1af5fd02e4a8747" category="inline-link-macro-rx"></block></block>
  <block id="b26caac6068e09e5f849cfcb3e8c0c90" category="cell"><block ref="b26caac6068e09e5f849cfcb3e8c0c90" category="inline-link-macro-rx"></block></block>
  <block id="c38e870d503879d110dbddd5bf388ab2" category="cell">iSCSI Extensions for RDMA （ iSER ）</block>
  <block id="7fa3b767c460b54a2be4d49030b349c7" category="cell">いいえ</block>
  <block id="de5a656362f0d785d2cc7d3097a507ef" category="inline-link-macro">FC を使用した NVMe over Fabric （ NVMe/FC ）</block>
  <block id="71a94ffc9bd97f314990ee2cd7a87154" category="cell"><block ref="71a94ffc9bd97f314990ee2cd7a87154" category="inline-link-macro-rx"></block></block>
  <block id="16d2954ba1640e32b21c312695337233" category="cell">RDMA over Converged Ethernet （ NVMe/RoCE ）を使用した NVMe over Fabric</block>
  <block id="344567ba51767dd5805c908c602fb10e" category="admonition">iSER または NVMe/RoCE VMFS が必要な場合は、 SANtricity ベースのストレージシステムをチェックしてください。</block>
  <block id="8ce83a5c4c3183c4e25f0d8d7b657ffc" category="summary">このページでは、 VMware vSphere 環境での NFS データストアのサポートについて説明します。</block>
  <block id="3769193a46f06731838a6d904cf1da37" category="doc">ONTAP を使用した、 vSphere の従来型ファイルストレージのプロビジョニング</block>
  <block id="8d3005420a2cb4cc915402d9c5604538" category="paragraph">VMware vSphere では次の NFS プロトコルがサポートされていますが、どちらも ONTAP をサポートしています。</block>
  <block id="78aa97ac78d1291969b5893edcfe448a" category="inline-link-macro">NFS バージョン 3</block>
  <block id="fb110cc4ad992a0846c0eaea7fbf2d94" category="list-text"><block ref="fb110cc4ad992a0846c0eaea7fbf2d94" category="inline-link-macro-rx"></block></block>
  <block id="2d6affbd5ec6eb1f6009383ca5ba9b2b" category="inline-link-macro">NFS バージョン 4.1</block>
  <block id="3f65d9416139ab7c1ff75966bccf6f7d" category="list-text"><block ref="3f65d9416139ab7c1ff75966bccf6f7d" category="inline-link-macro-rx"></block></block>
  <block id="fc5929c224818a87a89047d2813dd2c5" category="inline-link-macro">この NFS クライアントバージョンの比較</block>
  <block id="ce51dd3c15b8a6638d0c212b990ae643" category="paragraph">vSphere に適した NFS バージョンを選択する方法については、を参照してください <block ref="8055fbd4933fc4c8b583fa212ff14ff2" category="inline-link-macro-rx"></block>。</block>
  <block id="e69b470437a857bf2d9517ce4ef8d2c1" category="summary">このページでは、 VMware vSphere 環境に NetApp ONTAP ストレージ FC VMFS データストアを導入する手順を説明します。</block>
  <block id="91d9498cf61618ef81368a106318efd2" category="doc">vSphere VMFS データストア - Fibre Channel ストレージバックエンドに ONTAP を使用</block>
  <block id="b6e52e53cc59b8620dcdc05f2b812be4" category="paragraph">このセクションでは、 ONTAP Fibre Channel （ FC ；ファイバチャネル）ストレージを使用した VMFS データストアの作成について説明します。</block>
  <block id="6b70d8f91894fa50b3c04af804f090b6" category="list-text">vSphere 環境およびを管理するために必要な基本的なスキル ONTAP</block>
  <block id="0335588c7903659bdeaa310c8f7bcdf4" category="list-text">｛ ONTAP_version ｝ を実行している ONTAP ストレージシステム（ FAS/AFF/CVO/ONTAP Select / ASA ）</block>
  <block id="fdb8f60c37b623874df816146436f56b" category="list-text">ONTAP クレデンシャル（ SVM 名、ユーザ ID 、パスワード）</block>
  <block id="d0a36a0dcdef62d026caa08afbaa4a42" category="inline-link-macro">入力した FC 構成ワークシート</block>
  <block id="5c42144bb611ba366591a823d4c2955e" category="list-text"><block ref="5c42144bb611ba366591a823d4c2955e" category="inline-link-macro-rx"></block></block>
  <block id="c7f58b1f94665d7ebf6f107970d1b91b" category="list-text">vSphere ホスト情報</block>
  <block id="cdce6351191da46d795898e4570b8da2" category="list-text">｛ vsphere_version ｝</block>
  <block id="63fc76a195a29345d466bc86f293ca14" category="list-text">ファブリックスイッチ</block>
  <block id="46fdd1539543376bfbbf2cc6da976539" category="list-text">単一のイニシエータの単一ターゲットゾーンを作成します。</block>
  <block id="df7f994fb0c494b66708667a64b2c406" category="list-text">イニシエータごとにゾーンを 1 つ作成します（単一のイニシエータゾーン）。</block>
  <block id="5a1cb943a687396a356750829002d982" category="list-text">各ゾーンに、 SVM の ONTAP FC 論理インターフェイス（ WWPN ）であるターゲットを含めます。SVM ごとに、ノードごとに少なくとも 2 つの論理インターフェイスが必要です。物理ポートの WWPN は使用しないでください。</block>
  <block id="d13dd15101d292f5b2c56e5be828fec8" category="section-title">VMFS データストアのプロビジョニング</block>
  <block id="95877ca095b0f0a0a981f8a12d234ad5" category="paragraph">VMFS データストアをプロビジョニングするには、次の手順を実行します。</block>
  <block id="195e1a47999aff0fbaa4eb8d97be6c40" category="inline-link-macro">FCP 構成がサポートされています</block>
  <block id="e1b87801d0d31fd947fb52aa411c2815" category="list-text">を確認します <block ref="a0240d867f430aa7cc80ec129fc2bdb1" category="inline-link-macro-rx"></block>。</block>
  <block id="e7dc6b39e7e5bd6df8fa93e90a426161" category="list-text">「 system license show 」コマンドを使用して、 FCP が一覧表示されていることを確認します。</block>
  <block id="d1b0a5732b3cb229ef0f788fbb095f05" category="list-text">ライセンスを追加するには 'license add-license-code &lt;license code&gt; を使用します</block>
  <block id="86a53381cefd41dcca81850274f0203a" category="list-text">SVM で FCP プロトコルが有効になっていることを確認します。</block>
  <block id="169e237a691059b9ac1933f0e7be8f56" category="inline-link-macro">既存の SVM の FCP を確認します。</block>
  <block id="5bb60b756067a0334c310be1e2260c3b" category="list-text"><block ref="5bb60b756067a0334c310be1e2260c3b" category="inline-link-macro-rx"></block></block>
  <block id="fab6621b43b19a018afc1860a5b85c21" category="inline-link-macro">既存の SVM で FCP を設定</block>
  <block id="7d4ca3fa89beb77990d305e17ed9ba64" category="list-text"><block ref="7d4ca3fa89beb77990d305e17ed9ba64" category="inline-link-macro-rx"></block></block>
  <block id="0d195904efc6cfb176bbc04e93c2947d" category="inline-link-macro">FCP で新しい SVM を作成します。</block>
  <block id="df062a6cafa16aee5f7ea64ea6991776" category="list-text"><block ref="df062a6cafa16aee5f7ea64ea6991776" category="inline-link-macro-rx"></block></block>
  <block id="5aab5d056538757626dd0562a563471a" category="list-text">FCP 論理インターフェイスが SVM で使用可能であることを確認します。</block>
  <block id="aa01379022dd5b86e18f436c76f651f5" category="list-text">「 Network Interface show 」を使用して、 FCP アダプタを確認します。</block>
  <block id="f89eac3d097d3dae5c0159f0da84b1c7" category="list-text">GUI を使用して SVM を作成する場合、論理インターフェイスはそのプロセスの一部です。</block>
  <block id="946b60eb8bd4945ad82b28fd9ccd3c63" category="list-text">ネットワーク・インターフェイスの名前を変更するには ' Network Interface modify を使用します</block>
  <block id="52fa81ab62bea2599ed516f01925678d" category="inline-link-macro">LUN を作成してマッピングします。</block>
  <block id="c8ecf540bebb63423545ecd3d02c6ca0" category="list-text"><block ref="a2b18e9ce335dd856363e6613d961c1a" category="inline-link-macro-rx"></block> VMware vSphere 用の ONTAP ツールを使用する場合は、この手順を省略してください。</block>
  <block id="e4f7ebeb9544fb23a73028ab714ca87c" category="section-title">VMware vSphere タスク</block>
  <block id="7407e0a15262132133381a890e36e47a" category="inline-link-macro">ストレージアダプタ情報</block>
  <block id="c57f32bc5ce6f95f5f9bec8260ecdb08" category="inline-link-macro">ONTAP ツールを使用して VMFS データストアをプロビジョニングする</block>
  <block id="b3a5f140339b1ca0940c5875b2a76d0b" category="list-text"><block ref="89ebfed741bd060c10a4a1472581f4e2" category="inline-link-macro-rx"></block>。</block>
  <block id="6fe85aae6e8fa231a1f417edfeef3759" category="doc">vSphere VMFS データストア - iSCSI ストレージバックエンド（ ONTAP を使用）</block>
  <block id="4f6f7882fc7b858bc0eb3e3a41991494" category="paragraph">このセクションでは、 ONTAP iSCSI ストレージを使用した VMFS データストアの作成について説明します。</block>
  <block id="383b1f30f341cb0eff11db96d70e9f50" category="list-text">vSphere 環境と ONTAP を管理するために必要な基本的なスキル。</block>
  <block id="47c341511ad626bfba98caeaa0762774" category="list-text">iSCSI の ONTAP ネットワークポート、 SVM 、および LUN の情報</block>
  <block id="f76f5dc5c6861d7938aa8d60b08976c8" category="inline-link-macro">完了した iSCSI 構成ワークシート</block>
  <block id="275e54409e966e03b62ee630e4856daa" category="list-text"><block ref="275e54409e966e03b62ee630e4856daa" category="inline-link-macro-rx"></block></block>
  <block id="c7e4d06c6b5e45fbb711be2b15976173" category="list-text">iSCSI VMkernel アダプタの IP 情報</block>
  <block id="3a6f48cf422509b67592ce2a0b4dd558" category="list-text">iSCSI 用に設定されている VLAN</block>
  <block id="a9df884192a193f56d8208439b4d1fca" category="list-text">との互換性を確認します<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block>。</block>
  <block id="881de4e9f9e9dba55f3d9f09d3fc8eac" category="inline-link-macro">iSCSI 構成がサポートされていることを確認します。</block>
  <block id="6a2fb6d042919f5807315156f926ab10" category="list-text"><block ref="6a2fb6d042919f5807315156f926ab10" category="inline-link-macro-rx"></block></block>
  <block id="f04a1b9690234d25ff072d6719666947" category="inline-link-macro">iSCSI の ONTAP ライセンスを確認します</block>
  <block id="41bf6980693d9ba9f5e7a797fe2f4417" category="list-text"><block ref="0767ceac1f7ac130ade75fb7fae3fc53" category="inline-link-macro-rx"></block>。</block>
  <block id="3ffc628bd3f213f0998146fb5262f366" category="list-text">「 system license show 」コマンドを使用して、 iSCSI がリストされているかどうかを確認します。</block>
  <block id="97035bc2443de65f877c3fddd838c6ae" category="inline-link-macro">SVM で iSCSI プロトコルが有効になっていることを確認します。</block>
  <block id="3807dbdaab3b890b6a293c99c7b46f63" category="list-text"><block ref="3807dbdaab3b890b6a293c99c7b46f63" category="inline-link-macro-rx"></block></block>
  <block id="cb66a92bc9fa6195f8b2914bcf868664" category="list-text">iSCSI ネットワーク論理インターフェイスが SVM で使用可能であることを確認します。</block>
  <block id="da91d0d17d1f671a0af23e7ebb96ec92" category="admonition">GUI を使用して SVM を作成すると、 iSCSI ネットワークインターフェイスも作成されます。</block>
  <block id="da6a83da2309e8dbd81bb5b55c7c9602" category="list-text">ネットワークインターフェイスを表示または変更するには ' ネットワークインタフェースコマンドを使用します</block>
  <block id="53fd22677faa2085c1fc51f1d116faff" category="admonition">ノードごとに 2 つの iSCSI ネットワークインターフェイスを推奨します。</block>
  <block id="69fea75e454b43e67ba176dddb604159" category="inline-link-macro">iSCSI ネットワークインターフェイスを作成</block>
  <block id="bd494b2c15d88a1dfa29c308b39e8f6e" category="inline-link-macro">データ iSCSI サービスがサービスポリシーに含まれていることを確認します。</block>
  <block id="c0e1d066d0482fc5cc1554edaa3f36b2" category="inline-link-macro">ジャンボフレームが有効になっていることを確認します。</block>
  <block id="a355e4512cfabb746ee4c05a87a61107" category="list-text"><block ref="a355e4512cfabb746ee4c05a87a61107" category="inline-link-macro-rx"></block></block>
  <block id="5ccd820a879b8d1daef5e44125431184" category="inline-link-macro">LUN を作成してマッピングします。</block>
  <block id="5c9b297b088335a8562568dc59549c7d" category="list-text">iSCSI VLAN で少なくとも 1 つの NIC が使用可能であることを確認します。パフォーマンスとフォールトトレランスを向上させるために、 2 枚の NIC を推奨します。</block>
  <block id="fe9e58c95c20042a4032ef737d6e8400" category="inline-link-macro">vSphere ホストで使用可能な物理 NIC の数を特定します。</block>
  <block id="96cf3cacac94299a7630f48f5cf5b7e3" category="list-text"><block ref="96cf3cacac94299a7630f48f5cf5b7e3" category="inline-link-macro-rx"></block></block>
  <block id="87d3329dab6e8f24601b6f45d40614ea" category="inline-link-macro">iSCSI イニシエータを設定します。</block>
  <block id="fd823eb37045485458bb3d5d52ddc46f" category="inline-link-macro">iSCSI 用 TCP / IP スタックが利用可能であることを確認します</block>
  <block id="875d65383afa504aad11a619d920adc7" category="list-text"><block ref="025b4ff12eca60b6c5b5be76597b5e95" category="inline-link-macro-rx"></block>。</block>
  <block id="e45f6655250b094b5a8370ff511869c3" category="inline-link-macro">iSCSI ポートグループが使用可能であることを確認します</block>
  <block id="4c93429599cf15be2af5aa0f59131c17" category="list-text"><block ref="5e67546a702454fa060946b3e582d0e9" category="inline-link-macro-rx"></block>。</block>
  <block id="b7b554d373b5992838a126134a03ba0d" category="list-text">通常、複数のアップリンクポートを持つ単一の仮想スイッチを使用します。</block>
  <block id="879d70f2184599f483fd94f0f274163f" category="list-text">1:1 のアダプタマッピングを使用します。</block>
  <block id="9f60e3586ab900b8f879404be003b539" category="list-text">iSCSI VMkernel アダプタが有効になっていて NIC の数が一致していて、 IP が割り当てられていることを確認します。</block>
  <block id="3e6e09b1cda3200c7407173a3473a103" category="inline-link-macro">iSCSI ソフトウェアアダプタを iSCSI VMkernel アダプタにバインド</block>
  <block id="70d687ef257c5d00e0d85844c0101c77" category="list-text"><block ref="70d687ef257c5d00e0d85844c0101c77" category="inline-link-macro-rx"></block></block>
  <block id="187fbd973609969af8f47e857f8579c4" category="inline-link-macro">ONTAP Tools を使用して VMFS データストアをプロビジョニングします</block>
  <block id="1e9df60603ff2a9fe2495b189aecc647" category="list-text"><block ref="efecd5d76f6fc92c9c9a8111cf809724" category="inline-link-macro-rx"></block>。すべてのデータストアについて、同じ手順を繰り返します。</block>
  <block id="5f4723c28ea2b13a27b86c1116720a8a" category="inline-link-macro">ハードウェアアクセラレーションのサポートを確認します。</block>
  <block id="aa0cfa24dd578f0629299a21b453583c" category="list-text"><block ref="aa0cfa24dd578f0629299a21b453583c" category="inline-link-macro-rx"></block></block>
  <block id="1d3fa7ee382266d716ba7a360f30f188" category="paragraph">これらのタスクが完了すると、 VMFS データストアで仮想マシンのプロビジョニングに使用できるようになります。</block>
  <block id="93ac3f76e97265952e309b2cbb980030" category="summary">このページでは、 NetApp ONTAP NFS バージョン 4 のデータストアを VMware vSphere 環境に導入する手順を説明します。</block>
  <block id="11bbb95c80fd3935828f1472bade3ae4" category="doc">vSphere NFS データストア - ONTAP バージョン 4.1</block>
  <block id="0a339846bb9d45c2252cf84f27f8390e" category="paragraph">このセクションでは、 ONTAP NAS ストレージを使用した NFS バージョン 4.1 データストアの作成について説明します。</block>
  <block id="d5ffdd3b223c5bb3d1d66e5756977564" category="list-text">vSphere 環境およびを管理するために必要な基本的なスキル ONTAP</block>
  <block id="a65c730562f6a5feffebe8a600829c71" category="list-text">ONTAP ストレージシステム（ FAS / AFF / CVO / ONTAP Select / クラウドボリュームサービス / Azure ネットアップファイル） ｛ ONTAP_version ｝ を実行しています</block>
  <block id="8e7f2b8f8c015d7ce248683387c1daf5" category="list-text">vSphere ホスト情報 ｛ vsphere_version ｝</block>
  <block id="7d0a7cdd836d94b19d4ecbce81ba2c1e" category="list-text">ONTAP システムのネットワークデータポート、 vSphere ホストを接続します</block>
  <block id="d4e890b3139e840bac898dc24d2330a3" category="list-text">VMware vSphere 向け ONTAP ツールの導入、設定、利用可能な状態</block>
  <block id="f2f6f93a63f235f63bf8a14ad398ddd0" category="inline-link">Interoperability Matrix Tool （ IMT ）</block>
  <block id="2c364f266e330209041f2cf854afab91" category="list-text">との互換性を確認します<block ref="975c7893d48b02c6727b59b0582d74bc" category="inline-link-rx"></block></block>
  <block id="863feef43abaa752e441459bd37722c3" category="list-text">以下の ONTAP および vSphere タスクを実行します。</block>
  <block id="1b2d2406823c016e35ebeddf0ec29c66" category="inline-link-macro">NFS の ONTAP ライセンスを確認</block>
  <block id="7209cd833425a764d216b4e565ac65c6" category="list-text"><block ref="7209cd833425a764d216b4e565ac65c6" category="inline-link-macro-rx"></block></block>
  <block id="55d2948d4abb6ad9ea1e2b6a5b73460b" category="list-text">「 system license show 」コマンドを使用して、 NFS がリストされているかどうかを確認します。</block>
  <block id="0a5e80a3066e5036387d5026a58fe582" category="inline-link-macro">NFS の設定ワークフローに従います</block>
  <block id="4b9e38c0f910614d9be47f85cf0f07bc" category="list-text"><block ref="4b9e38c0f910614d9be47f85cf0f07bc" category="inline-link-macro-rx"></block></block>
  <block id="4344c7f5d714fb1797033b7d9cca43fd" category="inline-link-macro">vSphere 用 NFS クライアント構成のワークフローに従います。</block>
  <block id="c9fb47d82da1089992044972b4b65103" category="paragraph"><block ref="c9fb47d82da1089992044972b4b65103" category="inline-link-macro-rx"></block></block>
  <block id="a7ba4bd9aa10b0456b8f13ef40a2d1d5" category="summary">このページでは、 VMware vSphere 環境に NetApp ONTAP ストレージ FCoE VMFS データストアを導入する手順を説明します。</block>
  <block id="1937a4bfde18bb02682d378132d0b6a9" category="doc">vSphere VMFS Datastore - Fibre Channel over Ethernet ストレージプロトコル ONTAP を使用します</block>
  <block id="66439ac6171413528646918952bff23e" category="paragraph">このセクションでは、 Fibre Channel over Ethernet （ FCoE ）転送プロトコルを使用して ONTAP ストレージに VMFS データストアを作成する方法について説明します。</block>
  <block id="b087c7e1213b84e69de1a6e5214cd942" category="list-text">｛ ONTAP_version ｝ を実行している ONTAP ストレージシステム（ FAS/AFF/CVO/ONTAP Select ）</block>
  <block id="d9da372e69584852a9808bfa9fcc99a9" category="inline-link-macro">サポートされる FCoE の組み合わせ</block>
  <block id="b61947ecee08267d1f6930ccbd646d52" category="list-text"><block ref="b61947ecee08267d1f6930ccbd646d52" category="inline-link-macro-rx"></block></block>
  <block id="08b42ec45ef1147093b9161cc743b0a0" category="inline-link-macro">設定ワークシートに記入</block>
  <block id="bcf78e9148ebbc12ed4a54d2149cc2bc" category="list-text"><block ref="bcf78e9148ebbc12ed4a54d2149cc2bc" category="inline-link-macro-rx"></block></block>
  <block id="80ba2a0b5b5ae31742a18c682e724b6e" category="list-text">ONTAP FC データポートまたは vSphere ホストを接続</block>
  <block id="52dd4b667b031cd80a33b9d176e43827" category="list-text">N_Port ID Virtualization （ NPIV ）機能が有効になっている場合</block>
  <block id="d7b3fbe677a7bffd7e387a3578d6b481" category="inline-link-macro">FC / FCoE ゾーニングが設定されました</block>
  <block id="434da439fcd2a7729ac67cef537d6651" category="list-text"><block ref="434da439fcd2a7729ac67cef537d6651" category="inline-link-macro-rx"></block></block>
  <block id="5d914ccaef7b5404838cb47cff27fa11" category="list-text">FCoE のサポート</block>
  <block id="b74438cda33fca6618da9e30ef5fee5d" category="list-text">DCB のサポート</block>
  <block id="69b788fe29f78e1fb439efd1bec08ab6" category="inline-link-macro">FCoE のジャンボフレーム</block>
  <block id="e92f4c11834e879e94fa441894d8e9c9" category="list-text"><block ref="e92f4c11834e879e94fa441894d8e9c9" category="inline-link-macro-rx"></block></block>
  <block id="42cdbee955a0e208306a321b74a948b1" category="section-title">VMFS データストアをプロビジョニングする</block>
  <block id="f067d14dc86c5c0ec984803b3485a7a6" category="inline-link-macro">FCoE 構成がサポートされていることを確認します</block>
  <block id="79d164739c1e0aaf7f56e13c2a4c66ac" category="list-text"><block ref="4201ef99768aac8f72883e5cb6ec656f" category="inline-link-macro-rx"></block>。</block>
  <block id="1a04100ec801e5e2d1708d89eb1159b6" category="inline-link-macro">FCP の ONTAP ライセンスを確認します。</block>
  <block id="7fcd357d480b8eaa4a38cdbbddfd6c97" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block></block>
  <block id="f2a0a9000f5ff3910235e570c0ac5e44" category="list-text">「 system license show 」コマンドを使用して、 FCP が一覧表示されていることを確認します。</block>
  <block id="e5b8ca3e9ff580bcc9315fabcb34312e" category="list-text">SVM で FCP プロトコルが有効になっていることを確認します。</block>
  <block id="015c565181667d59b83b7761e35682d1" category="inline-link-macro">FCP で新しい SVM を作成します。</block>
  <block id="de4606f963140e2d2d0a3df251ffd646" category="list-text"><block ref="de4606f963140e2d2d0a3df251ffd646" category="inline-link-macro-rx"></block></block>
  <block id="2d6fd01ea0767b50e214a74ff1fcfae0" category="list-text">FCP 論理インターフェイスが SVM で使用可能になっていることを確認します。</block>
  <block id="ee7f4720a3fc60686c4a9f7429a60cbc" category="list-text">ネットワーク・インターフェイスの名前を変更するには ' Network Interface modify を使用します</block>
  <block id="6e67c7d604ae439f60ceb51480fdbb1c" category="inline-link-macro">LUN を作成してマッピングします</block>
  <block id="e4eeb9421963195597743339d2f38ff6" category="list-text"><block ref="96e32c32f267ac1d65d603f36f017a41" category="inline-link-macro-rx"></block>； VMware vSphere 用の ONTAP ツールを使用する場合は、この手順を省略してください。</block>
  <block id="f6c0391a150cfd40a68682285c56e835" category="inline-link-macro">ストレージアダプタ情報</block>
  <block id="60f05805eb8189d665c19856d5388e3c" category="list-text">HBA ドライバがインストールされていることを確認しますVMware がサポートする HBA には、すぐに使用できるドライバとが付属しています は、に表示されている必要があります <block ref="c5f1cce809af8cfecf09908d33f4c097" category="inline-link-macro-rx"></block>。</block>
  <block id="d4f43ea12f3f521c93fb3dd4d93c428d" category="summary">このページでは、 VMware vSphere 環境に VMFS データストア用の NetApp ONTAP NVMe/FC ストレージを導入する手順について説明します。</block>
  <block id="9e433440cdaf3b61716784200e8abf6d" category="doc">vSphere VMFS データストア - NVMe / FC と ONTAP</block>
  <block id="9367f3df6c8d54eba1da3cd9c5fa2776" category="paragraph">このセクションでは、 NVMe/FC を使用した ONTAP ストレージを使用した VMFS データストアの作成について説明します。</block>
  <block id="7890464cdce93f078097395e27132775" category="inline-link-macro">NVMe/FC の基本的な知識</block>
  <block id="c6e7cd589502f52a9398e779ede56d14" category="list-text"><block ref="62a43aa3bd2eb01e27a6091d3017311c" category="inline-link-macro-rx"></block>。</block>
  <block id="62eadfe081f86e1f9a72988a4feb7bfc" category="inline-link-macro">記入済みの FC 構成ワークシート</block>
  <block id="f186921a73873df63dc496b515bc2099" category="list-text"><block ref="f186921a73873df63dc496b515bc2099" category="inline-link-macro-rx"></block></block>
  <block id="c4436d4a190778b7ec1e9461f6454bdd" category="list-text">vCenter Server の各サービスを提供</block>
  <block id="5fd6c6da49bc906cc217c5aff2041a52" category="list-text">vSphere ホスト情報（ ｛ vsphere_version ｝ ）</block>
  <block id="71d4977f0fd6be92644e1ff9f8096637" category="section-title">VMFS データストアをプロビジョニングする</block>
  <block id="f42c50210dcc0a3a69c8258256e75e4b" category="inline-link-macro">NVMe/FC 構成がサポートされていることを確認します。</block>
  <block id="5312bcc81ee6d7bce6549b2089c9d1ac" category="list-text"><block ref="5312bcc81ee6d7bce6549b2089c9d1ac" category="inline-link-macro-rx"></block></block>
  <block id="6ad7e9002145710745843d16314895e3" category="inline-link-macro">NVMe ネームスペースとサブシステムを作成する</block>
  <block id="06badf30aa173febc3374aceef25c5ce" category="list-text"><block ref="06badf30aa173febc3374aceef25c5ce" category="inline-link-macro-rx"></block></block>
  <block id="9761a89a99469e468e71b7a0087be29d" category="inline-link-macro">vSphere ホストの NVMe ドライバのインストールと検証のタスクを実行します</block>
  <block id="926e4d89379d3dde2510965ca53771af" category="list-text"><block ref="926e4d89379d3dde2510965ca53771af" category="inline-link-macro-rx"></block></block>
  <block id="e229fd9b7b8948ddebf276bda8a9145e" category="inline-link-macro">VMFS データストアを作成します</block>
  <block id="3dbbea9263919f89335d7ba053f09a39" category="list-text"><block ref="3dbbea9263919f89335d7ba053f09a39" category="inline-link-macro-rx"></block></block>
  <block id="ad1cf94aab71c9962e22037ed60d41e9" category="list-text"><block ref="ad1cf94aab71c9962e22037ed60d41e9" category="inline-link-macro-rx"></block></block>
  <block id="e6ba927c9d14295015e39be05cf54040" category="inline-link-macro">NetApp ONTAP に Red Hat OpenShift を実装するマルチテナンシー</block>
  <block id="ab439bcac737f2565970fe2612976b75" category="list-text"><block ref="ab439bcac737f2565970fe2612976b75" category="inline-link-macro-rx"></block></block>
  <block id="ad95c47343e102dc30ec33fa6f1ccc55" category="inline-link-macro">NVA-1160 - ネットアップでの Red Hat OpenShift</block>
  <block id="1043b5153afff839b84d714aa9127913" category="list-text"><block ref="1043b5153afff839b84d714aa9127913" category="inline-link-macro-rx"></block></block>
  <block id="d48e549b4fdcc889e0243c53bbb4dda0" category="sidebar">解決策の検証とユースケース</block>
  <block id="d6bf2b10101446c7afd28ff94926fc44" category="sidebar">オペレータを介して展開します</block>
  <block id="e6b088db24ebe67ed0e9567d309387ec" category="sidebar">ワークフロー</block>
  <block id="88c506562ebadd679bb16d76a4558619" category="sidebar">VM のクローニング</block>
  <block id="6c30682e8603121e14abe8bab7bd88f3" category="sidebar">VMware Virtualization for ONTAP の略</block>
  <block id="c0bf5949fe87e1e5caf42e4746cd0080" category="sidebar">VMware vSphere と ONTAP のベストプラクティス</block>
  <block id="f5344fe4d88d29ee79ba6110f60cfa9b" category="list-text">Ansible 制御ホストとして使用できるように Linux ホストを設定するには、<block ref="8688caf90b0dc445f61be35cbf93ed1a" category="inline-link-macro-rx"></block>または<block ref="2b00e81c1e240a58c4df0e850699511b" category="inline-link-macro-rx"></block></block>
  <block id="9b64a6dfae1f3fa326b750c2790c79fe" category="summary">このセクションでは、 Azure NetApp Files SMB ボリュームを使用して AOAG 構成に SQL データベース資産をリアルタイムで導入する方法について説明します。</block>
  <block id="5ca1071c67ab704b04ed27747f213551" category="doc">リアルタイムの高レベル・リファレンス・デザイン</block>
  <block id="bb0357d1c0b3b8ebd31a43c9b30f3745" category="list-text">ノード数： 4.</block>
  <block id="7f4f30d96e1d0a820a6962ad6ac994ee" category="list-text">データベース数： 21</block>
  <block id="f28735e3e5e57049aa575b3f0ec83c61" category="list-text">可用性グループの数： 4.</block>
  <block id="96fb94ba9fad0b4452c212b21df61eab" category="list-text">バックアップの保持： 7 日</block>
  <block id="a8d1485807d36562316fb8b2254bca57" category="list-text">バックアップアーカイブ： 365 日</block>
  <block id="4afa49afd4ebc3638f3e000d65825370" category="admonition">Azure NetApp Files 共有を使用して Azure 仮想マシンに SQL Server と FCI を導入すると、コスト効率に優れたモデルでデータのコピーを 1 つ作成できます。この解決策では、ファイルパスがセカンダリレプリカと異なる場合に、追加ファイル操作の問題を回避できます。</block>
  <block id="ab030ea777250278c4f110a497eeef88" category="paragraph"><block ref="ab030ea777250278c4f110a497eeef88" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4822d9597460a9166778308da312709c" category="paragraph">次の図は、 AOAG 内のデータベースがノード全体に分散していることを示しています。</block>
  <block id="af316199cc8e77dcbb6fb560cbc4c44c" category="paragraph"><block ref="af316199cc8e77dcbb6fb560cbc4c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">データレイアウト</block>
  <block id="35c33dd0c5565dbdba04dc2b313d7a2e" category="paragraph">ユーザデータベースファイル（ .mdf ）とユーザデータベーストランザクションログファイル（ .ldf ）は、 tempdb とともに同じボリュームに格納されます。サービスレベルは Ultra です。</block>
  <block id="9b7d6479a15395afefc6d7f9e38a4f17" category="paragraph">構成は 4 つのノードと 4 つの AGS で構成されます。21 個のデータベース（ Dynamic AX 、 SharePoint 、 RDS コネクションブローカー、インデックスサービスの一部）はすべて Azure NetApp Files ボリュームに格納されます。ノード上のリソースを効果的に使用するために、 AOAG ノード間でデータベースが分散されます。WSFC には、 AOAG 構成に属する 4 つの D32 v3 インスタンスが追加されています。これらの 4 つのノードは Azure Virtual Network でプロビジョニングされ、オンプレミスから移行されることはありません。</block>
  <block id="fcbd19b726fdd6160dfe2ab43f285a55" category="paragraph">* 注： *</block>
  <block id="09a10f0ab048cde1d7b704392ba05d9a" category="list-text">アプリケーションの性質と実行するクエリに応じて、ログのパフォーマンスとスループットが向上する必要がある場合は、データベースファイルを Premium サービスレベルに配置し、 Ultra サービスレベルでログを格納できます。</block>
  <block id="51368a236b969e288242f0b0b615cf74" category="list-text">tempdb ファイルが Azure NetApp Files に配置されている場合は、 Azure NetApp Files ボリュームをユーザのデータベースファイルから分離する必要があります。AOAG でのデータベースファイルの配布例を次に示します。</block>
  <block id="2e66f3d288799e6f4235b883bb2f693c" category="list-text">Snapshot コピーベースのデータ保護のメリットを維持するために、データとログのデータを同じボリュームに統合しないことを推奨します。</block>
  <block id="1452bcdb4aeb229a2c2e503f9bbba753" category="list-text">セカンダリデータベースのファイルパスが対応するプライマリデータベースのパスと異なる場合、プライマリレプリカで実行されるアドオンファイル処理がセカンダリデータベースで失敗する可能性があります。この状況は、プライマリノードとセカンダリノードで共有パスが異なる場合（コンピュータアカウントが異なることが原因）に発生することがあります。この障害が発生すると、セカンダリデータベースが原因によって中断される可能性があります。拡張またはパフォーマンスのパターンを予測できず、あとでファイルを追加する予定の場合は、 Azure NetApp Files を使用した SQL Server フェイルオーバークラスタも許容される解決策です。ほとんどの環境では、 Azure NetApp Files がパフォーマンス要件を満たしています。</block>
  <block id="19f59b74448f6a27519db281a44e4b12" category="section-title">データ移行</block>
  <block id="cd6b4503e07d15cebc0842bb8da7b765" category="paragraph">オンプレミスの SQL Server ユーザデータベースを Azure 仮想マシンの SQL Server に移行するには、いくつかの方法があります。移行はオンラインとオフラインのどちらでも実行できます。選択するオプションは、 SQL Server のバージョン、ビジネス要件、および組織内で定義されている SLA によって異なります。データベース移行プロセス中のダウンタイムを最小限に抑えるために、 AlwaysOn オプションまたはトランザクションレプリケーションオプションのどちらかを使用することを推奨します。これらの方法を使用できない場合は、データベースを手動で移行できます。</block>
  <block id="2d4221f1ee93c102ca047daac1fba4a7" category="paragraph">マシン間でデータベースを移動するための最もシンプルで徹底的にテストされたアプローチは、バックアップとリストアです。通常は、データベースバックアップのあとにデータベースバックアップのコピーを Azure に作成します。そのあとでデータベースをリストアできます。最適なデータ転送パフォーマンスを実現するには、圧縮されたバックアップファイルを使用してデータベースファイルを Azure VM に移行します。本ドキュメントで紹介している高度な設計では、 Azure ファイルストレージのバックアップ方法と Azure ファイルの同期を使用し、 Azure NetApp Files にリストアするアプローチを採用しています。</block>
  <block id="623f8382f97ee8df2d7af54439833812" category="admonition">Azure Migrate は、 SQL Server ワークロードの検出、評価、移行に使用できます。</block>
  <block id="fbc25f1c70f1a9c133715cac6d66b21b" category="paragraph">移行を実行するには、次の手順を実行します。</block>
  <block id="d807caa187d2fea33bab50ed1e1c79bb" category="list-text">要件に基づいて、接続をセットアップします。</block>
  <block id="59f59f1aebe4fc18ab054480b3a1098a" category="list-text">オンプレミスのファイル共有場所へのフルデータベースバックアップを実行</block>
  <block id="4891d727582d5df766ee6737fe7fb761" category="list-text">Azure ファイル同期を使用して、バックアップファイルを Azure ファイル共有にコピーします。</block>
  <block id="135899cc34886eb6ce9baf7211d4adb5" category="list-text">目的のバージョンの SQL Server で VM をプロビジョニングします。</block>
  <block id="fbef0b11b7ee9e0d709d3d1c6efbd4d4" category="list-text">コマンド・プロンプトから copy コマンドを使用して ' バックアップ・ファイルを VM にコピーします</block>
  <block id="b9786aca69df61c5165147929b4ced89" category="list-text">フルデータベースを Azure 仮想マシン上の SQL Server にリストアします。</block>
  <block id="e937691d64dcb1188cbbcbcd83d87d2f" category="admonition">21 のデータベースをリストアするには、約 9 時間かかりました。この方法はこのシナリオに特有です。ただし、状況や要件に応じて、以下に示すその他の移行方法を使用できます。</block>
  <block id="2b9d85faa379ef985ae3851810db1403" category="paragraph">オンプレミスの SQL Server から Azure NetApp Files にデータを移動するためのその他の移行オプションには、次のものがあります。</block>
  <block id="90248308f9c24bd3bf817ee129838603" category="list-text">データファイルとログファイルを切り離し、 Azure Blob Storage にコピーして、 URL からマウントされた ANF ファイル共有を使用して Azure VM 内の SQL Server に接続します。</block>
  <block id="82ce70205698ed956d1fce48af1360c0" category="inline-link">Azure レプリカの追加ウィザード</block>
  <block id="e5e07f1ff84f0082089e4fec71ed43a4" category="list-text">常時稼働の可用性グループをオンプレミスに導入する場合は、を使用します<block ref="aea558e3371e9956f5e03828309464a0" category="inline-link-rx"></block> をクリックして Azure でレプリカを作成し、フェイルオーバーを実行します。</block>
  <block id="eedc53c13a9992999dba36bda1b62255" category="inline-link">トランザクションレプリケーション</block>
  <block id="47a43d904457c52da2918f290a0ae5cb" category="list-text">SQL Server を使用します<block ref="21bf5f41b40b598aae9dd55aa9dcb960" category="inline-link-rx"></block> Azure SQL Server インスタンスをサブスクライバとして設定するには、レプリケーションを無効にして、ユーザに Azure データベースインスタンスをポイントさせます。</block>
  <block id="bf4614882fd1000329cfcb76f98f6c17" category="list-text">Windows インポート / エクスポートサービスを使用して、ハードドライブを出荷します。</block>
  <block id="be062cdcabbb3055334e8f19b4bdf378" category="section-title">バックアップとリカバリ</block>
  <block id="b855582b6472c4fbe2a5f606191e66d6" category="paragraph">バックアップとリカバリは、 SQL Server 環境にとって重要な要素です。AOAG などの高可用性ソリューションと組み合わせて、さまざまなデータ障害および損失シナリオから迅速にリカバリするための適切な安全ネットを用意する必要があります。CommVault などのサードパーティ製バックアップツールでは、 SQL Server データベースの休止ツール、 Azure バックアップ（ストリーミング）、またはアプリケーションと整合性のあるデータベースバックアップを実行できます。</block>
  <block id="3896e1102f68b0bc974f324bb134f6e6" category="inline-link">SCSQLAPI ツール</block>
  <block id="e372173044ccba12657b2e3dbff1879b" category="paragraph">Azure NetApp Files の Snapshot テクノロジを使用すると、パフォーマンスやネットワーク利用率に影響を与えることなく、ユーザデータベースのポイントインタイム（ PiT ）コピーを簡単に作成できます。また、このテクノロジを使用すると、新しいボリュームに Snapshot コピーをリストアしたり、ボリュームの状態を、ボリュームリバート機能を使用して Snapshot コピーが作成された時点の状態にすばやくリバートしたりできます。Azure NetApp Files スナップショットプロセスは非常に高速で効率的で、 Azure バックアップのストリーミングバックアップとは異なり、毎日のバックアップを複数作成できます。1 日に複数の Snapshot コピーを作成できるため、 RPO と RTO が大幅に短縮されます。Snapshot コピーの作成前にデータに損傷がなく、ディスクに適切にフラッシュされるようにアプリケーションの整合性を追加するには、 SQL Server データベースの休止ツールを使用します <block ref="b800e9e09a17fc5b41967404ec8e47ac" category="inline-link-rx"></block>; このリンクにアクセスするには、 NetApp SSO ログインクレデンシャルが必要です）。このツールは PowerShell から実行できます。 PowerShell では、 SQL Server データベースを休止し、アプリケーションと整合性のあるバックアップ用ストレージ Snapshot コピーを作成できます。</block>
  <block id="04666a337d02195d17089298f5773f4c" category="paragraph">* 注： *</block>
  <block id="a4d5ac6087b7ce119cfe6b7ad4d77ee5" category="list-text">SCSQLAPI ツールは、 2016 および 2017 バージョンの SQL Server のみをサポートします。</block>
  <block id="fdcb10d4c2db07cf930247a4f9898ec5" category="list-text">SCSQLAPI ツールは、一度に 1 つのデータベースでのみ動作します。</block>
  <block id="2f65ae42dc3aa8b735406a2d56ceb6fb" category="list-text">各データベースのファイルを別々の Azure NetApp Files ボリュームに配置して、それらのファイルを分離します。</block>
  <block id="879351e17b2cd6d740ac0974e9ff8a5a" category="inline-link">Azure バックアップ</block>
  <block id="794b24c8957eec03a1402459d32f6810" category="paragraph">SCSQL API には大きな制限があるため、<block ref="10a72c6743c3c6714e03b5537ec15603" category="inline-link-rx"></block> SLA 要件を満たすためにデータ保護に使用されていた。Azure Virtual Machine と Azure NetApp Files で実行される SQL Server のストリームベースのバックアップを提供します。Azure Backup では、 15 分の RPO を実現し、ログバックアップと PIT リカバリを最大 1 秒まで頻繁に実行できます。</block>
  <block id="423e555c5ec3885f2bb5d9d2d6627f63" category="section-title">監視</block>
  <block id="fe58430a0bb00057a08eed382c5d82b2" category="paragraph">Azure NetApp Files は、時系列データ用の Azure Monitor と統合されており、割り当てられたストレージ、実際のストレージ使用量、ボリューム IOPS 、スループット、ディスク読み取りバイト / 秒に関する指標を提供します。 ディスク書き込みバイト / 秒、ディスク読み取り / 秒、ディスク書き込み / 秒、および関連するレイテンシ。このデータを使用して、アラート生成によるボトルネックを特定し、健常性チェックを実行して、 SQL Server 環境が最適な構成で実行されていることを確認できます。</block>
  <block id="48419e90c914ae5fa935283404de8a2a" category="paragraph">この HLD では、 ScienceLogic を使用して、適切なサービスプリンシパルを使用してメトリックを公開することで Azure NetApp Files を監視します。次の図は、 Azure NetApp Files Metric オプションの例です。</block>
  <block id="2bede5da6907dcdcebc6a8f407f07467" category="paragraph"><block ref="2bede5da6907dcdcebc6a8f407f07467" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fe292df6373534e554d5a7938bc3c3b" category="section-title">シッククローンを使用した DevTest</block>
  <block id="652f67778e6d02c7b5bfe46a3e579f7f" category="paragraph">Azure NetApp Files を使用すると、アプリケーション開発サイクル中に現在のデータベースの構造とコンテンツを使用して実装が必要な機能をテストするためのデータベースのコピーを瞬時に作成でき、データの抽出と操作を行うツールを使用してデータウェアハウスにデータを取り込むことができます。 また、誤って削除または変更されたデータをリカバリすることもできます。このプロセスでは Azure Blob コンテナからデータをコピーする必要がないため、非常に効率的です。ボリュームのリストア後は読み取り / 書き込み処理に使用できるため、検証と製品化までの時間が大幅に短縮されます。この機能は、 SCSQLAPI と併用してアプリケーションの整合性を保つ必要があります。このアプローチでは、別の継続的なコスト最適化手法に加えて、 Restore to New volume オプションを活用する Azure NetApp Files も提供されます。</block>
  <block id="e4665dd99280634e4b44ff82666fbb9f" category="list-text">Snapshot コピーから作成されたボリュームに Restore New Volume オプションを使用すると、容量プールの容量が使用されます。</block>
  <block id="0031911d8ba66a79d06b9819afd4f082" category="list-text">REST または Azure CLI を使用してクローンボリュームを削除すると、追加のコストを回避できます（容量プールの拡張が必要になった場合）。</block>
  <block id="cb4d46fdcb0881652013c495d90ae732" category="section-title">ハイブリッドストレージの選択肢</block>
  <block id="e6a1767911a937e11cc1750fcc4256c3" category="paragraph">ネットアップでは、 SQL Server 可用性グループのすべてのノードに同じストレージを使用することを推奨していますが、場合によっては複数のストレージオプションを使用できます。このシナリオは、 Azure NetApp Files で、 AOAG のノードが Azure NetApp Files SMB ファイル共有に接続され、 2 つ目のノードが Azure Premium ディスクに接続されている場合に発生します。このような場合は、 Azure NetApp Files SMB 共有にユーザデータベースのプライマリコピーが保持され、 Premium ディスクがセカンダリコピーとして使用されていることを確認してください。</block>
  <block id="009d3d51226fdccd09052934b65100db" category="list-text">このような環境でフェイルオーバーの問題を回避するには、 SMB ボリュームで継続的可用性が有効になっていることを確認してください。継続的可用性属性を持たないストレージレイヤでバックグラウンドでメンテナンスを実施すると、データベースで障害が発生する可能性があります。</block>
  <block id="918e9d895272e6a326c6585e05ae4c08" category="list-text">データベースのプライマリコピーは Azure NetApp Files SMB ファイル共有に保持します。</block>
  <block id="1a5c3601eda1cd38072323e418968743" category="section-title">ビジネス継続性</block>
  <block id="064ea84d2e6072b28bfd7a8b36aed3db" category="paragraph">ディザスタリカバリは、一般にあらゆる導入で後回しになっています。ただし、ビジネスへの影響を回避するために、設計および導入の初期段階でディザスタリカバリに対処する必要があります。Azure NetApp Files では、クロスリージョンレプリケーション（ CRR ）機能を使用して、予期しないリージョンの停止を処理するためにブロックレベルでボリュームデータをペアリングされたリージョンにレプリケートできます。CRR 対応のデスティネーション・ボリュームは読み取り処理に使用できるため、災害復旧シミュレーションに最適です。さらに 'CRR デスティネーションを最小のサービス・レベル（ Standard など）で割り当てることにより ' 全体的な TCO を削減できますフェイルオーバーが発生した場合はレプリケーションを解除することで対応するボリュームを読み取り / 書き込み可能にすることができます。また、動的なサービスレベル機能を使用してディザスタリカバリコストを大幅に削減することで、ボリュームのサービスレベルを変更することもできます。これは Azure NetApp Files 独自の機能で、 Azure 内でブロックレプリケーションを実行します。</block>
  <block id="86258094262f66b30d10068d1d9c29d4" category="section-title">長期的な Snapshot コピーのアーカイブ</block>
  <block id="65bd92a3b5fcfea7efeb973a0a2483d8" category="inline-link">AzCopy</block>
  <block id="e6bf440e9e7e787ce92e6f8661daf9e9" category="paragraph">多くの組織では、 Snapshot データをデータベースファイルから長期的に保持することが必須のコンプライアンス要件として求められています。このプロセスはこの HLD では使用されませんが、を使用した単純なバッチスクリプトを使用すると簡単に実行できます<block ref="f326c7b047cd071718d141dba06c550f" category="inline-link-rx"></block> をクリックして Azure BLOB コンテナに Snapshot ディレクトリをコピーします。スケジュールされたタスクを使用して、特定のスケジュールに基づいてバッチスクリプトを実行できます。このプロセスは簡単で、次の手順で構成されます。</block>
  <block id="dfdc6514d824f948d82ee2ac6515603f" category="list-text">AzCopy V10 実行ファイルをダウンロードします。これは 'exe` ファイルであるため ' インストールするものはありません</block>
  <block id="5434519f37049a19d388fb3edabd08f7" category="list-text">コンテナレベルで適切な権限を持つ SAS トークンを使用して 'AzCopy を承認します</block>
  <block id="73facdc1e77927e1c0d4c2f66c6fedf9" category="list-text">AzCopy が承認されると、データ転送が開始されます。</block>
  <block id="a2c31034ac77c6ad0ce6dae2a7882d73" category="list-text">バッチファイルでは、 SAS トークンに表示される % 文字をエスケープする必要があります。そのためには、 SAS トークン文字列で既存の % 文字の横に % 文字を追加します。</block>
  <block id="0eed577952fd376af1fa48aa241e3df7" category="inline-link">セキュアな転送が必要です</block>
  <block id="b2f731ca364e7df30cd69650bdc19d46" category="list-text">。<block ref="7e9be5c7f255e20f7f3a81046108dcad" category="inline-link-rx"></block> ストレージアカウントの設定によって、ストレージアカウントへの接続が Transport Layer Security （ TLS ）で保護されるかどうかが決まります。この設定はデフォルトで有効になっています。次のバッチスクリプト例は、 Snapshot コピーディレクトリから指定された BLOB コンテナにデータを再帰的にコピーします。</block>
  <block id="f2c225fb316953652d9040f71e76717c" category="paragraph">PowerShell で次のコマンドが実行されます。</block>
  <block id="e7cc24e4ddff469c6304653aea869597" category="list-text">長期保持用の同様のバックアップ機能も、近日中に Azure NetApp Files で使用可能になります。</block>
  <block id="03930ecbc2c505278298d571631e23bb" category="list-text">バッチスクリプトは、任意のリージョンの BLOB コンテナにデータをコピーする必要がある場合に使用できます。</block>
  <block id="a39ae09f8be4327fc176cfeb76a0e366" category="section-title">コストの最適化</block>
  <block id="07ecdeff0f5a70968e882eb4ace6f576" category="paragraph">ボリュームの形状変更とサービスレベルの動的変更をデータベースに対して完全に透過的に行うことで、 Azure NetApp Files は Azure で継続的なコスト最適化を実現します。この HLD では、この機能を使用して、ワークロードの急増に対処するためにストレージを追加でオーバープロビジョニングすることを回避しています。</block>
  <block id="bf511e8b678dd2ecee162930e6c8c9e6" category="paragraph">ボリュームのサイズ変更は、 Azure 機能と Azure アラートログを組み合わせて作成すると簡単に実行できます。</block>
  <block id="75b7d47e2aa19968e092ab7ddb108a3f" category="summary">オールクラウドにも、ストレッチデータベースを使用したハイブリッドクラウドにも、 Azure NetApp Files は、データベースワークロードの導入と管理に最適なオプションを提供します。データ要件はアプリケーションレイヤとシームレスに連携し、 TCO を削減します。</block>
  <block id="d8d2e6021f496c4e4a31a3d5d51c0a97" category="paragraph">このドキュメントでは、 Azure NetApp Files を使用した Microsoft SQL Server 環境の計画、設計、最適化、拡張に関する推奨事項について説明します。この推奨事項は、実装によって大きく異なる場合があります。適切な解決策は、導入の技術的な詳細と、プロジェクトの背景にあるビジネス要件の両方によって異なります。</block>
  <block id="56925354251a536c23de1174d3001595" category="section-title">重要なポイント</block>
  <block id="033e6e43f2148e187e072dc7e6585802" category="paragraph">本ドキュメントの主な内容は次のとおりです。</block>
  <block id="b2b363e230905b04f6e9c7263aa93f42" category="list-text">Azure NetApp Files を使用して、 SQL Server クラスタのデータベースおよびファイル共有監視をホストできるようになりました。</block>
  <block id="4d6ec76303888bc681d543d1f4593c55" category="list-text">アプリケーションの応答時間を短縮し、 99.9999% の可用性を実現して、必要なときに必要な場所で SQL Server データにアクセスできるようにします。</block>
  <block id="408e4b7fbec4ba85e097b9393d2b27a7" category="list-text">シンプルで瞬時のサイズ変更により、 SQL Server の導入と、 RAID ストライピングなどの継続的な管理の全体的な複雑さを緩和できます。</block>
  <block id="41642b38214243168d907d92759dde36" category="list-text">インテリジェントな運用機能を利用すれば、 SQL Server データベースを数分で導入し、開発サイクルを短縮できます。</block>
  <block id="61a32d891a5f7bca599a014bc56eec61" category="list-text">Azure クラウドが移行先である場合、最適化された導入に最適なストレージ解決策は Azure NetApp Files です。</block>
  <block id="4db58285a0e634acd6843c40f7a6f4e0" category="paragraph">このドキュメントに記載されている情報の詳細については、次の Web サイトのリンクを参照してください。</block>
  <block id="d53a72004974ee8431ee292856c0bba3" category="list-text">Azure NetApp Files を使用した解決策アーキテクチャ</block>
  <block id="653ba0610595f0695c3ceb2c59afed59" category="inline-link"><block ref="653ba0610595f0695c3ceb2c59afed59" category="inline-link-rx"></block></block>
  <block id="d5ec9321fb49816034de6b296ef6baa2" category="paragraph"><block ref="d5ec9321fb49816034de6b296ef6baa2" category="inline-link-rx"></block></block>
  <block id="ba110408cece764b57b56f1129b3ba2e" category="list-text">Azure NetApp Files for SQL Server の導入のメリット</block>
  <block id="62b5dbc436fc2540c46476bd8e484c11" category="inline-link"><block ref="62b5dbc436fc2540c46476bd8e484c11" category="inline-link-rx"></block></block>
  <block id="44594562b4f528fe8d864bd3f48ddff6" category="paragraph"><block ref="44594562b4f528fe8d864bd3f48ddff6" category="inline-link-rx"></block></block>
  <block id="7aa91f5f0414f1488ce2f5324e63d12e" category="list-text">『 SQL Server on Azure Deployment Guide Using Azure NetApp Files 』を参照してください</block>
  <block id="9021ea474df74856b145a78c58c35e05" category="inline-link"><block ref="9021ea474df74856b145a78c58c35e05" category="inline-link-rx"></block></block>
  <block id="52a5313d9aca117b5d167e6be79c5bc7" category="paragraph"><block ref="52a5313d9aca117b5d167e6be79c5bc7" category="inline-link-rx"></block></block>
  <block id="49217b0d4a68c88899c93d24203a34b4" category="list-text">耐障害性、高可用性、 Azure NetApp Files との耐障害性を備えています</block>
  <block id="9e5e063336d276080a054861016aadd8" category="inline-link"><block ref="9e5e063336d276080a054861016aadd8" category="inline-link-rx"></block></block>
  <block id="7ff89d0ad939652d37cbab9b6f420f65" category="paragraph"><block ref="7ff89d0ad939652d37cbab9b6f420f65" category="inline-link-rx"></block></block>
  <block id="a2810b66f557bf43f1c602ecfe7f52b1" category="summary">このドキュメントでは、 Azure NetApp Files で Azure 仮想マシンを利用して SQL Server Always On 可用性グループ（ AOAG ）をリアルタイムで導入する方法について説明します。</block>
  <block id="0ecccb1d48727b6da357728efe7b6375" category="doc">TR-4877 ：『 SQL Server on Azure NetApp Files - Real Deployment View 』</block>
  <block id="4eae423bbc6520b4a8fa4d0d4de28b8a" category="paragraph">ネットアップ、 Niyaz Mohamed</block>
  <block id="8ae2b9aab28b6c00df7581f99f9211ef" category="paragraph">IT 組織は絶えず変化しています。Gartner のレポートでは、すべてのデータベースのほぼ 75% が 2022 年までにクラウドベースストレージが必要になると報告されています。Microsoft SQL Server は、業界をリードするリレーショナルデータベース管理システム（ RDBMS ）として、 Windows プラットフォームで設計されたアプリケーションや組織に最適です。エンタープライズリソースプランニング（ ERP ）から分析、コンテンツ管理まで、 SQL Server に依存します。SQL Server は、大規模なデータセットを管理する方法を変革し、アプリケーションを強化して、スキーマやクエリのパフォーマンスの要求に対応できるようにしました。</block>
  <block id="eae371fd2d593d80849fab02c4e8b90b" category="paragraph">ほとんどの IT 組織は、クラウドファーストのアプローチを採用しています。変革フェーズにあるお客様は、現在の IT 環境を評価し、評価と調査の演習に基づいてデータベースワークロードをクラウドに移行します。柔軟性 / バースト性、データセンターの終了、データセンターの統合、サポート終了シナリオ、合併、合併など、お客様をクラウドへ移行させる要因には次のものがあります。 買収など。移行の理由は、組織ごとの優先事項と、それぞれのビジネスの優先事項によって異なります。クラウドに移行する際には、 SQL Server データベースクラウドの導入を有効に活用するために、適切なクラウドストレージを選択することが非常に重要です。</block>
  <block id="f9468c81b3d59ac0030570c4f58e95f1" category="section-title">ユースケース</block>
  <block id="cf8b0bda1e058c1f8383f434c4da9b71" category="paragraph">SQL Server 環境を Azure に移行し、 SQL Server を Azure の膨大なプラットフォームサービス（ PaaS ）機能（ Azure Data Factory 、 Azure IoT Hub 、 Azure Machine Learning など）と統合することで、デジタル変革をサポートするための大きなビジネス価値が生まれます。また、クラウドを採用することで、各事業部門は、 CAPEX モデルや従来のプライベートクラウドモデルに頼らずに、生産性に重点を置き、新機能や拡張機能（ DevTest ユースケース）をより迅速に提供することができます。このドキュメントでは、 Azure NetApp Files で Azure 仮想マシンを利用して SQL Server Always On 可用性グループ（ AOAG ）をリアルタイムで導入する方法について説明します。</block>
  <block id="239a02aaaf9289a3093f682835f65f88" category="paragraph">Azure NetApp Files は、継続的な可用性が確保されたファイル共有を備えたエンタープライズクラスのストレージを提供しますSQL Server の本番用データベースの SMB ファイル共有には、継続的可用性を備えた共有が必要です。これにより、コントローラのアップグレードや障害などのシステム停止を伴うシナリオにおいて、ノードは常にデータベースストレージにアクセスできます。継続的な可用性が確保されたファイル共有により、ストレージノード間でデータをレプリケートする必要がなくなります。Azure NetApp Files は、 SMB 3.0 のスケールアウト、永続的ハンドル、透過的なフェイルオーバー機能を使用して、計画的停止と計画外停止の間のノンストップオペレーション（ NDO ）をサポートします。これには、多くの管理タスクが含まれます。</block>
  <block id="f47a858d79de9725a0d6881541748e9b" category="paragraph">クラウドへの移行を計画する場合は、常に最適な使用方法を評価する必要があります。アプリケーション移行で最も一般的かつ簡単なアプローチはリホスト（リフトアンドシフトとも呼ばれます）です。このドキュメントの例では、リホスト方法を使用しています。Azure NetApp Files を使用した Azure 仮想マシン上の SQL Server では、オンプレミスのハードウェアを管理しなくても、クラウド上で SQL Server のフルバージョンを使用できます。SQL Server 仮想マシン（ VM ）は、従量課金制でもライセンスコストを簡易化し、開発、テスト、環境の更新シナリオ向けに柔軟性とバースト性の高い機能を提供します。</block>
  <block id="64899c745691f41e5b1dc01d3a4487d2" category="summary">このセクションでは、クラウドで Azure NetApp Files を SQL Server に使用する場合に考慮する必要があるさまざまな問題について説明します。</block>
  <block id="bb4695a70b92668f0a7927d04580db60" category="doc">考慮すべき要因</block>
  <block id="4dd91c7652639dacea041fe6033e2627" category="section-title">VM パフォーマンス</block>
  <block id="e6ac657ee6eac68b739c5cc437863922" category="inline-link">メモリの最適化</block>
  <block id="68e5d4a238cdfe033afa141123484499" category="paragraph">パブリッククラウドのリレーショナルデータベースのパフォーマンスを最適化するには、適切な VM サイズを選択することが重要です。Microsoft では、オンプレミスサーバ環境の SQL Server と同じデータベースパフォーマンス調整オプションを引き続き使用することを推奨しています。使用<block ref="187f54af8632f4f6696d6052e8b74aec" category="inline-link-rx"></block> SQL Server ワークロードのパフォーマンスを最適化するための VM サイズ。既存の導入環境のパフォーマンスデータを収集し、適切なインスタンスを選択しながら RAM と CPU の利用率を確認します。ほとんどの導入環境では、 D 、 E 、または M シリーズのいずれかを選択できます。</block>
  <block id="8b2db846b8ed65b2919d93a68b819a43" category="list-text">SQL Server ワークロードのパフォーマンスを最大限に高めるには、メモリに最適化された VM サイズを使用します。</block>
  <block id="32a3b4d7b7e6cf1ecde48636119e0288" category="list-text">ネットアップと Microsoft は、適切なメモリと VCORE の比率に基づいてインスタンスタイプを選択する前に、ストレージのパフォーマンス要件を特定することを推奨しています。これは、適切なネットワーク帯域幅を備えた低いインスタンスタイプを選択して、 VM のストレージスループットの制限に克服するのにも役立ちます。</block>
  <block id="0abdff1d9e33eca61c14ccafe8012cd5" category="section-title">VM の冗長性</block>
  <block id="9fecd525b2d9ad39ac38bbfc4d05ee17" category="inline-link">可用性セット</block>
  <block id="26075dbb6cfad683e0d9bd0d29c570b8" category="inline-link">可用性ゾーン</block>
  <block id="e936e004eab3eccfc1e7f46a3187dfd1" category="paragraph">冗長性と高可用性を高めるには、 SQL Server VM を同じにする必要があります<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> または別のものです<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>。Azure VM を作成する場合は、アベイラビリティセットとアベイラビリティゾーンのどちらかを設定する必要があります。 Azure VM を両方に含めることはできません。</block>
  <block id="94eeeae1e60f97a446e8c4f69d6d6f43" category="paragraph">高可用性を実現するには、 SQL Server AOAG または Always On フェイルオーバークラスタインスタンス（ FCI ）を構成することを推奨します。AOAG の場合、これには仮想ネットワーク内の Azure Virtual Machine 上の SQL Server の複数のインスタンスが含まれます。データベースレベルで高可用性が必要な場合は、 SQL Server 可用性グループを設定することを検討してください。</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">ストレージ構成</block>
  <block id="fa32aac4116ce1980c311f004157a133" category="paragraph">Microsoft SQL Server では、ストレージオプションとして SMB ファイル共有を導入できます。SQL Server 2012 以降、システムデータベース（マスター、モデル、 msdb 、または tempdb ）、 およびユーザデータベースは、ストレージオプションとして Server Message Block （ SMB ；サーバメッセージブロック）ファイルサーバとともにインストールできます。この環境は、 SQL Server のスタンドアロンと SQL Server FCI の両方に対応しています。</block>
  <block id="250548ef00796e6a203215b1d550bb0d" category="admonition">SQL Server データベース用のファイル共有ストレージでは、継続的可用性がサポートされている必要があります。これにより、ファイル共有データに中断なくアクセスできます。</block>
  <block id="45a6af9c92529e3da9ccdbeae9d692ac" category="paragraph">Azure NetApp Files は、あらゆる要求の厳しいワークロードに対応できる高性能なファイルストレージを提供し、ブロックストレージソリューションに比べて SQL Server の TCO を削減します。ブロックストレージでは、 VM の I/O およびディスク処理の帯域幅に制限があり、ネットワーク帯域幅の制限だけが Azure NetApp Files に適用されます。つまり、 Azure NetApp Files には VM レベルの I/O 制限は適用されません。これらの I/O 制限がない場合、 Azure NetApp Files に接続された小規模な VM で SQL Server を実行することも、はるかに大規模な VM で SQL Server を実行することもできます。Azure NetApp Files は、コンピューティングとソフトウェアのライセンスコストを削減することで、 SQL Server の導入コストを削減します。Azure NetApp Files for SQL Server 環境を使用することによるコスト分析とパフォーマンス上のメリットの詳細については、を参照してください<block ref="458fda910151e8d66385b2aabb6cd60e" category="inline-link-rx"></block>。</block>
  <block id="9d2b7eb8bc76e60b0d9cd237d67a34fb" category="paragraph">Azure NetApp Files for SQL Server を使用する利点は次のとおりです。</block>
  <block id="8ee22743237d82e9adc18a596977a138" category="list-text">Azure NetApp Files を使用すると、インスタンスを小さくしてコンピューティングコストを削減できます。</block>
  <block id="3de639403ea86ae87a5883d359deb4ab" category="list-text">また、 Azure NetApp Files はソフトウェアライセンスコストを削減し、全体的な TCO を削減します。</block>
  <block id="46790c8fe72176f6262b4b5531482ee5" category="list-text">ボリュームを再構築して動的なサービスレベル機能を利用すると、安定状態のワークロードのサイジングを行い、オーバープロビジョニングを回避することでコストを最適化できます。</block>
  <block id="860d93b2ef30525111fa6440bf4d5bd7" category="list-text">冗長性と高可用性を高めるには、 SQL Server VM を同じにする必要があります<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> または違う<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>。ユーザ定義のデータファイルが必要な場合は、ファイルパスの要件を考慮してください。その場合は、 SQL FCI over SQL AOAG を選択します。</block>
  <block id="c6fbfcd868e29e37e88eaeff82a7f430" category="inline-link">\\ANFSMB-b4ca.anf.test\sqldb および \\ANFSMB-b4ca.anf.test\sqldb\</block>
  <block id="e2bed4e218692d056237b3ae3d24293c" category="list-text">次の UNC パスがサポートされます。<block ref="cb8cdd6ee3ebeed12086142f1a66cc3e" category="inline-link-rx"></block>。</block>
  <block id="0b4d3828f5dae91cd27e48bffa786d91" category="list-text">ループバック UNC パスはサポートされていません。</block>
  <block id="db3d2f4f54b992af225801eb51ea7387" category="list-text">サイジングには、オンプレミス環境の履歴データを使用します。OLTP ワークロードの場合は、ワークロードの平均時間とピーク時間、ディスク読み取り回数 / 秒、ディスク書き込み回数 / 秒のパフォーマンスカウンタを使用して、ターゲット IOPS とパフォーマンス要件を一致させます。Data Warehouse および Reporting のワークロードの場合は、ワークロードの平均時間とピーク時間、およびディスクの読み取りバイト数 / 秒とディスクの書き込みバイト数 / 秒を使用して、ターゲットのスループットを調整します平均値は、ボリュームの形状変更機能と組み合わせて使用できます。</block>
  <block id="da3259c6aa3dafdc8ca15c687022a5cd" category="section-title">継続的可用性を備えた共有を作成</block>
  <block id="f7ee3eee4fa679986e37911272d13a29" category="inline-link">継続的可用性を備えた共有を作成しています</block>
  <block id="de7d92d6f4ac1f140ac05886ec017f09" category="paragraph">Azure ポータルまたは Azure CLI を使用して、継続的可用性を備えた共有を作成する。ポータルで、 [ 継続的な可用性を有効にする ] プロパティオプションを選択します。Azure CLI では、「 azz netappfiles volume create with the sm-continuously-available - AVL 」オプションを「 $True 」に設定して、共有を継続的可用性を備えた共有として指定します。継続的可用性を有効にした新しいボリュームの作成の詳細については、を参照してください<block ref="86e4b436e8054cc83fccec640f98e218" category="inline-link-rx"></block>。</block>
  <block id="9a3932b7bdfdbb892087fd595ec7acb9" category="list-text">次の図に示すように、 SMB ボリュームの継続的可用性を有効にします。</block>
  <block id="c012fe8c05a3d9875a4f87cee09d1ca9" category="list-text">管理者以外のドメインアカウントを使用する場合は、そのアカウントに必要なセキュリティ権限が割り当てられていることを確認してください。</block>
  <block id="762783478495f0889d01a59db256f92c" category="list-text">共有レベルで適切な権限を設定し、適切なファイルレベルの権限を設定します。</block>
  <block id="bfb74db6a55528f52e8ecb83a507a043" category="inline-link">既存の SMB ボリュームを継続的可用性を使用するように変換します</block>
  <block id="3cad4a4fcd378074292bfc2ff45fd4ca" category="list-text">既存の SMB ボリュームでは継続的可用性プロパティを有効にできません。既存のボリュームを変換して継続的な可用性が確保された共有を使用するには、 NetApp Snapshot テクノロジを使用します。詳細については、を参照してください<block ref="25dc0603f84029cfd15a97a37903a54c" category="inline-link-rx"></block>。</block>
  <block id="015dd90c833178044ff327aee63f72ec" category="paragraph"><block ref="015dd90c833178044ff327aee63f72ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">パフォーマンス</block>
  <block id="ee38206503545cf54ad072dee7f8ab1a" category="paragraph">Azure NetApp Files は、 Standard （テラバイトあたり 16mbps ）、 Premium （テラバイトあたり 64MBps ）、 Ultra （テラバイトあたり 128MBps ）の 3 つのサービスレベルをサポートします。データベースワークロードのパフォーマンスを最適化するには、適切なボリュームサイズをプロビジョニングすることが重要です。Azure NetApp Files では、ボリュームのパフォーマンスとスループット制限は次の要素の組み合わせに基づいて決まります。</block>
  <block id="b87f5218989e854f2889f939a4e2ec06" category="list-text">ボリュームが属する容量プールのサービスレベル</block>
  <block id="9320cce40e9ab4d677bfcc78eddc64d5" category="list-text">ボリュームに割り当てられているクォータ</block>
  <block id="2d98af90367bed299b95066a85be0a17" category="list-text">容量プールのサービス品質（ QoS ）タイプ（ auto または manual ）</block>
  <block id="a6f08c2897faaf4d449d71d87f473ff1" category="inline-link">Azure NetApp Files のサービスレベル</block>
  <block id="ac56170d8576092b90989d467f2d383e" category="paragraph">詳細については、を参照してください<block ref="1e8ed0f384e427209ce2e9dfbaed249d" category="inline-link-rx"></block>。</block>
  <block id="79bcc7c0be7625b4b6b95ac8189ec45e" category="paragraph"><block ref="79bcc7c0be7625b4b6b95ac8189ec45e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">パフォーマンスの検証</block>
  <block id="af3948d0fe6860f3a865cd04abebc009" category="inline-link">SQL Server Storage Benchmark （ SB ）ツール</block>
  <block id="01384acc34d886b9383610a7494ca75a" category="paragraph">あらゆる導入同様、 VM とストレージをテストすることが重要です。ストレージの検証には、 HammerDB 、 Apploader 、などのツールを使用します<block ref="df8d6ca8d2831e94c0812b2b971f8958" category="inline-link-rx"></block>、または適切な読み取り / 書き込み混在の任意のカスタムスクリプトまたは fio を使用する必要があります。ただし、 SQL Server のワークロードのほとんどは、ビジー状態の OLTP ワークロードでも、読み取りが 80~90% 、書き込みが 10~20% 近くになることに注意してください。</block>
  <block id="10fde396dd4a669ec17689dd7cf8b599" category="paragraph">パフォーマンスを確認するために、 Premium サービスレベルを使用してボリュームに対してクイックテストを実行しました。このテストでは、ボリュームサイズを 100GB から 2TB にオンザフライで拡張しました。アプリケーションへのアクセスを中断することなく、データの移行もゼロでした。</block>
  <block id="6fab14b7b6a90422e865a3b09497edaa" category="paragraph"><block ref="6fab14b7b6a90422e865a3b09497edaa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eedfe317eed7692e9d95ba36177a80e9" category="paragraph">ここでは、 HammerDB を使用して導入した、リアルタイムのパフォーマンステストの別の例を示します。このテストでは、 vCPU 8 個、 500GB Premium SSD 、 500GB SMB Azure NetApp Files ボリュームを含む小規模インスタンスを使用しました。HammerDB は、 80 のウェアハウスと 8 人のユーザで構成されています。</block>
  <block id="c365893719ad3de45f14fa9c19408eca" category="paragraph">次のグラフから、 Azure NetApp Files では、 1 分あたりのトランザクション数が 2.6x で、同等のサイズのボリューム（ 500GB ）を使用した場合のレイテンシが 4 分の 1 に削減されたことがわかります。</block>
  <block id="d50d666921da97fdc14e35f752474e41" category="paragraph">さらに、 vCPU が 32 個、 Azure NetApp Files が 16TB の大容量インスタンスへのサイズ変更によって、テストを実施しました。1 分あたりのトランザクション数は大幅に増加し、レイテンシは常に 1 ミリ秒に抑えられました。HammerDB は、このテストで 80 個のウェアハウスと 64 人のユーザで構成されました。</block>
  <block id="3b38e0407e747349840c72259c5da930" category="paragraph"><block ref="3b38e0407e747349840c72259c5da930" category="inline-image-macro-rx" type="image"></block></block>
  <block id="892725223bbd64ebec595545eeaf8c28" category="paragraph">Azure NetApp Files を使用すると、ボリュームのサイズを透過的に無停止で変更でき、ダウンタイムやアプリケーションへの影響なしでサービスレベルを変更できます。これは、動的なコスト管理が可能な独自の機能で、ピーク時の指標を使用してデータベースのサイジングを行う必要を回避できます。安定した状態のワークロードを利用できるため、初期投資が不要になります。ボリュームの形状変更とサービスレベルの動的変更を使用すると、データアクセスを維持しながら、 I/O を一時停止することなく、 Azure NetApp Files ボリュームの帯域幅とサービスレベルをほぼ瞬時にオンデマンドで調整できます。</block>
  <block id="44aaafbc17f2a4fcbd6d52e1c8ee0cae" category="paragraph">LogicApp や関数などの Azure PaaS ソリューションを使用すると、特定の webhook または alert ルールトリガーに基づいてボリュームのサイズを簡単に変更し、ワークロードの要件を満たしながらコストを動的に処理できます。</block>
  <block id="d613d5e1ef7a7f52eed191ef1066a08a" category="paragraph">たとえば、安定した動作に 250Mbps のデータを必要とするデータベースがありますが、 400Mbps のピークスループットも必要とします。この場合、安定したパフォーマンスの要件を満たすために、 Premium サービスレベルに 4TB ボリュームを追加して導入する必要があります。ピーク時のワークロードに対処するには、 Azure の機能を使用して特定の期間でボリュームサイズを 7TB に増やしてから、導入コストを抑えるためにボリュームのサイズを縮小します。この構成では、ストレージのオーバープロビジョニングを回避できます。</block>
  <block id="760b7d532df381143dc946fd59bf0b62" category="sidebar">Azure NetApp Files 上の SQL Server</block>
  <block id="61def2ac347af2f10fd60cd67052a311" category="sidebar">リファレンス・デザイン（リアルタイムの高レベル設計）</block>
  <block id="3699cb747ce71b2fed488fef61ad35be" category="inline-link-macro">ワークロードの移行 - ネットアップを使用した Red Hat OpenShift</block>
  <block id="4c37a5afd480a0042f69d7628cadd57d" category="summary">ネットアップを使用した Red Hat OpenShift での Kubernetes 向けの高度なクラスタ管理</block>
  <block id="43288d8129021b1fe8b4bc6784e65b32" category="doc">機能：ネットアップを使用した Red Hat OpenShift での Kubernetes 向けの高度なクラスタ管理</block>
  <block id="d10b633b8bd8d022c66a52d93e0ed6ce" category="section-title">クラスタのライフサイクル管理</block>
  <block id="8b9449bdfc859a900fc4da7c79420145" category="paragraph">さまざまな OpenShift クラスタを管理するには、クラスタを作成するか、 Advanced Cluster Management にインポートします。</block>
  <block id="0becde0fcfda03aec9c722d042326324" category="list-text">新しい OpenShift クラスタを作成するには、次の手順を実行します。</block>
  <block id="50dfc508091b37338da8357e63e6a405" category="image-alt">プロバイダ接続を追加します</block>
  <block id="2984cab36bd51d5446963e671e808f5d" category="image-alt">クラスタを追加</block>
  <block id="e6d9a6b38dd36fd9870260249ba5fc1f" category="list-text">既存のクラスタをインポートするには、次の手順を実行します。</block>
  <block id="9a618414b83afe67c19abcf935be6dbd" category="image-alt">既存のクラスタをインポートする</block>
  <block id="c812d1382d834648706b3bf1e6848135" category="list-text">複数のクラスタを作成してインポートしたら、 1 つのコンソールからクラスタを監視および管理できます。</block>
  <block id="068e5ec1cc0eaa7c2596be7eb1b40194" category="inline-link-macro">次の項目：機能 - アプリケーションライフサイクル管理。</block>
  <block id="0405bd6ea905b8d563fd501d933a3e51" category="paragraph"><block ref="0405bd6ea905b8d563fd501d933a3e51" category="inline-link-macro-rx"></block></block>
  <block id="31fd0c2c8d388a4cd2c6459234743476" category="section-title">オブザーバビリティ</block>
  <block id="7a6ccefec75a946583cffdd0a8a47e09" category="image-alt">オブザーバビリティホームページ</block>
  <block id="4a973ae1a908770e354f949d3c0592f8" category="image-alt">ポッドを確認します</block>
  <block id="8a373f777de729c082b5be2d80b7eca6" category="image-alt">ノードを監視します</block>
  <block id="2ececa2c251a851a85e976daae558c81" category="image-alt">クラスタを確認します</block>
  <block id="a883982d5f8961021329c238318d4e2b" category="inline-link-macro">次の手順：機能 - リソースを作成します。</block>
  <block id="5ca146f2101c14a961df161060f86cb9" category="paragraph"><block ref="5ca146f2101c14a961df161060f86cb9" category="inline-link-macro-rx"></block></block>
  <block id="de59be6e44d20d9dd12412571b745c5f" category="section-title">アプリケーションのライフサイクル管理</block>
  <block id="fa19c463235a810b3a93333d6ee51d6c" category="paragraph">アプリケーションを作成して一連のクラスタ全体で管理するには、</block>
  <block id="6b41f909eb299f214abfb15580583456" category="image-alt">アプリケーションを作成します</block>
  <block id="bcb3e5b76f189a87ea350550f86de83f" category="list-text">アプリケーションコンポーネントがインストールされると、アプリケーションがリストに表示されます。</block>
  <block id="d70fc022d09a33f4044c81cd670a71b6" category="image-alt">アプリケーションリスト</block>
  <block id="672d326704c3be4bebf6c816a48495e7" category="list-text">これで、アプリケーションをコンソールから監視および管理できるようになります。</block>
  <block id="0787d747a308cc786b50363313ccf714" category="inline-link-macro">次のステップ：機能 - ガバナンスとリスク</block>
  <block id="f4c7ffc89dab76d5a6dccad54114c204" category="paragraph"><block ref="f4c7ffc89dab76d5a6dccad54114c204" category="inline-link-macro-rx"></block></block>
  <block id="06fdae3f02fee5cbe172f1574564c925" category="doc">Kubernetes 向けの高度なクラスタ管理：ネットアップを使用した Red Hat OpenShift</block>
  <block id="30c15b5a84f4fb26cd25b38dc787b22d" category="paragraph">コンテナ化されたアプリケーションを開発環境から本番環境に移行する際、多くの組織では、そのアプリケーションのテストと導入をサポートするために複数の Red Hat OpenShift クラスタが必要になります。この機能を利用することで、多くの組織は、 OpenShift クラスタ上で複数のアプリケーションやワークロードをホストしています。そのため、組織ごとにクラスタのセットを管理する必要があり、 OpenShift の管理者は、複数のオンプレミスデータセンターとパブリッククラウドにまたがるさまざまな環境で複数のクラスタを管理および管理するという新たな課題に直面する必要があります。これらの課題に対処するために、 Red Hat は Kubernetes 向けの高度なクラスタ管理機能を導入しました。</block>
  <block id="a7516c278242a08b85090e24cbf67218" category="paragraph">Red Hat OpenShift クラスタに Red Hat Advanced Cluster Management for Kubernetes をアドオンとしてインストールし、このクラスタをすべての処理の中央コントローラとして使用します。このクラスタはハブクラスタと呼ばれ、ユーザが Advanced Cluster Management に接続するための管理プレーンを公開します。Advanced Cluster Management コンソールからインポートまたは作成されたその他のすべての OpenShift クラスタは、ハブクラスタによって管理され、管理対象クラスタと呼ばれます。Klusterlet というエージェントを管理対象クラスタにインストールし、ハブクラスタに接続し、クラスタライフサイクル管理、アプリケーションライフサイクル管理、オブザーバビリティ、およびセキュリティコンプライアンスに関連するさまざまなアクティビティの要求を処理します。</block>
  <block id="b1000f23e43dfac19b53c74d7ebe66c8" category="image-alt">ACM アーキテクチャ</block>
  <block id="a376445fd812a7fa27714e6b11bc6163" category="paragraph">詳細については、のドキュメントを参照してください<block ref="50c0dc50e188cf3a7847d9a813fd829e" category="inline-link-rx"></block>。</block>
  <block id="a99137a02f570225903b02b175e289a4" category="paragraph"><block ref="a99137a02f570225903b02b175e289a4" category="inline-link-macro-rx"></block></block>
  <block id="7c613b296892d4712b9041d3081282f8" category="summary">ネットアップを使用した Red Hat OpenShift での Kubernetes 向けの高度なクラスタ管理。</block>
  <block id="78e1aefe2bbb2518f1156636e761e479" category="paragraph">OpenShift クラスタに Kubernetes 向けの高度なクラスタ管理をインストールするには、次の手順を実行します。</block>
  <block id="b17056cdbd9ec695d4348e1ad799ace4" category="list-text">OpenShift クラスタをハブクラスタとして選択し、 cluster-admin 権限でログインします。</block>
  <block id="2e5d3941e033e96d5317cc2bbd1da914" category="image-alt">ACM タイル</block>
  <block id="cc5a9dd5971b8369354db684e5dbfe2b" category="image-alt">ACM タイルの詳細</block>
  <block id="72b342ddabad6a9ec11df82389c40b88" category="image-alt">ACM オペレータタイルを取り付ける</block>
  <block id="64524f91c2fdfcd54b4bbcab35392908" category="image-alt">ACM オペレータのインストールが進行中です</block>
  <block id="e0d84ec6a5b8f92909a7a3bef11455c1" category="image-alt">ACM オペレータのマルチクラスターハブ</block>
  <block id="344f0cb43d1b2e7a719bea808fe7c5bf" category="image-alt">マルチクラスタハブ画面を作成します</block>
  <block id="851548d1ad843a23609f325e8b54e72d" category="image-alt">ACM オペレータが取り付けられている</block>
  <block id="c7aa79f0c31ac15d728ee47c7e6eaee2" category="image-alt">マルチクラスタハブ対応</block>
  <block id="f761fad3f1c25e94d5f46ebd9e23a901" category="image-alt">ACM コンソールルート</block>
  <block id="4488e277b96ae08def5eb77c2d8c6e74" category="inline-link-macro">次のページ：機能 - クラスタのライフサイクル管理。</block>
  <block id="8a4d50965d8a3c708bdb16a716d64246" category="paragraph"><block ref="8a4d50965d8a3c708bdb16a716d64246" category="inline-link-macro-rx"></block></block>
  <block id="ddb9608f0f25d56d00a539a63333efa0" category="list-text"><block ref="ddb9608f0f25d56d00a539a63333efa0" category="inline-link-macro-rx"></block></block>
  <block id="86c2cc4630e619e2c08c32f54e844297" category="section-title">複数のクラスタにリソースを作成する</block>
  <block id="24800112d59462f8ea9ff03f5dd456a7" category="image-alt">リソースを作成する</block>
  <block id="5568d55567785f154c987872c1684bfa" category="doc">ワークロードの移行：ネットアップを使用した Red Hat OpenShift</block>
  <block id="f41043c73a62a435944d8abfb45094cb" category="list-text">管理対象クラスタの Red Hat OpenShift クラスタ（バージョン 4.4.4 よりも大きい）</block>
  <block id="374185e020d06ceed3f020af518a1c14" category="list-text">Kubernetes 向けの Advanced Cluster Management 向けの Red Hat サブスクリプション</block>
  <block id="9afcd045ce0197d71ba631e3fbe43095" category="paragraph">高度なクラスタ管理は OpenShift クラスタのアドオンであるため、ハブクラスタと管理対象クラスタで使用される機能に基づいて、ハードウェアリソースには一定の要件と制限があります。クラスタのサイジングを行う際は、これらの問題について考慮する必要があります。のドキュメントを参照してください<block ref="a5d2b81b971715f092f7296621743e22" category="inline-link-rx"></block> 詳細：</block>
  <block id="65a62318377ddbc5fe3f73548dc3d677" category="paragraph">オプションで、ハブクラスタにインフラストラクチャコンポーネントをホストする専用ノードがあり、それらのノードにのみ Advanced Cluster Management リソースをインストールする場合は、それに応じてそれらのノードに公差とセレクタを追加する必要があります。詳細については、のドキュメントを参照してください<block ref="df4d7b25534e8f26e8ab3acc1c646101" category="inline-link-rx"></block>。</block>
  <block id="3f71071db67a1d6b5b63e2d9cc6b0e93" category="inline-link-macro">次の手順：インストール。</block>
  <block id="2a9cc50366c16ec40c1a5132f8fe5533" category="paragraph"><block ref="2a9cc50366c16ec40c1a5132f8fe5533" category="inline-link-macro-rx"></block></block>
  <block id="03cae7751c31cc76a90cf5e94e86eb3a" category="section-title">ガバナンスとリスク</block>
  <block id="9d7264067197bc9ff368288f98750fd6" category="paragraph">この機能を使用すると、異なるクラスタのコンプライアンスポリシーを定義し、それらのクラスタが準拠していることを確認できます。ポリシーを設定して、ルールの逸脱や違反について通知したり修正したりできます。</block>
  <block id="f6262e5369e2b989638aaa9d4f333d91" category="image-alt">コンプライアンスポリシーを作成します</block>
  <block id="0a1575621f2b12d5216e6d1c95eed2e6" category="list-text">必要なポリシーをすべて設定したら、 Advanced Cluster Management でポリシーやクラスタの違反を監視して修正できます。</block>
  <block id="38c080ff2128a92954fb61942ea497c0" category="image-alt">ポリシーの監視</block>
  <block id="465d1c9d2d9ea711e43e2e20077e10f9" category="inline-link-macro">次の機能 - 観察性。</block>
  <block id="056789fad8ccaddf0ac3b4ef0a68b61a" category="paragraph"><block ref="056789fad8ccaddf0ac3b4ef0a68b61a" category="inline-link-macro-rx"></block></block>
  <block id="119ad672b0d69ab3f968877b6ec83dd3" category="list-text"><block ref="119ad672b0d69ab3f968877b6ec83dd3" category="inline-link-macro-rx"></block></block>
  <block id="d313887d8fa4b2493a50d1e00bad440e" category="sidebar">アプリケーションライフサイクル管理</block>
  <block id="f55899cffbf639043209795d5a1af970" category="sidebar">リソースの作成</block>
  <block id="c8d20ce0b6bb23d912f3368f706d5794" category="summary">ネットアップのソリューションは、お客様の最も重要なビジネスニーズをサポートするためにネットアップの製品とサービスのポートフォリオを強調する、戦略的機能とテクノロジ機能のセットです。</block>
  <block id="a4957cf974ce20219897bbbf5b131cb8" category="paragraph">管理者は、プロジェクトのニーズやストレージシステムモデルに基づいて複数のストレージバックエンドを構成し、圧縮、特定のディスクタイプ、 QoS レベルなどの高度なストレージ機能を有効にして一定のレベルのパフォーマンスを保証できます。定義されたバックエンドは、プロジェクトの開発者が永続的ボリューム要求（ PVC ）を作成し、永続的ストレージをオンデマンドでコンテナに接続するために使用できます。</block>
  <block id="b62bb4786ef52ad76706950add6991dd" category="paragraph">20.04 リリース以降、 Trident のセットアップは Trident オペレータによって実行されます。オペレータが大規模な導入を容易にし、 Trident インストールの一部として導入されたポッドの自己修復などの追加サポートを提供します。</block>
  <block id="3ce67d5de6974f67e0048e6fdbf89498" category="admonition">場合によっては、お客様の環境で Trident の導入のカスタマイズが必要になることもあります。このような場合は、 Trident のオペレータを手動でインストールし、含まれているマニフェストを更新して配置をカスタマイズすることもできます。</block>
  <block id="1315b42a551dafb715ab654d8eb5af40" category="list-text">Trident にはこのファイルを渡すオプションがないため、まず、ユーザクラスタの「 kubeconfig 」ファイルの場所を環境変数として設定します。</block>
  <block id="693642fbb464db49c22715a536e99c3f" category="paragraph">iSCSI プロトコルによるブロックストレージボリュームのマッピングを許可するようにワーカーノードを準備するには、その機能をサポートするために必要なパッケージをインストールする必要があります。</block>
  <block id="cccb85b5e6a9a19187087f71254d1fb2" category="paragraph">Red Hat OpenShift では、 MCO （マシン構成オペレータ）を展開後にクラスタに適用することによって処理されます。</block>
  <block id="7b8e6ef8272a81ebcc108ee3fcf4eac8" category="list-text">OCP Web コンソールにログインし、 [ 計算 ]&gt;[ マシン構成 ] に移動します。[ マシン構成の作成 ] をクリックします。YAML ファイルをコピーして貼り付け、 [ 作成 ] をクリックします。</block>
  <block id="c25282bfd8c140d1f79c25362637f744" category="paragraph">マルチパスを使用しない場合：</block>
  <block id="541c76e8762c84e3e0488f91c8062e08" category="paragraph">マルチパスを使用する場合：</block>
  <block id="d9f036d3b9f84b626f8a777480066cab" category="list-text">構成の作成後、約 20~30 分で設定がワーカーノードに適用され、再ロードされます。「 OC GET MCP 」を使用してマシン構成が適用されているかどうかを確認し、ワーカーのマシン構成プールが更新されていることを確認します。ワーカーノードにログインして、 iscsid サービスが実行されている（マルチパスを使用している場合、 multipathd サービスが実行されている）ことを確認することもできます。</block>
  <block id="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="list-text"><block ref="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="inline-link-macro-rx"></block></block>
  <block id="d7b539d4bc16fbdf1477adddfda6c802" category="list-text"><block ref="d7b539d4bc16fbdf1477adddfda6c802" category="inline-link-macro-rx"></block></block>
  <block id="2e5d36490241211379006b7f6934bf06" category="list-text"><block ref="2e5d36490241211379006b7f6934bf06" category="inline-link-macro-rx"></block></block>
  <block id="25d77826c061b84a0c036f43e02aa129" category="doc">OpenShift Virtualization のインストール：ネットアップでの Red Hat OpenShift</block>
  <block id="762a14964ee1713d320b8beefaf55b17" category="inline-link-macro">ビデオ： Installing OpenShift Virtualization - Red Hat OpenShift with NetApp 』</block>
  <block id="5ac70ba9dc4ef90bfb3a829919c8044d" category="list-text"><block ref="5ac70ba9dc4ef90bfb3a829919c8044d" category="inline-link-macro-rx"></block></block>
  <block id="aad993afc3c78a3a38ae471fa2ae1060" category="inline-link-macro">ビデオ： Deploying a Virtual Machine with OpenShift Virtualization - Red Hat OpenShift with NetApp</block>
  <block id="1c9dc04aa9e0e0aaf52a33af61d8d630" category="list-text"><block ref="1c9dc04aa9e0e0aaf52a33af61d8d630" category="inline-link-macro-rx"></block></block>
  <block id="114856cfc010d937269afe29138175fc" category="doc">OpenShift Virtualization による仮想マシンの導入：ネットアップを使用した Red Hat OpenShift</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">価値</block>
  <block id="bbaff12800505b22a853e8b7f4eb6a22" category="inline-link">連絡先</block>
  <block id="d3db539e5d56da6e251021138c5fe53f" category="section-title">ネットアップと VMware のソリューションの詳細をご確認ください</block>
  <block id="09f93ac387258fa68c085baba3c8fc44" category="inline-link">NetApp &amp;amp; VMware ：より優れた組み合わせ</block>
  <block id="fb758bbc93c23b25607ef41f302d4eef" category="list-text"><block ref="35ef54e3b8ad8ec505bab4b973f86177" category="inline-link-rx"></block></block>
  <block id="b6741313b8f46ab1018ebd6a361c22a4" category="inline-link">ONTAP 9.8 VMware の最新機能の概要</block>
  <block id="d393be6d50183d7362f0adb8bc92ae08" category="list-text"><block ref="d393be6d50183d7362f0adb8bc92ae08" category="inline-link-rx"></block></block>
  <block id="b25a3522acbb33341ccacac99424fcce" category="inline-link">SnapCenter プラグイン for VMware vSphere の活用</block>
  <block id="a65898b7011ddfb663cdba62f90581c6" category="list-text"><block ref="a65898b7011ddfb663cdba62f90581c6" category="inline-link-rx"></block></block>
  <block id="60b0390f50a5ad13d613d49cfe1bce0b" category="inline-link">ネットアップと NVMe で VMware のパフォーマンスを再定義</block>
  <block id="f6dde7f191b6b8f8351902b139ec8672" category="list-text"><block ref="f6dde7f191b6b8f8351902b139ec8672" category="inline-link-rx"></block></block>
  <block id="c576371db342dc9cb166c73b0e157fb5" category="inline-link">AWS 上の VMware クラウド向けの低コストのパフォーマンスを実現する世界です</block>
  <block id="89487ceb1ada10e49befbbaed3b714ec" category="list-text"><block ref="89487ceb1ada10e49befbbaed3b714ec" category="inline-link-rx"></block></block>
  <block id="a88a91878fb958db59873117d16ad078" category="inline-link">仮想デスクトップインフラ（ VDI ）：従業員向けワークステーションをオンデマンドで提供します</block>
  <block id="9467ff6388811a059199513a0a484f0b" category="list-text"><block ref="9467ff6388811a059199513a0a484f0b" category="inline-link-rx"></block></block>
  <block id="d5e64137a19403f8c1c89f50546b82c5" category="inline-link">VMware on AWS ：アーキテクチャとサービスのオプション</block>
  <block id="6cb2c8a80e576f132097e4d28cec24cd" category="list-text"><block ref="6cb2c8a80e576f132097e4d28cec24cd" category="inline-link-rx"></block></block>
  <block id="cd4efd0ada1938b240dd48aa08010f04" category="inline-link">NetApp Cloud Volumes Service API で AWS エクスペリエンスを最適化するためのプログラミング</block>
  <block id="f61369e9428a21eb1090be340ef36f16" category="list-text"><block ref="f61369e9428a21eb1090be340ef36f16" category="inline-link-rx"></block></block>
  <block id="6d14f3ca0f5be54f01fd579906dd80bb" category="inline-link">Kubernetes ： vSphere と Tanzu で Kubernetes を実行する</block>
  <block id="ef8e103737164442c629df5b5d98769d" category="list-text"><block ref="ef8e103737164442c629df5b5d98769d" category="inline-link-rx"></block></block>
  <block id="92061b0dd7904e2299ac65ed9bc2d6af" category="inline-link">ネットアップとともに VMware Tanzu を紹介します</block>
  <block id="ae7c9beb8e4adca6da75607ee83e2403" category="list-text"><block ref="ae7c9beb8e4adca6da75607ee83e2403" category="inline-link-rx"></block></block>
  <block id="7e0caac7f6d493fab662f4f4d65ae213" category="section-title">仮想化データファブリックを構築</block>
  <block id="f1f4041236ed90e2a5e65e9a3c858875" category="section-title">ネットアップの VMware 向け最新ソリューションをご確認ください</block>
  <block id="0e8dd76bc961a90df87833953de6d067" category="inline-link">VMware vSphere と ONTAP ：ネットアップのソリューション</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="inline-link">SnapCenter Plug-in for VMware vSphere</block>
  <block id="730c2cf92bbe409c31ef1f39cf25377a" category="list-text"><block ref="730c2cf92bbe409c31ef1f39cf25377a" category="inline-link-rx"></block></block>
  <block id="c375e5bb7184da46adef700a9a36d674" category="inline-link">ネットアップの最新の NVMeoF VMware vSphere ワークロードの設計と検証</block>
  <block id="b54be27467e63a98d65e6b17a914e373" category="list-text"><block ref="902dd483e9192a0b4645b4c8be7acbff" category="inline-link-rx"></block></block>
  <block id="b860a89f6215a92f2320f0afe4e0ee05" category="inline-link">VMware と SQL Server 向けの、ネットアップの最新の NVMeoF クラウド対応フラッシュ解決策</block>
  <block id="0ebff16085636352cc1aa1e5b0003bdb" category="list-text"><block ref="ac70b8666634dd9095602966c4c61093" category="inline-link-rx"></block></block>
  <block id="eccda9b55035b56259299545d5781136" category="inline-link">VMware Tanzu &amp; ONTAP で Kubernetes への移行を加速</block>
  <block id="bb79e474557eb86fc30118354eef0039" category="list-text"><block ref="5dd92e330c2d45255a2025ee1eedd52d" category="inline-link-rx"></block></block>
  <block id="7f8cf1c43494d40e935f5e99e38ce659" category="inline-link">AWS で VMware Cloud を実行するコストを削減</block>
  <block id="f0d8a1b084d604c4db4319a2c5bbd522" category="list-text"><block ref="f0d8a1b084d604c4db4319a2c5bbd522" category="inline-link-rx"></block></block>
  <block id="7128c22bfdae1fe8be75c9a9ee56eca9" category="inline-link">『 Best Practices for VMware vSphere and NetApp ONTAP 』を参照してください</block>
  <block id="d2fa143a4aaef3477f2edb0d92676341" category="inline-link">VMware 環境 - ONTAP を使用して NVMe-oF で実行しましょう</block>
  <block id="e9c2b8b8a9962013c07f83742ca35f0e" category="inline-link">ONTAP ツールと VMware SRM を使用した VVol のディザスタリカバリ</block>
  <block id="e308c2a1dacddb5bc6ffa093081111e4" category="inline-link">データファブリック向けの VMware のバックアップとリカバリ</block>
  <block id="c10a86f3b9530baf3bed3b02aaaf873f" category="section-title">柔軟性に優れたハイブリッドクラウドと最新化された VMware 向けアプリケーションインフラを導入できます</block>
  <block id="f20368920280b50131814db2f83fda66" category="inline-link">NetApp All Flash FAS 上での VMware データストアの設計</block>
  <block id="253d309203cf1f2c1bb57255bd0a5bdc" category="inline-link">VMware VM を Google Cloud に移行します</block>
  <block id="3ca2b14e719d79aed66780282e879db4" category="section-title">ネットアップと VMware のエキスパートが支援します</block>
  <block id="20475522c77401af1c203f23942ffda5" category="inline-link">VMware ソリューションディスカッションフォーラムに参加します</block>
  <block id="1dccc60a61431b3ef3f48709a0f68de7" category="list-text"><block ref="1dccc60a61431b3ef3f48709a0f68de7" category="inline-link-rx"></block></block>
  <block id="a5810200dda7a3f37fc7eae5378cc8f3" category="inline-link">ネットアップグローバルサービスチームにお問い合わせください</block>
  <block id="efb954cbfdbe0c54f04c904a2719b98a" category="list-text"><block ref="efb954cbfdbe0c54f04c904a2719b98a" category="inline-link-rx"></block></block>
  <block id="3a8a3991c7ef251983bda0fd052b9b10" category="inline-link">TR-4890</block>
  <block id="3cbee33bcafaf0315e821a3331b91eb5" category="inline-link">ネットアップのフルサポートの並列ファイルシステム解決策 BeeGFS</block>
  <block id="63de7cb3a054a3754335c60a0c8ba878" category="paragraph">注：同じデータセットへの共有アクセスを必要とする多数の GPU サーバを対象とした大規模な HPC スタイルの分散トレーニング、または並列ファイルシステムを必要とする場合は、チェックアウトしてください <block ref="f82f3a4db7a848244fd5070f378c86fb" category="inline-link-rx"></block>。本テクニカルレポートでは、この情報を記載する方法について説明します <block ref="99c493838dffa23aa6d1149e33e3edf0" category="inline-link-rx"></block> ネットアップの AI コントロールプレーンの一部として提供されます。この解決策は、数台の NVIDIA DGX A100 システムで構成される 140 ノードの SuperPOD まで拡張できるように設計されています。</block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">このドキュメントに記載されている情報の詳細については、以下のドキュメントや Web サイトを参照してください。</block>
  <block id="7d9ee37e3155d571b441d63bcbc54709" category="inline-link"><block ref="7d9ee37e3155d571b441d63bcbc54709" category="inline-link-rx"></block></block>
  <block id="52c629361849219069b336f56f1556d0" category="list-text">TR-4400 ：『 VMware vSphere Virtual Volumes with ONTAP 』<block ref="b7bf139d6051615d8c8e01b6b63dacc3" category="inline-link-rx"></block></block>
  <block id="18df8e05a5400abd9d0980b1c5bc9ef3" category="list-text">TR-4015 『 SnapMirror Configuration Best Practice Guide for ONTAP 9 』<block ref="e361bd9d6f7b20da762bc23fcb3d09c2" category="inline-link-rx"></block></block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="249b98331fa56dc46bf6ba51dc6c39d5" category="list-text">RBAC User Creator for ONTAP の略<block ref="6b15b91279acfce2bbee060bdb17db43" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="1a57e0f74e725c1a5e2d53b4d4b4460d" category="list-text">VMware vSphere リソース用の ONTAP ツール<block ref="80c496cd9ab75e5683007d8f66ca6fbf" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="91a48e1708df22b7464bced79c745ad2" category="list-text">VMware Site Recovery Manager のドキュメント<block ref="92ad802ced4838839b492be6d0bf427d" category="inline-link-rx"></block></block>
  <block id="014a2413d22e5ac39371ac1333e38898" category="paragraph">を参照してください<block ref="99cfde592e1d7fa7832b186d73ee4002" category="inline-link-rx"></block> ネットアップサポートサイトで、本ドキュメントに記載されている製品や機能のバージョンがお客様の環境でサポートされるかどうかを確認してください。NetApp IMT には、ネットアップがサポートする構成を構築するために使用できる製品コンポーネントやバージョンが定義されています。サポートの可否は、お客様の実際のインストール環境が公表されている仕様に従っているかどうかによって異なります。</block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">可能であれば、必ず ONTAP ツールを使用してデータストアとボリュームをプロビジョニングしてください。ボリューム、ジャンクションパス、 LUN 、 igroup 、エクスポートポリシーが その他の設定は互換性のある方法で構成されます。</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">運用上のベストプラクティス</block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="section-title">データストアおよびプロトコル</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM では、 ONTAP 9 で iSCSI 、ファイバチャネル、および NFS バージョン 3 をサポートしているのは、 SRA 経由のアレイベースのレプリケーションを使用している場合です。SRM は、従来のデータストアまたは VVOL データストアでの NFS バージョン 4.1 のアレイベースのレプリケーションをサポートしていません。</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">接続を確認するために、 DR サイトの新しいテスト用データストアをデスティネーション ONTAP クラスタからマウントしてアンマウントできることを必ず確認してください。データストアの接続に使用する各プロトコルをテストします。テスト用データストアは SRM の指示に従ってすべてのデータストアの自動化を実行するため、 ONTAP ツールを使用して作成することを推奨します。</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">SAN プロトコルは各サイトで同機種にする必要があります。NFS と SAN を混在させることはできますが、 SAN プロトコルを 1 つのサイト内に混在させないでください。たとえば、サイト A では FCP を、サイト B では iSCSI を使用できますサイト A では、 FCP と iSCSI の両方を使用しないでくださいその理由は、 SRA がリカバリサイトに混在する igroup を作成しないため、 SRM が SRA に指定されたイニシエータリストをフィルタリングしないためです。</block>
  <block id="150f8d9d5018ff00285d9aa158451d7b" category="paragraph">以前のガイドでは、 LIF を作成してデータの局所性を確保することを推奨つまり、必ず、ボリュームを物理的に所有するノード上の LIF を使用してデータストアをマウントします。これは、 ONTAP 9 の最新バージョンでは必須ではなくなりました。可能 ONTAP であれば、クラスタを対象とした特定のクレデンシャルがあれば、データに対してローカルな LIF 間での負荷分散は引き続き行われますが、高可用性やパフォーマンスの要件ではありません。</block>
  <block id="ef6e8713285283721507f92e3c3ec674" category="paragraph">オートサイズで十分な緊急容量を確保できない場合にスペース不足の状態になったときに Snapshot コピーを自動的に削除してアップタイムを確保するように設定 ONTAP できます。デフォルトの設定では、 SnapMirror によって作成された Snapshot コピーは自動的には削除されません。SnapMirror Snapshot コピーが削除された場合、 NetApp SRA は関連ボリュームのレプリケーションを反転および再同期できません。ONTAP によって SnapMirror Snapshot コピーが削除されないようにするには、 Snapshot の自動削除機能を設定してください。</block>
  <block id="a4f47f677f45e1e7075186d98e4f3ec1" category="paragraph">SAN データストアを含むボリュームの場合はボリュームのオートサイズを「 grow 」に設定し、 NFS データストアの場合は「 GROE_SHシュリンク 」に設定する必要があります。を参照してください<block ref="ee2474fa4563985f2f3ebe16d4e1ab3a" category="inline-link-rx"></block> を参照してください。</block>
  <block id="e6955db66b8dc4aee170ebdb0b560249" category="section-title">SPBM と VVol</block>
  <block id="3077a08ffed60acebf18d37874130d44" category="paragraph">SRM 8.3 以降では、 VVol データストアを使用した VM の保護がサポートされています。SnapMirror スケジュールは、次のスクリーンショットに示すように、 ONTAP のツール設定メニューで VVOL のレプリケーションが有効になっている場合、 VASA Provider によって VM ストレージポリシーに公開されます。</block>
  <block id="399c1894baf71c0529aa0fba66ea18fb" category="paragraph">次の例は、 VVol レプリケーションを有効にする方法を示しています。</block>
  <block id="b180e7f35111dca8acd6c56cdbcabb3e" category="paragraph"><block ref="b180e7f35111dca8acd6c56cdbcabb3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">次のスクリーンショットは、 VM ストレージポリシーの作成ウィザードに表示される SnapMirror スケジュールの例を示しています。</block>
  <block id="43c130b36e9e2b3d61409aa974f89fc7" category="paragraph"><block ref="43c130b36e9e2b3d61409aa974f89fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783a951245ce43eb84161804072a38c6" category="paragraph"><block ref="783a951245ce43eb84161804072a38c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">VVOL データストア用にレプリケートされたボリュームを作成します</block>
  <block id="18231879821321e0aed7de84fe876766" category="paragraph">以前の VVOL データストアとは異なり、レプリケートされた VVOL データストアはレプリケーションを有効にして最初から作成する必要があります。また、 SnapMirror 関係を持つ ONTAP システムで事前に作成されたボリュームを使用する必要があります。そのためには、クラスタピアリングや SVM ピアリングなどの設定を事前に行う必要があります。これらの作業は ONTAP 管理者が行う必要があります。複数のサイトにわたって ONTAP システムを管理する担当者と、主に vSphere の運用を担当する担当者を厳密に分離できるためです。</block>
  <block id="0a8c8293003bf411817ef3cedf18a2a9" category="paragraph">これは、 vSphere 管理者の代わりに新たな要件となります。ボリュームは ONTAP ツールの範囲外に作成されるため、定期的な再検出スケジュール期間が設定されるまで ONTAP 管理者が行った変更を認識することはありません。そのため、 VVOL で使用するボリュームまたは SnapMirror 関係を作成したときは常に再検出を実行することを推奨します。次のスクリーンショットに示すように、ホストまたはクラスタを右クリックし、 NetApp ONTAP tools &gt; Update Host and Storage Data を選択します。</block>
  <block id="dd5e006520a09e3975e52f6fb8991fd2" category="paragraph"><block ref="dd5e006520a09e3975e52f6fb8991fd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">VVOL と SRM については、 1 つ注意が必要です。保護された VM と保護されていない VM を同じ VVOL データストアに混在させないでください。これは、 SRM を使用して DR サイトにフェイルオーバーする場合、保護グループに属する VM のみが DR でオンラインになるためです。そのため、再保護（ SnapMirror を DR から本番環境に戻して再保護）する際に、フェイルオーバーされなかった VM が上書きされて、貴重なデータが含まれる可能性があります。</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">アレイペアについて</block>
  <block id="6dd3f3008fe81f402905b00c8dca007c" category="paragraph">アレイペアごとにアレイマネージャが作成されます。SRM ツールと ONTAP ツールでは、クラスタクレデンシャルを使用している場合でも、各アレイペアリングを SVM の範囲で実行します。これにより、管理対象に割り当てられている SVM を基に、各テナント間で DR ワークフローを分割できます。特定のクラスタに対して複数のアレイマネージャを作成でき、非対称にすることができます。異なる ONTAP 9 クラスタ間でファンアウトまたはファンインを実行できます。たとえば、クラスタ 1 の SVM A と SVM B をクラスタ 2 の SVM C に、クラスタ 3 の SVM D に、またはその逆にレプリケートできます。</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">SRM でアレイペアを設定する場合は、 ONTAP ツールに追加するのと同じ方法でアレイペアを SRM に追加する必要があります。つまり、アレイペアは同じユーザ名、パスワード、および管理 LIF を使用する必要があります。これは、 SRA がアレイと正しく通信するための要件です。次のスクリーンショットは、 ONTAP ツールでのクラスタの表示方法と、アレイマネージャへのクラスタの追加方法を示しています。</block>
  <block id="7ec48584a43ed8a9b1dda55398d97cf4" category="paragraph"><block ref="7ec48584a43ed8a9b1dda55398d97cf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">複製グループについて</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">レプリケーショングループには、同時にリカバリされる仮想マシンの論理集合が含まれます。レプリケーショングループは、 ONTAP ツール VASA Provider で自動的に作成されます。ONTAP の SnapMirror レプリケーションはボリュームレベルで実行されるため、ボリューム内のすべての VM が同じレプリケーショングループに属します。</block>
  <block id="b57ec021fce4e5261ba61df6f0c013af" category="paragraph">レプリケーショングループについて考慮する必要がある要素と、 FlexVol ボリュームに VM を分散する方法にはいくつかの要素があります。同様の VM を同じボリュームにグループ化すると、アグリゲートレベルの重複排除が行われていない古い ONTAP システムでもストレージ効率が向上しますが、グループ化することでボリュームのサイズが増大し、ボリュームの I/O 同時実行が減少します。最新の ONTAP システムでパフォーマンスとストレージ効率の最適なバランスを実現するには、同じアグリゲート内の FlexVol ボリュームに VM を分散します。その結果、アグリゲートレベルの重複排除を利用して、複数のボリューム間で I/O の並列化を促進します。保護グループ（以下で説明）には複数のレプリケーショングループを含めることができるため、ボリューム内の VM を 1 つにまとめてリカバリできます。このレイアウトの欠点は、 Volume SnapMirror ではアグリゲートの重複排除が考慮されないため、ブロックがネットワーク経由で何度も転送されることです。</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">レプリケーショングループの最後の考慮事項の 1 つは、各グループがその性質によって論理整合グループになることです（ SRM 整合グループと混同しないようにしてください）。これは、ボリューム内のすべての VM が同じ Snapshot を使用して同時に転送されるためです。したがって、相互に整合性が必要な VM がある場合は、同じ FlexVol に格納することを検討してください。</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">保護グループについて</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">保護グループでは、 VM とデータストアをグループ単位で定義し、グループをまとめて保護サイトからリカバリします。保護対象サイトとは、通常の安定状態での運用中、保護グループで構成された VM が存在する場所です。SRM には保護グループの複数のアレイマネージャが表示される場合がありますが、保護グループは複数のアレイマネージャにまたがることはできません。このため、異なる SVM 上の複数のデータストアに VM ファイルをまたがって配置することはできません。</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">リカバリ・プランについて</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">リカバリプランでは、同じプロセスでリカバリする保護グループを定義します。同じリカバリプランに複数の保護グループを設定できます。また、リカバリプランの実行オプションを増やすには、 1 つの保護グループを複数のリカバリプランに含めることもできます。</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">リカバリプランを使用すると、 SRM 管理者は、 VM を優先グループ 1 （最大）から 5 （最小）に割り当てて、リカバリワークフローを定義できます。デフォルトは 3 （中）です。優先度グループ内で、 VM に依存関係を設定できます。</block>
  <block id="6d72567442b1f361e3c0e89cbc7dfd6a" category="paragraph">たとえば、会社のデータベースに Microsoft SQL Server を使用するティア 1 ビジネスクリティカルなアプリケーションを使用しているとします。したがって、優先度グループ 1 に VM を配置することにします。優先度グループ 1 では、サービスの提供順序の計画を開始します。Microsoft Windows ドメイン・コントローラを起動してから Microsoft SQL Server を起動してください。アプリケーション・サーバの前にオンラインになっている必要があります。依存関係は特定の優先グループ内でのみ適用されるため、これらのすべての VM を優先グループに追加してから、依存関係を設定します。</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">アプリケーションチームと連携してフェイルオーバーシナリオに必要な処理の順序を把握し、それに応じてリカバリ計画を作成することを強く推奨します。</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">テストフェイルオーバー</block>
  <block id="2772828493452c4a2ff21f8b2b66a1a7" category="paragraph">ベストプラクティスとして、保護対象の VM ストレージの構成を変更する場合は、必ずテストフェイルオーバーを実行してください。これにより、災害発生時に、 Site Recovery Manager が想定される RTO ターゲット内でサービスをリストアできるかどうかを信頼できます。</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">特に VM ストレージの再設定後にゲストアプリケーションの機能を確認することを推奨します。</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">テストリカバリ処理を実行すると、 VM 用の ESXi ホストにプライベートテスト用のバブルネットワークが作成されます。ただし、このネットワークは物理ネットワークアダプタに自動的には接続されないため、 ESXi ホスト間の接続は提供されません。DR テスト時に異なる ESXi ホストで実行されている VM 間の通信を可能にするために、 DR サイトの ESXi ホスト間に物理プライベートネットワークを作成します。テスト用ネットワークがプライベートであることを確認するために、テスト用のバブルネットワークを物理的に分離するか、 VLAN や VLAN タギングを使用して分離します。このネットワークは本番用ネットワークから分離する必要があります。 VM がリカバリされると、実際の本番用システムと競合する可能性のある IP アドレスを持つ本番用ネットワークに配置することはできなくなります。SRM でリカバリプランを作成する際、テスト中に VM を接続するためのプライベートネットワークとして、作成したテストネットワークを選択できます。</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">テストが検証されて不要になったら、クリーンアップ処理を実行します。クリーンアップを実行すると、保護されている VM が初期状態に戻り、リカバリプランが Ready 状態にリセットされます。</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">フェイルオーバーに関する考慮事項</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">サイトのフェイルオーバーに関しては、このガイドに記載されている処理の順序に加えて、その他にもいくつかの考慮事項があります。</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">競合する問題の 1 つに、サイト間のネットワークの違いがあります。環境によっては、プライマリサイトと DR サイトで同じネットワーク IP アドレスを使用できる場合があります。この機能は、拡張仮想 LAN （ VLAN ）または拡張ネットワークセットアップと呼ばれます。それ以外の環境では、プライマリサイトと DR サイトで別々のネットワーク IP アドレス（異なる VLAN など）を使用する必要があります。</block>
  <block id="1b41638d2115765dc12f82d77ce70138" category="paragraph">VMware では、この問題を解決する方法をいくつか提供しています。1 つは、 VMware NSX -T Data Center のようなネットワーク仮想化テクノロジーです。ネットワークスタック全体を運用環境からレイヤ 2 ～ 7 に抽象化し、より移植性の高いソリューションを実現します。NSX オプションの詳細については 'SRM で確認できます<block ref="99d78d594865360c3d4b527bf0a2a7f6" category="inline-link-rx"></block>。</block>
  <block id="09a74136e56a63c5aba38b89802d9080" category="paragraph">SRM では、リカバリ時に VM のネットワーク設定を変更することもできます。IP アドレス、ゲートウェイアドレス、 DNS サーバなどの設定が再設定されます。リカバリ時に個々の VM に適用されるさまざまなネットワーク設定を、リカバリプランの VM のプロパティ設定で指定できます。</block>
  <block id="99f0a91111e8acb2462e8df5ecf0ab8f" category="paragraph">VMware の dr-ip-customizer というツールを使用すると、リカバリプランで複数の VM のプロパティを個別に編集しなくても、 SRM で VM ごとに異なるネットワーク設定を適用できます。このユーティリティの使用方法については、 VMware のマニュアルを参照してください<block ref="b959814092e3e6cdc8d22e768887e618" category="inline-link-rx"></block>。</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">再保護</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">リカバリ後、リカバリサイトが新しい本番用サイトになります。リカバリ処理によって SnapMirror レプリケーションが解除されたため、新しい本番用サイトは今後の災害から保護されません。新しい本番用サイトは、リカバリ後すぐに別のサイトで保護することを推奨します。元の本番サイトが運用されている場合、 VMware 管理者は、元の本番サイトを新しいリカバリサイトとして使用して新しい本番サイトを保護できるため、保護の方向を実質的に変えることができます。再保護は、致命的でない障害でのみ使用できます。そのため、元の vCenter Server 、 ESXi サーバ、 SRM サーバ、および対応するデータベースを最終的にリカバリ可能な状態にする必要があります。使用できない場合は、新しい保護グループと新しいリカバリプランを作成する必要があります。</block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">フェイルバック</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">フェイルバック処理は、基本的に以前とは異なる方向のフェイルオーバーです。ベストプラクティスとして、フェイルバックを実行する前に、元のサイトが許容可能なレベルの機能に戻っていること、つまり元のサイトにフェイルオーバーしていることを確認することを推奨します。元のサイトが侵害されたままの場合は、障害が十分に修正されるまでフェイルバックを遅らせる必要があります。</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">フェイルバックのもう 1 つのベストプラクティスとして、再保護の完了後、および最終フェイルバックの実行前に、常にテストフェイルオーバーを実行することがあります。これにより、元のサイトに配置されたシステムで処理が完了できるかどうかを確認できます。</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">元のサイトを再保護する</block>
  <block id="2a0c13d7b927063987bf931a141f2662" category="paragraph">フェイルバックの完了後、再保護を再度実行する前に、サービスが正常に戻っていることをすべての利害関係者に確認する必要があります。</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">フェイルバック後の再保護を実行すると、基本的に環境は最初の状態に戻り、 SnapMirror レプリケーションが本番用サイトからリカバリサイトに再度実行されます。</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">ONTAP では、 Storage Virtual Machine （ SVM ）の概念を採用して、セキュアなマルチテナント環境で厳密にセグメント化します。</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">導入のベストプラクティス</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">SMT の SVM のレイアウトとセグメント化</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">ONTAP では、 Storage Virtual Machine （ SVM ）の概念を採用して、セキュアなマルチテナント環境で厳密にセグメント化します。ある SVM の SVM ユーザは、別の SVM のリソースにアクセスしたりリソースを管理したりすることはできませんこれにより、 ONTAP テクノロジを活用できます。ビジネスユニットごとに別々の SVM を作成して、同じクラスタ上で独自の SRM ワークフローを管理することで、全体的なストレージ効率を高めることができます。</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">SVM を対象としたアカウントと SVM 管理 LIF を使用して ONTAP を管理することを検討し、セキュリティ制御を強化するだけでなく、パフォーマンスも向上させます。SRA は、物理リソースを含むクラスタ全体のすべてのリソースを処理する必要がないため、 SVM を対象とした接続を使用する場合は本質的にパフォーマンスが向上します。その代わり、特定の SVM に抽象化された論理資産だけを認識する必要があります。</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">NAS プロトコルのみを使用する（ SAN アクセスなし）場合は、次のパラメータを設定することで、 NAS 向けに最適化された新しいモードを利用することもできます（ SRA と VASA は、アプライアンスで同じバックエンドサービスを使用するため）。</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">コントロール・パネルに \\https://&lt;IP address&gt;:9083' からログインして '[Web Based CLI interface] をクリックします</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">コマンド VP updateconfig -key=enable.qtree.enable -value=true' を実行します</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">コマンド VP updateconfig -key=enable.optimized.sra_value =true' を実行します</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">コマンド VP reloadconfig を実行します。</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">VVOL に ONTAP ツールを導入する際の考慮事項について説明します</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">SRM で VVol を使用する場合は、クラスタを対象としたクレデンシャルとクラスタ管理 LIF を使用してストレージを管理する必要があります。これは、 VM ストレージポリシーに必要なポリシーを満たすためには、 VASA Provider で基盤となる物理アーキテクチャを理解しておく必要があるためです。たとえば、オールフラッシュストレージを必要とするポリシーが設定されている場合、 VASA Provider では、どのシステムがオールフラッシュであるかを認識できる必要があります。</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">ONTAP Tools アプライアンスを管理している VVOL データストアに格納しないことを推奨します。その結果、アプライアンスがオフラインのためにアプライアンスのスワップ VVOL を作成できず、 VASA Provider の電源をオンにできなくなることがあります。</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">ONTAP 9 システムの管理に関するベストプラクティス</block>
  <block id="b4cbecf196108ad163c73c4e4194dde2" category="paragraph">前述したように、クラスタまたは SVM を対象としたクレデンシャルと管理 LIF を使用して ONTAP クラスタを管理できます。パフォーマンスを最適化するために、 VVOL を使用していないときは SVM を対象としたクレデンシャルの使用を検討してください。ただし、その場合は、いくつかの要件について確認しておく必要があります。また、機能の一部は失われます。</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">デフォルトの vsadmin SVM アカウントには、 ONTAP ツールのタスクを実行するために必要なアクセスレベルがありません。そのため、新しい SVM アカウントを作成する必要があります。</block>
  <block id="8557644859e03f54860c95ffb0bcfd53" category="list-text">ONTAP 9.8 以降を使用 https://&lt;IP している場合は、 ONTAP の System Manager の Users メニューを使用して、 ONTAP ツールアプライアンスの JSON ファイル（アドレス： 9083/VSC/config/ ）とともに、 RBAC の最小権限のユーザアカウントを作成することを推奨します。管理者パスワードを使用して JSON ファイルをダウンロードしてください。これは SVM またはクラスタを対象としたアカウントに使用できます。</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">ネットアップサポートサイトの Toolchest</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">ONTAP 9.6 以前を使用している場合は、で使用可能な RBAC User Creator （ RUC ）ツールを使用する必要があります<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>。</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">vCenter UI プラグイン、 VASA Provider 、 SRA サーバはすべて完全に統合されたサービスであるため、 vCenter UI で ONTAP ツール用のストレージを追加する場合と同じ方法で、 SRM で SRA アダプタにストレージを追加する必要があります。そうしないと、 SRA サーバが SRA アダプタ経由で SRM から送信された要求を認識しない可能性があります。</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">SVM を対象としたクレデンシャルを使用している場合、 NFS パスのチェックは実行されませんこれは、物理的な場所が SVM から論理的に抽象化されているためです。ただしこれは原因の問題ではありません。最新の ONTAP システムで間接パスを使用してもパフォーマンスが著しく低下することはなくなりました。</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">Storage Efficiency によるアグリゲートのスペース削減量が報告されないことがあります。</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">サポートされている場合、負荷共有ミラーを更新することはできません。</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">SVM を対象としたクレデンシャルで管理されている ONTAP システムでは、 EMS ロギングが実行されない場合があり</block>
  <block id="963739e9818c0bf4d8959b5cdf6a7956" category="summary">SRM で VVOL レプリケーションを使用する場合、 SRA と従来のデータストアで使用するワークフローは大きく異なります。</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">VVol レプリケーションを使用する場合の SRM のトラブルシューティング</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">SRM で VVOL レプリケーションを使用する場合、 SRA と従来のデータストアで使用するワークフローは大きく異なります。たとえば、アレイマネージャの概念はありません。そのため、「 discoverarrays 」コマンドと「 discoverdevices 」コマンドは表示されません。</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">トラブルシューティングを行う場合は、以下に示す新しいワークフローについて理解しておくと役立ちます。</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">queryReplicationPeer ： 2 つのフォールトドメイン間のレプリケーション契約を検出します。</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">queryFaultDomain ：障害ドメインの階層を検出します。</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">queryReplicationGroup ：ソースドメインまたはターゲットドメインに存在するレプリケーショングループを検出します。</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">syncReplicationGroup ：ソースとターゲット間でデータを同期します。</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">queryPointInTimeReplica ：ターゲット上のポイントインタイムレプリカを検出します。</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">testFailoverReplicationGroupStart ：テストフェイルオーバーを開始します。</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">testFailoverReplicationGroupStop ：テストフェイルオーバーを終了します。</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">promoteReplicationGroup ：テスト中のグループを本番環境に昇格します。</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">prepareFailoverReplicationGroup ：災害復旧の準備をします。</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">FailoverReplicationGroup ：ディザスタリカバリを実行します。</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">revertReplicateGroup ：逆方向のレプリケーションを開始します。</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">queryMatchingContainer: 指定されたポリシーを使用したプロビジョニング要求を満たす可能性のあるコンテナを（ホストまたはレプリケーショングループとともに）検索します。</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">queryResourceMetadata ： VASA Provider からすべてのリソースのメタデータを検出し、リソース利用率を回答として queryMatchingContainer 関数に返すことができます。</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">VVOL レプリケーションの設定時に表示される最も一般的なエラーは、 SnapMirror 関係を検出できないエラーです。これは、ボリュームおよび SnapMirror 関係が ONTAP ツールを対象としたものではないためです。そのため、 SnapMirror 関係が常に完全に初期化されていることを確認し、レプリケートされた VVOL データストアを作成する前に両方のサイトの ONTAP ツールで再検出を実行することを推奨します。</block>
  <block id="dcaf091737df278b1b4bdd2e37c10a75" category="summary">NetApp ONTAP は、 2002 年に最新のデータセンターに導入されて以来、 VMware vSphere 環境向けストレージ解決策として業界をリードしてきました。また、コストを削減しながら管理を簡易化する革新的な機能を継続的に追加しています。</block>
  <block id="1fdf67ffe178876efb8b8cacfb0f052b" category="doc">TR-4900 ：『 VMware Site Recovery Manager with NetApp ONTAP 9 』</block>
  <block id="cc6ab3d11d2dc330a573866f7c9f67aa" category="paragraph">Chance Bingen 、ネットアップ</block>
  <block id="60398bdc931fc67a9b6d781434c3a15a" category="section-title">ONTAP for vSphere の略</block>
  <block id="09d6c6a1868cc36795c7a0f8f84e50c9" category="paragraph">NetApp ONTAP は、 2002 年に最新のデータセンターに導入されて以来、 VMware vSphere 環境向けストレージ解決策として業界をリードしてきました。また、コストを削減しながら管理を簡易化する革新的な機能を継続的に追加しています。このドキュメントでは、 ONTAP 解決策 for VMware Site Recovery Manager （ SRM ）について説明します。 SRM は、最新の製品情報や、導入の合理化、リスクの軽減、継続的な管理の簡素化に役立つベストプラクティスを含む、業界をリードする VMware のディザスタリカバリ（ DR ）ソフトウェアです。</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">ベストプラクティスは、ガイドや互換性ツールなどの他のドキュメントを補うものです。ラボテストに基づいて開発されており、ネットアップのエンジニアやお客様は広範な現場経験を積んでいます。推奨されるベストプラクティスがお客様の環境に適していない場合もありますが、一般に最もシンプルなソリューションであり、ほとんどのお客様のニーズに対応できます。</block>
  <block id="c3edc14dbc5862176444f521372d1744" category="paragraph">本ドキュメントでは ONTAP 、 VMware vSphere （ NetApp Storage Replication Adapter [SRA] と VASA Provider [VP] を含む）のサポートされているバージョン、および VMware Site Recovery Manager 8 で使用される、最近のリリースの ONTAP 9 の機能に焦点を当てています。4.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">SRM で ONTAP を使用する理由</block>
  <block id="3c41d5be62c97a13079e9c7abf078292" category="paragraph">ONTAP ソフトウェアを基盤とするネットアップのデータ管理プラットフォームは、 SRM に最も広く採用されているストレージソリューションの一部です。理由は豊富です。セキュアでハイパフォーマンスなユニファイドプロトコル（ NAS と SAN ）を備えたデータ管理プラットフォームは、ストレージ効率の定義、マルチテナンシー、サービス品質管理、 SnapMirror によるスペース効率に優れた Snapshot コピーとレプリケーションによるデータ保護を提供します。VMware ワークロードを保護するためにネイティブのハイブリッドマルチクラウド統合を活用し、多数の自動化ツールやオーケストレーションツールを簡単に利用できます。</block>
  <block id="0d573b6a27c08499fee406e3db49812f" category="paragraph">SnapMirror をアレイベースのレプリケーションに使用すると、 ONTAP で最も実績のある成熟したテクノロジの 1 つを活用できます。SnapMirror を使用すると、 VM やデータストア全体ではなく、変更されたファイルシステムブロックのみをコピーして、データを安全かつ効率的に転送できます。重複排除、圧縮、コンパクションなどのスペース削減効果を活用できます。最新の ONTAP システムで、バージョンに依存しない SnapMirror が使用されるようになり、ソースとデスティネーションのクラスタを柔軟に選択できるようになりました。SnapMirror は、災害復旧のための最も強力なツールの 1 つとなりました。</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">従来の NFS 、 iSCSI 、ファイバチャネル接続データストア（現在は VVOL データストアをサポート）のいずれを使用している場合でも、 SRM は、ディザスタリカバリやデータセンター移行の計画とオーケストレーションに ONTAP の機能のメリットを活用する堅牢なファーストパーティ製品を提供します。</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">SRM での ONTAP 9 の活用方法</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM は、 ONTAP システムの高度なデータ管理テクノロジを活用して、 3 つの主要コンポーネントで構成される仮想アプライアンスである VMware vSphere 用 ONTAP ツールと統合します。</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">vCenter プラグイン（旧 Virtual Storage Console （ VSC ））は、 SAN と NAS のどちらを使用している場合でも、ストレージ管理と効率化機能の簡易化、可用性の向上、ストレージコストと運用オーバーヘッドの削減を実現します。データストアのプロビジョニングのベストプラクティスを使用して、 NFS 環境およびブロックストレージ環境用の ESXi ホスト設定を最適化します。以上のメリットのために、 ONTAP ソフトウェアを実行するシステムで vSphere を使用する場合はこのプラグインを推奨します。</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">VASA Provider for ONTAP は、 VMware vStorage APIs for Storage Awareness （ VASA ）フレームワークをサポートしています。VASA Provider では、 VM ストレージのプロビジョニングと監視に役立つように vCenter Server と ONTAP を接続します。VMware Virtual Volumes （ VVol ）のサポートと、ストレージ機能プロファイル（ VVol レプリケーション機能を含む）の管理、および個々の VM VVol のパフォーマンスの管理が可能になります。また、容量の監視やプロファイルへの準拠に関するアラームも生成されます。SRM と一緒に使用すると、 VASA Provider for ONTAP で VVOL ベースの仮想マシンをサポートできます。 SRM サーバに SRA アダプタをインストールする必要はありません。</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA は SRM と一緒に使用され、従来の VMFS データストアと NFS データストアの本番サイトとディザスタリカバリサイト間での VM データのレプリケーションを管理します。また、 DR レプリカの無停止テストにも使用できます。検出、リカバリ、再保護のタスクを自動化します。Windows SRM サーバおよび SRM アプライアンス用の SRA サーバアプライアンスと SRA アダプタの両方が含まれています。</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">SRM サーバに SRA アダプタをインストールして設定し、 VASA Provider で VVol 以外のデータストアを保護したり VVOL のレプリケーションを有効にしたりしたあとで、ディザスタリカバリ用に vSphere 環境を設定する作業を開始できます。</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">SRA と VASA Provider には、 SRM サーバ用のコマンド / 制御インターフェイスが用意されており、 VMware 仮想マシン（ VM ）を含む ONTAP FlexVol や、 SRA を保護する SnapMirror レプリケーションを管理できます。</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">SRM 8.3 以降では、 SRM サーバへの新しい SRM VVol Provider 制御パスが導入され、 SRA を使用せずに vCenter サーバおよびその経由で VASA Provider に通信できるようになりました。これにより、 SRM サーバは緊密に統合するための完全な API を提供するため、以前よりもはるかに ONTAP クラスタの制御を活用できました。</block>
  <block id="53e971f0dfb3ef96ca359dcb648176b9" category="paragraph">SRM は、ネットアップ独自の FlexClone テクノロジを使用して、 DR プランを無停止でテストし、 DR サイトの保護されたデータストアのクローンをほぼ瞬時に作成できます。SRM はサンドボックスを作成して安全にテストし、真の災害が発生した場合に組織とお客様を保護します。そのため、組織は災害時にフェイルオーバーを実行できます。</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">実際に災害が発生した場合や、計画的な移行の場合でも、 SRM では、最終的な SnapMirror 更新（必要な場合）を使用して、データセットに最新の変更を送信できます。その後、ミラーを解除し、 DR ホストにデータストアをマウントします。この時点で、計画済みの戦略に基づいて、 VM の電源を任意の順序で自動的にオンにすることができます。</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">SRM と ONTAP などのユースケース：ハイブリッドクラウドと移行</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">Equinix 内の NetApp Private Storage</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">SRM 環境に ONTAP の高度なデータ管理機能を統合することで、ローカルストレージオプションに比べて、拡張性とパフォーマンスが大幅に向上します。それだけではありませんが、ハイブリッドクラウドの柔軟性を備えています。ハイブリッドクラウドを使用すると、 FabricPool を使用して、未使用のデータブロックをハイパフォーマンスアレイから希望するハイパースケーラに階層化してコストを削減できます。これは、 NetApp StorageGRID などのオンプレミスの S3 ストアである可能性があります。また、 ONTAP Select （ CVO ）やを使用して、ソフトウェアで定義される Cloud Volumes ONTAP やクラウドベースの DR でエッジベースのシステムに SnapMirror を使用することもできます<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> Amazon Web Services （ AWS ）、 Microsoft Azure 、 Google Cloud Platform （ GCP ）で、クラウド内に完全に統合されたストレージ、ネットワーク、コンピューティングサービスのスタックを構築できます。</block>
  <block id="10ae334f731d3c4fabafa8017f7a3ab2" category="paragraph">FlexClone により、ストレージ設置面積がほぼゼロのクラウドサービスプロバイダーのデータセンター内でテストフェールオーバーを実行できます。組織を保護することで、かつてないほどコストを削減できます。</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">SRM は、 SnapMirror を使用して、計画的な移行を実行することもできます。これにより、 VM を 1 つのデータセンターから別のデータセンターに効率的に転送したり、独自のデータセンターや、任意の数のネットアップパートナーサービスプロバイダを介して VM を転送したりできます。</block>
  <block id="a9b73ebef33c98ef5a1044177d2b49f3" category="summary">VMware vCenter Site Recovery Manager は、ディザスタリカバリ製品です。自動オーケストレーションを提供し、一元的なリカバリプランの無停止テストを提供して、仮想化されたすべてのアプリケーションのディザスタリカバリ管理を簡素化します。</block>
  <block id="06f589670c0d0455912cc8bb70b78701" category="paragraph">Site Recovery Manager を NetApp ONTAP システムに導入することで、ディザスタリカバリのコストと複雑さを大幅に削減できます。ネットアップは、高性能で管理しやすく拡張性に優れたストレージアプライアンスと堅牢なソフトウェア製品により、 vSphere 環境をサポートする柔軟なストレージおよびデータ管理ソリューションを提供します。</block>
  <block id="00549aec33ddcae6a708ed7368a7bcd0" category="paragraph">このガイドで紹介するベストプラクティスと推奨事項は、すべての解決策に当てはまるわけではありません。本ドキュメントには、 SRM DR 計画の計画、導入、管理のガイドラインを提供するベストプラクティスと推奨事項がまとめられています。VMware vCenter Site Recovery 環境をネットアップストレージ上に計画および導入する際は、ネットアップの VMware エキスパートにご相談ください。ネットアップの VMware エキスパートが、あらゆる vSphere 環境のニーズとニーズを迅速に特定し、それに応じてストレージの解決策を調整できます。</block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">従来の仮想アプライアンスからの移行に対応した ONTAP ツールには、豊富な新機能と上限があり、 VVOL が新たにサポートされるようになりました。</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">SRM および ONTAP ツールの新機能</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">vSphere および Site Recovery Manager の最新バージョン</block>
  <block id="aa73b07f008975ca9fcabf87bfafb167" category="paragraph">SRM 8.3 以降と 9.7.1 以降の ONTAP ツールでは、 VMware vSphere 7 で実行されている VM を保護できるようになりました。</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">ネットアップは、約 20 年にわたり VMware との緊密なパートナーシップを共有し、できるだけ早く最新リリースのサポートを提供するよう努めています。ソフトウェアの最新の組み合わせについては、必ず NetApp Interoperability Matrix Tool （ IMT ）で確認してください。</block>
  <block id="63fe9875fcf8108a4dca29a0795d8674" category="paragraph">NetApp IMT が見つかります<block ref="dd81e3609a71c92c2a90d9165ca7bb00" category="inline-link-rx"></block>。</block>
  <block id="23a6222620917211381cf4455d9e0a83" category="section-title">VVol のサポート（ SRM でも SPBM が重要である理由）</block>
  <block id="a36269071ceeb480e636654c4620f7fb" category="paragraph">8.3 リリースから、 SRM は VVol とアレイベースのレプリケーションを活用して、 Storage Policy-Based Management （ SPBM ；ストレージポリシーベースの管理）をサポートするようになりました。これを実現するために、 SRM サーバが更新され、 vCenter サーバの SMS サービスと通信して VASA 関連のタスクを実行する新しい SRM VVol プロバイダサービスが追加されました。</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">このアーキテクチャのメリットの 1 つは、すべての処理に VASA を使用するため、 SRA が不要になったことです。</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM は vSphere ツールボックスの強力なツールで、プライベートクラウド環境とハイブリッドクラウド環境の自動化フレームワークによって、シンプルで予測可能な一貫したストレージサービスを利用できます。SPBM では、多様な顧客層のニーズを満たすサービスクラスを定義できます。SRM では、堅牢な業界標準のディザスタリカバリオーケストレーションと自動化を必要とする重要なワークロードに対して、レプリケーション機能をお客様に提供できるようになりました。</block>
  <block id="48e2854d95fac45929940abc72062193" category="section-title">vVol アーキテクチャ 2.3 では、アプライアンスベースの SRM サーバがサポートされます</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">従来の Windows ベースのプラットフォームに加え、光子 OS ベースの SRM サーバもサポートされるようになりました。</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">SRA アダプタを、希望する SRM サーバタイプに関係なくインストールできるようになりました。</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">IPv6 のサポート</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6 が次の制限付きでサポートされるようになりました。</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">vCenter 6.7 以降</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">SRM 8.2 （ 8.1 、 8.3 、および 8 ）ではサポートされていません。4 がサポートされています）</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">Interoperability Matrix Tool で確認してください</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">を確認します<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> 最新の認定バージョンについては、を参照してください。</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">パフォーマンスの向上</block>
  <block id="3efd4ca8de094abf49f004186cd70fff" category="paragraph">SRM タスクを実行するには、運用パフォーマンスが重要な要件です。最新の RTO と RPO の要件を満たすために、 SRA と ONTAP ツールで 2 つの新しい機能強化が行われました。</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">* 同時再保護処理のサポート。 * この機能を有効にすると、最初に SRA 9.7.1 で導入された、 2 つ以上のリカバリプランに対して再保護を同時に実行できるため、フェイルオーバーまたは移行後のデータストアの再保護に要する時間を短縮し、 RTO と RPO のパラメータ内に抑えることができます。</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">* ONTAP ツール 9.8 では、 NAS 専用に最適化された新しいモードが追加されました。 * SVM を対象としたアカウントを使用して、 NFS ベースのデータストアのみで ONTAP クラスタに接続している場合は、サポートされている環境でピークパフォーマンスが得られるように NAS 専用に最適化モードを有効</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">拡張性の向上</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">SRM 8.3 以降で使用する ONTAP ツールでは、 SRA で最大 500 個の保護グループ（ PG ）がサポートされるようになりました。</block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">同期レプリケーション</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">待望の新機能として、 ONTAP 9.5 以降を搭載した SnapMirror Synchronous （ SM-S ）があります。この機能は、ミッションクリティカルなアプリケーションに対して、ボリュームレベルで RPO ゼロのデータレプリケーション解決策を提供します。SM-S には、 ONTAP ツール 9.8 以降が必要です。</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">REST API をサポート</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">SRA サーバの設定を REST API で管理できるようになりました。自動化ワークフローの構築を支援するために Swagger UI が追加されていますまた 'https://&lt;appliance&gt;:8143/api/rest/swagger-ui.html#/` にある ONTAP ツール・アプライアンスからも参照できます</block>
  <block id="160f88ca0bed5b24e94c809f4e22f1e7" category="summary">ONTAP 9 では、クラスタの物理コンポーネントはクラスタ管理者には見えますが、クラスタを使用しているアプリケーションやホストからは直接見えません。</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">レプリケーショントポロジ</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">ONTAP 9 では、クラスタの物理コンポーネントはクラスタ管理者には見えますが、クラスタを使用しているアプリケーションやホストからは直接見えません。物理コンポーネントは共有リソースのプールを提供し、このリソースプールから論理クラスタリソースが構築されます。アプリケーションとホストは、ボリュームと LIF を含む SVM 経由でのみデータにアクセスします。</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">VMware vCenter Site Recovery Manager では、各 NetApp SVM がアレイとして扱われます。SRM は、特定のアレイ間（または SVM から SVM ）のレプリケーションレイアウトをサポートしています。</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">1 つの VM が、次の理由から、複数の SRM アレイ上で仮想マシンディスク（ VMDK ）または RDM を所有することはできません。</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM は SVM のみを認識し、個々の物理コントローラは認識しません。</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">SVM は、クラスタ内の複数のノードにまたがる LUN とボリュームを制御できます。</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">ベストプラクティス</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">サポートされるかどうかを判断するには、このルールに注意してください。 SRM と NetApp SRA を使用して VM を保護するには、 VM のすべての部分が 1 つの SVM 上にのみ存在する必要があります。このルールは、保護対象サイトとリカバリサイトの両方に適用されます。</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">サポートされる SnapMirror レイアウト</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">次の図は、 SRM と SRA でサポートされる SnapMirror 関係のレイアウトシナリオを示しています。レプリケートされたボリューム内の各 VM は、各サイトの 1 つの SRM アレイ（ SVM ）上のデータのみを所有します。</block>
  <block id="39d3085abe6ccb914d8535de8a5f3e37" category="paragraph"><block ref="39d3085abe6ccb914d8535de8a5f3e37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ae7670cf947a397bdf6a882fbcc912a" category="paragraph"><block ref="1ae7670cf947a397bdf6a882fbcc912a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="111d3212464dba203cbd675a0338dcbc" category="paragraph"><block ref="111d3212464dba203cbd675a0338dcbc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5dc3a606b05b41db22793ed3c1a72db" category="paragraph"><block ref="c5dc3a606b05b41db22793ed3c1a72db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">サポートされている Array Manager レイアウト</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">次のスクリーンショットに示すように、 SRM でアレイベースレプリケーション（ ABR ）を使用すると、保護グループは単一のアレイペアに分離されます。このシナリオでは、リカバリサイトで「 S VM1 」と「 S VM2 」は「 S VM3 」と「 S VM4 」とピア関係にあります。ただし、保護グループを作成するときに選択できるアレイペアは 2 つのうちの 1 つだけです。</block>
  <block id="68a1b289711a591ed50627014cd01ce9" category="paragraph"><block ref="68a1b289711a591ed50627014cd01ce9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">サポートされないレイアウトです</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">サポート対象外の構成では、個々の VM が所有する複数の SVM にデータ（ VMDK または RDM ）があります。次の図に示す例では、「 VM1 」には 2 つの SVM 上のデータがあるため、 SRM で保護するように「 VM1 」を設定することはできません。</block>
  <block id="5c251a65e8394fbeaf104ba1a1cad2e1" category="paragraph"><block ref="5c251a65e8394fbeaf104ba1a1cad2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="paragraph"><block ref="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">1 つのネットアップボリュームを 1 つのソース SVM から同じ SVM または異なる SVM の複数のデスティネーションにレプリケートするレプリケーション関係は、 SnapMirror ファンアウトと呼ばれます。SRM ではファンアウトはサポートされていません。次の図の例では 'VM1 は SnapMirror で 2 つの異なる場所にレプリケートされるため 'SRM で保護するように構成できません</block>
  <block id="688890bdbdfd2d73a05a09883f3c4b40" category="paragraph"><block ref="688890bdbdfd2d73a05a09883f3c4b40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">SnapMirror カスケード</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SnapMirror でソースボリュームをデスティネーションボリュームにレプリケートし、そのデスティネーションボリュームを SnapMirror で別のデスティネーションボリュームにレプリケートする SnapMirror 関係のカスケードを、 SRM ではサポートしていません。次の図に示すシナリオでは、 SRM を使用してサイト間のフェイルオーバーを実行することはできません。</block>
  <block id="2990fc44e9ba827a397e96e1c278a02a" category="paragraph"><block ref="2990fc44e9ba827a397e96e1c278a02a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror と SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">NetApp SnapVault ソフトウェアを使用すると、ネットアップストレージシステム間でエンタープライズデータをディスクベースでバックアップできます。SnapVault と SnapMirror は同じ環境内に共存できますが、 SRM でサポートされているのは、 SnapMirror 関係のフェイルオーバーだけです。</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">NetApp SRA は、「 mirror vault 」ポリシータイプをサポートします。</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault は ONTAP 8.2 で一から再構築されました。以前の Data ONTAP 7-Mode で使用されていたユーザは共通点に注意する必要がありましたが、このバージョンの SnapVault では主に拡張機能が追加されています。大きな進歩の 1 つは、 SnapVault 転送時にプライマリデータの Storage Efficiency を維持できることです。</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">アーキテクチャの重要な変更点は、 7-Mode SnapVault の場合と同様に、 ONTAP 9 の SnapVault でも qtree レベルではなくボリュームレベルでレプリケートされる点です。つまり、 SnapVault 関係のソースはボリュームでなければならず、そのボリュームは SnapVault セカンダリシステム上の独自のボリュームにレプリケートされる必要があります。</block>
  <block id="f7b20cbc14027c7711d53d03a84f31af" category="paragraph">SnapVault を使用する環境では、具体的にはプライマリストレージシステムに Snapshot コピーという名前が作成されます。実装した構成に応じて、指定した Snapshot コピーは、 SnapVault スケジュールまたは NetApp Active IQ Unified Manager などのアプリケーションによってプライマリシステム上に作成できます。プライマリシステムで作成された名前付きの Snapshot コピーは、 SnapMirror デスティネーションにレプリケートされ、そこから SnapVault デスティネーションに保存されます。</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">ソースボリュームは、ボリュームが DR サイトの SnapMirror デスティネーションにレプリケートされるカスケード構成で作成でき、そこから SnapVault デスティネーションに保存されます。ファンアウト関係では、一方のデスティネーションが SnapMirror デスティネーション、もう一方が SnapVault デスティネーションであるソースボリュームも作成できます。ただし、 SRM フェイルオーバーまたはレプリケーションの反転時に、 SRA は、 SnapMirror デスティネーションボリュームを SnapVault のソースとして使用するように SnapVault 関係を自動では再設定しません。</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">TR-4015 『 SnapMirror Configuration Best Practice Guide for ONTAP 9 』</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">SnapMirror および SnapVault for ONTAP 9 の最新情報については、を参照してください<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">SnapVault と SRM を同じ環境で使用する場合、通常は DR サイトの SnapMirror デスティネーションから SnapVault バックアップを実行する、 SnapMirror から SnapVault へのカスケード構成を使用することを推奨します。災害が発生すると、この構成によってプライマリサイトにアクセスできなくなります。リカバリサイトに SnapVault デスティネーションを配置すると、フェイルオーバー後に SnapVault バックアップを再設定して、リカバリサイトで SnapVault バックアップを継続できるようになります。</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">VMware 環境では、各データストアに Universal Unique Identifier （ UUID ）が割り当てられ、各 VM には一意の Managed Object ID （ MOID ）が割り当てられます。SRM は、フェイルオーバーやフェイルバックの実行時にこれらの ID を維持しません。SRM はフェイルオーバーでデータストア UUID と VM MOID を維持しないため、これらの ID に依存するアプリケーションは SRM フェイルオーバーのあとに再設定する必要があります。たとえば、 SnapVault レプリケーションを vSphere 環境と調整する NetApp Active IQ Unified Manager などがあります。</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">次の図に、 SnapMirror から SnapVault へのカスケード構成を示します。SnapVault デスティネーションがプライマリサイトの停止の影響を受けない DR サイトまたは第 3 のサイトにある場合、フェイルオーバー後にバックアップを続行できるように環境を再設定できます。</block>
  <block id="b56afb9a43332c671116b9fa3d597867" category="paragraph"><block ref="b56afb9a43332c671116b9fa3d597867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">次の図は、 SRM を使用して SnapMirror レプリケーションをプライマリサイトに反転したあとの構成を示しています。SnapMirror ソースから SnapVault バックアップが実行されるように環境が再設定されている。このセットアップは、 SnapMirror SnapVault のファンアウト構成です。</block>
  <block id="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="paragraph"><block ref="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">SRM でフェイルバックを実行し、 SnapMirror 関係が再度反転されると、本番環境のデータはプライマリサイトに戻ります。SnapMirror と SnapVault のバックアップにより、 DR サイトへのフェイルオーバー前と同じ方法でこのデータを保護できるようになりました。</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Site Recovery Manager 環境での qtree の使用</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">qtree は、 NAS のファイルシステムクォータを適用可能な特殊なディレクトリです。ONTAP 9 では qtree を作成でき、 SnapMirror でレプリケートされたボリュームに配置できます。ただし、 SnapMirror では、個々の qtree のレプリケーションまたは qtree レベルのレプリケーションは実行できません。すべての SnapMirror レプリケーションは、ボリュームレベルで実行されます。このため、 SRM で qtree を使用することは推奨されません。</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">FC と iSCSI の混在環境</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">サポート対象の SAN プロトコル（ FC 、 FCoE 、 iSCSI ）の場合、 ONTAP 9 は LUN サービスを提供します。 LUN サービスの提供とは、 LUN を作成して、接続されているホストにマッピングする機能です。クラスタは複数のコントローラで構成されるため、個々の LUN へのマルチパス I/O で管理される論理パスが複数あります。ホスト上で Asymmetric Logical Unit Access （ ALUA ；非対称論理ユニットアクセス）が使用されるため、 LUN への最適なパスが選択され、データ転送用にアクティブになります。LUN への最適パスが変わった場合（格納先ボリュームが移動された場合など）、 ONTAP 9 は自動的にこの変更を認識し、システムを停止することなく調整します。最適パスが利用できなくなった場合、 ONTAP は無停止で他の利用可能なパスに切り替えることができます。</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM と NetApp SRA の環境では、一方のサイトで FC プロトコルを使用し、もう一方のサイトで iSCSI プロトコルを使用できます。ただし、 FC 接続のデータストアと iSCSI 接続のデータストアを同じ ESXi ホストで混在させたり、同じクラスタ内の別のホストで使用したりすることはできません。この構成は SRM ではサポートされていません。 SRM フェイルオーバーまたはテストフェイルオーバーの実行中、 SRM は要求に応じて ESXi ホストのすべての FC イニシエータと iSCSI イニシエータを含めます。</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM と SRA では、保護サイトとリカバリサイト間での FC プロトコルと iSCSI プロトコルの混在をサポートしています。ただし、各サイトで FC または iSCSI のどちらかのプロトコルを 1 つだけ使用し、同じサイトで両方のプロトコルを使用することはできません。1 つのサイトに FC プロトコルと iSCSI プロトコル両方を設定する必要がある場合、一部のホストで iSCSI を使用し、他のホストで FC を使用することを推奨します。また、 VM がどちらか一方のホストグループまたは他方のホストグループにフェイルオーバーするように設定されるように、 SRM リソースマッピングを設定することも推奨します。</block>
  <block id="1918f1bc0ea91d0e5d8e37878d5ab562" category="sidebar">NetApp ONTAP 9 を搭載した VMware Site Recovery Manager</block>
  <block id="e88a70d67e9de42d391fd019f2d06484" category="summary">このドキュメントに記載されている情報の詳細については、以下のドキュメントや Web サイトを参照してください。</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="doc">追加情報</block>
  <block id="b49efd5b259d6a3bceda1ebb8e34064a" category="list-text">データセット： TuSimple</block>
  <block id="61554b11b65c50bf7a094a86d699c8d5" category="inline-link"><block ref="61554b11b65c50bf7a094a86d699c8d5" category="inline-link-rx"></block></block>
  <block id="b150fd9c1d7740c871626031a398c8a3" category="paragraph"><block ref="b150fd9c1d7740c871626031a398c8a3" category="inline-link-rx"></block></block>
  <block id="a3a3504f7b11916e352125a598e15797" category="list-text">ディープラーニングネットワークアーキテクチャ：空間的な畳み込みニューラルネットワーク</block>
  <block id="6467a460cb421335f9f5b0523c38c9a6" category="inline-link"><block ref="6467a460cb421335f9f5b0523c38c9a6" category="inline-link-rx"></block></block>
  <block id="35527148b08f99f1d85797af833430dc" category="paragraph"><block ref="35527148b08f99f1d85797af833430dc" category="inline-link-rx"></block></block>
  <block id="cc1881adebe7ddf5b873966741a32ef1" category="list-text">分散型ディープラーニングトレーニングフレームワーク： Horovod</block>
  <block id="732f85d0d5eaa9222831dd5290518ff2" category="inline-link"><block ref="732f85d0d5eaa9222831dd5290518ff2" category="inline-link-rx"></block></block>
  <block id="655c281079d0281fcf4b8f2f08634c16" category="paragraph"><block ref="655c281079d0281fcf4b8f2f08634c16" category="inline-link-rx"></block></block>
  <block id="934b1fbd011b584c4878284f454f812e" category="list-text">実行： AI コンテナオーケストレーション解決策： run ： AI 製品の概要</block>
  <block id="64b899832bfcad18bb426fb355a0d03b" category="inline-link"><block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="b78ec84f003a4d277e318031a163e191" category="paragraph"><block ref="b78ec84f003a4d277e318031a163e191" category="inline-link-rx"></block></block>
  <block id="275dbaaa3169640f82917075918df905" category="list-text">実行： AI インストールドキュメント</block>
  <block id="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link"><block ref="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link-rx"></block></block>
  <block id="517046a8acf2e7fa61798debc5b6e25e" category="inline-link"><block ref="517046a8acf2e7fa61798debc5b6e25e" category="inline-link-rx"></block></block>
  <block id="b8b2e04f115b148d49a8cb477ed86af9" category="paragraph"><block ref="f03e58e4917966d9b82995c8ce69643b" category="inline-link-rx"></block><block ref="3530112fad5ba376549c9e0750df83f3" category="inline-link-rx"></block></block>
  <block id="8787c0bfc5af7ce34db56c9a5739f788" category="list-text">実行時のジョブの送信： AI CLI</block>
  <block id="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link"><block ref="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link-rx"></block></block>
  <block id="ca4ef6cf830a9de78ea71279d0d5417c" category="paragraph"><block ref="ca4ef6cf830a9de78ea71279d0d5417c" category="inline-link-rx"></block></block>
  <block id="984fd97f526f8afe9d2472b0894b84c2" category="inline-link"><block ref="984fd97f526f8afe9d2472b0894b84c2" category="inline-link-rx"></block></block>
  <block id="65640a241681656a4410cd7184278c9b" category="paragraph"><block ref="65640a241681656a4410cd7184278c9b" category="inline-link-rx"></block></block>
  <block id="33a756969a35b0a9029bf2a2c10e6d67" category="list-text">Azure クラウドリソース： Azure NetApp Files</block>
  <block id="99ac98f589f6b551211f31e86cb9a212" category="inline-link"><block ref="99ac98f589f6b551211f31e86cb9a212" category="inline-link-rx"></block></block>
  <block id="3085d4407b575d4a8938814c7db17d92" category="paragraph"><block ref="3085d4407b575d4a8938814c7db17d92" category="inline-link-rx"></block></block>
  <block id="f938809a358080d4c7a941e59abfca40" category="list-text">Azure Kubernetes Service の略</block>
  <block id="21d0acc34f6416d6ebd8074617c57439" category="inline-link"><block ref="21d0acc34f6416d6ebd8074617c57439" category="inline-link-rx"></block></block>
  <block id="91c4b230ded9b13564b447ba71304aeb" category="paragraph"><block ref="91c4b230ded9b13564b447ba71304aeb" category="inline-link-rx"></block></block>
  <block id="d9d650693b25d0540fbb606b1d1fbe4e" category="list-text">Azure VM SKUs</block>
  <block id="08318cbecd61665ab1824d118c1029a5" category="inline-link"><block ref="08318cbecd61665ab1824d118c1029a5" category="inline-link-rx"></block></block>
  <block id="3e05fd8f7e2e0ac6116dd746a8823eaa" category="paragraph"><block ref="3e05fd8f7e2e0ac6116dd746a8823eaa" category="inline-link-rx"></block></block>
  <block id="b9a1a7c8f2194407b24183f7826d2e44" category="list-text">Azure VM と GPU SKU</block>
  <block id="6046df9266bb79e1d99f9c232c1835e3" category="inline-link"><block ref="6046df9266bb79e1d99f9c232c1835e3" category="inline-link-rx"></block></block>
  <block id="d0bf246853f6f35070f6a8231d468c87" category="paragraph"><block ref="d0bf246853f6f35070f6a8231d468c87" category="inline-link-rx"></block></block>
  <block id="43a545df8285ba2aba289a52824f250d" category="inline-link"><block ref="43a545df8285ba2aba289a52824f250d" category="inline-link-rx"></block></block>
  <block id="944823ac69152177e369bd5d9a61a02f" category="paragraph"><block ref="944823ac69152177e369bd5d9a61a02f" category="inline-link-rx"></block></block>
  <block id="a9359a0f51034e1b1972f7690fe03f71" category="list-text">ネットアップのデータファブリック</block>
  <block id="781262103885a96ffc9275431a7ef132" category="inline-link"><block ref="781262103885a96ffc9275431a7ef132" category="inline-link-rx"></block></block>
  <block id="93e35e3e458c1d81846aa83c346e240e" category="paragraph"><block ref="93e35e3e458c1d81846aa83c346e240e" category="inline-link-rx"></block></block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="a6214fe1ac9a6825ffe38f3b34489c9d" category="summary">ネットアップの Run AI は、このテクニカルレポートの作成時にパートナー関係を結び、 Azure NetApp Files 独自の機能と、 AI ワークロードのオーケストレーションを簡易化する Run AI プラットフォームを実証しています。</block>
  <block id="a55106260c16aab506cebfb58e07e030" category="paragraph">ネットアップと Run ： AI は、このテクニカルレポートの作成時にパートナー関係を結び、 Azure NetApp Files 独自の機能と、 AI ワークロードのオーケストレーションを簡易化する AI プラットフォームを、 RUN の手法で実証しています。このテクニカルレポートでは、分散レーン検出トレーニングのためにデータパイプラインとワークロードオーケストレーションのプロセスを合理化するリファレンスアーキテクチャを提供します。</block>
  <block id="4e51614a389f3ad4fa17e2ce7ad984e7" category="paragraph">その結果、大規模な分散トレーニング（特にパブリッククラウド環境）に関しては、リソースのオーケストレーションとストレージのコンポーネントは解決策の重要な要素となります。データ管理によって複数の GPU 処理が妨げられることがないようにすることで、 GPU サイクルの利用率を最適化できます。そのため、大規模な分散トレーニングのために、システムをできるだけ費用対効果の高いものにすることができます。</block>
  <block id="269c35b1959d92e9ef6665bb4c60ad5d" category="paragraph">ネットアップが提供するデータファブリックを使用すると、データサイエンティストやデータエンジニアは、手動操作なしでオンプレミスとクラウドを連携させ、同期データを保持できるため、この課題を克服できます。つまり、データファブリックによって、 AI ワークフローを複数の場所に分散して管理するプロセスがスムーズになります。また、コンピューティングと分析、トレーニング、検証に必要なときに必要な場所でデータを利用できるため、オンデマンドでのデータ可用性が容易になります。この機能により、データ統合だけでなく、データパイプライン全体の保護とセキュリティも実現できます。</block>
  <block id="7a879e305f90568b91e8623ce5f9ee39" category="summary">2019 年 5 月より、 Microsoft は Azure ネイティブのファーストパーティポータルサービスを提供し、 NetApp ONTAP テクノロジを基盤とするエンタープライズ NFS および SMB ファイルサービスを提供しています。</block>
  <block id="0bf51d984b6a6d3fddc0e24f62eb1a14" category="doc">TR-4886 ：『 Distributed training in Azure ： Lane detection - 解決策 design 』</block>
  <block id="0ab5aa2896d8eed7732e69be5e5782b4" category="paragraph">Muneer Ahmad 氏と Verron Martina 氏、ネットアップの Ronen Dar 、 RUN ： AAI</block>
  <block id="a89ade32996e322edf837476febbc9bd" category="paragraph">2019 年 5 月より、 Microsoft は Azure ネイティブのファーストパーティポータルサービスを提供し、 NetApp ONTAP テクノロジを基盤とするエンタープライズ NFS および SMB ファイルサービスを提供しています。この開発は、 Microsoft とネットアップの戦略的パートナーシップによって推進されており、ワールドクラスの ONTAP データサービスの Azure への対応範囲がさらに拡大しています。</block>
  <block id="d6312cb01ee08559dbaa35c308e72268" category="paragraph">業界をリードするクラウドデータサービスプロバイダであるネットアップは、 AI インフラを仮想化する企業である AI の運用を共同で開始し、 GPU 利用率を最大限に活用して AI の実験を高速化しました。このパートナーシップでは、多数の実験を並行して実行し、データへの高速アクセスを実現し、無限のコンピューティングリソースを活用することで、 AI を加速できます。Run ： AI は、リソースの割り当てを自動化することで GPU 利用率を最大限に高めます。実績のある Azure NetApp Files のアーキテクチャにより、データパイプラインに障害が生じることをなくし、あらゆる実験を最高の速度で実行できます。</block>
  <block id="5234f8ee670afed8c398940a707f25df" category="paragraph">ネットアップと RUN ： AI が力を合わせて、お客様に Azure で AI 導入を実現するための将来を見据えたプラットフォームを提供しています。分析やハイパフォーマンスコンピューティング（ HPC ）から自律判断（お客様は必要なときに必要なものだけを購入することで IT 投資を最適化できる）まで、ネットアップと RUN のアライアンスによって、 AI は Azure クラウドでの単一の統合エクスペリエンスを提供します。</block>
  <block id="ecb81ab37e1d2a7ed6dfce3807622e3d" category="summary">このセクションでは、ラン AI オーケストレーションツールを使用して大規模なレーン検出分散トレーニングを実行するためのプラットフォームの設定について詳しく説明します。</block>
  <block id="0714a752696f8feed939bbf52a6214f7" category="doc">レーン検出–実行による分散トレーニング： AI</block>
  <block id="dbf10b854b8b7fc90297279e7ad0f745" category="paragraph">このセクションでは、ランオーケストレーションツール AI を使用して大規模なレーン検出分散トレーニングを実行するためのプラットフォームの設定について詳しく説明します。ここでは、すべての解決策要素のインストールと、前述のプラットフォームでの配布トレーニングジョブの実行について説明します。ML のバージョン管理には、 NetApp SnapshotTM を使用し、 RUN ： AI の実験によってデータとモデルの再現性を達成しました。ML のバージョン管理は、モデルの追跡、チームメンバー間での作業の共有、結果の再現性、生産への新しいモデルバージョンのローリング、データソースの作成に重要な役割を果たします。ネットアップの ML バージョン管理（ Snapshot ）は、各実験に関連するデータ、トレーニング済みモデル、ログのポイントインタイムバージョンをキャプチャできます。豊富な API サポートにより、実行中の AI プラットフォームとの統合が容易になります。トレーニングの状態に基づいてイベントをトリガーするだけで済みます。また、コードや Kubernetes （ Kubernetes ）上で実行されているコンテナに何も変更を加えずに、実験全体の状態をキャプチャする必要もあります。</block>
  <block id="25d19977e35c6d286c5b051982ae3f3c" category="paragraph">最後に、このテクニカルレポートは、 AKS を介して複数の GPU 対応ノードでパフォーマンスを評価する方法をラップアップします。</block>
  <block id="1987a7039dccb848f2e8ce693ba3faff" category="section-title">TuSimple データセットを使用したレーン検出のユースケースに関する分散トレーニング</block>
  <block id="f75a7cb3d80e7be148c1ce86a4347011" category="paragraph">このテクニカルレポートでは、レーン検出用の TuSimple データセットに対して分散トレーニングを実行します。Horovod は、 AKS を使用して Kubernetes クラスタ内の複数の GPU ノードでデータ分散トレーニングを同時に実施するためのトレーニングコードで使用されます。コードは、 TuSimple データのダウンロードおよび処理用のコンテナイメージとしてパッケージされています。処理されたデータは、 NetApp Trident プラグインによって割り当てられた永続ボリュームに格納されます。トレーニングでは、 1 つ以上のコンテナイメージが作成され、データのダウンロード時に作成された永続ボリュームに格納されたデータが使用されます。</block>
  <block id="58b4798157820b4e4415d8136cf60fe9" category="paragraph">データとトレーニングのジョブを送信するには、 run ： AI を使用してリソースの割り当てと管理をオーケストレーションします。Run ： AI では、 Horovod に必要な Message Passing Interface （ MPI ；メッセージパッシングインターフェイス）処理を実行できます。このレイアウトでは、複数の GPU ノードが相互に通信して、各トレーニング mini バッチの実行後にトレーニングの重みを更新できます。また、 UI や CLI からトレーニングを監視できるため、実験の進捗状況を簡単に監視できます。</block>
  <block id="ecbeff08f5ec15c6952355b518d4ae02" category="paragraph">NetApp Snapshot はトレーニングコードに統合されており、あらゆる実験に対応するデータの状態とトレーニング済みモデルをキャプチャします。この機能を使用すると、使用するデータとコードのバージョン、および生成された関連するトレーニング済みモデルを追跡できます。</block>
  <block id="63addc90b28c066bd235c900fed65314" category="section-title">AK のセットアップとインストール</block>
  <block id="50f7d8213ee52350926ec407074e68f1" category="inline-link">AKS クラスタを作成します</block>
  <block id="55b295c729173e8c0c745bb036b03270" category="paragraph">AKS クラスタのセットアップとインストールは、に進みます<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block>。次に、次の一連の手順を実行します。</block>
  <block id="8f9d847fad9782b080de76b0161b1c45" category="list-text">ノードのタイプ（システム（ CPU ）ノードまたはワーカー（ GPU ）ノードのいずれであるか）を選択するときは、次のいずれかを選択します。</block>
  <block id="957d1a35f975177c3fd161490f3e2d83" category="list-text">「 agentpool 」という名前のプライマリ・システム・ノードを 'Standard _ DS2_v2' サイズに追加しますデフォルトの 3 つのノードを使用します。</block>
  <block id="8853a13db2e2a03cb5b2f1186fbcd0a6" category="list-text">'Standard_NC6s_v3' プール・サイズを使用して 'Worker ノード gpupool' を追加しますGPU ノードには最小 3 ノードを使用します。</block>
  <block id="5085043d6dea89934a2e516fc46f891a" category="paragraph"><block ref="5085043d6dea89934a2e516fc46f891a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633b880bff72a9f1c1114df31dec55bf" category="admonition">導入には 5 ～ 10 分かかります。</block>
  <block id="f55bb34768c41f91318fb57b85c1def9" category="inline-link">ツールをインストールします</block>
  <block id="6369fc9d36c9d56cbebefdeccda5fbff" category="list-text">導入が完了したら、 Connect to Cluster （クラスタへの接続）をクリックします。新しく作成した AKS クラスタに接続するには、ローカル環境（ラップトップ / PC ）から Kubernetes コマンドラインツールをインストールします。にアクセスします<block ref="bcd577f96ff7023ec6fd5c904f040896" category="inline-link-rx"></block> OS に応じてインストールします。</block>
  <block id="811c47e56617f97db3579bc32a9085c9" category="inline-link">ローカル環境に Azure CLI をインストールします</block>
  <block id="ea5d45554a3e9cb9cbc0ddea4c228b28" category="list-text"><block ref="2db79c584144175dd0bb69b6c7045fc9" category="inline-link-rx"></block>。</block>
  <block id="825ca3bff78c42ec87920dfbce105fae" category="list-text">端末から AKS クラスタにアクセスするには、まず「 AZ login 」と入力し、クレデンシャルを入力します。</block>
  <block id="3394029cd334ed00686c86c088d73c24" category="list-text">次の 2 つのコマンドを実行します。</block>
  <block id="193937b265ce655417f00a79334d3937" category="list-text">Azure CLI で、次のコマンドを入力します。</block>
  <block id="cbf78d8bb0be543834c56e61560773b0" category="admonition">ここで示したように 6 つのノードがすべて稼働していれば、 AKS クラスタをローカル環境に接続することができます。</block>
  <block id="e8085ec7505cfe6f3cfbe2c2628386dc" category="paragraph"><block ref="e8085ec7505cfe6f3cfbe2c2628386dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0143a2caee1b9ab090de587206b65fe6" category="section-title">Azure NetApp Files の委譲されたサブネットを作成します</block>
  <block id="450cf7e7f8262fdaa3454c2e11aad687" category="paragraph">Azure NetApp Files の委任されたサブネットを作成するには、次の手順を実行します。</block>
  <block id="0ca30ab1eb5e523356720465eb7439c8" category="list-text">Azure ポータル内の仮想ネットワークに移動します。新しく作成した仮想ネットワークを検索します。この例では、 AKs-vnet などのプレフィックスが必要です。仮想ネットワークの名前をクリックします。</block>
  <block id="ce0c628aca3577055043c7f8364600d9" category="paragraph"><block ref="ce0c628aca3577055043c7f8364600d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25157709e5a253560f5ec68b8262563c" category="list-text">[ サブネット ] をクリックし、上部のツールバーから [ サブネット + ] を選択します。</block>
  <block id="d9bf5876b80dbf558587f06630e3915c" category="paragraph"><block ref="d9bf5876b80dbf558587f06630e3915c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a07ef5dbc59d5ba150de82d519fb4f8" category="list-text">サブネットに「 ANF 」などの名前を付け、サブネットの委任の見出しの下で、 Microsoft.NetApp/volumes を選択します。他のものは変更しないでください。[OK] をクリックします。</block>
  <block id="a8ccea52e17d54aea1295a99ab4d5c2e" category="paragraph"><block ref="a8ccea52e17d54aea1295a99ab4d5c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d182b62071ada1a29e4f9c26487c1121" category="paragraph">Azure NetApp Files ボリュームはアプリケーションクラスタに割り当てられ、 Kubernetes で永続ボリューム要求（ PVC ）として使用されます。この割り当てにより、ボリュームをさまざまなサービスに柔軟にマッピングし、 Jupyter ノートブック PC やサーバーレス関数などに対応することができます</block>
  <block id="a74ff852d3b3b8447b0306018a76c4f1" category="paragraph">サービスのユーザは、プラットフォームのストレージをさまざまな方法で消費できます。Azure NetApp Files の主な利点は次のとおりです。</block>
  <block id="a7c5a83cc4ccf14374e496bcbb4363f5" category="list-text">スナップショットを使用できるようになります。</block>
  <block id="ea437fe76a4bba5bf335daccbbd24b50" category="list-text">Azure NetApp Files ボリュームに大量のデータを格納できます。</block>
  <block id="cedebf66380d43f58c07dfb1d4d686a6" category="list-text">Azure NetApp Files ボリュームのモデルを大量のファイルセットで実行する場合は、そのモデルのパフォーマンス向上が必要になります。</block>
  <block id="75ab13308585f62c3cd57a246d0e0c64" category="section-title">Azure NetApp Files セットアップ</block>
  <block id="8c060d9ae24c7bc4518e54cd5ed13098" category="inline-link">クイックスタート： Azure NetApp Files をセットアップし、 NFS ボリュームを作成します</block>
  <block id="fd01c32c80d631ed4bebff78fa83b23e" category="paragraph">Azure NetApp Files のセットアップを完了するには、まず、の説明に従って を設定する必要があります<block ref="2f4e63e538c7dd311b18db058621cef8" category="inline-link-rx"></block>。</block>
  <block id="e26f032bd6f7f5636860d6b94ac84859" category="paragraph">ただし、 Trident からボリュームを作成するため、 Azure NetApp Files 用の NFS ボリュームを作成する手順は省略できます。続行する前に、次のものがあることを確認してください。</block>
  <block id="e953b5e281d40c5db3cc047889eec4f2" category="inline-link">Azure NetApp Files とネットアップのリソースプロバイダに登録（ Azure Cloud Shell を使用）</block>
  <block id="3b46d13fb20fe6a92456f742b5732774" category="list-text"><block ref="527fb205c939c551ed93f597562513fb" category="inline-link-rx"></block>。</block>
  <block id="d0652e942d3d4b469179248d72ccaa5c" category="inline-link">Azure NetApp Files でアカウントを作成</block>
  <block id="82a51bbfec23ca7366c216813caeacc8" category="list-text"><block ref="874637dbfce24ba5a63adadd91968dc9" category="inline-link-rx"></block>。</block>
  <block id="02209b9e3a221b39bf0ce87641e7afc6" category="inline-link">容量プールをセットアップする</block>
  <block id="7b4cb99ad8c150ff95b1a65d0f0524cc" category="list-text"><block ref="0fa33cef09dfad4c8795f42dd9dd5248" category="inline-link-rx"></block> （必要に応じて、 4TiB Standard または Premium 以上）。</block>
  <block id="1c7c9057bf4f7aee40c5a117c160c0fd" category="section-title">AKS 仮想ネットワークおよび Azure NetApp Files 仮想ネットワークのピアリング</block>
  <block id="998069ab494c49ade2cc77591c02d9fa" category="paragraph">次に、次の手順に従って、 Azure NetApp Files VNet とともに AKS 仮想ネットワーク（ VNet ）のピア関係を設定します。</block>
  <block id="bf12dce8dcc6febfeddec5ed2570e7d7" category="list-text">Azure ポータル上部の検索ボックスに「 virtual networks 」と入力します。</block>
  <block id="3f961f79effdf0aa37042e1733ee53ef" category="list-text">vnet AK - vnet-name をクリックして、検索フィールドにピアを入力します。</block>
  <block id="0249aa06ef3e10e8754106189b542be4" category="list-text">+ Add をクリックして、次の表に示す情報を入力します。</block>
  <block id="6f16a5f8ff5d75ab84c018adacdfcbb7" category="cell">フィールド</block>
  <block id="88645c17102d75583e93db9aa716b012" category="cell">Value または概要のいずれかです</block>
  <block id="f80824cb9ab9f704542dec0c71c5f38b" category="cell">ピアリングリンク名</block>
  <block id="5d43607a5a0ebb50f3ea9348485daa15" category="cell">AKs-vnet-name_-to-anf</block>
  <block id="62912b52e584278e26870d9e5092e723" category="cell">サブスクリプション ID</block>
  <block id="7d97336a164d9ce685e88a121141b189" category="cell">ピアリング先の Azure NetApp Files VNet のサブスクリプション</block>
  <block id="82a60e720574cf435dda0a03976e8323" category="cell">VNet ピアリングパートナー</block>
  <block id="d2ade9376eb8b87db099330d20c4f180" category="cell">Azure NetApp Files VNet の略</block>
  <block id="5b92ad691782a9e4cc701e479c90997f" category="admonition">デフォルトでは、アスタリスク以外のすべてのセクションはそのままにしておきます</block>
  <block id="0e5883528161213f3edc02dd718e1693" category="list-text">[Add] または [OK] をクリックして、仮想ネットワークにピアリングを追加します。</block>
  <block id="12eee9bf8836d675f26602260016f7da" category="inline-link">仮想ネットワークピアリングを作成、変更、削除します</block>
  <block id="fa1f15d2aebd0592f338ea9f49e06377" category="paragraph">詳細については、を参照してください<block ref="610fa6db13a2eefe4a391b16732fbbf0" category="inline-link-rx"></block>。</block>
  <block id="91d2f55da5f23abbcf1a0656897d101b" category="paragraph">Trident は、アプリケーションコンテナの永続的ストレージ向けにネットアップが管理しているオープンソースプロジェクトです。Trident は、ポッドとして実行される外部プロビジョニングコントローラとして実装され、ボリュームを監視し、プロビジョニングプロセスを完全に自動化します。</block>
  <block id="4088b2a65b2a3182209479dced5e78c5" category="paragraph">NetApp Trident では、トレーニングデータセットとトレーニング済みモデルを格納する永続的ボリュームを作成して接続することで、 Kubernetes との円滑な統合が可能です。データサイエンティストやデータエンジニアは、データセットを手動で保存して管理する手間をかけることなく、 Kubernetes クラスタを簡単に使用できます。Trident では、論理的な API 統合を通じてデータ管理関連のタスクが統合されるため、データサイエンティストは新しいデータプラットフォームの管理を習得する必要もありません。</block>
  <block id="77dc68d199719a4b8f5eba742ecb7056" category="paragraph">Trident ソフトウェアをインストールするには、次の手順を実行します。</block>
  <block id="2f2e9ef9449e2f31756b1d3683a207b3" category="inline-link">最初に Helm をインストールします</block>
  <block id="089f0e488d4e2b1a4b02d6d6b638c9d3" category="list-text"><block ref="b3c10ddb3b7f0e3e121ce123f60cc497" category="inline-link-rx"></block>。</block>
  <block id="e12559703ec38e80de7b94fecc84a043" category="list-text">Trident 21.01.1 インストーラをダウンロードして展開します。</block>
  <block id="7ee913d1a8b01e1a461f9eb99b0bba74" category="list-text">ディレクトリを 'trident-installer' に変更します</block>
  <block id="8ad5650fb94bff45b328581838d836fd" category="list-text">tridentctl' をシステムの $path.` のディレクトリにコピーします</block>
  <block id="6da8d48465deb31425595b33a9172acf" category="list-text">Helm を使用して Kubernetes クラスタに Trident をインストールします。</block>
  <block id="7b09729551ddb1a7445f559eb1186978" category="list-text">ディレクトリを Helm ディレクトリに変更します。</block>
  <block id="27b4c36cae8d1c4fd515d289942c87cc" category="list-text">Trident をインストール</block>
  <block id="cea04f1ceb2ba2472ec50de3a03a689c" category="list-text">Trident ポッドのステータスを通常の Kubernetes クラスタの方法で確認します。</block>
  <block id="6ac3c5fc780260af91dd10523188e6fd" category="list-text">すべてのポッドが稼働中の場合は、 Trident がインストールされているので移行を推奨します。</block>
  <block id="7862dabe13bf66a99fcfd3a6b1af4d94" category="section-title">Azure NetApp Files のバックエンドとストレージクラスをセットアップする</block>
  <block id="7e98dce86779e84763b71398d851f7bb" category="paragraph">Azure NetApp Files バックエンドとストレージクラスをセットアップするには、次の手順を実行します。</block>
  <block id="dadab4bead78e450739c0f56bad40cda" category="list-text">ホームディレクトリに切り替えます。</block>
  <block id="65b8f7db2e9a3793e76d2ec3787f71fa" category="inline-link">プロジェクトリポジトリ</block>
  <block id="03636accad716972f761628ea21e43f6" category="list-text">をクローニングします<block ref="2b240ffa21ddbdc99d1706dee4302f7e" category="inline-link-rx"></block> lane -detection -SCNN-horovod`</block>
  <block id="0ea725833b806058fe7810e6be91f9c0" category="list-text">'trident-config' ディレクトリに移動します</block>
  <block id="c51fa2034e7d5d97ec8c31248fc18e98" category="list-text">Azure サービスの原則を作成します（サービスの原則は、 Trident が Azure と通信して Azure NetApp Files リソースにアクセスする方法です）。</block>
  <block id="7c794fc1e683a6843753158bb92cab75" category="paragraph">出力は次の例のようになります。</block>
  <block id="203565dfd87ac32927ce5a828d45babd" category="list-text">Trident のバックエンド JSON ファイルを作成します。</block>
  <block id="d7e47f31bf1c921dd5e28ee7e6f5cd34" category="list-text">任意のテキストエディタを使用して 'anf-backend.json ファイル内の下の表の次のフィールドに入力します</block>
  <block id="8c443e170595ba0feac007ffb92cb49a" category="cell">サブスクリプション ID</block>
  <block id="deb6a9aaa10be6bb24feea6a3540128c" category="cell">お客様の Azure サブスクリプション ID</block>
  <block id="bc54592d6183695b841c6d1880ec0bf8" category="cell">tenantID のこと</block>
  <block id="b147f00fa948b22faa89aa8044904495" category="cell">Azure テナント ID （前の手順での AZ AD SP の出力から取得）</block>
  <block id="93c5bebdea9c94a0740fe6fd9bb250f0" category="cell">ClientID</block>
  <block id="5760e6800c58c7dc9ee68efdc6db38de" category="cell">自分の appID （前のステップでの AZ 広告 SP の出力から）</block>
  <block id="2b53761249254ce6b502f521e5cc0683" category="cell">clientSecret</block>
  <block id="0571f76a94493cb2020d6c3b7453a367" category="cell">パスワード（前の手順での AZ AD SP の出力からの）</block>
  <block id="25e6b7ea847b31b4f88b60acd65052db" category="paragraph">ファイルは次の例のようになります。</block>
  <block id="49356331b94221561b7751ae1f5343a9" category="list-text">構成ファイルとして 'anf-backend.json を使用して 'trident' 名前空間に Azure NetApp Files バックエンドを作成するように Trident に指示します</block>
  <block id="bd9c5e9bd5f130a6fbdbcaeb04656652" category="list-text">ストレージクラスを作成します。</block>
  <block id="a9fa0a3d8bf1bce76ef654f0a047b8fe" category="list-text">k8 ユーザは、ストレージクラスを名前で指定する PVC を使用してボリュームをプロビジョニングします。次のコマンドを使用して ' 前の手順で作成した Azure NetApp Files バックエンドを参照するストレージ・クラス 'azurenetappfiles' を作成するよう 'Kubernetes クラスタに指示します</block>
  <block id="5e121b263b32950e629eaf774c12da78" category="list-text">次のコマンドを使用して、ストレージクラスが作成されたことを確認します。</block>
  <block id="202ed88f7ec48eda708f6c062786f474" category="paragraph"><block ref="202ed88f7ec48eda708f6c062786f474" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72611a189b0331f709788d99912a1bd7" category="section-title">ボリューム Snapshot コンポーネントを AKS に導入してセットアップします</block>
  <block id="3ea90db69187da57e9739e033add6801" category="paragraph">適切なボリューム Snapshot コンポーネントがあらかじめクラスタにインストールされていない場合は、次の手順を実行して、これらのコンポーネントを手動でインストールできます。</block>
  <block id="c3987ca9f11aad20ef5d2ae0dd30f9cb" category="admonition">AK 1.18.14 には Snapshot コントローラが事前にインストールされていません。</block>
  <block id="312e34d756f6ef39f0bd74e2f844773f" category="list-text">次のコマンドを使用して、スナップショットベータ版の CRD をインストールします。</block>
  <block id="529616f838a47cade6e5fac6f879ce5a" category="list-text">GitHub の次のドキュメントを使用して、 Snapshot Controller をインストールします。</block>
  <block id="90a2427d3a3145723cd2a130c5372865" category="inline-link">ボリューム Snapshot クラス</block>
  <block id="8f2838f14b6a64dd466dc23bcf7e3c01" category="list-text">ボリュームスナップショットを作成する前に 'K8s'volumesnapshotclass' を設定します<block ref="cba124de563550c68e57cf9a6641a5d1" category="inline-link-rx"></block> セットアップが完了している必要があります。Azure NetApp Files のボリューム Snapshot クラスを作成し、ネットアップの Snapshot テクノロジを使用して ML のバージョン管理を実現します。volumesnapshotclass NetApp-csi-snapclass' を作成し ' 次のようにデフォルトの ` volumesnapshotclass 」に設定します</block>
  <block id="adc3a39a071327998da9cc6708ef4fe8" category="paragraph"><block ref="adc3a39a071327998da9cc6708ef4fe8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="770bec683fa99c1a917babb074d95e66" category="list-text">次のコマンドを使用して、ボリュームの Snapshot コピークラスが作成されたことを確認します。</block>
  <block id="99b5a364457d91999df6ca6488b800f2" category="paragraph"><block ref="99b5a364457d91999df6ca6488b800f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d9a6cca62c9095cbae70692ef82741c" category="section-title">「 AI Installation 」を実行します</block>
  <block id="d1d2b81816d977b7a9d3480a495beda5" category="paragraph">Run ： AI をインストールするには、次の手順を実行します。</block>
  <block id="7899a1a12ecf76a5676a6d5ddb64842f" category="inline-link">Run ： AI クラスタを AKS にインストールします</block>
  <block id="54437101a8cdfe297499d517331ced60" category="list-text"><block ref="400679f1b873ae4a832f018613d486cc" category="inline-link-rx"></block>。</block>
  <block id="5f854e827ba37f66f45f8e47643e23ea" category="list-text">app.runai.ai にアクセスし、 [ 新しいプロジェクトの作成 ] をクリックして、レーン検出という名前を付けます。'runai' で始まる名前空間を Kubernetes クラスタに作成し ' そのあとにプロジェクト名を付けますこの場合、作成される名前空間は runai-lane detection になります。</block>
  <block id="e699d582d1b58a9a23ebd74cab11d5bc" category="paragraph"><block ref="e699d582d1b58a9a23ebd74cab11d5bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="546524b2c8ed6fd083c9286159ebd55a" category="inline-link">インストール実行： AI CLI</block>
  <block id="f3a9807f54199fd5dbad651af2ea853a" category="list-text"><block ref="6291ffcd5a23a3d0b996bc90930ef0b3" category="inline-link-rx"></block>。</block>
  <block id="08d1d73b27232763a82ef46a413779ce" category="list-text">ターミナルで、次のコマンドを使用して、 LANE 検出をデフォルトの実行として AI プロジェクトに設定します。</block>
  <block id="0ca589f93fd9565aa5fc097fd66437ae" category="paragraph"><block ref="0ca589f93fd9565aa5fc097fd66437ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cd1a85dd18a7a0b8f1d07b4240fafcf" category="list-text">Create ClusterRole and ClusterRoleBinding for the project namespace (`lane detection など ) 」という名前空間に属するデフォルトのサービスアカウントには ' ジョブの実行中に "volumeSnapshot" 操作を実行する権限があります</block>
  <block id="351495b134e625df33dfb5230d6eab7b" category="list-text">次のコマンドを使用して、名前空間を一覧表示し、「 runai-lane -detection 」が存在することを確認します。</block>
  <block id="bd546162071f28fd50f8c977ac61149e" category="paragraph">次のような出力が表示されます。</block>
  <block id="8c33c9910dfecb6260489cd05f43b275" category="paragraph"><block ref="8c33c9910dfecb6260489cd05f43b275" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f23930532ba19f8970c6dcb4b6ad778f" category="list-text">次のコマンドを使用して、 ClusterRole 「 netappsnapshot 」および ClusterRoleBinding 「 netappsnapshot 」を作成します。</block>
  <block id="7e3ec6f763cd8a13380162aba60c47e0" category="section-title">TuSimple データセットを実行時の AI ジョブとしてダウンロードして処理します</block>
  <block id="c0cc307d9f63d0a096f8d6e3193cd561" category="paragraph">TuSimple データセットを実行としてダウンロードして処理するプロセス。 AI ジョブはオプションです。このプロセスでは、次の手順を実行します。</block>
  <block id="52eeaf7bac6d3e2111d129a11d0bafed" category="list-text">Docker イメージをビルドしてプッシュするか、既存の Docker イメージを使用する場合は、この手順を省略します（「 m uneer7589/download-tusimple:1.0 」など）</block>
  <block id="0d5647db76048e129c1146a822abbdd8" category="list-text">ホームディレクトリに移動します。</block>
  <block id="02c403c221afbdccdc4f7182e2eb5cb7" category="list-text">プロジェクト「 lane detection - SCNN-horovod` のデータディレクトリに移動します。</block>
  <block id="eed104c2f8af7c3526ec55b8cc69dde7" category="list-text">「 build_image.sh 」シェル・スクリプトを変更し、 Docker リポジトリを自分のものに変更します。たとえば、「 `m uneer7589` 」を Docker リポジトリ名に置き換えます。Docker イメージ名とタグ（「 ownload -tusimple 」や「 1.0 」など）を変更することもできます。</block>
  <block id="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="paragraph"><block ref="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed49e04589e6c9071bbd1af307f83a0" category="list-text">スクリプトを実行して Docker イメージを構築し、次のコマンドを使用して Docker リポジトリにプッシュします。</block>
  <block id="8ebf5e70d0ed304519c7c9b525d80af1" category="list-text">実行を送信します。 AI ジョブをダウンロードして抽出し、前処理し、 TupSimple LANE 検出データセットを「 pvc 」に格納します。このデータセットは、 NetApp Trident によって動的に作成されます。</block>
  <block id="050d58b165aef32cad86839521b721b2" category="list-text">実行ファイルを送信するには、次のコマンドを使用します。 AI job ：</block>
  <block id="83b4fb868b7505e293871c3e5accc98c" category="list-text">次の表に情報を入力して、実行ファイルを送信します。 AI job ：</block>
  <block id="e50d72d773874b2be58530daec43900c" category="cell">名前</block>
  <block id="37e9bb74490b0ac510effff5a546f11d" category="cell">ジョブの名前</block>
  <block id="5503ed8f71ae365eb6f5e8221562a0eb" category="cell">- PVC</block>
  <block id="626299ff067d1e6a178beced1631ab43" category="cell">[StorageClassName]: Size:ContainerMountPath という形式の PVC では、ストレージクラス azurenetappfiles で Trident を使用して、オンデマンドで PVC を作成します。この場合の永続ボリューム容量は 100Gi で、パス /mnt にマウントされます。</block>
  <block id="0247d7fb481075907b9eb467cfe90e3a" category="cell">イメージ（ Image ）</block>
  <block id="b30f1ca8b35fd6ccab829a959f414a51" category="cell">このジョブのコンテナの作成時に使用する Docker イメージ</block>
  <block id="22a55ba6c8590fa98f1b3234141f2848" category="paragraph"><block ref="22a55ba6c8590fa98f1b3234141f2848" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af270e479cd849e4a9cb6d17b76585ef" category="list-text">送信された RUN ： AI ジョブのリストを表示します。</block>
  <block id="f740410b6ea33d3ffc740140cc23a0e2" category="paragraph"><block ref="f740410b6ea33d3ffc740140cc23a0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51869a860c4af748ec2815d406929a17" category="list-text">送信されたジョブログを確認してください。</block>
  <block id="ab353387b0e5276e03aecae4cc95d150" category="paragraph"><block ref="ab353387b0e5276e03aecae4cc95d150" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84dd51baa0cf15db0a639dbb6d5d8ee" category="list-text">作成された「 pvc 」をリストします。次のステップでトレーニングを行うには ' この pvc コマンドを使用します</block>
  <block id="cc2e05fe54a847aee415a2deb0b7f13e" category="paragraph"><block ref="cc2e05fe54a847aee415a2deb0b7f13e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b20e4749f78095f0b9adf5c3cad36f81" category="list-text">実行中のジョブを確認します： AI UI （または app.run.ai` ）。</block>
  <block id="ced39410c19f3968638fc81e16743f32" category="paragraph"><block ref="ced39410c19f3968638fc81e16743f32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3dee54cb181d3bfde644600fb15bbac4" category="section-title">Horovod を使用して、分散レーン検出トレーニングを実施します</block>
  <block id="645e2c981858a720c673c6a782efd9ea" category="paragraph">Horovod を使用した分散型レーン検出トレーニングの実行は、オプションのプロセスです。ただし、実行する手順は次のとおりです。</block>
  <block id="04e568eec6dda4a0cfb1fc6680509d35" category="list-text">Docker イメージをビルドしてプッシュするか、既存の Docker イメージを使用する場合はこの手順を省略します（例：「 muneer7589/dist lane -detection ： 3.1 ）：」</block>
  <block id="b01fdc5088b4a04549ed5e7cc71f898b" category="list-text">ホームディレクトリに切り替えます。</block>
  <block id="14e21ef8495bc1dd543db0aebbe06c5b" category="list-text">プロジェクトディレクトリの lane -detection -SCNN-horovod. に移動します</block>
  <block id="0a27aa824e245e7b31f5f8d990636ead" category="list-text">「 build_image.sh 」シェルスクリプトを変更し、 Docker リポジトリを自分のものに変更します（たとえば、「 m uneer7589 」を Docker リポジトリ名に置き換えます）。Docker イメージ名とタグも変更できます（「 dist-dlane detection 」や「 3.1 」など）。</block>
  <block id="c9ce95c3d4cf96d5e894e4a834754cb6" category="paragraph"><block ref="c9ce95c3d4cf96d5e894e4a834754cb6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2776d43d1e635424496622f14cfd745c" category="list-text">スクリプトを実行して Docker イメージを構築し、 Docker リポジトリにプッシュします。</block>
  <block id="b9bcfd06c5cdfc67a00ffe8a0c846318" category="list-text">RUN ：「分散型トレーニング（ MPI ）実行のための AI ジョブ」を提出します。</block>
  <block id="f3b76b64a9761cfb85f0ddc37d910fef" category="list-text">実行の送信を使用：前述のステップで PVC を自動的に作成するための AI （データのダウンロード用）のみ RWO アクセスを許可します。これにより、複数のポッドまたはノードが分散トレーニング用に同じ PVC にアクセスすることはできません。アクセスモードを ReadWriteMany に更新し、 Kubernetes パッチを使用して更新します。</block>
  <block id="2874172b683ddc4047fd63f29baf543d" category="list-text">まず、次のコマンドを実行して PVC のボリューム名を取得します。</block>
  <block id="bcc0952c2970bfd6c85cd65050e00533" category="paragraph"><block ref="bcc0952c2970bfd6c85cd65050e00533" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64ac0e4e6343f4593e210b98f9c91de" category="list-text">ボリュームにパッチを適用し、アクセスモードを ReadWriteMany に更新します（次のコマンドでは、ボリューム名を各自のに置き換えてください）。</block>
  <block id="7a9d347cf2f324e82478a9cf243448f7" category="list-text">次の表の情報を使用して、分散トレーニングジョブを実行するための AI MPI ジョブを実行します。</block>
  <block id="b068931cc450442b63f5b3d276ea4297" category="cell">名前</block>
  <block id="e4580c1854231c935f0cf2eb4609d97a" category="cell">配布トレーニングジョブの名前</block>
  <block id="384dd16a327b7f16278642f008c27fab" category="cell">大きなシャン</block>
  <block id="fc9fed4d0a3cb207102499ba041f2603" category="cell">大容量の /dev/shm デバイスを RAM にマウントする共有ファイルシステムであり、複数の CPU ワーカーがバッチを処理して CPU RAM にロードするために十分な共有メモリを提供します。</block>
  <block id="530968b205d33b3869aa32e2933fbfad" category="cell">プロセス</block>
  <block id="403e4aa48fedb1c5777ee913b2f2bedb" category="cell">配布されたトレーニングプロセスの数</block>
  <block id="0aa0be2a866411d9ff03515227454947" category="cell">GPU</block>
  <block id="031492a2d708ca774bd08c099eb4dd79" category="cell">このジョブでジョブに割り当てる GPU / プロセスの数には、 3 つの GPU ワーカープロセスがあります（ --processes=3 ）。各プロセスは 1 つの GPU で割り当てられます（ --GPU 1 ）。</block>
  <block id="642542e40351edbd731ebad352b31317" category="cell">PVC</block>
  <block id="c50723a53a74a682495f8c3810ce4a65" category="cell">前のジョブ（ download-tusimple-data-0 ）によって作成された既存の永続ボリューム（ pvc -pdownload -tusimple-data-0 ）を使用し、パス /mnt にマウントします</block>
  <block id="8c236f63f205a50942b609a6d45734a7" category="cell">コンテナで設定する環境変数を定義します</block>
  <block id="61dcf83940f915d0c5fe5b985eed7be8" category="cell">ワーカーを使用します</block>
  <block id="f84e120605e14d9755a1ed2e8e03cea6" category="cell">引数を true に設定すると、マルチプロセスのデータロードがオンになります</block>
  <block id="90b186f5d2a6890e77373c8aa60461e7" category="cell">num_Workers</block>
  <block id="a10574eb8e119b847fb5ab95b788e723" category="cell">データローダーワーカープロセスの数</block>
  <block id="61c67ea819106ff81c08249014791d3b" category="cell">batch_size</block>
  <block id="243f7fe32e2dbb7748c1a018fe60016e" category="cell">トレーニングバッチサイズ</block>
  <block id="d07f4474a5e5996da9b6e57abb250331" category="cell">使用 _ VAL</block>
  <block id="919bc92a851c1d3e2c467e844398b751" category="cell">引数を true に設定すると、検証が可能になります</block>
  <block id="c4407b612c3b5e2c00c1b5522c686c84" category="cell">Val_batch_size</block>
  <block id="597765782da042e86019b4c919a86248" category="cell">検証バッチサイズ</block>
  <block id="18e0d33045db50bb37e6f2fcd5c0b842" category="cell">Snapshot の有効化</block>
  <block id="67c5deea68dff022b0f807ffb3bf56e2" category="cell">引数を true に設定すると、 ML バージョン管理のためにデータとトレーニング済みのモデルスナップショットを取得できます</block>
  <block id="cdd7dd1603420ef6c3efe7b264205137" category="cell">pvc_name</block>
  <block id="d95926771c9100db9ba3e3247c86a192" category="cell">スナップショットを作成する PVC の名前。上記のジョブ送信では、データセットとトレーニング済みモデルで構成される Pvc-de-download-tusimple-data-0 のスナップショットを作成します</block>
  <block id="b302d66ab7f3f0c94236ff26c8ead4d9" category="inline-image-macro">エラー：グラフィックイメージがありません</block>
  <block id="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="paragraph"><block ref="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3299ed00d03beff0cc2ebaf178a91786" category="list-text">送信されたジョブを一覧表示します。</block>
  <block id="2e593aa2ccf62807184e56a543d23e97" category="paragraph"><block ref="2e593aa2ccf62807184e56a543d23e97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82abe908a319245230ef0f3ec84c263f" category="list-text">送信されたジョブログ：</block>
  <block id="dab56217fc48a1919fee48434a7c7204" category="paragraph"><block ref="dab56217fc48a1919fee48434a7c7204" category="inline-image-macro-rx" type="image"></block></block>
  <block id="981528b0e4cd4a19c56310c6b9c915ce" category="list-text">実行中のトレーニングジョブを確認します。次の図に示すように、 AI GUI （または app.runai.ai): run ： AI Dashboard ）。最初の図は、分散トレーニングジョブ用に割り当てられた 3 つの GPU を AKS の 3 つのノードに分散し、 2 番目の実行である AI ジョブの詳細を示しています。</block>
  <block id="d8cbd4299e4baf5de5572bf6af32dd52" category="paragraph"><block ref="d8cbd4299e4baf5de5572bf6af32dd52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90fdc4068f0b660d1d6b102946986bd1" category="paragraph"><block ref="90fdc4068f0b660d1d6b102946986bd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e8bb0b427c33dd6cf63d1a3a37c7022" category="list-text">トレーニングが完了したら、作成され、実行済みの NetApp Snapshot コピーである AI ジョブを確認します。</block>
  <block id="6c94f812a836696605e3e2b6bd5ca768" category="paragraph"><block ref="6c94f812a836696605e3e2b6bd5ca768" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4c0a1395081fc81855e465c493f4967" category="section-title">NetApp Snapshot コピーからデータをリストアします</block>
  <block id="ec8de1dcfce51c9d877901e2f6f5971e" category="paragraph">NetApp Snapshot コピーからデータをリストアするには、次の手順を実行します。</block>
  <block id="5adc4d7860e7ad0f78ada0bb1f0eaca6" category="list-text">プロジェクトディレクトリの lane -detection -SCNN-horovod' に移動します</block>
  <block id="6344772f26907403fed713060f33b8f4" category="list-text">「 restore-snaphot-pvc.yaml 」を変更し、「 ataSource `name」 フィールドをデータのリストア元の Snapshot コピーに更新します。また、データを復元する PVC 名を変更することもできます。この例では、「 restored-tusimple」 です。</block>
  <block id="b3b5448c329ac882bc890a1be1a1b369" category="paragraph"><block ref="b3b5448c329ac882bc890a1be1a1b369" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f8efb3d1b86c88cfab193291776b6ad" category="list-text">「 restore -snapshot-pvc.yaml 」を使用して新しい PVC を作成します。</block>
  <block id="34c7c2e95019754701182fe2ab194499" category="paragraph"><block ref="34c7c2e95019754701182fe2ab194499" category="inline-image-macro-rx" type="image"></block></block>
  <block id="070856555a817dbf9a4061542b2098ca" category="list-text">復元されたばかりのデータをトレーニングに使用する場合、ジョブ送信は以前と同じです。次のコマンドに示すように、トレーニングジョブの送信時に「 pvc_name 」を復元された「 pvc_name 」に置き換えるだけです。</block>
  <block id="e945ddc4d35a9c49a17bd00c53db05a6" category="section-title">パフォーマンス評価</block>
  <block id="3451b157ef07ae84bfaba5fb6639c1ba" category="paragraph">解決策のリニアな拡張性を示すために、 GPU × 1 と GPU × 3 という 2 つのシナリオでパフォーマンステストを実施しました。GPU 割り当て、 GPU とメモリの使用率、シングルノードと 3 ノードの異なるメトリックは、 TuSimple LANE 検出データセットのトレーニング中に取得されました。データは、トレーニングプロセス中のリソース使用率を分析するために 5 倍に増加します。</block>
  <block id="b8077d533d2f9918c47d330cbac4392d" category="inline-link-macro">Azure NetApp Files サービスレベル</block>
  <block id="da9b7dc2993c3c848d5d9a9a15806d8c" category="paragraph">解決策を使用すると、まず小規模なデータセットを配置し、一部の GPU で作業を開始できます。GPU の需要とデータ量が増加した場合、標準階層ではテラバイト規模まで動的にスケールアウトし、 Premium 階層にすばやくスケールアップして、データを移動することなく、テラバイトあたりのスループットを 4 倍にすることができます。このプロセスの詳細については、を参照してください。 <block ref="bdbab4daa7de478307acc7147c869853" category="inline-link-macro-rx"></block>。</block>
  <block id="090a231c840a0cb23aa29c8d1afc7832" category="paragraph">1 つの GPU での処理時間は 12 時間 45 分でした。3 つのノードにまたがる 3 つの GPU での処理時間は約 4 時間 30 分でした。</block>
  <block id="49eca64b9f03702167beb48ebd38587b" category="paragraph">本ドキュメントの以降の各セクションにある図は、個々のビジネスニーズに基づくパフォーマンスと拡張性の例を示しています。</block>
  <block id="abfc10c2bc00a990735e6d27797295a8" category="paragraph">次の図は、 1 つの GPU 割り当てとメモリ使用率を示しています。</block>
  <block id="8d7e3abab70510c3f4636ff7bf953250" category="paragraph"><block ref="8d7e3abab70510c3f4636ff7bf953250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31a3d2def4927574922946c38f043c0b" category="paragraph">次の図は、シングルノードの GPU 利用率を示しています。</block>
  <block id="58cf0f270760f08ac96254402d0696dc" category="paragraph"><block ref="58cf0f270760f08ac96254402d0696dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dcca9cfd87d9f2087d720ef187655cea" category="paragraph">次の図は、シングルノードのメモリサイズ（ 16GB ）を示しています。</block>
  <block id="e22d39f2830d0f3e3944644d0f605d41" category="paragraph"><block ref="e22d39f2830d0f3e3944644d0f605d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="576c0843e21d5ee884a067aa7b6a1a40" category="paragraph">次の図は、シングルノードの GPU 数（ 1 ）を示しています。</block>
  <block id="ef855771be83c072ebaafc60d2d1933f" category="paragraph"><block ref="ef855771be83c072ebaafc60d2d1933f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2c50f1b8fc86c36cc0df94dd14b46b9" category="paragraph">次の図は、シングルノードの GPU 割り当て（ % ）を示しています。</block>
  <block id="e295f84458327d01315b814d8deb2aea" category="paragraph"><block ref="e295f84458327d01315b814d8deb2aea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b2b7f256373eac14419bfec5b84b21" category="paragraph">次の図は、 GPU の割り当てとメモリという 3 つのノードにまたがる 3 つの GPU を示しています。</block>
  <block id="e763ef0e4b7cb9d022bf6db49319c570" category="paragraph"><block ref="e763ef0e4b7cb9d022bf6db49319c570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94ab4242b167972f7a9f0513ca772555" category="paragraph">次の図は、 3 つのノードの使用率（ % ）にまたがる 3 つの GPU を示しています。</block>
  <block id="d786146ae56597413fa5be548126cda9" category="paragraph"><block ref="d786146ae56597413fa5be548126cda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c31ecb239228cac5e96860d42f9a4d" category="paragraph">次の図は、 3 つのノードにまたがる 3 つの GPU のメモリ利用率（ % ）を示しています。</block>
  <block id="2224958fd5113068ac8a3b55a336661b" category="paragraph"><block ref="2224958fd5113068ac8a3b55a336661b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79f05e8f99917560625d1cf3f2d4fc5d" category="inline-link">サービスレベル</block>
  <block id="07c1fda2408980b5d53ea06ad3cc5ed1" category="paragraph">既存のボリュームのサービスレベルを変更するには、を使用する別の容量プールにボリュームを移動します<block ref="bc9fbd5fd43d884f02abe6a6f9b51339" category="inline-link-rx"></block> 必要なのはボリュームです。ボリュームの既存のサービスレベル変更では、データを移行する必要はありません。また、ボリュームへのアクセスにも影響しません。</block>
  <block id="5e2ff0b5dc3206032a81aa3aecb7c462" category="section-title">ボリュームのサービスレベルを動的に変更する</block>
  <block id="58e691ddc6184f73e5d6b513ca5a3c49" category="paragraph">ボリュームのサービスレベルを変更するには、次の手順を実行します。</block>
  <block id="3f19b438418ed162387a3050b304c89b" category="list-text">Volumes （ボリューム）ページで、サービスレベルを変更するボリュームを右クリックします。［ プールの変更 ］ を選択します</block>
  <block id="5acf521dbc5099b2ec33a64efac89595" category="paragraph"><block ref="5acf521dbc5099b2ec33a64efac89595" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6533c4186062235d8b7f47e232e92597" category="list-text">プールの変更ウィンドウで、ボリュームの移動先とする容量プールを選択します。[OK] をクリックします。</block>
  <block id="3f0874d07ce6ae728a6dcdda7903f9cd" category="paragraph"><block ref="3f0874d07ce6ae728a6dcdda7903f9cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb935c59f24539e0966b7ab5c761e862" category="section-title">サービスレベルの変更を自動化</block>
  <block id="1391028ed384c93fd59fd5a0097f9181" category="paragraph">動的サービスレベルの変更は現在、パブリックプレビューで有効になっていますが、デフォルトでは有効になっていません。Azure サブスクリプションでこの機能を有効にするには、次の手順を実行します<block ref="5c3671452d40598396b030d5c9c6dc27" category="inline-link-rx"></block>」</block>
  <block id="407443b5508c517acd825fbcddb7ab4c" category="inline-link">AZ netappfiles ボリューム： Azure NetApp Files （ ANF ）ボリュームリソースの管理</block>
  <block id="1d3afb31c5d2a81fca940ae760671a1c" category="list-text">Azure では、 CLI コマンドでも次のコマンドを使用できます。Azure NetApp Files のプール・サイズの変更の詳細については、を参照してください<block ref="8b45caafcc8d758d5c37edb19f8a2761" category="inline-link-rx"></block>。</block>
  <block id="ebd5b070cb8457b94f1916baa92c3c7d" category="inline-link">Azure NetApp Files ボリュームのプールを変更します</block>
  <block id="d5460fd5fbfbf643b9a4bc1d1de279d0" category="list-text">ここに示す 'set-aznetappfilesvolumepool' コマンドレットを使用すると、 Azure NetApp Files ボリュームのプールを変更できます。ボリュームプールのサイズ変更の詳細については、を参照してください<block ref="70c8d95cde8b63eae0d37a8b81a31482" category="inline-link-rx"></block>。</block>
  <block id="ca6d5ad374e3cf268dec341c0c398442" category="summary">このアーキテクチャでは、 AI や機械学習（ ML ）の分散型トレーニングプロセスであるレーン検出において、最も演算負荷の高い部分に焦点が当てられています。</block>
  <block id="8cb13336dc020a2fb7bca9d4e940cc64" category="paragraph">このアーキテクチャでは、 AI や機械学習（ ML ）の分散型トレーニングプロセスであるレーン検出において、最も演算負荷の高い部分に焦点が当てられています。車線検知は、自動運転で最も重要な作業の 1 つであり、車線区分線の位置を特定することで車両を誘導するのに役立ちます。車線標示などの静的コンポーネントは、車両を高速道路でインタラクティブかつ安全に走行させる。</block>
  <block id="0721542454dcaa77c97cd9c545d9063f" category="paragraph">畳み込みニューラルネットワーク（ CNN ）ベースのアプローチでは、シーンの理解とセグメント化が新たなレベルにまで押しつけられています。長い構造やリージョンが含まれているオブジェクト（ポール、車線の陰など）は適切に機能しませんが、空間的畳み込みニューラルネットワーク（ SCNN ）は、 CNN を豊かな空間レベルに一般化します。同一層のニューロン間で情報を伝播できるため、車線、ポール、トラックなどの構造化された物体（オ結論を含む）に最適です。この互換性は、空間情報を強化し、滑らかさと連続性を維持できるためです。</block>
  <block id="df38a65c87631c9530cc3a6832ea7a7d" category="paragraph">モデルがデータセット内のさまざまなコンポーネントを学習し、区別できるように、数千ものシーンイメージをシステムに挿入する必要があります。これらのイメージは天候、日中か夜、マルチレーンハイウェーの道および他の交通条件を含んでいる。</block>
  <block id="f7759f002b4a60b5c837abb7f8936037" category="paragraph">トレーニングには、質の高いデータと量のニーズがあります。1 つの GPU または複数の GPU でトレーニングを完了するには、数日から数週間かかることがあります。データ分散トレーニングは、マルチノードの GPU を複数使用することでプロセスを高速化できます。Horovod は、分散トレーニングを提供する一方で、 GPU のクラスタ間でデータを読み取ることは障害となる可能性があるフレームワークの 1 つです。Azure NetApp Files は、超高速、高スループット、一貫した低レイテンシを実現し、スケールアウト / スケールアップ機能を提供して、 GPU がコンピューティング容量の最適な値に活用されるようにします。当社の実験では、 SCNN を使用してレーン検出をトレーニングするために、クラスタ全体のすべての GPU が平均で 96% 以上使用されていることが確認されました。</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="section-title">対象読者</block>
  <block id="0ca450eccdc7141b5e85e9e691a7f16b" category="paragraph">データサイエンスには、 IT とビジネスに関する複数の分野が組み込まれているため、ターゲットを絞ったオーディエンスには複数のペルソナが含まれます。</block>
  <block id="8acb1f50d0ada4e1149c01a5aa15b9ce" category="list-text">データサイエンティストは、選択したツールとライブラリを柔軟に使用する必要があります。</block>
  <block id="d0ba3808090644db73caeb23fcc2b17c" category="list-text">データエンジニアは、データフローの仕組みと、データが格納されている場所を把握する必要があります。</block>
  <block id="22a8c99419dee54a28ed1e2355a6706b" category="list-text">自動運転のユースケースエキスパート。</block>
  <block id="18f66c4bad233033dabddf6ff1289eeb" category="list-text">クラウド（ Azure ）リソースのセットアップと管理を担当するクラウド管理者およびアーキテクト。</block>
  <block id="4c9b6067f04f945e9247ecd00c22e328" category="list-text">DevOps エンジニアは、新しい AI / ML アプリケーションを継続的統合 / 継続的導入（ CI / CD ）パイプラインに統合するためのツールを必要としています。</block>
  <block id="53720cf6403ac6b8a2402cce66c79d4f" category="list-text">ビジネスユーザは、 AI / ML アプリケーションにアクセスしたいと考えています。</block>
  <block id="68dcdc6243e54c14b4c41c129d574c43" category="paragraph">このドキュメントでは、 Azure NetApp Files 、 Run ： AI 、 Microsoft Azure の 3 つの役割がそれぞれビジネスにもたらす価値について説明します。</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="section-title">解決策テクノロジ</block>
  <block id="8017303b9b2c96742151083f089fc51f" category="paragraph">このセクションでは、 Azure クラウドで完全に稼働する規模の分散トレーニング解決策を実装することで、レーン検出のユースケースに必要なテクノロジについて説明します。次の図は、解決策アーキテクチャの概要を示しています。</block>
  <block id="f17291da16ed3dd7b705548f16706120" category="paragraph">この解決策で使用される要素は次のとおりです。</block>
  <block id="f28c5620810ae2a6961a1811277a7ff8" category="list-text">Azure Kubernetes Service （ AKS ）</block>
  <block id="03023f4a63d3d8f8ff86ff8246f75b9a" category="list-text">NVIDIA GPU を搭載した Azure コンピューティング SKU</block>
  <block id="ae5ba69294a1b9feb03e6dd75395092c" category="list-text">実行： AI</block>
  <block id="951370659c41a55ac9f80ff19c2f4b26" category="paragraph">ここに記載されているすべての要素へのリンクをに示します <block ref="c8b73068ae16e202922904f7ed452f8e" category="inline-link-macro-rx"></block> セクション。</block>
  <block id="00d9279819736707d2b224ec427a8aae" category="paragraph"><block ref="00d9279819736707d2b224ec427a8aae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6a2faff353ad4e74bf3ee92e5d8b9c6" category="section-title">クラウドリソースとサービスの要件</block>
  <block id="5b691a1a00c6c03be70e559f55ae4fef" category="paragraph">次の表に、解決策の実装に必要なハードウェアコンポーネントを示します。解決策の実装で使用されるクラウドコンポーネントは、お客様の要件に応じて異なる場合があります。</block>
  <block id="5f3bc5eb45e6b472bf3345d1036945e9" category="cell">AK</block>
  <block id="55b8660903ebaaed924e945432fe269e" category="cell">少なくとも 3 つのシステムノードと 3 つの GPU ワーカーノードが必要です</block>
  <block id="3580a6b3e7ba0d55af17daee07244cbd" category="cell">仮想マシン（ VM ） SKU システムノード</block>
  <block id="8f75b0af54b5e672a660f4f1f1557f18" category="cell">3 つの Standard_DS2_v2</block>
  <block id="a6066b29e1c4603af2c5c46cf549f764" category="cell">VM SKU GPU ワーカーノード</block>
  <block id="6aa4bab72f83c0b68587ee208f2c9ab0" category="cell">3 つの Standard_NC6s_v3</block>
  <block id="3468e131592d70a22139936f3fb21403" category="cell">4TB の標準ティア</block>
  <block id="cb251883efe045266871b7dd15229644" category="cell">バージョンまたはその他の情報</block>
  <block id="bb451ae1fa5a629a0307949d38a60e2d" category="cell">AK - Kubernetes バージョン</block>
  <block id="f2d1dd8f39098da402272f7606fd2638" category="cell">1.18.14</block>
  <block id="13c5eaa211a3778d391d5c8f65b80234" category="cell">AI CLI を実行</block>
  <block id="89633b9d6f401377b6ece0682b92530a" category="cell">v2.2.25</block>
  <block id="4b138e2d1492b1e550d42348c65cbf82" category="cell">実行： AI Orchestration Kubernetes Operator バージョン</block>
  <block id="6db851ff24c4b893a85242e63bbea119" category="cell">1.0.109</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">ホロボド</block>
  <block id="4a7724061c17f8cf5be61a8adf4c170f" category="cell">0.21.2</block>
  <block id="44adee2c140fc723412bae93732e5993" category="cell">20.01.1</block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">ONTAP VASA プロバイダでは、異なるストレージへのフェイルオーバーがサポートされます。たとえば、システムは、エッジの場所にある ONTAP Select からコアデータセンターの AFF システムにフェイルオーバーできます。ストレージの類似性に関係なく、レプリケーションが有効な VM ストレージポリシーのストレージポリシーマッピングとリバースマッピングを常に設定して、リカバリサイトで提供されるサービスが期待される要件を満たしていることを確認する必要があります。次のスクリーンショットは、ポリシーマッピングの例を示しています。</block>
  <block id="70be05b3500f28affc2d048f81c4f7ab" category="sidebar">Azure の分散トレーニング - レーン検出</block>
  <block id="7767872606b9c99eb656c9568c1fdd83" category="sidebar">レーン検出– AI を実行する分散トレーニング</block>
  <block id="b761cb4d962320708880627e8e2fe971" category="inline-link-macro">ONTAP を使用した VMware vSphere Virtual Volumes</block>
  <block id="5b90454e2bf0f381c8f7fc928ef6fb9e" category="list-text"><block ref="5b90454e2bf0f381c8f7fc928ef6fb9e" category="inline-link-macro-rx"></block></block>
  <block id="5ab6c918ee903c74a7d7c97b2432ebaf" category="section-title">最新の VMware ソリューションのビデオデモをご覧ください</block>
  <block id="207681662de4971035cc8d5c9347c986" category="list-text"><block ref="207681662de4971035cc8d5c9347c986" category="inline-link-macro-rx"></block></block>
  <block id="8ca7386c3cb63b01ffc6387ba41427ae" category="list-text"><block ref="8ca7386c3cb63b01ffc6387ba41427ae" category="inline-link-macro-rx"></block></block>
  <block id="9934e59457fa5f31d39a58f1d55ac5d5" category="list-text"><block ref="9934e59457fa5f31d39a58f1d55ac5d5" category="inline-link-macro-rx"></block></block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="section-title">ビデオ</block>
  <block id="8ff6498eeabd53b4271d75f543dc3bc4" category="list-text"><block ref="8ff6498eeabd53b4271d75f543dc3bc4" category="inline-link-macro-rx"></block></block>
  <block id="f1c2408ffc6e67ac6b34eb8da2b3039c" category="list-text"><block ref="f1c2408ffc6e67ac6b34eb8da2b3039c" category="inline-link-macro-rx"></block></block>
  <block id="7518aab5e189037f632ee46ea9e3cf07" category="video-title">『 Deploying Dynamic Persistent NetApp Storage for VMware Tanzu 』、パート 1</block>
  <block id="f86bf601d6e42c44cf076ea1772ae13c" category="video-title">『 Deploying Dynamic Persistent NetApp Storage for VMware Tanzu 』、パート 2</block>
  <block id="bf5c12d4eed319d2dc2b2b7279944f71" category="video-title">『 Deploying Dynamic Persistent NetApp Storage for VMware Tanzu 』、パート 3</block>
  <block id="a398d57165e21c951dd9c9def41598a9" category="inline-link-macro">VMware Cloud on AWS ：富士通が CVO を使用して何百万ドルものコストを削減する方法をご紹介</block>
  <block id="d750d47d5e87a6c526e7b40e12eab95b" category="list-text"><block ref="d750d47d5e87a6c526e7b40e12eab95b" category="inline-link-macro-rx"></block></block>
  <block id="334af7a3f788d83aa889d1ca7bd769f5" category="summary">このページでは、 ONTAP の Storage Efficiency について説明します。</block>
  <block id="c13f924c3ceac59a16a8a1ea96d43c91" category="doc">ONTAP の Storage Efficiency 機能</block>
  <block id="241a4f0482dfad2f5fc79419b18356c0" category="section-title">Storage Efficiency について</block>
  <block id="185081022bfbcfda8db4798eb4eed8c0" category="paragraph">ネットアップは、本番環境のワークロードで重複排除を初めて実現したのですが、この分野の最初または最後のイノベーションではありませんでした。まずは、パフォーマンスに影響を与えない、スペース効率に優れたデータ保護メカニズムである ONTAP Snapshot コピーと、本番環境やバックアップ用に VM の読み取り / 書き込みコピーを瞬時に作成する FlexClone テクノロジからスタートしました。ネットアップは、重複排除、圧縮、ゼロブロック重複排除などのインライン機能を提供し、高価な SSD のストレージを最後まで絞ります。ONTAP は最近、 Storage Efficiency を強化するためにコンパクション機能を追加しました。</block>
  <block id="d019495551b4899a9019567122f1e076" category="list-text">* インラインのゼロブロック重複排除。ゼロブロックのスペースを無駄に消費しません。</block>
  <block id="7634d08ecc5702f74271a3313502ec02" category="list-text">* インライン圧縮。 * データブロックを圧縮して、必要な物理ストレージ量を減らします。</block>
  <block id="8b7bb53489bfc2a6808c1d76314fa0d4" category="list-text">* インライン重複排除。 * ディスク上の既存のブロックが使用されていた受信ブロックを削除します。</block>
  <block id="b762ae2f528b0eca55e7be3f599e909d" category="list-text">* インラインデータコンパクション。 * より小さな I/O 処理とファイルを各物理ブロックにパックします。</block>
  <block id="fba6442665875d123719f22baafc619d" category="inline-image-macro">ストレージの効率化</block>
  <block id="f468c00b41afc3485647008dcf80cba1" category="paragraph"><block ref="f468c00b41afc3485647008dcf80cba1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8405ea940cfeab85adddf9d3ed915a97" category="paragraph">重複排除、データ圧縮、データコンパクションを一緒に、または個別に実行して、 FlexVol で最適なスペース削減効果を得ることができます。これらの機能を組み合わせることで、 VSI では最大 5 分の 1 、 VDI では最大 30 分の 1 のコストを削減できました。</block>
  <block id="b8c11cd315128247329c3d878c2143fe" category="inline-link">重複排除、データ圧縮、データコンパクションによるストレージ効率の向上</block>
  <block id="65bbb718266195d68e8d1accfc443e28" category="admonition">ONTAP の Storage Efficiency 機能の詳細については、を参照してください<block ref="f358a7faf94e9f579d11f8fc4efdbdec" category="inline-link-rx"></block> ONTAP 9 ドキュメントセンターを参照してください。</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">Virtual Volumes （ VVol ）と Storage Policy Based Management （ SPBM ）</block>
  <block id="25e09c324ad3c89ee3aa01454fce14cd" category="section-title">VVol と SPBM について</block>
  <block id="ab3304a5226d57b9bcaf0c7b3f819735" category="paragraph">ネットアップは、 vSphere Virtual Volumes （ VVol ）の開発において VMware と初期の設計パートナーとして、アーキテクチャに関する情報提供と、 VVol および VMware vSphere APIs for Storage Awareness （ VASA ）のサポートを提供していました。このアプローチにより、 VM のきめ細かなストレージ管理が VMFS にもたらされるだけでなく、 Storage Policy-Based Management （ SPBM ）を通じてストレージプロビジョニングの自動化もサポートされています。</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">SPBM は、仮想化環境で使用できるストレージサービスと、プロビジョニングされたストレージ要素の間の抽象化レイヤとして機能するフレームワークを、ポリシーを通じて提供します。このアプローチにより、ストレージアーキテクトは、 VM 管理者が簡単に利用できるさまざまな機能を備えたストレージプールを設計できます。仮想マシンのワークロード要件をプロビジョニングされたストレージプールと照合することで、仮想マシンごとまたは仮想ディスクレベルのさまざまな設定をきめ細かく制御できます。</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">ONTAP は VVol の規模においてストレージ業界をリードし、 1 つのクラスタで数十万もの VVol をサポートします。一方、エンタープライズアレイや小規模なフラッシュアレイベンダーは、アレイあたり数千の VVol をサポートします。また、 VVOL 3.0 をサポートする機能が追加され、 VM のきめ細かな管理が進化しています。</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">TR-4400 ：『 VMware vSphere Virtual Volumes with ONTAP 』</block>
  <block id="69173613658292fc2adeb513b12f29ca" category="admonition">VMware vSphere Virtual Volumes 、 SPBM 、および ONTAP の詳細については、を参照してください<block ref="354226c2546b1aed39f1c0c484e6a98a" category="inline-link-rx"></block>。</block>
  <block id="01a7d7174ccc6593753679eefec17d49" category="summary">このページでは、 VMware vSphere 環境で ONTAP の基本機能を自動化するメリットについて説明します。</block>
  <block id="1406aa071af210d31c6a2951fe66ddcc" category="doc">ONTAP と vSphere の自動化の概要</block>
  <block id="8e2b0503a0ad76f57c96738d7f0a3b0d" category="section-title">VMware の自動化</block>
  <block id="b5845209cb81dad561de4abe6e4481c4" category="paragraph">VMware ESX の最初の日から VMware 環境を管理するには、自動化が不可欠です。インフラをコードとして導入し、手法をプライベートクラウドの運用に拡張できるため、拡張性、柔軟性、自己プロビジョニング、効率性に関する懸念を軽減できます。</block>
  <block id="f7c9a2e2ec395a7e4b605bb3df40abf8" category="paragraph">自動化は、次のカテゴリに分類できます。</block>
  <block id="cba6f5a209d4f2ac1839f1c1e0a10051" category="list-text">* 仮想インフラストラクチャの導入 *</block>
  <block id="f41d0733c4edc0bf273a3d0587efb21e" category="list-text">* ゲストマシンの操作 *</block>
  <block id="7f2a4b0fa787b1f058accb56cc377af8" category="list-text">* クラウド運用 *</block>
  <block id="290a03d97ea4e48144d20f313e0a0826" category="paragraph">インフラの自動化に関して、管理者にはさまざまなオプションがあります。ホストプロファイルやカスタマイズ仕様などのネイティブ vSphere 機能を使用して、 VMware ソフトウェアコンポーネント、オペレーティングシステム、ネットアップストレージシステムで使用可能な API に仮想マシンを追加することで、重要なドキュメントやガイダンスを利用できます。</block>
  <block id="217dd73ccc3bd89b5d4e35d0bf50ea6c" category="paragraph">Data ONTAP 8.0.1 以降では、 ESX 4.1 以降を実行する ESX ホストで、 VMware vSphere APIs for Array Integration （ VAAI ）の特定の機能がサポートされます。VAAI は、 VMware vSphere ESXi ホストとストレージデバイス間の通信を可能にする一連の API です。これらの機能を使用すると、 ESX ホストからストレージシステムに処理の負荷をオフロードし、ネットワークスループットを向上させることができます。これらの機能は、正しい環境の ESX ホストで自動的に有効になります。VAAI 機能を使用している範囲は、 VAAI カウンタに含まれる統計情報で確認できます。</block>
  <block id="16123583d64fd438c5d7f5b61a1c1d2f" category="paragraph">VMware 環境の導入を自動化するための最も一般的な開始点は、ブロックベースまたはファイルベースのデータストアのプロビジョニングです。対応する自動化を開発する前に、実際のタスクの要件を確認することが重要です。</block>
  <block id="a78bd4dd1db96affe0c2889376cccf53" category="paragraph">VMware 環境の自動化の詳細については、次のリソースを参照してください。</block>
  <block id="ebd98e15bf07fe37dfdc879f9d0d1f48" category="inline-link">NetApp Pub</block>
  <block id="6123648b7dec055b609781b4d47c1b26" category="list-text"><block ref="6c65ff4f1dfb7aa26df896b1c9c849eb" category="inline-link-rx"></block>。ネットアップの構成管理と自動化：</block>
  <block id="7c4272bef0cc405b65fc74e3791664bc" category="inline-link">VMware 向けの Ansible Galaxy Community</block>
  <block id="59fb42204e71850f7fd7024e5e6a1058" category="list-text"><block ref="c471bcaf7efa6fb129f37edaa7c41a56" category="inline-link-rx"></block>。VMware 向けの Ansible リソースの集まり。</block>
  <block id="1ec695bd70399ce37180f1d84a33d151" category="inline-link">VMware ｛ code ｝ のリソース</block>
  <block id="489c5322cef99651507b070e2240b6a8" category="list-text"><block ref="77e0562f07512a7a248241b7170b6944" category="inline-link-rx"></block>。フォーラム、設計基準、サンプルコード、開発者ツールなど、ソフトウェア定義データセンターのソリューションを設計するために必要なリソース。</block>
  <block id="1e6584aafa5ae98aebb88d3ddecdaae5" category="doc">vSphere 管理者向けの ONTAP の概要</block>
  <block id="135b7f440129fbbacbc948adfb10ccec" category="paragraph">NetApp ONTAP は、オンプレミス環境とクラウド環境のどちらに導入しても、ストレージやデータの管理を簡易化し、 VMware 環境を明確に補完します。ネットアップの SAN ベースと NAS ベースのどちらの VMware アーキテクチャでも、業界最高レベルのデータ保護、 Storage Efficiency テクノロジ、卓越したパフォーマンスを実現できることは、何万ものお客様が vSphere 環境向けのストレージ解決策として ONTAP を選択している理由の 1 つです。</block>
  <block id="f93e431aaf745d4b5e4ecbd6c005b564" category="paragraph">ネットアップでは、仮想化環境の管理という課題に直面しているお客様をサポートするために、さまざまな VMware 製品の VMware プラグイン、検証、および認定資格を多数提供しています。ネットアップは、 VMware が仮想化に何をもたらすかをストレージとデータの管理に活用することで、お客様は物理ストレージの管理ではなく、中核となるコンピテンシーに注力できます。VMware とネットアップの 20 年近くにわたるこのパートナーシップは、 VMware Cloud Foundation や Tanzu などの新しいテクノロジが出現したときに、 vSphere の基盤を引き続きサポートしつつ、お客様に高い価値を提供し続けています。</block>
  <block id="b4e56252f38c98dde71bd489a93805fc" category="paragraph">お客様が重視する主な要因は次のとおりです。</block>
  <block id="d6f750861d7ae27706ca32ed1f4c1ac8" category="list-text">* ユニファイドストレージ *</block>
  <block id="04d737333774adefb9817d0115bab79b" category="list-text">* ストレージ効率 *</block>
  <block id="c44a0be5f0db0511994f2f8e76afeb25" category="list-text">* 仮想ボリュームとストレージ・ポリシー・ベースの管理 *</block>
  <block id="d78a5fe569360bb327d51dd5060d723c" category="list-text">* ハイブリッドクラウド *</block>
  <block id="45649dc755190fc40be0b7e38ec84851" category="paragraph">サポートされているネットアップと VMware のソリューションの詳細については、次のリソースを参照してください。</block>
  <block id="ec1bd76731eb238fa601fb03391f78d4" category="inline-link">NetApp Interoperability Matrix Tool を参照してください</block>
  <block id="d46e58d91be6ffba761ab9bd05a46fc5" category="list-text"><block ref="b47ad5992ee82e05d51ff22d87ae20c3" category="inline-link-rx"></block> IMTIMT では、 FC / FCoE 、 iSCSI 、 NFS 、 CIFS の各構成の構築に使用できる正規のコンポーネントとバージョンを定義しています。</block>
  <block id="8034c6a17370dafb5b3f6f5add755c62" category="inline-link">『 VMware Compatibility Guide 』を参照してください</block>
  <block id="f0c67c4d38f07e6eb4bead0202260ddb" category="list-text"><block ref="a9846c61dcf62d503a7738adf47f11be" category="inline-link-rx"></block>。『 VMware Compatibility Guide 』には、システム、 I/O 、ストレージ /SAN 、およびバックアップと VMware Infrastructure およびソフトウェア製品との互換性が記載されています</block>
  <block id="0f0b69f9725d17d0a8d3ceebcf33f72f" category="inline-link">VMware 向け NetApp ONTAP ツール</block>
  <block id="2be6bbf4ea543b07ab3b9a218eb509cc" category="list-text"><block ref="d1284fbca35bc1b47ead37f18b1c3ba2" category="inline-link-rx"></block>。VMware vSphere 用の ONTAP ツールは、 VSC 、 VASA Provider 、 Storage Replication Adapter （ SRA ）の拡張機能を含む vCenter Server プラグインです。</block>
  <block id="f2a03b032017931383878c3ef48cdb0a" category="list-text">ホスト、ターゲット、 SVM 、および LUN の情報の ONTAP WWPN</block>
  <block id="6c2e28f86b2049d110f0e73e9bb78709" category="list-text">接続された ONTAP FC データポートと vSphere ホスト</block>
  <block id="acd7065eaa19f6ad949216b6dcca52b6" category="list-text">VMware vSphere 向け ONTAP ツールの導入、設定、利用可能な状態</block>
  <block id="94dafc85e46c3bc0d374c052b1075890" category="list-text">との互換性を確認します<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="0b3f75b021ef6bdc0a532e2d9b2a9d74" category="inline-link-macro">FCP の ONTAP ライセンスがあることを確認します。</block>
  <block id="3c56f50608e95955ed2e1a3fb8b1dad1" category="list-text"><block ref="3c56f50608e95955ed2e1a3fb8b1dad1" category="inline-link-macro-rx"></block></block>
  <block id="f8aa00b1a94d3290ba6ac653b792dd8a" category="list-text">ライセンスを追加するには 'license add-license-code &lt;license code&gt; を使用します</block>
  <block id="25d85157bcfdbb601bbda056cd3a5bc6" category="list-text">HBA ドライバがインストールされていることを確認します。VMware がサポートする HBA には、すぐに使用できるドライバが導入されています に表示されます <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block>。</block>
  <block id="2093983846bbd6cd7e3d486531259f7d" category="summary">このページでは、 ONTAP と VMware vSphere で利用できるハイブリッドクラウド機能について説明します。</block>
  <block id="df94231e8c7a2b7372365ba3eb8ad621" category="doc">ONTAP と vSphere を使用したハイブリッドクラウド</block>
  <block id="c689fcb3c54ae34ac006a005e03aad07" category="section-title">ハイブリッドクラウドについて</block>
  <block id="cc81a55aaf5bd2bdf603a2aea92a875a" category="paragraph">ONTAP ソリューションは、オンプレミスのプライベートクラウド、パブリッククラウドインフラ、またはその両方のメリットを組み合わせたハイブリッドクラウドのいずれに使用しても、データ管理を合理化し、最適化するためのデータファブリックの構築を支援します。まずハイパフォーマンスのオールフラッシュシステムを導入し、データ保護とクラウドコンピューティングのためにディスクストレージシステムとクラウドストレージシステムのどちらかと組み合わせます。</block>
  <block id="9afb01441ce427bb3863eaccd46b9b5d" category="paragraph">Azure 、 AWS 、 IBM 、 Google のクラウドから選択して、コストを最適化し、ロックインを回避できます。必要に応じて、 OpenStack とコンテナテクノロジの高度なサポートを活用できます。</block>
  <block id="8a61dac106bf2a7f3b869c8ff58c4ce5" category="paragraph">多くの場合、お客様はクラウドへの移行を開始する際に最初に試すのがデータ保護です。保護は、キーデータの非同期レプリケーションと同様に簡単に行うことも、完全なホットバックアップサイトとして複雑にすることもできます。データ保護は、主に NetApp SnapMirror テクノロジに基づいています。</block>
  <block id="d059ff0a497ad1427248dbb8f770b1d5" category="paragraph">ワークロード全体をクラウドに移行することを選択しているお客様もいます。これは、単にクラウドをデータ保護に使用するだけではなく、クラウドベースのストレージを使用するようにアプリケーションを書き換える必要がないため、 ONTAP の移動が簡単になります。クラウドの ONTAP は、オンプレミスの ONTAP と同様に機能します。オンプレミスの ONTAP システムは、より少ない物理スペースに多くのデータを格納し、ほとんど使用されないデータを階層化して低コストのストレージに格納できるデータ効率化機能を備えています。ONTAP は、ハイブリッドクラウド構成を使用する場合でも、ワークロード全体をクラウドに移行する場合でも、ストレージのパフォーマンスと効率を最大限に高めます。</block>
  <block id="ad622d292f56f20b32a61fe1b8bd2f56" category="paragraph">ネットアップ ONTAP では、クラウドベースのバックアップ（ SnapMirror クラウド、 Cloud Backup Service 、 Cloud Sync ）やストレージ階層化 / アーカイブツール（ FabricPool ）も提供しており、運用コストの削減とクラウドの幅広いリーチの活用を支援します。</block>
  <block id="49c437176039e1c910728eac1f332689" category="paragraph">次の図は、ハイブリッドクラウドのユースケースの例を示しています。</block>
  <block id="e61ead4102c89a9758572df81301a1d2" category="inline-image-macro">ハイブリッドクラウド</block>
  <block id="9188eeccf6b5386d9573cea87cf05102" category="paragraph"><block ref="9188eeccf6b5386d9573cea87cf05102" category="inline-image-macro-rx" type="image"></block></block>
  <block id="293f510d2162f186910d817d97121159" category="inline-link">ONTAP とクラウド</block>
  <block id="3963100a9d31ca50911a23ac5c87aca1" category="admonition">ONTAP とハイブリッドクラウドの詳細については、を参照してください<block ref="92883b1d8840f28e1ad4810811bf56b5" category="inline-link-rx"></block> ONTAP 9 ドキュメントセンターを参照してください。</block>
  <block id="980e76f4fd03b06bfe740133284e92a9" category="list-text">ONTAP システムのネットワークデータポートと接続された vSphere ホストで使用</block>
  <block id="1bc0e04873be7c6291aef492ff2785cc" category="list-text"><block ref="d503e168b9096ac416caa1c8f13ab28a" category="inline-link-macro-rx"></block> default-data-blocks サービスポリシーを使用できます。</block>
  <block id="c436a9a899f5e1cfacf8828c90931ca9" category="list-text"><block ref="24788d985e181b3194881517c2ec7650" category="inline-link-macro-rx"></block> 確認には、「 network interface service-policy show 」を使用できます。</block>
  <block id="c49b54ab60508b16176724eeb8118049" category="list-text"><block ref="3a73ce9b9237c3e09863bf7b049ce423" category="inline-link-macro-rx"></block> VMware vSphere 用の ONTAP ツールを使用する場合は、この手順を省略してください。LUN ごとにこの手順を繰り返します。</block>
  <block id="536d7ac288972152b209e6f004917285" category="list-text"><block ref="95a6e2e5fae04247474cdc6a729342fc" category="inline-link-macro-rx"></block> 一般的なユースケースとしては、ソフトウェア iSCSI イニシエータがあります。</block>
  <block id="f5852a230bef6cf666f848c5a2137db2" category="doc">ONTAP ユニファイドストレージ</block>
  <block id="0dc14c0a294efec0c8cab98ebffa39f0" category="section-title">ユニファイドストレージについて</block>
  <block id="d00516b816f266ee64e7b1de5af59ff2" category="paragraph">ONTAP ソフトウェアを実行するシステムは、いくつかの重要な方法で統合されます。本来、このアプローチは、 1 つのストレージシステムで NAS プロトコルと SAN プロトコルの両方をサポートすることを指していました。 ONTAP は、 NAS における従来の強みと同様に、業界をリードする SAN 向けプラットフォームとして継続されています。Storage Virtual Machine （ SVM ）は、 ONTAP ソフトウェアを実行しているシステムにクライアントからアクセスできるようにする、論理的な構成要素です。SVM は、論理インターフェイス（ LIF ）を介して複数のデータアクセスプロトコルを使用して同時にデータをやり取りできます。SVM は、 CIFS や NFS などの NAS プロトコルでファイルレベルのデータアクセスを提供し、 iSCSI 、 FC / FCoE 、 NVMe などの SAN プロトコルでブロックレベルのデータアクセスを提供します。SVM は、 SAN クライアントと NAS クライアントそれぞれに同時にデータを提供できます。</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="inline-image-macro">ユニファイドストレージ</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d59082aeee25c59b01266eaef6cb14" category="paragraph">vSphere 環境では、このアプローチは仮想デスクトップインフラ（ VDI ）向けのユニファイドシステムと仮想サーバインフラ（ VSI ）の組み合わせを意味する場合もあります。ONTAP ソフトウェアを実行するシステムは一般に、従来のエンタープライズアレイに比べて VSI の方が安価ですが、同じシステムで VDI を処理するための高度な Storage Efficiency 機能も備えています。また、 ONTAP は、 SSD から SATA までさまざまなストレージメディアを統合し、クラウドへの拡張を容易にします。パフォーマンスのためにフラッシュアレイを 1 台、アーカイブ用の SATA アレイ、クラウド用のシステムを 1 台購入する必要はありません。ONTAP は、これらすべてを 1 つにまとめます。</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">ストレージ仮想化</block>
  <block id="54c9439ad8fb4842a5a86c34d2401e36" category="admonition">SVM 、ユニファイドストレージ、クライアントアクセスの詳細については、を参照してください<block ref="2843f934dec816d79f9c394ad0533c28" category="inline-link-rx"></block> ONTAP 9 ドキュメントセンターを参照してください。</block>
  <block id="fa7b524ea902bff51145e4279b653d84" category="summary">このページでは、ビデオとチュートリアルについて説明します。</block>
  <block id="4267881eb271396086a3cc1387da9a3a" category="section-title">VMware Tanzu ネットアップソリューション</block>
  <block id="2dd739333b022cfeccd93e19c8c39d83" category="paragraph">VMware Tanzu を使用すると、お客様は vSphere または VMware Cloud Foundation を通じて Kubernetes 環境を導入、管理、および管理できます。VMware のこの製品ポートフォリオでは、お客様のニーズに最適な VMware Tanzu エディションを選択することで、関連するすべての Kubernetes クラスタを単一のコントロールプレーンから管理できます。</block>
  <block id="f8d0723a562ed498a977795477b75cb0" category="inline-link">VMware Tanzu の概要</block>
  <block id="2d3e9ef8ae693e8ff80c4d6e70f0a876" category="paragraph">VMware Tanzu の詳細については、を参照してください<block ref="1951d4038519ab642a1c0f8898cecfe0" category="inline-link-rx"></block>。このレビューでは、 VMware Tanzu のユースケース、利用可能な追加機能などについて説明します。</block>
  <block id="31c49b154032d3d6039542b651e0f3d4" category="list-text"><block ref="31c49b154032d3d6039542b651e0f3d4" category="inline-link-rx"></block></block>
  <block id="fcf1189eaf4e4e32d27ee5174d63ae3c" category="list-text"><block ref="fcf1189eaf4e4e32d27ee5174d63ae3c" category="inline-link-rx"></block></block>
  <block id="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="list-text"><block ref="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="inline-link-rx"></block></block>
  <block id="20cf4402cce1622d010e58ef54b0c753" category="section-title">ネットアップは Red Hat OpenShift を採用しています</block>
  <block id="0454c59b86dfb678c92c2c7480958d1c" category="paragraph">エンタープライズ向け Kubernetes プラットフォームである Red Hat OpenShift を使用すると、オープンなハイブリッドクラウド戦略でコンテナベースのアプリケーションを実行できます。Red Hat OpenShift は、主要なパブリッククラウド上でクラウドサービスとして、または自己管理ソフトウェアとして利用でき、コンテナベースの解決策を設計する際に必要な柔軟性をお客様に提供します。</block>
  <block id="2426b725f5be26f50931584ae804c2eb" category="inline-link">Red Hat OpenShift の概要</block>
  <block id="ad973740d0b3378d367abba8a74a610e" category="paragraph">Red Hat OpenShift の詳細については、こちらを参照してください<block ref="dc6de73076240cafa99651f2d6acfef4" category="inline-link-rx"></block>。また、製品ドキュメントや導入オプションを確認して、 Red Hat OpenShift の詳細を確認することもできます。</block>
  <block id="ade88b04ec62ed28eb857e48bc32cef5" category="list-text"><block ref="ade88b04ec62ed28eb857e48bc32cef5" category="inline-link-rx"></block></block>
  <block id="a2f2cd3053597e34724347a57620122b" category="list-text"><block ref="a2f2cd3053597e34724347a57620122b" category="inline-link-rx"></block></block>
  <block id="46f04290f169589dff914e050d1a987b" category="list-text">GUI を使用して SVM を作成する場合、論理インターフェイスはそのプロセスの一部です。</block>
  <block id="6af0e7a38739ed6e2658342101a7b51e" category="list-text">vSphere 環境と ONTAP を管理するために必要な基本的なスキル</block>
  <block id="5422bc00db54a341b2c538f4cea614c0" category="list-text">｛ ONTAP_version ｝ を実行している ONTAP ストレージシステム（ FAS/AFF/CVO/ONTAP Select / ASA ）</block>
  <block id="2ec64af43682ffa45eeaf33a86950347" category="list-text">ホスト、ターゲット、および ONTAP と LUN の情報用の WWPN</block>
  <block id="60ce38e4967c52c316eff771b7a3c4ec" category="list-text">ONTAP の FC データポートと vSphere ホストを接続。</block>
  <block id="32086766e64ae646fcadddc3e16b203b" category="list-text">N_Port ID Virtualization （ NPIV ）機能が有効になっている場合</block>
  <block id="b6e0bd021536c90aa87cfea18d73d453" category="list-text">単一のイニシエータターゲットゾーンを作成します。</block>
  <block id="f386e9f209710f55d41a97e9502d1c7c" category="list-text">各ゾーンに、 SVM の ONTAP FC 論理インターフェイス（ WWPN ）であるターゲットを含めます。SVM ごとに、ノードごとに少なくとも 2 つの論理インターフェイスが必要です。物理ポートの WWPN は使用しないでください。</block>
  <block id="9d17f91ad987b7e7cf2fa7249cd97343" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block>「 system license show 」コマンドを使用して、 NVMe-oF が表示されているかどうかを確認します。ライセンスを追加するには 'license add-license-code &lt;license code&gt; を使用します</block>
  <block id="7193bed15c5b4f7c80f1f19630b57e1e" category="list-text">SVM で NVMe プロトコルが有効になっていることを確認します。</block>
  <block id="5eabd2d7390fc49cb61f882324bdcac0" category="inline-link-macro">NVMe 用の SVM を設定する</block>
  <block id="3838b8ad26ea53cc8ddea76f2a58b20a" category="list-text"><block ref="3838b8ad26ea53cc8ddea76f2a58b20a" category="inline-link-macro-rx"></block></block>
  <block id="f2fd2de931ce484e947c89ae8207346a" category="list-text">SVM で NVMe/FC 論理インターフェイスが使用可能になっていることを確認してください。</block>
  <block id="978583cfbb47e2700c599c43b7949a53" category="list-text">GUI を使用して SVM を作成する場合、論理インターフェイスはそのプロセスの一部です。</block>
  <block id="3866119a70b69102c1584c0baa386190" category="list-text">ネットワーク・インターフェイスの名前を変更するには ' Network Interface modify コマンドを使用します</block>
  <block id="c6613394adcc7526a48f6e92b61ee067" category="list-text">HBA ドライバがインストールされていることを確認しますVMware がサポートする HBA には、すぐに使用できるドライバが含まれており、に表示されます <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block></block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="sidebar">NetApp DataOps ツールキット</block>
  <block id="2a643eb4634917213492cef085506d45" category="sidebar">ネットアップと VMware のソリューションを今すぐご利用ください</block>
  <block id="cadc483b04d069f993431e3ac64341bf" category="sidebar">Virtual Volume and Storage Policy Based Management の略</block>
  <block id="c4f0254bef611d7217287539f6e00feb" category="sidebar">VMware vSphere の自動化</block>
  <block id="86fbb5b9292be9b680987addfa410586" category="sidebar">従来のブロックストレージプロビジョニング</block>
  <block id="805a0828a65bce146a58e3556113b017" category="sidebar">VMFS-Fibre Channel （ VMFS - ファイバチャネル）</block>
  <block id="26e113624e0cc32cbe2a26e1cde1da24" category="sidebar">VMFS- Fibre Channel over Ethernet （ Fibre Channel over Ethernet ）</block>
  <block id="8237af9088e8905784b1cb373e3a080d" category="sidebar">VMFS-5 - iSCSI</block>
  <block id="94cab344ef7124917167bd5415b137cf" category="sidebar">VMFS-5 - NVMe over Fabric</block>
  <block id="348ee034e8868e5211a6501c09d4b0f0" category="sidebar">従来のファイルストレージプロビジョニング</block>
  <block id="614b997c0fb5abcd68fda0ab9ca05d69" category="sidebar">NFS-v3</block>
  <block id="912655e9dd57ab01b86691021957e61e" category="sidebar">v4.1 に対応しています</block>
  <block id="ce006038ddc2a04747fe5a2c9c43b8f5" category="sidebar">デモとチュートリアル</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">さまざまな分析戦略に対応する各種ソリューション解決策 Brief</block>
  <block id="3c48757505a122bf371d1bf0105b6871" category="paragraph">doccomments@netapp.com に送信し、件名に TR-4597 を含めてください。</block>
  <block id="c1e392a90896851b3319d6075402fd4d" category="cell">* ハイブリッド / プライベートクラウド *</block>
  <block id="8ef4e9c7260e8d314760329e07c618ae" category="cell">* 仮想化 *</block>
  <block id="236122c6ab4c764632437a76fa95e5c0" category="cell">* デスクトップ仮想化 *</block>
  <block id="1ebfe0d8e53e3f7f2c37e8b3835c2adf" category="cell">* コンテナ *</block>
  <block id="bdca592f24222e5064192bb9e2f9af6e" category="sidebar">FlexPod - ネットアップの Cisco 解決策</block>
  <block id="0da8a1ebf94a3a1e650dbfbd01c69dd9" category="sidebar">FlexPod ソリューションのテクニカルコンテンツ</block>
  <block id="32591d046a055939af0d128133dc8606" category="sidebar">FlexPod のセールスページ</block>
  <block id="9e5a59ca9aef030e74a725dab3fb6dcf" category="paragraph">Astra Trident と Red Hat OpenShift を使用すると、ユーザは、プロビジョニングされたストレージクラス上の永続的ボリュームのスナップショットを作成できます。この機能を使用すると、ボリュームのポイントインタイムコピーを作成して、そのコピーを使用して新しいボリュームを作成したり、同じボリュームを以前の状態にリストアしたりできます。これにより、ロールバックからクローン、データリストアまで、さまざまなユースケースを実現またはサポートできます。</block>
  <block id="05cd0cf0962d29806df78d956f772deb" category="summary">Astra Trident は、コンテナや Kubernetes ディストリビューション向けの、 Red Hat OpenShift などのオープンソースで完全にサポートされているストレージオーケストレーションツールです。</block>
  <block id="0626021388a8dcc9b1e26b1209550b8d" category="paragraph">Astra Trident は、 Kubernetes と同様、迅速な開発サイクルを 1 年に 4 回リリースしています。</block>
  <block id="4281e618126caa3d322e78eafddba1b2" category="section-title">Astra Trident をダウンロード</block>
  <block id="f71051465199267cbb540658a51e2957" category="paragraph">Astra Trident Operator のインストールが完了したら、使用するネットアップストレージプラットフォームに合わせてバックエンドを設定する必要があります。Astra Trident のセットアップと設定を続行するには、次のリンクを参照してください。</block>
  <block id="7eba670f1ea5a6e2fba9cff6b6399064" category="summary">このページでは、 MetalLB ロードバランサのインストールおよび設定手順について説明します。</block>
  <block id="79a2d2fa50d2b47d02c0e9dbdfadc07f" category="doc">MetalLB ロードバランサのインストール：ネットアップでの Red Hat OpenShift</block>
  <block id="0b2da9b5fe81e13e88c9a05981a95a9e" category="paragraph">このページでは、 MetalLB ロードバランサのインストールおよび設定手順を示します。</block>
  <block id="28a4ce0a0514d0f6a6596fc7a9c5e725" category="section-title">MetalLB 設定オプション</block>
  <block id="04c22d763ca95631f9c8789eb2c6e68f" category="paragraph">MetalLB が OpenShift クラスタの外部でロードバランササービスに割り当てられた IP アドレスをどのようにアナウンスするかに基づいて、次の 2 つのモードで動作します。</block>
  <block id="92f98c10e5e0c86bcae2e9cb58b700e3" category="list-text">* レイヤ 2 モード。 * このモードでは、 OpenShift クラスタ内の 1 つのノードがサービスの所有権を取得し、その IP の ARP 要求に応答して、 OpenShift クラスタ外で到達可能にします。IP をアドバタイズするのはノードだけなので、帯域幅のボトルネックと低速フェールオーバーの制限があります。詳細については、のドキュメントを参照してください <block ref="4a1d14cac7ed68a2326a050e0f1fed80" category="inline-link-macro-rx"></block>。</block>
  <block id="32333b5f74abf17bffedb6e7abeb7b5f" category="section-title">MetalLB ロードバランサをインストールします</block>
  <block id="70bd399edc6825961c98dc29c2a49299" category="list-text">MetalLB リソースをダウンロードします。</block>
  <block id="d95ae9e4bae10f240e5577110ccbd7e6" category="list-text">ファイル「 metallb.yaml 」を編集し、「 pec.template.spec.securityContext` 」をコントローラ展開とスピーカー DemonSet から削除します。</block>
  <block id="39bb715a16a6f4c1ab16bc3ad3654f0b" category="paragraph">* 削除する行数： *</block>
  <block id="803519c541b237245faa09039c50dcaa" category="list-text">「 metallb-system' 」ネームスペースを作成します。</block>
  <block id="980aff973ca30f65ec180530f40def06" category="list-text">MetalLB CR を作成します。</block>
  <block id="f87be5542b64a7f94a807699fd549479" category="list-text">MetalLB スピーカを設定する前に、スピーカ DemonSet の昇格特権を与えて、ロードバランサを動作させるために必要なネットワーク設定を実行できるようにします。</block>
  <block id="53747915d8e79873876b08edb1ce3671" category="list-text">「 metalLB - システム」ネームスペースに「 ConfigMap 」を作成して、 MetalLB を設定します。</block>
  <block id="2b1e829362de1a86eeb131cdc4619908" category="list-text">これで、ロードバランササービスが作成されると、 MetalLB は外部 IP をサービスに割り当て、 ARP 要求に応答して IP アドレスをアドバタイズします。</block>
  <block id="234ce2b9b198f2acf2193cbd06120ff2" category="admonition">BGP モードで MetalLB を設定する場合は、上記の手順 6 を省略し、 MetalLB マニュアルの手順に従います <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>。</block>
  <block id="0f07e63979900ab2abf6d2d578850a47" category="inline-link-macro">次：解決策の検証 / ユースケース：ネットアップを使用した Red Hat OpenShift 。</block>
  <block id="3a29a96f08f4066b544db012326464ed" category="paragraph"><block ref="3a29a96f08f4066b544db012326464ed" category="inline-link-macro-rx"></block></block>
  <block id="dc7ec0964c3d39892e26bbe1593a79e2" category="list-text">OpenShift クラスタに Trident の Astra をインストール</block>
  <block id="e909486a42368b2659780687c3b4a31b" category="list-text">OpenShift クラスタ上でストレージクラスを構成し、 Astra Trident をプロビジョニングツールとして提供</block>
  <block id="a5369d9ec76321542413da21642ecc74" category="inline-link-macro">次のセクション：ネットアップストレージ統合の概要</block>
  <block id="1a9b0bf11ebe49684776b9ffad6b4022" category="paragraph"><block ref="1a9b0bf11ebe49684776b9ffad6b4022" category="inline-link-macro-rx"></block></block>
  <block id="7df52e0f8b2cb2af1e107fde51d06945" category="paragraph">ライブマイグレーションは、 OpenShift クラスタ内の 1 つのノードから別のノードに VM インスタンスをダウンタイムなしで移行するプロセスです。OpenShift クラスタでライブマイグレーションを実行するには、 VM を共有 ReadWriteAny アクセスモードの PVC にバインドする必要があります。NFS プロトコルが有効になっている NetApp ONTAP クラスタで SVM を使用して設定された Astra Trident バックエンドは、 PVC に対する共有 ReadWriteAny アクセスをサポートします。そのため、 NFS 対応の SVM から Trident によってプロビジョニングされた StorageClasses から要求された PVC を持つ VM をダウンタイムなしで移行できます。</block>
  <block id="a0c55f3c40b8bb2d3e26f8d11ca73cbc" category="summary">このリファレンスドキュメントでは、ネットアップによって検証済みの複数の異なるデータセンター環境に Installer Provisioned Infrastructure （ IPI ）を通じて導入された Red Hat OpenShift 解決策の導入を検証します。また、ネットアップストレージシステムとの統合についても、 Astra Trident ストレージオーケストレーションツールを使用して永続的ストレージを管理することで詳しく説明します。最後に、解決策検証と実際の使用事例をいくつか確認して文書化します。</block>
  <block id="a2ac5b8f3de7c17418af38c828121a15" category="list-text">ネットアップストレージと Kubernetes 向けオープンソースストレージオーケストレーションツールである Astra Trident とともに使用される Red Hat OpenShift の機能を紹介する実際の構成とユースケース。</block>
  <block id="d3d8eb53a347d6ffc9fb157d9ac8398b" category="paragraph">NetApp 解決策を使用した Red Hat OpenShift は、次の主要コンポーネントで構成されています。</block>
  <block id="2b8932b35916e8cecb6216546111322e" category="paragraph">Red Hat OpenShift Container Platform は、完全にサポートされているエンタープライズ向け Kubernetes プラットフォームです。Red Hat は、オープンソースの Kubernetes をいくつか強化して、コンテナ化されたアプリケーションの構築、導入、管理を完全に統合したすべてのコンポーネントを備えたアプリケーションプラットフォームを提供します。</block>
  <block id="9480fd8950471a46e6b29b165ba7ae41" category="paragraph">NetApp Astra Control Center は、 NetApp の信頼できるデータ保護テクノロジを基盤とするオンプレミス環境に導入された、ステートフル Kubernetes ワークロード向けの豊富なストレージおよびアプリケーション対応データ管理サービスを提供します。</block>
  <block id="12c17259bf3f3b36e970c9e3abbc6b43" category="cell">ネットアップアストラコントロールセンター</block>
  <block id="8d96276332b02a2ef892828c1d4fbab4" category="cell">アプリケーション対応データ管理</block>
  <block id="8de59ec369b10820d0dd336b9765c79b" category="cell">ネットアップアストラト Trident</block>
  <block id="824bd84e05db30b27e73f839dae3b8e5" category="list-text">Astra Trident のドキュメント</block>
  <block id="fe549ebd8a3f0fea1803cbaa947ef198" category="list-text">NetApp Astra Control Center のドキュメント</block>
  <block id="ad837604b59ea6a89754d8e75f595c7b" category="inline-link"><block ref="ad837604b59ea6a89754d8e75f595c7b" category="inline-link-rx"></block></block>
  <block id="4af69e66dd3d513168080d177919dd21" category="paragraph"><block ref="4af69e66dd3d513168080d177919dd21" category="inline-link-rx"></block></block>
  <block id="68dc46cb39cdfc93e4593bbdd5c218cf" category="paragraph">ほとんどの場合、 IPI インストール方法が推奨されます。これは、開発、テスト、および本番環境用の OCP クラスタを迅速に導入できるためです。</block>
  <block id="3dbb1adfd571e8b44af1259f287d723f" category="paragraph">ネットアップには、 Red Hat OpenShift に導入されたアプリケーション用のストレージをプロビジョニングするための、ネットアップの Astra Trident ストレージオーケストレーションツールで認定されているストレージプラットフォームが複数あります。</block>
  <block id="0d1d64b47559f0c28c883e7e790b8363" category="summary">このセクションは、実環境のユーザがこの解決策を本番環境に導入するときに実行する必要があるカスタマイズ（専用のイメージレジストリの作成やカスタムロードバランサインスタンスの導入など）に特化したものです。</block>
  <block id="2642cf401e87de575eae139953f87134" category="admonition">このセクションでは、サードパーティ製のロードバランサを使用するか、カスタマイズしたコンテナイメージをホストするプライベートレジストリを作成するなど、いくつかの高度な設定オプションについて説明しました。どちらも NetApp Astra Control Center をインストールするための前提条件です。</block>
  <block id="02b655f637212514780af2795fd74fc4" category="paragraph">以下のページでは、解決策追加情報を使用した Red Hat OpenShift で検証済みの高度な構成オプションについて説明します。</block>
  <block id="becc5334b7f3d2f4f57fc42cd287fd54" category="inline-link-macro">ロードバランサオプションの確認</block>
  <block id="22651dd64b4cd4c6d2742d1f8b126ae6" category="list-text"><block ref="22651dd64b4cd4c6d2742d1f8b126ae6" category="inline-link-macro-rx"></block></block>
  <block id="261bdcc1d2c24d15c43c5947e69ea9e6" category="inline-link-macro">プライベートイメージレジストリを設定しています</block>
  <block id="c8db11b008075455562a8b598b31753c" category="list-text"><block ref="c8db11b008075455562a8b598b31753c" category="inline-link-macro-rx"></block></block>
  <block id="c4a7756da710a87248298a14bd0c21e6" category="paragraph"><block ref="c4a7756da710a87248298a14bd0c21e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7a6c3c568d213db46836511343c4965" category="list-text">ONTAP 9.5 以降を実行している NetApp ONTAP ストレージシステムが 1 つ以上必要です。</block>
  <block id="c927c560df09d5ca001f99cd07b14700" category="list-text">Trident ストレージバックエンドは、 ONTAP クラスタがサポートする SVM を含む各 OpenShift クラスタで設定する必要があります。</block>
  <block id="67a56d728807272d2a01df50c6548f4f" category="list-text">ストレージプロビジョニングツールとして Astra Trident を使用し、各 OpenShift クラスタに設定されたデフォルトのストレージクラス。</block>
  <block id="dda5c1363ac68168c83f72fc2645f51f" category="list-text">ロードバランシングや OpenShift Services の公開のために、各 OpenShift クラスタにロードバランサをインストールして構成する必要があります。</block>
  <block id="7dbcc72cc3a693b8f89b064e38ed7a23" category="list-text">NetApp アストラ Control Center イメージをホストするには、プライベートイメージのレジストリを設定する必要があります。</block>
  <block id="537f97bbcef0e2e67d6840aa5845aa65" category="list-text">NetApp ONTAP クラスタへの管理者アクセスが必要です。</block>
  <block id="0507b40de1fbd59b7a77b9054689e92b" category="list-text">Docker または podman 、 tridentctl 、 OC または kubectl ツールがインストールされ、 $path に追加された管理ワークステーション。</block>
  <block id="8c7c70cb991e0295e289054b79308c5d" category="section-title">Astra Control Center をインストールします</block>
  <block id="ccab5cf8842d06d8d4e2f7f778657c4b" category="list-text">tar ボールを開梱し、作業ディレクトリを作成されたフォルダに変更します。</block>
  <block id="abe31bcfb59f2265c2fb97dde407366c" category="open-title">ポッドマン</block>
  <block id="e83d8437c3befea11906e730883605bf" category="list-text">レジストリ FQDN を、組織 / 名前空間 / プロジェクト名とともに環境変数「管理」としてエクスポートします。</block>
  <block id="9acf317cba8637e151b8daae04e3e998" category="list-text">レジストリにログインします。</block>
  <block id="326c4e96ff06709dede5c03038f00e78" category="list-text">ファイルを実行可能にします</block>
  <block id="ed85c18933b4b240788294af279f8624" category="list-text">シェルスクリプトを実行します。</block>
  <block id="05b6053c41a2130afd6fc3b158bda4e6" category="open-title">Docker です</block>
  <block id="a27cc132b2f3001f3e9df9c40dad4bfb" category="list-text">次のコマンドを実行して演算子を作成します。</block>
  <block id="685fe82295261a8902e709081b6c9599" category="list-text">すべての Astra Control Center リソースをインストールするための専用のネームスペースを作成します。</block>
  <block id="d689979a6af0f5660231db187d212950" category="list-text">Astra Control Center CRD を作成した名前空間に作成します。</block>
  <block id="9904a774f242f31a5ae37c8f75bda92b" category="list-text">「 acc-operator-controller-manager 」ログをチェックし、インストールが完了したことを確認します。</block>
  <block id="cc2ba6bb5620162b64bafdca9f089718" category="inline-image-macro">Astra Control Center ログイン</block>
  <block id="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="paragraph"><block ref="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90fbead2d113af1a2680805778908d98" category="inline-image-macro">Astra Control Center の必須パスワード変更</block>
  <block id="247e9fd0170ec4d9550de59ebd54787b" category="paragraph"><block ref="247e9fd0170ec4d9550de59ebd54787b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0dd5915bd7ca0f5d34df18bf7a183d50" category="inline-image-macro">Astra Control Center でユーザを作成</block>
  <block id="0ea309ed2f56bdc52dd6184b9043e683" category="paragraph"><block ref="0ea309ed2f56bdc52dd6184b9043e683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54936e9fda3da1e56a25c0056f054bce" category="inline-image-macro">Astra Control Center 追加ライセンス</block>
  <block id="02fd0244de299d20dfbaf9113b883030" category="paragraph"><block ref="02fd0244de299d20dfbaf9113b883030" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2044ecf5033cd4a7b9530b83075af99e" category="admonition">NetApp Astra Control Center のインストールまたは設定で問題が発生した場合は、既知の問題のナレッジベースを利用できます<block ref="d775d2705bd260971e4d33c3d1094402" category="inline-link-rx"></block>。</block>
  <block id="9204faa817ce36107d052d3cd7c886c7" category="inline-link-macro">次のページ： Red Hat OpenShift クラスタの登録：ネットアップでの Red Hat OpenShift 。</block>
  <block id="8d167505bef11e381036abf56e79f457" category="paragraph"><block ref="8d167505bef11e381036abf56e79f457" category="inline-link-macro-rx"></block></block>
  <block id="8b14fb34f5313442bf2fdc4d80edc389" category="summary">このセクションでは、ネットアップ環境で Red Hat OpenShift をカスタマイズするユーザ向けのロードバランサオプションについて説明します。</block>
  <block id="87beaa6eff6159cd7270b2a4e71c10a4" category="doc">ロードバランサのオプションの確認：ネットアップを使用した Red Hat OpenShift</block>
  <block id="0aa971b4d33bdc82c500a35166e588c8" category="paragraph">ただし、アプリケーションでは、適切なサービスを公開するために、カスタマイズしたロードバランサの導入と設定が必要になる場合があります。その一例が、ネットアップアストラコントロールセンターです。このニーズを満たすために、いくつかのカスタムロードバランサオプションを評価しました。このセクションでは、これらのインストールと設定について説明します。</block>
  <block id="6914d9014ff3e2cb99cabff26b55a0bc" category="paragraph">以下のページでは、解決策追加情報を搭載した Red Hat OpenShift で検証済みのロードバランサオプションについて説明します。</block>
  <block id="2b545f7c547a71eaeda9dcb451aea0c5" category="inline-link-macro">MetalLB</block>
  <block id="eaefba36e93c0d0177c3de1143bd08dd" category="list-text"><block ref="eaefba36e93c0d0177c3de1143bd08dd" category="inline-link-macro-rx"></block></block>
  <block id="16dcf1808fc3c9a6f8342f97305d2ad6" category="doc">アプリケーションを保護</block>
  <block id="58c0d00b6ee4c263f1fbe431b41eebf4" category="paragraph">アプリケーションワークロードを Astra Control Center で管理した後、それらのワークロードの保護設定を構成できます。</block>
  <block id="59af79c7ab060b4cca322301a4729f0c" category="section-title">アプリケーションスナップショットを作成しています</block>
  <block id="c0cf3c0162d106c6ee24b7afa9b79575" category="paragraph">アプリケーションの Snapshot コピーを作成すると、 ONTAP Snapshot コピーが作成されます。 Snapshot コピーに基づいて、アプリケーションを特定の時点にリストアまたはクローニングできます。</block>
  <block id="9101281f33d55e682b1a47a44251fa0e" category="list-text">アプリケーションのスナップショットを作成するには、 [ アプリ ] &gt; [ 管理 ] タブに移動し、 Snapshot コピーを作成するアプリケーションをクリックします。アプリケーション名の横にあるドロップダウンメニューをクリックし、 Snapshot をクリックします。</block>
  <block id="c01290a8a623e36f9bcae85b910a3410" category="inline-image-macro">Astra Control Center のスナップショットボタン</block>
  <block id="f40e241f10f15eb6887acbc81fec81b0" category="inline-image-macro">Astra Control Center でスナップショットを作成</block>
  <block id="1853746a915bea325b8b576237c24427" category="section-title">アプリケーションのバックアップを作成しています</block>
  <block id="91796648d42dbd448c6cbb2044cb92ba" category="paragraph">アプリケーションのバックアップは、アプリケーションのアクティブな状態とそのリソースの設定をキャプチャしてファイルに変換し、リモートのオブジェクトストレージバケットに格納します。</block>
  <block id="72e328bb06195897c7a644970c61d3a2" category="paragraph">Astra Control Center で管理対象アプリケーションのバックアップとリストアを行うには、バッキング ONTAP システムのスーパーユーザ設定を前提条件として設定する必要があります。そのためには、次のコマンドを入力します。</block>
  <block id="6db82a24b17137378420e9fc7961d961" category="list-text">Astra Control Center で管理対象アプリケーションのバックアップを作成するには、 [ アプリ ] &gt; [ 管理 ] タブに移動し、バックアップを作成するアプリケーションをクリックします。アプリケーション名の横にあるドロップダウンメニューをクリックし、 [ バックアップ ] をクリックします。</block>
  <block id="bc230776554b8a63af328cf9f01124e1" category="inline-image-macro">Astra Control Center のバックアップボタン</block>
  <block id="e10781941ccd98298d2856b437b3fb4b" category="inline-image-macro">Astra Control Center でバックアップを作成</block>
  <block id="92955527b375720b2a586155a776c0ac" category="inline-image-macro">Astra Control Center のクローンボタン</block>
  <block id="c4293ef1955d52694e7d2288b637df1a" category="inline-image-macro">Astra Control Center の復元</block>
  <block id="c501040965cb5ca97cc675347e9ebfdf" category="list-text">新しいアプリケーションは Discovering 状態になり、 Astra Control Center は選択したクラスタにアプリケーションを作成します。アプリケーションのすべてのリソースが Astra によってインストールおよび検出されると、アプリケーションは Available 状態になります。</block>
  <block id="9ff3c5458e4a8facc6e7c25656a3baf7" category="inline-image-macro">Astra Control Center の新しいアプリが検出されました</block>
  <block id="d19de154f02438c6d6918a4e016c7c62" category="doc">保護するアプリケーションを選択します</block>
  <block id="501195b19cb60bfec4c2e4899a2a460c" category="paragraph">Red Hat OpenShift クラスタを登録したら、 Astra Control Center を使用して導入および管理するアプリケーションを検出できます。</block>
  <block id="a022d74e2b8b62dd9f1caa37a51aa3f3" category="section-title">アプリケーションを管理します</block>
  <block id="d8c780951f3271e7d72b116e5f41d46b" category="list-text">OpenShift クラスタと ONTAP バックエンドが Astra Control Center に登録されると、コントロールセンターは、指定した ONTAP バックエンドで構成されたストレージクラスを使用するすべてのネームスペース内のアプリケーションを自動的に検出します。</block>
  <block id="3b5963749d054f288f27dfb2f20d0370" category="inline-image-macro">Astra Control Center アプリケーションが検出されました</block>
  <block id="a78e618a70881e5c5dda311aaa61c250" category="paragraph"><block ref="a78e618a70881e5c5dda311aaa61c250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c46442de8c982973aeee99a9441b746" category="list-text">[ アプリケーション ]&gt;[ 検出済み ] の順に移動し、 Astra を使用して管理するアプリケーションの横にあるドロップダウンメニューをクリックします。[ 管理 ] をクリックします。</block>
  <block id="22d84cdf10d4c1059d68b1ab7da5b375" category="inline-image-macro">Astra Control Center がアプリケーションを管理</block>
  <block id="4afca1ab36db499d54b08ff38dff8a5c" category="paragraph"><block ref="4afca1ab36db499d54b08ff38dff8a5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d694cfe5907a4790ea939388a8cfd25" category="list-text">アプリケーションが [ 使用可能（ Available ） ] 状態になり、 [ アプリケーション（ Apps ） ] セクションの [ 管理（ Managed ） ] タブで表示できます。</block>
  <block id="dc496d6799e0c6ab3bdfdbdc6a086b48" category="inline-image-macro">Astra Control Center アプリケーションを利用可能</block>
  <block id="872adedc4ac847cec0aa8fb9299d32e5" category="paragraph"><block ref="872adedc4ac847cec0aa8fb9299d32e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="472d13eb415cd6107aeef3a1ae6cd705" category="summary">ネットアップは、 Red Hat OpenShift などのコンテナベースの環境における永続的データのオーケストレーションや管理を支援する、さまざまな製品を提供しています。</block>
  <block id="ebfc0e639726a366f8eb5ac86bb7cc43" category="paragraph"><block ref="ebfc0e639726a366f8eb5ac86bb7cc43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd351007d4a671a321b6881f730d0dc3" category="paragraph">以下のページには、解決策追加情報に実装された Red Hat OpenShift でアプリケーションおよび永続的ストレージ管理のために検証されたネットアップ製品に関する があります。</block>
  <block id="afa49872fb8ae001174e4c8f2cc47208" category="inline-link-macro">次のセクションでは、ネットアップ Astra Control Center の概要について説明します</block>
  <block id="22fd530ae76b4bbe50669b9a4d5b72d7" category="paragraph"><block ref="22fd530ae76b4bbe50669b9a4d5b72d7" category="inline-link-macro-rx"></block></block>
  <block id="810a039d1a8524388b75a0fe8d837afc" category="summary">Astra Control Center でワークロードを管理できるようにするには、まず Red Hat OpenShift クラスタを登録する必要があります。</block>
  <block id="3557f7a93216446476c40d54e0426c40" category="doc">Red Hat OpenShift クラスタを Astra Control Center に登録します</block>
  <block id="349c99fe6f384da92e5b8289b828791c" category="section-title">Red Hat OpenShift クラスタを登録します</block>
  <block id="c179429ab818c9d0cca3d1db55f788bf" category="list-text">最初のステップでは、 OpenShift クラスタを Astra Control Center に追加して管理します。クラスタに移動してクラスタの追加をクリックし、 OpenShift クラスタの kubeconfig ファイルをアップロードして、ストレージの選択をクリックします。</block>
  <block id="8dfc7d6b819f8c17b51391e3b3159add" category="inline-image-macro">Astra Control Center でクラスタを作成</block>
  <block id="7470624615914e8e3d5fdf4ea1aa31de" category="paragraph"><block ref="7470624615914e8e3d5fdf4ea1aa31de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7d9a690231a2d896f69e9b45c9ff4a1" category="admonition">ユーザ名とパスワードまたはトークンを使用して認証するために kubeconfig ファイルを生成できます。トークンが期限切れになるまでの時間は制限されており、登録されたクラスタに到達できなくなる可能性があります。ネットアップでは、 OpenShift クラスタを Astra Control Center に登録するために、ユーザ名とパスワードを付けた kubeconfig ファイルを使用することを推奨します。</block>
  <block id="cab7d2cb072914c0a5a89baab41d38e8" category="inline-image-macro">Astra Control Center でクラスタ選択ストレージを作成</block>
  <block id="68ac91074dd3b4e5514e5f56a6c9c756" category="paragraph"><block ref="68ac91074dd3b4e5514e5f56a6c9c756" category="inline-image-macro-rx" type="image"></block></block>
  <block id="420b9c40f78cc4825914319af51801b9" category="inline-image-macro">Astra Control Center クラスタを使用可能</block>
  <block id="1b017a62213661e1ed3c5c581fcf74a2" category="paragraph"><block ref="1b017a62213661e1ed3c5c581fcf74a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d01de34ef9b9b934d18009a1e3273a9" category="list-text">ONTAP クラスタをストレージリソースとして Astra Control Center でバックエンドとして管理するようにインポートします。ストレージクラスが設定されている Astra に OpenShift クラスタが追加されると、ストレージクラスをサポートする ONTAP クラスタが自動的に検出されて検査されますが、 Astra コントロールセンターにインポートされて管理されません。</block>
  <block id="781ffd1df517a65b302412f53de974da" category="inline-image-macro">Astra Control Center バックエンド検出</block>
  <block id="1fcc7977dffdc8fd8fc53582c67da895" category="paragraph"><block ref="1fcc7977dffdc8fd8fc53582c67da895" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4da0c23c38cf0da34e1e6660ff74542b" category="inline-image-macro">Astra Control Center でバックエンドを作成</block>
  <block id="69dbaffc2661024ee0b5095bc3674f60" category="paragraph"><block ref="69dbaffc2661024ee0b5095bc3674f60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edb4425c04926a17b6ff9a4a2ecdc669" category="list-text">バックエンドを追加すると、ステータスが Available に変わります。このバックエンドには、 OpenShift クラスタ内の永続ボリュームと ONTAP システム上の対応するボリュームに関する情報が含まれます。</block>
  <block id="92c130f9be24925c7dee36f7580ea347" category="inline-image-macro">Astra Control Center バックエンドも利用可能</block>
  <block id="e9f487b0aad6779edbf50c6092477bd5" category="paragraph"><block ref="e9f487b0aad6779edbf50c6092477bd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2d10d92dc9d83e3cf3514e8e883e5cb" category="list-text">Astra Control Center を使用して OpenShift クラスタ間でバックアップとリストアを行うには、 S3 プロトコルをサポートするオブジェクトストレージバケットをプロビジョニングする必要があります。現在サポートされているオプションは、 ONTAP S3 、 StorageGRID 、および AWS S3 です。このインストールのために、 AWS S3 バケットを設定します。バケットに移動し、バケットの追加をクリックして、汎用 S3 を選択します。S3 バケットの詳細とアクセスするためのクレデンシャルを入力し、「 Make this bucket the default bucket for the cloud 」のチェックボックスをオンにして、 Add をクリックします。</block>
  <block id="6910cb9051734be0129cb1e7dd84ce5c" category="inline-image-macro">Astra Control Center バケットの作成</block>
  <block id="2786d0b632389f7cbd6c4e67fba0061f" category="paragraph"><block ref="2786d0b632389f7cbd6c4e67fba0061f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2ed5156911e542a4d3d64a6e160f6446" category="image-alt">ネットアップ ONTAP を基盤とする Astra Trident を使用した Red Hat OpenShift クラスタのマルチテナンシー</block>
  <block id="086e6c16e3fe8e13c336612ef636aa02" category="list-text">Astra Trident</block>
  <block id="bf4e72937ad57bd2f780561c81d25d53" category="paragraph">NetApp ONTAP をベースにした OpenShift Virtualization では、ライブ VM 移行、 VM ディスククローニング、 VM スナップショットなどの一部の機能がサポートされており、 Astra Trident の支援を受けています。それぞれのセクションで、このドキュメントの後半で各ワークフローの例について説明します。</block>
  <block id="d55adbfc40b7bcdb0606eb0bd4d88cae" category="summary">このセクションでは、 Astra Trident が提供する永続的ストレージを使用して、プライベートイメージレジストリを作成および設定します。</block>
  <block id="9c864113b9e4202e111b818a53d4f506" category="inline-link">キー・ IO</block>
  <block id="4b4141875f954447d204e6f73d93e2a0" category="inline-link">DockerHub</block>
  <block id="508888fd9f92f35e5edd97bd8083e289" category="paragraph">Red Hat OpenShift の導入では、のようなパブリックレジストリを使用します<block ref="b9eeebbe4a68a648d570ea2173e5ef99" category="inline-link-rx"></block> または<block ref="0252a6b70cc5017fa1445a78532155b6" category="inline-link-rx"></block> お客様のほとんどのニーズに対応ただし、お客様が独自のプライベートイメージまたはカスタマイズされたイメージをホストしたい場合があります。</block>
  <block id="00a3f196d7f27a1f41f5d6a7f48759d0" category="paragraph">この手順ドキュメントでは、 Astra Trident と NetApp ONTAP が提供する永続的ボリュームを使用して作成された、プライベートイメージレジストリを作成しています。</block>
  <block id="d9d5e29b1b83dd9c215f5ea158ca2475" category="admonition">Astra Control Center では、 Astra コンテナに必要なイメージをホストするためにレジストリが必要です。次のセクションでは、 Red Hat OpenShift クラスタにプライベートレジストリをセットアップし、 Astra Control Center のインストールをサポートするために必要なイメージをプッシュする手順について説明します。</block>
  <block id="86e93d266c168d718105c402f43fc91e" category="list-text">このプルシークレットは、サービスアカウントにパッチを適用するか、対応するポッド定義で参照できます。</block>
  <block id="18f8bf05a7a278e63d921de74d2a5966" category="list-text">TLS 証明書を Docker クライアントに追加します。</block>
  <block id="fe70522102670f75ed2fff361701d056" category="paragraph">このリファレンスドキュメントでは、ネットアップによって検証済みの複数の異なるデータセンター環境に Installer Provisioned Infrastructure （ IPI ）を通じて導入された Red Hat OpenShift 解決策の導入を検証します。また、ネットアップストレージシステムとのストレージ統合についても、永続的ストレージの管理には Astra Trident ストレージオーケストレーションツールを、ステートフルアプリケーションの管理と保護には NetApp Astra Control Center を活用して詳しく説明しています。最後に、解決策検証と実際の使用事例をいくつか確認して文書化します。</block>
  <block id="4a56de086437c8a56c22bccd4e7ed9ba" category="paragraph">OpenShift で既存の VM をクローニングするには、 Astra Trident の Volume CSI クローニング機能をサポートします。CSI ボリュームクローニングでは、 PV を複製することによって、既存の PVC をデータソースとして使用して新しい PVC を作成できます。新しい PVC が作成されると、その PVC は独立したエンティティとして機能し、送信元 PVC へのリンクや依存関係はありません。</block>
  <block id="9057e692817874e4c563dec1fa8c1700" category="paragraph">VM をシャットダウンして既存の VM をクローニングすることは、 Astra Trident のサポートとともに実装されるネイティブの OpenShift 機能です。VM をクローニングするには、次の手順を実行します。</block>
  <block id="306a916d056a0d0a4b898b9dca9692ee" category="inline-link-macro">Red Hat OpenShift を基盤とした NetApp Astra コントロールセンター</block>
  <block id="20c49a9a4d903fa259d4f8820b3755d2" category="cell"><block ref="20c49a9a4d903fa259d4f8820b3755d2" category="inline-link-macro-rx"></block></block>
  <block id="82ebdc178ed6bd9adb7b66c2edfb70d0" category="sidebar">ネットアップストレージシステムの概要</block>
  <block id="aef2d8db139dd41c9ae6c878ab92ae75" category="sidebar">ネットアップとストレージの統合の概要</block>
  <block id="5f6fc3deb668cb75e9e6c8932620df6a" category="sidebar">NetApp Astra Control Center の概要</block>
  <block id="846665f4ec19bffa9d9a8c3937c2f9fd" category="sidebar">Red Hat OpenShift クラスタを登録します</block>
  <block id="b1dbcb80c89b000949ef64c6d6d6c42b" category="sidebar">保護するアプリケーションを選択します</block>
  <block id="2913361a2ab3fddb4242f1761d4a6e38" category="sidebar">アプリケーションを保護</block>
  <block id="b066abadb76f5e6776aa1e7cfdf56b38" category="sidebar">NetApp Astra Trident の概要</block>
  <block id="938033783443233af5517c828deb6d1e" category="sidebar">OpenShift の高度な構成オプション</block>
  <block id="8252479af4b1df9b77ceaf67fa8cd07d" category="sidebar">プライベートイメージレジストリを作成しています</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="summary">著作権に関する声明、商標、特許などにアクセスできます。</block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">法的通知</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">著作権</block>
  <block id="09e95b77ffe81fe465a83ba99efad5c8" category="paragraph"><block ref="09e95b77ffe81fe465a83ba99efad5c8" category="inline-link-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">商標</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp 、 NetApp のロゴ、および NetApp の商標ページに記載されているマークは、 NetApp, Inc. の商標です。その他の会社名および製品名は、それぞれの所有者の商標である場合があります。</block>
  <block id="7aa531e9acfe2b98e34d2c92fe9846ff" category="paragraph"><block ref="7aa531e9acfe2b98e34d2c92fe9846ff" category="inline-link-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">特許</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">ネットアップが所有する特許の最新リストは、次のサイトで入手できます。</block>
  <block id="d7f1fbcf9ce4e42f705add574d262b2c" category="paragraph"><block ref="d7f1fbcf9ce4e42f705add574d262b2c" category="inline-link-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">プライバシーポリシー</block>
  <block id="fc248f74f5e36542f7f5627b8610e9a3" category="paragraph"><block ref="fc248f74f5e36542f7f5627b8610e9a3" category="inline-link-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">オープンソース</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">通知ファイルには、ネットアップソフトウェアで使用されるサードパーティの著作権およびライセンスに関する情報が記載されています。</block>
  <block id="d648f2a68a54fd1b3329efc3cf24d29c" category="sidebar">法的通知</block>
  <block id="5328ed3b5c6e4726166e04c16c2e5581" category="summary">このセクションでは、 Pandas で Crito Click Logs Day 15 をロードし、 scikit learn ランダムフォレストモデルをトレーニングする方法について説明します。この例では、 Dask cuDF を使用して DataFrame のロードを実行し、 Dask cuML でランダムなフォレストモデルのトレーニングを行いました。</block>
  <block id="a0432b74d7d4d2ad68e93e947654c865" category="doc">Dask の 15 日目をロードし、 Dask cuML ランダムフォレストモデルをトレーニングします</block>
  <block id="7c784438423fe1bee9ab4f91a8fd7559" category="inline-link-macro">前の手順： Pandas で Logs Day 15 をクリックし、 scikit に学習したランダムなフォレストモデルをトレーニングします。</block>
  <block id="5d5b75a952d74a7d4520c521956b9d7e" category="paragraph"><block ref="5d5b75a952d74a7d4520c521956b9d7e" category="inline-link-macro-rx"></block></block>
  <block id="78dc33cd9d496e2466a0c1e2ba09ab3f" category="inline-link-macro">「トレーニング時間の比較」</block>
  <block id="4a2764258721dd882c9ec28454963797" category="paragraph">前のセクションと同様に、 Pandas の Logs Day 15 をロードして、 scikit に学習したランダムフォレストモデルをトレーニングします。この例では、 Dask cuDF を使用して DataFrame のロードを実行し、 Dask cuML でランダムなフォレストモデルのトレーニングを行いました。セクションのトレーニング時間と規模の違いを比較しました <block ref="8d6c01ed5b9db5301efeb6183c858b76" category="inline-link-macro-rx"></block></block>
  <block id="356d8553da3749641cb731d318c85b0c" category="section-title">Crito_dASK_RF.ipynb</block>
  <block id="2f4f1a139be92d2b17647025ff8630ab" category="paragraph">このノートブックは、次の例に示すように、「 numpy`, cuml` 」、および必要な「 Ask 」ライブラリをインポートします。</block>
  <block id="7b871613dade772ae668d694698383bf" category="paragraph">Dask Client() を開始します。</block>
  <block id="3e9277d3d0f0519292426b933e52f232" category="paragraph">クラスタが正しく設定されていれば、ワーカーノードのステータスを確認できます。</block>
  <block id="d6b257c355ced1525e4967c96b62b83e" category="paragraph">AKS クラスタでは、次のステータスが表示されます。</block>
  <block id="d94a77691c281e8bf418635fea6ca580" category="paragraph"><block ref="d94a77691c281e8bf418635fea6ca580" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073b2194006d8da73b5f74f3d7224d76" category="paragraph">Dask は遅延実行パラダイムを採用しています。処理コードを瞬時に実行するのではなく、 Dask は Directed Acyclic Graph （ DAG ）を実行します。DAG には、各ワーカーが実行する必要のある一連のタスクとそのやり取りが含まれています。このレイアウトは、ユーザーが Dask に一方の方法または別の方法で実行するように指示するまで、タスクが実行されないことを意味します。Dask を使用すると、 3 つの主なオプションがあります。</block>
  <block id="a40049c3d7270ce955d2023f8e2015dc" category="list-text">* DataFrame 上のコールコンピュート () 。 * このコールはすべてのパーティションを処理し、結果をスケジューラに返して最終的な集約を行い、 cuDF DataFrame に変換します。このオプションは慎重に使用してください。スケジューラノードのメモリが不足しないかぎり、結果が大幅に低下する場合にのみ使用してください。</block>
  <block id="30e170dbe1dd223491e1a822605da52d" category="list-text">* DataFrame 上で Persist() を呼び出します。 * この呼び出しはグラフを実行しますが、スケジューラノードに結果を返すのではなく、クラスタ内で結果をメモリに保持するため、ユーザは同じ処理を再実行することなくパイプライン内で中間結果を再利用できます。</block>
  <block id="ca013764f3f6faeab137d2d529dba598" category="list-text">* DataFrame 上のコールヘッド () 。 * cuDF と同様に、この呼び出しは 10 件のレコードをスケジューラノードに返します。このオプションを使用すると、 DataFrame に目的の出力形式が含まれているかどうか、または処理と計算に応じてレコード自体が適切かどうかをすばやく確認できます。</block>
  <block id="7ac60f98a199ceae63010c7802a9aefa" category="paragraph">したがって、ユーザがこれらのアクションのいずれかをコールしない限り、スケジューラが処理を開始するのを待機するアイドル状態になります。この遅延実行パラダイムは、 Apache Spark などの最新の並列および分散コンピューティングフレームワークで一般的です。</block>
  <block id="d887d6a29f39f14cec0f83c5b02c42f8" category="paragraph">次の段落では、 Dask cuML を使用して、 GPU アクセラレーションによる分散コンピューティングを行い、モデル予測精度を計算することにより、ランダムなフォレストモデルのトレーニングを行います。</block>
  <block id="de76ff3258bd3001f89804efae30da38" category="inline-link-macro">次の手順：ネイティブタスクストリームダッシュボードを使用して Dask を監視します。</block>
  <block id="5db30f2a693de098d03dec622875beec" category="paragraph"><block ref="5db30f2a693de098d03dec622875beec" category="inline-link-macro-rx"></block></block>
  <block id="2e240897109c5037e05afe0bf035d177" category="inline-link-macro">前へ：終わりに。</block>
  <block id="d3202b7eec66185e032fcad76b4c2aa3" category="paragraph"><block ref="d3202b7eec66185e032fcad76b4c2aa3" category="inline-link-macro-rx"></block></block>
  <block id="27a5a0a02525fbb66788e119b829fe28" category="list-text">Azure NetApp Files の特長</block>
  <block id="45bd81d391ee3bd9831a237bff32b2c1" category="list-text">Azure NetApp Files のソリューションアーキテクチャのページです</block>
  <block id="57b815cb2da0c842a09d5ef586792c0a" category="inline-link"><block ref="57b815cb2da0c842a09d5ef586792c0a" category="inline-link-rx"></block></block>
  <block id="02508d077a7c6fbe1035568c37610d22" category="paragraph"><block ref="02508d077a7c6fbe1035568c37610d22" category="inline-link-rx"></block></block>
  <block id="f42fced7b7a9bfef49a209632add6f80" category="list-text">コンテナ向けの Trident 永続的ストレージ：</block>
  <block id="158e66cfa121c58b072656402170ca60" category="list-text">Azure NetApp Files と Trident</block>
  <block id="d9fe72ef646d82c8372b45ff009726a2" category="inline-link"><block ref="d9fe72ef646d82c8372b45ff009726a2" category="inline-link-rx"></block></block>
  <block id="e3c781df174a80c19c70a938b96db93a" category="paragraph"><block ref="e3c781df174a80c19c70a938b96db93a" category="inline-link-rx"></block></block>
  <block id="145f2a04d99fdbd7a450ef83e82d471b" category="list-text">Dask および Rapids ：</block>
  <block id="df5eb1591e808e358e02221e1e0111e6" category="list-text">Dask</block>
  <block id="7db6639777894f081a3d7c055b97900a" category="inline-link"><block ref="7db6639777894f081a3d7c055b97900a" category="inline-link-rx"></block></block>
  <block id="4846c68fb34aec3b1b7b7de96d27e71f" category="paragraph"><block ref="4846c68fb34aec3b1b7b7de96d27e71f" category="inline-link-rx"></block></block>
  <block id="41563f9620e92fbfd1e105e32ac297e4" category="list-text">Dask をインストールします</block>
  <block id="8659b02378fc9b47aac4428f69411abc" category="inline-link"><block ref="8659b02378fc9b47aac4428f69411abc" category="inline-link-rx"></block></block>
  <block id="972dffc891589785367dd3581a5abcef" category="paragraph"><block ref="972dffc891589785367dd3581a5abcef" category="inline-link-rx"></block></block>
  <block id="3ba7abeba4fd0f5d5ca9072155319afd" category="list-text">Dask API</block>
  <block id="f7673aa4f6b36ba9952cef7c98115776" category="inline-link"><block ref="f7673aa4f6b36ba9952cef7c98115776" category="inline-link-rx"></block></block>
  <block id="d43a23bd530cae7ba37a2e0ed6513bad" category="paragraph"><block ref="d43a23bd530cae7ba37a2e0ed6513bad" category="inline-link-rx"></block></block>
  <block id="1bfabf7fb7bf05567331dfc3d20c4921" category="list-text">Dask Machine Learning の略</block>
  <block id="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link"><block ref="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link-rx"></block></block>
  <block id="d05f63d77306100c615132f350f3fafe" category="paragraph"><block ref="d05f63d77306100c615132f350f3fafe" category="inline-link-rx"></block></block>
  <block id="90223e93e145939c9954970520e1767a" category="list-text">Dask Distributed Diagnostics の実行</block>
  <block id="e7252fe9d67234e05be7dc251c48cf74" category="inline-link"><block ref="e7252fe9d67234e05be7dc251c48cf74" category="inline-link-rx"></block></block>
  <block id="925c8b588cf5ae5fc486494a21fba8ac" category="paragraph"><block ref="925c8b588cf5ae5fc486494a21fba8ac" category="inline-link-rx"></block></block>
  <block id="d97adf46c9b097cad5eff54e3b65a21f" category="paragraph"><block ref="d97adf46c9b097cad5eff54e3b65a21f" category="inline-link-rx"></block></block>
  <block id="528d52adf23d34a248f0b9bf684c1832" category="paragraph"><block ref="528d52adf23d34a248f0b9bf684c1832" category="inline-link-rx"></block></block>
  <block id="a43c7ca8f7e6a4a034f6a940ec7566f5" category="inline-link-macro">次へ：バージョン履歴。</block>
  <block id="5f751f93279ebf35ea83b9aa80ef02df" category="paragraph"><block ref="5f751f93279ebf35ea83b9aa80ef02df" category="inline-link-macro-rx"></block></block>
  <block id="7580f940c2b73a449943bf14cfdb743e" category="summary">このページでは、 Azure NetApp Files のクラウドリソースの設定について説明します。</block>
  <block id="9ab9ef31301ca94d2090a6ac7e5141f0" category="doc">クラウドリソースの要件</block>
  <block id="1cee510209f529b7ddd8911bbc6e3ee2" category="inline-link-macro">Previous ：ソフトウェア要件。</block>
  <block id="abab2b04b3822b72d0eeb7b61dd84730" category="paragraph"><block ref="abab2b04b3822b72d0eeb7b61dd84730" category="inline-link-macro-rx"></block></block>
  <block id="00130c4c20e30be7264c0ff0d085261b" category="section-title">Azure NetApp Files を設定します</block>
  <block id="d696f60435e09b1c41d1db77b458999b" category="inline-link">クイックスタート： Azure NetApp Files をセットアップし、 NFS ボリュームを作成します</block>
  <block id="b955f251da04c8c868b22cbe7663a4f5" category="paragraph">の説明に従って、 Azure NetApp Files を設定します<block ref="f8525997ced72f3cfd70e1aecf287af9" category="inline-link-rx"></block>。</block>
  <block id="4ee734214d7dd4e522f2aab3d8e3d349" category="paragraph">「 Azure NetApp Files 用 NFS ボリュームの作成」のセクションを過ぎても、 Trident を使用してボリュームを作成できます。続行する前に、次の手順を実行します。</block>
  <block id="2a304a1348456ccd2234cd71a81bd338" category="inline-link">リンク</block>
  <block id="b1d13ce152415787185b9f596f9635e1" category="list-text">Azure NetApp Files とネットアップのリソースプロバイダに（ Azure Shell を使用）登録します<block ref="7a85c4f09a460b2978e2b516b5474576" category="inline-link-rx"></block>）。</block>
  <block id="4c21364a09ae3c9dab758e383fcae62d" category="list-text">Azure NetApp Files でアカウントを作成します（<block ref="27e1abf4e17aeb1c0d418f5fee2f2b5f" category="inline-link-rx"></block>）。</block>
  <block id="97f203356061531d1acaf022df0d4c3c" category="list-text">容量プール（必要に応じて、 4TB 以上の Standard または Premium ）をセットアップします（<block ref="16f1daa909eef5f1fe1f552d6b28d086" category="inline-link-rx"></block>）。次の表に、クラウドでのセットアップに必要なネットワーク構成を示します。Dask クラスタと Azure NetApp Files は同じ Azure Virtual Network （ VNet ）またはピア関係にある VNet に配置されている必要があります。</block>
  <block id="ddcf50c29294d4414f3f7c1bbc892cb5" category="cell">リソース</block>
  <block id="3e19b1ddc4033d0c6c439dad720f730d" category="cell">「 /version 」と入力します</block>
  <block id="21b6b0c072968b7235d21d8ec72be5dc" category="cell">エージェントノード</block>
  <block id="e5262abb96ddec17ecbca3557e70ea26" category="cell">3x Standard_DS2_v2</block>
  <block id="c64f4eaffc33134095fd3105b3d63832" category="cell">GPU ノード</block>
  <block id="11fed615c3da90add7abe544e965fa14" category="cell">3x Standard_NC6s_v3</block>
  <block id="238f4027146f2469c7d1209e594471e4" category="cell">標準的な容量のプールがある</block>
  <block id="9163995275052e5abd777ae389b15dfd" category="cell">容量（ TB ）</block>
  <block id="a6a0cae93cb8ecdef629c6de5f05989c" category="inline-link-macro">次の例：クリックスルー率予測ユースケースの概要</block>
  <block id="a5efee0d52d97830d344cded6ac0bf5c" category="paragraph"><block ref="a5efee0d52d97830d344cded6ac0bf5c" category="inline-link-macro-rx"></block></block>
  <block id="53ffd6a9e0049c8cbf7f940c2b8bc793" category="inline-link-macro">前： NetApp DataOps ツールキットを使用したデータセットとモデルのバージョニング。</block>
  <block id="01643859d7e5dff013d2acd6a02af35e" category="paragraph"><block ref="01643859d7e5dff013d2acd6a02af35e" category="inline-link-macro-rx"></block></block>
  <block id="eee817389517c17ec810d52f22a8222d" category="paragraph"><block ref="eee817389517c17ec810d52f22a8222d" category="inline-link-macro-rx"></block></block>
  <block id="4b022a47bb6a38cb1b05a5cbec618ccd" category="inline-link-macro">前の例：ピア AKS の VNet と Azure NetApp Files VNet</block>
  <block id="fec5fee1adce318e5e2f9ce6a66ccc02" category="paragraph"><block ref="fec5fee1adce318e5e2f9ce6a66ccc02" category="inline-link-macro-rx"></block></block>
  <block id="999aa3cd55c654beafcfa7653b65d339" category="paragraph">Helm を使用して Trident をインストールするには、次の手順を実行します。</block>
  <block id="36cd38f49b9afa08222c0dc9ebfe35eb" category="inline-link">ソース</block>
  <block id="9c5f8711af47a869d4ef82db9e55eda5" category="list-text">Install Helm （インストール手順については、を参照してください）<block ref="adf15389dc6d5fe4bd9024075437080f" category="inline-link-rx"></block>）。</block>
  <block id="f7c078ec85c617d77dfa95c309e4df1b" category="list-text">Trident 20.01.1 インストーラをダウンロードして展開します。</block>
  <block id="5729bb69ffc852a2e2757d743b7cb833" category="list-text">tridentctl' をシステム「 $PATH 」のディレクトリにコピーします。</block>
  <block id="d7fc4d1537e4623fdcebe9b8ba333cbb" category="list-text">Kubernetes （ Kubernetes ）クラスタに Trident をインストールし、 Helm （を参照<block ref="cbc920955683fc4acb62f9ea7099333f" category="inline-link-rx"></block>）：</block>
  <block id="f515d7de4d597c284ba8042f699a0eab" category="list-text">ディレクトリを 'helm' ディレクトリに変更します</block>
  <block id="6ee4094e2c3617e3e298ec79f9dc2898" category="list-text">Trident ポッドのステータスを確認</block>
  <block id="30f93734da9765d3bc7d49ca89932736" category="paragraph">すべてのポッドが稼働中の場合は、 Trident がインストールされてから次のポッドに移動できます。</block>
  <block id="cde865911fa15995bc83db30d852300b" category="list-text">AKS の Azure NetApp Files バックエンドとストレージクラスをセットアップします。</block>
  <block id="476fdb61358f28988640245a33bd9199" category="list-text">Azure サービスプリンシパルを作成します。</block>
  <block id="5cdfb88cd634d9d0eb47237e3251d4bd" category="paragraph">サービスプリンシパルは、 Trident が Azure と通信して Azure NetApp Files リソースを操作する方法を示します。</block>
  <block id="253a9ccb0f0696ed79c174b388867829" category="list-text">Trident バックエンド JSON ファイルを作成します。例：「 anf-backend.json 」</block>
  <block id="c17b83e07524acc467ac01e42fa0ebdb" category="list-text">任意のテキストエディタを使用して 'anf-backend.json ファイル内の次のフィールドに値を入力します</block>
  <block id="1197f8dc56b70115d87008dd2ecd3fca" category="list-text">次のフィールドを置き換えます。</block>
  <block id="b0b2134849d44712e969d6872e7245e5" category="list-text">' スクリプト ID' 。お客様の Azure サブスクリプション ID</block>
  <block id="7b42dbe86adeab0d66f36221b33bb0f4" category="list-text">「 tenantID 」。前の手順で「 AZ AD SP 」の出力から取得した Azure テナント ID 。</block>
  <block id="5a8bb8e509b4a424a1df50ef0bb41d89" category="list-text">「 clientID 」。前のステップで 'AZ ad sp' の出力からのあなたの appID 。</block>
  <block id="6334b606a5807346a083767eaab3934f" category="list-text">「 clientSecret 」を入力します。前の手順で「 AZ ad sp 」の出力から得たパスワード。</block>
  <block id="12104fe8975b3ce95324ec3cab160ffc" category="list-text">構成ファイルとして 'anf-backend.json を使用して 'trident'namespace に Azure NetApp Files バックエンドを作成するように Trident に指示します</block>
  <block id="d6d34c355bcd6b2efe2795a2aeedd247" category="paragraph"><block ref="d6d34c355bcd6b2efe2795a2aeedd247" category="inline-image-macro-rx" type="image"></block></block>
  <block id="004530c3d3b3f442f56243625372db1d" category="list-text">ストレージクラスを作成する。Kubernetes ユーザは、名前でストレージクラスを指定する PVC を使用してボリュームをプロビジョニングします。前の手順で作成した Trident バックエンドを参照するストレージクラス「 azurenetappfiles 」を作成するよう、 Kubernetes に指示します。</block>
  <block id="e777b114d6f12bc1190a60eaf8498e37" category="list-text">ストレージクラスおよびコピー用の YAML （ 'anf-storage-class.yaml ）ファイルを作成します。</block>
  <block id="01d45e8c6af153b1a477537e02466b5c" category="list-text">ストレージクラスが作成されたことを確認します。</block>
  <block id="445895be8456b7de5e864fc09994551a" category="paragraph"><block ref="445895be8456b7de5e864fc09994551a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d3fec4cfe088bc80c2c2930f051b60b" category="inline-link-macro">次の手順： Helm を使用して AKS に Rapids を導入して Dask をセットアップします。</block>
  <block id="f2d1f2f412dd744c26a147e39bfa708f" category="paragraph"><block ref="f2d1f2f412dd744c26a147e39bfa708f" category="inline-link-macro-rx"></block></block>
  <block id="4b737f96f31f513a87adcf43b83ec3a1" category="summary">このページでは、 AKS クラスタをセットアップするために必要な手順について説明します。</block>
  <block id="a81532d943508d42466c22d8d87bb4b8" category="doc">AKS クラスタをインストールしてセットアップします</block>
  <block id="ce3e1770b7ff86cfbc3a30a3e3ea87da" category="inline-link-macro">前：クリックスルー率予測ユースケースの概要。</block>
  <block id="80bf56f9bff31f7459309b983fbf8116" category="paragraph"><block ref="80bf56f9bff31f7459309b983fbf8116" category="inline-link-macro-rx"></block></block>
  <block id="40e1cc9f8d9321cbe9c1ef090f926a2b" category="paragraph">AKS クラスタをインストールしてセットアップする方法については、 Web ページを参照してください<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block> 次に、次の手順を実行します。</block>
  <block id="ad4af0825dd4979b7f48ae5ba031b23a" category="list-text">ノードのタイプ（ system [CPU] ノードまたは worker[GPU] ノード）を選択するときは、次のいずれかを選択します。</block>
  <block id="5a244a81080ee9fc08696fcbd45284e5" category="list-text">プライマリ・システム・ノードは ' 標準 DS2v2 （デフォルトでは 3 ノード）である必要があります</block>
  <block id="f3449ebebbf547282aa0562015bd360d" category="list-text">次に 'gpupool' という名前のユーザ・グループ（ GPU ノードの場合）のワーカー・ノード Standard_NC6s_v3 プール（最小 3 ノード）を追加します</block>
  <block id="d3d648c68589ef99efb6ad3ec15d1beb" category="paragraph"><block ref="d3d648c68589ef99efb6ad3ec15d1beb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2efc2b95642d4bcc76c710a3826225c" category="list-text">導入には 5 ～ 10 分かかります。完了したら、 Connect to Cluster （クラスタへの接続）をクリックします。</block>
  <block id="31797d7013400422e5d589ae3d91c79a" category="list-text">新しく作成した AKS クラスタに接続するには、ローカル環境（ラップトップ / PC ）から次のものをインストールします。</block>
  <block id="87e009e80a344ecb598be4c4bbe01c79" category="inline-link">使用している OS に応じた手順が表示されます</block>
  <block id="13a6d4f4230d0a1569b719c15884d447" category="list-text">を使用した Kubernetes コマンドラインツール<block ref="ad2337a31b7d16867fc954b03de661bd" category="inline-link-rx"></block></block>
  <block id="24a109d7bba4f8808eeb0bcf64d4357b" category="inline-link">Azure CLI をインストールします</block>
  <block id="7feed8a8a6c680e7beeca052b9fc9ed0" category="list-text">本ドキュメントに記載されている Azure CLI を使用して、<block ref="8e2043d81b680dba324c5a2abbee7b3f" category="inline-link-rx"></block></block>
  <block id="d33a4b8acf4001a4b35a2186fd020432" category="list-text">端末から AKS クラスタにアクセスするには、「 AZ login 」と入力し、クレデンシャルを入力します。</block>
  <block id="402ff6cff3671c1f49dc4af765835c14" category="list-text">「 Azure CLI ： kubectl get nodes 」と入力します。</block>
  <block id="4e5d89028ffbf65df6693ef1affd6573" category="list-text">次の例に示すように、 6 つのノードがすべて稼働していれば、 AKS クラスタをローカル環境に接続することができます</block>
  <block id="6b935f22371497abfe5378d4446df0da" category="paragraph"><block ref="6b935f22371497abfe5378d4446df0da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e57b7e32f49f0297d6c7524d1da1b3c0" category="inline-link-macro">次の例： Azure NetApp Files の委任されたサブネットを作成します。</block>
  <block id="46b5942a33ef6a130ca5fee3f6017bec" category="paragraph"><block ref="46b5942a33ef6a130ca5fee3f6017bec" category="inline-link-macro-rx"></block></block>
  <block id="e1490a61359279998443f8eab1c0483e" category="summary">このページでは、分散型または大規模なトレーニングにおける Azure NetApp Files の利点をまとめています。</block>
  <block id="b0de8e85db65da6381bb71646929daa6" category="doc">クリックスルー率予測ユースケースの概要</block>
  <block id="d7550d336c660c27c3f1aa9ffdbc1e08" category="inline-link-macro">Previous ：クラウドリソースの要件</block>
  <block id="6a4fb77bb2a725598588e7db128b749b" category="paragraph"><block ref="6a4fb77bb2a725598588e7db128b749b" category="inline-link-macro-rx"></block></block>
  <block id="3f504d5ee520c44b83e5875afd3f2831" category="inline-link">[ ログ ] をクリックします</block>
  <block id="ce2803fd5e9b90b62d0792d13e715d11" category="inline-link">Crito AI Lab の略</block>
  <block id="67ccf3c7c1e67c90000dfee83bab38ec" category="list-text">分散型または大規模なトレーニングにおける Azure NetApp Files の利点</block>
  <block id="e15bc9f9b7a013d672cb689660ab9f9f" category="list-text">CUDA 対応のデータ処理（ cDF 、 cuPy など）と ML アルゴリズム（ cuML ）をラピッズで表示</block>
  <block id="3876b7e4b6a608a0b9001ae2e65c91b1" category="inline-link-macro">次の手順： AK クラスタをインストールしてセットアップします。</block>
  <block id="2f0a1a89887d5c4f057724084bfdb718" category="paragraph"><block ref="2f0a1a89887d5c4f057724084bfdb718" category="inline-link-macro-rx"></block></block>
  <block id="17a9b27c376a8a5f5e184b2ebce41164" category="summary">すべてのデータを導入したら、新しいデータに対して推論を実行します。このモデルは、ユーザーが閲覧アクティビティに基づいて広告をクリックするかどうかを予測します。予測の結果は Dask cuDF に格納されます。Prometheus で結果を監視し、 Grafana ダッシュボードで視覚化できます。</block>
  <block id="af4d0cbb3c6dcf4f3a5e831b08e40ace" category="doc">Prometheus と Grafana で Dask と Rapids を監視します</block>
  <block id="a5d741c60ca9280a87382bcc2667207c" category="inline-link-macro">前：トレーニング時間の比較。</block>
  <block id="8162cd02e2793715a1b14265f2bfb54b" category="paragraph"><block ref="8162cd02e2793715a1b14265f2bfb54b" category="inline-link-macro-rx"></block></block>
  <block id="23c1612202d19b502b3701f893fb2557" category="inline-link">Rapids AI 培地ポスト</block>
  <block id="9fed5c9f0dab5b88ba96d45cf450079f" category="paragraph">詳細については、を参照してください<block ref="47200b727ab2088d205d11a973529202" category="inline-link-rx"></block>。</block>
  <block id="a5705f3e27851573a7eafd2a00a523b5" category="inline-link-macro">次のセクション： NetApp DataOps ツールキットを使用したデータセットとモデルのバージョニング</block>
  <block id="db75fb5c1fef47405a8df61e726e3c66" category="paragraph"><block ref="db75fb5c1fef47405a8df61e726e3c66" category="inline-link-macro-rx"></block></block>
  <block id="adb2100439d02c2978c4a5670cda87b8" category="summary">このページには、このタスクの構築に使用されたライブラリとフレームワークが一覧表示されます。これらのコンポーネントはすべて、 Azure の役割ベースのアクセスおよびセキュリティ制御と完全に統合されています。</block>
  <block id="235ff38f40d20846e27b4c64e964ce28" category="doc">データ処理およびモデルトレーニング用のライブラリ</block>
  <block id="542e61809d35e9c83a99b29c87aa40fb" category="inline-link-macro">前のバージョン： Azure NetApp Files のパフォーマンス階層</block>
  <block id="b7fe935ab4f924b870ae1983e3f3a271" category="paragraph"><block ref="b7fe935ab4f924b870ae1983e3f3a271" category="inline-link-macro-rx"></block></block>
  <block id="c4e831049faaa8b89e89eebd0a105dab" category="paragraph">次の表に、このタスクの構築に使用されたライブラリとフレームワークを示します。これらのコンポーネントはすべて、 Azure の役割ベースのアクセスおよびセキュリティ制御と完全に統合されています。</block>
  <block id="faeae27c134f5193efb923d2492daa47" category="cell">ライブラリ / フレームワーク</block>
  <block id="b540cdb28de9a6c72ef1a92504e69423" category="cell">Dask cuML</block>
  <block id="1fc1b4b6567949aab2cb7e6fecb1e68f" category="inline-link">cuML ライブラリ</block>
  <block id="efe85bbaa5690074ea98a2bfef62d930" category="cell">ML を GPU で動作させるには、を使用します<block ref="514c908f6fc3f426a00e1dabdf37831f" category="inline-link-rx"></block> Dask を使用して Rapids cuML パッケージにアクセスできます。Rapids cuML は、クラスタリング、寸法縮小、回帰アプローチなどの一般的な ML アルゴリズムを高性能 GPU ベースの実装で実装し、 CPU ベースのアプローチで最大 100 倍のスピードアップを実現します。</block>
  <block id="ede0db3d6c9043439d0762ee99543654" category="cell">Dask cuDF</block>
  <block id="a9c380d6e09cc11f858b53d56cf69da4" category="inline-link">dask -cudf ライブラリ</block>
  <block id="13a7d0199f9797a3533ff335da46b446" category="cell">cuDF には、データのサブ設定、変換、ワンホットエンコーディングなど、 GPU アクセラレーションによる抽出、変換、読み込み（ ETL ）をサポートするその他のさまざまな機能があります。Rapids チームはを維持する<block ref="836818db4e43067816d31d2b73198787" category="inline-link-rx"></block> これには、 Dask および cuDF を使用するためのヘルパーメソッドが含まれています。</block>
  <block id="0c9c2e873df681f1ab5b13053be78af7" category="cell">Scikit learn</block>
  <block id="cd1235fc9b090edba051d73dbc6f66bf" category="inline-link">エスティメータ</block>
  <block id="1977c9daa1d67de51a4651abdb160c09" category="inline-link">フィット</block>
  <block id="4f54da5a2c4a796e8215f20eb95fddcc" category="cell">Scikit-Learn には、数十の機械学習アルゴリズムとモデルが組み込まれています。これらは、試算ツールと呼ばれます。各<block ref="855747fa3f470c1754852d09071dd101" category="inline-link-rx"></block> は、を使用して一部のデータに装着できます<block ref="e52e604a9dbe357e0fb9bc58f4b62add" category="inline-link-rx"></block> メソッド</block>
  <block id="0dd4d530afb3c99ab869350770d7bebd" category="paragraph">2 つのノートブックを使用して、比較のための ML パイプラインを構築しました。 1 つは従来の Pandas の坐骨坐骨学習アプローチで、もう 1 つは Rapids および Dask との分散トレーニングです。各ノートブックを個別にテストして、パフォーマンスを時間と規模の観点から確認できます。各ノートブックについて個別に説明し、 Rapids および Dask を使用した分散型トレーニングの利点を示します。</block>
  <block id="7dd297826f91c438fab12307224d2c40" category="inline-link-macro">次に、 Pandas で Logs Day 15 をクリックし、 scikit に学習したランダムな森林モデルをトレーニングします。</block>
  <block id="ade9906123700a8bf734457510b6b3c8" category="paragraph"><block ref="ade9906123700a8bf734457510b6b3c8" category="inline-link-macro-rx"></block></block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="doc">バージョン履歴</block>
  <block id="3993b517d983222c5b766976180367f0" category="inline-link-macro">前へ（ Previous ）：追加情報を検索する場所。</block>
  <block id="7d5fc90090e6ef28f1b090f458e3bb91" category="paragraph"><block ref="7d5fc90090e6ef28f1b090f458e3bb91" category="inline-link-macro-rx"></block></block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">日付</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">ドキュメントのバージョン履歴</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">バージョン 1.0 以降</block>
  <block id="248f830b158797f9c038ea35ea266b89" category="cell">2021年8月</block>
  <block id="ea9349a37bfee247df0f87cbcacca796" category="cell">初版リリース</block>
  <block id="dfcb1d1644aa3be367d0ca7761be62ad" category="summary">このページでは、 Azure NetApp Files の委任サブネットを作成するために必要な手順について説明します。</block>
  <block id="d991c79e9311d59d4e38f3115d9c5b24" category="inline-link-macro">前へ： AKS クラスタをインストールしてセットアップします。</block>
  <block id="5dd65debe44935eb5866a15b9a62237e" category="paragraph"><block ref="5dd65debe44935eb5866a15b9a62237e" category="inline-link-macro-rx"></block></block>
  <block id="8bffe528b31ee595be868b5a4af3d25a" category="paragraph">Azure NetApp Files の委任されたサブネットを作成するには、次の手順を実行します。</block>
  <block id="1aa0034de6393efa24703b8a479a5aa6" category="list-text">Azure ポータル内の仮想ネットワークに移動します。新しく作成した仮想ネットワークを検索します。「 AKs-vnet 」などのプレフィックスが必要です。</block>
  <block id="f1621549bc319674bb9e859babb2a671" category="list-text">VNet の名前をクリックします。</block>
  <block id="c536871a8fac3a4390226f6e485cf662" category="paragraph"><block ref="c536871a8fac3a4390226f6e485cf662" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5025fbb3995af8640cab85f4f91126b" category="list-text">[ サブネット ] をクリックし、上部のツールバーの [ サブネット ] をクリックします。</block>
  <block id="22307856839205c5209cc8ce1f4ed0df" category="paragraph"><block ref="22307856839205c5209cc8ce1f4ed0df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e45b350630c9a3b31bf0c1a1f03dffb0" category="list-text">サブネットに「 ANF 」などの名前を付け、「サブネットの委任」見出しの下にある「 M icrosoft.Netapp/volumes` 」を選択します。他のものは変更しないでください。[OK] をクリックします。</block>
  <block id="3621b1bf0075cb659f152966504dfc0d" category="paragraph"><block ref="3621b1bf0075cb659f152966504dfc0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8034fc216ae23edc69bb75430f3de2f" category="paragraph">Azure NetApp Files ボリュームはアプリケーションクラスタに割り当てられ、 Kubernetes で永続ボリューム要求（ PVC ）として使用されます。その結果、 Jupyter ノートブック、サーバーレス関数などのさまざまなサービスに柔軟にマップできます。</block>
  <block id="ac3654eb11c3b0cfc94c6c1abdc6767a" category="paragraph">サービスのユーザは、プラットフォームのストレージをさまざまな方法で消費できます。このテクニカルレポートでは NFS について説明しているため、 Azure NetApp Files の主なメリットは次のとおりです。</block>
  <block id="42ba8b77b788a422a7e4ba2d8bb2d45e" category="list-text">ユーザに Snapshot コピーを使用できるようにする。</block>
  <block id="a51448debe1bbe5bb229b849d4057e09" category="list-text">ユーザが Azure NetApp Files ボリュームに大量のデータを格納できるようにする。</block>
  <block id="b7c10d399d058ef3538882e444459ba5" category="list-text">大容量のファイルセットでモデルを実行する場合、 Azure NetApp Files のパフォーマンスが向上します。</block>
  <block id="4b15c9979e20dd7eb0c0263e9d5ab1db" category="inline-link-macro">次の例：ピア AKS の VNet と Azure NetApp Files VNet</block>
  <block id="a9f725be439e4752193d45f7e7f41851" category="paragraph"><block ref="a9f725be439e4752193d45f7e7f41851" category="inline-link-macro-rx"></block></block>
  <block id="74b3e84bf9817092a6f26ddf10a2f3f8" category="summary">このページでは、この解決策で使用されているテクノロジの概要を説明します。</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">テクノロジの概要</block>
  <block id="5231f9fa4d08024f4620b759f83d0e97" category="inline-link-macro">前へ：はじめに。</block>
  <block id="dd5a70c15c985f455edb59eebf8d3eaa" category="paragraph"><block ref="dd5a70c15c985f455edb59eebf8d3eaa" category="inline-link-macro-rx"></block></block>
  <block id="4b2eedb67d8fb9da01af759e6e722a13" category="section-title">Microsoft とネットアップ</block>
  <block id="09e4ef7b38fea4a7bdf4341b588176d6" category="paragraph">2019 年 5 月より、 Microsoft は Azure ネイティブのファーストパーティポータルサービスを提供し、 NetApp ONTAP テクノロジをベースとしたエンタープライズ NFS および SMB ファイルサービスを提供しています。この開発は、 Microsoft とネットアップの戦略的パートナーシップによって推進されており、ワールドクラスの ONTAP データサービスの Azure への対応範囲がさらに拡大しています。</block>
  <block id="851e5baafa3bd23201e65e29f2fdf06a" category="paragraph">Azure NetApp Files サービスは、エンタープライズクラスの高パフォーマンスな従量課金制のファイルストレージサービスです。Azure NetApp Files は、あらゆる種類のワークロードに対応し、デフォルトで高可用性を実現します。サービスレベルとパフォーマンスレベルを選択し、サービスを使用して Snapshot コピーをセットアップできます。Azure NetApp Files は Azure ファーストパーティサービスで、コードを変更することなく、データベース、 SAP 、ハイパフォーマンスコンピューティングアプリケーションなど、クラウドで最も要件の厳しいエンタープライズファイルワークロードを移行して実行します。</block>
  <block id="f014a6e06480ef33e3f1ab027f7065ca" category="paragraph">このリファレンスアーキテクチャには、 IT 組織に次のようなメリットがあります。</block>
  <block id="5e6e9a1ee378cf26b50e61d8bd46d54d" category="list-text">さまざまなパフォーマンスとコストを考慮して、幅広いストレージ階層を提供します</block>
  <block id="295f4f6daaf50c87d2639d407c47f357" category="section-title">Dask と NVIDIA Rapids の概要</block>
  <block id="a9dcf931a9aad845de3c5b908d562955" category="paragraph">Dask は、 Python ライブラリを複数のマシン上で拡張し、大量のデータを高速処理する、オープンソースの並列コンピューティングツールです。これは、 Pandas 、 numpy 、 scikit learn などのシングルスレッド従来の Python ライブラリに類似した API を提供します。その結果、ネイティブの Python ユーザは、クラスタ全体でリソースを使用するために既存のコードを大幅に変更する必要がなくなります。</block>
  <block id="955647f3573b932f8596ba04ed80b7b6" category="paragraph">NVIDIA Rapids はオープンソースライブラリのスイートで、 GPU 上でエンドツーエンドの ML ワークフローとデータ分析ワークフローを完全に実行できます。Dask と組み合わせることで、 GPU ワークステーション（スケールアップ）からマルチノードのマルチ GPU クラスタ（スケールアウト）へ簡単に拡張できます。</block>
  <block id="7a9ece70a2d60d73203e927718fd8454" category="paragraph">クラスタに Dask を導入するには、 Kubernetes を使用してリソースのオーケストレーションを行います。次の図に示すように、ワーカーノードをプロセス要件に従ってスケールアップまたはスケールダウンすることもできます。これは、クラスタのリソース消費を最適化するのに役立ちます。</block>
  <block id="b3951b803e4010ed575c9238d2803949" category="paragraph"><block ref="b3951b803e4010ed575c9238d2803949" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2e194dd3ce5b4d001a02991ef567211" category="inline-link-macro">次の手順：ソフトウェア要件</block>
  <block id="23704e1baeed350311b18c3583ad89e9" category="paragraph"><block ref="23704e1baeed350311b18c3583ad89e9" category="inline-link-macro-rx"></block></block>
  <block id="0dff6955889d5634f0212efb574ef815" category="doc">クリックスルー率予測データの処理とモデルトレーニング</block>
  <block id="19075a93ccd90f3ea7019f0572778b2a" category="summary">このページには、この解決策に必要なソフトウェア要件が一覧表示されます。</block>
  <block id="b0167c15bc26c48af07aea36aba706fa" category="inline-link-macro">前のページ：テクノロジの概要</block>
  <block id="440b940924209e1d417ef7c4ef9bce34" category="paragraph"><block ref="440b940924209e1d417ef7c4ef9bce34" category="inline-link-macro-rx"></block></block>
  <block id="793d18702a236e0e3b768917638f0ba2" category="paragraph">次の表に、この解決策に必要なソフトウェア要件を示します。</block>
  <block id="8ab697a4168b5fb33603a98d6bc9a436" category="cell">Rapids および Dask の容器のイメージ</block>
  <block id="9ab6289633c326d69a377cbb29bd81a3" category="cell">リポジトリ : "rapidsai/rapidsai" タグ :0.17-cudda11.1-runtime-ubuntu18.04</block>
  <block id="6e1b77cc3b83d87aaee751e2eaed5044" category="inline-link-macro">次：クラウドリソースの要件</block>
  <block id="58bc7690a5a3a5a1aa5dc70739fd0b53" category="paragraph"><block ref="58bc7690a5a3a5a1aa5dc70739fd0b53" category="inline-link-macro-rx"></block></block>
  <block id="9e59f01034d2c132fac901b9c14a5d88" category="summary">NetApp DataOps Toolkit for Kubernetes は、ストレージリソースと Kubernetes ワークロードをデータサイエンスのワークスペースレベルまで抽象化します。これらの機能は、データサイエンティストとデータエンジニア向けに設計された、使いやすいシンプルなインターフェイスにパッケージ化されています。</block>
  <block id="7aee811c7e891ab94bb5be40b333faaf" category="doc">NetApp DataOps ツールキットを使用したデータセットとモデルのバージョン管理</block>
  <block id="f7136197d3b16131979b9319c4acce63" category="inline-link-macro">以前： Prometheus と Grafana を使用して Dask と Rapids を監視していました。</block>
  <block id="402dae1972461d7e7ba986ab6728df6c" category="paragraph"><block ref="402dae1972461d7e7ba986ab6728df6c" category="inline-link-macro-rx"></block></block>
  <block id="fd2d048a9ec0f96d89493b98f72cbe34" category="paragraph">NetApp DataOps Toolkit for Kubernetes は、ストレージリソースと Kubernetes ワークロードをデータサイエンスのワークスペースレベルまで抽象化します。これらの機能は、データサイエンティストとデータエンジニア向けに設計された、使いやすいシンプルなインターフェイスにパッケージ化されています。使い慣れた Python プログラムを使用しており、データサイエンティストやエンジニアは JupyterLab ワークスペースをわずか数秒でプロビジョニングおよび削除できます。これらのワークスペースには、テラバイト、あるいはペタバイト規模のストレージ容量が含まれることがあり、データサイエンティストは、すべてのトレーニングデータセットをプロジェクトのワークスペースに直接格納できます。ワークスペースとデータボリュームを個別に管理する時代は終わりました。</block>
  <block id="4a6c7893abd7ef92fb09d3359e17324d" category="inline-link">GitHub リポジトリ</block>
  <block id="eb0d40310a9cc0432fac66dc97652c39" category="paragraph">詳細については、ツールキットを参照してください<block ref="64134ca6239d4056f34489b42f2baeed" category="inline-link-rx"></block>。</block>
  <block id="1d1983037d4fd7beac963697b84f82bd" category="paragraph"><block ref="1d1983037d4fd7beac963697b84f82bd" category="inline-link-macro-rx"></block></block>
  <block id="cff4cbb413623685c446a2632974cf62" category="summary">このページでは、従来の Pandas を使用したモデルのトレーニング時間を Dask と比較します。Pandas では、メモリオーバーフローを回避するために、処理時間が遅くなるため、より少量のデータをロードしました。そのため、結果を補間して公平な比較を行いました。</block>
  <block id="014020acc8f97c1da58961d44b6301eb" category="doc">トレーニング時間の比較</block>
  <block id="76c5145913d13d6c3105c4265a78047e" category="inline-link-macro">前の手順：ネイティブタスクストリームダッシュボードを使用して Dask を監視します。</block>
  <block id="a871e4d194e2df9c65b061a5fc7cb154" category="paragraph"><block ref="a871e4d194e2df9c65b061a5fc7cb154" category="inline-link-macro-rx"></block></block>
  <block id="c8ed0bb49061765f5f30ba006ea7c5c0" category="paragraph">このセクションでは、従来の Pandas を使用したモデルのトレーニング時間を Dask と比較します。Pandas では、メモリオーバーフローを回避するために、処理時間が遅くなるため、より少量のデータをロードしました。そのため、結果を補間して公平な比較を行いました。</block>
  <block id="5b5214524edbd74fb721da08e61c8a41" category="paragraph">次の表は、 Pandas ランダムフォレストモデルに使用されるデータが大幅に少ない場合の、生のトレーニング時間の比較を示しています ( データセットの 1 日あたりの 2000 億行のうち、 5,000 万行 ) 。このサンプルでは、使用可能なすべてのデータの 0.25% 未満しか使用されていません。DASK cuML の場合は '20 億行すべての使用可能なローについてランダムフォレストモデルをトレーニングしましたこの 2 つのアプローチでは、同等のトレーニング時間が得られました</block>
  <block id="40a68b5da4b9b224764558bb02ecd028" category="cell">アプローチ</block>
  <block id="0e90ab0d7d04d2a878961f8d40071c83" category="cell">トレーニング時間</block>
  <block id="24cc88af022e13431f8005b38f74e0fd" category="cell">Scikit - Learn ：トレーニングデータとして day15 の 50 M 行のみを使用します</block>
  <block id="26e394f0b8009246698f4844db682015" category="cell">47 分 21 秒</block>
  <block id="ed536b2798ed9f16a79fb8f772601548" category="cell">Rapids-DASK ：トレーニングデータとして、 Day15 のすべての 20B 行を使用します</block>
  <block id="8809f6d1a4b5cbd872b52f83e378e527" category="cell">1 時間 12 分 11 秒</block>
  <block id="57093fade268287629c2720356ecac57" category="paragraph">次の表に示すように、トレーニング時間の結果を直線的に補間する場合、 Dask を使用した分散型トレーニングを使用すると大きな利点があります。従来の Pandas の scikit 学習アプローチでは、クリックログ 1 日あたり 45 GB のデータを処理してトレーニングするのに 13 日かかりますが、 Rapids-Dask アプローチでは同じ量のデータを処理するのにかかる時間は 262.39 倍になります。</block>
  <block id="36ebc33745cb5ac06238c615c8aaebdc" category="cell">Scikit - Learn ：トレーニングデータとして day15 のすべての 20B 行を使用します</block>
  <block id="b2ab615236e8c7812b0ab7dff59c552f" category="cell">13 日、 3 時間、 40 分、 11 秒</block>
  <block id="0d7cda3e89555f27bf26cf0c0c4f4fed" category="paragraph">前の表では、 Dask と Rapids を使用してデータ処理とモデルトレーニングを複数の GPU インスタンスに分散することで、従来の Pandas DataFrame 処理と比較して、 scikit 学習モデルトレーニングでの実行時間が大幅に短縮されたことを確認できます。このフレームワークを使用すると、マルチノードのマルチ GPU クラスタ内だけでなく、クラウド内でもオンプレミスでのスケールアップとスケールアウトが可能です。</block>
  <block id="fbd52cffa97d6ec5e0230516fc61f14c" category="inline-link-macro">次の例： Prometheus と Grafana で Dask と Rapids を監視します。</block>
  <block id="78117011d88a8971f2eadbeee6ac6474" category="paragraph"><block ref="78117011d88a8971f2eadbeee6ac6474" category="inline-link-macro-rx"></block></block>
  <block id="57a499fcdd85136edfd1ee55dedd9675" category="summary">この解決策は、 AI / ML アプリケーションのライフサイクルに従います。まず、データサイエンティストの仕事から始めて、データの準備やモデルのトレーニングに必要なさまざまなステップを定義します。Dask のラピッズを活用することで、 Azure Kubernetes Service （ AKS ）クラスタ全体で分散トレーニングを実施し、従来の Python の坐骨神経痛手法に比べてトレーニング時間を大幅に短縮しました。完全なサイクルを完了するには、パイプラインと Azure NetApp Files を統合します。</block>
  <block id="e6fab630e7da86a500e1e3c51fa61a00" category="paragraph">ネットアップ、 Verron Martina 、 Muneer Ahmad 、 Rick Huang 氏</block>
  <block id="4c3816ce69205bc811aa89dbe9d09a1a" category="paragraph">データサイエンティストの仕事は、機械学習（ ML ）モデルと人工知能（ AI ）モデルのトレーニングと調整に集中する必要があります。しかし、 Google の調査によると、データサイエンティストは、モデルをエンタープライズアプリケーションと連携させ、大規模に運用する方法を検討する時間の約 80% を費やしています。</block>
  <block id="a1451f6988178ae140f8da836d63a157" category="paragraph">エンドツーエンドの AI / ML プロジェクトを管理するには、エンタープライズコンポーネントについてより広範な理解が必要です。DevOps がその定義、統合、導入を引き継ぎましたが、 ML の運用では、 AI や ML プロジェクトを含む同様のフローがターゲットとなります。エンドツーエンドの AI / ML パイプラインが企業内でどのように影響するかを知るには、次の必要なコンポーネントのリストを参照してください。</block>
  <block id="24bea3d677b34d6aea9ff01417fd9d06" category="list-text">統合開発環境（ IDE ）</block>
  <block id="e6a53478c3fc5682c6f851672b3e7bc9" category="paragraph">データサイエンスの世界は、 IT とビジネスのさまざまな分野に影響をもたらしています。</block>
  <block id="9ca78187997ba2a23a73c094256ae63f" category="list-text">クラウド管理者とアーキテクトは、 Azure リソースをセットアップおよび管理できる必要があります。</block>
  <block id="060bc2911862b1ab8f6b4b77542434a2" category="paragraph">このテクニカルレポートでは、 Azure NetApp Files 、 Rapids AI 、 Dask 、 Azure が、これらの各役割がビジネスにもたらす価値について説明します。</block>
  <block id="ed8b6e047f5d4e844fe3e870c3fda4a3" category="paragraph">Azure NetApp Files は、さまざまなパフォーマンス階層を提供します。お客様はまず Standard 階層から始めて、データを移動することなく、スケールアウトしてハイパフォーマンス階層まで無停止でスケールアップできます。この機能により、データサイエンティストは、次の図に示すように、パフォーマンスの問題を発生させることなく、大規模なモデルのトレーニングを実施できます。クラスタ全体にデータサイロが発生することはありません。</block>
  <block id="d4dc9019b6000fd12d9dc6b091fe3e26" category="paragraph"><block ref="d4dc9019b6000fd12d9dc6b091fe3e26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b320345f652aacf7148c76dff24e2f68" category="inline-link-macro">次のステップ：テクノロジの概要</block>
  <block id="a20978df09e58f39953eb81f9368c2f2" category="paragraph"><block ref="a20978df09e58f39953eb81f9368c2f2" category="inline-link-macro-rx"></block></block>
  <block id="d577549f9b3a229c338e203a433489f6" category="summary">ここでは、 Azure NetApp Files VNet に AKS VNet をピアリングする方法について説明します。</block>
  <block id="e61e6d340ad05dc2e1ad0982f6857d7d" category="doc">ピア AKS の VNet と Azure NetApp Files VNet</block>
  <block id="1c45d541f316a23589217be5991b1545" category="inline-link-macro">前の処理： Azure NetApp Files の委譲されたサブネットを作成します。</block>
  <block id="786730f8769009abf0bf6400157dd16b" category="paragraph"><block ref="786730f8769009abf0bf6400157dd16b" category="inline-link-macro-rx"></block></block>
  <block id="e6ef5f0946a89d073a8f360de1038061" category="paragraph">AKS VNet を Azure NetApp Files VNet にピアリングするには、次の手順を実行します。</block>
  <block id="87c2d6c506d0bf65d2c5d773474f9c0f" category="list-text">検索フィールドに Virtual Networks と入力します。</block>
  <block id="7680f3bc49a836c67a8b0e7d2d9ccb44" category="list-text">「 vnet AK - vnet-name 」を選択します クリックして、検索フィールドに peerings と入力します。</block>
  <block id="fc3bb6a018a8f599cab21678959f92b0" category="list-text">+ Add をクリックします。</block>
  <block id="1991ef5bd8e165e42c56ccaefa2f640f" category="list-text">次の記述子を入力します。</block>
  <block id="51e5b9c0a583a9afbc2f998e622fd30d" category="list-text">ピアリングリンク名は 'AKs-vnet-name_-to-anf' です</block>
  <block id="14ac6521e2758ba95fe7be9ca6a82cd1" category="list-text">VNet ピアリングパートナーとしての SubscriptionID および Azure NetApp Files VNet</block>
  <block id="70b58cb057d859d4da9f17e43ffd238c" category="list-text">アスタリスク以外のすべてのセクションは、デフォルト値のままにします。</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">追加をクリックします。</block>
  <block id="50e3209c871e4867931ef51a9344a921" category="paragraph">詳細については、を参照してください<block ref="f81943721c88f7efe9b8252470f9ea43" category="inline-link-rx"></block>。</block>
  <block id="fd3c95528aa9718948de8d4e38b2fa2c" category="inline-link-macro">次の手順： Trident をインストール</block>
  <block id="18337fe57049583a9c04a79f64a2088f" category="paragraph"><block ref="18337fe57049583a9c04a79f64a2088f" category="inline-link-macro-rx"></block></block>
  <block id="dcfa517bb68d187d11e580baf2ecf588" category="summary">このページでは、 Helm を使用して AKS に Dask with Rapids deployment を設定する方法について説明します。</block>
  <block id="fd22fb1626b987fa7b72743fa9698ec6" category="doc">Helm を使用して、 AKS で Rapids デプロイメントを使用して Dask をセットアップします</block>
  <block id="d74bb88aa6e4b1c540be703fda33923e" category="inline-link-macro">前のページ： Trident をインストール</block>
  <block id="6020c64d2124fc0caa426123bfc5ba38" category="paragraph"><block ref="6020c64d2124fc0caa426123bfc5ba38" category="inline-link-macro-rx"></block></block>
  <block id="d81f517b6ad0d9702be81a8199a2246f" category="paragraph">Helm を使用して AKS で Rapids を使用して Dask をセットアップするには、次の手順を実行します。</block>
  <block id="549c839f491ec7099a895dd1cfea7534" category="list-text">Dask with Rapids をインストールするための名前空間を作成します。</block>
  <block id="74d041e68ac2a21a636ab14ae78f279d" category="list-text">クリックスルーレートデータセットを保存する PVC を作成します。</block>
  <block id="f5008aa6b27cdcaadbe27960383c8ff6" category="list-text">次の YAML コンテンツをファイルに保存して PVC を作成します。</block>
  <block id="67d464c36bcc48173c964a780459dbfd" category="list-text">YAML ファイルを Kubernetes クラスタに適用します。</block>
  <block id="be0ca76aafd92c18792693b8f05d01ce" category="inline-link"><block ref="be0ca76aafd92c18792693b8f05d01ce" category="inline-link-rx"></block></block>
  <block id="dc7ba914646428512334728c1f0ebd7d" category="list-text">rapidsai git リポジトリを複製します (<block ref="4f08c7c28c19e75f4d8607fc65d40067" category="inline-link-rx"></block>）。</block>
  <block id="50aef45ee39d958bc589f422bfb6d1bf" category="list-text">値 .yaml を変更し、作業者および Jupyter ワークスペース用に前に作成した PVC を含めます。</block>
  <block id="06867e85b141bb9d17f8ed6b4b685c46" category="list-text">リポジトリの 'rapidsai' ディレクトリに移動します</block>
  <block id="1a985ac965074fab9cfcee28ef954755" category="list-text">「 values] .yaml ファイルを更新し、 PVC を使用してボリュームをマウントします。</block>
  <block id="52076eb1fec3929530258335052328b3" category="list-text">リポジトリのホーム・ディレクトリに移動し 'Helm を使用して AKS 上に 3 つのワーカー・ノードを持つ Dask を展開します</block>
  <block id="bd4e74749939dd3c9f80ff138c18af53" category="inline-link-macro">次： Azure NetApp Files のパフォーマンス階層</block>
  <block id="52d5e0adb69809963ce4f94104a75b5e" category="paragraph"><block ref="52d5e0adb69809963ce4f94104a75b5e" category="inline-link-macro-rx"></block></block>
  <block id="1a17b23dd49d997677e18c9b9fe29935" category="summary">このページでは、ネイティブの Task Stream ダッシュボードを使用して Dask を監視する方法について説明します。</block>
  <block id="3268570ddd540695f3e92ff79d8f4684" category="doc">ネイティブタスクストリームダッシュボードを使用して Dask を監視します</block>
  <block id="1e80a6d70a902d1dae25d26917a5b490" category="inline-link-macro">前のページ : Dask の 15 日目をロードし、 Dask cuML ランダムフォレストモデルをトレーニングします。</block>
  <block id="3898f5ae37dfd830af10cdc128236b50" category="paragraph"><block ref="3898f5ae37dfd830af10cdc128236b50" category="inline-link-macro-rx"></block></block>
  <block id="9eeb55820f49a600fa229f23cfe9e5b5" category="inline-link">Dask 分散スケジューラ</block>
  <block id="99b248c7005783fe2682ad82217e9a24" category="paragraph">。<block ref="7df0d90bf997a373bfe85bbe10a2d2c8" category="inline-link-rx"></block> ライブフィードバックは、次の 2 つの形式で提供します。</block>
  <block id="d8516bf5d94a38a1fa1d7a8c3b92dee7" category="list-text">ライブ情報を含む多数のプロットやテーブルを含むインタラクティブなダッシュボード</block>
  <block id="d22ebe91c5dc1499387785da997fbe7d" category="list-text">コンソールやノートブックでの対話型の使用に適したプログレスバーです</block>
  <block id="6e35e4c1cc9332ebc8028df451bc4f06" category="paragraph">この場合、次の図は、保存されたバイト数、ストリーム数の詳細な内訳を示すタスクストリーム、実行された関連機能を持つタスク名ごとの進捗状況を監視する方法を示しています。この例では、ワーカーノードが 3 つあるため、ストリームには 3 つの主要なチャンクがあり、各ストリーム内で異なるタスクを示すカラーコードがあります。</block>
  <block id="5743e70224503025dacaa77fae253c4f" category="paragraph"><block ref="5743e70224503025dacaa77fae253c4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a5c7a858f05434bf6637c3995959f49" category="paragraph">個々のタスクを分析し、実行時間をミリ秒単位で調査するか、障害や障害を特定することができます。たとえば、次の図は、ランダムフォレストモデルフィッティングステージのタスクストリームを示しています。実行される関数は、 DataFrame 処理用の一意のチャンク、ランダムフォレストをフィッティングするための _construct_RF など、はるかに多くあります。Criteo のクリックログに含まれる 1 日分のデータのサイズ（ 45GB ）が大きいため、 DataFrame の処理にほとんどの時間が費やされていました。</block>
  <block id="816ff133aaa3d2f46ca0c7842f5fdaab" category="paragraph"><block ref="816ff133aaa3d2f46ca0c7842f5fdaab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5eca1492a19a4c24071ed91262666cf" category="inline-link-macro">次：トレーニング時間の比較。</block>
  <block id="d5d929f175d4a2062c661e45b9656f32" category="paragraph"><block ref="d5d929f175d4a2062c661e45b9656f32" category="inline-link-macro-rx"></block></block>
  <block id="d68d11ee3f69a45d681f78c744cae498" category="summary">既存のボリュームのサービスレベルを変更するには、そのボリュームに必要なサービスレベルを使用する別の容量プールにボリュームを移動します。この解決策を使用することで、お客様は、まず小規模なデータセットと少数の GPU を標準階層に配置し、データ量と GPU の増加に合わせてスケールアウトまたは Premium Tier へのスケールアップを行うことができます。</block>
  <block id="2fe5665064f07acc8afc830f911c09a5" category="doc">Azure NetApp Files のパフォーマンス階層</block>
  <block id="d84e339c1d1265f11e2f217f8d04354a" category="inline-link-macro">前の手順： Helm を使用して AKS に Rapids デプロイメントで Dask をセットアップしました。</block>
  <block id="1be55e0d10ba600a3d66b1f73f978b9f" category="paragraph"><block ref="1be55e0d10ba600a3d66b1f73f978b9f" category="inline-link-macro-rx"></block></block>
  <block id="de524ca3fc83ef426bc329e1a8b712ea" category="paragraph">既存のボリュームのサービスレベルを変更するには、そのボリュームに必要なサービスレベルを使用する別の容量プールにボリュームを移動します。この解決策を使用することで、お客様は、まず小規模なデータセットと少数の GPU を標準階層に配置し、データ量と GPU の増加に合わせてスケールアウトまたは Premium Tier へのスケールアップを行うことができます。Premium Tier は、 Standard 階層のテラバイトあたりスループットの 4 倍を提供し、ボリュームのサービスレベルを変更するためにデータを移動することなくスケールアップを実行できます。</block>
  <block id="5f92df8a2ac38644ed8ba20e16791602" category="paragraph">ボリュームのサービスレベルを動的に変更するには、次の手順を実行します。</block>
  <block id="8c83c4957baac2f6fea18f9d77767e3a" category="paragraph"><block ref="8c83c4957baac2f6fea18f9d77767e3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21ec2eabbe87e02cad1b0d4279ea00a7" category="list-text">プールの変更ウィンドウで、ボリュームの移動先となる容量プールを選択します。</block>
  <block id="ef3a0105bad35ad4c385d92daf6496a6" category="paragraph"><block ref="ef3a0105bad35ad4c385d92daf6496a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">[OK] をクリックします。</block>
  <block id="32ae33eea9c6b04002778d814c344fb5" category="section-title">パフォーマンス階層の変更を自動化</block>
  <block id="1c9506694c5a6fe83d1a0389d1d24564" category="paragraph">パフォーマンス階層の変更を自動化するには、次のオプションを使用できます。</block>
  <block id="54a3bcd89041e8f96766dcb598b15511" category="list-text">現在も動的サービスレベルの変更はパブリックプレビューで有効になっており、デフォルトでは有効になっていません。Azure サブスクリプションでこの機能を有効にする方法については、このドキュメントを参照してください<block ref="773d4c9e90e7325c5fcf35857900af6e" category="inline-link-rx"></block>。</block>
  <block id="0b01c5f61940e864222c5b29615a7eeb" category="inline-link">ボリュームプールの変更に関するドキュメント</block>
  <block id="265eed4df59633a830c9da49505786fc" category="list-text">Azure CLI の volume pool change コマンドについては、を参照してください<block ref="db78b725076ccf0203288c6620e52eb9" category="inline-link-rx"></block> 次に例を示します。</block>
  <block id="4455e376dc005ca0a99be0491b917ce7" category="inline-link">set-AzNetAppFilesVolumePool コマンドレット</block>
  <block id="a5bce2f378011f6036711869a5e8073b" category="list-text">PowerShell<block ref="45dc9ea5ce8eabd60a14674d792889e0" category="inline-link-rx"></block> Azure NetApp Files ボリュームのプールを変更し、次の例に示すようにします。</block>
  <block id="b79b50d5bff47e3a668f266c7b9dbc7b" category="inline-link-macro">次の例：データ処理とモデルトレーニング用のライブラリ。</block>
  <block id="edd770dcbb857ec8f0871955fb2f7d5d" category="paragraph"><block ref="edd770dcbb857ec8f0871955fb2f7d5d" category="inline-link-macro-rx"></block></block>
  <block id="60f89129c6220bfb3de5a84b4f6471ca" category="summary">このページでは、 Pandas と Dask DataFrames を使用して、 Criteo Terabyte データセットから Click Logs データをロードする方法について説明します。このユースケースは、広告交換のためのデジタル広告において、広告がクリックされるかどうかを予測したり、交換品が自動化されたパイプラインで正確なモデルを使用していないかどうかを予測したりすることで、ユーザーのプロファイルを作成する場合に適しています。</block>
  <block id="efdbc2f24f0a87c559175250c645b26b" category="doc">Pandas で Logs Day 15 をクリックして、 scikit に学習したランダムフォレストモデルをトレーニングします</block>
  <block id="2979440f06f7cfcab78b9a92ca964f28" category="inline-link-macro">Previous ：データ処理とモデルトレーニング用のライブラリ。</block>
  <block id="f2982e3861753bd206faa379a769d904" category="paragraph"><block ref="f2982e3861753bd206faa379a769d904" category="inline-link-macro-rx"></block></block>
  <block id="f82859e215621220b9aae984f796ef24" category="paragraph">このセクションでは、 Pandas と Dask DataFrames を使用して、 Criteo Terabyte データセットから Click Logs データをロードする方法について説明します。このユースケースは、広告交換のためのデジタル広告において、広告がクリックされるかどうかを予測したり、交換品が自動化されたパイプラインで正確なモデルを使用していないかどうかを予測したりすることで、ユーザーのプロファイルを作成する場合に適しています。</block>
  <block id="f08833dbbe310e84a1ba564838776db2" category="paragraph">Click Logs データセットから 15 日目のデータをロードし、合計 45GB にしました。Jupyter ノートブックの ctr-pandasrf-colated で次のセルを実行すると、最初の 5,000 万行を含む Pandas DataFrame が作成され、 scikit 学習ランダムフォレストモデルが生成されます。</block>
  <block id="f9964b2f8f54a1422ac46bab70fd1216" category="inline-link">公式の坐骨神経痛 - 学習文書</block>
  <block id="5646953e1414498e1ddf2eb3ab488e27" category="paragraph">トレーニングされたランダムフォレストモデルを使用して予測を実行するには、このノートブックで次の段落を実行します。重複を避けるために、 15 日目から最後の 100 万行をテストセットとして使用しました。セルはまた、モデルの発生率として定義された予測精度を計算し、ユーザーが広告をクリックするかどうかを正確に予測します。このノートブックの構成部品を確認するには、を参照してください<block ref="27e4d9ca2442a6439517a3ec2c7a4e73" category="inline-link-rx"></block>。</block>
  <block id="4e5653c75e720212b79703e8083de2a8" category="inline-link-macro">次は、 Dask の 15 日目をロードし、 Dask cuML ランダムフォレストモデルをトレーニングします。</block>
  <block id="8c9976282cff1b15934d937349911c30" category="paragraph"><block ref="8c9976282cff1b15934d937349911c30" category="inline-link-macro-rx"></block></block>
  <block id="7f39827ac712fa5b76b27ff0b267373c" category="sidebar">NetApp DataOps ツールキットを使用したデータセットとモデルのバージョン管理</block>
  <block id="6589da0279dd02b9b1d177e0ff5f457b" category="list-text">Astra Control Center Operator をインストールするための名前空間 NetApp-acc-operator を作成します。</block>
  <block id="e3990b0b892faaf03261a0a1bcd00b9b" category="list-text">NetApp-acc-operator ネームスペースのイメージレジストリにログインするためのクレデンシャルを含むシークレットを作成します。</block>
  <block id="8b6327b93d10679b1f412976af9d3bba" category="summary">Azure NetApp Files 、 Rapids 、 Dask は、 Docker や Kubernetes などのオーケストレーションツールと統合された大規模な ML 処理とトレーニングの導入を高速化し、簡易化します。エンドツーエンドのデータパイプラインを統合する解決策ことで、多くの高度なコンピューティングワークロードに特有のレイテンシと複雑さを軽減し、開発と運用のギャップを効果的に解消します。</block>
  <block id="5dc14d36063086387d2eb7cf012544aa" category="list-text">ボリューム Snapshot を作成するために使用できるボリューム Snapshot クラスを作成します。Storage &gt; VolumeSnapshotClasses の順に移動し、 Create VolumeSnapshotClass をクリックします。</block>
  <block id="3ffbaa72c8e63f0ec3ced08d8ebf9f72" category="list-text">最初に、スナップショットを新しい PVC に復元します。Storage &gt; VolumeSnapshots と進み、リストアする Snapshot の横にある省略記号をクリックして、 Restore as new PVC （新しい PVC として復元）をクリックします。</block>
  <block id="8a4d1acf8df9931b5c42b3253f943d79" category="list-text">次に、この PVC から新しい VM を作成します。[Workloads （ワークロード） ] &gt; [Virtualization （仮想化） ] &gt; [Virtual Machines （仮想マシン） ] に移動し、 [Create （作成）</block>
  <block id="91b9a57ab88a6942f692f9f393549f6e" category="list-text">spec&gt;template&gt;spec&gt;volumes セクションで、コンテナディスクからではなく、スナップショットから作成された新しい PVC を指定します。新しい VM について、要件に応じてその他の詳細をすべて指定します。</block>
  <block id="78c43863df60a7808264e8659cfa6b54" category="paragraph">Astra Trident は、コンテナや Kubernetes ディストリビューション向けの、 Red Hat OpenShift などのオープンソースで完全にサポートされているストレージオーケストレーションツールです。Trident は、 NetApp ONTAP や Element ストレージシステムを含むネットアップストレージポートフォリオ全体と連携し、 NFS 接続と iSCSI 接続もサポートします。Trident を使用すると、ストレージ管理者の手を煩わせることなく、エンドユーザがネットアップストレージシステムからストレージをプロビジョニングして管理できるため、 DevOps ワークフローが高速化されます。</block>
  <block id="d719c733d0cd8753c048c8c3a025fd51" category="paragraph">MetalLB は、 OpenShift クラスタにインストールされた自己ホスト型ネットワークロードバランサであり、クラウドプロバイダで実行されないクラスタでタイプロードバランサの OpenShift サービスを作成できます。LoadBalancer サービスをサポートするために連携する MetalLB の 2 つの主な機能は、アドレス割り当てと外部アナウンスメントです。</block>
  <block id="13f78a1c753a58b3786e5664e7b01344" category="list-text">* このモードでは、 OpenShift クラスタ内のすべてのノードがルータとの BGP ピアリングセッションを確立し、トラフィックをサービス IP に転送するためにルートをアドバタイズします。このための前提条件は、 MetalLB をそのネットワーク内のルータと統合することです。BGP のハッシュメカニズムにより、サービスの IP-to-Node マッピングが変更されることがあります。詳細については、のドキュメントを参照してください <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>。</block>
  <block id="5fe238de20fea7c5ec86dde0a98c5841" category="admonition">このマニュアルでは、レイヤ 2 モードで MetalLB を設定します。</block>
  <block id="0ef06ef8df800cf71fb95c66e0e08f1a" category="list-text">最初に、 [ インフラストラクチャの自動化 ] 、 [ クラスタ ] の順に移動</block>
  <block id="e056bb6efa17796fc810edad8410280d" category="list-text">プロバイダ接続の作成： [ プロバイダ接続 ] に移動して [ 接続の追加 ] をクリックし、選択したプロバイダタイプに対応するすべての詳細を入力して [ 追加 ] をクリックします。</block>
  <block id="401b252566122602a82ff66bc7ed3e6c" category="list-text">新しいクラスタを作成するには、クラスタに移動し、クラスタの追加 &gt; クラスタの作成をクリックします。クラスタと対応するプロバイダの詳細を指定し、 Create をクリックします。</block>
  <block id="2da6eeb34cf16de43ab8fa2f939d81c7" category="list-text">作成されたクラスタは、クラスタのリストに Ready ステータスで表示されます。</block>
  <block id="f52ae06380cfd00cae7839562f550e87" category="list-text">クラスタに移動し、クラスタの追加 &gt; 既存クラスタのインポートをクリックします。</block>
  <block id="63b7276dd1b569babc28304e786e2041" category="list-text">クラスタの名前を入力し、 [ インポートしてコードを生成して保存 ] をクリックします。既存のクラスタを追加するコマンドが表示されます。</block>
  <block id="be87809a27ab2944f89ccaebd89b7596" category="list-text">Copy コマンドをクリックし、ハブクラスタに追加するクラスタ上でコマンドを実行します。これにより、必要なエージェントのクラスタへのインストールが開始され、このプロセスが完了すると、クラスタがクラスタリストに「 Ready 」と表示されます。</block>
  <block id="627fd2c5e0310dc7409ea377e5d13045" category="section-title">割り当てられたプロジェクトで PVC またはポッドを作成するためのアクセスを検証します</block>
  <block id="8c9885c86a67cc4c47a30d7e8d14badb" category="section-title">アクセスを検証して別のプロジェクトに PVC またはポッドを作成するか、別のプロジェクト専用のリソースを使用します</block>
  <block id="83aa0a39007c30e71adde6fbf8180d9f" category="section-title">アクセス権を検証して、プロジェクト、リソースクォータ、ストレージクラスを表示および編集します</block>
  <block id="53c583e55a36ad49234df678a2dbcf45" category="paragraph">NetApp Element ソフトウェアは、拡張性に優れたモジュラ型のパフォーマンスを提供し、ストレージノードごとに容量とスループットを保証します。NetApp Element システムは、 1 つのクラスタで 4~100 ノードまで拡張でき、高度なストレージ管理機能も多数備えています。</block>
  <block id="28bbba0205a8bfd9f8f2da8b73522dc7" category="inline-link-macro">次のセクション：ネットアップストレージ統合の概要</block>
  <block id="d61c98dcb4bec6f3e1213776ebb1e6c3" category="paragraph"><block ref="d61c98dcb4bec6f3e1213776ebb1e6c3" category="inline-link-macro-rx"></block></block>
  <block id="1c01b62cc887329b006a88e9f959b5d4" category="list-text">IdP に project-3 のユーザグループが作成され、 OpenShift クラスタと同期されていることを確認してください。</block>
  <block id="e98511d60f9850de86f096614f447322" category="paragraph">Kubernetes 向けの高度なクラスタ管理機能を使用すると、ノード、ポッド、およびすべてのクラスタのアプリケーションとワークロードを監視できます。</block>
  <block id="36aff44ed429ca86d182dc7ee3dfdbb1" category="list-text">[ 環境の監視 ]&gt;[ 概要 ] に移動します。</block>
  <block id="c9904a9276a489fc238c999d2ddd633f" category="list-text">すべてのクラスタのすべてのポッドとワークロードが監視され、さまざまなフィルタに基づいてソートされます。ポッドをクリックすると、対応するデータが表示されます。</block>
  <block id="7cd1c61051d3647bc47d839e0efee222" category="list-text">クラスタ内のすべてのノードが、さまざまなデータポイントに基づいて監視および分析されます。ノードをクリックすると、対応する詳細が表示されます。</block>
  <block id="4e7f54a0ebc5cd69209a17181d477e4c" category="list-text">クラスタはすべて、クラスタのリソースとパラメータに基づいて監視および整理されます。クラスタをクリックしてクラスタの詳細を表示します。</block>
  <block id="842f7d4793f116332f5b12b648dfd539" category="list-text">ワークロード &gt; 仮想化 &gt; 仮想マシンと進み、作成 &gt; ウィザードを使用してをクリックします。</block>
  <block id="ae024d48dbfaaf4badad7bf9c812a98f" category="list-text">rootdisk の横にある省略記号をクリックし、 Trident を使用してプロビジョニングされたストレージクラスが選択されていることを確認します。[ 詳細設定 ] を展開し、 [ アクセスモード ] で [ 共有アクセス (RWX) ] を選択します。[ 保存 ] をクリックします。</block>
  <block id="289f346dbeb0185de2648a24955ca887" category="list-text">ワークロード &gt; 仮想化 &gt; 仮想マシンと進みます。</block>
  <block id="a542faac65568ba146d392d835d7fb33" category="list-text">* VMware vCenter Server* 。 VMware vCenter Server は、 1 つのコンソールからすべてのホストと VM を統合管理し、クラスタ、ホスト、 VM のパフォーマンス監視を集約します。</block>
  <block id="413563ec6c2672beb7df15f465cb4a48" category="list-text">* VMware vSphere vMotion 。 * VMware vCenter では、要求に応じて、無停止でクラスタ内のノード間で VM をホット移行できます。</block>
  <block id="e6583703b8777be27f8db85d741711b4" category="list-text">* vSphere High Availability 。 * ホスト障害時のシステム停止を避けるため、 VMware vSphere を使用すると、ホストをクラスタ化して High Availability に構成することができます。ホストの障害によってシステムが停止した VM は、クラスタ内の他のホストでまもなくリブートされ、サービスがリストアされます。</block>
  <block id="46b35ead34118cb2c50327c71e4aa640" category="list-text">* DRS （ Distributed Resource Scheduler ）。 * VMware vSphere クラスタは、ホストしている VM のリソースニーズを負荷分散するように構成できます。リソース競合のある VM は、十分なリソースを使用できるように、クラスタ内の他のノードにホット移行できます。</block>
  <block id="5c6371faa8d72dee8337811921707a4b" category="paragraph">NetApp 解決策上の Red Hat OpenShift では、 2 つのデータスイッチを使用して 25Gbps でプライマリデータ接続を提供します。また、ストレージノードのインバンド管理用に 1Gbps で接続を提供する管理スイッチをさらに 2 台使用し、 IPMI 機能のアウトオブバンド管理も行います。OCP のクラスタ管理には、 VMware vSphere 上の VM 論理ネットワークが使用されます。このセクションでは、解決策で使用される各仮想ネットワークセグメントの配置と目的について説明し、解決策を導入するための前提条件について説明します。</block>
  <block id="f33bd5bca507f2b59fc0a43383ade71b" category="cell">仮想ゲストネットワークアクセス</block>
  <block id="3500f2194985ef1b586c649fbe519d8d" category="paragraph">本ドキュメントで説明する検証済みのアーキテクチャには、 VMware vSphere HA と VMware vMotion を有効にして、 2 つの ESXi ハイパーバイザーノードを導入し、フォールトトレラント構成を確保することで、 HA 処理に適した最小限のハードウェア環境が示されています。この構成では、導入した VM を 2 つのハイパーバイザー間で移行し、 1 つのホストが使用できなくなった場合にリブートすることができます。</block>
  <block id="e79fa01ec6b411cfda4f8baad9f95cb0" category="paragraph">Red Hat OpenShift では最初に 3 つのマスターノードを導入するため、 2 ノード構成の少なくとも 2 つのマスターが同じノードを占有することがあります。その場合、特定のノードが使用できなくなったときに OpenShift が停止する可能性があります。そのため、 Red Hat のベストプラクティスでは、 OpenShift マスターを均等に分散してフォールトトレランスを高めるために、少なくとも 3 つの ESXi ハイパーバイザーノードを導入する必要があります。</block>
  <block id="f5428382aa8b44d7ef6ca71195afc8ca" category="paragraph">VM とホストのアフィニティを有効にすることで、複数のハイパーバイザーノードに OpenShift マスターを確実に分散させることができます。</block>
  <block id="c23c2371397ad3490af42526283948a4" category="paragraph">アフィニティまたは非アフィニティは、 VM やホストのセットに対してルールを定義する方法で、グループ内の同じホストまたはホスト上で VM を一緒に実行するか、別のホスト上で実行するかを決定します。VM とホストで構成されるアフィニティグループを作成することで、 VM に適用されます。このアフィニティグループには同じパラメータと条件が設定されます。アフィニティグループ内の VM がグループ内の同じホストで実行されているのか、または別々のホストで実行されているのかに応じて、アフィニティグループのパラメータでは正のアフィニティまたは負のアフィニティを定義できます。</block>
  <block id="5e059b05dcf86db414d6b8cdd66bcf0f" category="paragraph">IPI を使用すると、このドキュメントで前述した対話型ウィザードを使用して、 OpenShift クラスタを簡単に導入できます。ただし、クラスタ導入の一環として、一部のデフォルト値の変更が必要になる場合があります。</block>
  <block id="6e7315bf45cda77f0a1477ed6f712eb6" category="paragraph">このような場合は、クラスタをすぐに導入せずにウィザードを実行してタスクを実行できますが、代わりに、あとでクラスタを導入できる構成ファイルが作成されます。これは、 IPI のデフォルトを変更する必要がある場合や、マルチテナンシーなどの他の用途のために環境内に同一のクラスタを複数導入する場合に非常に便利です。OpenShift 用にカスタマイズされたインストール構成の作成の詳細については、を参照してください<block ref="fc4239653f75b84dd3ca03fe8b28dd64" category="inline-link-rx"></block>。</block>
  <block id="2a3b399798aa16ecfbc1425cc560bfad" category="section-title">ユースケース</block>
  <block id="f08561bbd831bfa1923e6acf045ef13a" category="section-title">ビジネスバリュー</block>
  <block id="81f74b2a02db97d708bd7cbf08d2463a" category="section-title">ネットアップストレージシステム</block>
  <block id="660d073f0987fac312dc40bd5dc868bd" category="paragraph">ネットアップには、エンタープライズデータセンターやハイブリッドクラウド環境に最適なストレージシステムが複数あります。ネットアップのポートフォリオには、コンテナ化されたアプリケーションに永続的ストレージを提供できる NetApp ONTAP 、 NetApp Element 、および NetApp E シリーズストレージシステムが含まれています。</block>
  <block id="069b087e8e1e69cc928f18a85f683523" category="section-title">ネットアップとストレージの統合</block>
  <block id="b4186621511a622be24ad982b0a8ec32" category="paragraph">NetApp Astra Control Center は、信頼性の高いネットアップのデータ保護テクノロジを基盤とするオンプレミス環境に導入された、ステートフル Kubernetes ワークロード向けの充実したストレージおよびアプリケーション対応のデータ管理サービスを提供します。</block>
  <block id="947496ade2e4a2c8e929d9aa9f00be04" category="paragraph">詳細については、 NetApp Astra の Web サイトをご覧ください<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>。</block>
  <block id="0bc570c518e7c4f356ebceb14fa8372f" category="section-title">Advanced Configuration Options （詳細設定オプション）</block>
  <block id="aa44798f04a58b33c3699abd02a59c57" category="paragraph">このセクションは、実環境のユーザがこの解決策を本番環境に導入するときに実行する必要があるカスタマイズ（専用のプライベートイメージレジストリの作成やカスタムロードバランサインスタンスの導入など）に特化したものです。</block>
  <block id="382742bb5fff6a719c144a0a01cd17e3" category="section-title">検証済みリリースの現在のサポートマトリックスです</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">ソフトウェアのバージョン</block>
  <block id="e3024b13494086daa1b9813a799ba41a" category="cell">データセンターの仮想化</block>
  <block id="35be109b995061abd3392d1b01fd0e9a" category="summary">Red Hat OpenStack Platform は、セキュアで信頼性の高いプライベート OpenStack クラウドの構築、導入、拡張を行うための統合基盤を提供します。</block>
  <block id="dc34aa9761794ceabad79dc29944976e" category="paragraph">OpenStack プロジェクトは、短期間で開発されたコミュニティプロジェクトで、 6 カ月ごとに更新リリースを提供します。最初の Red Hat OpenStack Platform は、すべてのアップストリームリリースに加えて新しいリリースを公開することで、このリリースサイクルのペースを維持していました。また、 3 回目のリリースごとに長期的なサポートを提供します。最近、 OpenStack Train をベースとした OSP リリース 16.0 ではリリース番号に対応しないことが選択されましたが、新しい機能はサブリリースにバックポートされています。最新のリリースは Red Hat OpenStack Platform 16.1 です。これには、アップストリームの Usuri および Victoria リリースからバックポートされた高度な機能が含まれています。</block>
  <block id="ffd7a6889e6ea6965969472250235082" category="paragraph">OpenStack Platform サービスはコンテナとして導入されます。コンテナはサービスを分離するため、アップグレードも簡単です。OpenStack Platform は、 Kolla によって構築、管理された一連のコンテナを使用します。サービスの導入は、 Red Hat Custom Portal からコンテナイメージを取得することによって行われます。これらのサービスコンテナは、 Podman コマンドを使用して管理され、 Red Hat OpenStack Director で導入、設定、および管理されます。</block>
  <block id="7adea0d9c77aabccd8bb67ae0a832d59" category="cell">プロジェクト名</block>
  <block id="e7a39f4cb0dd0ffaaffe8fb0319dec67" category="cell">OpenStack ネットワーク</block>
  <block id="4f0550f066ae72bb8c24fc3f59c323bf" category="cell">ブロックストレージ</block>
  <block id="670aaecb1a526fbed439dad3ec353a96" category="cell">オブジェクトストレージ</block>
  <block id="b81a67bf2ab52e16a62a9c71454c90ee" category="paragraph">Red Hat OpenStack Director では、皮肉なベアメタルプロビジョニングサービスを使用して Red Hat OpenStack Platform を導入するために、 IPMI 機能が必要です。</block>
  <block id="567f5ee3e60ecdd5338b39cab0006510" category="cell">ストレージインフラ</block>
  <block id="ea414c629935302b115bf3dabf5f827c" category="cell">Neutron は、 VXLAN を介したトンネリングによって、各テナントに独自のネットワークを提供します。ネットワークトラフィックは、各テナントネットワーク内で分離されます。各テナントネットワークには IP サブネットが関連付けられており、ネットワークネームスペースとは、複数のテナントネットワークで同じアドレス範囲を使用しても競合が発生することを意味します</block>
  <block id="f2feccaa3f5d086f0b16010ff463e369" category="cell">OpenStack Dashboard （ Horizon ）をグラフィカルに管理するためにホストする、公開されているネットワーク。 OpenStack サービスを管理するためのパブリック API 呼び出しが可能です。</block>
  <block id="493fd05bc58266bcd8394072cbe81748" category="paragraph">このドキュメントで説明する検証済みのアーキテクチャでは、 3 つの OSP コントローラノードと 2 つの OSP コンピューティングノードを導入して、 HA 運用に適した最小限のハードウェアを導入します。このアーキテクチャにより、耐障害性を備えた構成が実現し、両方のコンピューティングノードで仮想インスタンスを起動し、導入した VM を 2 つのハイパーバイザー間で移行できます。</block>
  <block id="ebe803a768c48af52bca59e6ab7df9bf" category="paragraph">Red Hat OpenShift 原因では最初に 3 つのマスターノードを導入するため、 2 ノード構成では少なくとも 2 つのマスターが同じノードを占有する可能性があり、その特定のノードが使用できなくなった場合には OpenShift が停止する可能性があります。そのため、 Red Hat では、少なくとも 3 つの OSP コンピューティングノードを導入して、 OpenShift マスターを均等に分散させ、解決策にフォールトトレランスを強化することをベストプラクティスとして推奨します。</block>
  <block id="bbfdc160550acbcdb4791a961a165d5d" category="paragraph">仮想マシンとホストのアフィニティを有効にすると、複数のハイパーバイザーノードに OpenShift マスターを分散できます。</block>
  <block id="cb346122cae28dfb1fcf0811f46296a2" category="paragraph">アフィニティとは、 VM やホストのセットに対してルールを定義する方法で、グループ内の同じホストで複数の VM が実行されるか、別々のホストで実行されるかを決定します。VM とホストで構成されるアフィニティグループを作成することで、 VM に適用されます。このアフィニティグループには同じパラメータと条件が設定されます。アフィニティグループ内の VM がグループ内の同じホストで実行されているのか、または別々のホストで実行されているのかに応じて、アフィニティグループのパラメータでは正のアフィニティまたは負のアフィニティを定義できます。Red Hat OpenStack Platform では、サーバグループを作成し、 Nova で導入されたインスタンスが異なるコンピューティングノードに導入されるようにフィルタを設定することで、ホストアフィニティルールと非アフィニティルールを作成して適用することができます。</block>
  <block id="de5bd213c3df23736df75636241f96de" category="admonition">OSP サーバグループには、特定のハードアフィニティや非アフィニティの制限があります。ノードを共有するために十分なリソースが別々のノードに導入できない場合や、リソースが不足している場合は、 VM をブートできません。</block>
  <block id="42bb5e38e5b1c611bdce679410b24d67" category="paragraph">このような場合は、クラスタをすぐに導入せずにウィザードを実行してタスクを実行できます。代わりに、あとでクラスタを導入できる構成ファイルを作成します。これは、 IPI のデフォルト値を変更する必要がある場合や、マルチテナンシーなどの他の用途のために環境内に同一のクラスタを複数導入する必要がある場合に非常に便利です。OpenShift 用にカスタマイズされたインストール構成の作成の詳細については、を参照してください<block ref="05810b34cd92ddfe8fd049160cb24f72" category="inline-link-rx"></block>。</block>
  <block id="dc5fa659e0452a77d6006f5b72f8b334" category="paragraph">Trident を NetApp Element ストレージシステムと統合するには、 iSCSI プロトコルを使用してストレージシステムと通信できるバックエンドを作成する必要があります。</block>
  <block id="05ca7295321cb9b417a251e75557c6c5" category="list-text">ダウンロードしたインストールアーカイブのサンプルバックエンドファイルは、「 sample -input 」フォルダ階層にあります。iSCSI を提供している NetApp Element システムの場合、「 backend-solidfire.json 」ファイルを作業ディレクトリにコピーし、ファイルを編集します。</block>
  <block id="b73d05719d0ea2964c963f6f83a34d3d" category="admonition">このファイルに定義されているオプションのフィールド「 fsType 」があります。iSCSI バックエンドでは、この値を特定の Linux ファイルシステムタイプ（ XFS 、 ext4 など）に設定するか、 OpenShift で使用するファイルシステムを決定できるようにするためにこの値を削除できます。</block>
  <block id="90dc29cb8c225faef816aefeaad3027d" category="inline-link-macro">次：解決策の検証 / ユースケース</block>
  <block id="99632a9c8a0d8380e77d9d11f96edfdc" category="paragraph"><block ref="99632a9c8a0d8380e77d9d11f96edfdc" category="inline-link-macro-rx"></block></block>
  <block id="920db239cf01c8ded4b7f364194ab540" category="list-text">サイドバーから Manage Applications に移動し、 Create Application をクリックします。作成するアプリケーションの詳細を入力し、 [ 保存 ] をクリックします。</block>
  <block id="f4fc33973424c12639f93790b1c6f370" category="paragraph">ネットアップは、堅牢なオールフラッシュ（ AFF ）およびスケールアウトハイブリッド（ FAS ）ストレージプラットフォームを提供し、低レイテンシのパフォーマンス、統合データプロテクション、マルチプロトコルのサポートのそれぞれに合わせてカスタマイズします。</block>
  <block id="c48db988cd283c11f89d4dd85803ec0a" category="doc">ネットアップを使用した Red Hat OpenShift でのマルチテナンシーの構成</block>
  <block id="6d72da55d82cdd434045ba5df1a959b6" category="paragraph">コンテナで複数のアプリケーションやワークロードを実行する多くの組織は、アプリケーションやワークロードごとに 1 つの Red Hat OpenShift クラスタを導入する傾向にあります。これにより、アプリケーションやワークロードを厳密に分離し、パフォーマンスを最適化し、セキュリティの脆弱性を軽減できます。ただし、アプリケーションごとに独立した Red Hat OpenShift クラスタを導入するには、独自の問題が発生します。これにより、各クラスタを個別に監視および管理する必要がある運用上のオーバーヘッドが増大し、さまざまなアプリケーションに専用リソースを使用することでコストが増大し、効率的な拡張性が妨げられます。</block>
  <block id="332dcd535fa9ce865f462efb80829a35" category="paragraph">この問題を解決するには、すべてのアプリケーションまたはワークロードを 1 つの Red Hat OpenShift クラスタで実行することを検討します。しかし、このようなアーキテクチャでは、リソースの分離とアプリケーションセキュリティの脆弱性が大きな課題の 1 つとなっています。あるワークロードのセキュリティの脆弱性は、自然に別のワークロードにオーバーフローする可能性があるため、影響ゾーンが増加します。また、あるアプリケーションによる突然の制御されないリソース使用率は、デフォルトではリソース割り当てポリシーがないため、別のアプリケーションのパフォーマンスに影響を与える可能性があります。</block>
  <block id="73c1b26ace2fc5fca6e6e78c00a61837" category="paragraph">このように効果的な解決策の 1 つは、 Red Hat OpenShift でマルチテナンシーを構成することです。マルチテナンシーは、複数のテナントを同じクラスタ上に共存させ、リソースやセキュリティなどを適切に分離できるアーキテクチャです。この場合、テナントは、特定のユーザグループが専用として使用するように設定されたクラスタリソースのサブセットとみなすことができます。Red Hat OpenShift クラスタでマルチテナンシーを設定する利点は次のとおりです。</block>
  <block id="f3ff3f5b3c67fb47bb8ec0f2f688b97d" category="paragraph">マルチテナント OpenShift クラスタを完全に実現するには、コンピューティング、ストレージ、ネットワーク、セキュリティなど、異なるリソースバケットに属するクラスタリソースにクォータと制限を設定する必要があります。この解決策のすべてのリソースバケットの特定の側面について説明しますが、 ネットアップでは、 NetApp ONTAP を基盤とする Astra Trident によって動的に割り当てられるストレージリソースにマルチテナンシーを設定することで、複数のワークロードで提供または消費されるデータを分離し、保護するためのベストプラクティスに焦点を当てています。</block>
  <block id="1cf7b9db4d7fe091bd1bbb685e5beea8" category="paragraph">Kubernetes 向けの Red Hat Advanced Cluster Management では、次のタスクを実行できます。</block>
  <block id="808c579683377aa7bd89b8e4d76ba220" category="list-text">複数のデータセンターとパブリッククラウドにわたって、複数のクラスタを作成、インポート、管理できます。</block>
  <block id="7fe0555145a586e3fb769f86902ccc72" category="list-text">1 つのコンソールから複数のクラスタにアプリケーションやワークロードを導入して管理</block>
  <block id="416434625b0f2158d99a4af37f233805" category="list-text">さまざまなクラスタリソースの健常性とステータスを監視および分析できます</block>
  <block id="fed6fdd49a1e6adda0ea12a93e74ea2d" category="list-text">複数のクラスタにわたってセキュリティコンプライアンスを監視し、実施できます。</block>
  <block id="1630dbfdd4887ce201ea82c71cde3d11" category="doc">Kubernetes 向けの高度なクラスタ管理機能を導入</block>
  <block id="bc2ab7a7550cebeb52a08cf830b5ecf6" category="list-text">Operators &gt; Operators Hub に移動し、 Kubernetes の Advanced Cluster Management を検索します。</block>
  <block id="c4ab802b80978ba1c5de3922d546bdb7" category="list-text">Kubernetes の高度なクラスタ管理を選択し、インストールをクリックします。</block>
  <block id="c972585d6241c4f2ed2604bcc8706358" category="list-text">Install Operator 画面で、必要な詳細情報を入力し（デフォルトのパラメータをそのまま使用することを推奨）、 Install をクリックします。</block>
  <block id="7bf3d0678c48be5730f20005e6f88aa1" category="list-text">オペレータがインストールされたら、 Create MultiClusterHub （ MultiClusterHub の作成）をクリックします。</block>
  <block id="95f29f27e373a9759cf065e1fde23e28" category="list-text">Create MultiClusterHub （マルチクラスタハブの作成）画面で、詳細を提供した後に Create （作成）をクリックします。これにより、マルチクラスタハブのインストールが開始されます。</block>
  <block id="a50aa5e8249109d6f4902945e968ad7d" category="list-text">すべてのポッドがオープンクラスタ管理ネームスペースの running 状態に移行し、オペレータが Succeeded 状態に移行すると、 Kubernetes の Advanced Cluster Management がインストールされます。</block>
  <block id="391dd52c88201d377f1572062e22c43e" category="list-text">ハブのインストールが完了するまでにはしばらく時間がかかり、完了すると、マルチクラスタハブは running 状態に移行します。</block>
  <block id="eef36825efd5d2d40e4f833635cd19da" category="list-text">オープンクラスタ管理ネームスペースにルートが作成されます。ルートの URL に接続して、 Advanced Cluster Management コンソールにアクセスします。</block>
  <block id="f122078c68f20c36897fec8a7c4a23e8" category="doc">OpenShift の概要</block>
  <block id="8c2b388bd42b0b6bae19890633c98a8d" category="list-text">* セキュリティとコンテナカタログ。 * OpenShift はマルチテナンシーを提供し、 Security-Enhanced Linux （ SELinux ）、 cgroups 、 Secure Computing Mode （ seccomp ）との確立されたセキュリティを使用してコンテナを分離し、保護することにより、ユーザを有害なコードの実行から保護します。また、さまざまなサブシステム用の TLS 証明書による暗号化、およびエンドユーザーに認証済みの信頼できるセキュアなアプリケーションコンテナを提供するためにセキュリティを重視してスキャンおよび採点される Red Hat 認定コンテナ（ access.redhat.com/containers ）へのアクセスも提供します。</block>
  <block id="9c2dd02f13d452b4422ac6c864933f01" category="paragraph">Red Hat OpenShift 4 以降、 OpenShift の導入方法には、高度にカスタマイズされた導入に User Provisioned Infrastructure （ UPI ；ユーザプロビジョニングインフラ）を使用する手動導入、または Installer Provisioned Infrastructure （ IPI ）を使用した完全に自動化された導入が含まれます。</block>
  <block id="66f8ff89bd2c9146cb3273d416c60fd2" category="list-text">Red Hat OpenShift を導入する環境を選択します。</block>
  <block id="f5806bcee67fc8f13f0255068a186e42" category="list-text">次の画面で、インストーラ、独自のプルシークレット、および管理用の CLI ツールをダウンロードします。</block>
  <block id="d711fd24836980dd490f3c01dd3ee8de" category="paragraph">ネットアップでは、以下の各データセンター環境で Installer Provisioned Infrastructure （ IPI ）導入方法を使用して、 Red Hat OpenShift のラボへの導入をテストし、検証しています。</block>
  <block id="77caa49b32b4fc8ce3276158f57f9229" category="doc">ネットアップストレージの概要</block>
  <block id="50bc4bb14f0d89a22c593112574d0fb3" category="list-text">AFF システムと FAS システムは、 NetApp ONTAP を実行し、ファイルベース（ NFS ）とブロックベース（ iSCSI ）の両方のユースケースにストレージを提供します。</block>
  <block id="bf3bfadca5040d5a50a8703c7dbb7ef1" category="list-text">Cloud Volumes ONTAP と ONTAP Select は、それぞれクラウドと仮想スペースに同じメリットをもたらします。</block>
  <block id="cb050b8fb8c2102a0ab337119eb19f0f" category="admonition">ネットアップのポートフォリオに含まれる各ストレージシステムでは、オンプレミスサイトとクラウド間でのデータ管理と移動の両方を容易に行えるため、データがアプリケーションの配置場所にあることを保証できます。</block>
  <block id="b432301f7ba469598e6ea2eb86e4859a" category="paragraph">一般的には、最も簡単に導入できる解決策が最適ですが、場合によっては、特定のアプリケーションまたは解決策の導入先環境の要件または仕様を満たすために、高度なカスタマイズが必要になります。そのため、 NetApp 解決策を使用した Red Hat OpenShift では、これらのニーズに合わせて次のカスタマイズを行うことができます。</block>
  <block id="d31d340fd6b135cac2cfac7b04a34c10" category="list-text">左上隅で、ロールを Administrator から Developer に変更します。+ 追加をクリックし、カタログからを選択します。キーワードでフィルターバーで Jenkins を検索します。永続的ストレージを使用する Jenkins Service を選択します。</block>
  <block id="fb86f2dea9912af1bb1677c9cf33e619" category="list-text">Jenkins ポッドが「 Ready 」状態になるまでに約 10 ～ 12 分かかります。</block>
  <block id="d59d1324dea050a2c0ffc376de411aa0" category="list-text">Jenkins アプリケーションの作成時に OpenShift OAuth が使用されていたため、「 OpenShift でログイン」をクリックします。</block>
  <block id="70a742210f3e3599821b3a11b682144c" category="list-text">Jenkins サービスアカウントに OpenShift ユーザへのアクセスを許可します。</block>
  <block id="b07934b6023389a7e3e183b45e3b7448" category="list-text">Jenkins のようこそページが表示されます。Maven ビルドを使用しているので、まず Maven のインストールを完了します。Manage Jenkins &gt; Global Tool Configuration に移動し、 Maven サブヘッドで Add Maven をクリックします。任意の名前を入力し、 [ 自動的にインストール ] オプションが選択されていることを確認します。[ 保存 ] をクリックします .</block>
  <block id="8fd32305bf380bf893ef2407eae75f5d" category="list-text">CI / CD のワークフローを示すパイプラインを作成できるようになりました。ホームページで、左側のメニューから [ 新規ジョブの作成 ] または [ 新規アイテム ] をクリックします。</block>
  <block id="cd55d787cacfb25983e0a24b58ba6d48" category="list-text">パイプライン (Pipeline) タブを選択しますサンプルパイプラインを試すドロップダウンメニューから、 Github + Maven を選択します。コードが自動的に入力されます。[ 保存 ] をクリックします .</block>
  <block id="eaeef52618dbbd29ca52633c93abcbb4" category="list-text">目的の OS を選択し、 Next （次へ）をクリックします。</block>
  <block id="6befc3ce0d5cbd575434f0d5e1ec1125" category="list-text">選択したオペレーティングシステムにブートソースが設定されていない場合は、設定する必要があります。Boot Source （起動ソース）で、 URL またはレジストリから OS イメージをインポートするかどうかを選択し、対応する詳細を指定します。Advanced を展開し、 Trident から作成されたストレージクラスを選択します。[ 次へ ] をクリックします。</block>
  <block id="3d210170d7f07fe3c907e8ac619f003a" category="doc">NetApp Astra Control Center の概要</block>
  <block id="9b0d9ae1197ded2c7d52147e5056475d" category="paragraph">NetApp Astra Control Center は、オンプレミス環境に導入され、ネットアップのデータ保護テクノロジを基盤とするステートフル Kubernetes ワークロード向けの充実したストレージサービスとアプリケーション対応データ管理サービスを提供します。</block>
  <block id="f0358bd53d50b55aa0509189dd381ca9" category="paragraph">NetApp Astra Control Center は、 Astra Trident ストレージオーケストレーションツールを導入し、 NetApp ONTAP ストレージシステムにストレージクラスとストレージバックエンドを使用して構成した Red Hat OpenShift クラスタにインストールできます。</block>
  <block id="8cc4d72a7129322eb1f39ea9b9cfb2f6" category="inline-link-macro">このドキュメントはこちら</block>
  <block id="1c2ddd920580e1a7860afb96d7ac352e" category="paragraph">Astra Trident のインストールと設定を行い、 Astra Control Center をサポートするには、を参照してください <block ref="a581b27b235a239b8b186164c4dbebd1" category="inline-link-macro-rx"></block>。</block>
  <block id="876ae62d75901b9ef80277fd884aa5e9" category="paragraph">クラウド接続環境では、 Cloud Insights を使用して高度なモニタリングとテレメトリを提供します。Cloud Insights 接続がない場合は、限定的な監視と計測（ 7 日間相当の指標）を使用でき、オープン指標エンドポイントを介して Kubernetes の標準の監視ツール（ Prometheus および Grafana ）にエクスポートされます。</block>
  <block id="54a5ba4de846d3c3ba8c0322f5139893" category="paragraph">Astra Control Center は、ネットアップの AutoSupport と Active IQ のエコシステムに完全に統合されており、ユーザをサポートし、トラブルシューティングを支援し、使用状況の統計を表示します。</block>
  <block id="34610c3089a79a0b0e58bcc24da4c16c" category="paragraph">Astra Control Center の有料版に加え、 90 日間の評価ライセンスも提供されています。評価版は、 E メールとコミュニティ（ Slack チャンネル）を通じてサポートされています。お客様は、これらの記事やその他のナレッジベース記事、および製品サポートダッシュボードから入手可能なドキュメントにアクセスできます。</block>
  <block id="b3d5fa878980b3f5b771ced3fa94111a" category="inline-link-macro">Astra の Web サイト</block>
  <block id="83d307afe7b187cee5d096f65402182f" category="paragraph">ネットアップアストラコントロールセンターの利用を開始するには、にアクセスしてください <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>。</block>
  <block id="7f9648de128837be473a3b24e53ff823" category="section-title">Astra Control Center のインストールの前提条件</block>
  <block id="8ffc0d45ec909884b280603fd2556021" category="list-text">1 つ以上の Red Hat OpenShift クラスタ。バージョン 4.6 EUS および 4.7 が現在サポートされています。</block>
  <block id="526a5a0f546838d61791ded926113f71" category="list-text">各 Red Hat OpenShift クラスタに Astra Trident をインストールして設定しておく必要があります。</block>
  <block id="7433dd0f15704f71764248a0ca105fad" category="admonition">サイトに各 OpenShift インストールを実装し、永続的ストレージ専用の SVM を用意することがベストプラクティスです。マルチサイト環境では、追加のストレージシステムが必要です。</block>
  <block id="e32d2cb3312c2c7797ca52bd8d6ff26f" category="admonition">リンクを参照してください <block ref="0065297854ca0573913043e80b99a2d1" category="inline-link-macro-rx"></block> この目的で検証済みのロードバランサに関する情報。</block>
  <block id="aa32c16385a1b749687956188e4f0d9a" category="admonition">リンクを参照してください <block ref="9d2000c3bba4885fe5f36ed192264583" category="inline-link-macro-rx"></block> この目的のために OpenShift プライベートレジストリをインストールして構成します。</block>
  <block id="121c2592ea226f655d357a8ecd8caf2e" category="inline-link">Astra 登録サイト</block>
  <block id="ba6df9237a2774d7ca28cdf134cf9314" category="admonition">Astra Control の試用版ライセンスの使用を開始するには、にアクセスしてください<block ref="dd61f8f3fbfa8ca8b0a268b985d55b0e" category="inline-link-rx"></block>。</block>
  <block id="29fc4f6574f437e623e4eb9d47136931" category="list-text">インストールを開始する前に、 Astra Control Center イメージをイメージレジストリにプッシュします。</block>
  <block id="25b4e951c048e2ae39554f36af8824b9" category="admonition">この手順では、 Docker または Podman のいずれかを使用して実行します。両方の手順については、この手順で説明します。</block>
  <block id="a53846d7be2355a59af69a47e2cf4637" category="list-text">シェルスクリプトファイルを作成し、次の内容を貼り付けます。</block>
  <block id="ad3318a786149147666e961c291c6875" category="admonition">レジストリに信頼されていない証明書を使用している場合は、シェルスクリプトを編集し、 podman push コマンドに「 --tls-verify=false 」を使用します。「 podman push $registry/ $ 」（ echo $astraalImage | sed's /^[^\\/]\\/'/')--tls-verify=false 」）。</block>
  <block id="f39d61476380fc033f45c2d744596b00" category="list-text">次に、イメージレジストリ TLS 証明書を OpenShift ノードにアップロードします。そのためには、 TLS 証明書を使用して OpenShift -config ネームスペースに ConfigMap を作成し、クラスタイメージ構成にパッチを適用して証明書を信頼できるようにします。</block>
  <block id="508ca0ca5ae419c052d9a8487bb0b2d0" category="admonition">ルートとともに入力オペレータからのデフォルト TLS 証明書を含む OpenShift 内部レジストリを使用している場合は、前の手順に従って、ルートホスト名に証明書をパッチする必要があります。入力オペレータから証明書を抽出するには、コマンド「 oc extract secret/router-ca --keys=tls.crt-n OpenShift ingress-operator 」を使用します。</block>
  <block id="6d71c41a686bcfc0b0866044afd43f2b" category="list-text">その名前空間のイメージレジストリにアクセスするためのシークレットを作成します。</block>
  <block id="25eb68598d15a49d385089020950412c" category="list-text">Astra Control Center CRD ファイル 'Astra_control_center_min.yaml を編集し 'FQDN' イメージレジストリの詳細 ' 管理者の電子メールアドレスなどの詳細を入力します</block>
  <block id="42b9bde28896d6478a324770641ac301" category="admonition">前のファイル「 Astra_control_center_min YAML 」は、 Astra Control Center CRD の最小バージョンです。PVC 作成時のデフォルト以外のストレージクラスを定義したり、メール通知用の SMTP の詳細を提供したりするなど、より詳細な制御を伴う CRD を作成する場合は、ファイル「 Astra_control_center.yaml 」を編集して必要な詳細を入力し、それを使用して CRD を作成します。</block>
  <block id="e3cd33ca69b8e508c973939783f528db" category="list-text">インストールが完了するまでに数分かかることがあります。NetApp-AstrA-cc' ネームスペース内のすべてのポッドとサービスが稼働していることを確認します</block>
  <block id="c27deb19babf146e6377dce25b1e70e7" category="list-text">Astra Control Center にログインするためのユーザ名は、 CRD ファイルに提供された管理者の電子メールアドレスで、パスワードは Astra Control Center UUID に付加された文字列「 ACC-` 」です。次のコマンドを実行します。</block>
  <block id="57a7aa2eaf00ddaa73ef6b49299ade6e" category="admonition">この例では、パスワードは「 ACC-345c55a5 -bf2e-21f0 -84b8 -b6f2bce5e95f 」です。</block>
  <block id="19bae630567610f1955167595b8daae3" category="list-text">CRD で提供された管理者メールアドレスを使用して初めて Astra Control Center GUI にログインする場合は、パスワードを変更する必要があります。</block>
  <block id="0c62383e1115b208212b5a634214ae37" category="list-text">ユーザーを Astra Control Center に追加する場合は、 [ アカウント ]&gt;[ ユーザー ] の順に選択し、 [ 追加 ] をクリックしてユーザーの詳細を入力し、 [ 追加 ] をクリックします。</block>
  <block id="60423d24e49c8db4836be0abd09fb78d" category="doc">NetApp ONTAP iSCSI 構成</block>
  <block id="cbaa3aa588b8aa5c85dca443c15a0195" category="doc">NetApp ONTAP の NFS 構成</block>
  <block id="f897eefba2c59919d6493db4825e2db2" category="admonition">カスタムの backendName 値は、簡単に識別できるように NFS を提供するストレージ DriverName とデータ LIF を組み合わせて定義することを推奨します。</block>
  <block id="a802e9436bb9bcbfa2b88bb549e28503" category="paragraph">ほとんどの場合、 Red Hat OpenShift は、ルートを介してアプリケーションを外部で利用できるようにします。サービスは、外部からアクセス可能なホスト名を付与することで公開されます。定義されたルートおよびサービスによって識別されるエンドポイントは、 OpenShift ルータによって使用され、外部クライアントにこの名前付き接続を提供できます。</block>
  <block id="abd6754aa5a185ca83b3f00c5da68534" category="inline-link-macro">次は、解決策の検証 / ユースケースです。</block>
  <block id="8bfe62be82a77570753936203ee020ca" category="paragraph"><block ref="8bfe62be82a77570753936203ee020ca" category="inline-link-macro-rx"></block></block>
  <block id="445b72f2cbecd97022bb6636eda3cbc7" category="cell">さまざまなアプリケーションやワークロード用のプロジェクトを作成できます</block>
  <block id="bfc5fb8ef5464441bc8b3ca7eda2892d" category="cell">割り当てられたプロジェクトで PVC またはポッドを作成またはパッチするためのアクセスを検証します</block>
  <block id="9e95c94350b2b7b51176ad958deb1388" category="cell">アクセスを検証して、別のプロジェクトで PVC またはポッドを作成またはパッチします</block>
  <block id="8c0b7954d326b4bcf2f42a57ef00eead" category="cell">アクセス権を検証して、プロジェクト、リソースクォータ、ストレージクラスを表示または編集します</block>
  <block id="c2c2a82496277a88b32b0e8d27249d3d" category="inline-link-macro">次のステップ：アプリケーションを保護しましょう。</block>
  <block id="d5be948b8a7fea6618eb171c64927be2" category="paragraph"><block ref="d5be948b8a7fea6618eb171c64927be2" category="inline-link-macro-rx"></block></block>
  <block id="bbb49986c10d9b599ce8b72ea09d5261" category="list-text">Operators &gt; OperatorHub に移動して、 OpenShift Virtualization を検索します。</block>
  <block id="2515fbef39d57544723402c683215c64" category="doc">ネットアップストレージ統合の概要</block>
  <block id="689ca76b61ed9331405d36eb5ded709d" category="paragraph">ネットアップは、 Red Hat OpenShift などのコンテナベースの環境における永続的データのオーケストレーションと管理に役立つさまざまな製品を提供します。</block>
  <block id="bc2397695676d1a63e489d4c80c8cd91" category="paragraph">Kubernetes 向けの高度なクラスタ管理機能を使用すると、ユーザはコンソールから 1 つ以上の管理対象クラスタ上にリソースを同時に作成できます。たとえば、異なる NetApp ONTAP クラスタでサポートされている異なるサイトに OpenShift クラスタがあり、両方のサイトで PVC をプロビジョニングする場合は、上部バーの（ + ）記号をクリックします。次に、 PVC を作成するクラスタを選択し、リソース YAML を貼り付けて、 Create をクリックします。</block>
  <block id="2fb91f8695d5dc9db4bf5a7ef710ec73" category="list-text">Astra Control Center で、対象となるストレージクラスが検出される。次に、ストレージクラスが NetApp ONTAP 上の SVM がサポートする Trident を使用してボリュームをプロビジョニングする方法を選択し、 Review （確認）をクリックします。次のペインで詳細を確認し、 Add Cluster をクリックします。</block>
  <block id="3edb3c83eb1bede6778cc1960a651973" category="list-text">手順 1 の説明に従って、両方の OpenShift クラスタを登録します。追加すると、 Astra Control Center がクラスタを検査して必要なエージェントをインストールしながら、クラスタは Discovering ステータスに移行します。クラスタが登録されると、クラスタのステータスが「 Running 」に変わります。</block>
  <block id="ed5c1a60b8165b8bc691cbdf1b0d122c" category="admonition">Astra Control Center で管理するすべての Red Hat OpenShift クラスタは、管理対象クラスタにインストールされたエージェントとしてインストールに使用されたイメージレジストリにアクセスできる必要があります。このレジストリからイメージがプルされます。</block>
  <block id="feab1371530d1ef069d928e811bcb08b" category="list-text">ONTAP クラスタをインポートするには、バックエンドに移動し、ドロップダウンをクリックして、管理対象の ONTAP クラスタの横にある Manage を選択します。ONTAP クラスタの資格情報を入力し、 [ 情報の確認 ] をクリックして、 [ ストレージバックエンドのインポート ] をクリックします。</block>
  <block id="d5a9f831c51dc05a9b40eae2850329fc" category="inline-link-macro">次に、保護するアプリケーションを選択します。</block>
  <block id="74dd157086250792afa856d5a6c32777" category="paragraph"><block ref="74dd157086250792afa856d5a6c32777" category="inline-link-macro-rx"></block></block>
  <block id="a62e902f0d244d960eddf2f14d3afa6f" category="paragraph">ベアメタル上の OpenShift では、コモディティサーバ上に OpenShift Container Platform を自動で導入できます。</block>
  <block id="0e05c6235b67ae8e5b743c9ca77358fa" category="paragraph">ベアメタル上の OpenShift は、コンテナ化の準備ができていないアプリケーションの仮想ワークロードをサポートしながら、 OpenShift クラスタの導入、迅速なプロビジョニング、拡張を容易にする OpenShift の仮想導入に似ています。ベアメタルに導入することで、 OpenShift 環境に加えてホストハイパーバイザー環境の管理に必要な追加のオーバーヘッドを必要としません。ベアメタルサーバに直接導入することで、ホストと OpenShift 環境間でリソースを共有する必要がある物理的なオーバーヘッドの制限を軽減できます。</block>
  <block id="9a3c3034787ddbd4af974d73f795c75a" category="list-text">* IPI またはサポートされたインストーラーの展開。 * ベアメタルサーバー上でインストーラー・プロビジョニング・インフラストラクチャー（ IPI ）によって展開される OpenShift クラスターにより、ハイパーバイザー層を管理することなく、汎用性が高く、容易に拡張できる OpenShift 環境を汎用サーバーに直接展開できます。</block>
  <block id="bf995f5252e568d22b265ec62c16914c" category="list-text">* 小型クラスタ設計。 * ハードウェア要件を最小限に抑えるため、ベアメタル上の OpenShift では、 OpenShift コントロールプレーンノードをワーカーノードやホストコンテナとしても機能させることにより、わずか 3 ノードのクラスタを導入できます。</block>
  <block id="13442dfd439ae0a377b0a2d2d9df1709" category="list-text">* OpenShift 仮想化。 * OpenShift では、 OpenShift Virtualization を使用してコンテナ内で仮想マシンを実行できます。このコンテナネイティブの仮想化では、コンテナ内で KVM ハイパーバイザーを実行し、 VM ストレージ用の永続ボリュームを接続します。</block>
  <block id="6e6a5272d3c6f8eceb96e3c19f0faaf6" category="list-text">* AI / ML に最適化されたインフラ。 * GPU ベースのワーカーノードを OpenShift 環境に組み込み、 OpenShift Advanced Scheduling を活用して、マシンラーニングアプリケーション向けの Kubeflow のようなアプリケーションを導入します。</block>
  <block id="6bc136fcf409560a1029f6f323619bbf" category="paragraph">NetApp 解決策上の Red Hat OpenShift では、 2 つのデータスイッチを使用して 25Gbps でプライマリデータ接続を提供します。また、ストレージノードのインバンド管理用に 1Gbps で接続を提供する管理スイッチを 2 台使用し、 IPMI 機能のアウトオブバンド管理も使用します。</block>
  <block id="17fea9675576fc9c72deb9501a5fd16a" category="paragraph">OpenShift ベアメタル IPI 環境では、プロビジョニングノード、つまりネットワークインターフェイスが別々のネットワークに接続されている Red Hat Enterprise Linux 8 マシンを作成する必要があります。</block>
  <block id="2f42f99315e0171a6e5c61957ae4689c" category="list-text">* ネットワークのプロビジョニング。 * このネットワークは、ベアメタルノードをブートし、 OpenShift クラスタを導入するために必要なイメージとパッケージをインストールするために使用されます。</block>
  <block id="aba727a2dc3dd836a33a2022bb2a9c3f" category="list-text">* ベアメタルネットワーク。 * このネットワークは、導入後のクラスタのパブリック側通信に使用されます。</block>
  <block id="7633522f66aaba6bc4bb2c25d299d287" category="paragraph">プロビジョニングノードをセットアップするために、お客様は、トラフィックをノード自体と、導入用にプロビジョニングされたブートストラップ VM に適切にルーティングできるようにするブリッジインターフェイスを作成します。クラスタが導入されると、 API および入力 VIP アドレスがブートストラップノードから新しく導入されたクラスタに移行されます。</block>
  <block id="963d7d04e1f1692a7fc49ae899123dbd" category="paragraph">次の図は、 IPI の導入時と導入の完了後の環境を示しています。</block>
  <block id="f53272342c85041784b2d5136e6eaa7d" category="cell">ベアメタルネットワーク</block>
  <block id="11405696f0e53417a3847f430a7b8ed0" category="cell">プロビジョニングネットワーク</block>
  <block id="eb5f501445f81cb1f7f4cf290565f9c8" category="admonition">これらの各ネットワークは仮想的に VLAN で分離されますが、 PXE ブートシーケンス中に VLAN タグを渡す方法がないため、各物理ポートをプライマリ VLAN が割り当てられたアクセスモードで設定する必要があります。</block>
  <block id="3ab0ae61b5256f874297403903fd5afc" category="paragraph">OpenShift Container Platform を導入する前に、次のインフラを用意する必要があります。</block>
  <block id="06a9d12a76441fd395abeba7bf0d7b91" category="list-text">インバンド管理ネットワークと VM ネットワークからアクセス可能な完全なホスト名解決を提供する DNS サーバが少なくとも 1 台必要です。</block>
  <block id="b611590ed189a9cbc27648402168f00a" category="inline-link-macro">次：ネットアップストレージの概要</block>
  <block id="2be0276ec05c9b03a47573ad9795095a" category="paragraph"><block ref="2be0276ec05c9b03a47573ad9795095a" category="inline-link-macro-rx"></block></block>
  <block id="932e95da8a59703292a426466e703c7a" category="paragraph">Red Hat Virtualization （ RHV ）は、 Red Hat Enterprise Linux （ RHEL ）で実行され、 KVM ハイパーバイザーを使用するエンタープライズ仮想データセンタープラットフォームです。</block>
  <block id="c29d3f9be705e3dcf947c6d2464cb090" category="list-text">* 自己ホスト型エンジン。 * ハードウェア要件を最小限に抑えるため、 RHV マネージャ（ RHV-M ）を、ゲスト VM を実行するホスト上の VM として導入することができます。</block>
  <block id="e2545c34b3a35dbcd93423b539eae91a" category="list-text">* 高可用性。 * ホスト障害時のシステム停止を回避するため、 RHV を使用することで、 VM を高可用性に設定することができます。高可用性 VM は、耐障害性ポリシーを使用してクラスタレベルで制御されます。</block>
  <block id="8f91b3a5c6d176cad584bb5f06c53684" category="list-text">* 高い拡張性。 * 1 つの RHV クラスタで最大 200 台のハイパーバイザホストを持つことができ、 IT 部門は大量の VM で、大量のリソースを消費するエンタープライズクラスのワークロードをホストするための要件をサポートできます。</block>
  <block id="a175fea9b8830c0cdbe1b268cb114738" category="list-text">* セキュリティ強化。 *RHV 、セキュア仮想化（ sVirt ）、およびセキュリティ強化 Linux （ SELinux ）テクノロジーから継承されたものは、セキュリティの強化とホストおよび VM の強化を目的として RHV によって採用されています。これらの機能の主なメリットは、 VM とそれに関連するリソースを論理的に分離できることです。</block>
  <block id="cd4c83df745cf56330120fb3ac308da2" category="paragraph">NetApp 解決策上の Red Hat OpenShift では、 2 つのデータスイッチを使用して 25Gbps でプライマリデータ接続を提供します。また、ストレージノードのインバンド管理用に 1Gbps で接続を提供する管理スイッチを 2 台追加し、 IPMI 機能用にアウトオブバンド管理を使用します。OCP は、クラスタ管理に RHV 上の仮想マシン論理ネットワークを使用します。このセクションでは、解決策で使用される各仮想ネットワークセグメントの配置と目的について説明し、解決策を導入するための前提条件について説明します。</block>
  <block id="c347686b0750301dfca053b321126bcc" category="cell">RHV-H ノード、 RHV-Manager 、および ovirtmgmt ネットワークの管理</block>
  <block id="4a3fe6077a529bcbe033bbb7d13027d6" category="paragraph">Red Hat OpenShift は最初に 3 つのマスターノードで導入するため、 2 ノード構成で少なくとも 2 つのマスターが同じノードを占有します。そのため、特定のノードが使用できなくなった場合に OpenShift が停止する可能性があります。そのため、解決策の一部として少なくとも 3 つの RHV - H ハイパーバイザーノードを導入して、 OpenShift マスターを均等に分散できるようにし、解決策にさらにフォールトトレランスを追加することが Red Hat のベストプラクティスです。</block>
  <block id="02d7502b2b132a675665088322fde9b0" category="paragraph">パラメータに定義された条件は、強制またはソフト強制のいずれかです。強制をハードに行うことで、アフィニティグループ内の VM は、外部条件に関係なく常に正または負のアフィニティに従って配置されます。ソフトな適用では、可能なかぎり、アフィニティグループ内の VM に対して肯定的または否定的なアフィニティに従って高い優先度が設定されます。このドキュメントで説明する 2 つまたは 3 つのハイパーバイザー構成では、ソフトアフィニティが推奨される設定です。大規模なクラスタでは、ハードアフィニティによって OpenShift ノードを適切に分散できます。</block>
  <block id="2b083bcbbb2d2208e64c13cb183af44f" category="paragraph">IPI を使用すると、このドキュメントで前述した対話型ウィザードを使用して、 OpenShift クラスタを簡単に導入できます。ただし、一部のデフォルト値については、クラスタの導入時に変更が必要になる場合があります。</block>
  <block id="a5867d73fa54e5b850ff2642c45ade52" category="paragraph">このような場合は、クラスタをすぐに導入せずにウィザードを実行してタスクを実行できます。クラスタの導入に使用する構成ファイルが作成されます。これは、 IPI のデフォルト値を変更する場合や、マルチテナンシーなどの他の用途のために環境内に同一のクラスタを複数導入する場合に非常に便利です。OpenShift 用にカスタマイズされたインストール構成の作成の詳細については、を参照してください<block ref="15427a9f842d7a49b872cf64115f33bc" category="inline-link-rx"></block>。</block>
  <block id="1d45b25ba986072287aaf72b6cf94130" category="paragraph">ネットアップ ONTAP を基盤とする Red Hat OpenShift と Astra Trident は、デフォルトでワークロードを分離する機能を提供していませんが、マルチテナンシーの設定に使用できる幅広い機能を備えています。ネットアップ ONTAP を基盤とする Astra Trident を使用した Red Hat OpenShift クラスタでのマルチテナント解決策の設計について理解を深めるために、一連の要件を含む例を検討し、その構成について概説します。</block>
  <block id="385df0e95c28430fb792ec836529f371" category="paragraph">2 つの異なるチームが取り組んでいる 2 つのプロジェクトの一環として、組織が Red Hat OpenShift クラスタ上で 2 つのワークロードを実行するとします。こうしたワークロードのデータは、 NetApp ONTAP NAS バックエンドの Astra Trident によって動的にプロビジョニングされる PVC 上に存在します。組織では、この 2 つのワークロードに対応するマルチテナント解決策を設計し、これらのプロジェクトに使用されるリソースを分離して、セキュリティとパフォーマンスを維持することが求められています。主に、これらのアプリケーションを提供するデータに重点が置かれています。</block>
  <block id="9c965c0beb472bc9265925ebbc55507e" category="paragraph">次の図は、ネットアップ ONTAP を基盤とする Astra Trident を使用した Red Hat OpenShift クラスタ上のマルチテナント解決策を示しています。</block>
  <block id="72710b926f57dad99b29203c63f4e3fd" category="paragraph">Red Hat OpenShift クラスタの観点からは、最初に最上位のリソースがプロジェクトです。OpenShift プロジェクトは、 OpenShift クラスタ全体を複数の仮想クラスタに分割するクラスタリソースと見なすことができます。したがって、プロジェクトレベルでの分離によって、マルチテナンシーの設定の基盤が提供されます。</block>
  <block id="20e1834bb9396599a6dcf7d743aa1b36" category="paragraph">次に、クラスタで RBAC を設定します。ベストプラクティスとして、すべての開発者が 1 つのプロジェクトまたはワークロードを担当し、アイデンティティプロバイダ（ IdP ）内の単一のユーザグループに設定することを推奨します。Red Hat OpenShift では、 IdP の統合とユーザグループの同期が可能なため、 IdP のユーザとグループをクラスタにインポートできるようになります。これにより、クラスタ管理者は、プロジェクト専用のクラスタリソースへのアクセスをそのプロジェクトに使用するユーザグループまたはグループに分離して、クラスタリソースへの不正アクセスを制限できます。Red Hat OpenShift への IdP の統合の詳細については、のドキュメントを参照してください<block ref="213cff8958909b80a9514e0c8321d8ef" category="inline-link-rx"></block>。</block>
  <block id="6d4e96186b1f4267def393ec42bf2d9e" category="paragraph">Red Hat OpenShift クラスタの永続的ストレージプロバイダとして機能している共有ストレージを分離し、各プロジェクト用にストレージ上に作成されたボリュームが、別々のストレージ上に作成されたものと同じようにホストに表示されるようにすることが重要です。そのためには、プロジェクトやワークロードに応じて Storage Virtual Machine （ SVM ）を NetApp ONTAP 上に作成し、各 SVM をワークロード専用にします。</block>
  <block id="76245f392269db8492c3610e325b1963" category="paragraph">ストレージクラスにネームスペースリソースが含まれていないため、あるプロジェクトのストレージクラスに対するストレージ要求を別のネームスペースまたはプロジェクトのポッドで拒否するにはどうすればよいですか？回答では、 ResourceQuotas を使用します。ResourceQuotas は、プロジェクトごとのリソースの合計使用量を制御するオブジェクトです。プロジェクト内のオブジェクトで消費できるリソースの合計量だけでなく、リソースの数も制限できます。ほとんどの場合、 ResourceQuotas を使用してプロジェクトのリソースを制限することができます。この機能を効率的に使用することで、リソースのオーバープロビジョニングや過剰消費によるコストやシステム停止を削減できます。のドキュメントを参照してください<block ref="9b2bb9683c8f6144876bed616f252527" category="inline-link-rx"></block> を参照してください。</block>
  <block id="5402bb91006fe391aea122e11c3607db" category="paragraph">このユースケースでは、特定のプロジェクトのポッドが、プロジェクト専用ではないストレージクラスのストレージを要求しないように制限する必要があります。これを行うには '&lt;storage-class-name&gt;.storageeclass.storage0.k8sio/persistentvolumeclaims'0 を設定して ' 他のストレージ・クラスに対する永続的ボリューム要求を制限する必要がありますさらに、クラスタ管理者は、プロジェクト内の開発者が ResourceQuotas を変更するためのアクセス権を持っていないことを確認する必要があります。</block>
  <block id="b1a934cbded2602c4186fb43d7c8a986" category="paragraph">それぞれのユースケースに応じて、コンテナと仮想マシン（ VM ）はどちらも、さまざまなタイプのアプリケーションに最適なプラットフォームとして機能します。そのため、多くの組織では、ワークロードの一部をコンテナで実行し、一部を VM で実行しています。そのため多くの場合、 VM 用のハイパーバイザーとアプリケーション用のコンテナオーケストレーションツールという別々のプラットフォームを管理する必要があり、組織はさらに多くの課題に直面します。</block>
  <block id="14bd8c5f1032dd20f94d4434365c6530" category="admonition">ここで説明するロール定義は単なる例です。エンドユーザの要件に基づいて開発者の役割を定義する必要があります。</block>
  <block id="cf17c458ea3abaad557d7cfc69886dbe" category="list-text">クラスタ内のすべてのプロジェクトの ResourceQuotas を管理する役割を作成して、ストレージ管理者に割り当てます。</block>
  <block id="db99ab183aa8f56c951cf20e25e7465c" category="list-text">クラスタが組織のアイデンティティプロバイダと統合され、ユーザグループがクラスタグループと同期されていることを確認します。次の例は、アイデンティティプロバイダがクラスタに統合され、ユーザグループと同期されていることを示しています。</block>
  <block id="38f22acd9ae9c74099644738d613baaa" category="admonition">ストレージ管理者の場合は、 Trident オペレータとリソースクォータの 2 つのロールにバインドする必要があります。</block>
  <block id="3434f6853d017037506e47f83a18c3eb" category="section-title">プライベートイメージレジストリを作成しています</block>
  <block id="9b1c6f527a1a481b925397807f319e71" category="list-text">「 PEC 」セクションに以下の保管パラメータを入力して、 imagegeistry のオペレータを編集します。</block>
  <block id="9ef71cd5ccaeb28206cd64b1d184019c" category="list-text">カスタムホスト名を使用して OpenShift ルートを作成するには、「 PEC 」セクションに次のパラメータを入力します。保存して終了します。</block>
  <block id="e0b23bc469102cf89472e5734da92a23" category="admonition">上記のルート設定は、ルートのカスタムホスト名が必要な場合に使用されます。OpenShift でデフォルトのホスト名を持つルートを作成するには、「 PEC 」セクションに「 defaultRoute ： true 」というパラメータを追加します。</block>
  <block id="625bd6ae5e3ac822b187b90d50edb553" category="sidebar-title">カスタム TLS 証明書</block>
  <block id="08e414328e39f86009287c06a5f23d23" category="paragraph">ルートにカスタムホスト名を使用している場合、デフォルトでは、 OpenShift 入力オペレータのデフォルトの TLS 設定が使用されます。ただし、カスタム TLS 設定をルートに追加することはできます。これには、次の手順を実行します。</block>
  <block id="60d14675c3111738a4ed19528764a7b1" category="list-text">ルートの TLS 証明書とキーを使用して秘密を作成します。</block>
  <block id="47f7f890b5c1bcb52ae163771dbf35b0" category="list-text">imageregistry 演算子を編集して 'PEC' セクションに次のパラメータを追加します</block>
  <block id="9199ff34349c38138ad0275e447e6588" category="list-text">このような場合は、すべての管理者をもう一度編集し、管理状態を「管理状態」に変更してください。保存して終了します。</block>
  <block id="2bc42a1a9a963d9a3ff2118466e5db07" category="list-text">すべての前提条件を満たしている場合は、プライベートイメージレジストリに PVC 、ポッド、およびサービスが作成されます。数分後にレジストリが起動します。</block>
  <block id="1f3713e339193dd15865ca74785eaa2c" category="list-text">入力オペレータ OpenShift レジストリルートにデフォルトの TLS 証明書を使用している場合は、次のコマンドを使用して TLS 証明書を取得できます。</block>
  <block id="295132dd97e1047a7c09e6a48054c469" category="list-text">OpenShift ノードがレジストリにアクセスしてイメージをプルできるようにするには、 OpenShift ノード上の Docker クライアントに証明書を追加します。TLS 証明書を使用して「 OpenShift -config 」ネームスペースに ConfigMap を作成し、証明書を信頼できるようにクラスタイメージ設定にパッチします。</block>
  <block id="98f3e484001465a59149c551e8d88cf0" category="list-text">OpenShift の内部レジストリは認証によって制御されます。OpenShift ユーザはすべて OpenShift レジストリにアクセスできますが、ログインユーザが実行できる操作はユーザ権限によって異なります。</block>
  <block id="561d4c8140016564eee98ecbc20f9add" category="list-text">ユーザーまたはユーザーのグループがレジストリから画像をプルできるようにするには、ユーザーにレジストリビューアの役割が割り当てられている必要があります。</block>
  <block id="88167e36ea0f872788407d0e01fc1382" category="list-text">ユーザーまたはユーザーグループにイメージの書き込みまたはプッシュを許可するには、ユーザーにレジストリエディタの役割が割り当てられている必要があります。</block>
  <block id="5ba9e8f3c64be4c82249856cac87a071" category="list-text">OpenShift ノードがレジストリにアクセスし、イメージをプッシュまたはプルするには、プルシークレットを設定する必要があります。</block>
  <block id="fe2033a9e377624583baa802ffd9ce6d" category="list-text">サービスアカウントにパッチを適用するには、次のコマンドを実行します。</block>
  <block id="59bd1dbdd3278e23e67bcabffbc4d55a" category="list-text">ポッド定義でプルシークレットを参照するには、「 PEC 」セクションに次のパラメータを追加します。</block>
  <block id="c0c3b4069e9a2e249507f67a6a2a3b07" category="list-text">OpenShift ノードとは別にワークステーションからイメージをプッシュまたはプルするには、次の手順を実行します。</block>
  <block id="312eaa3acf94b813cfe857f63a602724" category="list-text">OC ログインコマンドを使用して OpenShift にログインします。</block>
  <block id="cb4744e00672fbf6eba33b1b86d23ae0" category="list-text">podman/docker コマンドで OpenShift ユーザクレデンシャルを使用してレジストリにログインします。</block>
  <block id="aa20d170f1ff336ec9079cf6dd1ccee3" category="list-text">画像を押したり引いたりします。</block>
  <block id="85ca996063b5ec233e56a20ba93c5f44" category="list-text">Storage &gt; Storage VMs と進み、 Add をクリックします。必要な詳細を指定して、プロジェクト 1 用とプロジェクト 2 用に 1 つずつ、 2 つの SVM を作成します。また、 SVM とそのリソースを管理するには vsadmin アカウントを作成します。</block>
  <block id="b436e7799d01413277e05983e509574a" category="list-text">ストレージ管理者として Red Hat OpenShift クラスタにログインします。</block>
  <block id="f934b433773b966e5ebe0c7172decda4" category="admonition">この例では ONTAP と NAS のドライバを使用しています。ユースケースに基づいてバックエンドを作成する場合は、適切なドライバを使用します。</block>
  <block id="4e92dab2ab2bbe684f09a2aca58c9e44" category="list-text">NetApp ONTAP クラスタ：</block>
  <block id="f675b3d5e1e137870f481a742a3ec0af" category="list-text">Trident がクラスタにインストールされている。</block>
  <block id="1db1a9d97c708824712706fc4267ec25" category="list-text">tridentctl および OC ツールがインストールされ、 $PATH に追加された管理ワークステーション。</block>
  <block id="7cf4175762acfbabf9178d34f2504b28" category="list-text">ONTAP への管理アクセス。</block>
  <block id="10a540d0ed57154e8676c5725af53935" category="list-text">OpenShift クラスタへのクラスタ管理者アクセス。</block>
  <block id="6340f6ab1111f349228595ebceb8f6db" category="list-text">クラスタがアイデンティティプロバイダに統合されました。</block>
  <block id="9e110c19bb79322a0b76199795550dea" category="list-text">アイデンティティプロバイダは、異なるチームのユーザを効率的に区別するように設定されています。</block>
  <block id="39d08ecbb9add7bd87659df206457a73" category="list-text">ハブクラスタには Red Hat OpenShift クラスタ（バージョン 4.5 以降）が必要です</block>
  <block id="d60c66eb778a488709534045787b6a26" category="list-text">Red Hat OpenShift クラスタへのクラスタ管理者アクセス</block>
  <block id="3fc5f6755312b7edeef9542bd55ef639" category="section-title">ガバナンスとリスク</block>
  <block id="87f4e127e0ecf99187b35830ca7e78aa" category="list-text">サイドバーから「ガバナンスとリスク」に移動します。</block>
  <block id="0ecc505d3375f8bb3bd959aaaf7e710a" category="list-text">コンプライアンスポリシーを作成するには、 Create Policy （ポリシーの作成）をクリックし、ポリシー標準の詳細を入力して、このポリシーに準拠するクラスタを選択します。このポリシーの違反を自動的に修正するには、 [ サポートされている場合に適用 ] チェックボックスをオンにして、 [ 作成 ] をクリックします。</block>
  <block id="ea1abad541ee7994705555d53c0281c3" category="list-text">[Workloads （ワークロード） ] &gt; [Virtualization （仮想化） ] &gt; [Virtual Machines （仮想マシン） ] に移動し、クローンを作成する仮想マシンの横にある省略記号をクリックします。</block>
  <block id="81ab8abf2317781c0eb6f4deeaeea5a5" category="list-text">Storage &gt; PersistentVolume要求 と進み、ソース VM に接続されている PVC の横にある省略記号をクリックします。</block>
  <block id="5ba8ff3c009683ee423b0884c25360d0" category="list-text">[Workloads （ワークロード） ] &gt; [Virtualization （仮想化） ] &gt; [Virtual Machines （仮想マシン） ] に移動し、 [Create （作成）</block>
  <block id="cd32f6b0aebb29494cbc9cc21a10c926" category="list-text">spec&gt; template&gt; spec&gt; volumes セクションで、コンテナディスクではなく、クローン PVC を接続します。新しい VM について、要件に応じてその他の詳細をすべて指定します。</block>
  <block id="f79c612e785ac74789a25e8dda9e8731" category="doc">Astra Trident の概要</block>
  <block id="bd4a2d19c5168aa8c2b89b4affba2402" category="cell">9.8 、 9.9.1</block>
  <block id="4af39dbe40f8a0467bbdd739a971f0ea" category="admonition">次のメッセージは、 Astra Control Center のインストールが正常に完了したことを示します。</block>
  <block id="5946314197ad84982efa6561d9da8302" category="list-text">traefik サービスのロードバランサ IP を取得します。</block>
  <block id="298a1e8781e536e60684ab1700c60962" category="list-text">Astra Control Center CRD ファイルに指定された FQDN を指す DNS サーバーのエントリを、 traefik サービスの「 external-IP 」に追加します。</block>
  <block id="0c64767e085896708adcbcc1c32c55fe" category="inline-image-macro">ACC GUI の DNS エントリを追加します</block>
  <block id="1c278e58c0255ae1f09fc4fa520160b6" category="paragraph"><block ref="1c278e58c0255ae1f09fc4fa520160b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a37ba7c36c036650f5e1e7ded5232245" category="list-text">Astra Control Center では、すべての機能が動作するためにライセンスが必要です。ライセンスを追加するには、 ［ アカウント ］ &gt; ［ ライセンス ］ の順に選択し、 ［ ライセンスの追加 ］ をクリックして、ライセンスファイルをアップロードします。</block>
  <block id="a003986254b5a6c136733113505348da" category="doc">F5 BIG-IP ロードバランサのインストール</block>
  <block id="048600e045fd4c5afe58ec9d65aa4b19" category="paragraph">F5 BIG-IP は、 L4-L7 ロードバランシング、 SSL/TLS オフロード、 DNS 、ファイアウォールなど、高度な運用レベルのトラフィック管理およびセキュリティサービスを幅広く提供する Application Delivery Controller （ ADC; アプリケーションデリバリコントローラ）です。これらのサービスにより、アプリケーションの可用性、セキュリティ、パフォーマンスが大幅に向上します。</block>
  <block id="5c47e8322efb7f77c0aa515fec29477e" category="paragraph">F5 BIG-IP は、専用ハードウェア、クラウド、またはオンプレミスの仮想アプライアンスに、さまざまな方法で導入、使用できます。要件に応じて F5 BIG-IP を調査し、導入するには、ここで説明しているドキュメントを参照してください。</block>
  <block id="16a275a8b38f9c5211732c331edb7135" category="paragraph">F5 BIG-IP サービスを Red Hat OpenShift と効率的に統合するために、 F5 は BIG-IP Container Ingress Service （ CIS ）を提供します。CI は、特定のカスタムリソース定義（ CRD ）の OpenShift API を監視し、 F5 BIG-IP システム構成を管理するコントローラポッドとしてインストールされます。F5 BIG-IP CIS は、 OpenShift でサービスタイプ Loadancers とルートを制御するように構成できます。</block>
  <block id="e3ce824a7aff01576faaac58df9e0b18" category="paragraph">さらに、タイプ LoadBalancer にサービスを提供するための自動 IP アドレス割り当てには、 F5 IPAM コントローラを使用できます。F5 IPAM コントローラは、 LoadBalancer サービスの OpenShift API を ipamLabel 注釈で監視し、事前構成済みプールから IP アドレスを割り当てるコントローラポッドとしてインストールされます。</block>
  <block id="3b08b142099d42d5280d7b493288bf63" category="paragraph">このページには、 F5 BIG-IP CIS および IPAM コントローラのインストールおよび設定手順がリストされています。前提条件として、 F5 BIG-IP システムを導入し、ライセンスを取得しておく必要があります。また、デフォルトでは BIG-IP VE 基本ライセンスに含まれている SDN サービスのライセンスも必要です。</block>
  <block id="5fb7b483d0c9fa099945579d826691b8" category="admonition">F5 BIG-IP は、スタンドアロンモードまたはクラスタモードで導入できます。この検証の目的上、 F5 BIG-IP はスタンドアロンモードで導入されましたが、本番環境では、単一点障害を避けるために、大量の IP で構成されたクラスタを使用することを推奨します。</block>
  <block id="0d3e8be481c0c23fd0a68da9a9340ef7" category="admonition">F5 BIG-IP システムは、専用のハードウェア、クラウド、またはオンプレミスの仮想アプライアンスとして、バージョンが 12.x よりも大きいオンプレミスに導入でき、 F5 CIS と統合できます。このドキュメントでは、 BIG-IP VE エディションなどを使用して、 F5 BIG-IP システムを仮想アプライアンスとして検証しました。</block>
  <block id="39bc153685f2a0c6d56db4227295a3b0" category="section-title">検証済みのリリース</block>
  <block id="00d0a06cc7c922b3bc62b22524723ff8" category="cell">F5 BIG-IP VE エディション</block>
  <block id="5bd03f916d1e7b0410d0d3b2d12c6366" category="cell">16.1.0</block>
  <block id="c6f7874f49f685ffdf1b5a8aad8875c4" category="cell">F5 Container Ingress Service の略</block>
  <block id="21f47a5b35d016c2f0f8f57704079407" category="cell">2.5.1</block>
  <block id="9635118f932e26e24f0ca315d3843379" category="cell">F5 IPAM コントローラ</block>
  <block id="5256eb2d6e3cf80e003a290e63843800" category="cell">0.1.4</block>
  <block id="088afeececf092d5a406e0f5022a9638" category="cell">F5 AS3</block>
  <block id="425b0ca2d1d9d5c75555116fcd1614bf" category="cell">3.30.0</block>
  <block id="7cd8fb6e31cc946c078d2740c76a9899" category="section-title">インストール</block>
  <block id="b9a4064fa117596b59fb18df84df74df" category="inline-link">F5 AS3 GitHub リポジトリ</block>
  <block id="6463cf716c052865ec9f4716ff0b5d3f" category="list-text">F5 Application Services 3 拡張機能をインストールして、 big-IP システムが命令コマンドではなく JSON で構成を受け入れるようにします。に進みます<block ref="0d4e47593b830323684cdec40cb60c71" category="inline-link-rx"></block>をクリックし、最新の RPM ファイルをダウンロードします。</block>
  <block id="4c0802ebd79a8c6e5ea4aed829f023c9" category="list-text">F5 BIG-IP システムにログインし、 iApps &gt; Package Management LX に移動して、 Import （インポート）をクリックします。</block>
  <block id="3536ed517a711f49cfe64071db031cf5" category="list-text">[ ファイルの選択 ] をクリックして、ダウンロードした AS3 RPM ファイルを選択し、 [OK] をクリックして、 [ アップロード ] をクリックします。</block>
  <block id="2a90f793207a5a0c028d8ccc45e943fd" category="inline-image-macro">iApps のアップロード</block>
  <block id="7a3eaac0605c201c339e116a475c0bf6" category="paragraph"><block ref="7a3eaac0605c201c339e116a475c0bf6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="caedd771b59d267eda8f88d329e8784f" category="list-text">AS3 拡張機能が正常にインストールされたことを確認します。</block>
  <block id="c434efeb83b6dc500ea7893f1ad4236b" category="inline-image-macro">AS3 インストールの検証です</block>
  <block id="eb52ccb2be126d28d17e4383ae6ea6cf" category="paragraph"><block ref="eb52ccb2be126d28d17e4383ae6ea6cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97e9e05bfde432cfa7291b1e55a52ba7" category="list-text">次に、 OpenShift システムと BIG-IP システム間の通信に必要なリソースを構成します。まず、 OpenShift SDN のための BIG-IP システムに VXLAN トンネルインターフェイスを作成し、 OpenShift と BIG-IP サーバ間にトンネルを作成します。Network &gt; Tunnels &gt; Profiles と進み、 Create をクリックして Parent Profile を VXLAN に設定し、フラッディング Type を Multicast に設定します。プロファイルの名前を入力し、 [ 完了 ] をクリックします。</block>
  <block id="faaca798da0468a250bf3c3bffc26681" category="inline-image-macro">VXLAN プロファイルを作成する</block>
  <block id="bddf6bed69a1a2234f15cefc27853c50" category="paragraph"><block ref="bddf6bed69a1a2234f15cefc27853c50" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45ae0c96657fdc5a20e83839c2386c1e" category="list-text">Network &gt; Tunnels &gt; Tunnel List と進み、 Create をクリックして、トンネルの名前とローカル IP アドレスを入力します。前の手順で作成したトンネルプロファイルを選択し、 [ 完了 ] をクリックします。</block>
  <block id="1497a4f92d416d6c80392ec3467ff140" category="inline-image-macro">VXLAN トンネルを作成します</block>
  <block id="53ce9cdf8cf7f6cb09991e817df94959" category="paragraph"><block ref="53ce9cdf8cf7f6cb09991e817df94959" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc5e5bc480b39177b8cb8c9c3a2266ae" category="list-text">クラスタ管理者権限で Red Hat OpenShift クラスタにログインします。</block>
  <block id="986e63a308b4bebd3f531e38fa5a06c7" category="list-text">F5 BIG-IP サーバの OpenShift にホストサブネットを作成します。このサブネットは、 OpenShift クラスタから F5 BIG-IP サーバに拡張します。ホストサブネット YAML 定義をダウンロードします。</block>
  <block id="fd4475e12938f5f51ba3f312b42cdd39" category="list-text">ホストサブネットファイルを編集し、 OpenShift SDN の BIG-IP VTEP （ VXLAN トンネル） IP を追加します。</block>
  <block id="2e6d8a8db3c4d4a2227ffa0571be2a86" category="admonition">ご使用の環境に応じて、 hostIP などの詳細情報を変更します。</block>
  <block id="7f9916ee1bc520d892dfbbb1e06e2732" category="list-text">HostSubnet リソースを作成します。</block>
  <block id="7a46b2d02d466dda0cc67b215cb80bff" category="list-text">F5 BIG-IP サーバ用に作成されたホストサブネットのクラスタ IP サブネット範囲を取得します。</block>
  <block id="4f6c1fea3654c07f1606c0c76509d0b0" category="list-text">F5 BIG-IP サーバに対応する OpenShift のホストサブネット範囲の IP を使用して、 VXLAN OpenShift 上に自己 IP を作成します。F5 BIG-IP システムにログインし、 [ ネットワーク ]&gt;[ 自己 IP ] の順に選択し、 [ 作成 ] をクリックします。F5 BIG-IP ホストサブネット用に作成されたクラスタ IP サブネットから IP を入力し、 VXLAN トンネルを選択して、その他の詳細を入力します。[ 完了 ] をクリックします。</block>
  <block id="5c241806c0dd5ebb7030904151cb78ef" category="inline-image-macro">VXLAN 用に自己 IP を作成する</block>
  <block id="ffad9e123d8b7013e7d4553570644879" category="paragraph"><block ref="ffad9e123d8b7013e7d4553570644879" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d094b7d82871afb601d2f30d416ba8d" category="list-text">CIS で設定および使用する F5 BIG-IP システムにパーティションを作成します。[ システム ]&gt;[ ユーザ ]&gt;[ パーティションリスト ] の順に選択し、 [ 作成 ] をクリックして詳細を入力します。[ 完了 ] をクリックします。</block>
  <block id="4d81871723233ec21ed69ab80e638779" category="inline-image-macro">BIG-IP パーティションを作成します</block>
  <block id="b83428617c6ed29213f89e68f142bd18" category="paragraph"><block ref="b83428617c6ed29213f89e68f142bd18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37397397fa66431e2fa681b97126c399" category="admonition">CIS で管理されるパーティションでは手動で設定しないことをお勧めします。</block>
  <block id="81e4a49e9dbe0b55256fe5abf1b94fa4" category="list-text">OperatorHub のオペレータを使用して F5 BIG-IP CIS をインストールします。cluster-admin 権限を持つ Red Hat OpenShift クラスタにログインし、 F5 BIG-IP システムログインクレデンシャルを使用してシークレットを作成します。これはオペレータの前提条件です。</block>
  <block id="5de4ac005898cabf55523098c40c549b" category="list-text">F5 CIS CRD をインストールします。</block>
  <block id="0eddace1b16ed738fe1be181481c71b6" category="list-text">[ 演算子 ]&gt;[ 演算子ハブ ] に移動し、キーワード F5 を検索して、 F5 Container Ingress Service タイルをクリックします。</block>
  <block id="07543409cb05595e273df71050b9a9c0" category="inline-image-macro">オペレータハブに F5 CIS を配置します</block>
  <block id="334a7bbf4711d93b48b93c2b81d84a71" category="paragraph"><block ref="334a7bbf4711d93b48b93c2b81d84a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c25b2a3d320d6d02584fde4190d05d91" category="list-text">オペレータ情報を読み、 [ インストール ] をクリックします。</block>
  <block id="60d3353ed1910ad5c7bd352d0c1bea85" category="inline-image-macro">OperatorHub の F5 CIS 情報タイル</block>
  <block id="1aa79507d413f19135716c8006afa423" category="paragraph"><block ref="1aa79507d413f19135716c8006afa423" category="inline-image-macro-rx" type="image"></block></block>
  <block id="637a1bc658defc200d903b27828aa8fb" category="list-text">Install Operator （オペレータのインストール）画面で、デフォルトのパラメータをすべてそのままにして、 Install （インストール）をクリックします。</block>
  <block id="ccf254d7c8b666c9c127ec12fe14804b" category="inline-image-macro">F5 CIS オペレータをインストールします</block>
  <block id="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="paragraph"><block ref="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="636d8318702bc67a1613ceadf7ce9d00" category="list-text">オペレータのインストールには時間がかかります。</block>
  <block id="dffa3077bcff43536afd75bd61b11c0c" category="inline-image-macro">F5 CIS オペレータインストールの進行状況</block>
  <block id="b1be0ed9469d2ced1f6283b49735f5c1" category="paragraph"><block ref="b1be0ed9469d2ced1f6283b49735f5c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="197a0a4cc4a45ec9a62fe2b7335d8dfc" category="list-text">オペレータがインストールされると、「 Installation Successful 」というメッセージが表示されます。</block>
  <block id="5bf83e99bfa132430d0b690181334933" category="list-text">[ 演算子 ]&gt;[ インストールされている演算子 ] に移動し、 [F5BigIpCtlr ] タイルの下にある [F5 Container Ingress Service] をクリックして、 [ インスタンスの作成 ] をクリックします。</block>
  <block id="a5f584f06c59c2cf4a4a4e8b42d495a2" category="inline-image-macro">F5BigIpCtlr を作成します</block>
  <block id="a2574a02e64888de32a5a277ed05f668" category="paragraph"><block ref="a2574a02e64888de32a5a277ed05f668" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5ce9a4ef68c16a3ab5d0dd555305872" category="list-text">YAML View をクリックし、必要なパラメータを更新した後で次の内容を貼り付けます。</block>
  <block id="2e2beb899f89156ed06287fe6f78e6cf" category="admonition">以下のパラメータ「 bigip_dpartition 」、「 OpenShift 」 SDN_NAME 」、「 bigip_url 」、「 bigip_login_secret 」を更新して、内容をコピーする前にセットアップの値を反映させます。</block>
  <block id="50a17348dc3f981a95001edcc80a428f" category="list-text">このコンテンツを貼り付けたら、 [ 作成 ] をクリックします。これにより、 CIS ポッドが kube-system 名前空間にインストールされます。</block>
  <block id="72003ce6faa67d172e943ddd74fab63b" category="inline-image-macro">F5 CIS ポッドを検証します</block>
  <block id="ef76b6b9f85ff0ec00e48f565e13eff9" category="paragraph"><block ref="ef76b6b9f85ff0ec00e48f565e13eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc8632c05e82ccafb395157ccae4f5c3" category="admonition">Red Hat OpenShift は、デフォルトで、 L7 ロードバランシングのルートを介してサービスを公開する方法を提供します。組み込みの OpenShift ルータは、これらのルートのトラフィックのアドバタイズと処理を行います。ただし、外部 F5 BIG-IP システムを介してルートをサポートするように F5 CIS を構成することもできます。このシステムは、補助ルータとして実行することも、自己ホスト型 OpenShift ルータに代わるものでもあります。CIS は、 OpenShift ルートのルータとして機能する BIG-IP システムに仮想サーバを作成し、 BIG-IP はアドバタイズメントとトラフィックルーティングを処理します。この機能を有効にするためのパラメータについては、次のドキュメントを参照してください。これらのパラメータは、 APPS/v1 API の OpenShift Deployment リソースに対して定義されています。したがって、 F5BigIpCtlr リソース cis.f5.com/v1 API でこれらを使用する場合は、パラメータ名にハイフン (-) をアンダースコア (_) に置き換えます。</block>
  <block id="a6e55fc1fe932b26a294a0f2880478aa" category="list-text">CIS リソースの作成に渡される引数には 'IPAM:true' と 'custom_resource_mode:true' がありますこれらのパラメータは 'IPAM コントローラとの CIS 統合を有効にするために必要ですF5 IPAM リソースを作成して 'CIS で IPAM 統合が有効になっていることを確認します</block>
  <block id="84ac0b78989fa6595723d5541b8ec470" category="list-text">F5 IPAM コントローラに必要なサービスアカウント、ロール、およびロールバインドを作成します。YAML ファイルを作成し、次の内容を貼り付けます。</block>
  <block id="670c1074ae74616731a63f6b9462b94e" category="list-text">リソースを作成します。</block>
  <block id="b7802bea6dc04d06b63232b6301621bb" category="list-text">YAML ファイルを作成し、下記の F5 IPAM 展開定義を貼り付けます。</block>
  <block id="6a1491ddca525bea3293eca6ea8019d0" category="admonition">以下の spec.template.spec.containers [0] の ip-range パラメータを更新して、設定に対応する ipamLabel と IP アドレス範囲を反映させます。</block>
  <block id="642252b62fe47e95caa77e3b06a7dbaf" category="admonition">IPAM コントローラが定義された範囲から IP アドレスを検出して割り当てるには 'ipamLabels[`range1' および range2` を以下の例に示します ] が 'LoadBalancer 型のサービスに注釈を付ける必要があります</block>
  <block id="8f253132259909c28624117b3476a672" category="list-text">F5 IPAM コントローラ配置を作成します。</block>
  <block id="43946dccec13f46420eb559911e4c526" category="list-text">F5 IPAM コントローラポッドが実行されていることを確認します。</block>
  <block id="1362b3e7985b4f24d6c2ef4438ee1f0e" category="list-text">F5 IPAM スキーマを作成します。</block>
  <block id="52b8ffce119fe77b28034f2fdd35eb5f" category="section-title">検証</block>
  <block id="32172ccfad6e7060b8f5e091e296f09c" category="list-text">LoadBalancer タイプのサービスを作成します</block>
  <block id="0847be44e618094bc81c848c7d131399" category="list-text">IPAM コントローラが外部 IP を割り当てるかどうかを確認します。</block>
  <block id="0e51a0606ba7833099aa57bd61c62ba6" category="list-text">導入環境を作成し、作成した LoadBalancer サービスを使用します。</block>
  <block id="5f905cb56a4d1b364cab7fc57f4de4e5" category="list-text">ポッドが実行されているかどうかを確認します。</block>
  <block id="51b4d723f0434284233dab97982b185d" category="list-text">対応する仮想サーバが、 OpenShift の LoadBalancer タイプのサービス用に BIG-IP システムに作成されているかどうかを確認します。Local Traffic &gt; Virtual Servers &gt; Virtual Server List の順に選択します。</block>
  <block id="91193cea3335c4666b7dc31ca767030c" category="inline-image-macro">対応するサービスタイプの LoadBalancer 用の BIG-IP 仮想サーバの作成を検証します</block>
  <block id="879dfaa1de924ed5e9ccb98da9ac95cd" category="paragraph"><block ref="879dfaa1de924ed5e9ccb98da9ac95cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="10a93051f49f4080568cecc5ec30cd99" category="inline-link-macro">F5 BIG-IP</block>
  <block id="886218e92c071e06819887a13189b4e6" category="list-text"><block ref="886218e92c071e06819887a13189b4e6" category="inline-link-macro-rx"></block></block>
  <block id="0c3fd18fbca2ec11aa1ef250cf79f2e5" category="paragraph">NetApp Astra Control は、ネットアップのデータ保護テクノロジを基盤とするステートフル Kubernetes ワークロード向けの充実したストレージサービスとアプリケーション対応データ管理サービスを提供します。Astra Control Service は、クラウドネイティブの Kubernetes 環境でステートフルワークロードをサポートするために利用できます。Astra Control Center は、 Red Hat OpenShift などのオンプレミス環境でステートフルワークロードをサポートするために使用できます。詳細については、 NetApp Astra Control の Web サイトをご覧ください<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>。</block>
  <block id="1f23e5de73e650f12cbafec55d8a98cd" category="cell"><block ref="1f23e5de73e650f12cbafec55d8a98cd" category="inline-link-macro-rx"></block></block>
  <block id="69f55c7d7266874ad1ed57caf459c979" category="summary">この使用事例は、当社が実施した最も大規模な金融機関顧客向けコンセプトの実証（ CPOC ）に基づいています。ネットアップはこれまで、分析データを NetApp ONTAP AI に移動するためにネットアップの In-Place Analytics Module （ NIPAM ）を使用してきました。ただし、 NetApp XCP の最新の拡張機能とパフォーマンスの向上、および NetApp Data Mover 解決策独自のアプローチにより、 NetApp XCP を使用したデータ移行が再度行われます。</block>
  <block id="5084e1c3bd53b6115df08f4c40aadbe6" category="doc">データレイクから ONTAP NFS へ</block>
  <block id="ae8dcf06c5337995ca840fbd543188fc" category="inline-link-macro">Previous ：お客様のシナリオ</block>
  <block id="82f418da831bb7ca7897e30f8bc5525a" category="paragraph"><block ref="82f418da831bb7ca7897e30f8bc5525a" category="inline-link-macro-rx"></block></block>
  <block id="b1a11a01b3bdf3150e0240a1f037cdf5" category="section-title">お客様の課題と要件</block>
  <block id="9ed16d5ac47c336caaf9ca2b75930d78" category="paragraph">お客様が直面する課題と要件には、次のものがあります。</block>
  <block id="b6976e1a47e217f1a7c746e8f57e327c" category="list-text">構造化データ、非構造化データ、半構造化データ、ログ、 データレイク内のマシン間でデータを移動できます。AI システムでは、予測処理のために、これらすべてのタイプのデータを処理する必要があります。データがデータレイクネイティブファイルシステムにある場合、データを処理することは困難です。</block>
  <block id="d85cb5080a9e99841f0ff6c36abdadad" category="list-text">お客様の AI アーキテクチャは、 Hadoop Distributed File System （ HDFS ）および Hadoop Compatible File System （ HCFS ）からデータにアクセスできないため、データは AI 処理に利用できません。AI には、 NFS などのわかりやすいファイルシステム形式でデータが必要です。</block>
  <block id="982b6c87ace8f5b95c0523bd0557f4e2" category="list-text">データ量とスループットが多く、 AI システムにデータを移動するにはコスト効率の高い方法が必要であるため、データレイクからデータを移動するには特別なプロセスがいくつか必要になります。</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="section-title">Data Mover の解決策</block>
  <block id="b0a9a6f2387f2a23e13931f68fc509c1" category="paragraph">この解決策では、 MapR クラスタ内のローカルディスクから MapR ファイルシステム（ MapR - FS ）を作成します。MapR NFS Gateway は、仮想 IP を持つ各データノードに設定されています。ファイルサーバサービスは、 MapR - FS データを格納および管理します。NFS ゲートウェイを使用すると、仮想 IP を介して NFS クライアントからマップ FS データにアクセスできるようになります。Map NFS Gateway から NetApp ONTAP NFS にデータを転送するために、 MapR データノードごとに XCP インスタンスが実行されている。各 XCP インスタンスは、特定のソースフォルダのセットをデスティネーションの場所に転送します。</block>
  <block id="01e1c2900284f91d77ea71ffd32c6d18" category="paragraph">次の図は、 XCP を使用する MapR クラスタ用の NetApp Data Mover 解決策を示しています。</block>
  <block id="a7dcdfa2099e01480afb3c060c679f10" category="paragraph"><block ref="a7dcdfa2099e01480afb3c060c679f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="409f476aa8c516a92f8d6a42e21db5a0" category="inline-link">XCP を使用した、データレイクからハイパフォーマンスコンピューティング、 ONTAP NFS へのデータの移動</block>
  <block id="4084b5f9c9bab8db38eb6e04a3b3a4cc" category="paragraph">お客様の詳細なユースケース、デモの記録、テスト結果については、を参照してください<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> ブログ</block>
  <block id="6cef4abedb8153458ee404a47b193489" category="inline-link">TR-4732 ：『 Big Data Analytics Data to Artificial Intelligence 』</block>
  <block id="520ef13ea64298a652262e37756b6bd4" category="paragraph">NetApp XCP を使用して MapR FS データを ONTAP NFS に移動する手順の詳細については、の付録 B を参照してください<block ref="c952a09d2ff4403056a594c41db26c8d" category="inline-link-rx"></block>。</block>
  <block id="b4dd66db226c58dbbcc8455a7576d491" category="inline-link-macro">次に、 ONTAP NFS 向けのハイパフォーマンスコンピューティングを実現します。</block>
  <block id="9ebf542ce4a3a8a997eb85e5b6e086ed" category="paragraph"><block ref="9ebf542ce4a3a8a997eb85e5b6e086ed" category="inline-link-macro-rx"></block></block>
  <block id="89185de94c95d958df7a1d1f328c5d3d" category="summary">移行にはさまざまなフェーズがあり、移行の計画や完了に役立ちます。サードパーティ製 NAS ストレージまたは NetApp XCP を使用して直接接続された NAS エクスポートストレージからデータを移行する場合は、このセクションに記載されている移行のガイドラインに従ってください。</block>
  <block id="ee5b035493cdde88f6472904ffe00677" category="doc">データ移行ワークフロー</block>
  <block id="33af37ca0d75bc0783cc87782a94cb6e" category="inline-link-macro">以前のバージョン： NetApp XCP 。</block>
  <block id="c6f303d52bc03c848b2dde21f1b31f9d" category="paragraph"><block ref="c6f303d52bc03c848b2dde21f1b31f9d" category="inline-link-macro-rx"></block></block>
  <block id="5b312b66520bbb17746eeb5c9959e4ef" category="paragraph">次の図は、任意の NAS から NetApp NAS への移行ワークフローを示しています。</block>
  <block id="228d4a26c37192668bb7f7bf0d81ce40" category="paragraph"><block ref="228d4a26c37192668bb7f7bf0d81ce40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0e69ccbb7ad96f546f7924206944bfa" category="section-title">オンプレミス</block>
  <block id="8df17c51ab4a9817f3fe7cea57052110" category="paragraph">任意の NAS から NetApp NAS への移行ワークフローには、次の手順が含まれます。</block>
  <block id="3bd3dda9341b512ee536cc6e48d51a69" category="list-text">NAS 共有とデータを検出</block>
  <block id="7800ed0aa4aebf1d63fd7120c2bcf538" category="list-text">データをスキャンしてレポートを作成し、データのレイアウトを確認します。</block>
  <block id="8e9880476ad79e202d93a0a7d0bb5f5b" category="list-text">XCP Copy コマンドを実行してベースラインを作成します。移行を高速化するには、追加の XCP インスタンスを選択し、ワークロードをサブフォルダレベルで分割して、並行移行ジョブを開始します。</block>
  <block id="57324e972ea87c8e788d9831e510bc6d" category="list-text">差分更新の場合は、カットオーバー期間の変更率が低いまで XCP sync を使用します。</block>
  <block id="3812202d715addac73d7122672d3c8d0" category="list-text">移行を完了するには、 XCP sync コマンドを実行して、ソースを読み取り専用としてマークして最終同期を実行します。</block>
  <block id="2c1d8a91f274a7723f6ad2ffefc81b62" category="list-text">データが正しく転送されたことを確認するには 'XCP verify コマンドを実行して ' ソースとデスティネーションを比較します</block>
  <block id="8f4cde54f5af74d15d142ad98344aab6" category="paragraph">次の図は、オンプレミスからクラウドへの移行ワークフローを示しています。</block>
  <block id="9d1b3862e72bece8266c1c8b1098c696" category="paragraph"><block ref="9d1b3862e72bece8266c1c8b1098c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2fef7fa18bd688132425321b9188bb" category="paragraph">オンプレミスとクラウド間に直接インターネット接続がない場合は、トラックなどのオフラインデータ転送方式を使用して、オンプレミスからクラウドにデータを転送する必要があります。クラウドサービスプロバイダによって、データをデータセンターに移動するための用語が異なる手法が用意されています。</block>
  <block id="9e76bcaf48df4797c2e546f778fd72f8" category="paragraph">次の図は、 ExpressRoute を使用しないオンプレミスから Azure へのデータムーバーの解決策を示しています。</block>
  <block id="e13bab0261f71ca4765f8b68cea20a43" category="paragraph"><block ref="e13bab0261f71ca4765f8b68cea20a43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423066080659363cc444ec5dee611f48" category="paragraph">同様のアーキテクチャを各種クラウドサービスプロバイダの対応するコンポーネントと組み合わせて使用できます。</block>
  <block id="050572d01f21dded8086b49419066add" category="inline-link-macro">次のステップ：ファイル分析</block>
  <block id="ae292ee37a105844872f831698fb440f" category="paragraph"><block ref="ae292ee37a105844872f831698fb440f" category="inline-link-macro-rx"></block></block>
  <block id="c4e9391c8d60f1f326246cd6b6705492" category="summary">ネットアップは、 1 つまたは複数のボリュームから重複ファイルを検索する要求を受信しました。ネットアップは次の解決策を提供しました。</block>
  <block id="2e4e5fbe1f8f460b943ac3ed031c9dcf" category="doc">ファイルを複製します</block>
  <block id="f89d6874c6cf2c5de0dae9564728c7cf" category="inline-link-macro">前のバージョン： XCP Data Mover を使用して大容量ファイルを移行する。</block>
  <block id="6c8f161effcb72b9425f626e8733146b" category="paragraph"><block ref="6c8f161effcb72b9425f626e8733146b" category="inline-link-macro-rx"></block></block>
  <block id="dc4b36d55f5f1f0af63ed899a010c8f1" category="paragraph">単一のボリュームの場合は、次のコマンドを実行します。</block>
  <block id="2d2f31777cf3433071b9bcd33f39279a" category="paragraph">複数のボリュームの場合は、次のコマンドを実行します。</block>
  <block id="fdefb3eaaab41fef36db24700d399ef2" category="inline-link-macro">Next ：特定の日付ベースのスキャンとデータのコピー。</block>
  <block id="769f411db097d478d8d10a821946e501" category="paragraph"><block ref="769f411db097d478d8d10a821946e501" category="inline-link-macro-rx"></block></block>
  <block id="b25f76deff236f93a3afa73c8a5b2a2c" category="summary">このユースケースは、ネットアップが最も大規模な観光業界のお客様を対象に、クラウドへの小規模なオンプレミスファイルの移行を検討しています。</block>
  <block id="4b1739353c6d18cea69ed6a274b7135f" category="doc">XCP Data Mover を使用して、数百万個の小規模ファイルを柔軟なストレージに移行する</block>
  <block id="2b2142a0bf2476846ad59f7952380ca1" category="inline-link-macro">前のバージョン： ONTAP NFS へのハイパフォーマンスコンピューティング。</block>
  <block id="c81efa558deea51a126490ba8d09b59a" category="paragraph"><block ref="c81efa558deea51a126490ba8d09b59a" category="inline-link-macro-rx"></block></block>
  <block id="bb29cc4e9e4447f7bad1e81c1c5a9a1f" category="paragraph">このユースケースは、オンプレミスからクラウドへのデータ移行に関して、ネットアップの観光業界で最大のお客様を基準にしています。COVID-19 によって出張業界の需要が減少しているため、お客様は、オンプレミス環境のハイエンドストレージの設備投資を、需要に応じた価格設定アプリケーションで削減したいと考えています。このお客様は、数百万もの小規模ファイルをクラウドに移行するという厳しい SLA を持っています。</block>
  <block id="81ec900a5387f7a686d1451adaddf399" category="paragraph">次の図は、小規模ファイルを対象としたオンプレミスから Azure NetApp Files へのデータ移行を示しています。</block>
  <block id="214c5e9894032cde0e65b576e32294b9" category="paragraph"><block ref="214c5e9894032cde0e65b576e32294b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="099a60093e7de3795f557974125ce82b" category="inline-link">NetApp XCP Data Mover 解決策：オンプレミスからクラウドへ</block>
  <block id="50d4edabefc40ad9614b567197696a2e" category="paragraph">詳細については、を参照してください<block ref="2c0eb3741003532ef113837d4b882a9a" category="inline-link-rx"></block> ブログ</block>
  <block id="3242fe890cd89c89373a1bd576cef03a" category="inline-link-macro">次の手順： XCP Data Mover を使用して大容量ファイルを移行します。</block>
  <block id="c32441c7755c153b58450a597193448b" category="paragraph"><block ref="c32441c7755c153b58450a597193448b" category="inline-link-macro-rx"></block></block>
  <block id="485f9678c52b78d051ddff564d873eb9" category="summary">このセクションのコマンドでは、 CSV 形式でデータがダンプされます。サイズ列を合計してデータの合計サイズを確認できます。</block>
  <block id="92f6d6878e37105d20e75151b95d4e6a" category="doc">SMB / CIFS 共有からの CSV ファイルの作成</block>
  <block id="bab825782f37e3f0cd908b20bc8aa74c" category="inline-link-macro">Previous ：日付ベースの特定のスキャンとデータのコピー。</block>
  <block id="ad80673543d1d2744f55966060c4579b" category="paragraph"><block ref="ad80673543d1d2744f55966060c4579b" category="inline-link-macro-rx"></block></block>
  <block id="d122031c67144a65ca4721f8324ae0b3" category="paragraph">次に、 CSV 形式でデータをダンプするコマンドを示します。サイズ列を合計してデータの合計サイズを確認できます。</block>
  <block id="1bed902c0754e4abc7598b7f1a0450e0" category="paragraph">次のような出力が表示されます。</block>
  <block id="f7c322db5a6c805aed8a38858c7ba770" category="paragraph">3 つのサブディレクトリの深さまでスキャンし ' ソート順を指定するには 'XCP -du' コマンドを実行して ' 各ディレクトリ・レベルで 3 つのサブディレクトリの深さまでサイズをダンプします</block>
  <block id="7c12bd6fa64456eb3a61460a4bbb98e6" category="paragraph">ソートするには、情報を CSV ファイルにダンプして情報をソートします。</block>
  <block id="c2e9a8d6d376247b10a1ab4624bd2610" category="inline-link-macro">次のステップ： 7-Mode から ONTAP へのデータ移行</block>
  <block id="7155e60f207d105fa4db5d15efdce133" category="paragraph"><block ref="7155e60f207d105fa4db5d15efdce133" category="inline-link-macro-rx"></block></block>
  <block id="2246a929033f1d77a86efa97dda42849" category="inline-link-macro">前の手順：トラブルシューティング。</block>
  <block id="49c4600bab96ae4bda03f252b43985b4" category="paragraph"><block ref="49c4600bab96ae4bda03f252b43985b4" category="inline-link-macro-rx"></block></block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">このドキュメントに記載されている情報の詳細については、以下のドキュメントや Web サイトを参照してください。</block>
  <block id="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link"><block ref="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link-rx"></block></block>
  <block id="eba010943793fb5b647ad292a452b3ff" category="list-text">NetApp XCP ブログ<block ref="2639c38af267ba997fc1d85740cfc9a6" category="inline-link-rx"></block></block>
  <block id="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link"><block ref="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link-rx"></block></block>
  <block id="fb8d9f206204f9562c2a67c6b37a7d1b" category="list-text">NetApp XCP ユーザガイド<block ref="05f41a166d52148335e3a0df2eafec23" category="inline-link-rx"></block></block>
  <block id="e2c2bd378a3ae3740034d637754af7e2" category="inline-link"><block ref="e2c2bd378a3ae3740034d637754af7e2" category="inline-link-rx"></block></block>
  <block id="79b44e54a5eac82beac2de86249cd862" category="list-text">ビッグデータ分析から人工知能へ– Data Mover 解決策 for AI<block ref="79ced727b5c9638c0385a25671803fba" category="inline-link-rx"></block></block>
  <block id="9ebf058ce7a44ad4517e7033db8a90a7" category="paragraph"><block ref="9ebf058ce7a44ad4517e7033db8a90a7" category="inline-link-macro-rx"></block></block>
  <block id="0706a8a70e2892183b45c55ef1394714" category="summary">このセクションでは、 NFS 用にファイルサイズ 100 万個のファイルを使用して XCP コピー処理と XCP 同期処理を実行するおおよその時間を記載します。</block>
  <block id="137e4d3e0bc5586af6fc7ca9441511e1" category="doc">サイジングガイドライン</block>
  <block id="f688414f56f567909ca9a570f161016e" category="inline-link-macro">前の手順：導入手順</block>
  <block id="fb58e731328976afe8beac53cbe55ee7" category="paragraph"><block ref="fb58e731328976afe8beac53cbe55ee7" category="inline-link-macro-rx"></block></block>
  <block id="5224a4cb1d59edb5630ae27e640409e9" category="section-title">テストに基づく推定所要時間</block>
  <block id="1112334374c9149cc8ad8e80a76f2e56" category="paragraph">次の図に、 XCP コピー処理の結果を示します。</block>
  <block id="d6852faef2642951731c8d64e3009dbe" category="paragraph"><block ref="d6852faef2642951731c8d64e3009dbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58fe8c2d511caf443cb23313cb89181b" category="paragraph">次の図に、 XCP Sync の名前変更処理とリンク処理の結果を示します。</block>
  <block id="319b9e8dee4108359b7ef17af2fb492d" category="paragraph"><block ref="319b9e8dee4108359b7ef17af2fb492d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2186640ac8cac7be2b0f3940d871bf04" category="paragraph">ファイルのサイズは ' 名前を変更したソースファイルを転送するための XCP 同期完了時間とは一致しませんグラフは線形です</block>
  <block id="de54b82b6e27abb7d6f924e14d40a351" category="paragraph">リンクタイプは、ソフトリンク、ハードリンク、およびマルチリンクです。ソフトリンクは通常のファイルと見なされます。ファイルのサイズは、 XCP 同期処理を完了する時点とは関係ありません。</block>
  <block id="db3eb29ec347d79a716c6235063b1955" category="paragraph">次の図は、 XCP の同期アペンドおよび削除処理の結果を示しています。</block>
  <block id="feeff6134484088b1b404089dc5f92d9" category="paragraph"><block ref="feeff6134484088b1b404089dc5f92d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64c7d081568c95905b16364c19e1be1" category="paragraph">追加処理と削除処理では、小さなファイルサイズに比べて大きなファイルサイズの方が時間がかかります。処理の完了時間は、追加および削除の変更率と線形で表示されます。</block>
  <block id="ecc8d4faf16ec3b08a8badd1d71421d3" category="section-title">XCP 1.6.1 と XCP 1.5 を比較しています</block>
  <block id="ded6c17dda87ca50a7ecde2418543075" category="paragraph"><block ref="ded6c17dda87ca50a7ecde2418543075" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09a0804a78587affdd9192afd0f8c80c" category="paragraph">次の図は、 XCP 1.6.1 での XCP 同期パフォーマンスの結果と 1.5 の結果を示しています（ファイル数は 16K となります）。</block>
  <block id="b2733f54373c0149b19c3b37afbcb7da" category="paragraph"><block ref="b2733f54373c0149b19c3b37afbcb7da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7770abf0d9a0789407ea0a0e81cc5a6" category="paragraph"><block ref="e7770abf0d9a0789407ea0a0e81cc5a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71c6a3c1c59fc41b371a18011d1d5c9b" category="paragraph">XCP 1.7 のパフォーマンスは、平均して XCP 1.6.3 と同様で、「 XCP sync 」差分アップデートでは名前変更、追加、リンク、削除の各操作を 100 万ファイルの 1MB サイズで実行できます。</block>
  <block id="dd6275237d7504aabd0c206384365206" category="inline-link-macro">次の手順：パフォーマンスの調整。</block>
  <block id="cb619c90f7b537d24a1473acda746a47" category="paragraph"><block ref="cb619c90f7b537d24a1473acda746a47" category="inline-link-macro-rx"></block></block>
  <block id="a01ed8ff3f6e9e3ac0c0068a083281f2" category="summary">このセクションでは、 NetApp XCP を使用したデータ移行のトラブルシューティングについて説明します。</block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">トラブルシューティング</block>
  <block id="ae638a1049211e9956348a48a85bd359" category="inline-link-macro">Previous ：ベストプラクティスのガイドラインと推奨事項</block>
  <block id="e19cdddb31b62a88048cfee77eb96e9d" category="paragraph"><block ref="e19cdddb31b62a88048cfee77eb96e9d" category="inline-link-macro-rx"></block></block>
  <block id="95109c432d89e67182659615993ba75d" category="section-title">エラー 1 ： XCP Failed が NFS3 エラーで失敗しました。 70 ： stale filehandle Error in the xcp.log</block>
  <block id="99b1b0e3547443c29793187326a64dbc" category="paragraph">* 理由とガイダンス。 *</block>
  <block id="0774d3e8b775fcc34e680b302e85f3c1" category="paragraph">ソースフォルダをマウントし、フォルダが存在することを確認します。存在しない場合、または削除された場合は、「テールファイルハンドル」エラーが表示されます。この場合、エラーは無視してかまいません。</block>
  <block id="8fefb715a66a069c9e9318a58ecfdaee" category="section-title">エラー 2 ： NetApp NFS Destination Volume has Space 、 but XCP Failed with NFS3 error 28 ： no space left on device</block>
  <block id="bba52daa861e8093e201c3939f43057f" category="list-text">「 d f 」コマンドを実行するか、ストレージをチェックして、 NFS デスティネーション・ボリュームのスペースを確認します。</block>
  <block id="20183145becc54cc822a80107f92f13d" category="list-text">ストレージコントローラ内の inode を確認します。</block>
  <block id="fe3a96130e3ec3092026a84e4dd12e50" category="list-text">inode が使用されている場合は、次のコマンドを実行して inode の数を増やします。</block>
  <block id="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="paragraph"><block ref="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="inline-link-macro-rx"></block></block>
  <block id="3d5c39f585b0e679dbfe0855d556f0af" category="summary">NetApp XCP は、複数のスレッドとカスタマイズ可能な機能を使用してデータを転送します。データの移動や移行、ファイルシステム分析、ディレクトリツリーの高速削除という 3 つの主なユースケースに対応しています。</block>
  <block id="6416bf9c9c9445fbe2e15f69fa8371d2" category="paragraph">NetApp XCP は、複数のスレッドとカスタマイズ可能な機能を使用してデータを転送します。データの移動や移行、ファイルシステム分析、ディレクトリツリーの高速削除という 3 つの主なユースケースに対応しています。</block>
  <block id="7817bd783e8db0557909483f54288eae" category="section-title">データの移動または移行</block>
  <block id="a7786f240f16aadfd675c46be438f64e" category="paragraph">NetApp XCP は、任意の NAS から NetApp NAS にデータを転送します。このプロセスは、スキャン、コピー、同期、検証の 4 つの主要な処理で構成されます。データの監視と転送に役立つ追加の機能がいくつかあります。</block>
  <block id="59e4194e1b171063beeb99722a68e7af" category="list-text">* Copy. * はベースラインデータ転送を実行します。</block>
  <block id="a75ddee1308f2f19e478595122434544" category="list-text">* Sync. * は増分データ転送を実行します。</block>
  <block id="ae4ab572ec7de44b385c01df54f00d17" category="list-text">* 検証。 * ターゲットの完全な検証を実行します。</block>
  <block id="8ddbaa98ade9dcd56d4960b7abd22525" category="list-text">* Show （オプション）。 * NAS 共有を検出します。</block>
  <block id="4f4544fb0f8ed8f32e27a8b8651a46e6" category="paragraph">次の図は、 XCP データの移行とレプリケーションの処理を示しています。</block>
  <block id="6d97d3e510fc0fba449ece8ddd3f3d10" category="paragraph"><block ref="6d97d3e510fc0fba449ece8ddd3f3d10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="657bad21acd4ceb926477ced53a4ec55" category="section-title">ファイルシステム分析</block>
  <block id="65424b0dc0515cfa3b67e71712012db0" category="paragraph">NetApp XCP を使用すると、構造化されていないデータを標準で識別、精査、分析し、分析情報を向上させることができます。分析情報は、計画を改善し、価値の高いデジタル資産の運用を開始し、レポートと評価を通じてデータガバナンスを実現するために、企業のお客様に欠かせない重要な要件です。</block>
  <block id="03c5a03e8b03794f5fa193e72245496c" category="paragraph">機密データを扱うお客様は、 NetApp XCP を使用して、次のような回答の一般的な運用上の質問にお答えください。</block>
  <block id="6ad28c778baa08cff585599e160c12c8" category="list-text">データはどこにありますか？</block>
  <block id="5eccfafcfad0fb3dcd5f4f1036fed9f9" category="list-text">データの量とファイルの種類</block>
  <block id="b1c54971a6211d7b7e3d074bff16b4c9" category="list-text">どのようなデータがアクティブに使用され、休止状態になっているか？</block>
  <block id="81ff19b428c80049b09f8e1e6e55cfde" category="paragraph"><block ref="81ff19b428c80049b09f8e1e6e55cfde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a6c498fb90ee345d997f888fce3b18" category="section-title">削除</block>
  <block id="4125c56415a1c3b98b49ee7f8c2ebfc3" category="paragraph">ストレージ・チームや Electronic Design Automation （ EDA ）のワークロードでは、古いデータであっても、ストレージ・スペースを回復するためにクリーニングが必要なテスト・データであっても、大きなディレクトリをクリーンアップするのは非常に困難です。XCP は、ディレクトリツリー全体を削除できる高速削除機能を提供します。NetApp XCP Delete 機能は、特定の NAS パスからファイルとフォルダを削除します。一致フィルタを使用すると、特定のファイルおよびフォルダセットを削除できます。多数のファイルやフォルダに対しては、削除の確認を必要としない強制オプションを使用できます。</block>
  <block id="ecfd5328aaeaeb8ab72037598049a32c" category="section-title">ライブソース移行のサポート</block>
  <block id="286a0f56c729672b0709605c558d0008" category="paragraph">この機能では、ソースの変更はサポートされますが、デスティネーションに対する変更はサポートされません。移行中は、移行先をアクティブにしないでください。ライブソースマイグレーションは、 NFS マイグレーションでのみサポートされます。</block>
  <block id="2c346a482fcf83bd03d1d51f65d58b8d" category="admonition">ライブソース移行では、特別な設定は必要ありません。</block>
  <block id="ba41152bc4991a294ab26fbe691d52e3" category="section-title">XCP の前提条件</block>
  <block id="010e3e2a3d44100784dac368cdb601c0" category="paragraph">NetApp XCP を導入する前に、次の前提条件を満たしている必要があります。</block>
  <block id="b76760dcfae800f7180ec4e8c57a8e2f" category="list-text">次のコマンドを実行して、 NFS サーバで使用されている NFS ポートを確認します。</block>
  <block id="a9a9fca38da059af5a55e2fc58ef3851" category="list-text">オンプレミスインスタンスまたはクラウドインスタンス（ Azure 、 AWS 、 Google Virtual Machine [VM] インスタンスなど）の XCP 処理を実行する場所にアクセスするには、 NFS ポートのファイアウォールポートを開きます。</block>
  <block id="b22a57ce186f512ec584f5aac1d3de34" category="list-text">telnet コマンド '&lt; オンプレミスの NFS データ LIF IP または NAS ip&gt;2049 を使用して 'XCP サーバから NFS ポートにアクセスできることを確認しますデフォルトのポートは 2049. です。環境内のポートが異なる場合は、その IP を使用します。</block>
  <block id="e54a7adb3b7e28ed3d693d972fc48fd0" category="list-text">NFS の場合は、「 howmount -e &lt;NAS ip&gt;` コマンドを使用して、 XCP サーバから共有にアクセスできることを確認します。</block>
  <block id="da7f6a983e12f3b14b965ea651990ca9" category="list-text">デスティネーションボリュームの inode の数を、ソースファイルのファイル数（ファイル数）よりも多くします。</block>
  <block id="71858e85f290ec0f6955841bab9f3aef" category="inline-link">NetApp XCP ライセンスポータル</block>
  <block id="14324adbfb79ad4b6832f6a02a1275db" category="list-text">から XCP ライセンスをダウンロードします<block ref="eab886d42d2df7a710066e6d9bf6f5f5" category="inline-link-rx"></block>。</block>
  <block id="7481213bd7173438d06de418474e428b" category="list-text">mysupport.netapp.com にネットアップアカウントがあるか、または無償で登録できます。</block>
  <block id="d25e9f08475ddf6a2701e7cfbd67ff06" category="list-text">ライセンスをダウンロードしてご用意ください。</block>
  <block id="3d19c697861d11cce0f1d78d41cfea64" category="list-text">NAS ボリュームを作成し、データデスティネーションの共有を設定します。</block>
  <block id="4f2a304b9680876edc7cb61b5c4c7134" category="list-text">複数の XCP インスタンスがある場合、複数のソースフォルダまたはファイルからデスティネーションにデータを転送するには、サーバまたはクラウドインスタンスが 1 つ以上必要です。</block>
  <block id="adc4e34febc2f5919cfa03870630c2fc" category="list-text">maxdir サイズ（デフォルトは 308MB ）では、最大ファイル数（約 100 万）が 1 つのフォルダに定義されます。maxdir サイズ値を大きくして、ファイル数を増やします。値を増やすと、 CPU サイクルが増える。</block>
  <block id="a1552408599f6e2171495d55ae375802" category="list-text">クラウドでは、オンプレミスとクラウド間で ExpressRoute （ Azure ）、 Direct Connect （ AWS ）、または Cloud Interconnect （ GCP ）を使用することを推奨します。</block>
  <block id="fb41b0ab70237465636fc4267d1c00dd" category="inline-link-macro">次の手順：移行ワークフロー</block>
  <block id="7ed4381f9a10813d06ebeaf5c947c2c1" category="summary">NetApp XCP ファイル分析 GUI は、バックエンドで XCP を使用してファイルシステムスキャンを実行し、 NAS （ NFS 、 SMB ）ファイルシステムのグラフやビューなどの統計情報を表示するのに役立ちます。</block>
  <block id="250a5d043009990eb69a399d7c630462" category="doc">ファイル分析</block>
  <block id="47461303c8b8cbeb3e7558e2a9a1ca70" category="inline-link-macro">前のページ：移行ワークフロー</block>
  <block id="685a7e894721315c196897b76f95b8ce" category="paragraph"><block ref="685a7e894721315c196897b76f95b8ce" category="inline-link-macro-rx"></block></block>
  <block id="0f2604fbc18e6e91ba050460e6557361" category="paragraph">NetApp XCP ファイル分析 GUI は、バックエンドで XCP を使用してファイルシステムスキャンを実行し、 NAS （ NFS 、 SMB ）ファイルシステムのグラフやビューなどの統計情報を表示するのに役立ちます。1.6 以降では、構成オプションと systemctl オプションを使用して、簡単な導入手順で XCP をサービスとして実行できます。XCP Configure オプションでは、 Postgres と Web サーバのインストールと設定、およびクレデンシャルの収集が指示されます。systemctl オプションは、 GUI から REST API 通信のサービスとして XCP を実行します。</block>
  <block id="914cb171c700c273306e8265b56f4973" category="paragraph">次の図に、 XCP ファイルの分析フローを示します。</block>
  <block id="538e51b99e800ab65e133b5d57b2dc7f" category="paragraph"><block ref="538e51b99e800ab65e133b5d57b2dc7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bcdbf2b32a87f7efd13f706d43954d5" category="inline-link">NetApp XCP 1.6 が、オープンファイル分析とインフラストラクチャの向上を実現します</block>
  <block id="168c81694a3b19988d829a9baeda23fd" category="list-text">「 XCP scan 」と「 -match 」フィルタを使用して、消費されたスペースを使用して、 1 年を超えて変更されたファイルのリストを生成します。</block>
  <block id="de615506a73ca5960be54d36ba7fcd5b" category="list-text">1 年以上前のファイルで使用されているスペースを探します。</block>
  <block id="d2d1f03d5f19a1229103a85cc9224a61" category="list-text">1 年以上前に変更されたデータの合計サイズとグラフ表示を確認します。</block>
  <block id="d706f3d28ee3e74f9a6829c882169af8" category="paragraph">次のレポートは、 1 年以上前に変更されたファイルのカスタムスキャン例です。</block>
  <block id="4d614048a495643d1c641a86e53b78d3" category="paragraph"><block ref="4d614048a495643d1c641a86e53b78d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54e4262e01c029cac8932a431c7e3d3f" category="paragraph"><block ref="54e4262e01c029cac8932a431c7e3d3f" category="inline-link-macro-rx"></block></block>
  <block id="035fe4f74f99e66d6525774bf40236f9" category="summary">ここでは、 NetApp XCP を使用してデータを移行する際のベストプラクティス、ガイドライン、推奨事項について説明します。</block>
  <block id="52f7ac44cac2d8d1a3f005648d7521e3" category="doc">ベストプラクティスのガイドラインと推奨事項</block>
  <block id="b5a13e4f32bf69c6814808ff6a11eb9b" category="inline-link-macro">前のバージョン： ACL を使用した、ソースストレージボックスから ONTAP への CIFS データの移行。</block>
  <block id="a930ea4d6e07241178b9fe2f3c054fd2" category="paragraph"><block ref="a930ea4d6e07241178b9fe2f3c054fd2" category="inline-link-macro-rx"></block></block>
  <block id="1cce79308861dd86d5e56af13afefaf2" category="list-text">IMT でサポートされている XCP クライアントオペレーティングシステムを使用します。サポートされている IMT クライアントは、ネットアップで認定されています。</block>
  <block id="ec653488c4b3b9bb00702a4fb937f5b4" category="list-text">Linux オペレーティングシステムで root ユーザとして XCP を実行し、移行を実行します。sudo ユーザとして XCP コマンドを実行できますが、 XCP ではサポートされていません。</block>
  <block id="8c8f6415908fe0a235f0850d80a398a4" category="list-text">クライアントごとに 1 つの XCP インスタンスのみを実行します。技術的には、同じホスト上で異なる場所から複数のインスタンスの XCP を実行できますが、これはサポートされていません。実際、多数のインスタンスを実行すると、障害が発生する可能性があります。</block>
  <block id="cac486281cae3e805e89a64673c47eb3" category="list-text">現在の XCP バージョンでは、 Live Source はサポートされていません。ソースのネットアップボリュームがアクティブで、アプリケーションやユーザによって継続的に変更されている場合は、ソースボリュームの Snapshot を作成して移行を実行する必要があります。</block>
  <block id="c1f9797ffa66b762cf07348c6bc4a005" category="list-text">新しい Snapshot は、増分同期ごとに別の名前を使用して作成することを推奨します。これにより、障害発生時に Snapshot 名に基づいて差分移行パスを簡単に作成できます。</block>
  <block id="1309895bb5c78406c77a6cc2800160eb" category="list-text">Snapshot ベースのマイグレーションを実行する場合は、カットオーバーまで Snapshot ベースのマイグレーションを続行することを推奨します。</block>
  <block id="cc9954d8dc3e80c40af9d0a7ca3de005" category="list-text">ファイル数が 1 、 000 万を超え、増分データの変更率が 50% を超える場合は、インストールおよび管理ガイドでの最小推奨値よりもコア数とメモリ容量を増やすことを推奨します。</block>
  <block id="f6cb936ed9c08627956daed52c6c3323" category="inline-link-macro">次の手順：トラブルシューティング。</block>
  <block id="58c815a6f6adf3657aa40f96cb5f2d08" category="paragraph"><block ref="58c815a6f6adf3657aa40f96cb5f2d08" category="inline-link-macro-rx"></block></block>
  <block id="7776aec966d5a0c71bd4e8230f9470b8" category="summary">このユースケースは、テレビネットワークの顧客に基づいています。お客様は、 Oracle Recovery Manager （ RMAN ）のバックアップファイルをクラウドに移行し、 Azure NetApp Files と Pacemaker ソフトウェアを使用して Oracle E-Business Suite （ EBS ）アプリケーションを実行したいと考えていました。また、データベースバックアップファイルをオンデマンドのクラウドストレージに移行して、大容量ファイル（それぞれ 25GB から 50GB まで）を Azure に転送することも検討していました。</block>
  <block id="8108bac490ceb375198c578e8a439026" category="doc">XCP Data Mover を使用して大容量ファイルを移行する</block>
  <block id="adec666d077f4afe1b4f2b8720ed1247" category="inline-link-macro">前のバージョン： XCP Data Mover を使用して、数百万の小規模ファイルを柔軟なストレージに移行しています。</block>
  <block id="d6be3aed77745a993a24266eaf05084d" category="paragraph"><block ref="d6be3aed77745a993a24266eaf05084d" category="inline-link-macro-rx"></block></block>
  <block id="06470d7a09a56d555bad98bdf38a6cad" category="paragraph">次の図は、オンプレミスから大容量ファイルの Azure NetApp Files へのデータ移行を示しています。</block>
  <block id="1b95efe3eae02043da6528de3cf9caf8" category="inline-link-macro">次の手順：ファイルを複製します。</block>
  <block id="76fdb34470826293aaf52b30bf98fce0" category="paragraph"><block ref="76fdb34470826293aaf52b30bf98fce0" category="inline-link-macro-rx"></block></block>
  <block id="ddf97b6ffb913bd772848e3ebecfc8c1" category="summary">このセクションでは、 NetApp XCP でのデータ転送の導入手順について説明します。</block>
  <block id="8388066510b59c8d3387373b6969a7af" category="doc">導入手順</block>
  <block id="c6310b144c1666a29ec7cacf1c0dceab" category="inline-link-macro">前のページ：ファイル分析</block>
  <block id="57c4917a0617c8b675e6cc1dbad5c7fe" category="paragraph"><block ref="57c4917a0617c8b675e6cc1dbad5c7fe" category="inline-link-macro-rx"></block></block>
  <block id="8449c94058b7c2e686c3e19f7e772a65" category="section-title">ベッドの詳細をテストします</block>
  <block id="94cb70bde9d89f0b10ffdca34b0bec22" category="paragraph">次の表に、この導入およびパフォーマンス検証に使用したテストベッドの詳細を示します。</block>
  <block id="57419d904381619fcf00bc94e4ce26f1" category="cell">XCP バージョン 1.7</block>
  <block id="0bf2dca8ce9b94406660e58b59a3dbbd" category="list-text">Linux サーバ × 1 - Linux （ RHEL 7.9 または RHEL 8 ）</block>
  <block id="d85d793ce9fe1772209fa5e17fb29449" category="list-text">Windows サーバ × 1 – Windows Server 2019 標準</block>
  <block id="91ea491db15b6d672d79b23fb98eb089" category="cell">ソースボリュームの NetApp AFF ストレージアレイ HA ペア</block>
  <block id="23ec9249d03285a513eaaf182a7bcd49" category="list-text">AFF8080</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">NFS プロトコル</block>
  <block id="80fdc6d88149270be735269f2ff65645" category="cell">デスティネーションボリューム用の NetApp AFF ストレージアレイ HA ペア</block>
  <block id="203165a49e3a391bdbc44e3a05d54279" category="list-text">ONTAP 9</block>
  <block id="28712ee052ea500eba0cdbb1d847277f" category="cell">Fujitsu PRIMERGY RX2540 サーバ</block>
  <block id="539c5af1c2682685cd076697aaa6c700" category="cell">各装置には、 *48 CPU * Intel Xeon * 256GB 物理メモリ * 10GbE デュアルポートが搭載されています</block>
  <block id="0cc5c79089d6ca0752529568758efc4c" category="cell">10GbE</block>
  <block id="2879e817640f94636340918850eb6903" category="inline-link">NetApp XCP ユーザガイド</block>
  <block id="f2dd54ec57ec5464ee3aa191a48a8a43" category="paragraph">データ転送用に NetApp XCP を導入するには、まず移行先で XCP ソフトウェアをインストールしてアクティブ化します。詳細については、を参照してください<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>。これには、次の手順を実行します。</block>
  <block id="c58c8903e33903d2e630277aa3a78795" category="inline-link">NetApp XCP （ダウンロード）ページ</block>
  <block id="2d1acef34bb45f2c1878c6b576f3b400" category="list-text">から XCP ソフトウェアをダウンロードします<block ref="13844fc5dba1627d28169d2acfff11e2" category="inline-link-rx"></block>。</block>
  <block id="8319752fe43598ddb329e536217c1cb5" category="list-text">ダウンロードした XCP tar ファイルを XCP サーバにコピーします。</block>
  <block id="c9b8e059d1597eaead43d286e91c91e3" category="list-text">tar ファイルを解凍します。</block>
  <block id="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link"><block ref="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link-rx"></block></block>
  <block id="19f1deecf23a78878eb01c772b9233e0" category="list-text">からライセンスをダウンロードします<block ref="4da39fde529d1b69f60873c302229eed" category="inline-link-rx"></block> XCP サーバにコピーします。</block>
  <block id="3df11515e644382207c1430c36ea48bb" category="list-text">ライセンスをアクティブ化します。</block>
  <block id="ad7984249c2054b4da5fd3b57b1b91ef" category="list-text">ソース NFS ポートとデスティネーション NFS サーバを特定します。デフォルトのポートは 2049. です。</block>
  <block id="79fe861b8c719b1a534bdbcace1444a2" category="list-text">NFS の接続を確認します。NFS サーバのポートに Telnet を使用して、（ソースとデスティネーションの両方について） NFS サーバを確認します。</block>
  <block id="5e471de79dbe02105770bcf04bc501d5" category="list-text">カタログを設定する。</block>
  <block id="67005679d502da10622f2104421e894b" category="list-text">NFS ボリュームを作成し、 XCP カタログ用の NFS をエクスポートする。また、 XCP カタログにオペレーティングシステムの NFS エクスポートを利用することもできます。</block>
  <block id="d6f2a18783592d1858e3e5bdcabd4567" category="list-text">NFS エクスポートを確認します。</block>
  <block id="39b638480b201a7448774e8186012e4e" category="list-text">xcp.ini` を更新します</block>
  <block id="9d44d1309af47903754b16c403f68774" category="list-text">XCP show を使用して ' ソース NAS エクスポートを検索します検索：</block>
  <block id="fbff9a42f0ba33571594cb39da93ef4b" category="list-text">（オプション）ソース NAS データをスキャンします。</block>
  <block id="82d1938e7390e37babdea8d6fd359156" category="paragraph">ソース NAS データをスキャンすることで、データレイアウトを把握し、移行の潜在的な問題を特定するのに役立ちます。XCP スキャン処理時間は、ファイル数とディレクトリ深度に比例します。NAS データに精通している場合は、この手順を省略できます。</block>
  <block id="c6e94e11da5ba5bce0f27b8c782e4110" category="list-text">'XCP scan' が作成したレポートを確認します主に読み取り不能フォルダと読み取り不能ファイルを検索します。</block>
  <block id="6a6a10773cfc849f638ac0137a5f08d6" category="list-text">（任意） inode を変更します。inode の数を確認し、カタログボリュームとデスティネーションボリュームの両方で移行またはコピーするファイルの数に基づいて変更する（必要な場合）。</block>
  <block id="342779baf0b15fdf377f142c987e896a" category="list-text">デスティネーションボリュームをスキャン</block>
  <block id="a88831977a2b62e982b722f6fa6662b5" category="list-text">ソースボリュームとデスティネーションボリュームのスペースを確認します。</block>
  <block id="4b14d92fd07932987cf7416eb7f604ca" category="list-text">「 XCP copy 」を使用してソースからデスティネーションにデータをコピーし、概要を確認します。</block>
  <block id="506aae448569ed08125f41ed940eb00b" category="admonition">デフォルトでは、データをコピーするための 7 つの並行プロセスが XCP によって作成されます。これは調整可能です。</block>
  <block id="5c46a2da3e6e0423829946fe877c50b8" category="admonition">ソースボリュームは読み取り専用にすることを推奨します。ソースボリュームは、リアルタイムでアクティブなライブファイルシステムです。NetApp XCP はアプリケーションによって継続的に変更されるライブソースをサポートしていないため、「 XCP copy 」操作が失敗することがあります。</block>
  <block id="0f7dbc07af0b5c3ba51ff604b81ebe8a" category="paragraph">Linux では、 XCP Linux がカタログ化を実行するため、 XCP にインデックス ID が必要です。</block>
  <block id="764363dd147880ab6aca242a0417562e" category="list-text">（オプション）デスティネーションネットアップボリュームの inode を確認します。</block>
  <block id="ab3ba5fb62db279b7d07bac650a6c2d2" category="list-text">'XCP sync' を使用して差分更新を実行します</block>
  <block id="6cdfbe571ba2209e0a76f3bcabfee9f6" category="paragraph">このドキュメントでは、リアルタイムをシミュレートするために、ソースデータの 100 万個のファイルの名前が変更され、更新されたファイルは「 XCP sync 」を使用してデスティネーションにコピーされました。Windows の場合、 XCP にはソースパスとデスティネーションパスの両方が必要です。</block>
  <block id="13475b4ca9a916769b9d63f4fddfa18d" category="list-text">データ転送を検証送信元と宛先が同じデータであることを検証するには、「 XCP verify 」を使用します。</block>
  <block id="1cd06f171a5a99926a67bd673014f765" category="paragraph">XCP のマニュアルには 'CAN'copy''sync' および 've rify' オペレーション用の複数のオプション（例を含む）が用意されています詳細については、を参照してください<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>。</block>
  <block id="efa146517859e051c07fabac4c88d3e7" category="admonition">Windows のお客様は、アクセス制御リスト（ ACL ）を使用してデータをコピーする必要があります。ネットアップでは、コマンド XCP copy-acl-fallbackuser\&lt;username&gt;-fallbackgroup\&lt;username または groupname&gt; &lt;source&gt;&lt;destination&gt;` を使用することを推奨しています。パフォーマンスを最大限に高めるために、 ACL を備えた SMB データと NFS と SMB の両方からアクセスできるデータが格納されたソースボリュームを検討する場合、ターゲットは NTFS ボリュームである必要があります。XCP （ NFS バージョン）を使用して、 Linux サーバからデータをコピーし、 Windows サーバからの「 -acl 」および「 -nodata 」オプションを使用して XCP （ SMB バージョン）同期を実行し、ソースデータからターゲット SMB データに ACL をコピーします。</block>
  <block id="85760de676a9f74f28f26115c39c9a0b" category="inline-link">「監査とセキュリティログ」ポリシーを設定しています</block>
  <block id="a0251b301ad566d86ffa3916c5510295" category="paragraph">詳細な手順については、を参照してください<block ref="06fdba77988da3047baf401e4fdefca5" category="inline-link-rx"></block>。</block>
  <block id="d2bac014bbd39f6954893239102c5678" category="inline-link-macro">次：サイジングガイドライン</block>
  <block id="b49cd7fb5a227da1698c527804f31bbb" category="paragraph"><block ref="b49cd7fb5a227da1698c527804f31bbb" category="inline-link-macro-rx"></block></block>
  <block id="24992328317a5b7b3c00507eb27776df" category="paragraph"><block ref="24992328317a5b7b3c00507eb27776df" category="inline-link-macro-rx"></block></block>
  <block id="d4f4c40bd169a262676284f5da7a191a" category="cell">2020年10月</block>
  <block id="945407c0c602d0c34ead1ebb5427a84b" category="summary">GPU がデータを処理できるように、 GPFS から NFS にデータを移行するために NetApp XCP を使用しました。AI は通常、ネットワークファイルシステムのデータを処理します。</block>
  <block id="1f797a3a419cdffd442fc4b662974908" category="doc">ONTAP NFS へのハイパフォーマンスコンピューティング</block>
  <block id="95160fc4cfa09139af600f92561c7ef9" category="inline-link-macro">前のバージョン： ONTAP NFS へのデータレイク。</block>
  <block id="9d82d327cabd66bd4cccb55cb5ed28ec" category="paragraph"><block ref="9d82d327cabd66bd4cccb55cb5ed28ec" category="inline-link-macro-rx"></block></block>
  <block id="a4a4d9553ba807d3f28f8f25ea56cfec" category="paragraph">このユースケースは、フィールド組織からのリクエストに基づいています。ネットアップのお客様の中には、トレーニングモデルのデータ分析を可能にするハイパフォーマンスコンピューティング環境にデータを配置しているお客様もいらっしゃいます。この環境では、研究組織が大量のデジタルデータを分析して理解することができます。ネットアップのフィールドエンジニアは、 IBM の GPFS から NFS にデータを抽出するために、詳細な手順を必要としています。GPU がデータを処理できるように、 GPFS から NFS にデータを移行するために NetApp XCP を使用しました。AI は通常、ネットワークファイルシステムのデータを処理します。</block>
  <block id="0ce008ed1a75e69e9f21d1ad29ed23dd" category="paragraph">ONTAP NFS へのハイパフォーマンスコンピューティングのユースケース、デモの記録、およびテスト結果の詳細については、を参照してください<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> ブログ</block>
  <block id="fb64727a5df67d0ceff6f0a11b531ab5" category="paragraph">NetApp XCP を使用して MapR FS データを ONTAP NFS に移動する手順の詳細については、の「付録 A ： GPFS から NFS への移行」を参照してください<block ref="e760c508aca9c545c45aba81e95e5593" category="inline-link-rx"></block>。</block>
  <block id="1b5c563b4edac6a7e8566fac62f90b34" category="inline-link-macro">次の手順： XCP Data Mover を使用して、数百万の小規模ファイルを柔軟なストレージに移行します。</block>
  <block id="0461d449643091f3bbb27cfbb215c6f2" category="paragraph"><block ref="0461d449643091f3bbb27cfbb215c6f2" category="inline-link-macro-rx"></block></block>
  <block id="1357196e1dc18c4ad43fe26a6c1b30ad" category="inline-link-macro">Previous ：パフォーマンスの調整。</block>
  <block id="33672b776ede62bd1269689ea61e45aa" category="paragraph"><block ref="33672b776ede62bd1269689ea61e45aa" category="inline-link-macro-rx"></block></block>
  <block id="1ebf7a1cb4f3826913a58c19018c694e" category="paragraph">このセクションでは、お客様のシナリオとそのアーキテクチャについて説明します。</block>
  <block id="b58464d62b5399c457b8a1fcf6bbcd27" category="inline-link-macro">次の例は、 ONTAP NFS へのデータレイクです。</block>
  <block id="a24139c6a89df9b0694c3ea695639ace" category="paragraph"><block ref="a24139c6a89df9b0694c3ea695639ace" category="inline-link-macro-rx"></block></block>
  <block id="322bc614a8031f8c334d233f8221a4ab" category="summary">このセクションでは、 NetApp Data ONTAP 7-Mode から ONTAP にデータを移行する手順について詳しく説明します。</block>
  <block id="30ee25b2188724428e827e97bab504fe" category="doc">7-Mode から ONTAP へのデータマイグレーション</block>
  <block id="aecfc9b89f609bfde217a6cf8fc0b00a" category="inline-link-macro">前の手順： SMB / CIFS 共有からの CSV ファイルの作成</block>
  <block id="6da13b2cdb445320dc3e29759119f4e8" category="paragraph"><block ref="6da13b2cdb445320dc3e29759119f4e8" category="inline-link-macro-rx"></block></block>
  <block id="3ec8186e1900b95154cccf8ccea38023" category="section-title">7-Mode の NFSv3 ストレージを ONTAP for NFS データに移行する</block>
  <block id="e70a6b3d23d1e0da94c71a9ea26747d1" category="paragraph">このセクション ONTAP では、次の表に示す、手順システムへのソースの 7-Mode NFSv3 エクスポートの移行の手順を説明します。</block>
  <block id="cad365d13740342c8f6199feb7229137" category="paragraph">ソースの 7-Mode NFSv3 ボリュームがクライアントシステムにエクスポートされてマウントされ、 XCP が Linux システムにすでにインストールされていることを前提としています。</block>
  <block id="b40dbfa52a308abff927380b983cd868" category="list-text">ターゲット ONTAP システムが正常であることを確認します。</block>
  <block id="39745ae9472f91abcd9e844389157858" category="list-text">ターゲットシステムにルートではないアグリゲートが少なくとも 1 つ存在することを確認します。アグリゲートは正常な状態です。</block>
  <block id="47e01226b4fdf549d938eb5c6196970d" category="paragraph">データアグリゲートがない場合は、「 storage aggr create 」コマンドを使用して新しいアグリゲートを作成します。</block>
  <block id="5c52d0e31e44663ee633be681387faa1" category="list-text">ターゲットクラスタシステムに Storage Virtual Machine （ SVM ）を作成します。</block>
  <block id="426b5839edbb7a7772be396e7eaceace" category="list-text">ターゲット SVM から FCP 、 iSCSI 、 NDMP 、 CIDS の各プロトコルを削除します。</block>
  <block id="d03930721e424cdac105ccd0172f7dbe" category="paragraph">この SVM で許可されているプロトコルが NFS であることを確認してください。</block>
  <block id="4d6b5eb9160c3c34e9ff5535c403cea9" category="list-text">デスティネーション SVM に読み書き可能な新しいデータボリュームを作成します。セキュリティ形式、言語設定、容量の要件がソースボリュームと同じであることを確認します。</block>
  <block id="a2cebf1e91b2a266a58458873c8980fd" category="list-text">データ LIF を作成して NFS クライアントの要求に対応します。</block>
  <block id="6817d90b89495074e679248b56128378" category="paragraph">LIF が正常に作成されたことを確認します。</block>
  <block id="3a014fae7f5d70cc01c593a8401140ee" category="list-text">必要に応じて、 SVM で静的ルートを作成します。</block>
  <block id="84bb87c2987a4b39ea23430f38570808" category="paragraph">ルートが正常に作成されたことを確認します。</block>
  <block id="54b19b8b3b6de7bce018de598a1645ea" category="list-text">ターゲットの NFS データボリュームを SVM ネームスペースにマウントします。</block>
  <block id="6365adb4324221d944bc90c4663dfe5a" category="paragraph">ボリュームが正常にマウントされたことを確認します。</block>
  <block id="991398c32a43bcf95d7fa14129a6fcb0" category="paragraph">volume create コマンドを使用して ' ボリューム・マウント・オプション（ジャンクション・パス）を指定することもできます</block>
  <block id="6c02d24a81dd4d9b1ad7a15079b4f122" category="list-text">ターゲット SVM で NFS サービスを開始します。</block>
  <block id="e210fe657c5d46e3e11ca263d1a18af7" category="paragraph">サービスが開始され、実行されていることを確認します。</block>
  <block id="304683b37151feda067e3acfde300057" category="list-text">デフォルトの NFS エクスポートポリシーがターゲット SVM に適用されていることを確認します。</block>
  <block id="353fde8a37910716dc00dec81475c0d5" category="list-text">必要に応じて、ターゲット SVM 用の新しいカスタムエクスポートポリシーを作成します。</block>
  <block id="174608facfdad6448222d6d46c87fba5" category="paragraph">新しいカスタムエクスポートポリシーが作成されたことを確認します。</block>
  <block id="4007cf260b496d35ba0e925f1e7a183d" category="list-text">NFS クライアントへのアクセスを許可するようにエクスポートポリシールールを変更します。</block>
  <block id="5f249df749512e129505d18fd47d7010" category="list-text">クライアントがボリュームへのアクセスを許可されていることを確認します。</block>
  <block id="94a80f56f92334f07fd30337692ca889" category="list-text">Linux NFS サーバに接続します。NFS エクスポートボリュームのマウントポイントを作成します。</block>
  <block id="725ae014e8d8f66f0f2d477fa656ba32" category="list-text">このマウントポイントに、ターゲットの NFSv3 エクスポートボリュームをマウントします。</block>
  <block id="a345b19bdd483ecd745a2e643b756bc6" category="admonition">NFSv3 ボリュームはエクスポートする必要がありますが、 NFS サーバでマウントする必要はありません。マウント可能な場合は、 XCP Linux ホストクライアントでこれらのボリュームをマウントします。</block>
  <block id="b5b2af7fb88c03cfd258cdd77fc6fbe1" category="paragraph">マウントポイントが正常に作成されたことを確認します。</block>
  <block id="8d3ac4d5ea9c5d5c45d7322512d7b778" category="list-text">NFS エクスポートマウントポイントにテストファイルを作成して、読み取り / 書き込みアクセスを有効にします。</block>
  <block id="07e483b5917b8a9e91a22b2ebc20961a" category="admonition">読み取り / 書き込みテストが完了したら、ターゲットの NFS マウントポイントからファイルを削除します。</block>
  <block id="09280cd628b820e696b87163b3fe0fde" category="list-text">XCP がインストールされている Linux クライアントシステムに接続します。XCP のインストールパスを参照します。</block>
  <block id="86de6eeea329a50737c7056637f43e49" category="list-text">XCP Linux クライアントホストシステムで「 XCP show 」コマンドを実行して、ソースの 7-Mode NFSv3 エクスポートを照会します。</block>
  <block id="080173849f5fec049b214897a2882295" category="list-text">ソースの NFSv3 エクスポートパスをスキャンし、ファイル構造の統計を出力します。</block>
  <block id="df86b239e412ba3ba7192b581381b444" category="paragraph">XCP では、ソースの NFSv3 エクスポートは「 can 」、「 copy 」、「 sync 」の各処理で読み取り専用モードにすることを推奨します。</block>
  <block id="695efe20ffcfc7c261e44cbb1b62cc78" category="list-text">ソースの 7-Mode NFSv3 エクスポートを、ターゲット ONTAP システムの NFSv3 エクスポートにコピーします。</block>
  <block id="50515e001679292835a498c6bd3f3c31" category="list-text">コピーが完了したら、ソースとデスティネーションの NFSv3 エクスポートに同一のデータがあることを確認します。「 XCP verify 」コマンドを実行します。</block>
  <block id="70d6a53ca7c3c592cb4099e2988c226c" category="paragraph">送信元データと宛先データの間に相違がある場合 'XCP verify' はサマリーにエラー NO such file or directory を報告しますこの問題を修正するには、「 XCP sync 」コマンドを実行して、ソースの変更を宛先にコピーします。</block>
  <block id="505d73172f49d62bd99779ab53aa5eeb" category="list-text">カットオーバーの前後に、もう一度「ライフル」を実行します。ソースに新規または更新されたデータがある場合は、差分更新を実行します。「 XCP sync 」コマンドを実行します。</block>
  <block id="887abb0b5917a0a6b0c47f5ef3eca1ce" category="list-text">以前に中断されたコピー操作を再開するには 'XCP RESUME コマンドを実行します</block>
  <block id="f807709818ec3fbc508863a00ea17044" category="paragraph">「ファイルのコピーが完了したら、「グリフィ」を再度実行して、ソースストレージとデスティネーションストレージのデータが同一になるようにします。</block>
  <block id="d78900410b9203071958256c3d6a7701" category="list-text">NFSv3 クライアントホストは、 7-Mode ストレージからプロビジョニングされたソースの NFSv3 エクスポートをアンマウントし、ターゲットの NFSv3 エクスポートを ONTAP からマウントする必要があります。カットオーバーには停止が必要です。</block>
  <block id="6bd42ffcfd349b793e9f6c6f00c18cd8" category="section-title">7-Mode ボリュームの Snapshot コピーを ONTAP に移行する</block>
  <block id="fefac3d628a2abc2d1677e073a0688e7" category="paragraph">このセクションでは、ソースの 7-Mode ボリュームの NetApp Snapshot コピーを ONTAP に移行する手順について説明します。</block>
  <block id="721e28a3edb434ca3d7f37307126504c" category="admonition">ソースの 7-Mode ボリュームがクライアントシステムにエクスポートされてマウントされ、 XCP が Linux システムにすでにインストールされていることを前提としています。Snapshot コピーはボリュームのポイントインタイムイメージであり、前回の Snapshot コピー作成後の差分変更を記録します。7-Mode システムをソースとして「 snap 」オプションを使用します。</block>
  <block id="e18566c8fe02de3e35e48df30daa5189" category="paragraph">* 警告： * ベースの Snapshot コピーを保持します。ベースラインコピーが完了したあとにベース Snapshot コピーを削除しないでください。以降の同期処理にはベースの Snapshot コピーが必要です。</block>
  <block id="50bdf0eaa7b3716343ae0345a98e1a5f" category="list-text">ターゲットクラスタシステムに SVM を作成します。</block>
  <block id="2e4b636c74015de6d92a2eb874c15a88" category="list-text">ターゲット SVM から FCP 、 iSCSI 、 NDMP 、および CIFS の各プロトコルを削除します。</block>
  <block id="c45e0bc468a9249c2954fa84c21f833e" category="list-text">必要に応じて、 SVM を使用して静的ルートを作成します。</block>
  <block id="f35ea333881cef53fcd944d5a052be9d" category="paragraph">ボリュームが正常にマウントされたことを確認します。</block>
  <block id="71c0d546c4569fd9a5798bdbc9729ab6" category="paragraph">volume create コマンドを使用して ' ボリューム・マウント・オプション（ジャンクション・パス）を指定することもできます</block>
  <block id="7ec3f8d8dd165416936305e1ca1530f0" category="list-text">デフォルトの NFS エクスポートポリシーがターゲット SVM に適用されていることを確認します。</block>
  <block id="f69801ea46df8aed1b26399a9330f459" category="list-text">エクスポートポリシールールを変更して、ターゲットシステム上の NFS クライアントへのアクセスを許可します。</block>
  <block id="9fee35c8bded36b1931a6addb7635a81" category="list-text">クライアントがターゲットボリュームにアクセスできることを確認します。</block>
  <block id="7633c6765c7399ce0f1ecbca891fb11c" category="paragraph">ソースの NFSv3 エクスポートは、 XCP スキャン、「 copy 」、および「 sync 」処理の間に読み取り専用モードにすることを推奨します。'sync' 操作では '-snap' オプションに対応する値を渡す必要があります</block>
  <block id="486e9eb5a73ed3d87e070761d3ceeefe" category="list-text">ソースの 7-Mode NFSv3 Snapshot （ベース）をターゲット ONTAP システムの NFSv3 エクスポートにコピーします。</block>
  <block id="160bb3a75d27ad175143123df09bce76" category="admonition">このベース Snapshot は今後の同期処理用に保持します。</block>
  <block id="97ba1a5f7ee8f9243390e46469b6e8f3" category="list-text">コピーが完了したら、ソースとデスティネーションの NFSv3 エクスポートに同一のデータがあることを確認します。「 XCP verify 」コマンドを実行します。</block>
  <block id="44842ca325a3ba46b3b4703a79fab171" category="paragraph">「 ve rify 」でソース・データとデスティネーション・データの違いが検出された場合、「 No such file or directory 」というエラーが要約に報告されます。この問題を修正するには、「 XCP sync 」コマンドを実行して、ソースの変更を宛先にコピーします。</block>
  <block id="030bc6fe403e876e1c932987ece73d61" category="list-text">カットオーバーの前後に、もう一度「ライフル」を実行します。ソースに新規または更新されたデータがある場合は、差分更新を実行します。増分変更がある場合は、これらの変更の新しい Snapshot コピーを作成し、そのスナップショットパスを sync 操作のための「 -snap' 」オプションで渡します。</block>
  <block id="b29cfae254be5e3cfc339ed594ea9378" category="paragraph">--snap オプションとスナップショット・パスを指定して 'XCP sync コマンドを実行します</block>
  <block id="2885d0e1370007423656773743ce189b" category="admonition">この処理にはベース Snapshot が必要です。</block>
  <block id="121dba07a28112a093b812991271c895" category="list-text">NFSv3 クライアントホストは、 7-Mode ストレージからプロビジョニングされたソースの NFSv3 エクスポートをアンマウントし、ターゲットの NFSv3 エクスポートを ONTAP からマウントする必要があります。このカットオーバーには停止が必要です。</block>
  <block id="6db55966f4a2b44c31ed7672f14d023e" category="section-title">ACLv4 を NetApp 7-Mode からネットアップストレージシステムに移行する</block>
  <block id="8f81754856c547fbd3e5295b9da06cc7" category="paragraph">このセクションでは、ソースの NFSv4 エクスポートを ONTAP システムに移行するためのステップバイステップの手順について説明します。</block>
  <block id="fd58e84bd534e0ff49a00942e9ee2002" category="admonition">ソースの NFSv4 ボリュームがクライアントシステムにエクスポートされてマウントされ、 XCP が Linux システムにすでにインストールされていることを前提としています。ソースは、 ACL をサポートする NetApp 7-Mode システムである必要があります。ACL の移行はネットアップからネットアップへのみサポートされます。名前に特殊文字を含むファイルをコピーするには、ソースとデスティネーションが UTF-8 エンコード言語をサポートしていることを確認します。</block>
  <block id="88464fae780b488ca9d39f305a3b3777" category="section-title">ソースの NFSv4 エクスポートを ONTAP に移行するための前提条件</block>
  <block id="078b760bc7ad8cae447a095cc53029af" category="paragraph">ソースの NFSv4 エクスポートを ONTAP に移行する前に、次の前提条件を満たしている必要があります。</block>
  <block id="abb629da0d811e197b383d473d19f265" category="list-text">デスティネーションシステムで NFSv4 を設定しておく必要があります。</block>
  <block id="09e4d7a665b5df121af76a08951028cf" category="list-text">NFSv4 のソースとターゲットが XCP ホストにマウントされている必要があります。NFS v4.0 を選択してソースストレージとターゲットストレージを照合し、ソースシステムとターゲットシステムで ACL が有効になっていることを確認します。</block>
  <block id="c36e1764174e8e6a7791e7afd73f3294" category="list-text">XCP は、 ACL 処理のために、 XCP ホストにソース / ターゲットパスをマウントする必要があります。次の例では、「 vol1 (10.63.5.56:/vol1) 」が「 /mnt/vol1 」パスにマウントされています。</block>
  <block id="baa4716341f52ff4d0642ca1398e16f1" category="section-title">サブディレクトリオプション</block>
  <block id="66f63b7de79aaf05b47a1b63467b2a84" category="paragraph">サブディレクトリを操作するには、次の 2 つのオプションがあります。</block>
  <block id="5d1498ef6a2ee01cb9031bbf8a8dadc4" category="list-text">サブディレクトリ（ /vol1/dir1/DIR11` ）で XCP を動作させるには、 XCP ホストに完全なパス（「 10.63.5.56 ： /vol1/dir1/DIR11` ）をマウントします。</block>
  <block id="39b3225d42725e9616ca3fee7aa7cbb6" category="paragraph">完全なパスがマウントされていない場合、 XCP で次のエラーが報告されます。</block>
  <block id="84274fa575b6d9b0177512a818215d91" category="list-text">次の例に示すように、サブディレクトリ構文 (`m ount: subdirectory/qtree/.snapshot ') を使用します。</block>
  <block id="8dd9bb3f47ac0b27a42761c265b0c720" category="paragraph">ACL v4 を NetApp 7-Mode からネットアップストレージシステムに移行するには、次の手順を実行します。</block>
  <block id="b2f12804e995a318c2272527efb05774" category="paragraph">SVM が正常に作成されたことを確認します。</block>
  <block id="b887d08ec971525ffbfec7f19d01d72d" category="list-text">デフォルトの NFS エクスポートポリシーがターゲット SVM に適用されていることを確認します。</block>
  <block id="1c94e1638450716cd57f55bafd07e60f" category="paragraph">ポリシールールが変更されたことを確認します。</block>
  <block id="132fa7c123291d5007311a22ff8f5654" category="list-text">ターゲットの NFSv4 エクスポートボリュームをこのマウントポイントにマウントします。</block>
  <block id="c686c09824f51c6e681d87d1deb44c71" category="admonition">NFSv4 ボリュームはエクスポートする必要がありますが、 NFS サーバでマウントする必要はありません。マウント可能な場合は、 XCP Linux ホストクライアントでこれらのボリュームをマウントします。</block>
  <block id="e943b6ad310412b689f42adec28acf3a" category="paragraph">ファイルが作成されたことを確認します。</block>
  <block id="35ce5d99ee6b9bb871da972e459e7259" category="list-text">XCP Linux クライアント・ホスト・システムで XCP show コマンドを実行して、ソース NFSv4 エクスポートを照会します。</block>
  <block id="97cc35dcdaf8c5c5fa0e936cd31e9907" category="list-text">ソースの NFSv4 エクスポートパスをスキャンし、ファイル構造の統計を出力します。</block>
  <block id="5073080976611febfcee79295d42232e" category="paragraph">ネットアップでは、「 XCP scan 」、「 copy 」、および「 sync 」の処理中に、ソースの NFSv4 エクスポートを読み取り専用モードにすることを推奨しています。</block>
  <block id="f120bcab91519def54b7b66ee0fbecfe" category="list-text">ソースの NFSv4 エクスポートをターゲット ONTAP システムの NFSv4 エクスポートにコピーします。</block>
  <block id="39ff9cab7c62e62bf182a632271eb700" category="list-text">「 copy 」が完了したら、ソースおよびデスティネーションの NFSv4 エクスポートに同一のデータがあることを確認します。「 XCP verify 」コマンドを実行します。</block>
  <block id="977c8a5f0f7f70041a1c6359c72cb1cd" category="paragraph">「 ve rify 」でソース・データとデスティネーション・データの違いが検出された場合、「 No such file or directory 」というエラーが要約に報告されます。この問題を修正するには、「 XCP sync 」コマンドを実行して、ソースの変更を宛先にコピーします。</block>
  <block id="29aee025cf0bcad3c355bd0aad4516e6" category="admonition">この処理を実行するには、前のコピーインデックス名またはインデックス番号が必要です。</block>
  <block id="ee0fd4f8758695ad7502bee81363478a" category="list-text">以前に中断された「 copy 」操作を再開するには、「 XCP resume 」コマンドを実行します。</block>
  <block id="cdc35fb8de987dae3f48c142ffcb0686" category="section-title">7-Mode の SMB ストレージを ONTAP for CIFS データに移行する</block>
  <block id="74efc43b80fa7a84f709780789176e0d" category="paragraph">このセクションでは、ソースの 7-Mode SMB 共有を ONTAP システムに移行するためのステップバイステップの手順について説明します。</block>
  <block id="f6f758220d5d00061aaa03b99e14785b" category="admonition">7-Mode システムと ONTAP システムに SMB のライセンスが設定されていることを前提としています。デスティネーション SVM が作成され、ソースとデスティネーションの SMB 共有がエクスポートされます。 XCP がインストールされてライセンスが付与されます。</block>
  <block id="281c766457d5499048f9440f61957421" category="list-text">ファイルとディレクトリを含む SMB 共有をスキャンします。</block>
  <block id="95c490ed8cb5d13c961fc2c50c372940" category="list-text">ソースからデスティネーション SMB 共有にファイル（ ACL の有無に関係なく）をコピーします。次に、 ACL を含むコピーの例を示します。</block>
  <block id="dc056263ce0a29568cee559ae8ec35dc" category="admonition">データ・アグリゲートが存在しない場合は 'storage 'aggr create ' コマンドを使用して新しいアグリゲートを作成します</block>
  <block id="7c34f7c35c71ba790649c5563408e77e" category="list-text">ソースとデスティネーションのファイルを同期します。</block>
  <block id="974c1ef10ec8fef5b3ff19989555d061" category="list-text">ファイルが正しくコピーされたことを確認します。</block>
  <block id="8ae319b52e88ea41e78a01efdaab2143" category="inline-link-macro">次の例： ACL を使用した、ソースストレージボックスから ONTAP への CIFS データの移行</block>
  <block id="b6ea874ca7f1192a99c58fa3ff1199ba" category="paragraph"><block ref="b6ea874ca7f1192a99c58fa3ff1199ba" category="inline-link-macro-rx"></block></block>
  <block id="5dc302565fd7f552e134618ee18d2be2" category="summary">この解決策は、特定の日付に基づいてデータをコピーする必要があるお客様を対象としています。</block>
  <block id="07f04efd2f421076b9aa06c4fee83be5" category="doc">データの特定の日付ベースのスキャンおよびコピー</block>
  <block id="7af90e46070dd59c121e31e1525d4af2" category="inline-link-macro">前へ：ファイルを複製します。</block>
  <block id="7f58802ce1d6245244bb449cd961f0f3" category="paragraph"><block ref="7f58802ce1d6245244bb449cd961f0f3" category="inline-link-macro-rx"></block></block>
  <block id="e0b5216bc931e3e5fd7efb74ad10b1d3" category="paragraph">この解決策は、特定の日付に基づいてデータをコピーする必要があるお客様を対象としています。次の情報を確認します。</block>
  <block id="c277b447e2e86b92f26c7dbcf8fecdf2" category="inline-link-macro">次の手順： SMB / CIFS 共有からの CSV ファイルの作成</block>
  <block id="7a9653d25343b8ddab24257e57b5be7a" category="paragraph"><block ref="7a9653d25343b8ddab24257e57b5be7a" category="inline-link-macro-rx"></block></block>
  <block id="89bddd14a9f02aeace6d5ffadf25e4f3" category="summary">このドキュメントでは、 NetApp XCP のベストプラクティスのガイドラインとテストシナリオベースの解決策について説明します。これらのベストプラクティスは、オンプレミス向けの移行ワークフローと、クラウド、ファイルシステム分析、トラブルシューティング、および XCP のパフォーマンス調整を対象としています。</block>
  <block id="e7b1326bcbbf0b5513213b2373b5721a" category="doc">TR-4863 ：『 Best Practice Guidelines for NetApp XCP - Data Mover 、 File Migration 、 and Analytics 』</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">ネットアップ Karthikeyan Nagalingam</block>
  <block id="88d20f11fbf1788b5271fcc5d5297a41" category="paragraph">このドキュメントでは、 NetApp XCP のベストプラクティスのガイドラインとテストシナリオベースの解決策について説明します。これらのベストプラクティスは、オンプレミスの移行ワークフローと、クラウド、ファイルシステム分析、トラブルシューティング、および XCP のパフォーマンス調整を対象としています。テストシナリオのセクションでは、お客様のユースケースとその要件、 XCP を使用した NetApp 解決策、およびお客様へのメリットについて説明します。</block>
  <block id="842b5068483a5cd5b058644a5d000f1c" category="inline-link-macro">次： NetApp XCP 。</block>
  <block id="10dbc4bbbec11552354dca73bcd59c78" category="paragraph"><block ref="10dbc4bbbec11552354dca73bcd59c78" category="inline-link-macro-rx"></block></block>
  <block id="7e0710b4cb48030b7a4c065128b88194" category="summary">このセクションでは、セキュリティ情報を含む CIFS データをソース ONTAP システムからターゲット CIFS システムに移行するためのステップバイステップ形式の手順について説明します。</block>
  <block id="82f0875c37eacadc40a7a7fb2a6b6313" category="doc">ACL を使用した、ソースストレージボックスから ONTAP への CIFS データの移行</block>
  <block id="0f17f55a868185c28a66d0817a780f53" category="inline-link-macro">Previous ： 7-Mode から ONTAP へのデータマイグレーションを示します。</block>
  <block id="99b2c0d3f328317650f8748e47c7bedb" category="paragraph"><block ref="99b2c0d3f328317650f8748e47c7bedb" category="inline-link-macro-rx"></block></block>
  <block id="c55bb6c3381ca2d8a4016e387cc62883" category="list-text">SMB クライアント要求を処理するデータ LIF を作成します。</block>
  <block id="5368b7f480b92b4a2a9b475e6e9cf953" category="list-text">ターゲットのデータボリュームを SVM ネームスペースにマウントします。</block>
  <block id="18f8848c17d02fd34b293885d5d3a215" category="list-text">ターゲット SVM で CIFS サービスを開始します。</block>
  <block id="cf1269d629dc2110f2ae65edf8662b79" category="list-text">デフォルトのエクスポートポリシーがターゲット SVM に適用されていることを確認します。</block>
  <block id="74e1ca9e0b551a7349207f3d546b9f51" category="list-text">CIFS クライアントへのアクセスを許可するようにエクスポートポリシールールを変更します。</block>
  <block id="3c19a2ac394a25f9ace05db18ad86c8b" category="paragraph">ポリシールールが変更されたことを確認します。</block>
  <block id="876afc73f4771f46cfc9dba7fb687744" category="list-text">XCP がインストールされている Windows クライアントシステムに接続します。XCP のインストールパスを参照します。</block>
  <block id="e73a44af938fa16a4816d3639d2f3b69" category="list-text">XCP Windows クライアント・ホスト・システムで XCP show コマンドを実行して、ソース・ノードの SMB エクスポートを照会します。</block>
  <block id="7132ef955ec5e0151ccd0790da2551d7" category="list-text">コピーのために 'help' コマンドを実行します</block>
  <block id="268b71a144890a49d97f8ca062fd48f9" category="list-text">ターゲット ONTAP システムで、「 fallback-user 」および「 fallback-group 」引数パスの値として指定する必要があるローカルユーザおよびローカルグループ名のリストを取得します。</block>
  <block id="ac9ad1198db0fb6f730a1f3aa97c35ab" category="list-text">ACL を持つ CIFS データをソースからターゲットに移行するには 'acl' および– fallback-user/group' オプションを指定して 'XCP copy' コマンドを実行します</block>
  <block id="a53e836d6264ad1778a4e1a7ae34f58c" category="paragraph">「 fallback-user/group 」オプションには、 Active Directory またはローカルユーザ / グループ内のターゲットシステムに存在する任意のユーザまたはグループを指定します。</block>
  <block id="9aa080e55cad2c9968cc50de60a3f88e" category="list-text">「 XCP copy 」で「 error failed to obfallback security principal 」 ( フォールバックセキュリティプリンシパルの取得に失敗しました ) というエラーメッセージが表示された場合は、 hosts ファイルに宛先ボックスを追加します (C:\Windows\System32\drivers\etc\hosts) 。</block>
  <block id="b7ceaa0e08e9de5bf76572a50529f752" category="paragraph">ネットアップストレージのデスティネーションボックスのエントリには、次の形式を使用します。</block>
  <block id="569ccf25ad533b79cf2f639f0326d943" category="list-text">hosts ファイルに destination box エントリを追加した後にエラーメッセージ「 error failed to get fallback security principal 」が表示される場合は、ターゲットシステムにユーザ / グループが存在しません。</block>
  <block id="4a909d1b3a171fdcddc8da070e839ecc" category="list-text">ACL を持つ CIFS データを移行するには 'XCP copy' を使用します（ルート・フォルダを使用するかどうかは関係ありません）</block>
  <block id="a4ebb620bc1fbff4f93249967cd47f4b" category="paragraph">ルートフォルダを使用せずに、次のコマンドを実行します。</block>
  <block id="f6c1a65a9150853333bf43b4a6dc9e5b" category="paragraph">ルートフォルダを使用して、次のコマンドを実行します。</block>
  <block id="154ef40d43f003733406aef6be0ada62" category="inline-link-macro">次のステップ：ベストプラクティスのガイドラインと推奨事項</block>
  <block id="7fd167e59284838d9e36c5c99e4d2943" category="paragraph"><block ref="7fd167e59284838d9e36c5c99e4d2943" category="inline-link-macro-rx"></block></block>
  <block id="dc0b758a04bbb9e380300887d831e4e1" category="summary">ここでは、 XCP 処理のパフォーマンス向上に役立つチューニングパラメータをいくつか紹介します。</block>
  <block id="9db3ca538820d0cfb7b44ef80f16ca98" category="doc">パフォーマンスの調整</block>
  <block id="7931b9aae255139b42cb605b3b62a6db" category="inline-link-macro">前のバージョン：サイジングのガイドライン</block>
  <block id="0ff4824165c6661bc016402e35d2a9fe" category="paragraph"><block ref="0ff4824165c6661bc016402e35d2a9fe" category="inline-link-macro-rx"></block></block>
  <block id="ec6136417c258c9b7f95c39765c5ca51" category="paragraph">このセクションでは、 XCP 処理のパフォーマンスを向上させるために役立つチューニングパラメータをいくつか説明します。</block>
  <block id="dd10b781bf6dd686a8631401ce0fba96" category="list-text">拡張性を高め、ワークロードを複数の XCP インスタンスに分散させるには、移行とデータ転送用に各 XCP インスタンスのサブフォルダを分割します。</block>
  <block id="37e9b10f81fe31cb6b80609f724b34f8" category="list-text">XCP では最大 CPU リソースを使用できます。 CPU コア数が多いほど、パフォーマンスが向上します。そのため、 XCP サーバに追加の CPU が必要です。テストでは 128GB の RAM と 48 個のコア CPU を使用し、 8 倍の CPU と 8 GB の RAM に比べてパフォーマンスが向上しました。</block>
  <block id="a174d00dcd4849e0653429de84c71cde" category="list-text">Azure NetApp Files の場合、パフォーマンスはサービスレベルによって異なります。詳細については、次の表を参照してください。この表には、 Azure NetApp Files のサービスレベルとパフォーマンスの詳細が表示されます。</block>
  <block id="6d59be48f566a73e053e12167b279be5" category="cell">サービスレベル</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">標準</block>
  <block id="8d5e7e72f12067991186cdf3cb7d5d9d" category="cell">Premium サービス</block>
  <block id="7057376a419b3334cc7b8b7a9f064abb" category="cell">ウルトラ</block>
  <block id="0b85467ebafa7ca3c47e82dc38184484" category="cell">スループット</block>
  <block id="adcda45ec4de9aeb48e1893272b078d1" category="cell">1 テラバイトあたり 16mbps</block>
  <block id="93209d2e9d1ed8d87a279cef886b5021" category="cell">TB あたり 64MBps</block>
  <block id="f646efbbd60d091e92b32611965c4f1c" category="cell">TB あたり 128MBps</block>
  <block id="4a9cc851fc41c5762618832386fa4937" category="cell">ワークロードのタイプ</block>
  <block id="11969136028e1ffaeed70de5e59bde33" category="cell">汎用ファイル共有、 E メール、 Web</block>
  <block id="76ab8c335a6bb24396ea1953bac75705" category="cell">BMS 、データベース、およびアプリケーション</block>
  <block id="9dab8e594b90062c0612cbb1676234ba" category="cell">レイテンシの影響を受けやすいアプリケーション</block>
  <block id="0a568304277380e4cfb0f2d2abbd99b4" category="cell">パフォーマンスの説明</block>
  <block id="c55268b956eecd1d58f60723a410c808" category="cell">標準パフォーマンス： 1TB あたり 1 、 000 IOPS （ 16K I/O ）と TB あたり 16mbps</block>
  <block id="536d2154a9035458ae8efd38b24f3ea7" category="cell">優れたパフォーマンス– TB あたり 4 、 000 IOPS （ 16 、 000 I/O ）、 TB あたり 64MBps</block>
  <block id="91ff77656b0dc231fcbe8f488a15a253" category="cell">卓越したパフォーマンス： TB あたり 8 、 000 IOPS （ 16 、 000 I/O ）、 128MBps / TB</block>
  <block id="121bc30e927e8a3d918fc90c0ec18fee" category="paragraph">スループットとワークロードのタイプに基づいて適切なサービスレベルを選択する必要があります。ほとんどのお客様は Premium レベルから始めて、ワークロードに基づいてサービスレベルを変更します。</block>
  <block id="f44706d8f59ec82b48b083fb246a4fc7" category="inline-link-macro">次のステップ：お客様のシナリオ</block>
  <block id="bb0eaaf9fa62e9175efd3145f00946ea" category="paragraph"><block ref="bb0eaaf9fa62e9175efd3145f00946ea" category="inline-link-macro-rx"></block></block>
  <block id="4b1c76979225b75a8e5f476356ed17e8" category="paragraph">ネットアップで VMware を利用するには：まずはここから</block>
  <block id="d7b056332bb039010d62c71ede534471" category="paragraph">VMware 環境の変革を開始する準備ができたら、最新の解決策の概要をご覧ください。また、最新のテクニカルソリューションと製品デモもご覧いただけます。次のステップに進む準備が整ったら、ネットアップや VMware のエキスパートコミュニティと連携して、データセンターの最新化、ハイブリッドクラウド、コンテナ化されたアプリケーションへの取り組みの計画と実行を支援します。</block>
  <block id="be52ccc9c4dbcee449a6257062c0bcda" category="paragraph">どこから始めるべきかわからない場合は、 <block ref="dcd7ec98fb935d9a5fd8ade723a47456" category="inline-link-macro-rx"></block> ネットアップの VMware エキスパートのメンバーです。</block>
  <block id="27b7a196b8196df4eeee9d21ade20a45" category="inline-link-macro">PDF 形式</block>
  <block id="e2fd99d21fbe7a1b2ed6388c40d48b0f" category="admonition">このページに表示されるコンテンツは、からもダウンロードできます <block ref="a182addaadbc8a97de909268c8dc9bf0" category="inline-link-macro-rx"></block>。</block>
  <block id="9d0be07780aeb437025d4b3420d12540" category="sidebar">NetApp XCP データ移行</block>
  <block id="68dfe5056c735db544868f482f9f1d6f" category="sidebar">NetApp XCP のベストプラクティスガイドライン</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="sidebar">お客様のシナリオ</block>
  <block id="c5071cdf8081474104ef1eee5ec6d784" category="sidebar">ACL を使用した、ソースストレージボックスから ONTAP への CIFS データの移行</block>
  <block id="211c181ce8e8cb0472af3095c66dc5eb" category="paragraph"><block ref="211c181ce8e8cb0472af3095c66dc5eb" category="inline-link-macro-rx"></block></block>
  <block id="7480aca6b5f94dc27cc94b015284d5e9" category="paragraph"><block ref="7480aca6b5f94dc27cc94b015284d5e9" category="inline-link-macro-rx"></block></block>
  <block id="6be5bc354916244292cf704d8a451541" category="inline-link-macro">ビデオ： Workload Migration Using Astra Control Center - Red Hat OpenShift with NetApp</block>
  <block id="b0fd8947f538fb2988e86d35bac6d6fa" category="list-text"><block ref="b0fd8947f538fb2988e86d35bac6d6fa" category="inline-link-macro-rx"></block></block>
  <block id="c0a8420c339dd9d57d40448c30a749df" category="inline-link-macro">ビデオ： Workload Migration Using Astra Trident and SnapMirror - Red Hat OpenShift with NetApp</block>
  <block id="a43d8fe0429e313d082e6919f1fd2b75" category="list-text"><block ref="a43d8fe0429e313d082e6919f1fd2b75" category="inline-link-macro-rx"></block></block>
  <block id="344aeea955e7674b99b8e8db2354133d" category="doc">Astra Control Center を使用したワークロードの移行：ネットアップを使用した Red Hat OpenShift</block>
  <block id="7527b11aa1f9aa169a9d6103e9c4c417" category="paragraph">Azure NetApp Files 、 Rapids 、 Dask は、 Docker や Kubernetes などのオーケストレーションツールと統合することで、大規模な ML 処理とトレーニングの導入を高速化し、簡易化します。エンドツーエンドのデータパイプラインを統合する解決策ことで、多くの高度なコンピューティングワークロードに特有のレイテンシと複雑さを軽減し、開発と運用のギャップを効果的に解消します。データサイエンティストは、大規模なデータセットでクエリを実行し、トレーニングフェーズ中にデータやアルゴリズムのモデルを他のユーザーと安全に共有できます。</block>
  <block id="a93fc9ba708498e20819f22e22ecfa5c" category="paragraph">クラウドにエンドツーエンドの分散トレーニングモデルとデータパイプラインを構築することで、 GPU によって高速化されたデータ処理フレームワークやコンピューティングフレームワークを活用していない従来のオープンソースアプローチと比較して、ワークフロー全体の完了時間が 2 桁向上することを実証しました。</block>
  <block id="fcceee9f9e65e4b0d089c6c433f6c191" category="paragraph">ネットアップ、 Microsoft 、オープンソースのオーケストレーションフレームワーク、 NVIDIA を組み合わせることで、最新テクノロジをマネージドサービスとして統合し、優れた柔軟性を実現してテクノロジの採用を促進し、新しい AI / ML アプリケーションの市場投入期間を短縮できます。これらの高度なサービスはクラウドネイティブ環境で提供され、オンプレミス環境やハイブリッド導入アーキテクチャで簡単に移行できます。</block>
  <block id="b622f3d3bde9c5202a2be0c23982e0b2" category="paragraph">このユースケースは、一般に公開されているに基づいています<block ref="f00b4c49198828625540594bcd2c0e57" category="inline-link-rx"></block> データセットの作成元<block ref="3ba217c046bd683ab55f300076736b4a" category="inline-link-rx"></block>。ML プラットフォームとアプリケーションの最近の進歩により、現在は大規模な学習が注目されています。クリックスルー率（ CTR ）は、オンライン広告インプレッション数 100 件あたりの平均クリックスルー数（パーセンテージ）と定義されています。デジタルマーケティング、小売、 E コマース、サービスプロバイダなど、さまざまな業界やユースケースで重要な指標として広く採用されています。CTR を潜在的な顧客トラフィックの重要な指標として使用する例を以下に示します。</block>
  <block id="d86cf69a8b82547a94ca3f6a307cf9a6" category="inline-link">Google アナリティクス</block>
  <block id="fe123d76ac9bec74ba2056b6a34fbf5d" category="inline-link">広告ランク</block>
  <block id="747d705222dc64c89cfadd75a9792b30" category="list-text">* デジタルマーケティング :* インチ<block ref="6c9e2e85af2f8f35c64de5000ebda91e" category="inline-link-rx"></block>、 CTR は、広告主または販売主のキーワード、広告、および無料リストがどの程度効果を発揮しているかを測定するために使用できます。クリック率が高いと、ユーザーは広告やリストを便利で関連性の高いものとして見つけることができます。CTR はまたあなたのキーワードの予想される CTR に貢献する、の構成要素である<block ref="428c3403a03510f9dc338448b285e764" category="inline-link-rx"></block>。</block>
  <block id="8a2e97f5a0cefdd4b76863bdd3773fb2" category="list-text">* e- コマース： * 活用に加えて<block ref="8785133d6074d4ab5f5345c36bc35a21" category="inline-link-rx"></block>E コマースバックエンドには、少なくともいくつかの訪問者統計情報があります。これらの統計情報は一目見すると有用ではないように見えますが、通常は読みやすく、他の情報よりも正確な情報になる可能性があります。このような統計で構成されるファーストパーティデータセットは独占的なものであり、 E コマースの販売者、購買担当者、プラットフォームに最も関連性があります。これらのデータセットは、ベンチマークの設定に使用でき、過去 1 年と過去 1 日の間に結果を比較するために、さらに詳細な分析を行うための時系列を作成します。</block>
  <block id="5737cd832bf93fd33459cf0a04787441" category="list-text">* 小売： * 実店舗の小売業者は、訪問者数と顧客数を CTR に関連付けることができます。お客様の数は、販売時点の履歴から確認できます。小売業者のウェブサイトや広告トラフィックの CTR が、前述の売上につながる可能性があります。ロイヤルティプログラムは、オンライン広告や他の Web サイトからリダイレクトされたお客様が報奨を獲得するために参加する可能性があるため、別のユースケースです。小売業者は、ロイヤルティプログラムを通じて顧客を獲得し、販売履歴から行動を記録することで、さまざまなカテゴリーで消費者の購買行動を予測するだけでなく、クーポンをパーソナライズし、チャーンを減らす推奨システムを構築できます。</block>
  <block id="32c14bcab423a033bf540425e236d3e6" category="list-text">* 通信事業者とインターネット・サービス・プロバイダーは、豊富なデータを提供するファーストパーティのユーザー・テレメトリ・データを使用して、洞察に富んだ AI 、 ML 、分析のユースケースを実現しています。たとえば、携帯電話会社の Web 閲覧のトップレベルのドメイン履歴ログを毎日活用して、既存のモデルを微調整して最新のオーディエンスセグメンテーションを作成したり、顧客の行動を予測したり、リアルタイム広告を配置してオンライン体験を向上させることができます。このようなデータ主導のマーケティングワークフローでは、 CTR はコンバージョンを反映する重要な指標です。</block>
  <block id="78ae79f63f58a3ac75e77e3a075fd19e" category="inline-link">Crito Terabyte のログをクリックします</block>
  <block id="deb698cbe7918324e2e1564708266732" category="paragraph">デジタルマーケティングの文脈では、<block ref="cc065865c19a3af4babfdf02c1c6b55d" category="inline-link-rx"></block> 現在は、 ML プラットフォームとアルゴリズムのスケーラビリティを評価する際の参考データセットとなっています。広告主は、クリックスルーレートを予測することで、広告に対応する可能性が最も高い訪問者を選択し、閲覧履歴を分析し、ユーザーの関心に基づいて最も関連性の高い広告を表示できます。</block>
  <block id="5f326be91a09bc93ca87444e834df2a6" category="paragraph">このテクニカルレポートで紹介する解決策には、次のようなメリットがあります。</block>
  <block id="e150c8d445e71cda899957943e39b75f" category="list-text">分散型トレーニング用 Dask 並列コンピューティングフレームワーク</block>
  <block id="ec61531814ab09c5338813eecc764692" category="paragraph">Rapids AI と Azure NetApp Files をベースに構築されたエンドツーエンドのワークフローでは、ランダムフォレストモデルのトレーニング時間が 2 桁単位で大幅に短縮されたことが示されています。この点は、構造化された表形式データが 45 GB （平均）の実世界のクリックログを毎日処理する場合の従来の Pandas アプローチと比べて大幅に改善されています。これは、約 20 億行を含む DataFrame に相当します。このテクニカルレポートでは、クラスタ環境のセットアップ、フレームワークとライブラリのインストール、データのロードと処理、従来型のトレーニングと分散型のトレーニング、可視化と監視について説明し、重要なエンドツーエンドのランタイム結果を比較します。</block>
  <block id="0359d40b3d1a900a1841f1e8bd783cd5" category="doc">TR-4904 ：『 Distributed Training in Azure - Click Through Rate Prediction 』</block>
  <block id="1863627f5be51826024a24014fce26ff" category="sidebar">Azure での分散トレーニング - クリックスルー率予測</block>
  <block id="458df51beb3b33cfa61bdc8725403f5b" category="sidebar">Jupyter ノートブック ( リファレンス用 )</block>
  <block id="8d7efa937e97b1a8187ff8f122d9732a" category="sidebar">クラウドベースの VMware 環境向けにストレージを最適化</block>
  <block id="5a6bd3a9e0048284caf2b5f521d90959" category="list-text"><block ref="5a6bd3a9e0048284caf2b5f521d90959" category="inline-link-macro-rx"></block></block>
  <block id="2625fb6375d503af481868caf90606c9" category="summary">このセクションでは、本テクニカルレポートに関連する 2 つの Jupyter ノートブックへのリンクを示します。</block>
  <block id="91409fc3ebd20becb4eb816cbcceb02e" category="doc">Jupyter ノートブックを参考にしてください</block>
  <block id="cdd5560e07964d04d88721f16446a3b6" category="paragraph">このテクニカルレポートには、 Jupyter ノートブックが 2 つ関連付けられています。</block>
  <block id="1490d9a5ddbc6bcbe6cedaa01eb50f99" category="inline-link-macro">*CTR - PandasRF - 照合済み。 ipynb. *</block>
  <block id="562c7333f0fea5590cfeb818a55e6557" category="list-text"><block ref="6f686a9606ae64621340ea0a5e72dfde" category="inline-link-macro-rx"></block> このノートブックは Crito Terabyte Logs データセットから 15 日目を読み込み、データを Pandas DataFrame に処理してフォーマットし、 Scikit-learn ランダムフォレストモデルのトレーニングを行い、予測を実行し、精度を計算します。</block>
  <block id="c0cb1f1199ae4e4bdfa626e26a5a25cd" category="inline-link-macro">* Crito_dAsk _RF.ipynb.*</block>
  <block id="fa93cb17bf7778768ccae778487bf90d" category="list-text"><block ref="01d86d8522c2722466fcbda71181d3ff" category="inline-link-macro-rx"></block> このノートブックは Crito Terabyte Logs データセットから 15 日目をロードし、データを Dask cuDF に処理してフォーマットし、 Dask cuML ランダムフォレストモデルのトレーニングを行い、予測を実行し、精度を計算します。GPU を搭載した複数のワーカーノードを活用することで、この分散データとモデルの処理とトレーニングのアプローチを非常に効率的に行うことができます。処理するデータが多いほど、従来の ML アプローチに比べて時間を大幅に節約できます。このノートブックは、ネットワークセットアップによってデータやモデルの配布が自由に移動できる限り、クラウド、オンプレミス、または Kubernetes クラスタにコンピューティングとストレージが異なる場所に配置されているハイブリッド環境に導入できます。</block>
  <block id="95e5ff389c2796a171f904ad5b9322f6" category="list-text">ネットアップと VMware Cloud Foundation （ VCF ）</block>
  <block id="81cd1d42ffdb75544144e24cf0f8dc54" category="inline-link-macro">パート 1 ：はじめに</block>
  <block id="837bbffc16dc6e344470df1114a13c87" category="list-text"><block ref="837bbffc16dc6e344470df1114a13c87" category="inline-link-macro-rx"></block></block>
  <block id="0437c596200f9be8466a3200f5cf2438" category="inline-link-macro">パート 2 ： VCF および ONTAP プリンシパルストレージ</block>
  <block id="e361fc9a6477c5857207bca25b3d797f" category="list-text"><block ref="e361fc9a6477c5857207bca25b3d797f" category="inline-link-macro-rx"></block></block>
  <block id="14c9e898417d6b3caceb9c60335c4bb3" category="inline-link-macro">パート 3 ： VCF およびエレメントプリンシパルストレージ</block>
  <block id="aa37de763ea804c1fb3fe637fb6ee5ef" category="list-text"><block ref="aa37de763ea804c1fb3fe637fb6ee5ef" category="inline-link-macro-rx"></block></block>
  <block id="fbbcbe8b70235742e3e6aa656c7815d9" category="inline-link-macro">パート 4 ： VMware 用の ONTAP ツールと追加ストレージ</block>
  <block id="de8f12d6d2f85119918d1bbb774d43c8" category="list-text"><block ref="de8f12d6d2f85119918d1bbb774d43c8" category="inline-link-macro-rx"></block></block>
  <block id="00d07ce14f227693b9dabba2f52b53a5" category="inline-link-macro">ネットアップベースのクラウドサービスで Azure VMware 解決策を使い始めましょう</block>
  <block id="ac66988ead29ba5f4ed32ec3894527e7" category="list-text"><block ref="ac66988ead29ba5f4ed32ec3894527e7" category="inline-link-macro-rx"></block></block>
  <block id="3123a26626e19f387157faf3a8e35e86" category="list-text">Red Hat OpenShift クラスタにクラスタ管理者アクセス権限が必要です。</block>
  <block id="abfe00e88b26a267771078e0295b1573" category="admonition">Docker をインストールする場合は、 20.10 よりも前のバージョンの Docker 、 Podman をインストールする場合は、バージョン 3.0 よりも前の podman が必要です。</block>
  <block id="e2f745ac603721ed9903b0acea00d059" category="admonition">「 kubeadmin 」ユーザを使用してプライベートレジストリにログインしている場合は、「 podman login -u OCP -user -p token --tls-verify=false astra-registry.apps.ocp-vmw.cie.netapp.com` 」の代わりにトークンを使用します。</block>
  <block id="e4b91f5b748fa6ef8813d2871257b134" category="admonition">または、サービスアカウントのトークンを使用して、サービスアカウントを作成し、（プッシュアクセスまたはプルアクセスが必要かどうかに応じて）レジストリエディタまたはレジストリビューアロールを割り当て、レジストリにログインすることもできます。</block>
  <block id="ad533c54cadd80fbf8f60e58b7d3abd6" category="admonition">「 kubeadmin 」ユーザを使用してプライベートレジストリにログインする場合は、「 password - `d Occker login -u OCP-user-p token astra-registry.apps.ocp-vmw.cie.netapp.com` 」の代わりにトークンを使用します。</block>
  <block id="4324c8f0a70a221bdde33868774e5a76" category="list-text">Astra Control Center Operator CR 'Astra_control_center_deployment.yaml ' を編集します Astra Control Center は ' すべてのリソースを配備しますオペレータ CR で 'acc-operator-controller-managor' の配備定義を検索し ' イメージをレジストリにプッシュする際に指定した組織名とともに ' レジストリの FQDN を入力します ( この例では astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra` ) テキスト 'Astra_image_registry' を置き換えて 'imagePullSecret' セクションで作成したシークレットの名前を指定しますオペレータのその他の詳細を確認し、保存して閉じます。</block>
  <block id="0f436b7e192eae471d7abf1265bb4c02" category="list-text">Astra Control Center GUI に、 FQDN を参照してログインします。</block>
  <block id="8b2aacc194c3dc4c36ce93a57e31685c" category="list-text">現在のデフォルトストレージクラスからデフォルトのアノテーションを削除し、 OpenShift クラスタの Trident バック対象ストレージクラスをデフォルトとしてアノテートします。</block>
  <block id="53557215e4d209eda16495dbe5f7c505" category="paragraph">+ 注 : 「 kubeadmin 」ユーザを使用してプライベートレジストリにログインする場合は、パスワードの代わりにトークンを使用します。</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">このセクションでは、この AI 解決策の技術基盤について説明します。</block>
  <block id="42b507999e258502c07acce91c03de9f" category="paragraph"><block ref="42b507999e258502c07acce91c03de9f" category="inline-link-macro-rx"></block></block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">最先端の NetApp AFF ストレージシステムにより、 AI 推論をエッジで導入することで、業界をリードするパフォーマンス、卓越した柔軟性、クラウド統合、業界最高クラスのデータ管理機能を備えたエンタープライズストレージの要件を満たすことができます。ネットアップの AFF システムはフラッシュに特化して設計されており、ビジネスクリティカルなデータの高速化、管理、保護に役立ちます。</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">エントリレベルの NetApp AFF ストレージシステムは、 FAS2750 のハードウェアと SSD フラッシュメディアに基づいています</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">HA 構成の場合は 2 台のコントローラ</block>
  <block id="7df12cd193e8452ed6fc45ca8bcd3771" category="paragraph"><block ref="7df12cd193e8452ed6fc45ca8bcd3771" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">ネットアップのエントリレベルの AFF C190 ストレージシステムは、次の機能をサポートしています。</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">960GB SSD を最大で 24 本搭載できます</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">次の 2 つの構成が可能です</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">イーサネット（ 10GbE ）： 10GBASE-T （ RJ-45 ）ポート × 4</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">ユニファイド（ 16Gb FC または 10GbE ）：ユニファイドターゲットアダプタ 2 （ UTA2 ）ポート × 4</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">最大 50.5TB の実効容量</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">NAS ワークロードの場合、エントリレベルの AFF C190 システム 1 台で、シーケンシャルリードの場合は 4.4GBps 、スモールランダムリードの場合は 230K IOPS が 1 ミリ秒以下のレイテンシでサポートされます。</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">ネットアップは、他のエントリレベルストレージシステムも提供しています。このシステムは、大規模な環境にも対応できる優れたパフォーマンスと拡張性を提供します。NAS ワークロードの場合、 1 つのエントリレベルの AFF A220 システムで次のことがサポートされます。</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">シーケンシャルリードのスループットは 6.2GBps です</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">1 ミリ秒以下のレイテンシでスモールランダムリードの IOPS 値 375K</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">960GB 、 3.8TB 、 7.6TB の SSD の最大ドライブ数： 144x</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220 は、 1PB を超える実効容量にまで拡張できます</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">最大実効容量は 35PB で、最大スケールアウト構成は 2~24 ノード（ HA ペア × 12 ）</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">AFF A220 と比較して、パフォーマンスが 45% 以上向上します</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440 万 IOPS のランダムリード： 1 ミリ秒</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">最新のネットアップ ONTAP リリース ONTAP 9.8 を基盤としています</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">HA とクラスタインターコネクトに 25GB のイーサネットを利用しています</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">NetApp E シリーズ EF システム</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">EF シリーズは、エントリレベルとミッドレンジのオールフラッシュ SAN ストレージアレイファミリーです。データへのアクセスを高速化し、 NetApp SANtricity ソフトウェアを使用してデータから迅速に価値を引き出すことができます。SAS と NVMe の両方のフラッシュストレージを搭載し、低コストで卓越した IOPS 、 100 マイクロ秒未満の応答時間、最大 44GBps の帯域幅を実現します。これらのシステムは、混在ワークロードや、 AI 推論やハイパフォーマンスコンピューティング（ HPC ）などの要件の厳しいアプリケーションに最適です。</block>
  <block id="51ffc2dfd09bb521be00106f197d1009" category="paragraph"><block ref="51ffc2dfd09bb521be00106f197d1009" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">32Gb / 16Gb FC 、 25Gb / 10Gb iSCSI 、 12Gb SAS に対応しています</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">最大実効容量は 96 本のドライブで合計 1.5PB です</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">10Gbps のスループット（シーケンシャルリード）</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">30 万 IOPS （ランダムリード）</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">NetApp EF280 は、ネットアップポートフォリオの中で最も低コストのオールフラッシュアレイ（ AFA ）です</block>
  <block id="44114b1635cead15f56735bad0467251" category="section-title">NetApp EF300</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">合計容量 367TB の NVMe SSD を 24 本搭載</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">拡張オプションは合計で 240x NL-SAS HDD 、 96x SAS SSD 、またはその組み合わせです</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100Gb NVMe/IB 、 NVMe/RoCE 、 iSER/IB 、および SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32Gb NVMe/FC 、 FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">25Gb iSCSI です</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20GBps （シーケンシャルリード）</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670K IOPS （ランダムリード）</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">NetApp EF シリーズ NetApp EF シリーズオールフラッシュアレイ EF600 、 F300 、 EF570 、 EF280 のデータシート</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">詳細については、を参照してください<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block>。</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">データ管理を簡易化</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">データ管理は、アプリケーションやデータセットに適切なリソースを使用できるようにするために、エンタープライズ IT 運用にとって非常に重要です。ONTAP には、運用を合理化および簡易化し、総運用コストを削減するための次の機能が含まれています。</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">* インラインデータコンパクションと重複排除の強化。 * データコンパクションはストレージブロック内の無駄なスペースを削減し、重複排除は実効容量を大幅に増やします。この環境データはローカルに格納され、データはクラウドに階層化されます。</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">* 最小、最大、アダプティブの Quality of Service （ AQoS ）。 * きめ細かいサービス品質（ QoS ）管理機能により、高度に共有された環境で重要なアプリケーションのパフォーマンスレベルを維持できます。</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool 。 * この機能は、 Amazon Web Services （ AWS ）、 Azure 、 NetApp StorageGRID ストレージ解決策などのパブリックおよびプライベートクラウドストレージオプションへのコールドデータの自動階層化を提供します。FabricPool の詳細については、を参照してください <block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block>。</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">データの高速化と保護</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 は、卓越したパフォーマンスとデータ保護を実現し、以下の方法でこれらの機能を拡張します。</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">* パフォーマンスと低レイテンシ。 * ONTAP は、可能な限り低いレイテンシで最高のスループットを提供します。</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* NetApp Volume Encryption （ NVE ）。 * ONTAP は、オンボードと外部キー管理の両方をサポートし、ボリュームレベルでのネイティブな暗号化を実現します。</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">* マルチテナンシーと多要素認証。 * ONTAP により、インフラリソースを最高レベルのセキュリティで共有できます。</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">将来のニーズにも対応できるインフラ</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 には次の機能が搭載されており、要件が厳しく、絶えず変化するビジネスニーズに対応できます。</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">* シームレスな拡張とノンストップオペレーション。 * ONTAP は、既存のコントローラとスケールアウトクラスタに無停止で容量を追加できます。NVMe や 32Gb FC などの最新テクノロジへのアップグレードも、コストのかかるデータ移行やシステム停止を行わずに実行できます。</block>
  <block id="0cee26e8172666a9085f957269fc4b64" category="list-text">* クラウドへの接続。 * ONTAP は、すべてのパブリッククラウドで Software-Defined Storage （ ONTAP Select ）とクラウドネイティブインスタンス（ NetApp Cloud Volumes Service ）を選択できる、最もクラウドに接続されたストレージ管理ソフトウェアです。</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">* 新しいアプリケーションとの統合。 * ONTAP は、既存のエンタープライズアプリケーションをサポートする同じインフラストラクチャを使用して、自律走行車、スマートシティ、インダストリー 4.0 などの次世代プラットフォームやアプリケーションにエンタープライズクラスのデータサービスを提供します。</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">NetApp E シリーズ SANtricity ソフトウェアのデータシート</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity は、 E シリーズハイブリッドフラッシュと EF シリーズオールフラッシュアレイに業界をリードするパフォーマンス、信頼性、シンプルさを提供するように設計されています。E シリーズハイブリッドフラッシュアレイと EF シリーズオールフラッシュアレイのパフォーマンスと利用率を最大限に高め、データ分析、ビデオ監視、バックアップとリカバリなどの高負荷のアプリケーションに対応します。SANtricity を使用すると、ストレージをオンラインにしたまま、設定の調整、メンテナンス、容量の拡張などのタスクを実行できます。SANtricity は、優れたデータ保護、プロアクティブな監視、認定済みのセキュリティも提供します。いずれも使いやすい標準搭載の System Manager インターフェイスからアクセスできます。詳細については、を参照してください<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block>。</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">パフォーマンスの最適化</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">パフォーマンスが最適化された SANtricity ソフトウェアは、データ分析、ビデオ監視、バックアップのすべてのアプリケーションに、高い IOPS 、高いスループット、低レイテンシを実現します。高 IOPS 、低レイテンシのアプリケーション、広帯域幅、高スループットのアプリケーションのパフォーマンスを向上</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">アップタイムを最大限に向上</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">ストレージをオンラインにしたまま、すべての管理タスクを実行できます。構成の調整、メンテナンス、容量の拡張を、 I/O を中断せずに実行できます自動化機能、オンライン構成、最先端の Dynamic Disk Pools （ DPP ）テクノロジなどにより、業界最高の信頼性を実現します。</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">お休みください</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">SANtricity ソフトウェアは、使いやすい標準搭載の System Manager インターフェイスを通じて、優れたデータ保護、プロアクティブな監視、認定済みのセキュリティを実現します。ストレージ管理業務を簡易化E シリーズストレージシステムの高度な調整に必要な柔軟性を実現します。NetApp E シリーズシステムをいつでも、どこからでも管理可能標準搭載されている Web ベースのインターフェイスにより、管理ワークフローが合理化されます。</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block> ネットアップは、 Docker と Kubernetes 向けのオープンソースの動的ストレージオーケストレーションツールであり、永続的ストレージの作成、管理、使用を簡易化します。Kubernetes ネイティブアプリケーションである Trident は、 Kubernetes クラスタ内で直接実行されます。Trident を使用すると、 DL コンテナイメージをネットアップストレージにシームレスに導入し、エンタープライズクラスの AI コンテナ環境を実現できます。Kubernetes ユーザ（ ML 開発者やデータサイエンティストなど）は、オーケストレーションとクローニングを作成、管理、自動化し、ネットアップテクノロジを基盤とするネットアップの高度なデータ管理機能を活用できます。</block>
  <block id="e367efbc26bd12c0d6ae37dd6a55ef9b" category="inline-link">Cloud Sync</block>
  <block id="2d76806bea2175a1c575d37015a3621b" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> 迅速かつセキュアなデータ同期を実現するネットアップのサービスです。オンプレミスの NFS または SMB ファイル共有、 NetApp StorageGRID 、 NetApp ONTAP S3 、 NetApp Cloud Volumes Service 、 Azure NetApp Files 、 Amazon Simple Storage Service （ Amazon S3 ）、 Amazon Elastic File System （ Amazon EFS ）、 Azure Blob 、 Google Cloud Storage 間でファイルを転送する必要があるかどうか または、 IBM Cloud Object Storage を使用すると、 Cloud Sync で必要な場所に迅速かつ安全にファイルを移動できます。転送されたデータは、ソースとターゲットの両方で完全に使用できます。Cloud Sync は、事前定義されたスケジュールに基づいてデータを継続的に同期し、差分のみを移動するため、データレプリケーションにかかる時間とコストを最小限に抑えることができます。Cloud Sync は、セットアップや使用がきわめて簡単なソフトウェアサービス（ SaaS ）ツールです。Cloud Sync によって実行されるデータ転送は、データブローカーによって実行されます。Cloud Sync データブローカーは、 AWS 、 Azure 、 Google Cloud Platform 、オンプレミスに導入できます。</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="section-title">Lenovo ThinkSystem サーバ</block>
  <block id="e76fa728781968dd4a707e2d3b1d8108" category="paragraph">Lenovo ThinkSystem サーバは、革新的なハードウェア、ソフトウェア、サービスを搭載しており、お客様の現在の課題を解決し、将来の課題に対処するための、進化した、用途に合わせたモジュラー設計アプローチを提供します。これらのサーバは、クラス最高の業界標準テクノロジーと、差別化された Lenovo の革新技術を組み合わせて、 x86 サーバで可能な限り高い柔軟性を提供します。</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">Lenovo ThinkSystem サーバを導入する主なメリットは次のとおりです。</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">ビジネスの成長に合わせて拡張性に優れたモジュラ設計</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">業界をリードする耐障害性により、計画外停止にかかるコストを時間単位で削減します</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">高速フラッシュテクノロジにより、レイテンシを低減し、応答時間を短縮し、リアルタイムでのデータ管理をスマートに実現します</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">Lenovo は、 AI 分野において、企業がワークロードに ML と AI のメリットを理解し、採用できるようにするための実践的なアプローチをとっています。Lenovo のお客様は、 Lenovo AI Innovation Center で Lenovo AI 製品を調査および評価し、特定のユースケースの価値を十分に理解することができます。価値実現までの時間を短縮するために、このお客様中心のアプローチでは、 AI に最適化された、すぐに使用できる解決策開発プラットフォームのコンセプトの実証をお客様に提供しています。</block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="section-title">Lenovo ThinkSystem SE350 Edge Server</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">エッジコンピューティングにより、 IoT デバイスからのデータをネットワークのエッジで分析してから、データセンターやクラウドに送信できます。下の図に示す Lenovo ThinkSystem SE350 は、柔軟性、接続性、セキュリティ、およびリモート管理性を重視した、耐久性と環境を強化したコンパクトなフォームファクタのエッジでの導入に固有の要件を満たすように設計されています。</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">SE350 は、エッジ AI ワークロードの高速化をサポートする柔軟性を備えたインテル Xeon D プロセッサーを搭載しており、データセンター外のさまざまな環境でのサーバー導入の課題に対応できるように設計されています。</block>
  <block id="b739a166d96ffd72ac4d456012bfbe21" category="paragraph"><block ref="b739a166d96ffd72ac4d456012bfbe21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="paragraph"><block ref="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="section-title">MLPerf</block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">MLPerf 推論 v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf は、 AI のパフォーマンスを評価するための業界をリードするベンチマークスイートです。画像分類、オブジェクト検出、医療画像処理、自然言語処理（ NLP ）など、応用 AI の多くの分野をカバーしています。この検証では、推論 v0.7 ワークロードを使用しました。これは、この検証の完了時に MLPerf 推論の最新の反復処理です。。<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> Suite には、データセンターとエッジシステムのための 4 つの新しいベンチマークが含まれています。</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">* BERT * Transformers （ BERT ）の双方向エンコーダリプレゼンテーションは、チームデータセットを使用して質問に答えるように微調整されています。</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">* DLRM.* ディープラーニング・レコメンド・モデル（ DLRM ）は、クリックスルー・レート（ CTR ）を最適化するためのトレーニングを受けた、パーソナライズされた推奨モデルです。</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*3D U-Net. * 3D U-Net アーキテクチャは、 Brain Tumor Segmentation （ BRT ）データセットについてトレーニングされています。</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T* 再帰型ニューラルネットワークトランスデューサ (RNN-T) は、 LibriSpeech のサブセットについてトレーニングを受けた自動音声認識 (ASR) モデルです。MLPerf 推論の結果とコードは、 Apache ライセンスに基づいて公開およびリリースされます。MLPerf Inference にはエッジがあり、次のシナリオをサポートします。</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">* 単一ストリーム * このシナリオは、スマートフォンで実行されるオフライン AI クエリなど、応答性が重要な要因となるシステムを模倣しています。個々のクエリがシステムに送信され、応答時間が記録されます。すべての応答の 90 パーセンタイルレイテンシが結果として報告されます。</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">* マルチストリーム * このベンチマークは、複数のセンサーからの入力を処理するシステム用です。テスト中は、一定の間隔でクエリが送信されます。QoS の制約（許容される最大レイテンシ）が発生する。テストでは、 QoS の制約を満たしている間にシステムが処理できるストリーム数が報告されます。</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">* オフライン。 * これはバッチ処理アプリケーションを対象とした最も簡単なシナリオで、メトリックは 1 秒あたりのサンプル数でスループットです。すべてのデータをシステムで使用でき、ベンチマークはすべてのサンプルの処理にかかる時間を測定します。</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="c953c121914b99f83398f20ab2160ed1" category="paragraph">Lenovo は、本ドキュメントで使用されているサーバである T4 で SE350 の MLPerf Inference スコアを発表しました。の結果を参照してください<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> エントリ #0.7~145 の「 Edge 、 Closed Division 」セクションに記載されています。</block>
  <block id="26cb2cd90a9e0e03f63323eab13f117d" category="inline-link-macro">次の手順：テスト計画</block>
  <block id="91666b8460dc62d134fe80c31f05d28b" category="paragraph"><block ref="91666b8460dc62d134fe80c31f05d28b" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">AI 主導の自動化とエッジコンピューティングは、ビジネス組織がデジタル変革を実現し、運用効率と安全性を最大限に高めるための、業界をリードするアプローチです。エッジコンピューティングでは、データセンターとの間を移動する必要がないため、データの処理速度が大幅に向上します。そのため、データセンターやクラウドへのデータの送受信に関連するコストが削減されます。</block>
  <block id="1490b4526090ba1052ae7d989d2f44df" category="inline-link-macro">前のバージョン：アーキテクチャのサイジングオプション</block>
  <block id="9d58af74dd11a7bf0a907e66af94ae03" category="paragraph"><block ref="9d58af74dd11a7bf0a907e66af94ae03" category="inline-link-macro-rx"></block></block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">AI 主導の自動化とエッジコンピューティングは、ビジネス組織がデジタル変革を実現し、運用効率と安全性を最大限に高めるための、業界をリードするアプローチです。エッジコンピューティングでは、データセンターとの間を移動する必要がないため、データの処理速度が大幅に向上します。そのため、データセンターやクラウドへのデータの送受信に関連するコストが削減されます。エッジに導入された AI 推論モデルを使用してほぼリアルタイムで意思決定を行う必要がある場合は、レイテンシの低減とスピードの向上が効果的です。</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">ネットアップのストレージシステムは、ローカル SSD ストレージと同等以上のパフォーマンスを発揮し、データサイエンティスト、データエンジニア、 AI / ML 開発者、ビジネスや IT の意思決定者に次のようなメリットをもたらします。</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">AI システム、分析などの重要なビジネスシステム間でデータを容易に共有できます。このようなデータ共有により、インフラのオーバーヘッドを削減し、パフォーマンスを向上させ、企業全体のデータ管理を合理化できます。</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">個別に拡張可能なコンピューティングとストレージにより、コストを最小限に抑え、リソース使用率を向上させます。</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">統合された Snapshot コピーとクローンを使用して開発と導入のワークフローを合理化し、ユーザのワークスペースを瞬時にスペース効率よく利用できるほか、バージョン管理機能も統合され、導入も自動化されています。</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">ディザスタリカバリとビジネス継続性を実現するエンタープライズクラスのデータ保護本ドキュメントで紹介するネットアップと Lenovo の解決策は、柔軟性に優れたスケールアウトアーキテクチャを備えており、エッジでのエンタープライズクラスの AI 推論導入に最適です。</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">J. J. J.Falkanger 、 Sr.Lenovo 、 HPC &amp; AI ソリューション担当マネージャー</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">ネットアップ、テクニカルマーケティングエンジニア、 Dave Arnette 氏</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell 、 Tech Lead E シリーズ AI Solutions 、ネットアップ</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">ネットアップ、 QA エンジニア、 Cody Harryman 氏</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">NetApp AFF A シリーズアレイの製品ページ</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">NetApp ONTAP データ管理ソフトウェア— ONTAP 9 情報ライブラリ</block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727 ：『 NetApp EF Series Introduction 』</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">NetApp E シリーズ SANtricity ソフトウェアのデータシート</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">コンテナ向け NetApp 永続的ストレージ— NetApp Trident</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">TensorFlow ベンチマーク</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Lenovo ThinkSystem DM5100F ユニファイドフラッシュストレージアレイ</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="f8287e56c1a5982e49b792d1116aa372" category="paragraph"><block ref="f8287e56c1a5982e49b792d1116aa372" category="inline-link-rx"></block></block>
  <block id="5e79a20254a28ffdb604f6cba5216c75" category="cell">2021年3月</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">初版リリース</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">バージョン 2.0 以降</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">2021年10月</block>
  <block id="71b3f2dc39aa770e58cd3fad98b76c37" category="cell">EF および MLPerf Inference v1.1 で更新</block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">検証に使用する設定は、他のユースケースに合わせて調整できます。</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">アーキテクチャのサイジングオプション</block>
  <block id="ac0ec60d36dfa69ed9c33bff90080b23" category="inline-link-macro">前へ：テスト結果。</block>
  <block id="389a3124af7d4b9dc7165b05fd96a378" category="paragraph"><block ref="389a3124af7d4b9dc7165b05fd96a378" category="inline-link-macro-rx"></block></block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">コンピューティングサーバ</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">SE350 でサポートされている最小レベルの CPU である Intel Xeon D-2123IT CPU を使用し、 4 つの物理コアと 60W TDP を使用しました。サーバは CPU の交換をサポートしていませんが、より強力な CPU で発注することもできます。サポートされている CPU の上位は、 16 コアを搭載した Intel Xeon D-2183IT 、 2.20GHz で動作する 100W です。これにより、 CPU の計算能力が大幅に向上します。CPU は推論ワークロード自体を実行するためのボトルネックではありませんでしたが、データ処理や推論に関連するその他のタスクに役立ちます。現時点では、 NVIDIA T4 がエッジで唯一の GPU です。そのため、 GPU のアップグレードやダウングレードは行えません。</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">共有ストレージ</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">テストと検証には、ストレージ容量が最大 50.5TB の NetApp AFF C190 システムが使用されています。シーケンシャルリードの場合は 4.4GBps のスループット、スモールランダムリードの場合は 230K の IOPS が、このドキュメントではエッジ推論ワークロードに適していることが実証されています。</block>
  <block id="bb33c803e43b816786d862bbbbf2c824" category="paragraph">ただし、より多くのストレージ容量を必要としたり、より高速なネットワーク速度を必要とする場合は、 NetApp AFF A220 またはを使用してください<block ref="03f94a30ec5c979321fdd9a1ba99a1c6" category="inline-link-rx"></block> ストレージシステムまた、最大容量が 1.5PB の NetApp EF280 システムでは、この解決策検証に、帯域幅も 10Gbps 使用しました。より多くのストレージ容量をより多くの帯域幅で使用する場合は、<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> を使用できます。</block>
  <block id="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="paragraph"><block ref="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="inline-link-macro-rx"></block></block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">このセクションでは、この解決策の検証に使用するテスト手順について説明します。</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">手順をテストします</block>
  <block id="e46c1f341c1cea1321f4c00d15e90b0d" category="inline-link-macro">前の手順：設定をテストします。</block>
  <block id="ed760d2dffd7d011a7870619f7884005" category="paragraph"><block ref="ed760d2dffd7d011a7870619f7884005" category="inline-link-macro-rx"></block></block>
  <block id="bff816e8e8ddbe2a3b705d92abba6627" category="paragraph">この検証では次のテスト手順を使用しました。</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">オペレーティングシステムと AI 推論のセットアップ</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">コード</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">AFF C190 には、 NVIDIA ドライバと Docker を搭載した Ubuntu 18.04 を使用し、 NVIDIA GPU をサポートし、 MLPerf を使用しました<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> Lenovo から MLPerf Inference v0.7 への提出書類の一部として提供されます。</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">EF280 には、 NVIDIA ドライバと Docker を搭載した Ubuntu 20.04 を使用し、 NVIDIA GPU と MLPerf をサポートしました<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> Lenovo から MLPerf Inference v1.1 への提出の一部として提供されています。</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">AI 推論をセットアップするには、次の手順を実行します。</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">このディレクトリは、ネットワークストレージのユースケース用に共有ストレージ上で共有するか、またはローカルデータでテストする際にローカルディスク上で共有する必要があります。</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">実行中の Docker コンテナ内から次のコマンドがすべて実行されます。</block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">推論ワークロードを実行するには、次のコマンドを実行します（ 1 つのコマンド）。</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">AI 推論の実行</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">実行された実行のタイプは次の 3 つです。</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">ローカルストレージを使用した単一サーバの AI 推論</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">ネットワークストレージを使用した単一サーバの AI 推論</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">ネットワークストレージを使用したマルチサーバ AI 推論</block>
  <block id="7dc96590f7bab3379a7a79986056d22a" category="inline-link-macro">次の手順：テスト結果</block>
  <block id="697d202c2969580ba0434be04d39a929" category="paragraph"><block ref="697d202c2969580ba0434be04d39a929" category="inline-link-macro-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">このセクションでは、テスト構成、ネットワークインフラストラクチャ、 SE350 サーバ、およびストレージプロビジョニングの詳細について説明します。</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">設定をテストします</block>
  <block id="b1ee26c1917a17c30b17d7cd6b01e2cd" category="inline-link-macro">前の手順：テスト計画</block>
  <block id="7dffe110836fe412eac19d0f63cf5b5b" category="paragraph"><block ref="7dffe110836fe412eac19d0f63cf5b5b" category="inline-link-macro-rx"></block></block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">次の図に、テスト構成を示します。NetApp AFF C190 ストレージシステムと、 Lenovo ThinkSystem SE350 サーバを 2 台（それぞれ NVIDIA T4 アクセラレータを 1 台搭載）使用しました。これらのコンポーネントは、 10GbE ネットワークスイッチを介して接続されます。ネットワークストレージには、検証 / テスト用のデータセットと事前トレーニング済みのモデルが格納されます。サーバはコンピューティング機能を提供し、ストレージに NFS プロトコル経由でアクセスします。</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">このセクションでは、テスト構成、ネットワークインフラストラクチャ、 SE350 サーバ、およびストレージプロビジョニングの詳細について説明します。次の表に、解決策アーキテクチャの基本コンポーネントを示します。</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">SE350 サーバ x 2 （それぞれ NVIDIA T4 GPU カード 1 枚）</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">各サーバには Intel Xeon D-2123IT CPU が 1 つ搭載され、物理コアは 2.20GHz と 128GB の RAM で動作します</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">エントリレベルの NetApp AFF ストレージシステム（ HA ペア）</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">NetApp ONTAP 9 ソフトウェア</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">960GB SSD × 24</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">コントローラごとに 1 つのインターフェイスグループ。マウントポイント用に 4 つの論理 IP アドレスが割り当てられます</block>
  <block id="1a538c197da3186f1eba50d82572dc34" category="paragraph"><block ref="1a538c197da3186f1eba50d82572dc34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">次の表に、 AFF C190 と 2RU 、 24 ドライブスロットのストレージ構成を示します。</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">コントローラ</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">アグリゲート</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">FlexGroup ボリューム</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">Aggregatesize を実行します</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">ボリュームサイズ</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">オペレーティングシステムのマウントポイント</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">コントローラ 1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">aggr1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netappleenov_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/NetApp_Lenovo _ fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">コントローラ 2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">aggr2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">/netappLenovo_AI_fg フォルダには、モデルの検証に使用するデータセットが含まれています。</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">次の図は、テスト構成を示しています。NetApp EF280 ストレージシステムを 2 台、 Lenovo ThinkSystem SE350 サーバを 2 台（それぞれ NVIDIA T4 アクセラレータを 1 台搭載）使用しました。これらのコンポーネントは、 10GbE ネットワークスイッチを介して接続されます。ネットワークストレージには、検証 / テスト用のデータセットと事前トレーニング済みのモデルが格納されます。サーバはコンピューティング機能を提供し、ストレージに NFS プロトコル経由でアクセスします。</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">次の表に、 EF280 のストレージ構成を示します。</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">ボリュームグループ</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">ボリューム</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDPsize</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">接続方法</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">ボリューム 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 から iSCSI LUN 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">ボリューム 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 から iSCSI LUN 1 へ</block>
  <block id="43fa57e4031b0f759153c9c9fa49e6ed" category="paragraph"><block ref="43fa57e4031b0f759153c9c9fa49e6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0fccd40a3886a1e5dc539059407586a0" category="inline-link-macro">次の手順：手順をテストします。</block>
  <block id="3bee5237e36a9a0dc60fd351ce904544" category="paragraph"><block ref="3bee5237e36a9a0dc60fd351ce904544" category="inline-link-macro-rx"></block></block>
  <block id="290612199861c31d1036b185b4e69b75" category="doc">まとめ</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">先進的なドライバーアシスタンスシステム（ ADAS ）、インダストリー 4.0 、スマートシティ、モノのインターネット（ IoT ）など、いくつかの新しいアプリケーションシナリオでは、ほぼゼロのレイテンシで継続的なデータストリームを処理する必要があります。このドキュメントでは、こうした要件を満たすエッジ環境のネットアップストレージコントローラと Lenovo ThinkSystem サーバに GPU ベースの人工知能（ AI ）推論を導入するためのコンピューティングとストレージのアーキテクチャについて説明します。また、このドキュメントでは、業界標準の MLPerf Inference ベンチマークのパフォーマンスデータも提供し、 NVIDIA T4 GPU を搭載したエッジサーバ上のさまざまな推論タスクを評価します。オフライン、単一ストリーム、マルチストリームの推論のシナリオのパフォーマンスを調査し、コスト効率の高い共有ネットワークストレージシステムを使用したアーキテクチャはハイパフォーマンスであり、複数のエッジサーバのデータとモデルを一元的に管理できることを示します。</block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">提案するアーキテクチャのパフォーマンスを評価するために、多数のテストを実施しました。6 種類のワークロードがあります（画像分類、オブジェクト検出 [ 小規模 ] 、オブジェクト検出 [ 大規模 ] 、医療画像処理、音声テキスト変換、 また、ナチュラル言語処理（ NLP ）もサポートされており、オフライン、シングルストリーム、マルチストリームという 3 つのシナリオで実行できます。</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">テスト結果</block>
  <block id="5e2777e1d5ba6adfeabc55064de508f5" category="inline-link-macro">前へ：手順のテスト。</block>
  <block id="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="paragraph"><block ref="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="inline-link-macro-rx"></block></block>
  <block id="507b481f4f0fb36b82f97222c73fb91d" category="section-title">AFF のテスト結果</block>
  <block id="817fbb6103e6cb6855c19a5c1b25f817" category="paragraph">提案するアーキテクチャのパフォーマンスを評価するために、多数のテストを実施しました。6 種類のワークロードがあります（画像分類、オブジェクト検出 [ 小規模 ] 、オブジェクト検出 [ 大規模 ] 、医療画像処理、音声テキスト変換、 また、ナチュラル言語処理（ NLP ）もサポートされており、オフライン、シングルストリーム、マルチストリームの 3 つのシナリオで実行できます。</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">最後のシナリオは、画像分類とオブジェクト検出の場合にのみ実装されます。</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">その結果、次の 3 種類のセットアップですべてテストされた 15 のワークロードが生成されます。</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">単一のサーバ / ローカルストレージ</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">単一のサーバ / ネットワークストレージ</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">マルチサーバ / ネットワークストレージ</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">結果については、以降のセクションで説明します。</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">AFF のオフラインシナリオにおける AI 推論</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">このシナリオでは、すべてのデータがサーバで使用可能であり、すべてのサンプルの処理にかかった時間が測定されました。テストの結果として、帯域幅が 1 秒あたりのサンプル数で報告されます。複数のコンピューティングサーバを使用した場合、すべてのサーバの合計帯域幅がレポートされます。3 つのユースケースすべての結果を次の図に示します。2 サーバの場合は、両方のサーバからの帯域幅の合計を報告します。</block>
  <block id="d39bc80b598327ae50c15f64c44bb6ea" category="paragraph"><block ref="d39bc80b598327ae50c15f64c44bb6ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">結果から、ネットワークストレージがパフォーマンスに悪影響を与えていないことがわかります。変更は最小限で、一部のタスクでは何も検出されません。2 台目のサーバを追加する場合、合計帯域幅は正確に 2 倍になるか、最悪の場合は 1 % 未満になります。</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">AFF 向けの単一ストリームのシナリオでの AI 推論</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">このベンチマークではレイテンシを測定します。複数のコンピューティングサーバの場合は、平均レイテンシが報告されます。一連のタスクの結果を次の図に示します。2 台のサーバの場合は、両方のサーバの平均レイテンシが報告されます。</block>
  <block id="01f3906715186988e276bc34ebc661c0" category="paragraph"><block ref="01f3906715186988e276bc34ebc661c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">結果からも、タスクを処理するのに十分なネットワークストレージがあることがわかります。1 つのサーバケースにおけるローカルストレージとネットワークストレージの違いは、最小またはなしです。同様に、 2 台のサーバが同じストレージを使用している場合、両方のサーバの遅延は同じままであるか、非常に小さい値で変化します。</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">AFF のマルチストリームシナリオにおける AI 推論</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">この場合、 QoS の制約を満たしながらシステムで処理可能なストリーム数が返されます。したがって、結果は常に整数になります。複数のサーバについて ' すべてのサーバの合計ストリーム数を報告しますすべてのワークロードがこのシナリオをサポートしているわけではありませんが、そのシナリオを実行してきました。テストの結果を次の図にまとめます。2 サーバの場合は、両方のサーバからのストリームの合計数を報告します。</block>
  <block id="758b60f43cbc650fded1dcf9be428fa5" category="paragraph"><block ref="758b60f43cbc650fded1dcf9be428fa5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">この結果は、ローカルストレージとネットワーキングストレージでセットアップのパフォーマンスが完璧に向上し、 2 台目のサーバを追加すると、提案されたセットアップで処理できるストリーム数が 2 倍になります。</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">EF シリーズのテスト結果</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">提案するアーキテクチャのパフォーマンスを評価するために、多数のテストを実施しました。6 種類のワークロードがあります（画像分類、オブジェクト検出 [ 小規模 ] 、オブジェクト検出 [ 大規模 ] 、医療画像処理、音声テキスト変換、 とナチュラル言語処理（ NLP ）は、オフラインとシングルストリームの 2 つの異なるシナリオで実行されました。結果については、以降のセクションで説明します。</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">EF 向けのオフラインシナリオでの AI 推論</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">このシナリオでは、すべてのデータがサーバで使用可能であり、すべてのサンプルの処理にかかった時間が測定されました。テストの結果として、帯域幅が 1 秒あたりのサンプル数で報告されます。1 つのノードの実行については両方のサーバからの平均をレポートし、 2 つのサーバの実行については、すべてのサーバに合計された合計帯域幅をレポートします。ユースケースの結果を次の図に示します。</block>
  <block id="8e793f971410e2b57df427d1305ee0a2" category="paragraph"><block ref="8e793f971410e2b57df427d1305ee0a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">EF 向けの単一ストリームのシナリオでの AI 推論</block>
  <block id="5656e3a262dfb3d6e1cba96551717de0" category="paragraph"><block ref="5656e3a262dfb3d6e1cba96551717de0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="516a608926718d1a912cf9404f1a63ac" category="inline-link-macro">次：アーキテクチャのサイジングオプション</block>
  <block id="9cedf0fb8faddf365d88f523ae482015" category="paragraph"><block ref="9cedf0fb8faddf365d88f523ae482015" category="inline-link-macro-rx"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">このドキュメントでは、最新のアプリケーションシナリオを満たすエッジ環境のネットアップストレージコントローラと Lenovo ThinkSystem サーバに GPU ベースの人工知能（ AI ）推論を導入するためのコンピューティングとストレージのアーキテクチャについて説明します。</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886 ： Lenovo ThinkSystem-解決策 Design を使用したエッジネットアップでの AI 推論</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Lenovo 、 Miroslav Hodak 、 Sathish Thyagarajan 氏</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">企業は、ネットワークエッジで大量のデータを生成するケースが増えています。スマートセンサーや IoT データから最大限の価値を引き出すために、企業はエッジコンピューティングを可能にするリアルタイムのイベントストリーミング解決策を求めています。そのため、データセンターの外部にあるエッジでは、処理能力の高い作業がますます実行されるようになっています。AI 推論は、この傾向の推進要因の 1 つです。特にアクセラレータを使用する場合は、エッジサーバがこれらのワークロードに十分な処理能力を発揮しますが、ストレージが制限されることが多いのは、特にマルチサーバ環境では問題です。このドキュメントでは、共有ストレージシステムをエッジ環境に導入する方法と、パフォーマンスに影響を与えずに AI 推論ワークロードにどのようなメリットがあるかを説明します。</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">このドキュメントでは、エッジでの AI 推論向けのリファレンスアーキテクチャについて説明します。複数の Lenovo ThinkSystem エッジサーバとネットアップストレージシステムを組み合わせることで、導入と管理が容易な解決策を構築これは、複数のカメラと産業用センサーを備えた工場フロア、小売取引における POS システム、自律走行車の視覚的な異常を識別するフル・セルフ・ドライビング（ FSD ）システムなど、さまざまな状況での実践的な展開のための基本ガイドとなることを目的としています。</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">本ドキュメントでは、 Lenovo ThinkSystem SE350 Edge Server とエントリレベルの NetApp AFF および EF シリーズストレージシステムで構成された、コンピューティングとストレージの構成のテストと検証について説明します。リファレンスアーキテクチャは、 AI 導入向けの効率的でコスト効率に優れた解決策を提供すると同時に、 NetApp ONTAP と NetApp SANtricity データ管理ソフトウェアを使用して、包括的なデータサービス、統合データプロテクション、シームレスな拡張性、クラウド対応データストレージを提供します。</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">本ドキュメントは、次のような方を対象としています。</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">エッジで AI を生産するビジネスリーダーやエンタープライズアーキテクト。</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">データサイエンティスト、データエンジニア、 AI / 機械学習（ ML ）研究者、 AI システムの開発者</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">AI / ML モデルとアプリケーションの開発のためのソリューションを設計するエンタープライズアーキテクト。</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">ディープラーニング（ DL ）モデルや ML モデルを効率的に導入する方法を探しているデータサイエンティストと AI エンジニア。</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">エッジ推論モデルの導入と管理を担当するエッジデバイスマネージャとエッジサーバ管理者。</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">解決策アーキテクチャ</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">カメラやセンサーなどから受信したデータを推論しているエッジコンピューティングデバイス。</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">複数の用途に使用できる共有ストレージ要素：</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">推論モデルや推論の実行に必要なその他のデータを一元的に格納できます。コンピューティングサーバはストレージに直接アクセスし、ネットワーク全体で推論モデルを使用します。ローカルにコピーする必要はありません。</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">更新されたモデルはここにプッシュされます。</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">エッジサーバーが受信する入力データをアーカイブして、後で分析します。たとえば、エッジデバイスがカメラに接続されている場合、ストレージエレメントはカメラでキャプチャされたビデオを保持します。</block>
  <block id="45d9a14c8d568ce70d22acbde8373657" category="paragraph"><block ref="45d9a14c8d568ce70d22acbde8373657" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">赤</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">青</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Lenovo コンピューティングシステム</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">NetApp AFF ストレージシステム</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">カメラやセンサーなどからの入力で推論を実行するエッジデバイス。</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">推論モデルとエッジデバイスからのデータを保持する共有ストレージを使用して、後から分析することができます。</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">このネットアップと Lenovo 解決策は、主に次のようなメリットをもたらします。</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">エッジでの GPU アクセラレーションコンピューティング。</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">共有ストレージからバックアップおよび管理される複数のエッジサーバの導入。</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">堅牢なデータ保護により、データ損失ゼロで目標復旧時点（ RPO ）と目標復旧時間（ RTO ）を達成</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">NetApp Snapshot コピーとクローンでデータ管理を最適化し、開発ワークフローを合理化</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">このアーキテクチャの使用方法</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">本ドキュメントでは、提案アーキテクチャの設計とパフォーマンスを検証します。ただし、ネットアップでは、コンテナ、ワークロード、モデル管理、クラウドやデータセンターとのデータ同期など、特定のソフトウェアレベルの要素は導入シナリオに固有のものであるため、テストは実施していません。ここには複数の選択肢があります。</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">解決策エリア</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">AI 推論とエッジコンピューティングの主なメリットは、デバイスがレイテンシなしで高品質のデータを計算、処理、分析できることです。このドキュメントで説明するエッジコンピューティングのユースケースの例は非常に多くありますが、ここではいくつかの重要な例を示します。</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">自動車：自律走行車</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">従来のエッジコンピューティングの図は、自律走行車（ AV ）の先進ドライバーアシスタンスシステム（ ADAS ）にあります。ドライバーのいない自動車の AI は、カメラやセンサーからの大量のデータを迅速に処理して、安全性を強化する必要があります。物体と人間の間を解釈するのに時間がかかりすぎると、生命や死亡を意味することがあります。そのため、可能な限り車両の近くでそのデータを処理できることが重要です。この場合、 1 つ以上のエッジコンピュートサーバがカメラ、レーダー、 LiDAR などのセンサーからの入力を処理し、共有ストレージには推論モデルが保持されてセンサーからの入力データが格納されます。</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">ヘルスケア：患者のモニタリング</block>
  <block id="a5031cd8ea18cb91370c532194ecd58e" category="paragraph">AI とエッジコンピューティングがもたらす最大の影響の 1 つは、在宅ケアと集中治療ユニット（ ICU ）の両方において、慢性疾患の患者の継続的なモニタリングを強化できることです。インスリンレベル、呼吸、神経学的活性、心リズム、および消化管機能をモニターするエッジデバイスからのデータは、患者の生命を救うための時間が限られているため、ただちに作用する必要のあるデータを瞬時に分析する必要があります。</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">小売：現金払い</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">エッジコンピューティングは AI と ML を強化することで、小売企業はチェックアウト時間を短縮し、足のトラフィックを増加させることができます。キャッシュレスシステムは、次のようなさまざまなコンポーネントをサポートします。</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">認証とアクセス：物理的な買い物客を検証済みのアカウントに接続し、小売店のスペースへのアクセスを許可する。</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">インベントリの監視：センサー、 RFID タグ、コンピューター・ビジョン・システムを使用して、買い物客による商品の選択や選択解除を確認できます。</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">ここで ' 各エッジ・サーバが各チェックアウト・カウンタを処理し ' 共有ストレージ・システムが中央の同期ポイントとして機能します</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">金融サービス：キオスクでの人間の安全と不正防止</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">銀行業界では、 AI とエッジコンピューティングを活用して、パーソナライズされた銀行業務を革新し、創出しています。リアルタイムのデータ分析と AI 推論を使用したインタラクティブなキオスクにより、 ATM は顧客がお金を引き出すのを支援できるだけでなく、カメラからキャプチャされた画像を介してキオスクをプロアクティブに監視し、人間の安全や不正行為に対するリスクを特定できるようになりました。このシナリオでは、エッジコンピューティングサーバと共有ストレージシステムが対話型のキオスクやカメラに接続されて、銀行が AI 推論モデルでデータを収集して処理できるようにします。</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">製造： Industry 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">産業革命の 4 つ目（インダストリー 4.0 ）は、スマートファクトリーや 3D プリントなどの新たなトレンドとともに始まっています。データ主導の未来に備えるために、大規模な機械間（ M2M ）通信と IoT が統合されており、人間の介入なしに自動化を強化します。製造はすでに高度に自動化されており、 AI 機能の追加は長期的なトレンドの自然な流れを続けています。AI により、コンピュータビジョンやその他の AI 機能を活用して自動化できる運用を自動化できます。品質管理や、人間のビジョンや意思決定に依存するタスクを自動化して、工場の現場で組み立てライン上の材料を迅速に分析し、製造工場が必要とする ISO 規格の安全性と品質管理に適合できるようにすることができます。ここでは、各コンピュートエッジサーバが、製造プロセスを監視する一連のセンサーと、更新された推論モデルに必要に応じて共有ストレージにプッシュされます。</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">通信：地殻検出、タワー検査、およびネットワーク最適化</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">電気通信業界は、コンピュータビジョンと AI 技術を使用して、錆を自動的に検出し、腐食を含む基地局を特定する画像を処理しているため、さらなる検査が必要です。最近では、ドローン画像と AI モデルを使用して、塔の異なる領域を特定し、錆、表面の亀裂、腐食を分析しています。通信インフラやセルタワーを効率的に検査し、定期的に劣化を評価し、必要に応じて迅速に修復できる AI テクノロジの需要は高まり続けています。</block>
  <block id="50dba7db75064ae2e0beea487226ed46" category="paragraph">さらに、通信業界で新たに登場したユースケースとして、 AI と ML のアルゴリズムを使用して、データトラフィックパターンの予測、 5G 対応デバイスの検出、 MIMO （複数入力 / 複数出力）エネルギー管理の自動化と強化が挙げられます。MIMO ハードウェアは、ネットワーク容量を増やすために無線タワーで使用されていますが、これには追加のエネルギーコストが伴います。セルサイトに導入された「 MIMO スリープモード」用の ML モデルは、無線機の効率的な使用を予測し、モバイルネットワークオペレータ（ MNO ）のエネルギー消費コストを削減するのに役立ちます。AI 推論とエッジコンピューティングのソリューションは、 MNO がデータセンターにやり取りするデータ量を削減し、 TCO を削減し、ネットワーク運用を最適化し、エンドユーザの全体的なパフォーマンスを向上させるのに役立ちます。</block>
  <block id="f45c430b02aac052aef8d958c80ff351" category="paragraph"><block ref="f45c430b02aac052aef8d958c80ff351" category="inline-link-macro-rx"></block></block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">このドキュメントは、 MLPerf Inference v0.7 コード、 MLPerf Inference v1.1 コード、およびルールに準拠しています。このセクションで説明する表で定義されているように、エッジで推論用に設計されたベンチマークを実行しました。</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">テスト計画</block>
  <block id="35e08a3e7b357a4284ef29b287063ae5" category="paragraph"><block ref="35e08a3e7b357a4284ef29b287063ae5" category="inline-link-macro-rx"></block></block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">ルール</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">面積（ Area ）</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">タスク</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">QSL サイズ</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">品質</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">マルチストリーム遅延制約</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">ビジョン</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">画像分類</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNet (224x224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">FP32 の 99%</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50 ミリ秒</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">物体検出（大）</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD リネット 34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">ココ (1200x1200)</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66 ミリ秒</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">物体検出（小）</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">ssd - MobileNetsv1 を参照してください</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">ココ (300 x 300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">医療画像のセグメンテーション</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">2019 年 BRT （ 224x224x160 ）</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">FP32 の 99% および 99.9%</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">該当なし</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">スピーチ</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">音声テキスト</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">ライブラリキーテック開発 - クリーン</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">言語</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">言語処理</block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="cell">BERT</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">分隊 v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">シナリオ</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">画像分類</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">シングルストリーム、オフライン、マルチストリーム</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">単一ストリーム、オフライン</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">音声テキスト</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">この検証で開発されたネットワーク・ストレージ・アーキテクチャを使用してこれらのベンチマークを実行し、 MLPerf に送信されたエッジ・サーバ上のローカル実行の結果と比較しました。この比較は、共有ストレージが推論パフォーマンスに与える影響を判断するためのものです。</block>
  <block id="a53c037982ff4e0cd4a61ba90c4c21d3" category="inline-link-macro">次の手順：設定をテストします。</block>
  <block id="50cbf9a915ce97c432035077add8a92f" category="paragraph"><block ref="50cbf9a915ce97c432035077add8a92f" category="inline-link-macro-rx"></block></block>
  <block id="012b603d852affe4779f095a5c59f0c5" category="summary">パブリッククラウドの即応性、価値実現までの時間、コスト削減はすべて、データベースアプリケーションの開発とテストのためにパブリッククラウドを採用する企業にとって有益な価値提案です。このような状況を早急に実現するには、 SnapCenter より優れたツールはありません。SnapCenter では、オンプレミスで本番環境のデータベースを保護できるだけでなく、パブリッククラウドでアプリケーションの開発やコードのテスト用にコピーをすばやくクローニングして、余分なストレージの消費量を最小限に抑えることができます。以下に、ツールを使用したステップバイステッププロセスの詳細を示します。</block>
  <block id="38da6679588aeb2754e14dd58994685e" category="doc">クラウドへの開発 / テストバースト対応ワークフロー</block>
  <block id="5b9681a3caf5db6230c17718122074d3" category="inline-link-macro">前のセクション： AWS パブリッククラウドの導入を開始しました。</block>
  <block id="e9e59a2a982f81f5f964248f351b2446" category="paragraph"><block ref="e9e59a2a982f81f5f964248f351b2446" category="inline-link-macro-rx"></block></block>
  <block id="4d8a5b6bc9c43ab79e376d1aa4d83217" category="paragraph">パブリッククラウドの即応性、価値実現までの時間、コスト削減はすべて、データベースアプリケーションの開発とテストのためにパブリッククラウドを採用する企業にとって有益な価値提案です。このような状況を実現するためのツールは、 SnapCenter よりも優れています。SnapCenter では、オンプレミスで本番環境のデータベースを保護できるだけでなく、パブリッククラウドでのアプリケーション開発やコードテスト用にコピーをすばやくクローニングして、余分なストレージの消費量を最小限に抑えることもできます。以下に、このツールを使用するためのステップバイステッププロセスの詳細を示します。</block>
  <block id="b47b42841be2e173707ab5884714970b" category="section-title">レプリケートされた Snapshot バックアップから、開発 / テスト用の Oracle データベースをクローニングします</block>
  <block id="8d90529d1117b8d3781bd6781acf4e91" category="list-text">Oracle 用のデータベース管理ユーザ ID で SnapCenter にログインします。リソースタブに移動します。このタブには、 SnapCenter で保護されている Oracle データベースが表示されます。</block>
  <block id="a95ff2a2ae2905b0bb3bd0efa211a040" category="paragraph"><block ref="a95ff2a2ae2905b0bb3bd0efa211a040" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d539d2e9659870aa79747206fac4769" category="list-text">バックアップトポロジと詳細表示に使用するオンプレミスデータベースの名前をクリックします。セカンダリでレプリケートされた場所が有効になっている場合は、リンクされたミラーバックアップが表示されます。</block>
  <block id="20111f4a74a9c065157aa13379000a73" category="paragraph"><block ref="20111f4a74a9c065157aa13379000a73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4a9c1f33e524696d6f3adebf89947bb" category="list-text">ミラーバックアップをクリックして、ミラーバックアップビューに切り替えました。その後、セカンダリミラーバックアップが表示されます。</block>
  <block id="e1cbaea95bcc154ccf9e8aece7fc73b3" category="paragraph"><block ref="e1cbaea95bcc154ccf9e8aece7fc73b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4726a244c3941457e8f62b49c83d35d1" category="list-text">クローニングするミラーされたセカンダリデータベースバックアップコピーを選択し、時間およびシステムの変更番号または SCN でリカバリポイントを決定します。通常は、クローニングするフルデータベースバックアップ時間または SCN の末尾にリカバリポイントを設定します。リカバリポイントを決定したら、必要なログファイルのバックアップをリカバリ用にマウントする必要があります。ログファイルのバックアップは、クローンデータベースをホストする対象の DB サーバにマウントする必要があります。</block>
  <block id="81d132cd1ae26e007bb608e5f8609288" category="paragraph"><block ref="81d132cd1ae26e007bb608e5f8609288" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2dc441031605bf54d78fde13b3efc3c" category="paragraph"><block ref="b2dc441031605bf54d78fde13b3efc3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22a17e5abcfc4b5e70ebdea098cd1891" category="admonition">ログの削除が有効で、リカバリポイントが最後のログの削除よりも長くなっている場合は、複数のアーカイブログのバックアップのマウントが必要になることがあります。</block>
  <block id="e9606676533bbe916f4b4b6824eac195" category="list-text">クローニングするフルデータベースバックアップコピーを選択し、クローンボタンをクリックして DB クローンワークフローを開始します。</block>
  <block id="48493c19ee97a291cd320501daf5c721" category="paragraph"><block ref="48493c19ee97a291cd320501daf5c721" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c06d82b497809fcc0fd06d00c6d91a5" category="list-text">完全なコンテナデータベースまたは CDB クローンに適したクローン DB SID を選択してください。</block>
  <block id="f6ee6a459784097119ec1eee6224152e" category="paragraph"><block ref="f6ee6a459784097119ec1eee6224152e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2c50a030b1c5313fca09568edf8c0f9" category="list-text">クラウド内のターゲットクローンホストを選択すると、クローンワークフローによってデータファイル、制御ファイル、および REDO ログディレクトリが作成されます。</block>
  <block id="323554a005f5e77dfaa765ea81e645be" category="paragraph"><block ref="323554a005f5e77dfaa765ea81e645be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="701f017aeafb71656cf2bc3a9bd34862" category="list-text">なしクレデンシャル名は OS ベースの認証に使用され、データベースポートは無関係になります。ターゲットのクローン DB サーバで設定した Oracle Home 、 Oracle OS User 、 Oracle OS Group を適切な値に設定します。</block>
  <block id="c5237b674d4a9cd38d44c5e546cc51d4" category="paragraph"><block ref="c5237b674d4a9cd38d44c5e546cc51d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26a911f3c85fc3c73d79253e65bf30e3" category="list-text">クローニング処理の前に実行するスクリプトを指定します。さらに重要な点は、ここでデータベースインスタンスのパラメータを調整または定義できることです。</block>
  <block id="56774e452bc62021e52de3e3fea844a2" category="paragraph"><block ref="56774e452bc62021e52de3e3fea844a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09d7240367714707474d63a3a574222b" category="list-text">日時または SCN でリカバリポイントを指定します。Cancel を実行するまで ' データベースは使用可能なアーカイブ・ログまでリカバリされますアーカイブログボリュームをマウントするターゲットホストから、外部アーカイブログの場所を指定します。ターゲットサーバの Oracle 所有者がオンプレミスの本番サーバと異なる場合は、アーカイブログディレクトリがターゲットサーバの Oracle 所有者によって読み取り可能であることを確認します。</block>
  <block id="6cb86841376102e5b8924f9909b8f570" category="paragraph"><block ref="6cb86841376102e5b8924f9909b8f570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70b171a9c984de6358afb3557fe84586" category="paragraph"><block ref="70b171a9c984de6358afb3557fe84586" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a752afaf144d06159ca3eec8bb23455f" category="list-text">必要に応じて、 SMTP サーバに E メール通知を設定します。</block>
  <block id="b30b70196320d22207ea0d5d95d2c841" category="paragraph"><block ref="b30b70196320d22207ea0d5d95d2c841" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0421be6f676ac1ddace9e39eeeb54f0f" category="list-text">クローンの概要：</block>
  <block id="a930a442bf914f516109fbb28bf2fbd1" category="paragraph"><block ref="a930a442bf914f516109fbb28bf2fbd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d929881b22cd699e243e2343bd707d" category="list-text">クローニング後に検証して、クローンデータベースが正常に動作することを確認する必要があります。開発 / テストデータベースでは、リスナーの起動や DB ログアーカイブモードのオフなどのいくつかの追加タスクを実行できます。</block>
  <block id="9991775de6f914e5a41601ba523e3193" category="paragraph"><block ref="9991775de6f914e5a41601ba523e3193" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58732c8d9b1293bb6666ef2284840fd3" category="section-title">レプリケートされた Snapshot バックアップから、開発 / テスト用の SQL データベースをクローニングします</block>
  <block id="605f2bb9d099f78e26260848db117df7" category="list-text">SQL Server 用のデータベース管理ユーザ ID で SnapCenter にログインします。[ リソース ] タブに移動します。このタブには、 SnapCenter によって保護されている SQL Server ユーザーデータベースとパブリッククラウド内のターゲットスタンバイ SQL インスタンスが表示されます。</block>
  <block id="d238acd8e02d4df70c9b55828a4b8801" category="paragraph"><block ref="d238acd8e02d4df70c9b55828a4b8801" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39c34a717e197c67b1fc8d678db5815b" category="list-text">バックアップトポロジおよび詳細ビューで使用するオンプレミス SQL Server ユーザデータベース名をクリックします。セカンダリでレプリケートされた場所が有効になっている場合は、リンクされたミラーバックアップが表示されます。</block>
  <block id="8c57a9d29ca9640330e03e6edca2b6e5" category="paragraph"><block ref="8c57a9d29ca9640330e03e6edca2b6e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a5910fa5df5b6482c00b15ae683eef0f" category="list-text">ミラーバックアップをクリックして、ミラーバックアップビューに切り替えます。セカンダリミラーバックアップが表示されます。SnapCenter では SQL Server トランザクションログがリカバリ専用のドライブにバックアップされるため、ここにはフルデータベースバックアップのみが表示されます。</block>
  <block id="f8d3ed6786c765a87cec8464a574076a" category="paragraph"><block ref="f8d3ed6786c765a87cec8464a574076a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="368014bae8201ab49d2207a53c907069" category="list-text">バックアップコピーを選択し、 [ クローン ] ボタンをクリックして、 [ バックアップからクローン ] ワークフローを起動します。</block>
  <block id="87dbbaf733c71b9d4e0027ad4a85e709" category="paragraph"><block ref="87dbbaf733c71b9d4e0027ad4a85e709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75c22c861d423e3f3450da18d56f0599" category="paragraph"><block ref="75c22c861d423e3f3450da18d56f0599" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44258030a87117191bde6d62511ddb9a" category="list-text">ターゲットクローンサーバとしてクラウドサーバを選択し、クローンインスタンス名を指定し、クローンデータベース名を指定します。自動割り当てマウントポイントまたはユーザ定義のマウントポイントパスを選択します。</block>
  <block id="7841eed97c9a860bcb6a46b08ea08c11" category="paragraph"><block ref="7841eed97c9a860bcb6a46b08ea08c11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18145dc97ae06034ae9aafa8b98cb36e" category="list-text">リカバリポイントは、ログのバックアップ時刻または特定の日時を基準に決定します。</block>
  <block id="b2798123b4d42e447362355b510a424c" category="paragraph"><block ref="b2798123b4d42e447362355b510a424c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b9becceddf802cada91d9e2aa84ac5a" category="list-text">クローニング処理の前後に実行するオプションのスクリプトを指定します。</block>
  <block id="adee0219db450497bd0f545df8d862c7" category="paragraph"><block ref="adee0219db450497bd0f545df8d862c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e41b01ffd717fd3d0b5788e608e50b52" category="list-text">E メール通知が必要な場合は、 SMTP サーバを設定します。</block>
  <block id="9b758c550d5da3ecb44f04ae804293d4" category="paragraph"><block ref="9b758c550d5da3ecb44f04ae804293d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc89ae2ec0203249b8e60785a63ca258" category="list-text">クローンの概要。</block>
  <block id="ab74d2d908acf5c3e01544cd4b871b73" category="paragraph"><block ref="ab74d2d908acf5c3e01544cd4b871b73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28725828580a55d904e8b2a39f377eb9" category="list-text">ジョブステータスを監視し、目的のユーザデータベースがクラウドクローンサーバのターゲット SQL インスタンスに接続されていることを確認します。</block>
  <block id="766259946fc034002a24d5f23655c73e" category="paragraph"><block ref="766259946fc034002a24d5f23655c73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d512bf68b17268adfe539f9722d869b4" category="section-title">クローン後の設定</block>
  <block id="50d9180ea26c89fbe6506d71d81d3fb1" category="list-text">通常、オンプレミスの Oracle 本番データベースはログアーカイブモードで実行されます。このモードは、開発データベースやテストデータベースには必要ありません。ログアーカイブモードをオフにするには、 Oracle DB に sysdba でログインし、ログモード変更コマンドを実行して、データベースにアクセスできるようにします。</block>
  <block id="b205237d51ff9525496f4b2252942213" category="list-text">Oracle リスナーを設定するか、新しくクローニングされた DB をユーザアクセス用の既存のリスナーに登録します。</block>
  <block id="800699a04cdaa75b2219988799b0a048" category="list-text">SQL Server の場合は、ログボリュームがいっぱいになったときに SQL Server 開発 / テストログファイルを簡単に縮小できるように、ログモードを「 Full 」から「 Easy 」に変更します。</block>
  <block id="89e018d207fd292a4926870904035c18" category="section-title">クローンデータベースをリフレッシュします</block>
  <block id="d84550ba9a340ebf4fa6698dff5ba344" category="list-text">クローニングされたデータベースを削除し、クラウド DB サーバ環境をクリーンアップします。次に、前の手順に従って、新しいデータで新しい DB のクローンを作成します。新しいデータベースのクローニングには数分しかかかりません。</block>
  <block id="1170d6f09309cb8dc382034a34680937" category="inline-link-macro">クローンをリフレッシュします</block>
  <block id="fef062eeb7771b01e620bb2460b1bf9a" category="list-text">クローンデータベースをシャットダウンし、 CLI を使用してクローン更新コマンドを実行します。詳細については、次の SnapCenter のドキュメントを参照してください。 <block ref="1e4035dee07650c706f8f0714c384872" category="inline-link-macro-rx"></block>。</block>
  <block id="2d6962c20ba37b34437afc30e6838e0d" category="inline-link-macro">ネットアップの解決策自動化コミュニティでは、余裕期間のチャネルがサポートさ</block>
  <block id="7b88d7d11804db6b079e226a6f043ea7" category="paragraph">この解決策やユースケースに関するサポートが必要な場合は、に参加してください <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> また、ソリューション自動化チャネルを検索して、質問や問い合わせを投稿しましょう。</block>
  <block id="e2a76301a4117f21d6192304aa650018" category="inline-link-macro">次：ディザスタリカバリのワークフロー</block>
  <block id="28a87ee64d4675e6c24cd960fe71d9bf" category="paragraph"><block ref="28a87ee64d4675e6c24cd960fe71d9bf" category="inline-link-macro-rx"></block></block>
  <block id="d83342bb55cac062a4841a3b7a62a7fd" category="summary">ここでは、前のセクションで概説した前提条件を満たすために完了しておく必要がある作業の概要を示します。次のセクションでは、オンプレミスとパブリッククラウドの両方の運用に関するタスクの概要を説明します。関連リンクをクリックすると、詳細なプロセスと手順にアクセスできます。</block>
  <block id="21475c5fe4cf73cfbf7756ed71e43375" category="doc">概要の確認</block>
  <block id="fa952e93a2f3bc19270cbedd1510f523" category="inline-link-macro">前のバージョン：パブリッククラウドの前提条件</block>
  <block id="f50eb88fd106752cf99e25d4a7259bb7" category="paragraph"><block ref="f50eb88fd106752cf99e25d4a7259bb7" category="inline-link-macro-rx"></block></block>
  <block id="b2e7ae8381268c9d97dc3576aa67da04" category="list-text">SnapCenter でデータベース管理ユーザを設定します</block>
  <block id="e1c4efcd7b5b155c8a6e57d348b6c071" category="list-text">SnapCenter プラグインのインストールの前提条件</block>
  <block id="cf69df8da81eda7b468d606f3e9aff06" category="list-text">SnapCenter ホストプラグインのインストール</block>
  <block id="2a6faa57bc6cc0f7a4c90cebd5e63344" category="list-text">DB リソースの検出</block>
  <block id="2a36af746a3cc41f6964edac717b5206" category="list-text">ストレージクラスタピアリングと DB ボリュームレプリケーションをセットアップします</block>
  <block id="a227a5da83d0a04e6e8e7e76a89eba09" category="list-text">CVO データベースストレージの SVM を SnapCenter に追加してください</block>
  <block id="c615eed91e2ab578525394d0ff0138d9" category="list-text">SnapCenter でデータベースバックアップポリシーを設定する</block>
  <block id="8ecb914dad4186dafb38268be6fc8a1f" category="list-text">データベースを保護するためのバックアップポリシーを実装する</block>
  <block id="3041fe5faf49efefd030e278790b4faf" category="list-text">バックアップを検証</block>
  <block id="8a3f037eef48de78bfe13d14e3d7cdfa" category="section-title">AWS パブリッククラウド</block>
  <block id="0bcf61b20ebca1ef90cb7982284867a6" category="list-text">フライト前チェック</block>
  <block id="c27b238e54d27696cafed4684c6f1335" category="list-text">AWS に Cloud Manager と Cloud Volumes ONTAP を導入する手順</block>
  <block id="2bb50575568fc6429e2c1cef751d40f4" category="list-text">データベースワークロードの EC2 コンピューティングインスタンスを導入します</block>
  <block id="bc2dcb446bec0ecd131a2e612dbd1ecd" category="paragraph">詳細については、次のリンクをクリックしてください。</block>
  <block id="7146594a919f2b006b1b0911c7b6d7da" category="inline-link-macro">オンプレミス</block>
  <block id="21aa279d0a145dcaab5feaa02df2c02a" category="inline-link-macro">パブリッククラウド - AWS</block>
  <block id="fd0476c0c92270df2d75402a67cfe0f4" category="paragraph"><block ref="8f0e2d08c6bad9ef491c2061921b9d90" category="inline-link-macro-rx"></block>、 <block ref="11145243f1982fd305768240bff5daad" category="inline-link-macro-rx"></block></block>
  <block id="ff9d8653752bd48bb6b73cf97f207af1" category="summary">SnapCenter DR ワークフローによるハイブリッドクラウドデータベースソリューション</block>
  <block id="ac2e8778240cb518ee14b1defbf55765" category="doc">ディザスタリカバリワークフロー</block>
  <block id="461887ca64f2d60da58c130a00656a96" category="inline-link-macro">前の手順：クラウドへの開発 / テストバーストのワークフロー</block>
  <block id="b8499237e1a42a05b5306219f80b35ba" category="paragraph"><block ref="b8499237e1a42a05b5306219f80b35ba" category="inline-link-macro-rx"></block></block>
  <block id="8e84608bd62584b2f262d60fd734714f" category="paragraph">企業はパブリッククラウドを、ディザスタリカバリの実現可能なリソースとして活用してきました。SnapCenter は、このプロセスを可能な限りシームレスに実行します。このディザスタリカバリワークフローはクローニングワークフローと非常によく似ていますが、データベースリカバリは、クラウドにレプリケートされた最後の使用可能なログまで実行され、可能なすべてのビジネストランザクションをリカバリします。ただし、ディザスタリカバリに固有の、設定前の手順と設定後の手順がほかにもあります。</block>
  <block id="e230d95c57c5534b3e90b93fddbcb1c9" category="section-title">オンプレミスの Oracle 本番 DB を、 DR 用にクラウドへクローニング</block>
  <block id="db9517755259859dbae095126c803544" category="list-text">クローンリカバリが最後に使用可能なログで実行されるかどうかを検証するために、小さなテストテーブルを作成して行を挿入しました。テストデータは、使用可能な最後のログへの完全リカバリ後にリカバリされます。</block>
  <block id="39f00f2f1a95739a075844dcffac1441" category="paragraph"><block ref="39f00f2f1a95739a075844dcffac1441" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fd1337293be82f7472d90bc35f51e90" category="list-text">Oracle のデータベース管理ユーザ ID として SnapCenter にログインします。リソースタブに移動します。このタブには、 SnapCenter で保護されている Oracle データベースが表示されます。</block>
  <block id="1ddb1f7854ac534473544de627fc5289" category="paragraph"><block ref="1ddb1f7854ac534473544de627fc5289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e795ef17ab8e08159909afe558c32a1c" category="list-text">Oracle ログリソースグループを選択し、 Backup Now （今すぐバックアップ）をクリックして Oracle ログバックアップを手動で実行し、最新のトランザクションをクラウド内のデスティネーションにフラッシュします。実際の DR シナリオでは、最後にリカバリ可能なトランザクションはデータベースログボリュームからクラウドへのレプリケーション頻度によって異なり、クラウドへのレプリケーションは企業の RTO ポリシーまたは RPO ポリシーによって異なります。</block>
  <block id="e3ea77c81b6559a6984aee62074951ec" category="paragraph"><block ref="e3ea77c81b6559a6984aee62074951ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44d1c907c1d5302eb896d76cae9b5e7f" category="paragraph"><block ref="44d1c907c1d5302eb896d76cae9b5e7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d77575716b9cd49ab1453e367c405abe" category="admonition">非同期 SnapMirror では、ディザスタリカバリシナリオでクラウドデスティネーションにしていないデータは失われます。これは、データベースログのバックアップ間隔で行われます。データ損失を最小限に抑えるため、ログバックアップの頻度を増やすようにスケジュールを設定できます。ただし、技術的には、ログのバックアップ頻度に制限があります。</block>
  <block id="c684c2587fa959f3df40953faab1c1a1" category="list-text">セカンダリ・ミラー・バックアップで最後のログ・バックアップを選択し、ログ・バックアップをマウントします。</block>
  <block id="4d27921136b62a393650eec8f38c5a39" category="paragraph"><block ref="4d27921136b62a393650eec8f38c5a39" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6784de36878125b88feb4c3192d2aa3d" category="paragraph"><block ref="6784de36878125b88feb4c3192d2aa3d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fbfa0a2a63c1090863dedb14664d443c" category="list-text">最後のフルデータベースバックアップを選択し、 Clone をクリックしてクローンワークフローを開始します。</block>
  <block id="ecafa568fe2f36fee38130d0f80eeafc" category="paragraph"><block ref="ecafa568fe2f36fee38130d0f80eeafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3aa765536eeb5bd55823afbb43c9efdc" category="list-text">ホスト上で一意のクローン DB ID を選択します。</block>
  <block id="6d4d1ea488e25d46cd7824491f3f98fb" category="paragraph"><block ref="6d4d1ea488e25d46cd7824491f3f98fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d57d235b31b66e982ae6d433fa33948e" category="list-text">ログボリュームをプロビジョニングし、 Oracle フラッシュリカバリ領域とオンラインログのターゲット DR サーバにマウントします。</block>
  <block id="4ef6ef644cc7510226d8d150ce9cfe73" category="paragraph"><block ref="4ef6ef644cc7510226d8d150ce9cfe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d5730b3167534121e5ac4fcdf84cf1f" category="paragraph"><block ref="4d5730b3167534121e5ac4fcdf84cf1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6142419cbd2b279a240db52011ea3cab" category="admonition">Oracle クローン手順はログボリュームを作成しないため、クローニングを実行する前に DR サーバでプロビジョニングする必要があります。</block>
  <block id="b20da77a777ef0a84d95f447b254387c" category="list-text">ターゲットのクローンホストと、データファイル、制御ファイル、および REDO ログを配置する場所を選択します。</block>
  <block id="326062662ffdb461c61b5ddfc54974bc" category="paragraph"><block ref="326062662ffdb461c61b5ddfc54974bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b126b14adfdc04f12e6a00531155f4a" category="list-text">クローンのクレデンシャルを選択します。ターゲット・サーバの Oracle ホーム構成の詳細を入力します</block>
  <block id="ee4a9d80953ee6db29e5577ef13327ba" category="paragraph"><block ref="ee4a9d80953ee6db29e5577ef13327ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c76f59dc52686a71eb5917bbcabfa212" category="list-text">クローニングの前に実行するスクリプトを指定します。データベースパラメータは必要に応じて調整できます。</block>
  <block id="31b131b08153ae34a96d1e17fa891e1f" category="paragraph"><block ref="31b131b08153ae34a96d1e17fa891e1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7018f70f78c5e3154b2620e31167c12e" category="list-text">リカバリオプションとして Until Cancel を選択して、使用可能なすべてのアーカイブログをリカバリで実行し、セカンダリクラウドの場所に最後にレプリケートされたトランザクションをリカバリします。</block>
  <block id="57fa7fef5a8266470204775391a701d3" category="paragraph"><block ref="57fa7fef5a8266470204775391a701d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6233d74c8f9820a1029624d60ab66049" category="list-text">必要に応じて、 SMTP サーバで E メール通知を設定します。</block>
  <block id="a563132424d4d3d255697521a0446bc9" category="paragraph"><block ref="a563132424d4d3d255697521a0446bc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0cd00abfa258b121d480ce7d27e63" category="list-text">DR クローンの概要：</block>
  <block id="0f66818ccf8a8dd3d6491b9bcf74c02e" category="paragraph"><block ref="0f66818ccf8a8dd3d6491b9bcf74c02e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4ff014e6bff5ee06349d607c14fcf9e" category="list-text">クローニングされた DB は、クローンの完了直後に SnapCenter に登録され、バックアップ保護に使用できます。</block>
  <block id="18eac7477ab0c6038ec443444677a1eb" category="paragraph"><block ref="18eac7477ab0c6038ec443444677a1eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22d74aee547ad10d104f875521cfa6d7" category="section-title">Oracle の DR クローンの検証と設定後の POST コマンドです</block>
  <block id="9d58cce71d4c85948ccecfea105367ed" category="list-text">クラウドの DR サイトでフラッシュ、レプリケート、リカバリされた最後のテストトランザクションを検証します。</block>
  <block id="1db3ba1f62cbb82a66232de851bad3ce" category="paragraph"><block ref="1db3ba1f62cbb82a66232de851bad3ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61b3573abc722a493f53ed27503f7eff" category="list-text">フラッシュリカバリ領域を設定します。</block>
  <block id="71ca9fe67f8c3826e171fb227af4f666" category="paragraph"><block ref="71ca9fe67f8c3826e171fb227af4f666" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4005d553f013abc53c6a1a65aed1d65f" category="list-text">ユーザアクセス用に Oracle リスナーを設定します。</block>
  <block id="0c79c2a9e4fd1ea908a63d58f1f44917" category="list-text">レプリケートされたソースボリュームからクローンボリュームをスプリットします。</block>
  <block id="42e82bb35283d9f2e2b444419f518667" category="list-text">クラウドからオンプレミスへの逆レプリケーションを行い、障害が発生したオンプレミスデータベースサーバを再構築します。</block>
  <block id="4ce2420dd00dd0b543e2e51bf7c1c135" category="admonition">クローンスプリットでは、一時的にストレージスペースが利用され、通常の処理よりもはるかに高くなる場合があります。ただし、オンプレミスの DB サーバを再構築すると、追加スペースを解放できるようになります。</block>
  <block id="0e70133bb418f4025b82a6a35301e209" category="section-title">オンプレミスの SQL 本番 DB を DR 用のクラウドにクローニング</block>
  <block id="32bfa00a92b9f85d791a43f6d70a35cd" category="list-text">同様に、 SQL クローンリカバリが前回使用可能なログを通過したかどうかを検証するために、小さなテストテーブルを作成して行を挿入しました。テストデータは、使用可能な最後のログへのフルリカバリ後にリカバリされます。</block>
  <block id="321bd96e83b00fcd04bfcc72ec4564ff" category="paragraph"><block ref="321bd96e83b00fcd04bfcc72ec4564ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3b7f1fcf93afdd055ec19e230b54347" category="list-text">SQL Server 用のデータベース管理ユーザ ID で SnapCenter にログインします。[ リソース ] タブに移動します。このタブには、 SQL Server 保護リソースグループが表示されます。</block>
  <block id="c9673e38d22c239c3b46259620b7b190" category="paragraph"><block ref="c9673e38d22c239c3b46259620b7b190" category="inline-image-macro-rx" type="image"></block></block>
  <block id="608bfa3334f97023b71f6b7a04742bd6" category="list-text">パブリッククラウドのセカンダリストレージにレプリケートする最後のトランザクションをフラッシュするには、ログバックアップを手動で実行します。</block>
  <block id="94ca8d0daf1445cae1bbc5a13d7b0c42" category="paragraph"><block ref="94ca8d0daf1445cae1bbc5a13d7b0c42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b9ced1d8d8e91eb2606cb7d0932fa4" category="list-text">クローンに対して最後に実行した SQL Server のフルバックアップを選択します。</block>
  <block id="f93fa51d605a26ef233b6fb9c5489266" category="paragraph"><block ref="f93fa51d605a26ef233b6fb9c5489266" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82efcc579f2220a65dbe5cdd64f47253" category="list-text">クローンサーバ、クローンインスタンス、クローン名、マウントオプションなどのクローン設定を行います。クローニングが実行されるセカンダリストレージの場所が自動的に入力されます。</block>
  <block id="bb5bdefa03845f9483d1e3fcf8d3b40f" category="paragraph"><block ref="bb5bdefa03845f9483d1e3fcf8d3b40f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d84ecf0ed314694d6e3ad9b2a96a198" category="list-text">適用するすべてのログバックアップを選択します。</block>
  <block id="79284af3915a1bc3e4d4d3993acd9042" category="paragraph"><block ref="79284af3915a1bc3e4d4d3993acd9042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f68fbd76be71ebe267aa207f7bef25f" category="list-text">クローニングの前後に実行するオプションのスクリプトを指定します。</block>
  <block id="1f29cf99c49ef1910181e451424c3796" category="paragraph"><block ref="1f29cf99c49ef1910181e451424c3796" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ac43ede08a0b7154673a619b979f17d" category="list-text">E メール通知が必要な場合は、 SMTP サーバを指定します。</block>
  <block id="e8aa5b543b67c22f0a2a205562794787" category="paragraph"><block ref="e8aa5b543b67c22f0a2a205562794787" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7338d3af995c4a281de85493129cc18" category="list-text">DR クローンの概要：クローニングされたデータベースはただちに SnapCenter に登録され、バックアップ保護に使用できます。</block>
  <block id="332fb27e1cc349fc79252fbfc5de6ad0" category="paragraph"><block ref="332fb27e1cc349fc79252fbfc5de6ad0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8be7490bb89f986a83768e6a71d78ee8" category="paragraph"><block ref="8be7490bb89f986a83768e6a71d78ee8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f01a56e31a650c5bb83408b5238270e" category="section-title">DR による SQL のクローン検証後の構成</block>
  <block id="029640b7bf09578f05703e407e99b8d7" category="list-text">クローニングジョブのステータスを監視する。</block>
  <block id="d5f350d5580b71105a1718557ce88137" category="paragraph"><block ref="d5f350d5580b71105a1718557ce88137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68236fcee9bee8dbdc1c54b7b2d84b34" category="list-text">すべてのログファイルクローンとリカバリで、最後のトランザクションがレプリケートされてリカバリされたことを確認します。</block>
  <block id="3ebb58ab28579acf2742808bf95fc07e" category="paragraph"><block ref="3ebb58ab28579acf2742808bf95fc07e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50159c53d6f87eb33c314abd9f0bd28f" category="list-text">DR サーバで、 SQL Server ログバックアップ用の新しい SnapCenter ログディレクトリを設定します。</block>
  <block id="50f8c30e062c542679b96127a844db6a" category="paragraph">この解決策やユースケースに関するサポートが必要な場合は、にご参加ください <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> また、ソリューション自動化チャネルを検索して、質問や問い合わせを投稿しましょう。</block>
  <block id="467bda78c0e1adcc5ed650843fbfbdf5" category="summary">このセクションでは、 AWS に Cloud Manager と Cloud Volumes ONTAP を導入するプロセスについて説明します。</block>
  <block id="298a4809d5445df75b6c4a9fb94074a4" category="doc">AWS パブリッククラウドの導入</block>
  <block id="b8f5ff8c1ae69fa5befe459d3f34b68a" category="inline-link-macro">前の手順：オンプレミスでの作業の開始</block>
  <block id="19f84106226ff97c314f55dd621bbd98" category="paragraph"><block ref="19f84106226ff97c314f55dd621bbd98" category="inline-link-macro-rx"></block></block>
  <block id="87aa698992e009d04733c9906225592c" category="admonition">作業を簡単に進めるために、 AWS への導入に基づいて本ドキュメントを作成しました。ただし、 Azure と GCP の場合もプロセスはほぼ同じです。</block>
  <block id="39845311263ccad04c0d4f0b9aa9d4c6" category="section-title">1. 事前フライトチェック</block>
  <block id="12ed93944854c12caa37886d620f16db" category="paragraph">導入前に、次の段階で導入できるようにインフラが設置されていることを確認してください。これには次のものが含まれます。</block>
  <block id="c6368ae044df0f7bb26ed60afda5c591" category="list-text">AWS アカウント</block>
  <block id="4019c185756035c18c03fabfccd7d4b2" category="list-text">選択した地域の VPC</block>
  <block id="fca5d2fece6e360f78dff4573ba04a20" category="list-text">パブリックインターネットにアクセスできるサブネット</block>
  <block id="e3e5c3dadc3e70d536645a3be9744f79" category="list-text">AWS アカウントに IAM ロールを追加する権限</block>
  <block id="bd5c82fb0e0371a168f609848b11e92a" category="list-text">AWS ユーザのシークレットキーとアクセスキー</block>
  <block id="c3d1ff3c88148b2246bb0972916da82a" category="section-title">2. AWS に Cloud Manager と Cloud Volumes ONTAP を導入する手順</block>
  <block id="6d0eb695a99109617b806676e9610075" category="inline-link">ネットアップのクラウドに関するドキュメント</block>
  <block id="593581e466784760a050bceaea5e0c48" category="admonition">Cloud Manager と Cloud Volumes ONTAP を導入する方法は多数あります。最もシンプルですが、最も多くの権限が必要です。お使いの AWS 環境にこの方法が適していない場合は、を参照してください<block ref="97a20614f8c0e53f461a9353634e5e51" category="inline-link-rx"></block>。</block>
  <block id="bb3e779fdf877143137572122cf424e3" category="section-title">Cloud Manager Connector を導入します</block>
  <block id="4c6e32ff373dc3ce5b49202f92f01b08" category="list-text">に移動します<block ref="143fea272f01f72dbdc942451156df21" category="inline-link-rx"></block> ログインまたはサインアップします。</block>
  <block id="356cf5e12d635c19d987b1b195ff5a40" category="paragraph"><block ref="356cf5e12d635c19d987b1b195ff5a40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2300b8579a8761e452d89a2af6636b7d" category="list-text">ログイン後、キャンバスに移動します。</block>
  <block id="af93b0b88e1db5f3aa229d2336fedb3c" category="paragraph"><block ref="af93b0b88e1db5f3aa229d2336fedb3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3fbf2c408ce86ff3403990e7e32dcb3" category="list-text">「 Add Working Environment 」をクリックし、「 Cloud Volumes ONTAP in AWS 」を選択します。ここでは、シングルノードシステムとハイアベイラビリティペアのどちらを導入するかを選択することもできます。ハイアベイラビリティペアを導入することを選択しました。</block>
  <block id="bb18ff1ebac7ea2039aa297469c76b76" category="paragraph"><block ref="bb18ff1ebac7ea2039aa297469c76b76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="016aa0c0a7322975ec4b8eeac805f2c0" category="list-text">コネクタが作成されていない場合は、コネクタの作成を求めるポップアップが表示されます。</block>
  <block id="a05691eb0d806668c3796d3d6fe01157" category="paragraph"><block ref="a05691eb0d806668c3796d3d6fe01157" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fc3362a0d8ab63cc8fa21bbd0fb07db" category="list-text">[ 開始 ] をクリックし、 [AWS] を選択します。</block>
  <block id="55f5adc74d49945abd7798742f307124" category="paragraph"><block ref="55f5adc74d49945abd7798742f307124" category="inline-image-macro-rx" type="image"></block></block>
  <block id="deae4c054bb3102bbf634b14534da9bf" category="inline-link">ネットアップのポリシーのページ</block>
  <block id="651d429a2b6cfcd93f6adb1d4825a214" category="list-text">シークレットキーとアクセスキーを入力します。ユーザに、で概説されている正しい権限があることを確認します<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block>。</block>
  <block id="94497191b0b0c6d05a2df7d2175e87f5" category="paragraph"><block ref="94497191b0b0c6d05a2df7d2175e87f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d59b60a74630e45f83fd3c48207b47" category="list-text">コネクタに名前を付け、の説明に従って事前定義されたロールを使用する<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block> または、 Cloud Manager にロールの作成を依頼してください。</block>
  <block id="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="paragraph"><block ref="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02d395705fb063ad8d33d8c83c856e6f" category="list-text">コネクタの導入に必要なネットワーク情報を入力します。アウトバウンドインターネットアクセスが有効になっていることを確認します。</block>
  <block id="8215126360cbe5d8f5566c7ffc8cf224" category="list-text">コネクタにパブリック IP アドレスを割り当てます</block>
  <block id="22adb619c008bfd7495288573093ae44" category="list-text">コネクタにプロキシを与える</block>
  <block id="58a149795bbe86e4e0d4ab8f10413219" category="list-text">インターネットゲートウェイを経由してインターネットに接続するためのルートをコネクタに与える</block>
  <block id="5908ad1cf5bd748238e305dd5fc52fac" category="paragraph"><block ref="5908ad1cf5bd748238e305dd5fc52fac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c58ebc9f032dc8d2e5c4f522cedbe0b" category="list-text">セキュリティグループを提供するか、新しいセキュリティグループを作成して、 SSH 、 HTTP 、および HTTPS 経由でコネクタと通信する。IP アドレスからのみコネクタへのアクセスを有効にしました。</block>
  <block id="1d39d9c13f50dd25f7e54173c87c633a" category="paragraph"><block ref="1d39d9c13f50dd25f7e54173c87c633a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb444cfaba774437ecdbbb95856d94cd" category="list-text">概要ページの情報を確認し、追加をクリックしてコネクタを配置します。</block>
  <block id="5576df68e3720f55e585e7e091d5b9e3" category="paragraph"><block ref="5576df68e3720f55e585e7e091d5b9e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4255ace47c9ad7f2907c18df7512bb9f" category="list-text">コネクタがクラウド形成スタックを使用して導入されるようになりました。進捗状況は Cloud Manager または AWS から監視できます。</block>
  <block id="ff7fb4bedc0d09880f85d9745ec258a5" category="paragraph"><block ref="ff7fb4bedc0d09880f85d9745ec258a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca320cc147e2b9fac2dd7379e91012b6" category="list-text">導入が完了すると、成功ページが表示されます。</block>
  <block id="f5bbadf1ed57058e80e27764684e6314" category="paragraph"><block ref="f5bbadf1ed57058e80e27764684e6314" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6382283fd45b13b5c983745731fec990" category="section-title">Cloud Volumes ONTAP を導入します</block>
  <block id="5fe90897c7135ba3020c4a397f55adb6" category="list-text">AWS と、それぞれの要件に応じた導入タイプを選択します。</block>
  <block id="63b636f2002a2e7b7c2e2420cd64ff73" category="paragraph"><block ref="63b636f2002a2e7b7c2e2420cd64ff73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf1300c5621fdebe8c1a70fade44f3b" category="list-text">サブスクリプションが割り当てられておらず、 PAYGO で購入する場合は、資格情報の編集を選択します。</block>
  <block id="b893bded7e1bd3419a443758a8ef410f" category="paragraph"><block ref="b893bded7e1bd3419a443758a8ef410f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88eb84b1a8f0417c9de6e1202125df56" category="list-text">[Add Subscription] を選択します。</block>
  <block id="0b5d3e3d1a9347ff4a7395d09208a8f4" category="paragraph"><block ref="0b5d3e3d1a9347ff4a7395d09208a8f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="052208bafdfe08bc8f0735a78226e541" category="list-text">購読する契約のタイプを選択します。従量課金制を選択しました。</block>
  <block id="4d5ab1ed0682fe644e831558598d4638" category="paragraph"><block ref="4d5ab1ed0682fe644e831558598d4638" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65577508f7897e730adb501d0db73913" category="list-text">AWS にリダイレクトされます。 Continue to Subscribe を選択します。</block>
  <block id="ac33260d1e06f504f1dcac229aeb269c" category="paragraph"><block ref="ac33260d1e06f504f1dcac229aeb269c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="439c4fb23c120f0a99894c630cedaabd" category="list-text">登録すると、 NetApp Cloud Central にリダイレクトされます。すでに購読していてリダイレクトされていない場合は、「ここをクリック」リンクを選択します。</block>
  <block id="a90c8b1fc04a41aff490fd2b269f5932" category="paragraph"><block ref="a90c8b1fc04a41aff490fd2b269f5932" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14b9e98d2b57da92c29826ce7de32c32" category="list-text">Cloud Central にリダイレクトされます。ここで、サブスクリプションの名前を指定して、 Cloud Central アカウントに割り当てる必要があります。</block>
  <block id="c89376fd9624f6ebda7959df6176ef34" category="paragraph"><block ref="c89376fd9624f6ebda7959df6176ef34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4508f5994d1b34ff85cd1e8a1884d6c1" category="list-text">成功すると、チェックマークページが表示されます。Cloud Manager のタブに戻ります。</block>
  <block id="2b206bbd8f3b20e3282b660a356d90be" category="paragraph"><block ref="2b206bbd8f3b20e3282b660a356d90be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3294e5fb9ec1c42cde7ebf9b206c583" category="list-text">サブスクリプションが Cloud Central に表示されます。[ 適用 ] をクリックして続行します。</block>
  <block id="37ce5c33a55d907edabe632c39a2707c" category="paragraph"><block ref="37ce5c33a55d907edabe632c39a2707c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7927b068a5dddb4852b2e7dc256544" category="list-text">次のような作業環境の詳細を入力します。</block>
  <block id="0dbae4d42c7a0db53e2eb32adee12892" category="list-text">クラスタ名</block>
  <block id="0c191ee206a91460fd94e2ff976a38e7" category="list-text">クラスタのパスワード</block>
  <block id="53aa18427d1e2c7b7113c668561a62d2" category="list-text">AWS のタグ（オプション）</block>
  <block id="d3b6ff1e8c6317d132d3a5e974f1374c" category="paragraph"><block ref="d3b6ff1e8c6317d132d3a5e974f1374c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fb5b261ae3a3581304a283ef70a5246" category="inline-link">ネットアップクラウドのホームページ</block>
  <block id="e7b29c75e71a48483734401322ef6e92" category="list-text">導入する追加サービスを選択します。これらのサービスの詳細については、を参照してください<block ref="1bb1213784e04e4f47d06f252d1ba164" category="inline-link-rx"></block>。</block>
  <block id="88e71a2c19d98c79d2ed51a753c8a4c2" category="paragraph"><block ref="88e71a2c19d98c79d2ed51a753c8a4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0dffa77d5644a3816ba69e24ce813ff" category="list-text">複数のアベイラビリティゾーンに導入する（ 3 つのサブネットをそれぞれ異なる AZ に配置する）か、単一のアベイラビリティゾーンに導入するかを選択します。複数の AZ を選択しました。</block>
  <block id="6e4a3fe2b0629dae504d8e727147f709" category="paragraph"><block ref="6e4a3fe2b0629dae504d8e727147f709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b889b7255c34e7f230e392668605860" category="list-text">導入先のクラスタのリージョン、 VPC 、およびセキュリティグループを選択します。このセクションでは、ノード（およびメディエーター）ごとのアベイラビリティゾーンと、ゾーンが占有しているサブネットも割り当てます。</block>
  <block id="9ad68c9f72863557931a8569462bff52" category="paragraph"><block ref="9ad68c9f72863557931a8569462bff52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be43ebbf5380089f153e4f1b13e35e6f" category="list-text">メディエーターとともにノードの接続方法を選択します。</block>
  <block id="8bf6da8b537127466c4421c1ae3169be" category="paragraph"><block ref="8bf6da8b537127466c4421c1ae3169be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="204bd52e1d13052712299779cf041df6" category="admonition">メディエーターは AWS API との通信を必要とします。メディエーター EC2 インスタンスを導入したあとで API にアクセスできる場合は、パブリック IP アドレスは必要ありません。</block>
  <block id="52fade87431f9acc43b7bf6e4c5fd2f1" category="inline-link">ネットアップのクラウドに関するドキュメント</block>
  <block id="0c79e4a46253eeb94ba6b8218928aa99" category="list-text">フローティング IP アドレスは、クラスタ管理 IP やデータサービス IP など、 Cloud Volumes ONTAP で使用されるさまざまな IP アドレスへのアクセスを許可するために使用されます。これらのアドレスは、ネットワーク内でルーティングされていないアドレスである必要があり、 AWS 環境のルーティングテーブルに追加されます。これらのアドレスは、フェイルオーバー時に HA ペアの一貫した IP アドレスを有効にするために必要です。フローティング IP アドレスの詳細については、を参照してください<block ref="72cde540b4f97efa19e071f729439801" category="inline-link-rx"></block>。</block>
  <block id="fd4a46ceddfb2402b7e37177af575e04" category="paragraph"><block ref="fd4a46ceddfb2402b7e37177af575e04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ca6b5e9b64aed9132a6be07d061f3b" category="list-text">フローティング IP アドレスが追加されるルーティングテーブルを選択します。これらのルーティングテーブルは、クライアントが Cloud Volumes ONTAP と通信するために使用します。</block>
  <block id="3453ab81a2f04d5c39ae750fb79ece2a" category="paragraph"><block ref="3453ab81a2f04d5c39ae750fb79ece2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af918e519f9c0db1ed5ab4fd4b6e9e05" category="list-text">AWS で管理する暗号化を有効にするか、 AWS KMS を有効にして ONTAP ルートディスク、ブートディスク、データディスクを暗号化するかを選択します。</block>
  <block id="058eaefa711702bd45c5f6650cf01e4c" category="paragraph"><block ref="058eaefa711702bd45c5f6650cf01e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01bd54fa77587425fca4a6c352309b5c" category="list-text">ライセンスモデルを選択します。選択する項目がわからない場合は、ネットアップの担当者にお問い合わせください。</block>
  <block id="e5e49184799594a9fa690c9122eb883e" category="paragraph"><block ref="e5e49184799594a9fa690c9122eb883e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04110b24d1459a6e21e35ad976a8f10e" category="list-text">ユースケースに最も適した構成を選択してください。これは、前提条件のページに記載されているサイジングに関する考慮事項に関連したものです。</block>
  <block id="e19584159c9c3791a9e3c462cb0aa451" category="paragraph"><block ref="e19584159c9c3791a9e3c462cb0aa451" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ed47788a525c6d08246bfa2f90922da" category="list-text">必要に応じて、ボリュームを作成します。次の手順では SnapMirror を使用してボリュームを作成するため、この作業は必要ありません。</block>
  <block id="01da9401385484b72ba9c016ac6c19ab" category="paragraph"><block ref="01da9401385484b72ba9c016ac6c19ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76011f95c4e1b3f68fa5829dab0fb786" category="list-text">選択内容を確認し、チェックボックスをオンにして、 Cloud Manager によって AWS 環境にリソースが導入されることを確認します。準備ができたら、 [ 移動 ] をクリックします。</block>
  <block id="7b78e746aa55ffe6fee1f3e0b65b8cca" category="paragraph"><block ref="7b78e746aa55ffe6fee1f3e0b65b8cca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13b7f009673a469e5482a96832be1473" category="list-text">Cloud Volumes ONTAP による導入プロセスが開始されます。Cloud Manager は、 AWS API とクラウド形成スタックを使用して Cloud Volumes ONTAP を導入します。次に、お客様の仕様に合わせてシステムを構成し、すぐに利用できるすぐに使えるシステムを提供します。このプロセスのタイミングは、選択内容によって異なります。</block>
  <block id="11d15d8a4bb9195b48d5010fa30fa547" category="paragraph"><block ref="11d15d8a4bb9195b48d5010fa30fa547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e63d2329924bb302fb012e7916b3614" category="list-text">タイムラインに移動することで進行状況を監視できます。</block>
  <block id="77405312cc4c1e96d3f7f796e838bf89" category="paragraph"><block ref="77405312cc4c1e96d3f7f796e838bf89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b4df7cc92b3ee31f5d95082a78c7903" category="list-text">タイムラインは、 Cloud Manager で実行されるすべてのアクションの監査として機能します。Cloud Manager のセットアップ時に AWS と ONTAP クラスタの両方に対して行われたすべての API 呼び出しを表示できます。これは、直面している問題のトラブルシューティングにも効果的に使用できます。</block>
  <block id="8c17e020c76595308d57605fa71dc7af" category="paragraph"><block ref="8c17e020c76595308d57605fa71dc7af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c5674ad1910f0a25455fdeb0f3f097a" category="list-text">導入が完了すると、現在の容量である Canvas に CVO クラスタが表示されます。現在の状態の ONTAP クラスタは、設定なしで真のエクスペリエンスを提供できるように完全に設定されています。</block>
  <block id="db044bc640be9fc8227b7ada891f279d" category="paragraph"><block ref="db044bc640be9fc8227b7ada891f279d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28d2e01957d5845ff59688f17bd34339" category="section-title">オンプレミスからクラウドへ SnapMirror を設定</block>
  <block id="081494b1a178710486921a42e2bdfa87" category="paragraph">ソース ONTAP システムとデスティネーション ONTAP システムが導入されたので、データベースデータを含むボリュームをクラウドにレプリケートできます。</block>
  <block id="cb3269c2496a99fb03bebe82b6a3e4bc" category="inline-link">SnapMirror Compatibility Matrix を参照してください</block>
  <block id="46aad6288d89ba29f38b4742bf018aca" category="paragraph">互換性のある SnapMirror の ONTAP バージョンに関するガイドについては、を参照してください<block ref="f75a4f2138bf92eb17ef87cad85a9e34" category="inline-link-rx"></block>。</block>
  <block id="36c5350a8474f2212fecc811eb77df57" category="list-text">ソース ONTAP システム（オンプレミス）をクリックし、宛先にドラッグアンドドロップするか、 Replication （レプリケーション） &gt; Enable （有効）を選択するか、 Replication （レプリケーション） &gt; Menu （メニュー） &gt; Replicate （複製）を選択します。</block>
  <block id="5dbe69ec28d70286f46385336e96d003" category="paragraph"><block ref="5dbe69ec28d70286f46385336e96d003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8771a8fdaa9e84a7eef7540edcca5f40" category="paragraph">Enable を選択します。</block>
  <block id="ac21962f3f0ae9f9c17b26196452f903" category="paragraph"><block ref="ac21962f3f0ae9f9c17b26196452f903" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6a8dc55f6f333187a100f6ed328bdc0" category="paragraph">または [ オプション ] を選択し</block>
  <block id="949fa0a5e194cf44c9e08903cb914566" category="paragraph"><block ref="949fa0a5e194cf44c9e08903cb914566" category="inline-image-macro-rx" type="image"></block></block>
  <block id="066bf779660ad446aa9b0d4021c4bf40" category="paragraph">レプリケート：</block>
  <block id="deafbb4908c633cb93a7f7e76b31da08" category="paragraph"><block ref="deafbb4908c633cb93a7f7e76b31da08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a803b2a55429f981d25fbb8da94aef7" category="list-text">ドラッグアンドドロップしなかった場合は、レプリケート先のクラスタを選択します。</block>
  <block id="630e74180bc1b6c0c0c866d5478ff029" category="paragraph"><block ref="630e74180bc1b6c0c0c866d5478ff029" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761124dc5e0730086556a7d33d43418c" category="list-text">レプリケートするボリュームを選択します。データとすべてのログボリュームをレプリケートしました。</block>
  <block id="7bec2596a51a0d4a808a37dec9e6c540" category="paragraph"><block ref="7bec2596a51a0d4a808a37dec9e6c540" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bde4e8497f5ecaef866c0f049aada776" category="list-text">デスティネーションのディスクタイプと階層化ポリシーを選択します。ディザスタリカバリには、ディスクタイプとして SSD を使用し、データの階層化を維持することを推奨します。データを階層化することで、ミラーリングされたデータを低コストのオブジェクトストレージに階層化し、ローカルディスクにコストを削減できます。関係を解除するかボリュームのクローンを作成すると、高速なローカルストレージがデータに使用されます。</block>
  <block id="a7d9908d0f610b3db167c894d109d1ec" category="paragraph"><block ref="a7d9908d0f610b3db167c894d109d1ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f06f2f09c024b69ef3944a8cd78ad9" category="list-text">デスティネーション・ボリューム名を選択します [source_volume_name] _dr] を選択します</block>
  <block id="6f8ba85bc89d216799431f124e48b25f" category="paragraph"><block ref="6f8ba85bc89d216799431f124e48b25f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2882a0dbc1a6ad74198ac2cb6316870d" category="list-text">レプリケーションの最大転送速度を選択します。これにより、 VPN などのクラウドへの低帯域幅接続がある場合に帯域幅を節約できます。</block>
  <block id="041263f562a9058ae414685962469951" category="paragraph"><block ref="041263f562a9058ae414685962469951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f81dd66e0f0847d4cb1d2d12fadcc2f3" category="list-text">レプリケーションポリシーを定義ミラーを選択したところ、最新のデータセットがデスティネーションボリュームにレプリケートされます。また、要件に応じて別のポリシーを選択することもできます。</block>
  <block id="d0b86e2934c870915aaa77674d1d79d7" category="paragraph"><block ref="d0b86e2934c870915aaa77674d1d79d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4db5384e8d04b01ff24a9178b3efaf6a" category="list-text">レプリケーションを開始するスケジュールを選択します。要件に応じて変更することもできますが、ネットアップでは、データボリュームの「毎日」のスケジュールとログボリュームの「時間単位」のスケジュールを設定することを推奨します。</block>
  <block id="c6715d4de4d68a1f8eb9cb8acb63b097" category="paragraph"><block ref="c6715d4de4d68a1f8eb9cb8acb63b097" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02e3a269661e3c96a86a075872a1b269" category="list-text">入力した情報を確認し、 Go をクリックしてクラスタピアと SVM ピアをトリガーし（ 2 つのクラスタ間のレプリケーションを初めて行う場合）、 SnapMirror 関係を実装して初期化します。</block>
  <block id="75c2d297cd7282b30ce0400170110307" category="paragraph"><block ref="75c2d297cd7282b30ce0400170110307" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c160366cab97ee8f1a35416d1294ddb" category="list-text">データボリュームとログボリュームについては、このプロセスを続行してください。</block>
  <block id="64853c47f4f907262466c1e5ad154c8c" category="list-text">すべての関係を確認するには、 Cloud Manager の Replication （レプリケーション）タブに移動します。ここでは、関係を管理し、その状態を確認できます。</block>
  <block id="641e620fe8c714d7381775d20a707726" category="paragraph"><block ref="641e620fe8c714d7381775d20a707726" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c88bec52f9e24233a78b6a90efa32ec6" category="list-text">すべてのボリュームがレプリケートされたあと、安定した状態になり、ディザスタリカバリと開発 / テストのワークフローに進むことができます。</block>
  <block id="86fb3ee49ae2f8c0ee121c551a8f08c2" category="section-title">3. データベースワークロードの EC2 コンピューティングインスタンスを導入します</block>
  <block id="91ba52045df2b9244f28270482f749c9" category="inline-link">EC2 インスタンスタイプ</block>
  <block id="33aaa72e62140af9cecb2c48f836b84b" category="paragraph">AWS では、さまざまなワークロードに対して EC2 コンピューティングインスタンスが事前に設定されていますインスタンスタイプの選択によって、 CPU コア数、メモリ容量、ストレージタイプと容量、およびネットワークパフォーマンスが決まります。OS パーティションを除き、データベースワークロードを実行するメインストレージは、 CVO または FSX ONTAP ストレージエンジンから割り当てられます。したがって、考慮すべき主な要因は、 CPU コア、メモリ、およびネットワークパフォーマンスレベルの選択です。一般的な AWS EC2 インスタンスタイプは次のとおりです。<block ref="9334d5b9e602c5921b4f295f6041489b" category="inline-link-rx"></block>。</block>
  <block id="0af43c3d809d6e56a6a7a0d1ed039bbc" category="section-title">コンピューティングインスタンスのサイズを決定します</block>
  <block id="0b6e77aedd6bd733f979314fef2a98d7" category="list-text">必要なワークロードに基づいて適切なインスタンスタイプを選択します。考慮すべき要因としては、サポートされるビジネストランザクションの数、同時ユーザの数、データセットのサイジングなどがあります。</block>
  <block id="c421d122321bec48d6b30858f4e7b515" category="inline-link">Amazon EC2</block>
  <block id="ed4b68006572e288530a2152f7fbe5fe" category="list-text">EC2 インスタンスの導入は、 EC2 ダッシュボードから実行できます。具体的な導入手順については、この解決策では説明していません。を参照してください<block ref="3a5862dd365e3998013717e9cf118a9a" category="inline-link-rx"></block> を参照してください。</block>
  <block id="708991723f71fa1bd7b8081be442552c" category="section-title">Oracle ワークロード向けの Linux インスタンス構成</block>
  <block id="5c17b7d75ff16063f772234e1ea8eeb1" category="paragraph">このセクションでは、 EC2 Linux インスタンスを導入したあとの追加の設定手順について説明します。</block>
  <block id="39d786446455bb2b3017b793805fc902" category="list-text">SnapCenter 管理ドメイン内で名前解決のために、 Oracle スタンバイインスタンスを DNS サーバに追加します。</block>
  <block id="385a2a4f5305fe5ce8017f18fb7eabd4" category="list-text">パスワードなしの sudo 権限で SnapCenter OS のクレデンシャルとして Linux 管理ユーザ ID を追加します。EC2 インスタンスで SSH パスワード認証を使用する ID を有効にします。（デフォルトでは、 EC2 インスタンスで SSH パスワード認証とパスワードなしの sudo は無効になっています）。</block>
  <block id="a2b4677d7a72840a78373c600441681a" category="list-text">OS パッチ、 Oracle のバージョン、パッチなど、オンプレミスの Oracle インストールと一致するように Oracle インストールを設定します。</block>
  <block id="66b65364302a847feb2630bfd7974256" category="inline-link">Oracle 19C 自動導入</block>
  <block id="fa470598a181c1ed905bace243e46aa3" category="list-text">NetApp Ansible DB 自動化ロールを使用して、データベースの開発 / テストとディザスタリカバリのユースケース用に EC2 インスタンスを設定できます。自動化コードは、 NetApp パブリックの GitHub サイトからダウンロードできます。<block ref="437f8b44ff65600fb5697e9d369a0c54" category="inline-link-rx"></block>。目的は、データベースソフトウェアスタックを EC2 インスタンスにインストールして設定し、オンプレミスの OS とデータベースの設定を一致させることです。</block>
  <block id="97875b4799caf4c948118e7b4776c9fb" category="section-title">SQL Server ワークロード用の Windows インスタンス構成</block>
  <block id="c63751cfdcf8c0b4e26635a47c7f0d97" category="paragraph">このセクションでは、 EC2 Windows インスタンスを最初に導入したあとの追加の設定手順を示します。</block>
  <block id="5f44e6a78874f9f49acae3caa71cc14d" category="list-text">RDP を使用してインスタンスにログインするには、 Windows 管理者パスワードを取得します。</block>
  <block id="eabafc642b0901afd6622ab0f19d9ef0" category="list-text">Windows ファイアウォールを無効にし、ホストを Windows SnapCenter ドメインに追加し、名前解決のために DNS サーバにインスタンスを追加します。</block>
  <block id="08bf2d7ff3ac9ab37cfa8dc449b3c8da" category="list-text">SQL Server ログファイルを格納する SnapCenter ログボリュームをプロビジョニングします。</block>
  <block id="f97ac9d1946c873247af15165559b47a" category="list-text">Windows ホストで iSCSI を構成し、ボリュームをマウントしてディスクドライブをフォーマットします。</block>
  <block id="6c2a9c611f48cae767f6ebea6fca0457" category="inline-link">NetApp の自動化</block>
  <block id="6dea6226167bd38268de4c4d948d72de" category="list-text">繰り返しになりますが、これまでのタスクの多くは、 NetApp Automation 解決策 for SQL Server を使用して自動化することができます。NetApp Automation のパブリック GitHub サイトで、新たに公開されたロールとソリューションを確認できます。<block ref="8cafb3a3b1222d318fcd262791229701" category="inline-link-rx"></block>。</block>
  <block id="752c08adf364adb2721c9a373759f8f6" category="inline-link-macro">次：クラウドへの開発 / テストバーストのワークフロー</block>
  <block id="4e3fc3c2eb04754fcac9e4e23b6de054" category="paragraph"><block ref="4e3fc3c2eb04754fcac9e4e23b6de054" category="inline-link-macro-rx"></block></block>
  <block id="ac9bef0f960e3a46befd2d06b223b61d" category="summary">このセクションでは、開発とテスト、および DR の運用に使用される一般的なハイブリッドクラウドアーキテクチャについて説明します。</block>
  <block id="fece52c505c48f2979e3fa0c8b6bd8bc" category="paragraph"><block ref="fece52c505c48f2979e3fa0c8b6bd8bc" category="inline-link-macro-rx"></block></block>
  <block id="4085a97aa705c0122bbcec0c84dd97d3" category="paragraph">次のアーキテクチャ図は、開発 / テスト運用とディザスタリカバリ処理のためのエンタープライズデータベース運用をハイブリッドクラウドで実装する一般的な方法を示しています。</block>
  <block id="acb339f710a626679c374df5b90c5416" category="paragraph"><block ref="acb339f710a626679c374df5b90c5416" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cdc302c6d83b60c8ec7ad0b550e55a8" category="paragraph">通常のビジネス運用では、クラウド内の同期されたデータベースボリュームをクローニングし、アプリケーションの開発 / テスト用データベースインスタンスにマウントできます。障害が発生した場合は、クラウド内の同期されたデータベースボリュームをディザスタリカバリ用にアクティブ化できます。</block>
  <block id="fbfd3304757c668454a7bdd10f9de200" category="inline-link-macro">次のステップ：ソリューションの要件</block>
  <block id="ae3b1bce66c4c75d8abf9828ec9f2608" category="paragraph"><block ref="ae3b1bce66c4c75d8abf9828ec9f2608" category="inline-link-macro-rx"></block></block>
  <block id="c94d29f1f4f8ef37e9d27f30b7d7c67d" category="summary">SnapCenter ハイブリッドクラウドデータベースワークロード環境を準備するには、このセクションで説明するタスクをオンプレミスで完了する必要があります。</block>
  <block id="f6a196d9d3a941e76765e4a9395630c4" category="doc">オンプレミスの前提条件</block>
  <block id="eac55cbc45bfe6b98b8847b3952de7d3" category="inline-link-macro">前のページ：前提条件の設定</block>
  <block id="e63a288cc25b5c4127d3021b339c9f20" category="paragraph"><block ref="e63a288cc25b5c4127d3021b339c9f20" category="inline-link-macro-rx"></block></block>
  <block id="40931dcd4d9132545ec0faf2c5fb1b64" category="paragraph">SnapCenter ハイブリッドクラウドデータベースワークロード環境を準備するには、オンプレミスで次のタスクを完了する必要があります。</block>
  <block id="79daf399b9626cde309801f41a1e2e14" category="section-title">SnapCenter のインストールと設定</block>
  <block id="2607530756fefa4173e12cfcd5fbfb01" category="paragraph">NetApp SnapCenter ツールは Windows ベースのアプリケーションで、通常は Windows ドメイン環境で実行されますが、ワークグループ導入も可能です。これは、集中管理サーバー（ SnapCenter サーバー）とデータベースワークロード用のデータベースサーバーホスト上の SnapCenter プラグインを含む多層アーキテクチャに基づいています。ここでは、ハイブリッドクラウドの導入に関する主な考慮事項をいくつか示します。</block>
  <block id="9f8c0bcd11d7afd1dd2ee818191cb914" category="list-text">* 単一インスタンスまたは HA 展開。 * HA 展開は、単一 SnapCenter インスタンスサーバーに障害が発生した場合に冗長性を提供します。</block>
  <block id="1bfa2867d5aa49106efbf3ac752f3084" category="list-text">* 名前解決。 * フォワードルックアップとリバースルックアップのためには、ストレージ SVM 上だけでなくすべてのデータベースホストを解決するために SnapCenter サーバ上で DNS を設定する必要があります。フォワードルックアップとリバースルックアップの両方で SnapCenter サーバとストレージ SVM を解決するためには、データベースサーバで DNS も設定する必要があります。</block>
  <block id="41f54308d86c1d7b525475d6ead22892" category="list-text">* ロールベースアクセス制御（ RBAC ）の設定。 * 混在データベースワークロードの場合は、 RBAC を使用して、 Oracle データベースの管理者や SQL Server の管理者など、異なる DB プラットフォーム用の管理責任を分離できます。DB 管理者ユーザには、必要な権限が付与されている必要があります。</block>
  <block id="5aee5dffd2e329652ec35995add763ae" category="list-text">* バックアップの一貫性と信頼性を確保するために、ポリシー・ベースのバックアップ戦略を有効にします。 *</block>
  <block id="dde4790e572aa9d01cd58fcfd8498766" category="list-text">* ファイアウォール上の必要なネットワーク・ポートを開きます。 * オンプレミスの SnapCenter サーバーが、クラウド DB ホストにインストールされたエージェントと通信できるようにします。</block>
  <block id="e2962676531ebdcf62cb2a7b96042e77" category="list-text">* ポートは、オンプレミスとパブリッククラウド間の SnapMirror トラフィックを許可するためにオープンである必要があります。 * SnapCenter サーバは、 ONTAP SnapMirror を使用して、オンサイトの Snapshot バックアップをクラウドの CVO ストレージ SVM にレプリケートします。</block>
  <block id="549762060d7242346fa79f39cba51791" category="inline-link-macro">SnapCenter の設置ワークフロー</block>
  <block id="aec875397d57826c45f7072636026a07" category="paragraph">インストール前の計画と考慮事項を慎重に検討したら、これをクリックしてください <block ref="f44e9d032441cc842cad02c3aab57d84" category="inline-link-macro-rx"></block> SnapCenter のインストールと設定の詳細については、を参照してください。</block>
  <block id="df3fb602185c77a88bab186791d02636" category="section-title">オンプレミスのデータベースサーバのストレージ構成</block>
  <block id="f7f3a649be867b87ccb26789453199db" category="paragraph">データベースとアプリケーションの全体的なパフォーマンスには、ストレージのパフォーマンスが重要な役割を果たします。適切に設計されたストレージレイアウトでは、 DB のパフォーマンスを向上させるだけでなく、データベースのバックアップとリカバリの管理も簡単に行えます。ストレージレイアウトを定義する際には、データベースのサイズ、データベースの予想されるデータ変更率、バックアップの実行頻度など、いくつかの要素を考慮する必要があります。</block>
  <block id="8481231881c8e64b34aa3c7e29510a25" category="paragraph">一般に、仮想データベースワークロード用に NFS または iSCSI でストレージ LUN をゲスト VM に直接接続すると、 VMDK 経由で割り当てられたストレージよりもパフォーマンスが向上します。次の図に示す LUN 上にある大規模な SQL Server データベースのストレージレイアウトを使用することを推奨します。</block>
  <block id="cc75f443d22e45e490468a8f20689d77" category="paragraph"><block ref="cc75f443d22e45e490468a8f20689d77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99aea05cf884bfdec230afa5250968b2" category="paragraph">次の図は、 LUN 上の小規模または中規模の SQL Server データベースに推奨されるストレージレイアウトを示しています。</block>
  <block id="9fc72535f1113895818f8aa60ef773e7" category="paragraph"><block ref="9fc72535f1113895818f8aa60ef773e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ecde8f778d0dd0676f392793ce4382" category="admonition">ログディレクトリは SnapCenter 専用で、データベースリカバリ用のトランザクションログロールアップを実行します。1 つのボリュームに複数の LUN を割り当てて、パフォーマンスを向上させることもできます。</block>
  <block id="ee9158729a15dbd90d166650ba285d0e" category="paragraph">Oracle データベースワークロードの場合、 SnapCenter は、 ONTAP ストレージを使用するデータベース環境をサポートします。この環境は、物理デバイスまたは仮想デバイスとしてホストにマウントされます。環境の重要度に基づいて、データベース全体を単一または複数のストレージデバイス上にホストすることができます。通常、専用ストレージにあるデータファイルは、制御ファイル、 REDO ファイル、アーカイブログファイルなどの他のすべてのファイルから分離されます。これにより、管理者は Snapshot テクノロジを使用して数秒から数分以内に（ ONTAP の単一ファイル SnapRestore ）を迅速にリストアしたり、大規模な重要データベース（ペタバイト規模）のクローンを作成したりできます。</block>
  <block id="b31fbb7e1a6e863315e431fdf9c00db9" category="paragraph"><block ref="b31fbb7e1a6e863315e431fdf9c00db9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="959a3405dfdfb0469534f5276ffb8e5e" category="paragraph">レイテンシの影響を受けやすいミッションクリティカルなワークロードに対しては、可能なかぎり最適なレイテンシを実現するために、異なる種類の Oracle ファイルに専用のストレージボリュームを導入する必要があります。大規模なデータベースの場合は、ボリュームごとに複数の LUN をデータファイルに割り当てる必要があります（最大 8 個まで推奨）。</block>
  <block id="ac111cbcae2e9eaedafe418acc3a2cab" category="paragraph"><block ref="ac111cbcae2e9eaedafe418acc3a2cab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2702ce3d59ec94853fa030462b309f2f" category="paragraph">小規模な Oracle データベースの場合、 SnapCenter は共有ストレージレイアウトをサポートしています。共有ストレージレイアウトでは、同じストレージボリュームまたは LUN 上で複数のデータベースまたはデータベースの一部をホストできます。このレイアウトの例として、 +DATA ASM ディスクグループまたはボリュームグループ上のすべてのデータベースのデータファイルをホストできます。それ以外のファイル（ REDO ファイル、アーカイブログファイル、および制御ファイル）は、別の専用ディスクグループまたはボリュームグループ（ LVM ）でホストすることができます。このような導入シナリオを次に示します。</block>
  <block id="6c12e98a6e201f55836390c2a6232e5a" category="paragraph"><block ref="6c12e98a6e201f55836390c2a6232e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93cf45b97655292e0536b810cb248828" category="paragraph">Oracle データベースの再配置を容易にするには、通常のバックアップポリシーに含まれている別の LUN に Oracle バイナリをインストールする必要があります。これにより、新しいサーバホストにデータベースを再配置する場合、 Oracle バイナリの同期が取れていないため、潜在的な問題が発生することなく、 Oracle スタックをリカバリ用に起動できます。</block>
  <block id="1e69a4a8adec0842d1e110e970112268" category="section-title">ライセンス要件</block>
  <block id="7f59934b2c0edd33f0d981f3bc4d12e7" category="paragraph">SnapCenter は、ネットアップが提供するライセンスソフトウェアです。これは通常、オンプレミスの ONTAP ライセンスに含まれています。ただし、ハイブリッドクラウドの導入の場合は、 SnapCenter に CVO をターゲットデータレプリケーションのデスティネーションとして追加するために、 SnapCenter のクラウドライセンスも必要です。詳細については、次のリンク先で SnapCenter の標準容量ベースのライセンスを確認してください。</block>
  <block id="9e86ae6c96041e3cb31e88116102ee35" category="inline-link-macro">SnapCenter の容量単位の標準ライセンスです</block>
  <block id="a1d51b5b5f3258b40cbe392146bc8868" category="paragraph"><block ref="a1d51b5b5f3258b40cbe392146bc8868" category="inline-link-macro-rx"></block></block>
  <block id="85db56d490cdd7a31d40697ad1c9be3c" category="section-title">ネットワークとセキュリティ</block>
  <block id="254215e6d18fb5582ba78464fa468553" category="paragraph">オンプレミスの本番データベースをオンプレミスで運用し、開発 / テストやディザスタリカバリのためにクラウドへの移行が非常に活発になるハイブリッドデータベースでは、環境をセットアップしてオンプレミスのデータセンターからパブリッククラウドに接続する際に、ネットワークとセキュリティを考慮することが重要です。</block>
  <block id="1e356fab450b44971b6cdbd1c25586b8" category="paragraph">パブリッククラウドでは、一般に仮想プライベートクラウド（ VPC ）を使用して、パブリッククラウドプラットフォーム内の異なるユーザを分離します。個々の VPC 内では、 VPC のロックダウンのユーザニーズに基づいて設定可能なセキュリティグループなどの手法を使用してセキュリティが制御されます。</block>
  <block id="5192a6d33c7a0127a67cbd7e07801735" category="paragraph">オンプレミスのデータセンターから VPC への接続は、 VPN トンネルを介して保護できます。VPN ゲートウェイでは、 NAT およびファイアウォールルールを使用してセキュリティを強化できます。このルールでは、インターネット上のホストから企業データセンター内のホストへのネットワーク接続の確立をブロックします。</block>
  <block id="04a3995237c020c6a587d8a7723af6a6" category="paragraph">ネットワークとセキュリティに関する考慮事項については、任意のパブリッククラウドに対する、関連するインバウンドおよびアウトバウンドの CVO ルールを確認してください。</block>
  <block id="d15513a147fbd525b88805bee9ea17ea" category="inline-link-macro">CVO-AWS のセキュリティグループルール</block>
  <block id="f8d1f085169118c4d407be16136389c6" category="list-text"><block ref="f8d1f085169118c4d407be16136389c6" category="inline-link-macro-rx"></block></block>
  <block id="39f48b44d100d16ed6e2b931111663b7" category="inline-link-macro">CVO-Azure のセキュリティグループルール</block>
  <block id="bcde746324630d82052a4fc9861cfea6" category="list-text"><block ref="bcde746324630d82052a4fc9861cfea6" category="inline-link-macro-rx"></block></block>
  <block id="7b20c547f2fd113499deaa3c0e418282" category="inline-link-macro">CVO-GCP のファイアウォールルール</block>
  <block id="acde731d82a437ab33cb200791f7a197" category="list-text"><block ref="acde731d82a437ab33cb200791f7a197" category="inline-link-macro-rx"></block></block>
  <block id="d9446a69434b7c7fdec5c9e35d222834" category="section-title">Ansible による自動化を使用して、オンプレミスとクラウドの間で DB インスタンスを同期することもできます。これはオプションです</block>
  <block id="1c7c9b49a62ea0dc765d1439120cfc8f" category="paragraph">ハイブリッドクラウドデータベース環境の管理を簡易化するために、ネットアップでは Ansible コントローラを導入して、コンピューティングインスタンスをオンプレミスやクラウドに同期させるなどの一部の管理タスクを自動化することを強く推奨していますが、必須ではありません。特に重要なのは、クラウド内の同期されていないコンピューティングインスタンスが原因で、カーネルパッケージやその他の問題が原因で、リカバリされたデータベースがクラウドエラーになる可能性があるためです。</block>
  <block id="7468552c7fc3a7ca377b7fc2405a9940" category="paragraph">Ansible コントローラの自動化機能を使用して、 SnapMirror インスタンスの解除などの特定のタスクで SnapCenter を補強し、本番環境で DR データコピーをアクティブ化することもできます。</block>
  <block id="6ac547919eb6ca11f5a8387eaf990843" category="inline-link-macro">RedHat / CentOS Ansible コントローラのセットアップ</block>
  <block id="c8e133fc33bbdb52f84b3532496f2ac8" category="inline-link-macro">Ubuntu / Debian Ansible のコントローラセットアップ</block>
  <block id="6f332c2f54a4d49478f9588c5cd6c57c" category="paragraph">以下の手順に従って、 RedHat または CentOS マシン用の Ansible コントロールノードをセットアップします。 <block ref="fedce547519117863322cfa54cc2ba7d" category="inline-link-macro-rx"></block>。Ubuntu または Debian マシン用の Ansible の制御ノードをセットアップするには、次の手順に従います。 <block ref="1c50818f5fe40dbc8b2e05138d554fa4" category="inline-link-macro-rx"></block>。</block>
  <block id="d5316785c089f90464e8e683aadd02e1" category="inline-link-macro">次のステップ：パブリッククラウド</block>
  <block id="d09f79a080b121cb1acc181711b5d02a" category="paragraph"><block ref="d09f79a080b121cb1acc181711b5d02a" category="inline-link-macro-rx"></block></block>
  <block id="d89002d36151bd13d2bba69f3533ee5f" category="summary">この解決策では、ネットアップの営業担当者やお客様に、 NetApp SnapCenter の GUI ベースのツールとパブリッククラウドのネットアップストレージサービス CVO を使用して、データベースをハイブリッドクラウド環境に設定、運用、移行するための手順とガイダンスを提供しています。</block>
  <block id="8269707c3930f3cbcd49193be33bc125" category="doc">TR-4908 ：『 Hybrid Cloud Database Solutions with SnapCenter Overview 』</block>
  <block id="7c4d94e1b484fb577b0aeafbec788ea1" category="paragraph">ネットアップ、 Felix Melligan 、 Alan Co 氏</block>
  <block id="268a30b4d0cad062acd42967ce0fab50" category="paragraph">この解決策では、次のユースケースについて、 NetApp SnapCenter の GUI ベースのツールとパブリッククラウドのネットアップストレージサービス CVO を使用して、データベースをハイブリッドクラウド環境に設定、運用、移行するための手順とガイダンスを、ネットアップの営業担当者やお客様に提供しています。</block>
  <block id="e88a2467c8ad8bf481854b1a745a875b" category="list-text">ハイブリッドクラウドでのデータベース開発 / テスト運用</block>
  <block id="3c9552536897a076f75b078a5e2a3703" category="list-text">ハイブリッドクラウドでのデータベースディザスタリカバリ</block>
  <block id="a1ac690c228caf22f3228d3a4d8b5cab" category="paragraph">現在でも、多くのエンタープライズデータベースは、パフォーマンスやセキュリティなどの理由から、プライベートな企業データセンターに配置されています。このハイブリッドクラウドデータベース解決策を使用すると、開発 / テストデータベースの運用にパブリッククラウドを使用しながら、企業はプライマリデータベースをオンサイトで運用できるようになります。ディザスタリカバリにも対応しているため、ライセンスコストと運用コストを削減できます。</block>
  <block id="d900d125b3be40bcb79452d624c38561" category="paragraph">Oracle 、 SQL Server 、 SAP HANA など、多数のエンタープライズデータベース 高いライセンスコストと運用コストを負担します。多くのお客様は、コアを開発、テスト、本番、ディザスタリカバリに使用するかどうかにかかわらず、データベース環境内のコンピューティングコアの数に基づいて 1 回限りのライセンス料金と年間サポートコストを負担しています。そのような環境の多くは、アプリケーションのライフサイクルを通じてフル活用されない場合があります。</block>
  <block id="1f49cc83c5c3735827e3353f320f5f7f" category="paragraph">このソリューションは、開発、テスト、ディザスタリカバリに特化したデータベース環境をクラウドに移行することで、ライセンス可能なコア数を潜在的に削減するためのオプションをお客様に提供します。パブリッククラウドの拡張性、冗長性、高可用性、使用量に応じた課金モデルを使用することで、ライセンスと運用のコストを大幅に削減できると同時に、アプリケーションの使用や可用性を損なうこともありません。</block>
  <block id="1a197dd926608052c7d43edfd09556fa" category="paragraph">ネットアップの容量ベースの CVO ライセンスモデルでは、潜在的なデータベースライセンスコストの削減に加えて、ストレージコストを GB 単位で削減すると同時に、競合するストレージサービスでは利用できない高レベルのデータベース管理機能を利用できるようにしています。次のグラフは、パブリッククラウドで利用できる一般的なストレージサービスのストレージコストの比較です。</block>
  <block id="810fba7bc9a3829eb522ebbc24326a08" category="paragraph"><block ref="810fba7bc9a3829eb522ebbc24326a08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e222eb27a0002f2960d1cf1e14bbf7d" category="paragraph">この解決策は、 SnapCenter の GUI ベースのソフトウェアツールと NetApp SnapMirror テクノロジを使用することで、ハイブリッドクラウドデータベースの運用を簡単にセットアップ、実装、運用できることを実証しています。</block>
  <block id="26cc8c416b5c9fd6bec3dc68e6f2f0c8" category="paragraph">次のビデオでは、 SnapCenter の実際の動作を紹介します。</block>
  <block id="edc6673fe24c4867029921bbe72f25cb" category="inline-link">SnapCenter を使用して、ハイブリッドクラウド全体で Oracle データベースをバックアップする</block>
  <block id="b10d6cd72b187359c3769fbf5ff10e4c" category="list-text"><block ref="0d160cec2141981b284cd9986321651e" category="inline-link-rx"></block></block>
  <block id="68d9033a95c0ed286c9b7e0e7454cd86" category="inline-link">SnapCenter - Oracle データベース用の AWS クラウドに開発 / テストをクローニング</block>
  <block id="da8d0116fa67f0499837675277668911" category="list-text"><block ref="da8d0116fa67f0499837675277668911" category="inline-link-rx"></block></block>
  <block id="3b04263461ad5a7b57aa872e093ec9fa" category="paragraph">特に、このドキュメントの図では、 CVO をパブリッククラウドのターゲットストレージインスタンスとして示していますが、 ONTAP は、 AWS 向け FSX 解決策ストレージエンジンの新しいリリースに対しても完全に検証されています。</block>
  <block id="c5a6d2f45fc4352f35e95d92c804b6f2" category="paragraph">解決策の動作やユースケースを自社でテストするために、ネットアップラボオンデマンドの SL10680 が次のリンクからリクエストできます： https://labondemand.netapp.com/lod3/labtest/request?nodeid=68761&amp;destination=lod3/testlabs[TL_AWS_004 HCD ： AWS-NW 、 SnapCenter （ OnPrem ） ^ ]</block>
  <block id="d31314285161c777a09609cc4fb2d07a" category="inline-link-macro">次は、ソリューションアーキテクチャです。</block>
  <block id="0830319fc7a6b051bbb0602c2778e67c" category="paragraph"><block ref="0830319fc7a6b051bbb0602c2778e67c" category="inline-link-macro-rx"></block></block>
  <block id="8f7280c86689be0a39cdf74aa673040d" category="summary">この解決策はハイブリッドクラウド環境で設計されており、開発 / テストやディザスタリカバリ処理の目的で一般的なすべてのパブリッククラウドにバーストできます。オンプレミスの本番データベースをサポートします。</block>
  <block id="132f2888eb2cfdeef2730212f50c53e3" category="doc">SnapCenter の要件</block>
  <block id="e2a7d0854ef572e10255339732bb005d" category="inline-link-macro">以前のバージョン：ソリューションアーキテクチャ。</block>
  <block id="b10927905ed5379ba0d73333abdbe06d" category="paragraph"><block ref="b10927905ed5379ba0d73333abdbe06d" category="inline-link-macro-rx"></block></block>
  <block id="185b108b21dccef917f415be6026c91c" category="paragraph">本番環境のデータベースサーバをオンプレミスでホストし、 ONTAP ストレージクラスタから DB ホストに DB ボリュームを提供するとします。SnapCenter ソフトウェアをオンプレミスにインストールし、データベースのバックアップとクラウドへのデータレプリケーションを行う。Ansible コントローラを推奨しますが、データベース導入の自動化や、 OS カーネル、およびデータベース構成の、パブリッククラウドのスタンバイ DR インスタンスや開発 / テストインスタンスとの同期には必要ありません。</block>
  <block id="47099d9ea153f8abfa5b6b70da253b3a" category="cell">* オンプレミス *</block>
  <block id="d36407241494bfc1e84614ad1b0dd6a4" category="cell">SnapCenter でサポートされるデータベースおよびバージョン</block>
  <block id="8c8c8ca7a4093a1210412a3a5e5ad55f" category="cell">SnapCenter v4.4 以降</block>
  <block id="9d9ebf67dab68c3c892de99e981039cf" category="cell">Ansible v2.09 以降</block>
  <block id="62dd4f48e99b13c8a00fbaba684f9592" category="cell">ONTAP クラスタ 9.x</block>
  <block id="d0fdc58e1e05d6cbc8b1beb072bfa235" category="cell">クラスタ間 LIF が設定されました</block>
  <block id="7135df562bcb25bfdf20e4317b923b88" category="cell">オンプレミスからクラウド VPC への接続（ VPN 、インターコネクトなど）</block>
  <block id="8c27863f5ffd0e66a9304eaca2e47fde" category="cell">ネットワークポートが開いています - ssh 22 - TCP 8145 、 8146 、 10000 、 11104 、 11105</block>
  <block id="bcb9f3419f724f768e30956a4427261d" category="cell">* クラウド - AWS *</block>
  <block id="61c90d44785278f980592f082ef500f1" category="inline-link">Cloud Manager Connector の略</block>
  <block id="97bc5062dceccb6827b1e3f0522035f0" category="cell"><block ref="97bc5062dceccb6827b1e3f0522035f0" category="inline-link-rx"></block></block>
  <block id="2f077494ceff1f33085c5b163c3673b3" category="cell"><block ref="2f077494ceff1f33085c5b163c3673b3" category="inline-link-rx"></block></block>
  <block id="59b2c9424963f98d73ec69c59dde54cb" category="cell">DB OS EC2 インスタンスとオンプレミスを一致させる必要があります</block>
  <block id="e26786a16da88ee829ab76c48fd3b003" category="cell">* クラウド - Azure *</block>
  <block id="c2f8674b07907f393b67a3f9e98d3d56" category="cell"><block ref="c2f8674b07907f393b67a3f9e98d3d56" category="inline-link-rx"></block></block>
  <block id="a8dd724647657a383eb37fd8775ec1a9" category="cell"><block ref="a8dd724647657a383eb37fd8775ec1a9" category="inline-link-rx"></block></block>
  <block id="8bede1f0e559918be01f0646b75b4257" category="cell">DB OS の Azure 仮想マシンをオンプレミスと一致させる</block>
  <block id="b2a454fb4ff03b84162c59d674fdae25" category="cell">* クラウド - GCP*</block>
  <block id="af072236983e991ab34e773871b10236" category="cell"><block ref="af072236983e991ab34e773871b10236" category="inline-link-rx"></block></block>
  <block id="499477cf7953707f63a1b1313c8c065a" category="cell"><block ref="499477cf7953707f63a1b1313c8c065a" category="inline-link-rx"></block></block>
  <block id="2900c5e1ee191606f20d007194e70edf" category="cell">DB OS の Google Compute Engine インスタンスをオンプレミスと一致させる</block>
  <block id="126b29c0beff0884077277115103a374" category="inline-link-macro">次の手順：前提条件の構成。</block>
  <block id="a6d027dea0e97ba248528210d36e5475" category="paragraph"><block ref="a6d027dea0e97ba248528210d36e5475" category="inline-link-macro-rx"></block></block>
  <block id="d0bb28dcc0cc1b523a41bbb46875db9e" category="summary">Cloud Manager Connector と Cloud Volumes ONTAP をインストールして SnapMirror を設定する前に、クラウド環境向けの準備を行う必要があります。このページでは、 Cloud Volumes ONTAP を導入する際に考慮すべき点と同様に、実行する必要がある作業について説明します。</block>
  <block id="8c6fb9ece3bad11d3e76d1344d9ed9ab" category="doc">パブリッククラウドの前提条件</block>
  <block id="ac7eeb8ecebe00daa1fdf4fd06cc46de" category="inline-link-macro">前：オンプレミスの前提条件</block>
  <block id="70ba5e430ac8eade85f8e01e51412fe4" category="paragraph"><block ref="70ba5e430ac8eade85f8e01e51412fe4" category="inline-link-macro-rx"></block></block>
  <block id="5a2798d22185b0e40ea502bbbb171d38" category="section-title">Cloud Manager と Cloud Volumes ONTAP の導入の前提条件チェックリスト</block>
  <block id="1e094e6477be231098329b0096c7221f" category="list-text">NetApp Cloud Central へのログイン</block>
  <block id="b59e275c4ece2430dff67db92845ab7f" category="list-text">Web ブラウザから複数のエンドポイントへのネットワークアクセス</block>
  <block id="d2ed5c7ede8a1ce9d218ec60b0f03935" category="list-text">コネクタのネットワーク上の場所</block>
  <block id="0d07862d67097acd517fe27c0de099d7" category="list-text">クラウドプロバイダの権限</block>
  <block id="203802866ac2835e79bd76c94a3761c2" category="list-text">個々のサービスのネットワーク</block>
  <block id="c4d5e1cbdfc47a0fdcb4a1a9dddd9e17" category="inline-link">クラウドのドキュメント</block>
  <block id="1a22a3f7b690b2ec8919c8806633fb26" category="paragraph">開始する必要がある項目の詳細については、を参照してください<block ref="247d95fa755d21bb8790cc6d7a2fc412" category="inline-link-rx"></block>。</block>
  <block id="ea61e2c2ff507048203824add1eb7c21" category="section-title">考慮事項</block>
  <block id="176ca67b83510a1281a4cfc749a3543a" category="section-title">1. Cloud Manager Connector とは</block>
  <block id="1681641037afae45bd6074dcde9eed00" category="paragraph">ほとんどの場合、 Cloud Central アカウント管理者はクラウドまたはオンプレミスネットワークにコネクタを導入する必要があります。Connector を使用すると、 Cloud Manager でパブリッククラウド環境内のリソースとプロセスを管理できます。</block>
  <block id="8a78be5d168f00b24bf1625de3d5409c" category="paragraph">コネクタの詳細については、を参照してください<block ref="f39c14bbbbdd46ca70a63fb06046c789" category="inline-link-rx"></block>。</block>
  <block id="fcc2bf38b8157a22b5fc6975b7054acc" category="section-title">2. Cloud Volumes ONTAP のサイジングとアーキテクチャ</block>
  <block id="1c09b5154aa1f43cb9ebcbd6fea5eadc" category="paragraph">Cloud Volumes ONTAP を導入する際には、事前定義されたパッケージを選択するか、独自の設定を作成するかを選択できます。これらの値の多くはあとで無停止で変更することができますが、クラウドに導入するワークロードに基づいていくつかの重要な決定を行う必要があります。</block>
  <block id="331ce28903aee0b30cd3c94e5483edf5" category="inline-link">CVO のサイジングツール</block>
  <block id="acaed5d74e38e1779b3831dcf51c7600" category="paragraph">クラウドプロバイダごとに導入オプションが異なり、ほぼすべてのワークロードに独自のプロパティがあります。ネットアップには、があります<block ref="6a71e7e42ab9335484c5530029f79b92" category="inline-link-rx"></block> これは、容量とパフォーマンスに基づいて導入の規模を正しく決定するのに役立ちますが、次の点を考慮していくつかの基本的な概念を中心に構築されています。</block>
  <block id="145c90afb7955854f2371e9decf3de9b" category="list-text">容量が必要です</block>
  <block id="f1521b662bf51f1af6c2d38bd610afae" category="list-text">クラウド仮想マシンのネットワーク機能</block>
  <block id="f75d8ba5edc8017382d5df68baf9e30f" category="list-text">クラウドストレージのパフォーマンス特性</block>
  <block id="af9d66ea3132fcfeb46b85557bc1af1b" category="paragraph">重要な点は、現在の容量とパフォーマンスの要件を満たすだけでなく、将来の拡張も考慮する構成を計画することです。これは、一般に容量ヘッドルームおよびパフォーマンスヘッドルームと呼ばれます。</block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="inline-link">AWS</block>
  <block id="3a580f142203677f1f0bc30898f63f53" category="inline-link">Azure</block>
  <block id="c731f72e1d22a7c5e01a7cb789a8885e" category="inline-link">GCP</block>
  <block id="180f0326dff3a03aecf5e184943d108a" category="paragraph">詳細については、の計画に関するドキュメントを参照してください<block ref="af5d70b69c3436f8bcf6f7b9579c4e83" category="inline-link-rx"></block>、<block ref="c2e85b51d3015b4c720388e64a3de23e" category="inline-link-rx"></block>および<block ref="b1068926334a08925797774f64291db4" category="inline-link-rx"></block>。</block>
  <block id="c50ea1f0c6dcf02fbdd39e1e6b5befc2" category="section-title">3. シングルノードとハイアベイラビリティのどちらか？</block>
  <block id="eadb13b9c72271dbf16967e78059fea4" category="paragraph">どのクラウドでも、 CVO を導入できるノードは 1 つだけです。 2 つのノードで構成されるクラスタハイアベイラビリティペアにもなります。ユースケースによっては、コストを削減するためにシングルノードを導入したり、可用性と冗長性を向上させるために HA ペアを導入したりすることができます。</block>
  <block id="9cbd119b18cd836b6020fcfd3bfbe37f" category="paragraph">DR のユースケースでは、開発とテストのために一時的なストレージをスピンアップする場合でも、突然のゾーンの停止やインフラの停止による影響が小さいため、シングルノードが一般的です。ただし、本番環境では、データが 1 箇所だけに格納されている場合や、データセットの冗長性と可用性を高める必要がある場合に、高可用性を推奨します。</block>
  <block id="83d2ad0cda1f71c52878284cc7c1f713" category="paragraph">各クラウドバージョンのハイアベイラビリティのアーキテクチャの詳細については、のドキュメントを参照してください<block ref="4344469628657b2a6a0d147e5e6fbc9a" category="inline-link-rx"></block>、<block ref="28a8305eced80cb5b1351f5cffb268ae" category="inline-link-rx"></block> および<block ref="1b945d178a8347e94e5c5456dc9e6db8" category="inline-link-rx"></block>。</block>
  <block id="f0d106c1997a933ecb53ee88e83670e7" category="inline-link-macro">次の手順：概要。</block>
  <block id="fd43d07d375b44f30fde6995279b9265" category="paragraph"><block ref="fd43d07d375b44f30fde6995279b9265" category="inline-link-macro-rx"></block></block>
  <block id="a10998cc3e1dc7f2a013754d935c4f26" category="summary">NetApp SnapCenter ツールでは、ロールベースアクセス制御（ RBAC ）を使用してユーザリソースのアクセスと権限付与を管理します。また、 SnapCenter のインストール時に、すでにデータを含むロールが作成されます。また、ニーズやアプリケーションに基づいてカスタムロールを作成することもできます。</block>
  <block id="7e3b07f9add4cd78ade3c795a52dfad2" category="doc">オンプレミスでの作業の開始</block>
  <block id="32229cff9e0b41c513b3e3b9e19cec88" category="inline-link-macro">前の手順：概要。</block>
  <block id="6be036b00e3db4159514171a989cacd6" category="paragraph"><block ref="6be036b00e3db4159514171a989cacd6" category="inline-link-macro-rx"></block></block>
  <block id="d30e54646ba482722332f48ddc22bde5" category="section-title">1. SnapCenter でデータベース管理者ユーザを設定します</block>
  <block id="72f706d19ed0d09889b4fbc7578cd1a3" category="paragraph">NetApp SnapCenter ツールでは、 Role-Based Access Control （ RBAC ；ロールベースアクセス制御）を使用してユーザリソースのアクセス権と権限付与を管理し、 SnapCenter のインストール時にすでにデータを含むロールが作成されます。また、ニーズやアプリケーションに基づいてカスタムロールを作成することもできます。データベースのバックアップ、リストア、ディザスタリカバリを行う場合は、 SnapCenter でサポートされているデータベースプラットフォームごとに専用の管理者ユーザ ID を使用することを推奨します。単一の ID を使用してすべてのデータベースを管理することもできます。テストケースとデモでは、それぞれ Oracle と SQL Server の両方に専用の管理者ユーザを作成しました。</block>
  <block id="27733e8f07432bb94ac7621b28d3b2c8" category="paragraph">特定の SnapCenter リソースは、 SnapCenterAdmin ロールでのみプロビジョニングできます。その後、リソースを他のユーザ ID に割り当ててアクセスできるようになります。</block>
  <block id="64784aa3cec13e83af6e941f8489cf06" category="paragraph">オンプレミスの SnapCenter 環境が事前にインストールおよび設定されている場合は、次のタスクがすでに完了している可能性があります。設定されていない場合は、次の手順でデータベース管理ユーザを作成します。</block>
  <block id="c8867eac833e7bb55520105b00139f1a" category="list-text">Windows Active Directory に管理者ユーザを追加します。</block>
  <block id="dd3e743eb52cbe7c2b6104573a9767e0" category="list-text">SnapCenterAdmin ロールで付与された ID を使用して SnapCenter にログインします。</block>
  <block id="a6bd76cb24271ba173d16f01bf4108d0" category="list-text">[ 設定とユーザー ] の下の [ アクセス ] タブに移動し、 [ 追加 ] をクリックして新しいユーザーを追加します。新しいユーザ ID は、手順 1 で Windows Active Directory に作成した管理者ユーザにリンクされます。。必要に応じて、適切なロールをユーザに割り当てます。必要に応じて、管理者ユーザにリソースを割り当てます。</block>
  <block id="6a67bb048bd14dd348cca7f81b62d699" category="paragraph"><block ref="6a67bb048bd14dd348cca7f81b62d699" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5d2c51e83f473f137861a132554d1916" category="section-title">2. SnapCenter プラグインのインストールの前提条件</block>
  <block id="7bd973d4d28d6fcf5f50379b33a49758" category="paragraph">SnapCenter は、 DB ホストで実行されているプラグインエージェントを使用して、バックアップ、リストア、クローニングなどの処理を実行します。プラグインのインストールやその他の管理機能の [ 設定と資格情報 ] タブで設定された資格情報を使用して、データベースホストとデータベースに接続します。Linux や Windows などのターゲットホストタイプとデータベースのタイプに基づいて、特定の権限要件があります。</block>
  <block id="c342f214098114b90cb67297a2ef5dc3" category="paragraph">SnapCenter プラグインをインストールする前に、 DB ホストのクレデンシャルを設定しておく必要が一般に、 DB ホスト上の管理者ユーザアカウントは、プラグインのインストールに使用するホスト接続クレデンシャルとして使用します。OS ベースの認証を使用して、データベースアクセスに同じユーザ ID を付与することもできます。一方、データベース管理アクセスには、異なるデータベースユーザ ID を使用したデータベース認証を使用することもできます。OS ベースの認証を使用する場合は、 OS 管理ユーザ ID に DB アクセス権を付与する必要があります。Windows ドメインベースの SQL Server をインストールする場合、ドメイン管理者アカウントを使用して、ドメイン内のすべての SQL Server を管理できます。</block>
  <block id="19df1192effefad83e57653fd3a47415" category="paragraph">SQL Server 用 Windows ホスト：</block>
  <block id="e1cc3ce53d7753e33588201db3d3b147" category="list-text">認証に Windows クレデンシャルを使用している場合は、プラグインをインストールする前にクレデンシャルを設定する必要があります。</block>
  <block id="a82f1290b72a26d654b93632a1ec50bb" category="list-text">認証に SQL Server インスタンスを使用している場合は、プラグインのインストール後にクレデンシャルを追加する必要があります。</block>
  <block id="63f74bef6650942c6795f96366a39e6a" category="list-text">クレデンシャルの設定時に SQL 認証を有効にすると、検出されたインスタンスやデータベースに赤いロックアイコンが表示されます。ロックアイコンが表示された場合、リソースグループに追加する際にそのインスタンスまたはデータベースのクレデンシャルを指定する必要があります。</block>
  <block id="b61dad3bbbf3270bf2dada5c2ac1f775" category="list-text">次の条件に該当する場合、 sysadmin アクセスがない RBAC ユーザにクレデンシャルを割り当てる必要があります。</block>
  <block id="34cefb5a19894e4f9b1b068544c0f591" category="list-text">SQL インスタンスに資格情報が割り当てられます。</block>
  <block id="6707464a5871a6aa26dcf785bea4052c" category="list-text">SQL インスタンスまたはホストが RBAC ユーザに割り当てられている。</block>
  <block id="4bc8aac02ff00d874ad8b4ccd4d745ed" category="list-text">RBAC DB 管理者ユーザには、リソースグループとバックアップ権限の両方が必要です。</block>
  <block id="9198b455aa67840c7a69c7a54e94301a" category="paragraph">Oracle 用 UNIX ホスト：</block>
  <block id="71d53e54a48cfe7de69347bcd854ef30" category="list-text">sshd.conf を編集して sshd サービスを再起動して、 root または root 以外のユーザのパスワードベースの SSH 接続を有効にしておく必要があります。AWS インスタンスでのパスワードベースの SSH 認証は、デフォルトではオフになっています。</block>
  <block id="efa873f0464a14d54b066f475ad74480" category="list-text">プラグインプロセスをインストールして開始できるように root 以外のユーザの sudo 権限を設定します。プラグインをインストールすると、プロセスは有効な root ユーザーとして実行されます。</block>
  <block id="82a2174029175f8fbc3f52fea4e18c84" category="list-text">インストールユーザの Linux 認証モードでクレデンシャルを作成します。</block>
  <block id="86b3cc44ebd8e0a9185e48c4f22e81e9" category="list-text">Java 1.8.x （ 64 ビット）は Linux ホストにインストールする必要があります。</block>
  <block id="c1e8851d10ecc615c47a47f704569d29" category="list-text">Oracle データベースプラグインをインストールすると、 UNIX 用 SnapCenter プラグインもインストールされます。</block>
  <block id="7efb27733d1fb21feae901a41580dced" category="section-title">3. SnapCenter ホストプラグインのインストール</block>
  <block id="37a5c714defad8175b81b4d49eb0544c" category="admonition">SnapCenter プラグインをクラウド DB サーバーインスタンスにインストールする前に、コンピューティングインスタンスの導入に関する該当するクラウドセクションに記載されているすべての設定手順が完了していることを確認してください。</block>
  <block id="283aa502c28fe1c9ff8dadd1700955fc" category="paragraph">次の手順は、 SnapCenter プラグインがホストにインストールされている状態で、データベースホストが SnapCenter に追加される方法を示しています。手順環境はオンプレミスホストとクラウドホストの両方を追加します。次のデモでは、 AWS に Windows または Linux ホストを追加します。</block>
  <block id="81ed46777c39c0d0618953601572fc27" category="section-title">SnapCenter の VMware グローバル設定を構成します</block>
  <block id="2aa8a40dbbfb6b52621408c81aa5373c" category="paragraph">[ 設定 ] &gt; [ グローバル設定 ] に移動します。ハイパーバイザー設定で、「 VM に iSCSI 直接接続ディスクまたはすべてのホスト用の NFS がある」を選択し、更新をクリックします。</block>
  <block id="4c120331c9eea223eee675b6588d76ee" category="paragraph"><block ref="4c120331c9eea223eee675b6588d76ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f63a469619859e4cfab52fd63523aca" category="section-title">Windows ホストおよびプラグインのインストールをホストに追加します</block>
  <block id="997da6deedab4436b559e3a8f7f05a2e" category="list-text">SnapCenterAdmin 権限でユーザ ID を使用して SnapCenter にログインします。</block>
  <block id="97e7f600216a2e9ae18423777e11ad9c" category="list-text">左側のメニューから [Hosts] タブをクリックし、 [Add] をクリックして [Add Host] ワークフローを開きます。</block>
  <block id="35314bae57d7ff62ab36156211c1cc71" category="list-text">ホストタイプとして Windows を選択しますホスト名には ' ホスト名または IP アドレスを指定できますホスト名を SnapCenter ホストから正しいホスト IP アドレスに解決する必要があります。手順 2 で作成したホストクレデンシャルを選択します。インストールするプラグインパッケージとして Microsoft Windows と Microsoft SQL Server を選択します。</block>
  <block id="b9740ae9eb2ef0fe27e4c541d06a961f" category="paragraph"><block ref="b9740ae9eb2ef0fe27e4c541d06a961f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31efcd689861354799bb539ab2571ebe" category="list-text">プラグインが Windows ホストにインストールされると、その全体的なステータスは「 Configure log directory 」と表示されます。</block>
  <block id="0e15e25c5ee21469698f72cf35caa7bf" category="paragraph"><block ref="0e15e25c5ee21469698f72cf35caa7bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2aeaa4503c6d72513c0dbe0f205ee3b" category="list-text">ホスト名をクリックして、 SQL Server ログディレクトリの設定を開きます。</block>
  <block id="6fc78660a180b747f815b878c89e3cb0" category="paragraph"><block ref="6fc78660a180b747f815b878c89e3cb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb2b40646a77b4f044e7fa04ea20306" category="list-text">[ ログディレクトリの設定 ] をクリックして、 [ Plug-in for SQL Server の設定 ] を開きます。</block>
  <block id="5e3bf9ddacfcad12c5cf63614a869ad4" category="paragraph"><block ref="5e3bf9ddacfcad12c5cf63614a869ad4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7143b5d162d385dfb1af07f61c59f65" category="list-text">[ 参照 ] をクリックしてネットアップストレージを検出し、ログディレクトリを設定できるようにします。 SnapCenter はこのログディレクトリを使用して、 SQL Server トランザクションログファイルをロールアップします。[ 保存 ] をクリックします。</block>
  <block id="50eb49de485da684ac1556947ac46aba" category="paragraph"><block ref="50eb49de485da684ac1556947ac46aba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0d88588bdb07dd412a4ba1d08348b29" category="admonition">DB ホストにプロビジョニングされたネットアップストレージを検出するには、 CVO の手順 6 に示すように、ストレージ（オンプレミスまたは CVO ）を SnapCenter に追加する必要があります。</block>
  <block id="d744af12906d55ab51aa932b3ffcd121" category="list-text">ログディレクトリを構成すると、 Windows ホストプラグインの [ 全般的なステータス ] が [ 実行中 ] に変更されます。</block>
  <block id="3f7bfffdbb76fd620b0a31d300415528" category="paragraph"><block ref="3f7bfffdbb76fd620b0a31d300415528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41517f2e270a138f4ae92988a4cbdd2" category="list-text">ホストをデータベース管理ユーザー ID に割り当てるには、 [ 設定とユーザー ] の [ アクセス ] タブに移動し、データベース管理ユーザー ID ( この場合はホストを割り当てる必要がある sqldba ) をクリックして、 [ 保存 ] をクリックしてホストリソースの割り当てを完了します。</block>
  <block id="b21f826d2ea15e58b9c8aadccb566cfe" category="paragraph"><block ref="b21f826d2ea15e58b9c8aadccb566cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021de72edbb0f174ffe954c5e5367b80" category="paragraph"><block ref="021de72edbb0f174ffe954c5e5367b80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2fe19c733a6342990513e02264db163" category="section-title">UNIX ホストを追加し、プラグインをホストにインストールします</block>
  <block id="6a0f36be9f208d20c3c1145c3a09b876" category="list-text">左側のメニューから [Hosts] タブをクリックし、 [Add] をクリックして [Add Host] ワークフローを開きます。</block>
  <block id="dd8c6d773e31c4254eb58b4b5e2ae1be" category="list-text">ホストタイプとして Linux を選択します。ホスト名には、ホスト名または IP アドレスを使用できます。ただし、ホスト名を解決して、 SnapCenter ホストから正しいホスト IP アドレスを取得する必要があります。手順 2 で作成したホストクレデンシャルを選択します。ホストのクレデンシャルには sudo 権限が必要です。Oracle Database をインストールするプラグインとしてチェックし、 Oracle と Linux の両方のホストプラグインをインストールします。</block>
  <block id="7d4cdef2144fd1466fae298bd27476d1" category="paragraph"><block ref="7d4cdef2144fd1466fae298bd27476d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="711730391561a228d41f7fede13ca6e8" category="list-text">[ その他のオプション ] をクリックし、 [ インストール前のチェックをスキップ ] を選択します。 インストール前のチェックを省略するかどうかを確認するプロンプトが表示されます。[ はい ] をクリックし、 [ 保存 ] をクリック</block>
  <block id="3511b18d059f3f300b5fbe827f7273ac" category="paragraph"><block ref="3511b18d059f3f300b5fbe827f7273ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e095a093138c6b1968d313d5f799255a" category="list-text">Submit をクリックして、プラグインのインストールを開始します。次のように指紋の確認を求められます。</block>
  <block id="146c4805beb9310e4554842f776cb88b" category="paragraph"><block ref="146c4805beb9310e4554842f776cb88b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53dcda6f2c03efbe73ae5eb311852a8d" category="list-text">SnapCenter はホストの検証と登録を実行し、プラグインを Linux ホストにインストールします。ステータスは、プラグインのインストールから実行に変わります。</block>
  <block id="2636403a6c50748422736d9d84a3e4be" category="paragraph"><block ref="2636403a6c50748422736d9d84a3e4be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="33ea9d9313933c68d640ebb655ec43dc" category="list-text">新しく追加したホストに、適切なデータベース管理ユーザ ID （この場合は oradba ）を割り当てます。</block>
  <block id="2815d2f5e3b49d9332a320ec997271dd" category="paragraph"><block ref="2815d2f5e3b49d9332a320ec997271dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb6a9566891a97e0f8fbaefbd4878bdd" category="paragraph"><block ref="eb6a9566891a97e0f8fbaefbd4878bdd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b4c839521fd41e845e6e8c3158b809b" category="section-title">4. データベースリソースの検出</block>
  <block id="45e46a9524f23884445bf542bf464b93" category="paragraph">プラグインのインストールが正常に完了すると、ホスト上のデータベースリソースがすぐに検出されます。左側のメニューの [ リソース ] タブをクリックします。データベースプラットフォームのタイプに応じて、データベース、リソースグループなどのさまざまなビューを使用できます。ホスト上のリソースが検出されて表示されない場合は、 Refresh Resources タブをクリックする必要があります。</block>
  <block id="79fca6395972f8079320d3229822e491" category="paragraph"><block ref="79fca6395972f8079320d3229822e491" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66789731e61fd3d4b6024e5fcb0945e1" category="paragraph">データベースが最初に検出されると、全体的なステータスは「 Not protected 」と表示されます。 前のスクリーンショットは、バックアップポリシーでまだ保護されていない Oracle データベースを示しています。</block>
  <block id="68148a1249ca9110d03c698ae152932a" category="paragraph">バックアップの設定またはポリシーが設定されていて、バックアップが実行された場合、データベースの全体的なステータスには、バックアップのステータスが「 Backup succeeded 」と表示され、最後のバックアップのタイムスタンプが表示されます。次のスクリーンショットは、 SQL Server ユーザデータベースのバックアップステータスを示しています。</block>
  <block id="2cdfb74ac3aabfde7e1fae347ed5afc7" category="paragraph"><block ref="2cdfb74ac3aabfde7e1fae347ed5afc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c9616324bc00808729d46fba94ad75" category="paragraph">データベースアクセスクレデンシャルが適切に設定されていない場合は、赤いロックボタンが表示され、データベースにアクセスできないことが示されます。たとえば、 Windows クレデンシャルにデータベースインスタンスへの sysadmin アクセスがない場合、赤いロックを解除するためにデータベースクレデンシャルを再設定する必要があります。</block>
  <block id="dd4606e87689c86d82a694412c5654a5" category="paragraph"><block ref="dd4606e87689c86d82a694412c5654a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="884f07ad394b89553e7d6d1f90fae584" category="paragraph"><block ref="884f07ad394b89553e7d6d1f90fae584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0024854a814ddd68bcf3907357c46bc2" category="paragraph">Windows レベルまたはデータベースレベルのいずれかで適切なクレデンシャルを設定すると、赤いロックは消え、 SQL Server Type の情報が収集および確認されます。</block>
  <block id="95c88e08b2fd416b4514ce2454af2038" category="paragraph"><block ref="95c88e08b2fd416b4514ce2454af2038" category="inline-image-macro-rx" type="image"></block></block>
  <block id="864f4d2595d06e5e8b46b08edb3899e6" category="section-title">5. ストレージクラスタピアリングと DB ボリュームレプリケーションの設定</block>
  <block id="785196ec55a9e713ad1a4f962baa31dd" category="paragraph">パブリッククラウドをターゲットとするデスティネーションとしてオンプレミスのデータベースデータを保護するために、オンプレミスの ONTAP クラスタデータベースボリュームは、 NetApp SnapMirror テクノロジを使用してクラウドの CVO にレプリケートされます。レプリケートされたターゲットボリュームを、開発 / OPS またはディザスタリカバリ用にクローニングできます。以下に、クラスタピアリングと DB ボリュームレプリケーションの設定手順の概要を示します。</block>
  <block id="1f1927293f04e4cf0fc91a7e389612eb" category="list-text">オンプレミスクラスタと CVO クラスタインスタンスの両方で、クラスタピアリング用のクラスタ間 LIF を設定できます。この手順は、 ONTAP システムマネージャを使用して実行できます。CVO のデフォルトの導入では、クラスタ間 LIF が自動的に設定されます。</block>
  <block id="9547803d96e78bbc38305e6300f7a800" category="paragraph">オンプレミスクラスタ：</block>
  <block id="2ef6da9ba547bc5361495650ac3fc992" category="paragraph"><block ref="2ef6da9ba547bc5361495650ac3fc992" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3c5b3e342f57b792e2263e69e41677a" category="paragraph">ターゲットの CVO クラスタ：</block>
  <block id="d94586e4cd285619a4f1ef0e06636dd1" category="paragraph"><block ref="d94586e4cd285619a4f1ef0e06636dd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79d372933b80ed2ca8ca14d8458828af" category="inline-link-macro">はじめに - AWS パブリッククラウド</block>
  <block id="6a87ea28950f9209121872c9d2690049" category="list-text">クラスタ間 LIF を設定した場合、 NetApp Cloud Manager でドラッグアンドドロップを使用してクラスタピアリングとボリュームレプリケーションを設定できます。を参照してください <block ref="28783e162df4af496939d6f9f6f31d5f" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="d1567c6c8f0752cbc7deb6d9f639ba12" category="paragraph">または、 ONTAP System Manager を使用して、クラスタピアリングと DB ボリュームレプリケーションを次のように実行することもできます。</block>
  <block id="494c0b53ff31502c0c1105881e2e389a" category="list-text">ONTAP システムマネージャにログインします。クラスタ &gt; 設定に移動し、ピアクラスタをクリックして、クラウド内の CVO インスタンスとのクラスタピアリングをセットアップします。</block>
  <block id="ba770272a0f634af47a5788634e80d54" category="paragraph"><block ref="ba770272a0f634af47a5788634e80d54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54de72c782c4b4ccc7f2914a858d5356" category="list-text">Volumes （ボリューム）タブに移動します。レプリケートするデータベースボリュームを選択し、 Protect （保護）をクリックします。</block>
  <block id="32588f46a47679329b03194fd2e9084f" category="paragraph"><block ref="32588f46a47679329b03194fd2e9084f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0aace069b478e8b2b0753f855f2be94" category="list-text">保護ポリシーを非同期に設定します。デスティネーションクラスタと Storage SVM を選択してください。</block>
  <block id="7dbec53b432ae53f7e454836ad0dad00" category="paragraph"><block ref="7dbec53b432ae53f7e454836ad0dad00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a2a64fe8af0790615a9344069794e2e" category="list-text">ソースとターゲットの間でボリュームが同期されていること、およびレプリケーション関係が正常な状態であることを確認します。</block>
  <block id="97edcd79a5e90d9caafde40fcb586185" category="paragraph"><block ref="97edcd79a5e90d9caafde40fcb586185" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36097c4ad6058de288de8992f89adbb8" category="section-title">6. CVO データベースストレージの SVM を SnapCenter に追加する</block>
  <block id="ebcf85d67af3f672ade8bd7b224a8a2b" category="list-text">メニューからストレージシステムタブをクリックし、新規をクリックして、レプリケートされたターゲットデータベースボリュームをホストする CVO ストレージ SVM を SnapCenter に追加します。Storage System フィールドにクラスタ管理 IP を入力し、適切なユーザ名とパスワードを入力します。</block>
  <block id="41e9c94a0c8cb108959099b8f87adb82" category="paragraph"><block ref="41e9c94a0c8cb108959099b8f87adb82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a27406b63f99780f65572b95f2f72348" category="list-text">[ その他のオプション ] をクリックして、追加のストレージ構成オプションを開きます。[ プラットフォーム Cloud Volumes ONTAP ] フィールドで、 [ 保存 ] をクリックし、 [ セカンダリ ] をオンにします。</block>
  <block id="8a60464ab91cb2499a03c722639c3aee" category="paragraph"><block ref="8a60464ab91cb2499a03c722639c3aee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b474a0a2de59b8e3013112beb48af7b7" category="list-text">に示すように、ストレージシステムを SnapCenter データベース管理ユーザ ID に割り当てます <block ref="8a46cbc3838a53b9205abb25a577bbc8" category="inline-xref-macro-rx"></block>。</block>
  <block id="8691f91a1fe977fd76aa5e53b0f71034" category="paragraph"><block ref="8691f91a1fe977fd76aa5e53b0f71034" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39ec95149453e7bb6b73f1c03228e85c" category="section-title">7. SnapCenter でデータベースバックアップポリシーを設定します</block>
  <block id="37d9f685e375f77a2231e13c88ccc606" category="paragraph">次に、フルデータベースバックアップポリシーまたはログファイルバックアップポリシーを作成する手順を示します。このポリシーを実装することで、データベースリソースを保護できます。データベースバックアップやログバックアップの頻度は、 Recovery Point Objective （ RPO ；目標復旧時点）または Recovery Time Objective （ RTO ；目標復旧時間）によって決まります。</block>
  <block id="739184f368f13e142dd034fcdc853594" category="section-title">Oracle のフルデータベースバックアップポリシーを作成します</block>
  <block id="94b39254a7aba068b68fec64f6331b0b" category="list-text">データベース管理ユーザ ID として SnapCenter にログインし、 [ 設定 ] をクリックして、 [ ポリシー ] をクリックします。</block>
  <block id="90affc4ffbb767a3d1272be5e1ad8f0c" category="paragraph"><block ref="90affc4ffbb767a3d1272be5e1ad8f0c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1d144b8c78fc8541b57aa9f0ca863a6" category="list-text">新規をクリックして新しいバックアップポリシー作成ワークフローを開始するか、変更する既存のポリシーを選択します。</block>
  <block id="29618ae8465c694d23d68e171fe9d905" category="paragraph"><block ref="29618ae8465c694d23d68e171fe9d905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c9dac29c26006ce512153a9bdabcc95" category="list-text">バックアップタイプとスケジュール頻度を選択します。</block>
  <block id="10e2791563a2891fd7e4e68c5673671b" category="paragraph"><block ref="10e2791563a2891fd7e4e68c5673671b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4df94ad44381c9fb7fe2f8d01dcd16d8" category="list-text">バックアップ保持を設定します。これにより、保持するフルデータベースバックアップコピーの数が定義されます。</block>
  <block id="6dcc4aa023085480846059b6b1d5e5b3" category="paragraph"><block ref="6dcc4aa023085480846059b6b1d5e5b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd634020906b35a41e0ba633eddeb96a" category="list-text">セカンダリレプリケーションのオプションを選択して、クラウドのセカンダリサイトにレプリケートするローカルプライマリ Snapshot バックアップをプッシュします。</block>
  <block id="25ef9e4c73a2da8519e8d232b6a95fcb" category="paragraph"><block ref="25ef9e4c73a2da8519e8d232b6a95fcb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2e3af55a4355bc46e91425ac5701174" category="list-text">バックアップの実行前と実行後に実行するオプションのスクリプトを指定します。</block>
  <block id="326d50fae4f713cebe97d0f6bb23a2d9" category="paragraph"><block ref="326d50fae4f713cebe97d0f6bb23a2d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd009bc210e371d36d466b592179e883" category="list-text">必要に応じてバックアップ検証を実行</block>
  <block id="0b132e3438f5cf31e90f45e79710f0b9" category="paragraph"><block ref="0b132e3438f5cf31e90f45e79710f0b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba73d3ec3f929ff18665087076291ac" category="list-text">まとめ</block>
  <block id="4f92fa99421beeb9f74ee7613de52706" category="paragraph"><block ref="4f92fa99421beeb9f74ee7613de52706" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3594f2789840eda9633139ca530384a" category="section-title">Oracle のデータベースログバックアップポリシーを作成します</block>
  <block id="be763ec2afcb0358426bb0abcae4dd60" category="list-text">データベース管理ユーザ ID で SnapCenter にログインし、 [ 設定 ] をクリックして、 [ ポリシー ] をクリックします。</block>
  <block id="b0e663a3d363868d6c71ab9ec37940c6" category="list-text">新規をクリックして新しいバックアップポリシー作成ワークフローを開始するか、既存のポリシーを選択して変更します。</block>
  <block id="fa2687f5a5fbedb43745f649a2e11950" category="paragraph"><block ref="fa2687f5a5fbedb43745f649a2e11950" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0938f6574b189bdac27cdd92abc521c5" category="paragraph"><block ref="0938f6574b189bdac27cdd92abc521c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59480846ec23463481d361bf3026235e" category="list-text">ログの保持期間を設定します。</block>
  <block id="c8df578fbf71151edda735bc81e8511c" category="paragraph"><block ref="c8df578fbf71151edda735bc81e8511c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04ba33c0584145006ca637b4556aa919" category="list-text">パブリッククラウド内のセカンダリサイトへのレプリケーションを有効にします。</block>
  <block id="fdbe42a8484a3e984e4aacb6a31cccef" category="paragraph"><block ref="fdbe42a8484a3e984e4aacb6a31cccef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab9406cbd3a8f082700523fdac8a0c1d" category="list-text">ログバックアップの前後に実行するオプションのスクリプトを指定します。</block>
  <block id="5b04423521e56720f1f5d0291db584ef" category="paragraph"><block ref="5b04423521e56720f1f5d0291db584ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4b55e05a9ae89fe14377b98bc8a8166" category="list-text">バックアップ検証スクリプトを指定します。</block>
  <block id="c4dc219fd9466ab86c22ac8e859384ea" category="paragraph"><block ref="c4dc219fd9466ab86c22ac8e859384ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2564f2d008c62044da1b7f7397252edf" category="paragraph"><block ref="2564f2d008c62044da1b7f7397252edf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe147647227dfec6603bc76daf30463e" category="section-title">SQL のフルデータベースバックアップポリシーを作成します</block>
  <block id="fa726a7e85857bee77ace96dcf7e5316" category="paragraph"><block ref="fa726a7e85857bee77ace96dcf7e5316" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce2168daff0c9b1a74e59d999d6ead44" category="paragraph"><block ref="ce2168daff0c9b1a74e59d999d6ead44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30637cfd5a5cc820d6bc4116fccfff7e" category="list-text">バックアップオプションとスケジュール頻度を定義します。可用性グループが設定された SQL Server の場合は、優先バックアップレプリカを設定できます。</block>
  <block id="b520dcfd25c4b29395bb9b12ac643bb2" category="paragraph"><block ref="b520dcfd25c4b29395bb9b12ac643bb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f74ada8393aecd40e892de04b5b30f8" category="list-text">バックアップの保持期間を設定します。</block>
  <block id="4ade95d8122243cda1455b04504d3367" category="paragraph"><block ref="4ade95d8122243cda1455b04504d3367" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1a67a80a7ad9403781b210983ea778d" category="list-text">クラウドのセカンダリサイトへのバックアップコピーレプリケーションを有効にする。</block>
  <block id="caf8324e53d9bb41b3ecb64f3e3b7dda" category="paragraph"><block ref="caf8324e53d9bb41b3ecb64f3e3b7dda" category="inline-image-macro-rx" type="image"></block></block>
  <block id="17b7b360fc2163537795a34cd8d14d6a" category="list-text">バックアップジョブの前後に実行するオプションのスクリプトを指定します。</block>
  <block id="abbc7de57d2b0d5d1c462b7513199253" category="paragraph"><block ref="abbc7de57d2b0d5d1c462b7513199253" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb836d972496d965dd2170ed1480917b" category="list-text">バックアップ検証を実行するオプションを指定します。</block>
  <block id="b4dd01df6b310e6b0814328a86bd6ed6" category="paragraph"><block ref="b4dd01df6b310e6b0814328a86bd6ed6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67cfb8548ccb78172db31d7af494fa02" category="paragraph"><block ref="67cfb8548ccb78172db31d7af494fa02" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b67ed2348002e614d5a35151577632" category="section-title">SQL のデータベースログバックアップポリシーを作成します。</block>
  <block id="b405195aec7cf62440373fcdc490dec6" category="list-text">データベース管理ユーザ ID で SnapCenter にログインし、 [ 設定 ] 、 [ ポリシー ] 、 [ 新規 ] の順にクリックして、新しいポリシー作成ワークフローを開始します。</block>
  <block id="c236030076b67936a7c1c11d49408838" category="paragraph"><block ref="c236030076b67936a7c1c11d49408838" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acdaf46fc90606d68f3f2b52cca5e95b" category="list-text">ログバックアップオプションとスケジュール頻度を定義します。可用性グループが設定された SQL Server の場合は、優先バックアップレプリカを設定できます。</block>
  <block id="19ab604707a9384fa4883cedd5a525f9" category="paragraph"><block ref="19ab604707a9384fa4883cedd5a525f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da00d968a5d810d846ddc815b8f405a4" category="list-text">SQL Server データバックアップポリシーでログバックアップの保持を定義します。デフォルトをここで受け入れます。</block>
  <block id="783828e5ae6dcfd713966e7301831296" category="paragraph"><block ref="783828e5ae6dcfd713966e7301831296" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d04d89062d3ed67bbc9c4aee35bdba7f" category="list-text">クラウドのセカンダリへのログバックアップのレプリケーションを有効にします。</block>
  <block id="b1968bd01bc5c402dcd27c99ce6326cc" category="paragraph"><block ref="b1968bd01bc5c402dcd27c99ce6326cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30c50cf9d6726341a29a3caf97dc84e8" category="paragraph"><block ref="30c50cf9d6726341a29a3caf97dc84e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4d9b291b4ffaddb50c99313e530077f" category="paragraph"><block ref="c4d9b291b4ffaddb50c99313e530077f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f28f6c36698b3a4cd47cbeead15eddf2" category="section-title">8. データベースを保護するためのバックアップポリシーを実装します</block>
  <block id="37b889cc1b57f66ae9018b6eacb891ba" category="paragraph">SnapCenter では、リソースグループを使用して、サーバでホストされている複数のデータベース、同じストレージボリュームを共有しているデータベース、ビジネスアプリケーションをサポートしている複数のデータベースなど、データベースリソースを論理的にグループ化してデータベースをバックアップします。1 つのデータベースを保護すると、そのデータベース専用のリソースグループが作成されます。次の手順は、セクション 7 で作成したバックアップポリシーを実装して、 Oracle データベースと SQL Server データベースを保護する方法を示しています。</block>
  <block id="0603dbbe978e4cd3ee1c45ba96a1aa6f" category="section-title">Oracle のフルバックアップ用のリソースグループを作成する</block>
  <block id="5f4e02f34bcd7993867c4b3297a171d0" category="list-text">データベース管理ユーザ ID で SnapCenter にログインし、 Resources タブに移動します。[ 表示 ] ドロップダウンリストで、 [ データベース ] または [ リソースグループ ] を選択して、リソースグループ作成ワークフローを起動します。</block>
  <block id="6eac6f96ac8d968dfec8184d16a73d43" category="paragraph"><block ref="6eac6f96ac8d968dfec8184d16a73d43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="98dcf41bcde9cb6c4235a6a7dfe69346" category="list-text">リソースグループの名前とタグを指定します。Snapshot コピーの命名形式を定義し、冗長なアーカイブログデスティネーションが設定されている場合は省略できます。</block>
  <block id="a75ba82042ae54dd2e68cf6c7a26614c" category="paragraph"><block ref="a75ba82042ae54dd2e68cf6c7a26614c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0cd85a82e6f02b779006b158b9c5f828" category="list-text">リソースグループにデータベースリソースを追加する。</block>
  <block id="3836a8be1f86b6658a7fa6b180e4a72d" category="paragraph"><block ref="3836a8be1f86b6658a7fa6b180e4a72d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cee52cb6702e7590fbef45eccc8fb2df" category="list-text">ドロップダウンリストから、セクション 7 で作成したフルバックアップポリシーを選択します。</block>
  <block id="af900bffdda986bc1db955ae78832742" category="paragraph"><block ref="af900bffdda986bc1db955ae78832742" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fe872cd84ea2e9051770379e63f9caf" category="list-text">（ + ）記号をクリックして、目的のバックアップスケジュールを設定します。</block>
  <block id="9da504fd8ab60cfcc873608530cf5d56" category="paragraph"><block ref="9da504fd8ab60cfcc873608530cf5d56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdc27a4c5d48dbfc04f81ecac85acd64" category="list-text">Load Locators （ロケータのロード）をクリックして、ソースボリュームとデスティネーションボリュームをロードします。</block>
  <block id="7242164857e43688f8a7bec97559c36e" category="paragraph"><block ref="7242164857e43688f8a7bec97559c36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b612dc8868902cf8fbf2b1024ad94e65" category="paragraph"><block ref="b612dc8868902cf8fbf2b1024ad94e65" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95633243861715786b64e1554b629435" category="paragraph"><block ref="95633243861715786b64e1554b629435" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f7192b9766e6f09c261f3ca3d3bddc8" category="section-title">Oracle のログバックアップ用のリソースグループを作成します</block>
  <block id="1a0cd5de7c84ddbf632838dd9f510d37" category="paragraph"><block ref="1a0cd5de7c84ddbf632838dd9f510d37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0ad3d9537c50952c04b71be3f9d4579" category="paragraph"><block ref="f0ad3d9537c50952c04b71be3f9d4579" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c33c31714f671e112fbe52b660d3e7a4" category="paragraph"><block ref="c33c31714f671e112fbe52b660d3e7a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03955b73285eab0d68e90c627da9726d" category="list-text">ドロップダウンリストから、セクション 7 で作成したログバックアップポリシーを選択します。</block>
  <block id="6286629570d2ca91cf6860e7da6e9073" category="paragraph"><block ref="6286629570d2ca91cf6860e7da6e9073" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88c73129e9a418955658ce5c48d9d8b5" category="list-text">（ + ）記号をクリックして、目的のバックアップスケジュールを設定します。</block>
  <block id="8cdd30063d988671ffa9240fe171b1ce" category="paragraph"><block ref="8cdd30063d988671ffa9240fe171b1ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eacfd6f10777b8dfb41199e4d4dfa915" category="list-text">バックアップ検証が設定されている場合は、ここに表示されます。</block>
  <block id="69911c1794125b768effca94c8153987" category="paragraph"><block ref="69911c1794125b768effca94c8153987" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a27fac4b1d49d5468930a56c3a6de56" category="list-text">必要に応じて、 E メール通知用の SMTP サーバを設定します。</block>
  <block id="fd540644538dcedf1f6543455447728f" category="paragraph"><block ref="fd540644538dcedf1f6543455447728f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="554dbe35f6afa38e8232497f5d05d1c1" category="paragraph"><block ref="554dbe35f6afa38e8232497f5d05d1c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf688c7a95f421447e84a47fd03f3aa2" category="section-title">SQL Server のフルバックアップ用のリソースグループを作成する</block>
  <block id="d08ef097ee33c4a3506183adeb51c5e7" category="list-text">データベース管理ユーザ ID で SnapCenter にログインし、 Resources タブに移動します。[ 表示 ] ドロップダウンリストで、 [ データベース ] または [ リソースグループ ] を選択して、リソースグループ作成ワークフローを起動します。リソースグループの名前とタグを指定します。Snapshot コピーの命名形式を定義できます。</block>
  <block id="87d2630813d214672697efc01974d64e" category="paragraph"><block ref="87d2630813d214672697efc01974d64e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ace5324d60cb3faa1863efd675149" category="list-text">バックアップするデータベースリソースを選択します。</block>
  <block id="15330fe5b8f32032bd3b30c091d7dc4b" category="paragraph"><block ref="15330fe5b8f32032bd3b30c091d7dc4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2fc1974f486effa4a60bf216e63a88d5" category="list-text">セクション 7 で作成したフル SQL バックアップポリシーを選択します。</block>
  <block id="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="paragraph"><block ref="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b70beeb570488ba753a620378cacd8" category="list-text">バックアップの正確なタイミングおよび頻度を追加します。</block>
  <block id="8fa0a3897bc03e9b1653d17308464031" category="paragraph"><block ref="8fa0a3897bc03e9b1653d17308464031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49252579bd8140847f4bbac20ef89b07" category="list-text">バックアップ検証を実行する場合は、セカンダリ上のバックアップ用の検証サーバを選択します。Load Locator （ロケータのロード）をクリックしてセカンダリストレージの場所を入力します。</block>
  <block id="355e5eb56524b7365674014ea5868ee6" category="paragraph"><block ref="355e5eb56524b7365674014ea5868ee6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19e819eadb96ee5769ff4c6309352a62" category="paragraph"><block ref="19e819eadb96ee5769ff4c6309352a62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0be278d93ec2e64895e31bf440c54b98" category="paragraph"><block ref="0be278d93ec2e64895e31bf440c54b98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4dd921984d3a8a89e7df5c97875b923" category="section-title">SQL Server のログバックアップ用のリソースグループを作成します</block>
  <block id="4e94ca9b995e68691b4e67b82b9f5bce" category="list-text">データベース管理ユーザ ID で SnapCenter にログインし、 Resources タブに移動します。[ 表示 ] ドロップダウンリストで、 [ データベース ] または [ リソースグループ ] を選択して、リソースグループ作成ワークフローを起動します。リソースグループの名前とタグを指定します。Snapshot コピーの命名形式を定義できます。</block>
  <block id="4e71263f0aec815017fd21a22ddb87d6" category="paragraph"><block ref="4e71263f0aec815017fd21a22ddb87d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="013faf9f6cde83814469c6d583e10702" category="paragraph"><block ref="013faf9f6cde83814469c6d583e10702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23e15d7c127e66b1da1d72072a29e9eb" category="list-text">セクション 7 で作成した SQL ログバックアップポリシーを選択します。</block>
  <block id="52a8553e4c33eb8353d56286d3845b28" category="paragraph"><block ref="52a8553e4c33eb8353d56286d3845b28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e7cac98c16b45d7e4ebec8786b8fda1" category="list-text">バックアップの正確なタイミングと頻度を追加します。</block>
  <block id="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="paragraph"><block ref="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68398b6746dde91649e96505d97acc40" category="list-text">バックアップ検証を実行する場合は、セカンダリ上のバックアップ用の検証サーバを選択します。Load Locator をクリックしてセカンダリストレージの場所を入力します。</block>
  <block id="3bde998a2436b40589b20d91a713d3ee" category="paragraph"><block ref="3bde998a2436b40589b20d91a713d3ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80000e8cb7742af4686df786fdf38249" category="paragraph"><block ref="80000e8cb7742af4686df786fdf38249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d32fb038efa6b409f8dedd0e02a10f26" category="paragraph"><block ref="d32fb038efa6b409f8dedd0e02a10f26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c72629a46c2e88cf7f6a012167bb16" category="section-title">9. バックアップを検証する</block>
  <block id="d1c55c296cbdaa8d88eda765a6158b62" category="paragraph">データベースリソースを保護するためにデータベースバックアップリソースグループを作成すると、定義済みのスケジュールに従ってバックアップジョブが実行されます。[ モニタ ] タブでジョブの実行ステータスを確認します。</block>
  <block id="5f9af2a4e435e2b39c27f43b580d6d20" category="paragraph"><block ref="5f9af2a4e435e2b39c27f43b580d6d20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57882e224a8cbe8f694da9b1d8fa503e" category="paragraph">リソースタブでデータベース名をクリックしてデータベースバックアップの詳細を表示し、ローカルコピーとミラーコピーを切り替えて、 Snapshot バックアップがパブリッククラウドのセカンダリサイトにレプリケートされていることを確認します。</block>
  <block id="f9b40afbdb387dd32b8523c95080a898" category="paragraph"><block ref="f9b40afbdb387dd32b8523c95080a898" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28268d417882b5cf7a3d3ee3a15834c8" category="paragraph">この時点で、クラウド内のデータベースバックアップコピーをクローニングして、開発 / テストプロセスを実行したり、プライマリに障害が発生した場合にディザスタリカバリを実行したりできます。</block>
  <block id="78b29bbf3f07a44b62307ce90b34904e" category="inline-link-macro">次は、 AWS パブリッククラウドの導入を開始するにあたり、</block>
  <block id="7d32c0298884bcc4c0211357748d0e6e" category="paragraph"><block ref="7d32c0298884bcc4c0211357748d0e6e" category="inline-link-macro-rx"></block></block>
  <block id="0f22160e43c900ef7426d8a19e9f482d" category="summary">ハイブリッドクラウドデータベースワークロードを実行する前に、オンプレミスとクラウドの両方で特定の前提条件を設定する必要があります。ここでは、このプロセスの概要を示し、必要なシステム構成の詳細については次のリンクを参照してください。</block>
  <block id="1dad826770c4d2c619351c974f725b36" category="doc">前提条件の設定</block>
  <block id="ce38f65c711e7e3047c9350abe42c0c3" category="inline-link-macro">以前のバージョン：ソリューションの要件。</block>
  <block id="d3fe0eebddd46d46399cb319c7219427" category="paragraph"><block ref="d3fe0eebddd46d46399cb319c7219427" category="inline-link-macro-rx"></block></block>
  <block id="4df40e141b0559f15db8f84f78aed013" category="section-title">オンプレミス</block>
  <block id="caea8340e2d186a540518d08602aa065" category="list-text">自動化</block>
  <block id="761883c0d5c55fba5b200ac8ac0d86e5" category="section-title">パブリッククラウド</block>
  <block id="37aa83a33297d9d16b4423be342598bb" category="list-text">コネクタのネットワーク上の場所</block>
  <block id="74c043a4451dd260729a23ce96aa1550" category="paragraph">重要な考慮事項：</block>
  <block id="7aee27c83b5e3622c1d8cbd5c2098c60" category="list-text">Cloud Manager Connector の導入場所</block>
  <block id="43fd5c6fa3d9ba8a215c31f3bf0a9859" category="list-text">Cloud Volumes ONTAP のサイジングとアーキテクチャ</block>
  <block id="7a0e00d70e3b0ff06476a52565f923c4" category="list-text">シングルノードとハイアベイラビリティのどちらか？</block>
  <block id="2d0b46fff3ae203a435b167c7111b389" category="paragraph">詳細については、次のリンクを参照してください。</block>
  <block id="cfd98f49422c4fba755a2ff74c55a4a0" category="paragraph"><block ref="cfd98f49422c4fba755a2ff74c55a4a0" category="inline-link-macro-rx"></block></block>
  <block id="704849d56e695ab8f9df0b106e0d7e33" category="inline-link-macro">パブリッククラウド</block>
  <block id="96e41b2b281ca4b71edf4ed16e46a2be" category="paragraph"><block ref="96e41b2b281ca4b71edf4ed16e46a2be" category="inline-link-macro-rx"></block></block>
  <block id="7c12725837ee75c4c0a9bbc14f99934d" category="inline-link-macro">次のステップ：オンプレミスでの前提条件</block>
  <block id="bc57dd30a9059d494c9d76e4b0a9ce8f" category="paragraph"><block ref="bc57dd30a9059d494c9d76e4b0a9ce8f" category="inline-link-macro-rx"></block></block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">Lenovo ThinkSystem-解決策 Design を使用したエッジネットアップでの AI 推論</block>
  <block id="30b22b544972f5adb280ca2975099846" category="sidebar">SnapCenter を使用したハイブリッドクラウドデータベースソリューション</block>
  <block id="59f8ae0d5c4ba13dee4828e2727c8859" category="sidebar">オンプレミスでの作業の開始</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">次の図は、 NetApp EF280 ストレージシステムを示しています。</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1 は、ネットアップの最新世代のストレージ管理ソフトウェアです。インフラを最新化し、クラウド対応データセンターに移行することができます。ONTAP は、業界をリードするデータ管理機能を活用して、データの格納場所に関係なく、単一のツールセットでデータの管理と保護を実現します。エッジ、コア、クラウドなど、必要な場所に自由にデータを移動することもできます。ONTAP 9.8.1 には、データ管理を簡易化し、重要なデータの高速化と保護を実現し、ハイブリッドクラウドアーキテクチャ全体で次世代インフラ機能を実現する、多数の機能が搭載されています。</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">登録が必要なデータセット、 ImageNet 2012 Validation set 、 Crito Terabyte データセット、および BRT 2019 Training セットをダウンロードし、ファイルを解凍します。</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">1TB 以上の作業ディレクトリを作成し、ディレクトリを参照する環境変数「 M LPERF_scratch_path 」を定義します。</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">make 「 prebuild 」コマンドを実行します。このコマンドは、必要な推論タスク用の Docker コンテナを構築して起動します。</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">MLPerf Inference タスク用のトレーニング済み AI モデル「 make download_model 」をダウンロードしてください</block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">無料でダウンロードできる追加のデータセット「 make download_data 」をダウンロードしてください</block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">データをプリプロセスします。「 preprocess_data 」にします</block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">「 make build 」を実行します。</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">コンピューティングサーバの GPU に最適化された推論エンジン「 generate_engines 」を構築します</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">このベンチマークではレイテンシを測定します。いずれの場合も、実行に関連するすべてのサーバの平均レイテンシを報告します。一連のタスクの結果が表示されます。</block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">結果から、このタスクを処理するのに十分なネットワークストレージがあることが再びわかります。1 つのサーバケースにおけるローカルストレージとネットワークストレージの違いは、最小またはなしです。同様に、 2 台のサーバが同じストレージを使用している場合、両方のサーバの遅延は同じままであるか、非常に小さい値で変化します。</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">この Lenovo ThinkSystem サーバと NetApp ONTAP または NetApp SANtricity ストレージ解決策は、従来の CPU に加えて GPU の処理能力を使用して大規模なデータセットで AI 推論を処理するように設計されています。この検証では、次の 2 つの図に示すように、単一または複数の Lenovo SR350 エッジサーバを 1 つの NetApp AFF ストレージシステムと相互接続したアーキテクチャを使用して、パフォーマンスと最適なデータ管理を実現します。</block>
  <block id="aacb24ff7918ccc37aea66f8c9548b68" category="paragraph"><block ref="aacb24ff7918ccc37aea66f8c9548b68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">次の図の論理アーキテクチャの概要は、このアーキテクチャのコンピューティング要素とストレージ要素の役割を示しています。具体的には、次の情報が表示されます。</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">このドキュメントは MLPerf 推論 v0.7 に準拠しています<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block>、 MLPerf Inference v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block>および<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block>。次の表に示すように、エッジでの推論向けに設計された MLPerf ベンチマークを実行しました。</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">次の表に、 Edge ベンチマークのシナリオを示します。</block>
  <block id="5174c42549c4dd0407a40298a4d9e362" category="paragraph"><block ref="5174c42549c4dd0407a40298a4d9e362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8a1e11a906a27bd156606bf4717e8e8" category="summary">このサポートセンターの解決策のアーキテクチャは、 NVIDIA が構築したツールと NetApp DataOps ツールキットを中心にしています。NVIDIA のツールを使用すると、構築済みのモデルとパイプラインを使用して、ハイパフォーマンスな AI ソリューションを迅速に導入できます。NetApp DataOps ツールキットにより、さまざまなデータ管理タスクが簡易化され、開発期間が短縮されます。</block>
  <block id="d51083e81cbf0ec7828af24692206315" category="inline-link-macro">以前のバージョン：ユースケース</block>
  <block id="beff34f173af198016bee889c9f9ed7a" category="paragraph"><block ref="beff34f173af198016bee889c9f9ed7a" category="inline-link-macro-rx"></block></block>
  <block id="c779b37f861deb44744634dea201514f" category="inline-link-macro">NVIDIA RIVA</block>
  <block id="ccfdc9ae99a97b7a6b8ad83a329bcdc8" category="paragraph"><block ref="eb3a0fd60dc608626ce6d809beb18359" category="inline-link-macro-rx"></block> GPU でリアルタイムのパフォーマンスを実現する、マルチモーダルな会話型 AI アプリケーションを構築するための GPU アクセラレーション対応 SDK です。NVIDIA Train 、 Adapt 、 Optimize （ TAO ）ツールキットは、トレーニングを高速化し、高精度で高性能なドメイン固有の AI モデルをすばやく簡単に作成する方法を提供します。</block>
  <block id="600ff5755ecd6aa4213eb806162b679e" category="paragraph">NetApp DataOps ツールキットは Python ライブラリで、開発者、データサイエンティスト、 DevOps エンジニア、データエンジニアはさまざまなデータ管理タスクを簡単に実行できます。これには、新しいデータボリュームまたは JupyterLab ワークスペースのほぼ瞬時のプロビジョニング、データボリュームまたは JupyterLab ワークスペースのほぼ瞬時のクローニング、データボリュームまたは JupyterLab ワークスペースのほぼ瞬時の Snapshot コピーによるトレーサビリティとベースライン設定が含まれます。</block>
  <block id="1c8bd88c9d2cb845c6c27915f4a3fe8e" category="paragraph">次の図は、解決策のアーキテクチャを示しています。環境には、クラウド、コア、エッジの 3 つのカテゴリがあります。各カテゴリは地理的に分散させることができます。たとえば、クラウドにはバケット内の音声ファイルを含むオブジェクトストアがあり、コアには高速ネットワークまたは NetApp Cloud Sync 経由でリンクされたデータセンターが含まれる場合があります。エッジノードは、ヒューマンエージェントの日常的な作業プラットフォームを表しています。このプラットフォームでは、対話型ダッシュボードツールとマイクを使用して感情を視覚化したり、顧客との会話から音声データを収集したりできます。</block>
  <block id="5d103a663d28ddc9aa2af5f7b958e52c" category="inline-link">リバ</block>
  <block id="cc7a5a83afae781789c3a002465500b5" category="inline-link">Tao ツールキット</block>
  <block id="9595827147dc1170c44979ae1fcabaa6" category="paragraph">GPU によって高速化されたデータセンターでは、 NVIDIA を使用できます<block ref="cfd3aefe24e0725c1b0424dd8b503dc1" category="inline-link-rx"></block> 会話型 AI アプリケーションを構築するためのフレームワーク。それには、があります<block ref="ccdd6931e40e98163a0ae3c3c3bfb185" category="inline-link-rx"></block> Transfer L ラーニング技術を使用して、モデルのフィニッチニングと再トレーニングを接続します。これらのコンピューティングアプリケーションとワークフローは、を基盤としています<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>ONTAP が提供する最高のデータ管理機能を実現します。このツールキットを使用すると、企業のデータチームは、スナップショットやクローンを使用して、構造化データと非構造化データでモデルのプロトタイプを迅速に作成できるため、トレーサビリティ、バージョン管理、 A/B テストを実現し、セキュリティ、ガバナンス、 コンプライアンスを実現できます。を参照してください <block ref="3f1432f6921bc0c51d34759cb0d748ab" category="inline-link-macro-rx"></block> 詳細：</block>
  <block id="816c3453eeba98af344f96d7eefe8834" category="paragraph">この解決策では、オーディオファイル処理、 NLP モデルトレーニング、トランスファーラーニング、およびデータ管理の詳細な手順について説明します。最終的なパイプラインが生成され、ヒューマンサポートエージェントのダッシュボードにリアルタイムで表示されるセンチメントの概要が生成されます。</block>
  <block id="b6fb1598d37d2537eed4160a485b790e" category="paragraph"><block ref="b6fb1598d37d2537eed4160a485b790e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62519b55e4debcf57caf02c89620de61" category="cell">応答遅延テスト</block>
  <block id="b763dc0a5ffab97a986c74098214cae6" category="cell">時間（ミリ秒）</block>
  <block id="08fa9c0a2e18301dd14e18c393fb4280" category="cell">データ処理</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10.</block>
  <block id="08db96f19d3c99c2b42fd180d9d81580" category="cell">推論</block>
  <block id="212e6da10eee5f14935bd37b84fe9684" category="paragraph">この応答時間テストは、 560 の会話で 50,000 以上のオーディオファイルで実行されました。各オーディオファイルのサイズは、 MP3 の場合は約 100 KB 、 WAV の場合は約 1 MB でした。データ処理手順では、 MP3 を WAV ファイルに変換します。推論の手順では、オーディオファイルをテキストに変換し、テキストから感情を抽出します。これらのステップは互いに独立しており、並列化することでプロセスを高速化できます。</block>
  <block id="c18e24981c583441c6975f2116288cb7" category="paragraph">ストア間でのデータ転送の遅延を考慮すると、マネージャは、文章の最後の 2 番目の時間内にリアルタイムの感情分析の更新を確認できるようになります。</block>
  <block id="1c4968697a5851a64ad0fbf1b594e919" category="section-title">NVIDIA Riva ハードウェア</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">OS</block>
  <block id="4c8be35e5fe3d8471f378a69f74c0ab6" category="cell">Linux x86_64</block>
  <block id="4d240f00b5a82cfaaf594cdc72f552f3" category="cell">GPU メモリ（ ASR ）</block>
  <block id="3fa503e0bb3bf46423ef9176821a1f6c" category="cell">ストリーミングモデル：最大 5600 MB の非ストリーミングモデル：約 3100 MB</block>
  <block id="6345afe417f42d9e0cf6a269bff00b4c" category="cell">GPU メモリ（ NLP ）</block>
  <block id="217941fb2e441b0bae1b5fec0b454c31" category="cell">1 つの BERT モデルで最大 500MB</block>
  <block id="7e04ebd38c78635d1f8aa53de0dde49b" category="section-title">NVIDIA TAO ツールキットハードウェア</block>
  <block id="03282e46abfd7449ab38bb851caf2c8d" category="cell">システム RAM</block>
  <block id="edaf98e5dae9931cbd74a93b3dd93849" category="cell">32 GB</block>
  <block id="6ddfc451ef4f9a7613468cd288d2ab3e" category="cell">GPU RAM</block>
  <block id="2b55387dd066c5bac646ac61543d152d" category="cell">CPU</block>
  <block id="04911a799cc8712b473ed5a3cb2b8904" category="cell">8 コア</block>
  <block id="fceec3562665d08f1dd24689f68f0f29" category="cell">NVIDIA （ A100 、 V100 、 RTX 30x0 ）</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD の場合</block>
  <block id="2f9289dfcac06a2ba95650d7e24ea9e8" category="cell">100GB</block>
  <block id="19aa61315132dbea1d19c7aeeef5f5b2" category="section-title">フラッシュストレージシステム</block>
  <block id="fd5487a1e906d6cd514dbbc16f17a489" category="paragraph">ネットアップの最新世代のストレージ管理ソフトウェア ONTAP 9.9 は、インフラの刷新とクラウド対応データセンターへの移行を可能にします。ONTAP は、業界をリードするデータ管理機能を活用して、データの格納場所に関係なく、単一のツールセットでデータの管理と保護を実現します。エッジ、コア、クラウドなど、必要な場所に自由にデータを移動することもできます。ONTAP 9.9 には、データ管理を簡素化し、重要なデータを高速化および保護し、ハイブリッドクラウドアーキテクチャ全体で次世代のインフラ機能を実現する、多数の機能が含まれています。</block>
  <block id="78a2efe59d4ad6ad51556ea77f5fdec3" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> は、高速でセキュアなデータ同期を実現するネットアップのサービスです。オンプレミスの NFS または SMB ファイル共有間で、次のいずれかのターゲットにファイルを転送できます。</block>
  <block id="df2c24964ca3e99761acc48b2c8a75c9" category="list-text">NetApp ONTAP S3</block>
  <block id="1a4c7c9b6e3157ccd0101fd0836c0bfc" category="list-text">NetApp Cloud Volumes Service の略</block>
  <block id="ddcf3699b41cd4c4ee5be4b9dd95c1e6" category="list-text">Amazon Simple Storage Service （ Amazon S3 ）</block>
  <block id="8224436b00c48149c863f4b17219a19d" category="list-text">Amazon Elastic File System （ Amazon EFS ）</block>
  <block id="52745271323ee9ea30e3a37d0338d118" category="list-text">Azure Blob の略</block>
  <block id="833c2c211a541e50ad94433664e4b5c1" category="list-text">Google クラウドストレージ</block>
  <block id="5446a6bee3301e1f52824fc0affa6299" category="list-text">IBM クラウドオブジェクトストレージ</block>
  <block id="1b238365e840da0711b49e8f646e2fdf" category="paragraph">Cloud Sync は、必要な場所に迅速かつ安全にファイルを移動します。転送されたデータは、ソースとターゲットの両方で完全に使用できます。Cloud Sync は、事前定義されたスケジュールに基づいてデータを継続的に同期し、差分のみを移動するため、データレプリケーションにかかる時間とコストを最小限に抑えることができます。Cloud Sync は、セットアップや使用が簡単なソフトウェアサービス（ SaaS ）ツールです。Cloud Sync によって実行されるデータ転送は、データブローカーによって実行されます。Cloud Sync データブローカーは、 AWS 、 Azure 、 Google Cloud Platform 、オンプレミスに導入できます。</block>
  <block id="a5c952f5be43013a024d778712474fbc" category="paragraph">StorageGRID の Software-Defined オブジェクトストレージスイートは、パブリッククラウド、プライベートクラウド、ハイブリッドマルチクラウド環境のすべてをシームレスにサポートし、幅広いユースケースに対応しています。業界をリードするイノベーションにより、 NetApp StorageGRID は、非構造化データを長期にわたって自動化されたライフサイクル管理などの多目的に保管、保護、保管します。詳細については、を参照してください<block ref="7660f0463c83c682b9f091117b07c3b3" category="inline-link-rx"></block> サイト</block>
  <block id="6ffce2da93d4b296032f30d7b2adea01" category="paragraph">次の表に、この解決策を実装するために必要なソフトウェアコンポーネントを示します。解決策の特定の実装で使用されるソフトウェアコンポーネントは、お客様の要件に応じて異なる場合があります。</block>
  <block id="d20072ce64f4d9efd57e036d2b7c30ec" category="cell">ホストマシン</block>
  <block id="7915eebeca25d928212b5d457786a549" category="cell">Riva ( 以前の開発コード名 Jarv)</block>
  <block id="1bf6e69c18341244d990250bf5aa3ce0" category="cell">1.4.0</block>
  <block id="7a2cd4790985cbbb0b362dfe8e59d991" category="cell">Tao ツールキット ( 以前の Transfer Learning Toolkit)</block>
  <block id="55c82b601deae028c1c5e87fd820923d" category="cell">3.0</block>
  <block id="67c6ecbcd91c613e8659b3f0c4b01510" category="cell">9.9.1</block>
  <block id="8bec4fb7fbc1430e393d3f41063748e7" category="cell">DGX OS</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="1b13fe3d4acac980a061d9efb92000d5" category="cell">DTK</block>
  <block id="d233662f9c26d1a06118c93ef2fd1de9" category="cell">2.0.0</block>
  <block id="76e535c7d7533499b0d86f60a0d15b84" category="section-title">NVIDIA Riva ソフトウェア</block>
  <block id="5d7bf724a19463b3251c61a94a446c4c" category="cell">&gt;19.02 （ NVIDIA - Docker をインストール済み） &gt;=19.03 （ DGX を使用していない場合</block>
  <block id="3ff6010d41ffb33d6f0971a202e76ad7" category="cell">NVIDIA ドライバ</block>
  <block id="616120c1963dd46f2321dd37e823f8a0" category="cell">465.19.01 + 418.40 + 、 440.33 + 、 450.51 + 、 460.27 + （データセンターの GPU の場合</block>
  <block id="88f8128d405513d54a3e9831c73f87a0" category="cell">コンテナ OS</block>
  <block id="73611f9a837b7a25dad3a9c5d1a98658" category="cell">Ubuntu 20.04</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="cell">CUDA （ CUDA</block>
  <block id="a26b47ba45087eadbeaa7c4802b3a8c8" category="cell">11.3.0</block>
  <block id="d92ef06e9564a9db573d075b4220057e" category="cell">cuBLAS</block>
  <block id="a8a364c27ce7406b7be591b4f973d5bb" category="cell">11.5.1.101</block>
  <block id="9bfd6cd63a5597c998aa2d96564f5c34" category="cell">cuDNN</block>
  <block id="15daa8f1432fd7e2b07f63097623dfab" category="cell">8.2.0.41</block>
  <block id="1ed15cc4178fd8ec4d845042a8f1ead0" category="cell">NCCL</block>
  <block id="f10585a0c5c8f535143471006baef867" category="cell">2.9.6</block>
  <block id="61918500e2bc645b2aea3f447086a8a5" category="cell">TensorRT</block>
  <block id="086934e5e95d3c797fc75f38fb3d086c" category="cell">7.2.3.4.</block>
  <block id="d024876954df77538311467564f00917" category="cell">Triton Inference サーバ</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="2efc85a476098fde0ecbf8d81505b612" category="section-title">NVIDIA TAO ツールキットソフトウェア</block>
  <block id="cb6c22f673a55391483c7f040d8cf637" category="cell">Ubuntu 18.04 LTS</block>
  <block id="23eeeb4347bdd26bfc6b7ee9a3b755dd" category="cell">Python</block>
  <block id="c80362c25c18981fcf433e78dda5de78" category="cell">3.6.9 以上</block>
  <block id="aec7ff22e2f74b581cffbfa59e63f347" category="cell">Docker - CE</block>
  <block id="21ca3af3ea5e6a282911a64dbf5ced7a" category="cell">19.03.5</block>
  <block id="0cf76d9b00333f4396d0424ae164dd07" category="cell">Docker - API</block>
  <block id="ca2b7e7213f7ba5d4b3923e807af27df" category="cell">1.40</block>
  <block id="ad2f80b0463af47fcb7430e0e1789841" category="cell">nvidia -container-toolkit</block>
  <block id="12b58130c1d9383cf3bf63391bd04721" category="cell">&gt;1.3.0-1</block>
  <block id="cec57b9746d41fd1c1749d591dbd7baf" category="cell">nvidia Container - ランタイム</block>
  <block id="68b90d96e3d934d65890ff695d37f354" category="cell">3.4.0 -1</block>
  <block id="f235b98dbe494fca328354abf0b52858" category="cell">nvidia - docker2</block>
  <block id="10439f6f665bce43173e2871a0b7bfc6" category="cell">2.5.0-1</block>
  <block id="fd3811d814e856dc6a43152673bb6753" category="cell">nVidia ドライバ</block>
  <block id="06c61cdd8c93e750b3e0d4e2537416ea" category="cell">&gt; 455</block>
  <block id="b6da1806d8ccb5327c3d80bbcfea4737" category="cell">python-pip</block>
  <block id="7b043cb99d00fe56df3fead569b1a4de" category="cell">&gt;21.06</block>
  <block id="3bdf92e45d10e51e2bdc2b16cf33f345" category="cell">nvidia -pyindex</block>
  <block id="9ca445b9db010a99239196af5ac3a8b9" category="cell">最新バージョン</block>
  <block id="cf87f69879c53ebf670ee8bd793ad7ba" category="section-title">ユースケースの詳細</block>
  <block id="7cb906d40b2e5bad2205a60ef8b6a019" category="list-text">感情分析</block>
  <block id="52a38da70697d6c80e3b6a204f64263f" category="paragraph"><block ref="52a38da70697d6c80e3b6a204f64263f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8ff4a485cc084b2a4b5bb829cf18055" category="paragraph">音声テキスト変換のユースケースは、まずサポートセンターの音声ファイルを取り込むことから始まります。このオーディオは、 Riva が必要とする構造に合わせて処理されます。オーディオファイルが解析単位に分割されていない場合は、オーディオを Riva に渡す前にこれを行う必要があります。オーディオファイルが処理されると、 API 呼び出しとして Riva サーバーに渡されます。サーバは、ホスティングしている多くのモデルの 1 つを採用し、応答を返します。この音声 / テキスト（自動音声認識の一部）は、音声のテキスト表現を返します。そこから、パイプラインはセンチメント分析部分に切り替わります。</block>
  <block id="230007c23660d290efdea5586b1716aa" category="paragraph">感情分析では、自動音声認識からのテキスト出力がテキスト分類への入力として機能します。Text Classification は、任意の数のカテゴリにテキストを分類するための NVIDIA コンポーネントです。サポートセンターとの会話では、感情のカテゴリがプラスからマイナスになります。モデルのパフォーマンスは、ホールドアウトセットを使用して、微調整ステップの成功を判断することができます。</block>
  <block id="3390cebd79348bc76a1e5eb5f169bedf" category="paragraph"><block ref="3390cebd79348bc76a1e5eb5f169bedf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="952b3f5758e644ef2558d59d3aace0b1" category="inline-link">NVIDIA NGC カタログ</block>
  <block id="4fa0a0d712258621946173068bf4f7e0" category="paragraph">TAO ツールキット内の音声テキスト分析と感情分析にも、同様のパイプラインが使用されています。主な違いは、モデルの微調整に必要なラベルの使用です。TAO ツールキットパイプラインは、データファイルの処理から始まります。次に、事前にトレーニングされたモデル（から入手可能<block ref="aaddb3bb47bcb0ca6e2a55cdce808e9b" category="inline-link-rx"></block>）は、サポートセンターのデータを使用して微調整されます。微調整されたモデルは、対応するパフォーマンス指標に基づいて評価され、事前トレーニングされたモデルよりもパフォーマンスが高い場合は、 Riva サーバに導入されます。</block>
  <block id="587796d49571c1c4d5c89993d7ed01dd" category="inline-link-macro">次：設計上の考慮事項</block>
  <block id="1165e49145cd3a7ebc2b75e325d8797a" category="paragraph"><block ref="1165e49145cd3a7ebc2b75e325d8797a" category="inline-link-macro-rx"></block></block>
  <block id="431db7b0dc79bb29f07c20c6060c3338" category="summary">このセクションでは、この解決策に役立つ Jupyter ノートブックとその他のリソースを示します。</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="doc">ビデオとデモ</block>
  <block id="eeb22c31d24f52a9b8225da48c32dd15" category="inline-link-macro">Previous ：検証結果</block>
  <block id="234bbb7420397102b6a782bcaafff71a" category="paragraph"><block ref="234bbb7420397102b6a782bcaafff71a" category="inline-link-macro-rx"></block></block>
  <block id="4b8db041d93aa27fd0cc94a261e224ca" category="inline-link-macro">「サポート - センタ - センチメント - 分析 - パイプライン .ipynb 」</block>
  <block id="4e336784d7218f9fd7024470cba6b522" category="inline-link">「サポート - センター - モデル - 転送 - 学習と微調整 .ipynb 」</block>
  <block id="46e3dcdd2c6c30a1d9fcf40d37f0deb3" category="paragraph">センチメント分析パイプラインを含むノートブックが 2 つあります。<block ref="8ed620ac9482ce00db4c0f6de7250148" category="inline-link-rx"></block> および <block ref="ff8619e3bd3fbeea07c38337a7b773f7" category="inline-link-macro-rx"></block>。これらのノートブックは、ユーザーのデータに微調整された最先端のディープラーニングモデルを使用して、サポートセンターのデータを取り込み、各文から感情を抽出するパイプラインを開発する方法を示しています。</block>
  <block id="fa8c0b2056c13341c1455ad44cc91889" category="section-title">サポートセンター - 感情分析パイプライン .ipynb</block>
  <block id="6b3450c2b921c398bbf90a1aee0b016c" category="paragraph">このノートブックには、オーディオの取り込み、テキストへの変換、外部ダッシュボードで使用するための感情の抽出を行う推論 Riva パイプラインが含まれています。データセットは、まだダウンロードされていない場合は自動的にダウンロードされて処理されます。ノートブックの最初のセクションは、音声ファイルからテキストへの変換を処理する Speech to Text です。続いて、各テキスト文の感情を抽出し、それらの結果を提案されたダッシュボードと同様の形式で表示する感情分析セクションが表示されます。</block>
  <block id="63abda3d2c420172da9a3a20c7f64dda" category="admonition">MP3 データセットをダウンロードして正しい形式に変換する必要があるため、このノートブックはモデルのトレーニングや微調整の前に実行する必要があります。</block>
  <block id="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="paragraph"><block ref="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="295c2feb943bbe2efca238849828084e" category="section-title">サポートセンター - モデルトレーニングと微調整 .ipynb</block>
  <block id="6efbeb8cfc7e387edbf91bad41170349" category="paragraph">ノートブックを実行する前に、 TAO Toolkit 仮想環境を設定する必要があります ( インストール手順については、『 Commands Overview 』の TAO Toolkit の項を参照してください ) 。</block>
  <block id="a9d805c9ddfdf62e60632a9754e29404" category="paragraph">このノートブックは、 TAIO ツールキットを使用して、お客様のデータに基づいてディープラーニングモデルを微調整します。前のノートブックと同様に、この 2 つのセクションに分かれて、 Speech to Text コンポーネントと、センチメント分析コンポーネントが表示されます。各セクションでは、データ処理、モデルトレーニング、微調整、結果の評価、およびモデルのエクスポートについて説明します。最後に、 Riva で使用するために、両方の微調整済みモデルを導入するための最終セクションがあります。</block>
  <block id="b40454c57dd60f999f3243514cd90ede" category="paragraph"><block ref="b40454c57dd60f999f3243514cd90ede" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f89bf51287609a0c0cf7563b31265c06" category="paragraph"><block ref="f89bf51287609a0c0cf7563b31265c06" category="inline-link-macro-rx"></block></block>
  <block id="00a9f41b5383bf6bcb5b7f6540d427b4" category="summary">NVIDIA 、 AWS 、 Google などが公開している最新のトレーニング済みモデリングツールを使用することで、複雑なモデルを含むエンドツーエンドのパイプラインを容易に構築してカスタマイズできるようになりました。</block>
  <block id="14e5cae1e8e56eca8add5bdcedfe2335" category="inline-link-macro">前のバージョン：データセンター分析をサポート</block>
  <block id="d39a6e05d58eb4f71cae7257dc52a1d0" category="paragraph"><block ref="d39a6e05d58eb4f71cae7257dc52a1d0" category="inline-link-macro-rx"></block></block>
  <block id="710217ef02bea8d1d76bc6fc0e7bc056" category="paragraph">これらのサポートセンターで処理されるコールの数が原因で、手動で実行した場合はコールパフォーマンスの評価にかなりの時間がかかる可能性があります。BAG of Words カウンティングなどの従来のメソッドは、いくつかの自動化を実現できますが、これらのメソッドは、ダイナミック言語の微妙な側面や意味をキャプチャしません。AI モデリング手法を使用すると、このように詳細な分析を自動化された方法で実行できます。さらに、 NVIDIA 、 AWS 、 Google などが公開している最新のトレーニング済みモデリングツールを使用することで、複雑なモデルを含むエンドツーエンドのパイプラインを容易に構築し、カスタマイズできるようになりました。</block>
  <block id="dd4541bcdb4728a1a380e825494f08e2" category="paragraph">サポートセンターの感情分析のためのエンドツーエンドのパイプラインは、従業員が発信者と会話するときに、音声ファイルをリアルタイムで取り込みます。次に、これらのオーディオファイルは音声テキストコンポーネントで使用するために処理され、テキスト形式に変換されます。会話中の各文は、感情（肯定的、否定的、または中立的）を示すラベルを受け取ります。</block>
  <block id="cfc9b6a29659e2208f66d876bd355200" category="paragraph">感情分析は、コールパフォーマンスを評価するための会話の重要な側面を提供することができます。これらの感情は、従業員と発信者間のやり取りにさらに深いレベルを追加します。AI を活用した感情ダッシュボードは、マネージャーが会話内の感情をリアルタイムに追跡し、従業員の過去の問い合わせを過去に分析します。</block>
  <block id="2357d01362feabb1716e49b27d23f9cf" category="inline-link">NVIDIA Maxine の 2 つのポートが</block>
  <block id="a2415fcdba82ba111e08286b17d98943" category="paragraph">この問題を解決するエンドツーエンドの AI パイプラインを迅速に構築するための強力な方法が用意されています。この場合、 NVIDIA Riva ライブラリを使用して、音声変換と感情分析の 2 つの直列タスクを実行できます。1 つ目は教師あり学習信号処理アルゴリズムで、 2 つ目は教師あり学習 NLP 分類アルゴリズムです。NVIDIA TAO Toolkit を使用すれば、ビジネス関連のデータを使用して、関連するあらゆるユースケースに合わせてアルゴリズムを微調整できます。その結果、コストとリソースの数分の 1 に過ぎず、より正確で強力なソリューションを構築できます。お客様はを組み込むことができます<block ref="2aa9e1b3ec0ddf7f0bf09cdb2976222a" category="inline-link-rx"></block> サポートセンター設計における GPU アクセラレーションビデオ会議アプリケーションのフレームワーク。</block>
  <block id="076dd41fe8ba902e5439b5ba07f330ee" category="paragraph">この解決策の中核をなすのは、次のユースケースです。どちらのユースケースでも、 TAIO ツールキットを使用してモデルの微調整を行い、 Rivea を使用してモデルを展開します。</block>
  <block id="bc176e8f914533ec222bba678e13955f" category="paragraph">従業員と顧客の間のサポートセンターのやり取りを分析するために、音声コールの形式で各顧客との会話をパイプラインを通じて実行し、文レベルの感情を抽出できます。そのような感情は、人間が感情を正当化するか、必要に応じて調整することができます。次に、ラベル付けされたデータが微調整ステップに渡され、感情の予測が改善されます。ラベル付きの感情データがすでに存在する場合は、モデルの微調整を迅速に行うことができます。どちらの場合も、パイプラインは音声の取り込みと文章の分類を必要とする他のソリューションに対して一般化可能です。</block>
  <block id="91fa9ce0e0cb723f35d6cc55f796be7e" category="paragraph"><block ref="91fa9ce0e0cb723f35d6cc55f796be7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8836d456396ee0865c317994c018a24b" category="paragraph">AI の感情に関するアウトプットは、外部クラウドデータベースまたは企業が管理するストレージシステムにアップロードされます。この大規模なデータベースからローカルストレージにセンチメント出力が転送され ' 管理者のセンチメント分析を表示するダッシュボード内で使用されますダッシュボードの主な機能は、カスタマーサービスのスタッフとリアルタイムで連携することです。マネージャは、コール中の従業員に関する評価やフィードバックを行い、各文章の感情を最新の状態に更新したり、従業員の過去のパフォーマンスや顧客からの反応を履歴的に確認したりすることができます。</block>
  <block id="586779135ffb596b1f1844ada64164b6" category="paragraph"><block ref="586779135ffb596b1f1844ada64164b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="539788a6fdaffc74393f282739bdd3e2" category="paragraph">。 <block ref="95472f01c3cd86dddef6619dbb9af815" category="inline-link-macro-rx"></block> Riva 推論パイプラインが感情ラベルを生成した後も、データストレージシステムの管理を継続できます。これらの AI 分析結果は、 NetApp DataOps ツールキットで管理するデータストレージシステムにアップロードできます。データストレージシステムは、数百ものインサートを管理し、毎分選択できる能力を備えている必要があります。ローカルデバイスストレージシステムは、大容量のデータストレージをリアルタイムで照会して抽出します。大規模なデータストレージインスタンスを照会して履歴データを照会することで、ダッシュボードのエクスペリエンスを強化することもできます。NetApp DataOps ツールキットを使用すると、データを迅速にクローニングし、データを使用するすべてのダッシュボードにデータを分散できるため、この 2 つの方法を簡単に使用できます。</block>
  <block id="679db67ee98260ef471da732862ed356" category="list-text">従業員のマネージャー</block>
  <block id="7e6beec614d536589c47de8f77fa1b1a" category="list-text">データエンジニア / データサイエンティスト</block>
  <block id="a2ce7e25564bee3c78076bcff87d1329" category="list-text">IT 管理者（オンプレミス、クラウド、ハイブリッド）</block>
  <block id="8dcd09ac05ad9012a6ff01f7b5fc337b" category="paragraph">会話中に感情を追跡することは、従業員のパフォーマンスを評価するための貴重なツールです。AI ダッシュボードを使用することで、マネージャーは従業員と発信者が自分の感情をリアルタイムでどのように変化させるかを確認できるため、ライブ評価やガイダンスセッションが可能になります。さらに、音声会話、テキストチャットボット、ビデオ会議に参加しているお客様から、価値ある顧客インサイトを得ることができます。このような顧客分析では、最新の AI モデルとワークフローを使用して、大規模なマルチモーダル処理の機能を活用しています。</block>
  <block id="b7c29e65097b6ed45e464f6492ff670d" category="paragraph">データ側では、多数のオーディオファイルがサポートセンターによって毎日処理されます。NetApp DataOps ツールキットを使用すると、モデルの定期的な微調整と感情分析用ダッシュボードの両方で、このデータ処理タスクを容易に行うことができます。</block>
  <block id="1da289b166db713f9283c5be78ef5b96" category="paragraph">IT 管理者は、 NetApp DataOps ツールキットを利用して、導入環境と本番環境の間でデータを迅速に移動することもできます。また、リアルタイム推論のためには、 NVIDIA 環境とサーバも管理、分散する必要があります。</block>
  <block id="7179915e029316714169ac136027ef31" category="paragraph"><block ref="7179915e029316714169ac136027ef31" category="inline-link-macro-rx"></block></block>
  <block id="c1579c333c7c7a4e52136c7f58a7efc6" category="summary">このテクニカルレポートで提案している解決策は、こうした優れたカスタマーエクスペリエンスの提供を支援することを実証しています。課題は、企業が AI インフラとワークフローを最新化するためのアクションを取ることです。</block>
  <block id="9c5e72cb1709251063c12e4bddb1ba12" category="inline-link-macro">Previous （前）：ビデオとデモ。</block>
  <block id="2f6461cd01fcb0c2d85704a563bd7c19" category="paragraph"><block ref="2f6461cd01fcb0c2d85704a563bd7c19" category="inline-link-macro-rx"></block></block>
  <block id="50d6e8cef34560d1d68c6688a12b1cb8" category="paragraph">顧客体験が競争上の重要な戦場と見なされるようになった今、 AI を強化したグローバルサポートセンターは、ほぼすべての業界の企業が無視することができない重要な要素となっています。このテクニカルレポートで提案している解決策は、こうした優れたカスタマーエクスペリエンスの提供を支援することを実証しています。課題は、企業が AI インフラとワークフローを最新化するためのアクションを取ることです。</block>
  <block id="f6e349295b2165b25a412793116b8675" category="paragraph">顧客サービスにおける AI の最適な実装は、人事担当者の代わりになるものではありません。AI は、リアルタイムの感情分析、紛争のエスカレーション、マルチモーダルの感情コンピューティングを通じて、優れた顧客体験を生み出す力を発揮します。これにより、包括的な AI モデルが大規模に推奨事項を提示し、個々のヒューマンエージェントが欠けている可能性のある点を補足する、言葉、言葉以外の顔の手がかりを検出できます。AI は、特定のお客様と現在対応可能なエージェントをよりよくマッチさせることもできます。AI を活用することで、企業は、プロバイダの製品、サービス、ブランドイメージに対する顧客の考えや印象に関する価値ある感情を引き出すことができます。</block>
  <block id="eb5cb6f03236a80f7ddd5085afa95729" category="paragraph">解決策を使用して、客観的なパフォーマンス評価指標として機能するように、サポートエージェントの時系列データを作成することもできます。従来の顧客満足度調査では、十分な回答が得られないことが雇用者は、長期的な従業員や顧客の感情を収集することで、サポートエージェントのパフォーマンスに関して十分な情報に基づいた判断を下すことができます。</block>
  <block id="aa20fc291fbb8ceda8651d8d8ee9dba6" category="paragraph">ネットアップ、 SFL Scientific 、オープンソースのオーケストレーションフレームワーク、 NVIDIA を組み合わせることで、最新テクノロジをマネージドサービスとして統合し、優れた柔軟性を提供することで、テクノロジの採用を促進し、新しい AI / ML アプリケーションの市場投入期間を短縮できます。これらの高度なサービスはオンプレミスで提供され、クラウドネイティブ環境やハイブリッド導入アーキテクチャへの移植が容易です。</block>
  <block id="71fd14327d5bf7e725ab97e00192b238" category="paragraph"><block ref="71fd14327d5bf7e725ab97e00192b238" category="inline-link-macro-rx"></block></block>
  <block id="9c08a0abcced906f3225e86f61dd598c" category="paragraph"><block ref="9c08a0abcced906f3225e86f61dd598c" category="inline-link-macro-rx"></block></block>
  <block id="c5648cc9e6e76ab4aa041d71661d0288" category="list-text">3D 対話型デモ</block>
  <block id="26e071d5769be8e940617a0c8dd5c22d" category="inline-link">www.netapp.com/ai</block>
  <block id="9e22db1b830d668e86d5dc1b5c204555" category="paragraph"><block ref="9e22db1b830d668e86d5dc1b5c204555" category="inline-link-rx"></block></block>
  <block id="1fa584a3d1190f1a7fdded0c91412cac" category="list-text">ネットアップの AI スペシャリストと直接つながる</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="488d7301e5d1a52040c33186d7e11657" category="paragraph"><block ref="488d7301e5d1a52040c33186d7e11657" category="inline-link-rx"></block></block>
  <block id="787dd83fbbc162f0279e320ada1f7c0b" category="list-text">ネットアップ解決策が実現する NVDIA 基本コマンドプラットフォームの概要</block>
  <block id="5541299dd0999c42fcd24fd754001e38" category="inline-link"><block ref="5541299dd0999c42fcd24fd754001e38" category="inline-link-rx"></block></block>
  <block id="ac527e3c2b2d8a080840aa28c13b127b" category="paragraph"><block ref="ac527e3c2b2d8a080840aa28c13b127b" category="inline-link-rx"></block></block>
  <block id="465b9c508fba1d27d188eb21e0655293" category="list-text">AI 向けネットアップ 10 の理由を解説したインフォグラフィック</block>
  <block id="75048e22ffd1c45ce07e6cae3170780a" category="inline-link"><block ref="75048e22ffd1c45ce07e6cae3170780a" category="inline-link-rx"></block></block>
  <block id="e2435a6f01dee5a11f6cd698a292183d" category="paragraph"><block ref="e2435a6f01dee5a11f6cd698a292183d" category="inline-link-rx"></block></block>
  <block id="66d4373905c5c7c0a3f51e5480d443b2" category="list-text">ヘルスケア分野の AI ：『 Deep learning to identify COVID-19 nscions in lung CT scans 』ホワイトペーパーを参照してください</block>
  <block id="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link"><block ref="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link-rx"></block></block>
  <block id="d1e9d43080e6c2364ee86ac930ae1341" category="paragraph"><block ref="d1e9d43080e6c2364ee86ac930ae1341" category="inline-link-rx"></block></block>
  <block id="2ece031fbb30496ba2ec244a07557107" category="list-text">ヘルスケア分野の AI ：ヘルスケア設定におけるフェイスマスクの使用状況を監視するホワイトペーパーです</block>
  <block id="aa895997d9bc7e84d90779885cb936b7" category="inline-link"><block ref="aa895997d9bc7e84d90779885cb936b7" category="inline-link-rx"></block></block>
  <block id="4ac3d75f4e132824f0fe3a418d42a9f9" category="paragraph"><block ref="4ac3d75f4e132824f0fe3a418d42a9f9" category="inline-link-rx"></block></block>
  <block id="ff11da2c36a9883c6eb658395f3de353" category="list-text">医療分野の AI ：診断画像診断テクニカルレポート</block>
  <block id="41575d740e0d837694e2fa66ce618124" category="inline-link"><block ref="41575d740e0d837694e2fa66ce618124" category="inline-link-rx"></block></block>
  <block id="61a15cd6b61d637fb54ae6ae99ae39d5" category="paragraph"><block ref="61a15cd6b61d637fb54ae6ae99ae39d5" category="inline-link-rx"></block></block>
  <block id="1527888e6b729290296c51cf9c3aeeec" category="list-text">小売業向け AI ：ネットアップの会話型 AI で NVIDIA Riva を使用</block>
  <block id="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link"><block ref="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link-rx"></block></block>
  <block id="dc1f6c62d8de3b68ec946b66d053f5a7" category="paragraph"><block ref="dc1f6c62d8de3b68ec946b66d053f5a7" category="inline-link-rx"></block></block>
  <block id="2281741ceb773b1efc91b48b4e5e04fe" category="list-text">NetApp ONTAP AI 解決策の概要</block>
  <block id="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link"><block ref="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link-rx"></block></block>
  <block id="a32cc63ad53dc74caf680b96a921ad3b" category="paragraph"><block ref="a32cc63ad53dc74caf680b96a921ad3b" category="inline-link-rx"></block></block>
  <block id="c6b4ec978259e83d537f6a179912448a" category="list-text">NetApp DataOps ツールキットの解決策概要</block>
  <block id="c50b3ec30c711b6233dd7753f12165d4" category="inline-link"><block ref="c50b3ec30c711b6233dd7753f12165d4" category="inline-link-rx"></block></block>
  <block id="a045bf4eb32fbbf6c351d4c3cbd5932c" category="paragraph"><block ref="a045bf4eb32fbbf6c351d4c3cbd5932c" category="inline-link-rx"></block></block>
  <block id="9399af78c2a9b2a197612e42bf8b8f79" category="list-text">ネットアップの AI コントロールプレーン解決策の概要</block>
  <block id="c771257beb97f479ebb6d342d91b61bd" category="inline-link"><block ref="c771257beb97f479ebb6d342d91b61bd" category="inline-link-rx"></block></block>
  <block id="ce6060d7bc79a57fdb337f6364f0e8a9" category="paragraph"><block ref="ce6060d7bc79a57fdb337f6364f0e8a9" category="inline-link-rx"></block></block>
  <block id="b6e1af8dc83073dfa46f061507b15586" category="list-text">『データの活用で業界を変革』の E ブック</block>
  <block id="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link"><block ref="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link-rx"></block></block>
  <block id="195010aa6331d4b94de36f6aa5cf3fc7" category="paragraph"><block ref="195010aa6331d4b94de36f6aa5cf3fc7" category="inline-link-rx"></block></block>
  <block id="4dcaafba5ac7511b65c0f3a3688f8d81" category="list-text">NetApp EF シリーズ AI 解決策の概要</block>
  <block id="385bae1ac9580238d4ef22dad99878c3" category="inline-link"><block ref="385bae1ac9580238d4ef22dad99878c3" category="inline-link-rx"></block></block>
  <block id="5bbcd3b785c7ecb740b1302ea68fb4ff" category="paragraph"><block ref="5bbcd3b785c7ecb740b1302ea68fb4ff" category="inline-link-rx"></block></block>
  <block id="e72de1f0850154df8bf93fae76b2276d" category="list-text">AI 推論向けのネットアップの AI と Lenovo ThinkSystem 解決策の概要</block>
  <block id="883d1d69b62bc20ea26446649b6c95b0" category="inline-link"><block ref="883d1d69b62bc20ea26446649b6c95b0" category="inline-link-rx"></block></block>
  <block id="74686a12110c0c39ad22ac2252bcb1a1" category="paragraph"><block ref="74686a12110c0c39ad22ac2252bcb1a1" category="inline-link-rx"></block></block>
  <block id="8954bee2812529847e7f3108185fc57d" category="list-text">エンタープライズ AI および ML 向けのネットアップ AI と Lenovo ThinkSystem の解決策概要</block>
  <block id="f877ccffca68b901c2c61513c04dbf37" category="inline-link"><block ref="f877ccffca68b901c2c61513c04dbf37" category="inline-link-rx"></block></block>
  <block id="214ebd5c8513ce31087d4bf0cd12af76" category="paragraph"><block ref="214ebd5c8513ce31087d4bf0cd12af76" category="inline-link-rx"></block></block>
  <block id="7cbca96fc14ecadf4054303e98a81787" category="list-text">ネットアップと NVIDIA – AI ビデオで可能なことを再定義</block>
  <block id="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link"><block ref="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link-rx"></block></block>
  <block id="c7531fbb829ae07f04aab76de6fad46c" category="paragraph"><block ref="c7531fbb829ae07f04aab76de6fad46c" category="inline-link-rx"></block></block>
  <block id="f521e3eae9fd2145ce8aeede6602641d" category="summary">このセクションでは、この解決策のさまざまなコンポーネントの設計上の考慮事項について説明します。</block>
  <block id="5b1c62f1e35074e19185d9341b492c54" category="inline-link-macro">前のバージョン：アーキテクチャ</block>
  <block id="b180067c966e23ba80c92f3bb1bf6745" category="paragraph"><block ref="b180067c966e23ba80c92f3bb1bf6745" category="inline-link-macro-rx"></block></block>
  <block id="35ff22a5291df56d5075c29d8dc65044" category="section-title">ネットワークとコンピューティングの設計</block>
  <block id="49d41bdb2234e0a4330f0c9d7d03853a" category="paragraph">データセキュリティの制限に応じて、すべてのデータはお客様のインフラストラクチャまたはセキュアな環境内に保持されている必要があります。</block>
  <block id="5a20c2b759137410d60f5ce368ca45d2" category="paragraph"><block ref="5a20c2b759137410d60f5ce368ca45d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d6e133bd239a98d559f693ee2ff5ecc" category="section-title">ストレージ設計</block>
  <block id="3051d856c7b26f6d385279d67a8a532b" category="paragraph">NetApp DataOps ツールキットは、ストレージシステムを管理するための主要なサービスです。DataOps ツールキットは Python ライブラリで、開発者、データサイエンティスト、 DevOps エンジニア、データエンジニアは、新しいデータボリュームや JupyterLab ワークスペースのほぼ瞬時のプロビジョニング、データボリュームや JupyterLab ワークスペースのほぼ瞬時のクローニングなど、さまざまなデータ管理タスクを簡単に実行できます。 トレーサビリティやベースライン設定のためのデータボリュームまたは JupyterLab ワークスペースのほぼ瞬時のスナップショット作成。この Python ライブラリは、任意の Python プログラムまたは Jupyter Notebook にインポートできるコマンドラインユーティリティまたは関数ライブラリとして機能します。</block>
  <block id="6f9e8585e5f750b8ceb149639b1e25e6" category="section-title">RIVA のベストプラクティス</block>
  <block id="7ecab6bd65c2f169e987be2f59219357" category="inline-link">ベストプラクティスに基づくデータ保護</block>
  <block id="f51b8fa6c731ea53318149e50e826ddb" category="paragraph">NVIDIA はいくつかの一般的な機能を提供<block ref="f6aee1daf7f2fd9cd207fcd26f08d8be" category="inline-link-rx"></block> リベットを使用する場合：</block>
  <block id="20430e77ba2ecbe15261761c8f4fa2c4" category="list-text">* 可能であれば、ロスレスのオーディオフォーマットを使用します。 * MP3 などの損失のあるコーデックを使用すると、品質が低下する可能性があります。</block>
  <block id="8b3e389f067f32da1e1ab7df2b8d8155" category="list-text">* トレーニングデータの増加。 * 音声トレーニングデータにバックグラウンドノイズを追加することで、当初は精度を低下させながら堅牢性を高めることができます。</block>
  <block id="b37d69a795b4d7bb6e0f28a42c3ef8ae" category="list-text">* スクラップテキストを使用すれば語彙のサイズを制限しなさい。 * 多くのオンライン源にタイプミスまたは補助発音および珍しい単語を含んでいる。これらを削除すると、言語モデルが改善されます。</block>
  <block id="6afe4c71ada39a70da349380efbad345" category="list-text">* 可能であれば、最小サンプリングレート 16kHz を使用します。 * ただし、オーディオ品質が低下するため、リサンプルしないようにしてください。</block>
  <block id="cab3977e4ad163e19ab6245a9b09f541" category="paragraph">これらのベストプラクティスに加えて、パイプラインの各ステップで正確なラベルを持つ代表的なサンプルデータセットの収集に優先順位を付ける必要があります。つまり、サンプルデータセットには、ターゲットデータセットに典型的な指定された特性を比例的に反映させる必要があります。同様に、データセットの注釈には、データの品質と量を最大化するために、正確性とラベル付けの速度のバランスをとる責任があります。たとえば、このサポートセンターの解決策には、音声ファイル、ラベル付きテキスト、および感情ラベルが必要です。この解決策は、シーケンシャルなので、パイプラインの開始時に発生したエラーが最後まで伝播されます音声ファイルの品質が悪い場合は、テキスト文字変換と感情ラベルも同様になります。</block>
  <block id="0b6b65c9613285433178682e3550355c" category="paragraph">このエラーの伝播も同様に、環境 the models Trained on this data です。感情の予測が 100% 正確であるにもかかわらず、音声テキスト変換モデルのパフォーマンスが低い場合、最終的なパイプラインは最初の音声テキスト変換によって制限されます。開発者は、各モデルのパフォーマンスを個別に、また大きなパイプラインのコンポーネントとして考慮する必要があります。この場合、最終目標は、感情を正確に予測できるパイプラインを開発することです。そのため、パイプラインを評価する全体的な指標は感情の精度であり、音声からテキストへの変換は直接影響を与えます。</block>
  <block id="f3b552e561f520013398b3be885a4420" category="paragraph"><block ref="f3b552e561f520013398b3be885a4420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1ce31a9f2a1a3a478bb69589e180bd" category="paragraph">NetApp DataOps ツールキットは、ほぼ瞬時のデータクローニングテクノロジを使用して、データ品質チェックパイプラインを補完します。各ラベル付きファイルを評価し、既存のラベル付きファイルと比較する必要があります。これらの品質チェックをさまざまなデータストレージシステムに分散させることで、これらのチェックを迅速かつ効率的に実行できます。</block>
  <block id="6d61a746e66a6545c5c9faf68668e013" category="inline-link-macro">次は、サポートセンターの感情分析の展開です。</block>
  <block id="58a113e09ecc7941870d9bcc2d2ee3df" category="paragraph"><block ref="58a113e09ecc7941870d9bcc2d2ee3df" category="inline-link-macro-rx"></block></block>
  <block id="34d110ef6b6b3684adfe9c791fce2f95" category="summary">このセクションでは、この解決策を導入するために必要な詳細な手順について説明します。</block>
  <block id="e0673e67d0ae2470ff4a9a3a926792b0" category="doc">サポートセンターのセンチメント分析の導入</block>
  <block id="0c7ee1e6d81ae421558f2979d46adb5d" category="inline-link-macro">前の手順：設計上の考慮事項。</block>
  <block id="2e4639bc721df1da69c19fe5c10f5764" category="paragraph"><block ref="2e4639bc721df1da69c19fe5c10f5764" category="inline-link-macro-rx"></block></block>
  <block id="b23f4e3eb5ff4f900ba54c824bf7a676" category="paragraph">解決策の導入には、次のコンポーネントが含まれます。</block>
  <block id="1b497bff4e1d2dff7f8855237612936b" category="list-text">NGC の設定</block>
  <block id="2dcf1afb8ed1445e4b167ef91fdd8a1b" category="list-text">NVIDIA Rivea サーバ</block>
  <block id="6894a1e922948fc0bc9cc96291183448" category="list-text">NVIDIA TAO ツールキット</block>
  <block id="3b498dd8feee94c2dbcb419be10d3b70" category="list-text">TAO モデルを Riva にエクスポートします</block>
  <block id="534b37206d500ff97473ada660fb69d3" category="paragraph">導入を実行するには、次の手順を実行します。</block>
  <block id="2f6c7bd50828792593b3aa4deff875cc" category="section-title">NetApp DataOps ツールキット：センターのセンチメント分析をサポート</block>
  <block id="3b84de14b99e2695fdfd099f56b254be" category="paragraph">を使用します<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>、次の手順を実行します。</block>
  <block id="d19523f192f664c9e34bf949d6f084c3" category="list-text">PIP でツールキットをインストールします。</block>
  <block id="1fe6ae43439f5ccecf9883686d6b3784" category="list-text">データ管理を設定</block>
  <block id="36b413e2c45a91e66db4aac6abd67ba1" category="section-title">NGC 構成：センターの感情分析をサポート</block>
  <block id="e3ab64bcab09d9eb8219520405242267" category="inline-link">NVIDIA NGC</block>
  <block id="f526ba073cf7bc97c2b0d3bfe091e293" category="paragraph">セットアップするには<block ref="5b4e29c9d8254a25bb1abc36cd17ca4c" category="inline-link-rx"></block>、次の手順を実行します。</block>
  <block id="a485a457c113aa9f2f8096ac1ca500d7" category="list-text">NGC をダウンロード</block>
  <block id="7438544460c4a4fdf0b70bb65bb03a92" category="list-text">現在のディレクトリをパスに追加します。</block>
  <block id="4f1208b2473595e5f4c3118c13de0fcc" category="list-text">コマンドを実行できるように、 NGC CLI を設定する必要があります。次のコマンドを入力します。プロンプトが表示されたら、 API キーも入力します。</block>
  <block id="5307692c5f99e57b8002a6a87f08c240" category="paragraph">Linux ベースではないオペレーティングシステムについては、を参照してください<block ref="481e32faa0c657434738f6f0a550651b" category="inline-link-rx"></block>。</block>
  <block id="326419ec6a380f68d7d15a373452bf35" category="section-title">NVIDIA Rivea サーバ：センタ心理分析をサポートします</block>
  <block id="92ed82a726e834b50a6863c8c4e9db4e" category="paragraph">セットアップするには<block ref="fb85035785391c7c4b815d01de952f38" category="inline-link-rx"></block>、次の手順を実行します。</block>
  <block id="a4fc5fd3d1cea05f031d5adc045dc1e0" category="list-text">NGC から Riva ファイルをダウンロード</block>
  <block id="5f2573d8cf9e274560d9a9b3eb2e1aaa" category="list-text">Riva セットアップを初期化します (`Riva_init.sh`)</block>
  <block id="3b570ac682cfeffcdb2c7243afdbf285" category="list-text">Riva サーバ (`Riva_start.sh`) を起動します</block>
  <block id="d44d4e10378cce2928c99a4b49e45cea" category="list-text">Riva クライアント (`Riva_start_client.sh`) を起動します</block>
  <block id="6846c1a17ddaf84e01f26ec51c151e78" category="inline-link">FFmpeg</block>
  <block id="22c9c751571566e0566c448194d9d64f" category="list-text">Riva クライアント内で、オーディオ処理ライブラリをインストールします（<block ref="3e294dfc4ee3a49adac5a070482274ce" category="inline-link-rx"></block>)</block>
  <block id="8637711b2ee1b94fe789bb28e88c4b61" category="list-text">を起動します<block ref="37a4c4b3ad3c3851ac5717bfd3104346" category="inline-link-rx"></block> サーバ</block>
  <block id="b57a5203a9fd3e877aacee6cba6bc9c8" category="list-text">Riva Inference Pipeline Notebook を実行します。</block>
  <block id="5dceab25ae38dae0d7ed3167abd32377" category="section-title">NVIDIA TAO Toolkit ：センターの感情分析をサポートします</block>
  <block id="2418d4c7f6be40d5c9a50e4aecab1b27" category="paragraph">NVIDIA TAO Toolkit をセットアップするには、次の手順を実行します。</block>
  <block id="630eef78d15fd844ba4a38ea7f7a9c79" category="inline-link">仮想環境</block>
  <block id="35fb58d5f90347e4f0c445b4968db5f6" category="list-text">を準備してアクティブ化します<block ref="3d97a4392c0af686650645d1371fa8ef" category="inline-link-rx"></block> TAO ツールキット用。</block>
  <block id="0a80b2068950d6e04f34c0142a10e719" category="inline-link">必須パッケージ</block>
  <block id="40eb0bd8a87ab1b39e8f2ee5ea287a22" category="list-text">をインストールします<block ref="3646357cb54591ae95dd3b8f0889f0c2" category="inline-link-rx"></block>。</block>
  <block id="c0e95a7dacbc170e387c4e1a0fe41a0b" category="list-text">トレーニング中および微調整中に使用したイメージを手動で引き出します。</block>
  <block id="b5a6ae7c1df936b55910309efc466f01" category="list-text">TAO 微調整ノートブックを実行します。</block>
  <block id="e6dda626093691f78b3127a8faa82b6e" category="section-title">TAO モデルを Riva にエクスポート：センターの感情分析をサポートします</block>
  <block id="6a358d81cb24a7e408b0339062f6bb92" category="inline-link">Rivea の Tao ツールキットモデル</block>
  <block id="53ace4ba305859107cead3e5b0b53b8b" category="paragraph">を使用してください<block ref="ce50a5bf8eb35af9ad9bb322336ee3af" category="inline-link-rx"></block>、次の手順を実行します。</block>
  <block id="08c3be8307b7659c6ad67ee4d9659d58" category="list-text">TAO 微調整ノートブックにモデルを保存します。</block>
  <block id="ac711bb6af28947dfa8b29512acb36e8" category="list-text">TAO トレーニング済みモデルを Riva モデルディレクトリにコピーします。</block>
  <block id="1317e1d8d20d5c44c680825aba2196e6" category="section-title">導入の障害です</block>
  <block id="6e3da39922ebbd1a8a1a5a7238a89168" category="paragraph">独自の解決策を開発する際に留意すべき点をいくつかご紹介します。</block>
  <block id="47c0613abd5b97b67a94c2355692cf08" category="list-text">最初に NetApp DataOps ツールキットをインストールし、データストレージシステムが最適に動作するようにします。</block>
  <block id="943f803f8c6b4c6508bc97536a6d7b2b" category="list-text">NVIDIA NGC は、イメージとモデルのダウンロードを認証するため、それ以外のコンポーネントよりも先にインストールする必要があります。</block>
  <block id="70367b72bfd96b5608a7c72ac3f983bf" category="list-text">Rivea は、 TAO ツールキットの前にインストールする必要があります。Riva インストールでは、必要に応じてイメージをプルするように Docker デーモンが設定されます。</block>
  <block id="1ed7124aa68792cb6ce3049f6f1d4f7b" category="list-text">DGX および Docker でモデルをダウンロードするには、インターネットアクセスが必要です。</block>
  <block id="de9b04ca3177b736c9f3cc74d62f5088" category="inline-link-macro">次の例は、検証結果です</block>
  <block id="3556370bb03d018998375ff0476db59a" category="paragraph"><block ref="3556370bb03d018998375ff0476db59a" category="inline-link-macro-rx"></block></block>
  <block id="0e85d8fd0ce7acdba87f57325a14b3fb" category="summary">前のセクションで説明したように、 2 つ以上の機械学習モデルが順番に実行されている場合は常に、エラーがパイプライン全体に伝播されます。この解決策では、企業の株価リスクレベルを測定する上で最も重要な要因は、文章の感情です。音声対テキストモデルは、パイプラインに不可欠ですが、感情を予測する前に前処理単位として機能します。</block>
  <block id="6700d3710d10e74d6e48f994b760d48b" category="doc">検証結果</block>
  <block id="ee4eec78ae095f539af53c130e976afa" category="inline-link-macro">前の内容：サポートセンターの感情分析の展開</block>
  <block id="ac96c8f3af95b93c2683c2124998e668" category="paragraph"><block ref="ac96c8f3af95b93c2683c2124998e668" category="inline-link-macro-rx"></block></block>
  <block id="2e10a4ae90aad11c07592a14fbf8c5c6" category="paragraph">前のセクションで説明したように、 2 つ以上の機械学習モデルが順番に実行されている場合は常に、エラーがパイプライン全体に伝播されます。この解決策では、企業の株価リスクレベルを測定する上で最も重要な要因は、文章の感情です。音声対テキストモデルは、パイプラインに不可欠ですが、感情を予測する前に前処理単位として機能します。実際に重要なのは、基本的な真実文と予測された文の感情の違いです。これは、ワードエラーレート（ WER ）のプロキシとして機能します。音声とテキストの正確さは重要ですが、 WER は最終的なパイプラインメトリックでは直接使用されません。</block>
  <block id="0fc4c7871adf5db8dd2b13fc4c381da8" category="paragraph">これらの感情指標は、 F1 スコア、リコール、各文章の精度について計算できます。結果は集約され、各メトリックの信頼間隔とともに混乱マトリックス内に表示されます。</block>
  <block id="66554c8f1474c5658d17e23710901f98" category="paragraph">転送学習を使用する利点は、データ要件、トレーニング時間、コストの数分の 1 でモデルのパフォーマンスが向上することです。また、微調整されたモデルをベースラインバージョンと比較して、転送学習がインペアリングではなくパフォーマンスを向上させるようにする必要があります。つまり、調整済みモデルの方が、サポートセンターのデータのパフォーマンスが事前トレーニング済みモデルよりも優れているはずです。</block>
  <block id="6e979ee914c9401fddd049d16cdef66a" category="section-title">パイプラインの評価</block>
  <block id="7f109f66c71a1fd15436d1c413354c41" category="cell">テストケース</block>
  <block id="e7f1ec3a5f35af805407a8a531eefb79" category="cell">テスト番号</block>
  <block id="6bf1af9a7f1b6dd6cca4b7434097ad94" category="cell">パイプラインのセンチメント指標</block>
  <block id="beed3529b961c63b785104d7a17cf5f4" category="cell">テストの前提条件</block>
  <block id="c7320b1f70fd8a9831e530d17a82f34d" category="cell">音声 / テキストおよび感情分析モデル向けに微調整されたモデル</block>
  <block id="9d5b1bc6dcdedf0c8750e543fab75738" category="cell">予想される結果</block>
  <block id="74015a89b882f01e94433a9c1f1c904c" category="cell">微調整されたモデルのセンチメント・メトリックは、元の事前トレーニング済みモデルよりも優れています。</block>
  <block id="68d279a19e31962e0ab0b648f25c07ee" category="list-text">ベースラインモデルのセンチメントメトリックを計算します。</block>
  <block id="b6168629c9e5a47b0637aa362112642d" category="list-text">微調整モデルのセンチメントメトリックを計算します。</block>
  <block id="97ae5da5f745d90cf815a206b3549e0a" category="list-text">これらの指標間の差異を計算します。</block>
  <block id="fc997f472d1b5e66aadb364e10c29f4f" category="list-text">すべての文の違いを平均化します。</block>
  <block id="c6b3b1378b2e31169a4a1cd4c20691c8" category="inline-link-macro">次は、ビデオとデモです</block>
  <block id="6016219a0b0ad0bb3594f964b5e6396d" category="paragraph"><block ref="6016219a0b0ad0bb3594f964b5e6396d" category="inline-link-macro-rx"></block></block>
  <block id="67d45a00257105f21f4427f31e0c9fa1" category="summary">このテクニカルレポートでは、転送学習と会話型 AI を使用して、ネットアップのデータ管理テクノロジと NVIDIA ソフトウェアフレームワークを使用して、エンタープライズレベルのグローバルサポートセンターで感情分析を行うための設計ガイダンスを提供します。</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="doc">TR-4910 ：『 NetApp AI と顧客コミュニケーションを組み合わせた感情分析』</block>
  <block id="22268d4ee4f32cda2f20141957aac961" category="paragraph">Sathish Thyagarajan 、 Rick Huang 氏、および SFL Scientific 、 Diego Sosa-coba 、 David Arnette 氏</block>
  <block id="0c450c48691e7a55b657f2cb7d18a0dd" category="paragraph">このテクニカルレポートでは、転送学習と会話型 AI を使用して、ネットアップのデータ管理テクノロジと NVIDIA ソフトウェアフレームワークを使用して、エンタープライズレベルのグローバルサポートセンターで感情分析を行うための設計ガイダンスを提供します。この解決策は、チャットログ、 E メール、およびその他のテキストまたは音声通信を表す録音された音声ファイルやテキストファイルから顧客の洞察を得たいと考えているあらゆる業界に適用されます。ネットアップはエンドツーエンドのパイプラインを実装して、ネットアップのクラウド対応オールフラッシュストレージを使用した GPU アクセラレーションコンピューティングクラスタで、自動音声認識、リアルタイムの感情分析、ディープラーニングの自然言語処理モデル再トレーニング機能をデモンストレーションしました。大規模で最先端の言語モデルのトレーニングと最適化により、世界規模のサポートセンターで推論を迅速に実行できるようになり、優れたカスタマーエクスペリエンスと目標を達成し、長期的な従業員パフォーマンス評価を実施できます。</block>
  <block id="549c85ede9b39be6ef0eec80db7e098c" category="paragraph">感情分析は、正、負、または中性感情がテキストから抽出される Natural Language Processing （ NLP ）内の研究分野です。会話型 AI システムは、より多くの人がコミュニケーションを行うようになったため、ほぼグローバルレベルの統合にまで成長しました。感情分析には、サポートセンターの従業員のパフォーマンスを発信者との会話で決定し、適切な自動チャットボット応答を提供し、四半期ごとの収益呼における企業の代表者と対象者間のやり取りに基づいて会社の株価を予測するなど、さまざまなユースケースがあります。さらに、感情分析を使用して、ブランドが提供する製品、サービス、サポートに関するお客様の見解を判断できます。</block>
  <block id="5855677156d63ad3c93a7b5382098060" category="paragraph">このエンドツーエンドの解決策は、 NLP モデルを使用して、サポートセンター分析フレームワークを可能にする高度なセンチメント分析を実行します。音声録音は文書化されたテキストに処理され、会話の各文から感情が抽出されます。結果はダッシュボードに集約され、会話の感情を分析するために、従来とリアルタイムの両方で巧妙に細工することができます。この解決策は、データモダリティと出力ニーズが似ている他のソリューションに汎用化できます。適切なデータを使用することで、他のユースケースにも対応できます。たとえば、企業収益の問い合わせを、同じエンドツーエンドパイプラインを使用して、センチメントについて分析することができます。また、パイプラインの柔軟性が高いため、トピックモデリングや Named Entity Recognition （ NER ）などの他の形式の NLP 解析も可能です。</block>
  <block id="ea4f750fd9fd89aeff4ca8d4162fb673" category="paragraph">これらの AI 実装は、 NVIDIA Rivea 、 NVIDIA TAO Toolkit 、 NetApp DataOps ツールキットが連携して実現しました。NVIDIA のツールを使用すると、あらかじめ組み込まれたモデルとパイプラインを使用して、ハイパフォーマンスな AI ソリューションを迅速に導入できます。NetApp DataOps ツールキットにより、さまざまなデータ管理タスクが簡易化され、開発期間が短縮されます。</block>
  <block id="7a7e97f7fcf4e2974d9a6feee2b056f8" category="section-title">お客様にもたらされる価値</block>
  <block id="3815ef30c3d6c6bdc3862cc9530d091e" category="paragraph">企業は、感情分析のためのテキスト、音声、ビデオの会話について、従業員評価および顧客対応ツールから価値を得ています。マネージャーは、ダッシュボードに表示される情報を活用して、会話の両側に基づいて従業員と顧客満足度を評価できます。</block>
  <block id="da210ea22d819ca26070a3795f9a14d4" category="paragraph">さらに、 NetApp DataOps ツールキットは、お客様のインフラストラクチャ内でのデータのバージョン管理と割り当てを管理します。その結果、ダッシュボードに表示される分析情報が頻繁に更新されるため、データストレージのコストを抑えることができません。</block>
  <block id="e5fcadecc4515efec9267b8ad57b28a5" category="inline-link-macro">次：ユースケース</block>
  <block id="93b7bce28e36a4eebec23c8fd4be315d" category="paragraph"><block ref="93b7bce28e36a4eebec23c8fd4be315d" category="inline-link-macro-rx"></block></block>
  <block id="c4ff33edf6e94fb434fb59e4ad2c286b" category="inline-link-macro">SnapCenter を使用したハイブリッドクラウドデータベースソリューション</block>
  <block id="fc25c016a8fb35a621842044a8d4f2e7" category="inline-link-macro">ハイブリッドクラウドで Oracle データベースインフラを自動化</block>
  <block id="ae270ffdc87820776fadfe121aa13143" category="sidebar">ネットアップの AI による地合い分析</block>
  <block id="f74720767a0bf20cfdb6bba5f215d795" category="sidebar">サポートセンターの感情分析の導入</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">このユースケースでは、 DevTest と Reporting の目的で同じデータセンターとリモートサイトに大量の分析データを格納した既存の Hadoop クラスタをベースに、新しい Hadoop / Spark クラスタを迅速かつ効率的に構築することがお客様の要件となります。</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">ユースケース 3 ：既存の Hadoop データに対して DevTest を有効化</block>
  <block id="aeab228f25b5fbe0b00f83117579246e" category="inline-link-macro">従来のユースケース 2 - クラウドからオンプレミスへのバックアップとディザスタリカバリ</block>
  <block id="cf44ed74ea7e07a8e4478e43d9537e07" category="paragraph"><block ref="cf44ed74ea7e07a8e4478e43d9537e07" category="inline-link-macro-rx"></block></block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">シナリオ（ Scenario ）</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">このシナリオでは、大規模な Hadoop データレイク実装をオンプレミスとディザスタリカバリサイトで使用して、複数の Spark / Hadoop クラスタを構築しています。</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="section-title">要件と課題</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">このユースケースの主な要件と課題は次のとおりです。</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">DevTest 、 QA 用など、同じ本番環境のデータへのアクセスを必要とする用途に複数の Hadoop クラスタを作成この課題は、非常に大規模な Hadoop クラスタを、スペース効率に優れた方法で何度も瞬時にクローニングすることです。</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">運用効率を高めるために、 Hadoop データを DevTest チームとレポートチームに同期します。</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">業務用クラスタと新規クラスタに同じクレデンシャルを使用して Hadoop データを分散します。</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">スケジュールされたポリシーを使用して、本番クラスタに影響を与えずに効率的に QA クラスタを作成</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">解決策</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">FlexClone テクノロジは、直前に説明した要件を回答に適用するために使用されます。FlexClone テクノロジは、 Snapshot コピーの読み取り / 書き込みコピーです。親 Snapshot コピーのデータを読み取り、新規または変更されたブロック用に追加のスペースのみを消費します。高速でスペース効率に優れています。</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">まず、ネットアップの整合グループを使用して既存のクラスタの Snapshot コピーを作成し、</block>
  <block id="4b481b20e942087b64c5bb7b07d9dca9" category="paragraph">NetApp System Manager またはストレージ管理プロンプト内の Snapshot コピー。整合グループ Snapshot コピーはアプリケーションと整合性のあるグループ Snapshot コピーであり、整合グループ Snapshot コピーに基づいて FlexClone ボリュームが作成されます。FlexClone ボリュームは親ボリュームの NFS エクスポートポリシーを継承することに留意する必要があります。Snapshot コピーの作成後、次の図に示すように、 DevTest および Reporting 用に新しい Hadoop クラスタをインストールする必要があります。インプレース分析モジュールは、 NFS データのインプレース分析モジュールユーザーおよびグループ許可を介して、新しい Hadoop クラスタからクローン NFS ボリュームにアクセスします。</block>
  <block id="4c490dfedbcc5a021b8a4c823e337d41" category="paragraph">適切なアクセス権を持つには、インプレース分析モジュールのユーザーとグループ構成で設定されたユーザーに対して、新しいクラスタに同じ UID と GUID が設定されている必要があります。</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">この図は、 DevTest 用の Hadoop クラスタを示しています。</block>
  <block id="4157075925c8c1518cc71d1d0abab403" category="paragraph"><block ref="4157075925c8c1518cc71d1d0abab403" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e10ad11fd299ee6f161f17d772a78a48" category="inline-link-macro">次のユースケース 4 - データ保護とマルチクラウド接続</block>
  <block id="8109e574f349ced8f667b9389c9189a4" category="paragraph"><block ref="8109e574f349ced8f667b9389c9189a4" category="inline-link-macro-rx"></block></block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">このセクションでは、ネットアップが提供するさまざまな Hadoop データ保護要件を満たすユースケースとソリューションの概要を説明します。</block>
  <block id="23496143e5ca83c13eb4d953786abdcd" category="inline-link-macro">前：ユースケース 5 - 分析ワークロードの高速化</block>
  <block id="09b7371b2ae3168a3c54b30e4966e86e" category="paragraph"><block ref="09b7371b2ae3168a3c54b30e4966e86e" category="inline-link-macro-rx"></block></block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">このセクションでは、ネットアップが提供するさまざまな Hadoop データ保護要件を満たすユースケースとソリューションの概要を説明します。ネットアップのデータファブリックを使用することで、お客様は次のことが可能になります。</block>
  <block id="ce0bf05854efb234905c751e40774ab5" category="list-text">ネットアップの充実したデータ管理機能と Hadoop ネイティブワークフローとの統合により、適切なデータ保護ソリューションを柔軟に選択できます。</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Hadoop クラスタのバックアップ時間を約 70% 短縮します。</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Hadoop クラスタのバックアップによるパフォーマンスへの影響を排除します。</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">異なるクラウドプロバイダからのマルチクラウドデータ保護とデータアクセスを、単一の分析データソースに同時に提供できます。</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">FlexClone テクノロジを使用すると、スペース効率に優れた高速な Hadoop クラスタコピーを作成できます。</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">このドキュメントに記載されている情報の詳細については、以下のドキュメントや Web サイトを参照してください。</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">ネットアップのビッグデータ分析ソリューション</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">ネットアップストレージを使用した Apache Spark ワークロード</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">ネットアップの Apache Spark 向けストレージソリューション</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">ネットアップが有効にしたデータファブリック上の Apache Hadoop</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="list-text">NetApp In-Place Analytics Module の略</block>
  <block id="1d669c79bffe95dd384dffb8309a0d40" category="inline-link"><block ref="1d669c79bffe95dd384dffb8309a0d40" category="inline-link-rx"></block></block>
  <block id="fde1cd76fa73f8065aeb8a97c77b40ec" category="paragraph"><block ref="fde1cd76fa73f8065aeb8a97c77b40ec" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">謝辞</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">ネットアップ、 ANZ 地域セールス担当、 Paul Burland 氏</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">ネットアップ、ビジネス開発マネージャー、 Hoseb Dermanilian 氏</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">ネットアップ、 MPSG ディレクター、 Lee Dorrior 氏</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">ネットアップ、 ANZ ビクトリア地区 SE 、システムエンジニア David Thiessen 氏</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">2018 年 1 月</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">ユースケース 5 ：分析ワークロードの高速化を更新</block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">このシナリオでは、大規模なオンプレミスの Hadoop リポジトリがあり、ディザスタリカバリのためにバックアップを作成したいと考えています。しかし、お客様の現在のバックアップ解決策はコストが高く、 24 時間以上のバックアップウィンドウに悩まされています。</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">使用事例 1 ： Hadoop データのバックアップ</block>
  <block id="8efec9e11b7742f59dbe1af079e1c1d0" category="inline-link-macro">以前： Hadoop のデータ保護のユースケースの概要。</block>
  <block id="259b434ecfae95df231c879645a98918" category="paragraph"><block ref="259b434ecfae95df231c879645a98918" category="inline-link-macro-rx"></block></block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">ソフトウェアの下位互換性：</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">提案する代替バックアップ解決策は、本番用 Hadoop クラスタで現在実行しているソフトウェアバージョンと互換性があることが必要です。</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">コミットされた SLA を満たすためには、代替の解決策で非常に低い RPO と RTO を達成することを推奨します。</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">ネットアップのバックアップ解決策で作成したバックアップは、データセンターのローカルに構築された Hadoop クラスタ、およびリモートサイトのディザスタリカバリロケーションで実行されている Hadoop クラスタで使用できます。</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">提案する解決策は対費用効果が高いものでなければなりません。</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">提案する解決策は、バックアップ処理中に実行中の本番環境の分析ジョブに与えるパフォーマンスへの影響を軽減する必要があります。</block>
  <block id="e3d4f6860e578b28733c41c2c852f821" category="section-title">お客様の既存のバックアップ解決策</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">次の図は、元の Hadoop ネイティブのバックアップ解決策を示しています。</block>
  <block id="2975218bd3c71a4ac4eac95d3529a9cb" category="paragraph"><block ref="2975218bd3c71a4ac4eac95d3529a9cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">本番環境のデータは、中間バックアップクラスタを通じてテープに保護されます。</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">hadoop distcp-update &lt;hdfs1 &gt;&lt;hdfs2&gt;` コマンドを実行することにより、 HDFS1 データが HDFS2 にコピーされます。</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">バックアップ・クラスタは NFS ゲートウェイとして機能し ' テープ・ライブラリを介して Linux'cp' コマンドを使用してデータを手動でテープにコピーします</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">元の Hadoop ネイティブバックアップ解決策には次のようなメリットがあります。</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">解決策は Hadoop ネイティブのコマンドをベースにしているため、新しい手順を習得する必要がなくなります。</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">解決策は、業界標準のアーキテクチャとハードウェアを活用しています。</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">元の Hadoop ネイティブバックアップ解決策には、次のような欠点があります。</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">バックアップ時間が長いと 24 時間を超えるため、本番環境のデータが脆弱になります。</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">バックアップ時間中にクラスタのパフォーマンスが大幅に低下します。</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">テープへのコピーは手動で行います。</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">バックアップ解決策は、必要なハードウェアと、手動プロセスに必要な人的時間の点でコストが高くなります。</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">バックアップソリューション</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">これらの課題と要件に基づいて、既存のバックアップシステムを検討し、 3 つのバックアップソリューションを提案しました。以降のサブセクションでは、解決策 A ～ 解決策 C というラベルの付いた 3 種類のバックアップソリューションについて説明します</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">解決策 A の略</block>
  <block id="8ee7b0fbb95cf5b1c98578a7ef03b9eb" category="paragraph">解決策 A は、バックアップ Hadoop クラスタにインプレース分析モジュールを追加し、次の図に示すように、ネットアップ NFS ストレージシステムへのセカンダリバックアップを可能にします。これにより、テープの要件がなくなります。</block>
  <block id="411ee6c684ee720eff303771433e41d6" category="paragraph"><block ref="411ee6c684ee720eff303771433e41d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">解決策 A の詳細なタスクは次のとおりです。</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">本番環境の Hadoop クラスタには、保護が必要な HDFS 内のお客様の分析データがあります。</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">HDFS を使用するバックアップ Hadoop クラスタは、データの中間的な場所として機能します。Just a Bunch of Disks （ JBOD ）は、本番環境の Hadoop クラスタとバックアップの Hadoop クラスタの両方で HDFS にストレージを提供する。</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">「 hadoop distcp – update – diff&lt;hdfs1 &gt;&lt;hdfs2&gt;` コマンド」を実行することで、 Hadoop 本番クラスタの HDFS からバックアップクラスタの HDFS へと Hadoop 本番データを保護します。</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Hadoop スナップショットは、本番環境からバックアップ Hadoop クラスタへデータを保護するために使用されます。</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">NetApp ONTAP ストレージコントローラは、バックアップ Hadoop クラスタにプロビジョニングされる NFS エクスポートボリュームを提供します。</block>
  <block id="b0e42779d51b21a745cae08f938ec60a" category="list-text">MapReduce と複数のマッパを利用して「 hadoop distcp 」コマンドを実行することで、分析データはインプレース分析モジュールを使用してバックアップ Hadoop クラスタから NFS に保護されます。</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">ネットアップストレージシステム上の NFS にデータを格納したあと、必要に応じて、ネットアップの Snapshot 、 SnapRestore 、および FlexClone テクノロジを使用して Hadoop データをバックアップ、リストア、および複製します。</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">Hadoop データは、 SnapMirror テクノロジを使用してクラウドやディザスタリカバリロケーションに保護できます。</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">解決策 A には、次のような利点があります。</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Hadoop の本番データはバックアップクラスタから保護されます。</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">HDFS データは NFS を通じて保護されるため、クラウドやディザスタリカバリの場所を保護できます。</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">バックアップ処理をバックアップクラスタにオフロードすることでパフォーマンスを向上します。</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">手動でのテープ操作が不要になります</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">ネットアップのツールを使用してエンタープライズ管理機能を利用できます。</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">既存の環境への変更は最小限で済みます。</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">対費用効果の高い解決策です。</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">この解決策の欠点は、パフォーマンスを向上させるためにバックアップクラスタと追加のマッパが必要であることです。</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">お客様は最近、解決策 A を導入しました。シンプルさ、コスト、全体的なパフォーマンスが理由です。</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">この解決策では、 JBOD の代わりに ONTAP の SAN ディスクを使用できます。このオプションを選択すると、バックアップクラスタのストレージ負荷が ONTAP にオフロードされますが、問題となるのは SAN ファブリックスイッチが必要な場合です。</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">解決策 B</block>
  <block id="304af2b0b47890c7db8f6097978fdede" category="paragraph">解決策 B は本番用 Hadoop クラスタにインプレース分析モジュールを追加するため、次の図に示すように、バックアップ Hadoop クラスタは不要です。</block>
  <block id="303388aba87d7dcff207a6cd098b0cfe" category="paragraph"><block ref="303388aba87d7dcff207a6cd098b0cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">解決策 B の詳細なタスクは次のとおりです。</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">NetApp ONTAP ストレージコントローラは、本番用 Hadoop クラスタに対して NFS エクスポートをプロビジョニングします。</block>
  <block id="3c321f811c173c1f133bdcc77fc81a33" category="paragraph">hadoop native 「 hadoop distcp 」コマンドは、実稼働クラスタ HDFS からインプレース分析モジュールを介して NFS へ Hadoop データを保護します。</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">ネットアップストレージシステム上の NFS にデータを格納したあと、 Snapshot 、 SnapRestore 、および FlexClone テクノロジを使用して、必要に応じて Hadoop データをバックアップ、リストア、および複製します。</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">解決策 B には次のような利点があります。</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">本番環境クラスタは、バックアップ解決策用に若干変更されるため、実装が簡単になり、インフラコストを削減できます。</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">バックアップ処理のためのバックアップクラスタは必要ありません。</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">HDFS の本番環境のデータは、 NFS データへの変換によって保護されます。</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">解決策では、ネットアップのツールを使用してエンタープライズ管理機能を実行できます。</block>
  <block id="02946730aaff0e3d8abfa986a2fe949d" category="paragraph">この解決策の欠点は、本番クラスタに実装されており、本番クラスタに管理者タスクを追加できることです。</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">解決策 C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">解決策 C では、次の図に示すように、 NetApp SAN ボリュームが HDFS ストレージの Hadoop 本番クラスタに直接プロビジョニングされます。</block>
  <block id="dc460b3501caf17186202576855a6d3c" category="paragraph"><block ref="dc460b3501caf17186202576855a6d3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">解決策 C の詳細な手順は次のとおりです。</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">NetApp ONTAP SAN ストレージは、 HDFS データストレージの本番用 Hadoop クラスタでプロビジョニングされます。</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">NetApp Snapshot テクノロジと SnapMirror テクノロジを使用して、本番用 Hadoop クラスタの HDFS データをバックアップします。</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">バックアップはストレージレイヤにあるため、 Snapshot コピーのバックアッププロセス中は Hadoop / Spark クラスタの本番環境でパフォーマンスが低下することはありません。</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">Snapshot テクノロジを使用すると、データのサイズに関係なく数秒で完了するバックアップを作成できます。</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">解決策 C には次のような利点があります。</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">スペース効率に優れたバックアップは、 Snapshot テクノロジを使用して作成できます。</block>
  <block id="5788267ffe4023e91b333de591766cca" category="inline-link-macro">次のユースケース 2 ：クラウドからオンプレミスへのバックアップとディザスタリカバリ</block>
  <block id="1619284091911820ebd1407554fb6da7" category="paragraph"><block ref="1619284091911820ebd1407554fb6da7" category="inline-link-macro-rx"></block></block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">このユースケースは、クラウドベースの分析データをオンプレミスのデータセンターにバックアップする必要がある放送局の顧客に基づいています。</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">ユースケース 2 ：クラウドからオンプレミスへのバックアップとディザスタリカバリ</block>
  <block id="d05b5b5452aa966fcd3c8947a172f44a" category="inline-link-macro">前：ユースケース 1 - Hadoop データのバックアップ</block>
  <block id="d6b3b64a2054103914910c4432cc9e18" category="paragraph"><block ref="d6b3b64a2054103914910c4432cc9e18" category="inline-link-macro-rx"></block></block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">このユースケースは、放送局のお客様がクラウドベースの分析データをオンプレミスのデータセンターにバックアップする必要がある場合を基準にしています。以下の図を参照してください。</block>
  <block id="063e138ba69a95a99bd2f908b540e210" category="paragraph"><block ref="063e138ba69a95a99bd2f908b540e210" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">このシナリオでは、 IoT センサーのデータがクラウドに取り込まれ、 AWS 内のオープンソースの Apache Spark クラスタを使用して分析されます。処理されたデータをクラウドからオンプレミスにバックアップすることが要件です。</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">データ保護を有効原因にしても、本番環境の Spark / Hadoop クラスタのパフォーマンスへの影響は一切ありません。</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">効率的かつ安全な方法で、クラウドセンサーデータをオンプレミスに移動して保護する必要があります。</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">オンデマンド、瞬時、クラスタの低負荷時など、さまざまな条件下でクラウドからオンプレミスにデータを柔軟に転送できます。</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">お客様は、 Spark クラスタの HDFS ストレージとして AWS Elastic Block Store （ EBS ）を使用して、 Kafka 経由でリモートセンサーからデータを受け取り、取り込むことになりました。そのため、 HDFS ストレージはバックアップデータのソースとして機能します。</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">これらの要件を満たすために、 NetApp ONTAP Cloud が AWS に導入され、 Spark / Hadoop クラスタのバックアップターゲットとして機能する NFS 共有が作成されます。</block>
  <block id="c260f0b6bfdb6eff1473aafbf5bd075a" category="paragraph">NFS 共有が作成されると、インプレース分析モジュールを使用して、 HDFS EBS ストレージから ONTAP NFS 共有にデータがコピーされます。データが ONTAP クラウド上の NFS に配置されると、 SnapMirror テクノロジを使用して、必要に応じてクラウドからオンプレミスのストレージにデータを安全かつ効率的にミラーリングできます。</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">この図は、クラウドからオンプレミスの解決策へのバックアップとディザスタリカバリを示しています。</block>
  <block id="94c7a6b63152038de5e8b2763cdef06c" category="paragraph"><block ref="94c7a6b63152038de5e8b2763cdef06c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bbd6a10b63926b84e9a28da6d4214925" category="inline-link-macro">次：ユースケース 3 - 既存の Hadoop データに対して DevTest を有効化</block>
  <block id="e0f915fb1893e398d54abc6f9d00ca57" category="paragraph"><block ref="e0f915fb1893e398d54abc6f9d00ca57" category="inline-link-macro-rx"></block></block>
  <block id="69efde21ccf40f1dda4d665f81bacefe" category="summary">このシナリオでは、 NetApp NFS ストレージ解決策を使用して大規模な金融サービスおよび投資銀行の分析プラットフォームを最新化し、資産管理および定量的ビジネスユニットの投資リスクおよび派生物の分析を大幅に改善しました。</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">ユースケース 5 ：分析ワークロードを高速化</block>
  <block id="c8ea1eda8e0ac121148ac86dee9649a7" category="inline-link-macro">前のステップ：ユースケース 4 - データ保護とマルチクラウド接続</block>
  <block id="87fb2a1eb3f12014af6e5dd36ba66e5e" category="paragraph"><block ref="87fb2a1eb3f12014af6e5dd36ba66e5e" category="inline-link-macro-rx"></block></block>
  <block id="24b0e878b8196875cd088397ac8312a9" category="paragraph">お客様の既存の環境では、分析プラットフォームに使用される Hadoop インフラストラクチャは、 Hadoop サーバの内部ストレージを活用しています。JBOD 環境の専有特性により、組織内の多くの社内顧客は、リアルタイムデータの繰り返しサンプルに依存するシミュレーションであるモンテカルロ定量モデルを利用できませんでした。市場動向の不確実性の影響を理解するのに最適な能力は、量的資産管理事業部門にとって好ましくないものとなっていました。</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">銀行の定量事業部門は、正確でタイムリーな予測を実現するための効率的な予測方法を求めていました。そのためには、インフラを刷新し、既存の I/O 待機時間を短縮し、 Hadoop や Spark などの分析アプリケーションのパフォーマンスを向上させて、投資モデルを効率的にシミュレートし、潜在的な利益を測定し、リスクを分析する必要性を認識しました。</block>
  <block id="5ff37557b096819452a25d129a312360" category="paragraph">お客様は、既存の Spark 解決策の JBOD を使用していました。その後、 NetApp ONTAP 、 NetApp StorageGRID 、 MinIO Gateway to NFS を活用して、銀行の定量的財務グループの I/O 待機時間を短縮し、潜在的な利益とリスクを評価する投資モデルのシミュレーションと分析を実行しました。この図は、 Spark の解決策とネットアップストレージを示しています。</block>
  <block id="095ba715431845442ef6bf2f4283ad1c" category="paragraph"><block ref="095ba715431845442ef6bf2f4283ad1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">上の図に示すように、 Spark 搭載の 6 ノード Hadoop クラスタで NFS プロトコルと S3 プロトコルを使用して寄木細工のファイルにアクセスするために AFF A800 、 A700 システム、 StorageGRID を導入し、データ分析処理用に糸と Hive のメタデータサービスを用意しました。</block>
  <block id="bc12facb8aa0a34db56b00fdbc21c351" category="paragraph">お客様の古い環境にある DAS （直接接続型ストレージ）解決策には、コンピューティングとストレージを個別に拡張するという欠点がありました。NetApp ONTAP 解決策 for Spark を使用することで、銀行の財務分析事業部門はストレージをコンピューティングから切り離し、必要に応じてインフラリソースをより効率的に提供することができました。</block>
  <block id="582c4aa65d1bd005ddc785db8b807fca" category="paragraph">NFS で ONTAP を使用することで、 Spark の SQL ジョブにはコンピュートサーバの CPU がほぼフルに活用され、 I/O 待機時間が 70% 近く削減されました。その結果、 Spark のワークロードの処理能力とパフォーマンスが向上しました。また、 CPU 利用率の向上により、お客様は GPUDirect などの GPU を活用してプラットフォームをさらに最新化できるようになりました。さらに、 StorageGRID は Spark のワークロードに低コストのストレージオプションを提供し、 MinIO Gateway は S3 プロトコル経由で NFS データへの安全なアクセスを提供します。クラウド内のデータには、 Cloud Volumes ONTAP 、 Azure NetApp Files 、 NetApp Cloud Volumes Service を推奨します。</block>
  <block id="6e362ed6e741056d737b93021ab2f3f9" category="paragraph"><block ref="6e362ed6e741056d737b93021ab2f3f9" category="inline-link-macro-rx"></block></block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop ディストリビュータは、大規模なクラスタ間コピーとクラスタ内コピーに使用されるネイティブツールです。Hadoop DistCp の基本的なプロセスは、 MapReduce などの Hadoop ネイティブツールを使用して Hadoop のデータを HDFS ソースから対応するターゲットにコピーする、一般的なバックアップワークフローです。</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Hadoop データ保護機能とネットアップ</block>
  <block id="9445444fbd9e863564ea85ad226c0e80" category="inline-link-macro">従来のソリューション：ネットアップのビッグデータアーキテクチャを基盤とするデータファブリック。</block>
  <block id="e30c587da81860e05b3f8ecfb5b9965b" category="paragraph"><block ref="e30c587da81860e05b3f8ecfb5b9965b" category="inline-link-macro-rx"></block></block>
  <block id="5f45c95989226891db648114a547a6bd" category="paragraph">Hadoop ディストリビュータは、大規模なクラスタ間コピーとクラスタ内コピーに使用されるネイティブツールです。次の図に示す Hadoop ディストリビュータの基本的なプロセスは、 MapReduce などの Hadoop ネイティブツールを使用した一般的なバックアップワークフローで、 HDFS ソースから対応するターゲットに Hadoop データをコピーします。NetApp NFS の直接アクセスを使用すると、 Hadoop DistCp ツールのターゲットデスティネーションとして NFS を設定し、 HDFS ソースから MapReduce 経由で NFS 共有にデータをコピーできます。NetApp NFS への直接アクセスは、 DistCp ツールの NFS ドライバとして機能します。</block>
  <block id="6369c8cb38b142174d2f84d12d2f0420" category="paragraph"><block ref="6369c8cb38b142174d2f84d12d2f0420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4849340a20db94ed712aca71c30b915" category="inline-link-macro">次： Hadoop のデータ保護のユースケースの概要。</block>
  <block id="817c6593a9a8efc031ec597b5d11d605" category="paragraph"><block ref="817c6593a9a8efc031ec597b5d11d605" category="inline-link-macro-rx"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">このユースケースは、お客様のビッグデータ分析データにマルチクラウド接続を提供するという課題を抱えるクラウドサービスパートナーに適しています。</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">ユースケース 4 ：データ保護とマルチクラウド接続</block>
  <block id="2c8eccdfa6390b1d09b2527f7d7d2cc5" category="inline-link-macro">前：ユースケース 3 - 既存の Hadoop データに対する DevTest の有効化</block>
  <block id="fda5cc5b496f5f7aa6de18740227bc15" category="paragraph"><block ref="fda5cc5b496f5f7aa6de18740227bc15" category="inline-link-macro-rx"></block></block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">このシナリオでは、さまざまなソースから AWS で受信した IoT データが NPS の中央の場所に保存されます。NPS ストレージは、 AWS と Azure 上にある Spark / Hadoop クラスタに接続されています。これにより、同じデータにアクセスする複数のクラウドで実行されるビッグデータ分析アプリケーションを実現できます。</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">お客様は、複数のクラウドを使用して、同じデータに対して分析ジョブを実行したいと考えています。</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">オンプレミスやクラウドなどのさまざまなソースから、さまざまなセンサーやハブを介してデータを受信する必要があります。</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">解決策は、効率性とコスト効率に優れている必要があります。</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">主な課題は、オンプレミスと異なるクラウドの間でハイブリッド分析サービスを提供する、対費用効果の高い効率的な解決策を構築することです。</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">この図は、データ保護とマルチクラウド接続解決策を示しています。</block>
  <block id="faaf8e6278dc7a68fd1dd98dfe7f525a" category="paragraph"><block ref="faaf8e6278dc7a68fd1dd98dfe7f525a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14c23633f1ab374f4c801386847ba2f8" category="paragraph">上の図に示すように、センサーからのデータはストリーミングされ、 Kafka を介して AWS Spark クラスタに取り込まれます。データは NPS 内の NFS 共有に格納されます。 NPS は、 Equinix データセンター内のクラウドプロバイダの外部にあります。NetApp NPS は、 Direct Connect 接続と Express Route 接続を通じて Amazon AWS と Microsoft Azure に接続されているため、お客様はインプレース分析モジュールを利用して、 Amazon と AWS 両方の分析クラスタからデータにアクセスできます。このアプローチは、複数のハイパースケーラにわたるクラウド分析の実現を解決します。</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">そのため、オンプレミスと NPS ストレージはどちらも ONTAP ソフトウェアを実行するため、 SnapMirror を使用して NPS データをオンプレミスクラスタにミラーリングし、オンプレミスと複数のクラウドにわたるハイブリッドクラウド分析を実現できます。</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">パフォーマンスを最大限に高めるために、通常は複数のネットワークインターフェイスと直接接続 / エクスプレスルートを使用してクラウドインスタンスからデータにアクセスすることを推奨します。</block>
  <block id="1ef541fe0fa79d247c0f1751629bb504" category="inline-link-macro">次：ユースケース 5 - 分析ワークロードの高速化</block>
  <block id="7dfabd0b120fe0403ff107668db4094a" category="paragraph"><block ref="7dfabd0b120fe0403ff107668db4094a" category="inline-link-macro-rx"></block></block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">このセクションでは、データ保護のユースケースの概要を概要で説明します。これが、本ドキュメントで重要となるのです。以降のセクションでは、それぞれのユースケースについて、お客様の問題（シナリオ）、要件と課題、ソリューションなどの詳細を説明します。</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Hadoop のデータ保護のユースケースの概要</block>
  <block id="d161097dc6596d3807b21a5635856d71" category="inline-link-macro">以前のバージョン： Hadoop データ保護機能とネットアップ。</block>
  <block id="1a5df0b83f496dc00b4a331caac0d5cd" category="paragraph"><block ref="1a5df0b83f496dc00b4a331caac0d5cd" category="inline-link-macro-rx"></block></block>
  <block id="385dae214dc9bab52698dc7cd42632ad" category="paragraph">このユースケースでは、大規模な金融機関がインプレース分析モジュールを使用して、バックアップ時間を 24 時間以上から数時間未満に短縮しました。</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">大規模な放送会社では、ネットアップのデータファブリックをビルディングブロックとして使用することで、オンデマンド、瞬時、データ転送などのさまざまなデータ転送モードに応じて、クラウドデータをオンプレミスのデータセンターにバックアップするという要件を満たすことができました。 または、 Hadoop / Spark のクラスタの負荷に基づいて計算されました。</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">ネットアップのソリューションは、オンラインの音楽配信企業が、スペース効率に優れた複数の Hadoop クラスタをさまざまなブランチオフィスに迅速に構築し、レポートを作成したり、定期的なポリシーを使用して日々の DevTest タスクを実行したりできるよう支援しました</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">ある大手サービスプロバイダは、ネットアップのデータファブリックを使用して、さまざまなクラウドインスタンスからお客様にマルチクラウド分析を提供していました。</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">最大規模の金融サービスおよび投資銀行の 1 つは、ネットアップのネットワーク接続型ストレージ解決策を使用して、 I/O 待ち時間を短縮し、定量的な金融分析プラットフォームを高速化しました。</block>
  <block id="2afe208a471bf6c54f0ccc97f4c6508d" category="inline-link-macro">次のユースケース 1 - Hadoop データのバックアップ</block>
  <block id="aac250a096aacf9aed26ebbd137818da" category="paragraph"><block ref="aac250a096aacf9aed26ebbd137818da" category="inline-link-macro-rx"></block></block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">ネットアップのデータファブリックは、クラウド環境とオンプレミス環境全体でデータ管理を簡易化、統合することで、デジタル変革を加速します。ネットアップのデータファブリックは、一貫した統合的データ管理サービスとアプリケーション（ビルディングブロック）を提供し、データの可視化と分析、データのアクセスと制御、データの保護とセキュリティを実現します。</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">ネットアップのデータファブリックを基盤としたビッグデータアーキテクチャ</block>
  <block id="32e0d2b797e6706a73e8146d103572c7" category="inline-link-macro">Previous ：解決策の概要を示します。</block>
  <block id="45af7a946606481f9e2b5f0434aa0484" category="paragraph"><block ref="45af7a946606481f9e2b5f0434aa0484" category="inline-link-macro-rx"></block></block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">ネットアップのデータファブリックは、クラウド環境とオンプレミス環境全体でデータ管理を簡易化、統合することで、デジタル変革を加速します。</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">ネットアップのデータファブリックは、一貫した統合的データ管理サービスとアプリケーション（ビルディングブロック）を提供し、データの可視性と分析、データのアクセスと制御、データの保護とセキュリティを実現します。以下の図を参照してください。</block>
  <block id="22313f8779f9135c9b421ac0d4b320fb" category="paragraph"><block ref="22313f8779f9135c9b421ac0d4b320fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">実績のあるデータファブリックのユースケース</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">ネットアップのデータファブリックは、以下の 9 つのユースケースをお客様に提供します。</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">分析ワークロードを高速化</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">DevOps 変革を加速</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">クラウドとホスティングのインフラ構築</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">クラウドデータサービスを統合</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">データの保護とセキュリティ</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">非構造化データを最適化</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">データセンターの効率化</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">データの分析と管理を実現</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">簡易化と自動化</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">このドキュメントでは、 9 つのユースケースのうち 2 つを取り上げ、それぞれのソリューションを紹介します。</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">NetApp NFS への直接アクセス</block>
  <block id="233060aa11b5715000c000e94576cca9" category="paragraph">NetApp NFS から直接アクセス（旧 NetApp In-Place Analytics Module ）を使用すると、データを移動したりコピーしたりすることなく、既存または新規の NFSv3 / NFSv4 データに対してビッグデータ分析ジョブを実行できます。データの複数のコピーが作成されるため、ソースとデータを同期する必要がありません。たとえば、金融機関では、ある場所から別の場所へデータを移動する際に法的義務を果たす必要がありますが、これは容易な作業ではありません。このシナリオでは、 NetApp NFS の直接アクセスによって、元の場所から財務データが分析されます。もう 1 つの主な利点は、 NetApp NFS 直接アクセスを使用すると、ネイティブの Hadoop コマンドを使用して Hadoop データを保護しやすくなることと、ネットアップの充実したデータ管理ポートフォリオを活用してデータ保護ワークフローを実現できることです。</block>
  <block id="96e1e6bac181280c42ba5de56a8ef4c2" category="paragraph"><block ref="96e1e6bac181280c42ba5de56a8ef4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">NetApp NFS 直接アクセスでは、 Hadoop クラスタと Spark クラスタに対して次の 2 種類の導入オプションを提供しています。</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">デフォルトでは、 Hadoop / Spark クラスタは、データストレージとデフォルトのファイルシステムに Hadoop Distributed File System （ HDFS ； Hadoop 分散ファイルシステム）を使用しています。NetApp NFS の直接アクセスを使用すると、デフォルトの HDFS をデフォルトのファイルシステムとして NFS ストレージに置き換えることができるため、 NFS データに対する直接分析処理が可能になります。</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">もう 1 つの導入オプションでは、 NetApp NFS 直接アクセスを使用して、 1 つの Hadoop / Spark クラスタ内に HDFS を追加のストレージとして構成することもできます。この場合、 NFS エクスポートを介してデータを共有し、 HDFS データと同じクラスタからデータにアクセスできます。</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">NetApp NFS 直接アクセスを使用する主な利点は次のとおりです。</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">現在の場所からデータを分析するため、分析データを HDFS などの Hadoop インフラに移動する時間とパフォーマンスのかかるタスクは発生しません。</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">レプリカの数を 3 つから 1 つに減らします。</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">ユーザはコンピューティングとストレージを切り離して個別に拡張できます。</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">ONTAP の豊富なデータ管理機能を活用して、エンタープライズデータを保護します。</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">Hortonworks データプラットフォームで認定されています。</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">ハイブリッドデータ分析環境を実現</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">動的なマルチスレッド機能を活用して、バックアップ時間を短縮します。</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">ビッグデータ向けのビルディングブロック</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">ネットアップのデータファブリックは、以下の図に示すように、データアクセス、制御、保護、セキュリティのためのデータ管理サービスとアプリケーション（ビルディングブロック）を統合しています。</block>
  <block id="f0a67f0f8f389fb239ce107f693a7e68" category="paragraph"><block ref="f0a67f0f8f389fb239ce107f693a7e68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">上の図の構成要素は次のとおりです。</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* NetApp NFS 直接アクセス。 * 最新の Hadoop クラスタと Spark クラスタを、ソフトウェアやドライバの追加の必要なしに NetApp NFS ボリュームに直接アクセスできます。</block>
  <block id="2867a490011894512662b9423698d0e0" category="list-text">* ネットアップの Cloud Volumes ONTAP とクラウドボリュームサービス。 * ソフトウェア定義型の接続ストレージ。 Amazon Web Services （ AWS ）で実行されている ONTAP または Microsoft Azure クラウドサービスで実行されている Azure NetApp Files （ ANF ）に基づいています。</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">* NetApp SnapMirror テクノロジ * 。オンプレミスと ONTAP クラウドインスタンスまたは NPS インスタンス間でデータ保護機能を提供します。</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">* クラウド・サービス・プロバイダー。 * これらのプロバイダーには、 AWS 、 Microsoft Azure 、 Google Cloud 、 IBM Cloud が含まれます。</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">* PaaS * AWS の Amazon Elastic MapReduce （ EMR ）や Databricks 、 Microsoft Azure HDInsight 、 Azure Databricks などのクラウドベースの分析サービスを利用できます。</block>
  <block id="35848dde21e4a5f344385ead6dec9a43" category="inline-link-macro">次のステップ： Hadoop データ保護とネットアップ。</block>
  <block id="149584f581a09d835c88f233c514412e" category="paragraph"><block ref="149584f581a09d835c88f233c514412e" category="inline-link-macro-rx"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">本ドキュメントでは、 NetApp AFF および FAS ストレージシステム、 NetApp Cloud Volumes ONTAP 、ネットアップ接続ストレージ、 Spark および Hadoop 向けの NetApp FlexClone テクノロジを使用したハイブリッドクラウドデータソリューションについて説明します。これらの解決策アーキテクチャを使用することで、お客様の環境に適したデータ保護解決策を選択できます。ネットアップは、お客様とのやり取りと、お客様のビジネスユースケースに基づいてこれらのソリューションを設計しました。</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="doc">TR-4657 ：ネットアップのハイブリッドクラウドデータソリューション - Spark と Hadoop はお客様のユースケースに基づいています</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">ネットアップ、 Karthikeyan Nagalingam と Sathish Thyagarajan</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">本ドキュメントでは、 NetApp AFF および FAS ストレージシステム、 NetApp Cloud Volumes ONTAP 、ネットアップ接続ストレージ、 Spark および Hadoop 向けの NetApp FlexClone テクノロジを使用したハイブリッドクラウドデータソリューションについて説明します。これらの解決策アーキテクチャを使用することで、お客様の環境に適したデータ保護解決策を選択できます。ネットアップは、お客様とのやり取りと、お客様のビジネスユースケースに基づいてこれらのソリューションを設計しました。このドキュメントでは、次の詳細情報を提供します。</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Spark 環境や Hadoop 環境、お客様の課題に対応するデータ保護が必要な理由</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">ネットアップのビジョンと、そのビルディングブロックとサービスを基盤とするデータファブリック。</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">これらのビルディングブロックを使用して、柔軟なデータ保護ワークフローを構築する方法</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">実際のお客様のユースケースに基づく、複数のアーキテクチャの長所と短所各ユースケースには、次のコンポーネントがあります。</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">解決策</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">ソリューションの概要</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Hadoop のデータ保護を選ぶ理由</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">Hadoop 環境と Spark 環境では、次の点に注意する必要があります。</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">* ソフトウェアや人為的なエラー。 * Hadoop データの処理中にソフトウェアを更新したときに人的エラーが発生すると、業務によって原因が予期せぬ結果を招く可能性がある動作不良になることがあります。このような場合は、障害や妥当でない結果が生じないように、データを保護する必要があります。たとえば、ソフトウェアアップデートの実行が不十分でトラフィック信号分析アプリケーションが実行されたため、トラフィック信号データをプレーンテキスト形式で適切に分析できない新機能があります。ソフトウェアは JSON やその他の非テキストファイル形式を分析して、リアルタイムトラフィック制御分析システムを生成し、データポイントが不足している予測結果を生成します。このような状況では、原因が出力不良の可能性があり、交通信号で事故につながるおそれがあります。データ保護機能を使用すると、以前の作業中のアプリケーションバージョンにすばやくロールバックできるため、この問題に対応できます。</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">* サイズと拡張性。 * 分析データのサイズは日々増え続けています。その理由は、データソースとボリュームの数が増え続けることにあります。現在のビッグデータ市場では、ソーシャルメディア、モバイルアプリ、データ分析、クラウドコンピューティングの各プラットフォームがデータの主要なソースとなっており、データは急速に増加しています。そのため、データを保護して、正確なデータ運用を確保する必要があります。</block>
  <block id="80908b4b31d37977701d3694fbc636ac" category="list-text">* Hadoop のネイティブデータ保護。 * Hadoop には、データを保護するためのネイティブコマンドがありますが、このコマンドはバックアップ中のデータの整合性を提供しません。ディレクトリレベルのバックアップのみをサポートします。Hadoop によって作成された Snapshot は読み取り専用であり、バックアップデータを直接再利用することはできません。</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Hadoop や Spark のお客様にとって、データ保護の課題が発生しています</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Hadoop と Spark のお客様にとってよくある課題は、データ保護の際に本番クラスタのパフォーマンスに悪影響を与えることなく、バックアップ時間を短縮し、バックアップの信頼性を向上させることです。</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">また、 RPO （目標復旧時点）と RTO （目標復旧時間）のダウンタイムを最小限に抑え、オンプレミスとクラウドベースのディザスタリカバリサイトを制御して、ビジネス継続性を最適化する必要もあります。この制御は、通常、エンタープライズレベルの管理ツールを使用して行われます。</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">データ量が膨大で増え続けているだけでなく、データの到着率も増加しているため、 Hadoop 環境と Spark 環境は複雑化しています。このようなシナリオでは、ソースデータから効率的で最新の DevTest 環境と QA 環境を迅速に構築することは困難です。ネットアップはこれらの課題を認識し、本ホワイトペーパーで紹介しているソリューションを提供しています。</block>
  <block id="1f60e9ce60971dc2129b30c8820ff343" category="inline-link-macro">次のステップ：ネットアップのビッグデータアーキテクチャを基盤とするデータファブリック。</block>
  <block id="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="paragraph"><block ref="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="inline-link-macro-rx"></block></block>
  <block id="ea490901c403ce2b2a89f80227d0fb90" category="paragraph">バイナリおよびデータベースのレプリケーションマニュアルのスケジュール</block>
  <block id="2c777d857235f251004d6d8d70c9751d" category="list-text">以前に作成したジョブテンプレートをコピーします。</block>
  <block id="1eb977b1f69b531db931e9c62c1a0de9" category="list-text">「 ONTAP/CVO Setup Template 」を探して、右端で「 Copy Template 」をクリックします</block>
  <block id="3c96e57d33780bedfb652def025f39de" category="list-text">コピーしたテンプレートで [ テンプレートの編集 ] をクリックし、名前を [ バイナリおよびデータベースのレプリケーションのマニュアル ] に変更します。</block>
  <block id="b07fb736e8c17cea7e9e3753e7a67fd1" category="list-text">テンプレートの同じインベントリ、プロジェクト、資格情報を保持します。</block>
  <block id="f42c6e71dcb07b403b8393d5ab7f7fe4" category="list-text">実行するプレイブックとして ora_replication_cg.yml を選択します。</block>
  <block id="69fa06239fd734936aac1af5250c7f57" category="list-text">変数は変更されませんが、 CVO クラスタの IP は変数 dst_cluster_ip に設定する必要があります。</block>
  <block id="ec7445bbcbadd1f11fe1bc3e5e56eef9" category="list-text">ジョブテンプレートをスケジュールします。</block>
  <block id="ce0d20e65f0354847807516cbcc696f6" category="list-text">バイナリおよびデータベースのレプリケーション用プレイブックテンプレートをクリックし、一番上のオプションセットにあるスケジュールをクリックします。</block>
  <block id="d9a6405dc4a6cd71f6d77c749070a5e6" category="list-text">[ 追加 ] をクリックし、 [ バイナリおよびデータベースレプリケーションの名前スケジュールの追加 ] をクリックし、時間の開始時に [ 開始日時 ] を選択し、 [ ローカルタイムゾーン ] を選択して、 [ 実行頻度 ] をクリックします。実行頻度は、多くの場合、 SnapMirror レプリケーションが更新されます。</block>
  <block id="2dc4dec75c83aeb010419dc2a02da40b" category="admonition">ログボリュームのレプリケーション用に別のスケジュールが作成されるため、より頻繁にレプリケートできます。</block>
  <block id="cc335cb73dc47f7a9b404288e3b4330f" category="paragraph">ONTAP と CVO のセットアップ</block>
  <block id="6bc14a28f101e9d80ecc643ef13ef7fb" category="list-text">「 ONTAP/CVO Setup 」という名前を入力します</block>
  <block id="a7244f663b97629084f004e6c89b4a75" category="list-text">ジョブタイプを選択します。 Run は、プレイブックに基づいてシステムを設定します。</block>
  <block id="57344b3bd58c0e451513e303e45d49b7" category="list-text">オンプレミス環境用の ONTAP_setup.yml プレイブックを選択するか、 CVO-setup.yml を選択して CVO インスタンスにレプリケーションします。</block>
  <block id="41c1d72990c270d0221458749497c3e6" category="admonition">このテンプレートを使用して、他のプレイブック用にコピーします。</block>
  <block id="63c0320f73b5f4e528bbe1488acc5103" category="section-title">Oracle データベースのデータ保護を自動化</block>
  <block id="d798c6a829fee4b3d8316144e8769e91" category="paragraph">組織は環境を自動化して、効率を高め、導入を高速化し、手動作業を削減しています。Ansible などの構成管理ツールを使用して、エンタープライズデータベースの運用を合理化しています。この解決策では、 Ansible を使用して NetApp ONTAP による Oracle のデータ保護を自動化する方法を紹介します。ストレージ管理者、システム管理者、 DBA は、オフサイトのデータセンターやパブリッククラウドへのデータレプリケーションを一貫して迅速にセットアップできるため、次のようなメリットがあります。</block>
  <block id="1d4694b7ed077df8b2c51d4ef956ce0c" category="list-text">クラスタ間レプリケーション、 CVO のインスタンス化、 Oracle データベースのリカバリの構成にかかる時間を短縮できます</block>
  <block id="60bcf8682ddc3583a74e6cd2d95e1ccb" category="list-text">データベースリカバリワークフローを使用して、 DR シナリオを簡単にテストできます。</block>
  <block id="7fa4d3428dbef9829f6325b288c071bc" category="section-title">オンプレミスからオンプレミスへのレプリケーション</block>
  <block id="911a9e8dd85bfeeba31c1ed049e41e1c" category="list-text">ソースとデスティネーションにクラスタ間 LIF を作成</block>
  <block id="2f4eb56dd9301fc33f559b4345b90eb3" category="list-text">クラスタと SVM のピア関係を確立</block>
  <block id="2b71f4136dce37491ef0f319f5d1fbd9" category="list-text">Oracle ボリュームの SnapMirror を作成して初期化</block>
  <block id="20f4a46f5b12b0533f7a2268c4c2bf41" category="list-text">AWX/Tower を使用して、 Oracle バイナリ、データベース、ログ用のレプリケーションスケジュールを作成します</block>
  <block id="6ef1c2ae7c9ca61a54d88de28349a772" category="list-text">デスティネーションで Oracle DB のリストアを行い、データベースをオンラインにします</block>
  <block id="f4ec61d9ffa147f621f854609523a0fb" category="section-title">オンプレミスから AWS の CVO へ</block>
  <block id="3f155aa6a9345b3e25f3bb44ecccfc0a" category="list-text">AWS コネクタを作成します</block>
  <block id="1531cb3c2d4db27dcd3bfa2ad4711ec5" category="list-text">AWS で CVO インスタンスを作成</block>
  <block id="2f159b717f78e9925b219e87cbd20f9a" category="list-text">オンプレミスのクラスタを Cloud Manager に追加</block>
  <block id="df16a1e23dbbcc2f19f07ab1af741617" category="list-text">ソースにクラスタ間 LIF を作成</block>
  <block id="d1f660bb2bff2f31a46c751115155999" category="list-text">パート 1 ：未定</block>
  <block id="1ee2253d8fe666dbea54ab3648a62511" category="list-text">パート 2 ：未定</block>
  <block id="0679a51ae3a4071a6bd3dedbe97fd329" category="summary">このページでは、 NetApp ONTAP ストレージに Oracle データ保護を導入するための自動化方法について説明します。</block>
  <block id="22e3bbd761fbb7ae69b8035eb12f222d" category="paragraph">この解決策は、 AWX/Tower 環境で動作するように設計されています。</block>
  <block id="ad5310e9dcd8f367be2b92490488d86d" category="list-text">解決策は、プライベートクラウドのシナリオ（オンプレミスからオンプレミス）およびハイブリッドクラウド（オンプレミスからパブリッククラウドへの Cloud Volumes ONTAP [CVO] ）で実行するように設計されています。</block>
  <block id="936c99ed52ca08a052ebf611285dd998" category="inline-link-macro">CVO の導入と Connector の導入の前提条件を収集</block>
  <block id="ec329a9106131eb9bf99b0f9e67b0564" category="list-text">CVO Data Protection に必要なキーとトークンの取得方法の詳細については、を参照してください <block ref="e21f73de51752f791cddc773d1f38740" category="inline-link-macro-rx"></block></block>
  <block id="13716f12996b882bb4c7e0bd84c7c128" category="open-title">&lt;strong class="big"&gt; オンプレミス &lt;/strong&gt;&lt;strong&gt;|&lt;/strong&gt;</block>
  <block id="72bd33cc372377848ab3bb360deb365e" category="cell">ONTAP バージョン 9.8+</block>
  <block id="3ca63226b942aff3abcf62934a91e382" category="cell">ソース上の既存の Oracle 環境と、デスティネーション（ DR サイトまたはパブリッククラウド）上の同等の Linux オペレーティングシステム</block>
  <block id="6114118ecf4e8d86a2e7c80bfab462f6" category="open-title">&lt;strong&gt; 「ビッグ」 &gt;CVO&lt;/strong&gt;</block>
  <block id="2f960df807c8ad51e74c447149eb2033" category="cell">* Cloud Manager / AWS *</block>
  <block id="571f37fae4494df03321c2abe1fcc053" category="cell">AWS のアクセス / シークレットキー</block>
  <block id="7a5be8c4513f3bd0696db24a6bd977f4" category="cell">NetApp Cloud Manager アカウント</block>
  <block id="99e55608ac5f1697eb6804aaf586af09" category="cell">NetApp Cloud Manager Refresh Token</block>
  <block id="3f9ec2a23fee1cafeb1a700de677caac" category="cell">Playbook</block>
  <block id="1f959110c5104b300b1a3d5fe3ee80dc" category="cell">* ONTAP_setup*</block>
  <block id="b7ed1e5c864a764f83f035d7f4f774ee" category="cell">ソースクラスタでのクラスタ間 LIF の作成（オプション）</block>
  <block id="73ddb5848c16203494697871a4e993cd" category="cell">デスティネーションクラスタでのクラスタ間 LIF の作成（オプション）</block>
  <block id="04a35ce053d611d390fc192544fa4899" category="cell">クラスタ / SVM ピアリングの作成</block>
  <block id="4605aea1d05aa2979e72d73dd2c51773" category="cell">SnapMirror デスティネーションの作成と、指定された Oracle ボリュームの初期化</block>
  <block id="0dd4c7b6672d8937b6eb899b454fb7fe" category="cell">* ora_replication_cg *</block>
  <block id="7187aaa97acef94360159347d76a84c9" category="cell">/etc/oratab 内の各データベースのバックアップモードを有効にします</block>
  <block id="f9198142d6e5690166713858ae8a0cdd" category="cell">Oracle バイナリボリュームとデータベースボリュームの Snapshot</block>
  <block id="23ba14a0a5cf33c38faec5b66fff712e" category="cell">SnapMirror を更新しました</block>
  <block id="114debcae141b96db77c72e8a1e8fadb" category="cell">/etc/oratab 内の各データベースのバックアップモードをオフにします</block>
  <block id="682094861a79bcba0e0ab2e193198762" category="cell">* ora_replication_log *</block>
  <block id="1d03ae98454d1c807318a1e29a4e2736" category="cell">/etc/oratab 内の各データベースの現在のログを切り替えます</block>
  <block id="47e4696811eedec695f727189503e8df" category="cell">Oracle ログボリュームの Snapshot</block>
  <block id="86836efae3e3d868a96ae69bcbc987ba" category="cell">* ora_recovery*</block>
  <block id="6ceab4515ef4144abed0f0ce5ed3038f" category="cell">SnapMirror を解除します</block>
  <block id="a6066c717f63ac99226b48abb4cf1d85" category="cell">デスティネーションで NFS を有効にし、 Oracle ボリュームのジャンクションパスを作成します</block>
  <block id="aa46cdc29b66725a1180f57d02f0cee3" category="cell">DR Oracle ホストを設定</block>
  <block id="dea9253f9b15f57a0c2161848a3c27a3" category="cell">Oracle ボリュームをマウントして確認</block>
  <block id="ee95819ff53983a149759d555a93ba4b" category="cell">Oracle データベースをリカバリして起動します</block>
  <block id="5a6b57bc1fdf2f0e1259ed22f1d027a4" category="cell">* CVF_setup*</block>
  <block id="331c87cd495ffdc9cd55d8b3935a75f5" category="cell">環境の事前チェック</block>
  <block id="5f17c8d8d95282db12506044ba4d6ab9" category="cell">AWS Configure / AWS Access Key ID / Secret Key / Default Region</block>
  <block id="cef449920fe163cdd74231266cbdf23d" category="cell">AWS ロールの作成</block>
  <block id="85a4bcbc96cde90931ad369de96535b2" category="cell">AWS での NetApp Cloud Manager Connector インスタンスの作成</block>
  <block id="abe14752834b641e86064c7214f6719c" category="cell">AWS での Cloud Volumes ONTAP （ CVO ）インスタンスの作成</block>
  <block id="c2a9449cd3b0ae879520f450b65b1621" category="cell">オンプレミスのソース ONTAP クラスタを NetApp Cloud Manager に追加</block>
  <block id="fbb54d6efa6ca64af90fbe2289812be8" category="cell">デスティネーション CVO で NFS を有効にし、 Oracle ボリュームのジャンクションパスを作成してください</block>
  <block id="3ef6389d9b9aacdce331793dd2a96ce8" category="paragraph">自動化を簡易化するために、必要な Oracle パラメータがデフォルト値で多数設定されています。通常、ほとんどの環境でデフォルトパラメータを変更する必要はありません。上級ユーザーは ' デフォルト・パラメータを変更する際に注意してくださいデフォルトのパラメータは、各ロールフォルダの defaults ディレクトリにあります。</block>
  <block id="a98d844e94ad28c8e0fb089e005d6b9f" category="inline-link-macro">AWX/Tower の詳細な手順については、こちらを参照してください</block>
  <block id="7e599865fd1cdad0e26add5715f65267" category="paragraph">準備ができたら、をクリックします <block ref="d28bc5520349bb0598caaa5132432326" category="inline-link-macro-rx"></block>。</block>
  <block id="47373f46adef617d17665b0b94be8f67" category="paragraph">ログ・レプリケーション・プレイブックのスケジュール</block>
  <block id="8e43fbf8e210fdbb3e1d59ca59cde628" category="list-text">コピーしたテンプレートで [ テンプレートの編集 ] をクリックし、名前を [ リストアとリカバリプレイブック ] に変更します。</block>
  <block id="42f2159b893bbf4b6bf098ba9a026a1c" category="list-text">実行するプレイブックとして ora_recoveryyml を選択します。</block>
  <block id="0a3fe9b740fe79971ae2379eaec4822c" category="admonition">このプレイブックは、リモートサイトでデータベースをリストアする準備ができるまでは実行されません。</block>
  <block id="261e91a1afdfe1123497b1b9ba5ab3e1" category="section-title">AWX/Tower Oracle データ保護</block>
  <block id="db2b28449b6d868d910cd53527934988" category="list-text">最初のグループの Oracle という名前を入力し、 [ 保存 ] をクリックします。</block>
  <block id="200e1fa09608b23de5cd04d22d3a5bdb" category="list-text">DR_Oracle という名前の 2 つ目のグループに対してこの手順を繰り返します。</block>
  <block id="1e29c17b60e9145858da82263315e402" category="list-text">作成した Oracle グループを選択し、 Hosts サブメニューに移動して、 Add New Host をクリックします。</block>
  <block id="250d5368537e295251f9ccf63f950087" category="list-text">ソース Oracle ホストの管理 IP の IP アドレスを入力し、 [ 保存 ] をクリックします。</block>
  <block id="22dcd973cf7a10ed9d03c5b959e65807" category="list-text">DR_Oracle グループに対してこの手順を繰り返し、 DR/Destination Oracle ホストの管理 IP / ホスト名を追加する必要があります。</block>
  <block id="1a4eca6a53be80f21117669b80a5dbc8" category="admonition">以下は、オンプレミスと ONTAP 、または AWS 上の CVO のクレデンシャルタイプとクレデンシャルを作成する手順です。</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="open-title">オンプレミス</block>
  <block id="50d33cb309a9ea4bacb0a5541498b670" category="list-text">クレデンシャルタイプの作成ONTAP を使用するソリューションでは、ユーザ名とパスワードのエントリを照合するようにクレデンシャルタイプを設定する必要があります。</block>
  <block id="c048e95ab07253cc1cb87bef130c410b" category="list-text">次の内容をインジェクタ設定に貼り付け、 [ 保存 ] をクリックします。</block>
  <block id="9302fe5c60a983a24bb8787c00db4862" category="list-text">ONTAP のクレデンシャルを作成します</block>
  <block id="0a0aab79fb5a20fa5f830947226ef87c" category="list-text">ONTAP クレデンシャルの名前と組織の詳細を入力します</block>
  <block id="81999e930ad44af27e84682c3ea1e750" category="list-text">前の手順で作成したクレデンシャルタイプを選択します。</block>
  <block id="1546222d368538c25b5704b5fcf160f5" category="list-text">タイプの詳細で、ソースクラスタとデスティネーションクラスタのユーザ名とパスワードを入力します。</block>
  <block id="c4be718383c8ca0aa17633d911fc38fd" category="list-text">[ 保存 ] をクリックします .</block>
  <block id="39f6f9fe82cbf0c0970d13b6a043ad84" category="list-text">Oracle のクレデンシャルを作成します</block>
  <block id="30d4be106e7fb63befec4c8c7c815ad0" category="list-text">Oracle の名前と組織の詳細を入力します。</block>
  <block id="61d6c643401e4a602f3c8b4b6fc0a93c" category="list-text">必要に応じて、 DR_Oracle ホストの別のクレデンシャルに対して同じ手順を繰り返します。</block>
  <block id="f7fc367b5de87581ac78fc80805439af" category="open-title">CVO を確認して</block>
  <block id="61efb6ce79debd57f1e5eb28b08f94ba" category="list-text">クレデンシャルタイプを作成する。ONTAP が関連するソリューションでは、ユーザ名とパスワードのエントリに一致するクレデンシャルタイプを設定する必要があります。また、 Cloud Central と AWS のエントリも追加します。</block>
  <block id="b95cd128bfca5d5c9181a46d0392c360" category="list-text">次の内容をインジェクタ構成に貼り付け、 [ 保存（ Save ） ] をクリックする。</block>
  <block id="75f3f97810b5eef177a5355b86dabfd0" category="list-text">ONTAP / CVO / AWS のクレデンシャルを作成</block>
  <block id="922922f515b0ac072e20128999512b50" category="list-text">Oracle のクレデンシャルの作成（ソース）</block>
  <block id="7ebca140d5dcaa006aeda44b19cfc52e" category="list-text">Oracle ホストの名前と組織の詳細を入力します</block>
  <block id="ca530facf78f2112c60ee838d85b9b5b" category="list-text">Oracle 保存先のクレデンシャルを作成します</block>
  <block id="063e8368b0de123266b00f2c88e317fb" category="list-text">DR Oracle ホストの名前と組織の詳細を入力します</block>
  <block id="0d28c8cc8415971cf2cd02507176bf94" category="list-text">Type Details に、ユーザ名（ ec2-user またはデフォルトの入力から変更した場合は、そのユーザ名）と SSH 秘密鍵を入力します</block>
  <block id="cb8f433dfb62a17f7a02f4d7a8839b1c" category="list-text">適切な特権昇格方式（ sudo ）を選択し、必要に応じてユーザ名とパスワードを入力します。</block>
  <block id="791ef966f9be349751448b9066bdd8fa" category="list-text">入力するコマンド <block ref="1881636a0f344e587cc2202e2db4c5ac" category="inline-link-rx"></block> をソース管理 URL として指定します。</block>
  <block id="285a3bb8fb6f692046facadb3c0984cf" category="paragraph">実行する必要があるプレイブックは 4 つあります。</block>
  <block id="37472723bc7712fedddee6d02e29228d" category="list-text">環境のセットアップに関するプレイブック：オンプレミス、 CVO</block>
  <block id="5138c89250c5086accf2d1a5961c9b17" category="list-text">Oracle バイナリとデータベースをスケジュールどおりにレプリケートする Playbook</block>
  <block id="3e552d6e5b2c316c63eb1fc2081d42a8" category="list-text">Oracle ログをスケジュールどおりにレプリケートするためのプレイブック</block>
  <block id="33f4f1514dc2ceb963af16685f4de58c" category="list-text">デスティネーションホストでのデータベースのリカバリに関するプレイブック</block>
  <block id="17ae7167fac3c2364c6ad7b58819a920" category="open-title">ONTAP/CVO セットアップ</block>
  <block id="16f928d0ebd67060f6b3b2abf0481928" category="open-title">バイナリおよびデータベースボリュームのレプリケーション</block>
  <block id="b723f9a72bec39ac17d89e51ff0ba336" category="open-title">ログボリュームのレプリケーション</block>
  <block id="048f2ee27b8617cb0e13b6a0b7da956f" category="list-text">コピーしたテンプレートで [ テンプレートの編集 ] をクリックし、名前を [ ログレプリケーションのプレイブック ] に変更します。</block>
  <block id="d4a86123c8e623e35eaa51ab9583e03b" category="list-text">実行するプレイブックとして ora_replication_loges.yml を選択します。</block>
  <block id="d6e504930da1d0732ea4162514a38e8e" category="list-text">Log Replication Playbook テンプレートをクリックし、一番上のオプションセットにある Schedules （スケジュール）をクリックします。</block>
  <block id="1c03188c731004905466903c2eb763c4" category="list-text">[ 追加 ] をクリックし、 [ ログ複製の名前スケジュールの追加 ] をクリックし、時間の開始時に開始日時を選択し、 [ ローカルタイムゾーン ] と [ 実行頻度 ] を選択します。実行頻度は、多くの場合、 SnapMirror レプリケーションが更新されます。</block>
  <block id="d23bfe090a9fd09613c7a6573f619c02" category="admonition">1 時間ごとの最新の更新に確実にリカバリできるように、ログスケジュールを 1 時間ごとに更新するように設定することを推奨します。</block>
  <block id="f76dbca531ab83300165aacf97e1b7ff" category="open-title">データベースのリストアとリカバリ</block>
  <block id="b8a177e5fd059f33473cad4d1d073d38" category="list-text">オンプレミスの本番 Oracle データベースのデータボリュームは、 NetApp SnapMirror レプリケーションを使用して、セカンダリデータセンターの冗長 ONTAP クラスタまたはパブリッククラウドの Cloud Volume ONTAP に保護されます。完全に構成されたディザスタリカバリ環境では、セカンダリデータセンターまたはパブリッククラウドのリカバリコンピューティングインスタンスがスタンバイ状態になり、災害発生時に本番データベースをリカバリできます。スタンバイコンピューティングインスタンスは、 OS カーネルパッチで paraellel アップデートを実行するか、ロックステップでアップグレードすることで、オンプレミスインスタンスと同期したままになります。</block>
  <block id="57d8ad774cb4fef3d53ee8836bfee761" category="list-text">この解決策で実証されている Oracle バイナリ・ボリュームは、ターゲット・インスタンスに複製され、ターゲット・インスタンスにマウントされて、 Oracle ソフトウェア・スタックが起動されます。この Oracle リカバリアプローチには、災害発生時に Oracle を新規にインストールした場合よりも優れています。Oracle のインストールは、現在のオンプレミスの本番ソフトウェアのインストールレベルやパッチレベルと完全に同期されていることが保証されます。ただし、 Oracle でのソフトウェアライセンスの構成によっては、リカバリサイトで複製された Oracle バイナリボリュームにソフトウェアライセンスが影響する場合とそうでない場合があります。ユーザは、 Oracle のライセンス要件を評価するために、ソフトウェアライセンス担当者に確認してから、同じ方法を使用することを推奨します。</block>
  <block id="74eaa493ffed695592003e0844d93c46" category="list-text">デスティネーションのスタンバイ Oracle ホストには、 Oracle の前提条件となる構成が設定されています。</block>
  <block id="0be4357ac224d44b11800179b23eb202" category="list-text">SnapMirror が切断され、ボリュームが書き込み可能になり、スタンバイ Oracle ホストにマウントされます。</block>
  <block id="69504b415e8aad20e18beca0de96ab6a" category="list-text">すべての DB ボリュームがスタンバイコンピューティングインスタンスにマウントされたあと、 Oracle リカバリモジュールは以下のタスクを実行して、リカバリサイトで Oracle をリカバリおよび起動します。</block>
  <block id="5e52a9563e31960cdf02c7b83e6495e7" category="list-text">制御ファイルを同期します。重要なデータベース制御ファイルを保護するために、異なるデータベースボリュームに Oracle 制御ファイルを重複して配置しました。1 つはデータボリューム上にあり、もう 1 つはログボリューム上にあります。データボリュームとログボリュームは異なる頻度でレプリケートされるため、リカバリ時に同期されません。</block>
  <block id="26b9a788a0ef0527f25f68892b364d19" category="list-text">Oracle バイナリの再リンク： Oracle バイナリは新しいホストに再配置されるため、再リンクが必要です。</block>
  <block id="b66ad18a7982f7c233e9d0af2f867856" category="list-text">Oracle データベースのリカバリ：リカバリ・メカニズムは、 Oracle ログ・ボリューム内の最後に使用可能なアーカイブ・ログのシステム変更番号を制御ファイルから取得し、 Oracle データベースをリカバリして、障害発生時に DR サイトにレプリケートされたすべてのビジネス・トランザクションをリカバリします。次に、データベースが新しいインカネーションで起動され、リカバリサイトでユーザ接続とビジネストランザクションが実行されます。</block>
  <block id="b9b07f10c0ce1735548942e3abaa3447" category="summary">このページでは、 NetApp Cloud Manager を介して CVO および Cloud Manager Connector の導入に必要なリフレッシュトークンとアクセス / シークレットキーを収集するための詳細情報を提供します。</block>
  <block id="bcc03f70ea2e77a98ddb6e8267e4892f" category="paragraph">AWX/Ansible タワーを介した Ansible プレイブックを使用して、 CVO とコネクタの自動導入を設定するには、次の情報が必要です。</block>
  <block id="193fc1c355935356ecd5d07811792512" category="section-title">AWS からアクセスキーとシークレットキーを取得する</block>
  <block id="60b6439418495e0d1821d169b7d4b885" category="list-text">Cloud Manager に CVO と Connector を導入するには、 AWS Access/Secret Key が必要です。IAM --&gt; ユーザー --&gt; ユーザー名 --&gt; セキュリティ資格情報 --&gt; アクセスキーの作成を起動して、 AWS コンソールでキーを取得します。</block>
  <block id="ad1cc06192440312813c412c9cf08bc5" category="list-text">アクセスキーをコピーし、 Connector および CVO の導入で使用するためのセキュリティを確保しておきます。</block>
  <block id="4ba9f13f5b12512f3651d5ea2d3ffa05" category="admonition">キーが紛失した場合は、別のアクセスキーを作成し、失われたアクセスキーを削除できます</block>
  <block id="ad35fbaef240a8ec1f43e8a0d5e15099" category="image-alt">トークンを更新します</block>
  <block id="89d8fe92eb33da3c73df38422c3fa73e" category="section-title">NetApp Cloud Central から Refresh Token を取得しています</block>
  <block id="3d7e1d21530a3a98c74b0b7484c84516" category="list-text">のアカウントクレデンシャルを使用して、 Cloud Central アカウントにログインします<block ref="ddbd83acb6424bbb7fa6878eff0976a1" category="inline-link-rx"></block></block>
  <block id="a95c6d24569073e45c394bcbd6a2c0e4" category="list-text">更新トークンを生成し、展開用に保存します。</block>
  <block id="ecd636681b83fa2697020594594aea14" category="section-title">クライアント ID を取得しています</block>
  <block id="2a1ed6ca97aeb484a26d6e0d625af96b" category="list-text">API ページにアクセスして、クライアント ID をにコピーします<block ref="06324b77583872f7e211b3e7ec3f882f" category="inline-link-rx"></block>。</block>
  <block id="1093ef7993a1f3824edbf581bb54b571" category="list-text">右上にある [Learn how to Authenticate] をクリックします。</block>
  <block id="622dcb1fafb9f30d36b32341e23ae7a0" category="list-text">ユーザ名とパスワードを入力してログインする必要がある場合は、ポップアップ表示される [Authentication] ウィンドウから通常のアクセスからクライアント ID をコピーします。SSO を使用するフェデレーテッドユーザは、 [ トークンの更新 ] タブからクライアント ID をコピーする必要があります。</block>
  <block id="76525f0f34b48475e5ca33f71d296f3b" category="image-alt">クライアント ID</block>
  <block id="6090065e2462d5f96ebac132568bdf46" category="section-title">AWS からキーペアを取得しています</block>
  <block id="294b903c23e96b98876b04f51502cec4" category="list-text">AWS コンソールで、「キーペア」を検索し、「 PEM 」とのキーペアを作成します。ここでは、 key_pair の名前を覚えておいてください。この名前を使用してコネクタを配置します。</block>
  <block id="ddb20e807acdf5ddf189dd213ff6d0cf" category="image-alt">キーペア</block>
  <block id="3ce1d7d6e1b4509256dd2574b6b5d290" category="section-title">アカウント ID を取得しています</block>
  <block id="8f19980a36fbde35540547e8f630c9e5" category="list-text">Cloud Manager で、 Account – &gt; Manage Accounts の順にクリックし、 AWX の変数で使用するアカウント ID をコピーします。</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">ネットアップのハイブリッドクラウドデータソリューション - Spark と Hadoop はお客様のユースケースに基づいています</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">使用事例 1 - Hadoop データのバックアップ</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">ユースケース 2 - クラウドからオンプレミスへのバックアップとディザスタリカバリ</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">ユースケース 3 - 既存の Hadoop データに対する DevTest の有効化</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">ユースケース 4 - データ保護とマルチクラウド接続</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">ユースケース 5 - 分析ワークロードの高速化</block>
  <block id="12367669ba6a0b6e059b69b5a95f2902" category="sidebar">Oracle Database のデータ保護</block>
  <block id="3e9d3644ee18a66c51ddd16b668eaa5a" category="sidebar">Oracle データ保護の自動化</block>
  <block id="82be90bcfc8fd03855e030edaa25583a" category="sidebar">AWX/Tower 向け Oracle データ保護の自動化</block>
  <block id="c515da31cebf8cf63b394c59f3f5f2c0" category="inline-link-macro">次の例： ONTAP AI 導入向けハイパフォーマンスジョブの概要</block>
  <block id="5c11e6d83807487f2c41bd48dc524734" category="paragraph"><block ref="5c11e6d83807487f2c41bd48dc524734" category="inline-link-macro-rx"></block></block>
  <block id="68cba59815f152ec72363e2495bab8d2" category="paragraph"><block ref="68cba59815f152ec72363e2495bab8d2" category="inline-link-macro-rx"></block></block>
  <block id="e76934323b48d5421aa2271f7e9fbee2" category="inline-link-macro">次のセクションでは、 NetApp Trident の導入と構成の概要について説明します</block>
  <block id="4e3ff90ed271e98a6802a9063034ea76" category="paragraph"><block ref="4e3ff90ed271e98a6802a9063034ea76" category="inline-link-macro-rx"></block></block>
  <block id="c64f80d07d5c1623b7b2f34e40d7b46c" category="inline-link-macro">次の例：ノートブック PC とパイプライン</block>
  <block id="c3714374d558db5573b4ecd4261e206e" category="paragraph"><block ref="c3714374d558db5573b4ecd4261e206e" category="inline-link-macro-rx"></block></block>
  <block id="defd49beb1345ee37b446e866e8b3420" category="inline-link-macro">次の例： Kubeflow の操作とタスク</block>
  <block id="2ecf31480279823ef2aed30a0fc061f2" category="paragraph"><block ref="2ecf31480279823ef2aed30a0fc061f2" category="inline-link-macro-rx"></block></block>
  <block id="64b0abe7a29610e134041ed793101fce" category="inline-link-macro">次の例： Trident の処理</block>
  <block id="f6c488122d476f1d213cf78dc2ee84d2" category="paragraph"><block ref="f6c488122d476f1d213cf78dc2ee84d2" category="inline-link-macro-rx"></block></block>
  <block id="f8bc0cf277b3c4424978d08f10f9df70" category="inline-link-macro">次の例： ONTAP AI 導入向けの Kubernetes Stageclasses</block>
  <block id="a58ef634a291d01e3abec43e5619294a" category="paragraph"><block ref="a58ef634a291d01e3abec43e5619294a" category="inline-link-macro-rx"></block></block>
  <block id="52a739b78342bd0cef8801d4c5c193b6" category="inline-link-macro">次の例： Apache Airflow の導入</block>
  <block id="6564dd7688129caf4acb63587998eb65" category="paragraph"><block ref="6564dd7688129caf4acb63587998eb65" category="inline-link-macro-rx"></block></block>
  <block id="b7cd12d2dd9ac8e3414514a02e5df6f4" category="inline-link-macro">次のセクションでは、シングルノードの AI ワークロードを実行します</block>
  <block id="6ee8519e7493385361c9afcfd675c8d0" category="paragraph"><block ref="6ee8519e7493385361c9afcfd675c8d0" category="inline-link-macro-rx"></block></block>
  <block id="080e5221e660ab18a3746fe480956ebc" category="paragraph">コンテナ管理レベルでは、 Kubernetes コンテナ管理が最適な選択肢であり、エンタープライズ環境に適した完全アップストリームバージョン（ Canonical ）または変更バージョン（ Red Hat ）のどちらでも十分にサポートされています。。 <block ref="8ff9014ec7345470e1bb9286d28496e4" category="inline-link-macro-rx"></block> NetApp Trident と新たに追加された Trident を使用しています<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> トレーサビリティ、データ管理機能、インターフェイス、ツールが組み込まれており、データサイエンティストやデータエンジニアはネットアップストレージと統合できます。Kubernetes 向け ML ツールキットである Kubeflow は、 TensorFlow サービスや NVIDIA Triton Inference Server などの複数のプラットフォームで、モデルのバージョン管理と KFServing をサポートするほか、 AI 機能も追加します。もう 1 つの選択肢は NVIDIA EGX プラットフォームです。このプラットフォームは、 GPU 対応 AI 推論コンテナのカタログにアクセスしながら、ワークロード管理を提供します。ただし、これらのオプションを使用するには、本番環境に移行するための多大な労力と専門知識が必要になる場合があります。また、サードパーティの独立系ソフトウェアベンダー（ ISV ）やコンサルタントの支援が必要になる場合もあります。</block>
  <block id="bdbf5a5e65f2cf7435dfcea294400b35" category="inline-link-macro">次に、データサイエンティストや開発者が使用する Jupyter Notebook Workspace をプロビジョニングします</block>
  <block id="86e512bbf34bd396dd043a14ff2027ec" category="paragraph"><block ref="86e512bbf34bd396dd043a14ff2027ec" category="inline-link-macro-rx"></block></block>
  <block id="b569e24403ad128c09e2d0dbd0116463" category="inline-link-macro">次のセクションでは、 Kubeflow の導入の概要を説明します</block>
  <block id="66f5564ed29f37f0b81d2dde741b9c8f" category="paragraph"><block ref="66f5564ed29f37f0b81d2dde741b9c8f" category="inline-link-macro-rx"></block></block>
  <block id="fffa1b56750a0334993c90d5adc9912a" category="doc">TR-4798 ：『 NetApp AI Control Plane 』</block>
  <block id="6dd86945b1681007efc06cd445661f24" category="inline-link-macro">次の手順：概念とコンポーネント</block>
  <block id="742ed784bbf61aca3af793407a42b1f5" category="paragraph"><block ref="742ed784bbf61aca3af793407a42b1f5" category="inline-link-macro-rx"></block></block>
  <block id="4fe6ae61b2ccf0bd553bc2c0f15cf803" category="inline-link-macro">次の例： ONTAP AI 導入向けの Trident バックエンド</block>
  <block id="8de05380035e6d3c48105e0b80ca2e32" category="paragraph"><block ref="8de05380035e6d3c48105e0b80ca2e32" category="inline-link-macro-rx"></block></block>
  <block id="96e1c56a273105095d8b5e23e670f72f" category="inline-link-macro">次の手順：ハードウェアとソフトウェアの要件</block>
  <block id="1c3ce2e5bdbf1449bbeba4ecbd124676" category="paragraph"><block ref="1c3ce2e5bdbf1449bbeba4ecbd124676" category="inline-link-macro-rx"></block></block>
  <block id="7af76512b5f0f470c6a7a6db368a9818" category="inline-link-macro">次のステップ：同期分散 AI ワークロードを実行します</block>
  <block id="e79dd849e38d01ac3faa7090e83320b2" category="paragraph"><block ref="e79dd849e38d01ac3faa7090e83320b2" category="inline-link-macro-rx"></block></block>
  <block id="99c61a2c4480337fdf852f9dbe8a8863" category="inline-link-macro">次の例： Apache Airflow ワークフロー</block>
  <block id="d719776b249ed9e7109b922484d474a2" category="paragraph"><block ref="d719776b249ed9e7109b922484d474a2" category="inline-link-macro-rx"></block></block>
  <block id="26c21566450ecb01d82e6d0e3f7ef1a3" category="inline-link-macro">次： Kubernetes の導入</block>
  <block id="0635bed13bdc0ace58fec0264ac3d119" category="paragraph"><block ref="0635bed13bdc0ace58fec0264ac3d119" category="inline-link-macro-rx"></block></block>
  <block id="256fbc599203bd1bd63bfe25b7a5b9ad" category="inline-link-macro">次のステップ：パフォーマンステスト</block>
  <block id="35bb3345a07dfa439dd6936ea8f69faf" category="paragraph"><block ref="35bb3345a07dfa439dd6936ea8f69faf" category="inline-link-macro-rx"></block></block>
  <block id="68eff5f8d34b801d40ab55f098bc6478" category="inline-link-macro">解決策の使用を開始するには、こちらをクリックしてください</block>
  <block id="e5dec240e8be4a30564a7e8ddc0d568a" category="list-text">準備ができたら、をクリックします <block ref="a171481e1cde5211da297c03090cb7ce" category="inline-link-macro-rx"></block>。</block>
  <block id="4d0c05180ba83e5c8a9bbac094c365e2" category="list-text">自動化は、 Oracle バイナリのセットアップ、データベース、ログ、ログのレプリケーションスケジュール、ログのみのレプリケーションスケジュールの 3 つのフェーズと、 DR サイトでのデータベースリカバリのための 4 つのフェーズで実行されます。</block>
  <block id="675b1e5a01195fa5d419962701704b96" category="cell">Oracle EC2 インスタンスに適切なスワップスペースを設定します。デフォルトでは、一部の EC2 インスタンスは 0 スワップで導入されます</block>
  <block id="68085bee9e04417d4d9e74101a357a22" category="list-text">Type Details に、ソースクラスタと CVO クラスタ、 Cloud Central / Manager 、 AWS Access / Secret Key 、 Cloud Central Refresh Token のユーザ名とパスワードを入力します。</block>
  <block id="861503fb33ea04fecb13449e713e8ac6" category="admonition">Recovering Playbook を実行する前に、次の情報を確認してください。 /etc/oratab および /etc/oraInst.loc を介して、ソース Oracle ホストからデスティネーションホストにコピーしてください</block>
  <block id="72feee9e055adc523c4c9ca3c1453409" category="inline-link-macro">ビデオ： Astra Control を使用した CI / CD パイプラインでのデータ保護</block>
  <block id="3bf54df2b09b6352059075c261817bd0" category="cell"><block ref="3bf54df2b09b6352059075c261817bd0" category="inline-link-macro-rx"></block></block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">このドキュメントでは、 VMware vSphere 向け ONTAP ツールの製品セキュリティについて説明します。</block>
  <block id="289953e1dbd51c07cae2ecf1e6fb88a1" category="doc">WP-7353 ：『 ONTAP tools for VMware vSphere - Product Security 』</block>
  <block id="595319f89334a6a0b8edd4f81172fc71" category="paragraph">Chance Bingen 、 Dan Tulledge 、ネットアップ、 Jenn Schrie 氏</block>
  <block id="7ab9df3e4e38ca227c1b48b0f6740675" category="section-title">安全な開発活動</block>
  <block id="1a79eb278bc02ebdbd2ab32925e316f6" category="paragraph">NetApp ONTAP Tools for VMware vSphere のソフトウェアエンジニアリングでは、次の安全な開発作業を実施します。</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">* 脅威モデリング。 * 脅威モデリングの目的は、ソフトウェア開発ライフサイクルの早い段階で、機能、コンポーネント、または製品のセキュリティ上の欠陥を発見することです。脅威モデルとは、アプリケーションのセキュリティに影響するすべての情報を構造化したものです。本質的に、これはセキュリティの観点から見たアプリケーションとその環境です。</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">* Dynamic Application Security Testing （ DAST ）。 * このテクノロジーは、実行中のアプリケーションで脆弱な状態を検出するように設計されています。DAST は、 Web 対応アプリケーションの公開 HTTP および HTML インターフェイスをテストします。</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">* サードパーティーのコード通貨。 * オープンソース・ソフトウェア（ OSS ）を使用したソフトウェア開発の一環として、製品に組み込まれた OSS に関連するセキュリティ上の脆弱性に対処する必要があります。これは継続的な取り組みです。新しい OSS バージョンには、いつでも新たに検出された脆弱性が報告される可能性があります。</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">* 脆弱性スキャン。 * 脆弱性スキャンは、お客様にリリースされる前にネットアップ製品の一般的なセキュリティの脆弱性と既知のセキュリティの脆弱性を検出するためのものです。</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">* ペネトレーションテスト。 * ペネトレーションテストは、システム、 Web アプリケーション、またはネットワークを評価して、攻撃者によって悪用される可能性のあるセキュリティの脆弱性を検出するプロセスです。ネットアップでのペネトレーションテスト（ペンテスト）は、承認された信頼できる第三者企業のグループが実施します。テスト範囲には、高度な攻撃方法やツールを使用した悪意のある侵入者やハッカーと同様のアプリケーションまたはソフトウェアに対する攻撃の開始が含まれます。</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">製品のセキュリティ機能</block>
  <block id="85d61648687f15050da0b86741b90358" category="paragraph">NetApp ONTAP Tools for VMware vSphere には、各リリースに次のセキュリティ機能が含まれています。</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">* ログインバナー。 * SSH はデフォルトでは無効になっており、 VM コンソールから有効になっている場合は 1 回限りのログインしか許可されません。ユーザがログインプロンプトでユーザ名を入力すると、次のログインバナーが表示されます。</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">* 警告： * このシステムへの不正アクセスは禁止されており、法律で訴追されます。このシステムにアクセスすることで、不正な使用が疑われる場合に、ユーザーのアクションが監視される可能性があることに同意したものとみなされます。</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">ユーザが SSH チャネルを介したログインを完了すると、次のテキストが表示されます。</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">* ロールベースアクセス制御 (RBAC) 。 * ONTAP ツールには、次の 2 種類の RBAC 制御が関連付けられています。</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">vCenter Server 標準の権限</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">vCenter プラグインに固有の権限。詳細については、を参照してください<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>。</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">* 暗号化された通信チャネル。 * すべての外部通信は、バージョン 1.2 の TLS を使用して HTTPS 経由で行われます。</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">* 最小限のポート露出。 * 必要なポートのみがファイアウォールで開かれています。</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">次の表に、オープンポートの詳細を示します。</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">TCP v4 / V6 ポート番号</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">機能</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">REST API 用の HTTPS 接続</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">HTTPS 接続</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">HTTPS 接続で SOAP over https 接続に使用される HTTPS 接続このポートを開いて、クライアントが ONTAP ツール API サーバに接続できるようにする必要があります。</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH （デフォルトでは無効）</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">HTTPS 接続 - VP および SRA - ループバックからの内部接続のみ</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">VP SNMP トラップパケット</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Derby データベースポート。このコンピュータとそれ自体の間のみ、外部接続は許可されません -- 内部接続のみ</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">こちらの技術情報アーティクル</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">* 認証局（ CA ）署名証明書のサポート。 * VMware vSphere 用の ONTAP ツールは CA 署名証明書をサポートしています。を参照してください<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> を参照してください。</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">* 監査ログ。 * サポートバンドルはダウンロード可能で、非常に詳細です。ONTAP ツールは、すべてのユーザログインおよびログアウトアクティビティを個別のログファイルに記録します。VASA API 呼び出しは、専用の VASA 監査ログ（ローカルの cxf.log ）に記録されます。</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">* パスワードポリシー。 * 次のパスワードポリシーが適用されます。</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">パスワードはどのログファイルにも記録されません。</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">パスワードはプレーンテキストで伝達されません。</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">パスワードは、インストールプロセスで設定します。</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">パスワード履歴は設定可能なパラメータです。</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">パスワードの最小有効期間は 24 時間に設定されます。</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">パスワードフィールドの自動入力は無効です。</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">ONTAP ツールは、保存されているすべてのクレデンシャル情報を SHA256 ハッシュで暗号化し</block>
  <block id="62783f5d69cb5d3cb22b077c1d2b8777" category="cell">2021年11月</block>
  <block id="a38830c0aa781c889eeb5910f47be6ea" category="summary">Astra Control Center を使用して、 CI / CD パイプラインでデータ保護を実現</block>
  <block id="dc0365ad4c92bc3f8973ff5616cd6830" category="doc">Astra Control Center を使用した CI / CD パイプラインでのデータ保護</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">ティアストレージのテストを 3~4 ノードで実施し、生成されるワークロードと利用者のワークロードについては NetApp StorageGRID のセットアップを使用しました。</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">拡張性を備えたパフォーマンステスト</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">ストレージノードの数が増えると、農産物と消費者の処理を完了するまでの時間が直線的に短くなりました。</block>
  <block id="544baf869b5baa766e8839cd33697872" category="paragraph"><block ref="544baf869b5baa766e8839cd33697872" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">s3 読み出し処理のパフォーマンスは、 StorageGRID ノードの数に基づいてリニアに向上します。StorageGRID は、最大 200 個の StorgeGRID ノードをサポートします。</block>
  <block id="2cd319a657a7fccb8f747dab6f102dcc" category="paragraph"><block ref="2cd319a657a7fccb8f747dab6f102dcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">このセクションでは、この解決策で使用されるテクノロジーについて説明します。</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Grid Manager で管理を簡易化</block>
  <block id="a96dbd2aff4998074bc0ca48dc4817d5" category="paragraph"><block ref="a96dbd2aff4998074bc0ca48dc4817d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">イメージ、ビデオ、レコードなどのオブジェクトを収めた、グローバルに分散されたペタバイト規模のリポジトリを管理します。</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">グリッドノードとサービスを監視してオブジェクトの可用性を確保します。</block>
  <block id="52134209a1824af49cd06b67ca3aedc7" category="list-text">Information Lifecycle Management （ ILM ；情報ライフサイクル管理）ルールを使用してオブジェクトデータの配置を継続的に管理します。これらのルールによって、取り込まれたオブジェクトのデータの処理、損失から保護する方法、格納場所と保管期間が決まります。</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">システム内のトランザクション、パフォーマンス、処理を監視します。</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">情報ライフサイクル管理ポリシー</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">ロードバランサとエンドポイントの設定</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">StorageGRID の管理ノードは、 StorageGRID システムを表示、設定、管理するための Grid Manager UI （ユーザインターフェイス）エンドポイントと REST API エンドポイント、およびシステムアクティビティを追跡するための監査ログを提供します。そこで、 Conluent Kafka の階層化ストレージに可用性の高い S3 エンドポイントを提供するために、 StorageGRID ロードバランサを実装しました。このロードバランサは、管理ノードとゲートウェイノードでサービスとして実行されます。また、ロードバランサはローカルトラフィックを管理し、ディザスタリカバリに役立つ GSLB （グローバルサーバロードバランシング）と通信します。</block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="section-title">Apache Kafka です</block>
  <block id="d1675da945892e06b2f84c42c32b7074" category="paragraph"><block ref="d1675da945892e06b2f84c42c32b7074" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka には、 Producer と呼ばれる任意の数のプロセスから生成されるキーと値のメッセージが格納されます。データは、異なるトピック内の異なるパーティションにパーティショニングできます。パーティション内では、メッセージはオフセット（パーティション内のメッセージの位置）によって厳密に順序付けされ、インデックスが作成され、タイムスタンプとともに格納されます。コンシューマと呼ばれる他のプロセスは、パーティションからメッセージを読み取ることができます。Kafka はストリーム処理用の API を提供しており、 Kafka からデータを利用する Java アプリケーションを作成して Kafka に結果を書き込むことができます。Apache Kafka は、 Apache Apex 、 Apache Flink 、 Apache Spark 、 Apache Storm 、 Apache NiFi などの外部ストリーム処理システムとも連携します。</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka は 1 つ以上のサーバで構成されたクラスタ（ブローカー）上で実行され、すべてのトピックのパーティションがクラスタノード全体に分散されます。さらに、パーティションは複数のブローカーにレプリケートされます。Kafka はこのアーキテクチャにより、フォールトトレラントな方法で大量のメッセージストリームを配信でき、 Java Message Service （ JMS ）や Advanced Message Queuing Protocol （ AMQP ）などの従来のメッセージングシステムの一部を置き換えることができます。0.11.0.0 リリース以降、 Kafka はトランザクション書き込みを提供しており、これは Streams API を使用して一度のストリーム処理を提供します。</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka では、 Regular とコンパクションの 2 種類のトピックをサポートしています。通常のトピックでは、保持期限またはスペースバインドを設定できます。指定した保持期限よりも古いレコードがある場合や、パーティションのスペースバインドを超過している場合、 Kafka では古いデータを削除してストレージスペースを解放することができます。デフォルトでは、トピックの保持期間は 7 日間に設定されていますが、データを無期限に保存することもできます。コンパクションの対象となるトピックについては、レコードの有効期限は時刻やスペースの上限に基づいて切れません。Kafka では、以降のメッセージを同じキーを持つ古いメッセージの更新として扱い、キーごとに最新のメッセージを削除しないことを保証しています。ユーザは、特定のキーのヌル値を持つ、いわゆる tombstone メッセージを書き込むことによって、メッセージを完全に削除できます。</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Kafka には 5 つの主要な API があります。</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">* Producer API. * は、アプリケーションがレコードのストリームをパブリッシュすることを許可します。</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*Consumer API. * は、アプリケーションがトピックを購読し、レコードのストリームを処理することを許可します。</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">* Connector API. * は、トピックを既存のアプリケーションにリンクできる再利用可能なプロデューサおよびコンシューマ API を実行します。</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*Streams API. * この API は入力ストリームを出力に変換し、結果を生成します。</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">* 管理者 API 。 Kafka のトピック、ブローカー、その他の Kafka のオブジェクトを管理するのに使用されます。</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">Kafka メッセージングプロトコルをベースに構築されたコンシューマ向け API とプロデューサー用 API は、 Java で Kafka コンシューマクライアントとプロデューサークライアント向けのリファレンス実装を提供します。基本的なメッセージングプロトコルは、開発者が任意のプログラミング言語で独自のコンシューマクライアントまたはプロデューサクライアントを作成するために使用できるバイナリプロトコルです。これにより、 Java Virtual Machine （ JVM ； Java 仮想マシン）エコシステムの Kafka のロックが解除されます。使用可能な Java 以外のクライアントの一覧は、 Apache Kafka wiki で管理されています。</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">流暢な理由</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">履歴データとリアルタイムデータを一元化された単一の情報源に統合することで、 Conluent は、まったく新しいカテゴリの最新のイベント駆動型アプリケーションを簡単に構築し、ユニバーサルデータパイプラインを取得し、拡張性、パフォーマンス、信頼性を備えた強力な新しいユースケースを開放します。</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">流暢なものは何のために使用されるか。</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Conflicent Platform を使用すると、データが異なるシステム間でどのように転送または統合されるかなど、基本的なメカニズムを気にすることなく、データからビジネス価値を引き出す方法に集中できます。具体的には、 Con裕福 なプラットフォームによって、 Kafka へのデータソースの接続やストリーミングアプリケーションの構築、 Kafka インフラの保護、監視、管理が簡易化されます。現在、 Conluent Platform は、金融サービス、オムニチャネル小売、自律走行車など、さまざまな業界のさまざまなユースケースに使用されています。 マイクロサービス、 IoT 。</block>
  <block id="a4eaf48584aaa7df975a9275a8b4ee24" category="paragraph"><block ref="a4eaf48584aaa7df975a9275a8b4ee24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0693822e07a3206c53912f33e3d67758" category="section-title">流暢なイベントストリーミング技術の概要</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">流暢なプラットフォームの中核はです<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block>最も人気の高いオープンソースの分散ストリーミングプラットフォームです。Kafka の主な機能は次のとおりです。</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">レコードのストリームをパブリッシュしてサブスクライブします。</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">レコードのストリームをフォールトトレラントな方法で保存します。</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">レコードのストリームを処理します。</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">Conluent Platform には Schema Registry 、 REST Proxy 、合計 100 以上の Kafka コネクタ、および ksqlDB も含まれています。</block>
  <block id="55be5d4d3f7143137050de9374d03f6f" category="section-title">流暢なプラットフォームのエンタープライズ機能の概要</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">* Conluent Control Center * Kafka を管理および監視するための GUI ベースのシステム。Kafka Connect の管理や、他のシステムとの接続の作成、編集、管理を簡単に行うことができます。</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">* Kubernetes には流暢な言葉があります。 * Kubernetes の流暢な言葉は Kubernetes のオペレータです。Kubernetes の運用担当者は、特定のプラットフォームアプリケーションに固有の機能と要件を提供することで、 Kubernetes のオーケストレーション機能を拡張します。Con裕福 なプラットフォームの場合は、 Kubernetes での Kafka の導入プロセスを大幅に簡易化し、一般的なインフラのライフサイクルタスクを自動化します。</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">* Kafka コネクタは、 Kafka Connect API を使用して、 Kafka をデータベース、キーバリューストア、検索インデックス、ファイルシステムなどの他のシステムに接続します。Confluent Hub には、一般的なデータソースおよびシンク用のダウンロード可能なコネクタがあります。これには、 Conluent Platform でこれらのコネクタの完全なテストとサポートされたバージョンが含まれます。詳細については、を参照してください<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>。</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">* セルフバランシングクラスタ。 * 自動ロードバランシング、障害検出、自己修復機能を提供します。必要に応じてブローカーの追加や運用停止をサポートし、手動での調整は不要です。</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">* クラスタを直接接続し、リンクブリッジを介して 1 つのクラスタから別のクラスタにトピックをミラーリングします。クラスタリンクにより、マルチデータセンター、マルチクラスタ、ハイブリッドクラウドの導入を簡易化できます。</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">* 流暢な自動データバランサ。 * ブローカーの数、パーティションのサイズ、パーティションの数、およびクラスタ内のリーダーの数について、クラスタを監視します。これにより、データを移動してクラスタ全体で均等なワークロードを作成しながら、トラフィックのリバランシングを調整して、リバランシング中の本番ワークロードへの影響を最小限に抑えることができます。</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">* 流暢なリプリケータ * により、複数のデータセンターで複数の Kafka クラスターを容易に保守できます。</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">* 階層化ストレージ。 * 任意のクラウドプロバイダを使用して大量の Kafka データを保存するオプションを提供し、運用上の負担とコストを削減します。階層型ストレージでは、コスト効率に優れたオブジェクトストレージにデータを格納し、ブローカーを拡張するために、必要なコンピューティングリソースが増えた場合のみデータを利用できます。</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">* Conluent JMS Client. * Conluent Platform には Kafka 用の JMS 対応クライアントが含まれています。Kafka クライアントは、 Kafka ブローカーをバックエンドとして使用して、 JMS 1.1 標準 API を実装しています。これは 'JMS を使用するレガシーアプリケーションがあり ' 既存の JMS メッセージブローカを Kafka に置き換える場合に便利です</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">* Coneluent MQTT プロキシ * を使用すると、 MQTT デバイスやゲートウェイから Kafka に直接データを公開できます。 MQTT ブローカーは必要ありません。</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">* 流暢なセキュリティプラグイン。 * 流暢なセキュリティプラグインは、各種の流暢なプラットフォームツールや製品にセキュリティ機能を追加するために使用されます。現在、 Conluent REST プロキシ用のプラグインが用意されており、受信要求の認証に役立ち、認証されたプリンシパルを要求に Kafka に伝播できます。これにより、 Con裕福 な REST プロキシクライアントでは、 Kafka ブローカーのマルチテナントセキュリティ機能を利用できます。</block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">このドキュメントでは、ネットアップのストレージコントローラで Kafka を使用する場合のベストプラクティスのガイドラインを説明しています。</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="doc">TR-4912 ：『 Best Practices guidelines for ConFluent Kafka Tiered Storage with NetApp 』</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">また、 NetApp StorageGRID の階層型ストレージとして Kafka を使用して、 ConFluent Platform の認定を受けています。</block>
  <block id="0a569fd987814c0464300156b2e26414" category="paragraph"><block ref="0a569fd987814c0464300156b2e26414" category="inline-link-macro-rx"></block></block>
  <block id="82dc8b1c8f1a6f08261f17b764e74bf4" category="paragraph"><block ref="82dc8b1c8f1a6f08261f17b764e74bf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">競合する階層型ストレージ構成</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">階層化ストレージの構成には、 Kafka に次のパラメータが必要です。</block>
  <block id="1ba0fc45020f864c62328d58df2351ef" category="paragraph"><block ref="1ba0fc45020f864c62328d58df2351ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">オブジェクトストアの正確性テスト</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">階層化機能の正確性テスト</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">ティアフェッチベンチマーク</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">このテストでは、階層型オブジェクトストレージの読み取りパフォーマンスを検証し、ベンチマークによって生成されたセグメントからの負荷が大きい範囲での読み取り要求のフェッチをチェックしました。このベンチマークでは、 Conluent 社は階層フェッチ要求に対応するカスタムクライアントを開発しました。</block>
  <block id="b2ce010f52b23eb40ba6b51b92837acb" category="inline-link-macro">次のステップ：拡張性を備えたパフォーマンステスト</block>
  <block id="4a94c930da0f9f0974ad6d4f2d17726b" category="paragraph"><block ref="4a94c930da0f9f0974ad6d4f2d17726b" category="inline-link-macro-rx"></block></block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">本ドキュメントでは、 ConFluent Kafka の認定テスト、パフォーマンスの結果、チューニング、 Kafka コネクタ、自己リバランシング機能など、ネットアップのストレージで Kafka を使用する場合のベストプラクティスを紹介します。</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">Apache Kafka とは何ですか</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">S3 シンクパラメータの詳細</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">このテストは自己バランシングクラスタ機能に基づいており、クラスタトポロジの変更や負荷の不均一に基づいてリバランシングを自動で実行します。</block>
  <block id="6dec1258fbcccbfaa7098758abb00055" category="inline-link-macro">これまでの Kafka s3 コネクタを使用しました。</block>
  <block id="6e3bea5fe8473b6e884edafaf7fcf1d4" category="paragraph"><block ref="6e3bea5fe8473b6e884edafaf7fcf1d4" category="inline-link-macro-rx"></block></block>
  <block id="cc87abc70119e2ad833c42a865a33659" category="inline-link-macro">次のステップ：ベストプラクティスのガイドライン</block>
  <block id="caf8da5a9482899a1495e1e052a4b287" category="paragraph"><block ref="caf8da5a9482899a1495e1e052a4b287" category="inline-link-macro-rx"></block></block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">このセクションでは、この認定資格から得られた教訓について説明します。</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">ベストプラクティスのガイドライン</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">オブジェクトストレージは、セグメントの方がパフォーマンスに優れています。バイト数が多い場合は 512 MB をテストしました。</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">Kafka では、トピックに対して生成される各レコードのキーまたは値の長さ（バイト単位）は、「 length.key.value 」パラメータによって制御されます。StorageGRID では、 S3 オブジェクトの取り込みと読み出しのパフォーマンスがより高い値に引き上げられました。たとえば、 512 バイトが 5.8GBps の読み出しを提供し、 1024 バイトが 7.5GBps の s3 読み出しを提供し、 2048 バイトが 10Gbps 近く提供します。</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">次の図に、「 length.key.value 」に基づいた S3 オブジェクトの取り込みと読み出しを示します。</block>
  <block id="b50ee24368ac624f2816b9e550167cb9" category="paragraph"><block ref="b50ee24368ac624f2816b9e550167cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4127d3e6d7b548701a1cf83ef1d7a922" category="paragraph"><block ref="4127d3e6d7b548701a1cf83ef1d7a922" category="inline-link-macro-rx"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">このセクションでは、流暢な認定に使用されるハードウェアおよびソフトウェアについて説明します。この情報は、ネットアップストレージで Kafka を導入する場合に該当します。</block>
  <block id="40328f8a932f8ae1964c73c1f2eca76b" category="paragraph"><block ref="40328f8a932f8ae1964c73c1f2eca76b" category="inline-link-macro-rx"></block></block>
  <block id="f4e981d58b1468737da82402b3cce7f1" category="paragraph"><block ref="f4e981d58b1468737da82402b3cce7f1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="section-title">解決策アーキテクチャの詳細</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Kafka バージョン 6.2 と競合します</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">ご主人の 3 人</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">5 台のブローカーサーバ</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">Grafana × 1</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">1 つのコントロールセンター</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux （ Ubuntu 18.04 ）</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">すべてのサーバ</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">SG1000 × 1 （ロードバランサ）</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">24 本、 800 本の SSD × 4</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">S3 プロトコル</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">Fujitsu Primergy RX2540 サーバ × 15</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">各モデルには、 CPU × 2 、物理コア × 16 、 Intel Xeon × 256GB 物理メモリ × 100GbE デュアルポートが搭載されています</block>
  <block id="c88aa001e26103d0ebe4894b3c9ab9f5" category="paragraph"><block ref="c88aa001e26103d0ebe4894b3c9ab9f5" category="inline-link-macro-rx"></block></block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">このセットアップでは、 Kafka s3 sink Connector を使用して、 Kafka のオブジェクトストレージのトピックの読み取りと書き込みを直接実行する方法を紹介します。このテストでは、スタンドアロンの流暢なクラスタを使用しましたが、このセットアップは分散クラスタに適用できます。</block>
  <block id="9b154eb37aabb62c75c78bd31457468f" category="inline-link-macro">Previous ：拡張性を備えたパフォーマンステスト。</block>
  <block id="aa4f22f43748e77c4fb71f8cb5333c25" category="paragraph"><block ref="aa4f22f43748e77c4fb71f8cb5333c25" category="inline-link-macro-rx"></block></block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Conluent Kafka の Web サイトからダウンロードできます。</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">パッケージをサーバー上のフォルダに展開します。</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">2 つの変数をエクスポートします。</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">スタンドアロンの ConFluent Kafka セットアップの場合、クラスタは「 /tmp 」に一時的なルートフォルダを作成します。Zookeeper 、 Kafka 、スキーマレジストリ、 connect 、 ksql-server 、 とコントロールセンターのフォルダを作成し、それぞれの構成ファイルを「 $confliclus_home 」からコピーします。次の例を参照してください。</block>
  <block id="fc1644d2d2819b87443b810d963409fa" category="list-text">Zookeeper を構成します。デフォルトのパラメータを使用する場合は、何も変更する必要はありません。</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">上記の設定では、サーバを更新しました。xxx ’プロパティ。デフォルトでは、 Kafka リーダーの選択に 3 名の Zookeepers が必要です。</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">myid ファイルを tmp/conflicluent .406980/zookeeper /data に一意の ID で作成しました。</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">myid ファイルの最後の数の IP アドレスを使用しました。Kafka 、 connect 、 control-ccenter、 Kafka 、 Kafkakarest 、 ksql-server 、およびスキーマレジストリ設定。</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Kafka サービスを開始します。</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">構成ごとにログフォルダがあり、問題のトラブルシューティングに役立ちます。場合によっては、サービスの開始に時間がかかることがあります。すべてのサービスが稼働中であることを確認します。</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">「 confliclue-hub 」を使用して Kafka connect をインストールします。</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">また、「 conflicluent -hub install conflicentinc / Kafka-connect-s3 ： 10.0.3` を使用して、特定のバージョンをインストールすることもできます。</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">デフォルトでは、「 confluentinc - Kafka-connect-s3 」は「 /data/luent confin/conflicluent - 6.2.0/conflicluent -huber-components/conflicentinc - Kafka-connect-s3 」にインストールされています。</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">新しい「 confluentinc - Kafka -connect-s3` でプラグインパスを更新します。</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">流暢なサービスを停止し、再起動します。</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">アクセス ID とシークレットキーを「 /root/.AWS/credentials 」ファイルに設定します。</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">バケットに到達できることを確認します。</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">s3 およびバケット設定用の s3-sink プロパティファイルを設定します。</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">s3 バケットに数件のレコードをインポートします。</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">S3 シンクコネクタを取り付けます。</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">s3-sink のステータスを確認します。</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">ログをチェックして、 s3-sink のトピックを受け入れる準備ができていることを確認します。</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Kafka のトピックを確認してください。</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">s3 バケット内のオブジェクトを確認します。</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">内容を確認するには、次のコマンドを実行して、 S3 からローカルファイルシステムに各ファイルをコピーします。</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Apache アーカイブ</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">レコードを印刷するには、 avro-tools-1.11.0.1.jar を使用します（『』で入手できます）<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block>）。</block>
  <block id="9f4b95975f14f6481a322f453e05049c" category="sidebar">VMware vSphere 向け ONTAP ツール - 製品セキュリティ</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">ConFluent Kafka のベストプラクティスをご確認ください</block>
  <block id="0c138556fe4f10d4cdba4c61933afd91" category="doc">Google Cloud Virtualization Engine （ GCVE ）向けネットアップソリューション</block>
  <block id="4177c39712dda5976b0ba657b24af234" category="doc">Cloud Volumes ONTAP を Google Cloud に導入（自分で導入）</block>
  <block id="2839d8571363b149cc3fd9db82a7183d" category="paragraph">Cloud Volumes ONTAP 共有と LUN は、 GCVE プライベートクラウド環境で作成された VM からマウントできます。Cloud Volumes ONTAP は iSCSI 、 SMB 、 NFS の各プロトコルをサポートしているため、 iSCSI 経由でマウントしたボリュームを Linux クライアントや Windows クライアントにマウントし、 LUN に Linux クライアントや Windows クライアントからブロックデバイスとしてアクセスすることもできます。Cloud Volumes ONTAP ボリュームは、いくつかの簡単な手順で設定できます。</block>
  <block id="3b020916a45973167bc70cb4517bd8c8" category="inline-link-macro">システム間のデータレプリケーションの設定</block>
  <block id="83f1904115d07e05de148ff5c69277db" category="paragraph">ディザスタリカバリや移行の目的でオンプレミス環境からクラウドにボリュームをレプリケートするには、サイト間 VPN または Cloud Interconnect を使用して Google Cloud へのネットワーク接続を確立します。オンプレミスから Cloud Volumes ONTAP へのデータのレプリケートについては、本ドキュメントでは扱いません。オンプレミスシステムと Cloud Volumes ONTAP システム間でデータをレプリケートする方法については、を参照してください <block ref="17b5522e2d467cfa8e1eed2f77bb1eff" category="inline-link-macro-rx"></block>。</block>
  <block id="9eb931a836eecf8e743b47b449c70bc5" category="inline-link-macro">Cloud Volumes ONTAP サイジングツール</block>
  <block id="165fc07e6910d8748be18ecaaab5392d" category="admonition">使用 <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Cloud Volumes ONTAP インスタンスのサイズを正確に設定します。また、オンプレミスのパフォーマンスを監視し、 Cloud Volumes ONTAP のサイジングツールの情報として使用できます。</block>
  <block id="a1d02afc571062ee1235156b645846f8" category="list-text">NetApp Cloud Central にログイン— Fabric View （ファブリックビュー）画面が表示されます。Cloud Volumes ONTAP タブを探し、 Go to Cloud Manager を選択します。ログインすると、キャンバス画面が表示されます。</block>
  <block id="52111b7d24cc23248fa9cf8138732943" category="paragraph"><block ref="52111b7d24cc23248fa9cf8138732943" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67b4a468763f61993484edb54b0d5eaa" category="list-text">Cloud Manager Canvas タブで、 Add a Working Environment をクリックし、クラウドとして Google Cloud Platform を選択し、システム構成のタイプを選択します。次に、 [ 次へ ] をクリックします。</block>
  <block id="da94c5003e26421e5282adb2dc7794bf" category="paragraph"><block ref="da94c5003e26421e5282adb2dc7794bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="956a76d4c71f02e39d36ada071ba66ca" category="list-text">環境名と admin クレデンシャルなど、作成する環境の詳細を指定します。完了したら、 [ 続行 ] をクリックします。</block>
  <block id="786bd072b9aad97a5bb9b71b8988a176" category="paragraph"><block ref="786bd072b9aad97a5bb9b71b8988a176" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f716cee2acaef077786ecfa7a3f8bfe7" category="list-text">データセンスとコンプライアンス、クラウドへのバックアップなど、 Cloud Volumes ONTAP 導入用のアドオンサービスを選択または選択解除します。次に、 [ 続行 ] をクリックします。</block>
  <block id="03e0c2afea8f7c3aff4a53d66784f843" category="paragraph">ヒント：アドオンサービスを無効にすると、確認のポップアップメッセージが表示されます。CVO の導入後にアドオンサービスを追加 / 削除できます。コストを回避するために、不要なサービスは最初から選択解除することを検討してください。</block>
  <block id="d784fbb10e1bdb60322e86126fe6b77a" category="paragraph"><block ref="d784fbb10e1bdb60322e86126fe6b77a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faa5bffdcdb67efcb08e91a60de40950" category="list-text">場所を選択し、ファイアウォールポリシーを選択し、チェックボックスを選択して Google Cloud ストレージへのネットワーク接続を確認します。</block>
  <block id="5eb45a43e8f46d401f435ef2b77fc946" category="paragraph"><block ref="5eb45a43e8f46d401f435ef2b77fc946" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f73472fc9b5e80548aa8910eb7b409d7" category="list-text">ライセンスオプションとして、「従量課金制」または「 BYOL for using existing license 」を選択します。この例では、 Freemium オプションが使用されています。次に、 [ 続行 ] をクリックします。</block>
  <block id="ef8c5ea172d5c008d091f693a2a4b4bd" category="paragraph"><block ref="ef8c5ea172d5c008d091f693a2a4b4bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e3f0304199574fcad7150c8cbc80cf" category="list-text">AWS SDDC 上の VMware クラウドで実行されている VM に導入されるワークロードのタイプに基づいて、複数の事前設定パッケージから選択できます。</block>
  <block id="1cd93d1b6baa56bdec898225ef3fea89" category="paragraph">ヒント：タイルの上にマウスを移動して詳細を表示したり、 [ 構成の変更 ] をクリックして CVO コンポーネントと ONTAP バージョンをカスタマイズしたりできます。</block>
  <block id="7498ab388fb0a7938d43af30f32657b5" category="paragraph"><block ref="7498ab388fb0a7938d43af30f32657b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="623ce055c6e7272198e998744efd8deb" category="list-text">[ 確認と承認 ] ページで、選択内容を確認して確定します。 Cloud Volumes ONTAP インスタンスを作成するには、 [ 移動 ] をクリックします。</block>
  <block id="fcf4e1533222260897c2613078eae18e" category="paragraph"><block ref="fcf4e1533222260897c2613078eae18e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b8217eede1f57c19d7d36c1501891b" category="list-text">Cloud Volumes ONTAP のプロビジョニングが完了すると、 [Canvas] ページの作業環境に表示されます。</block>
  <block id="37030c826a75013cff1396c6351d33c0" category="paragraph"><block ref="37030c826a75013cff1396c6351d33c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="962c53cd54b0b3876e054c2fea4c4ff8" category="section-title">SMB ボリューム用の追加の設定</block>
  <block id="9af22b589cfa398b9a704f786d96a90d" category="list-text">作業環境の準備ができたら、 CIFS サーバに適切な DNS および Active Directory 設定パラメータが設定されていることを確認します。この手順は、 SMB ボリュームを作成する前に実行する必要があります。</block>
  <block id="8f10b252acc74e058dc00a78e8c33250" category="paragraph">ヒント：メニューアイコン（ º ）をクリックし、詳細設定を選択してオプションを表示し、 CIFS のセットアップを選択します。</block>
  <block id="0cd857f422db3bb835695ca4400e7afb" category="paragraph"><block ref="0cd857f422db3bb835695ca4400e7afb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c2efcf3ec5fbe68c5a418d6b0d5ed94" category="list-text">SMB ボリュームの作成は簡単なプロセスです。キャンバスで、 Cloud Volumes ONTAP 作業環境をダブルクリックしてボリュームを作成および管理し、ボリュームの作成オプションをクリックします。適切なサイズを選択し、包含アグリゲートを選択するか、高度な割り当てメカニズムを使用して特定のアグリゲートに配置します。このデモでは、プロトコルとして CIFS/SMB が選択されます。</block>
  <block id="597899b3d186b1c50739aeb0a82a2094" category="paragraph"><block ref="597899b3d186b1c50739aeb0a82a2094" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e1a14aa082ec04534624b099e0a4bd9" category="list-text">ボリュームのプロビジョニングが完了すると、 Volumes （ボリューム）ペインにボリュームが表示されます。CIFS 共有はプロビジョニングされるため、ユーザまたはグループにファイルとフォルダに対する権限を付与し、ユーザが共有にアクセスしてファイルを作成できることを確認してください。ファイル権限とフォルダ権限はすべて SnapMirror レプリケーションの一部として保持されるため、オンプレミス環境からボリュームをレプリケートする場合はこの手順は必要ありません。</block>
  <block id="4cdd5a747f01838b94117ef6fb699278" category="paragraph">ヒント：ボリュームメニュー（ º ）をクリックすると、そのオプションが表示されます。</block>
  <block id="368cd84bdda136cebde14eea38e8a0f2" category="paragraph"><block ref="368cd84bdda136cebde14eea38e8a0f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7a0ccac4888fc1553dadeee03d7e99" category="list-text">ボリュームが作成されたら、 mount コマンドを使用してボリュームの接続手順を表示し、 Google Cloud VMware Engine 上の VM から共有に接続します。</block>
  <block id="92890420fd7a7668e3b04db90e8a2ff2" category="paragraph"><block ref="92890420fd7a7668e3b04db90e8a2ff2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5ee926d870d7b6e5ee68e0001a9db42" category="list-text">次のパスをコピーし、 Map Network Drive オプションを使用して、 Google Cloud VMware Engine で実行されている VM にボリュームをマウントします。</block>
  <block id="809f33612149b405423b98b77a13d18f" category="paragraph"><block ref="809f33612149b405423b98b77a13d18f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0895b43b6a4f7ded9ce501e420da7cae" category="paragraph">マッピングが完了すると、このマッピングに簡単にアクセスでき、 NTFS アクセス権を適切に設定できます。</block>
  <block id="2565b7a7d81a362c6b3fc5f32d83075b" category="paragraph"><block ref="2565b7a7d81a362c6b3fc5f32d83075b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="262a1d892164ab4100a969a952274934" category="section-title">Cloud Volumes ONTAP 上の LUN をホストに接続します</block>
  <block id="049f63d3d6479b8801f942e53b31cfd6" category="paragraph">Cloud Volumes ONTAP LUN をホストに接続するには、次の手順を実行します。</block>
  <block id="2fc81fae057994bbe703cb2892b727c9" category="list-text">キャンバスページで、 Cloud Volumes ONTAP 作業環境をダブルクリックしてボリュームを作成および管理します。</block>
  <block id="3a596dcd3d3dd43ed187aea6bea5842e" category="list-text">Add Volume （ボリュームの追加） &gt; New Volume （新しいボリューム）をクリックし、 iSCSI を選択して Create Initiator Group （イニシエータContinue をクリックします。 .</block>
  <block id="b5f2af2dc909b8d634ef7e8dd729c0bc" category="paragraph"><block ref="99dce170472373a603dcc6cab1306eea" category="inline-image-macro-rx" type="image"></block>
<block ref="99eed8d2ce50ff339d9bff41a9fe9a51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4296bb5afd2416d05f951e9d3380e5e4" category="list-text">ボリュームのプロビジョニングが完了したら、ボリュームメニュー（ º ）を選択し、ターゲット IQN をクリックします。iSCSI Qualified Name （ IQN ）をコピーするには、 Copy （コピー）をクリックします。ホストから LUN への iSCSI 接続をセットアップします。</block>
  <block id="5bbe705670fa05ddb0b508acf301a379" category="paragraph">Google Cloud VMware Engine 上のホストで同じ処理を実行するには、次の手順を実行します。</block>
  <block id="a730e43d2afac8730f77c3fab06bcdc0" category="list-text">Google Cloud VMware Engine でホストされている VM への RDP</block>
  <block id="c4b994ff6c03cf45471392a32ff9809b" category="list-text">［ iSCSI イニシエータのプロパティ ］ ダイアログ・ボックスを開きます ［ サーバーマネージャ ］ ＞ ［ ダッシュボード ］ ＞ ［ ツール ］ ＞ ［ iSCSI イニシエータ ］</block>
  <block id="beacd9a0aebca77f6cc20d5cab0fb37c" category="list-text">Discovery （検出）タブで、 Discover Portal （ポータルの検出）または Add Portal （ポータルの追加）をクリックし、 iSCSI ターゲットポートの IP アドレスを入力します。</block>
  <block id="c4ab0fc2a07f004fb45eacc91a07e22c" category="list-text">ターゲットタブで検出されたターゲットを選択し、ログオンまたは接続をクリックします。</block>
  <block id="4f04cc11e470becd190503a4cea0e217" category="list-text">[ マルチパスを有効にする ] を選択し、コンピュータの起動時に [ この接続を自動的に復元する ] または [ この接続をお気に入りターゲットのリストに追加する ] を選択します。Advanced （詳細設定）をクリック</block>
  <block id="ed010f49a5a1ad0895131daffcd73a3c" category="admonition">Windows ホストには、クラスタ内の各ノードへの iSCSI 接続が必要です。ネイティブ DSM では、使用する最適なパスが選択されます。</block>
  <block id="88c7456aa49f0bfe0258958c4c42a153" category="paragraph"><block ref="88c7456aa49f0bfe0258958c4c42a153" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f2340e83f93b283dd5fc7023e4e72a2" category="paragraph">Storage Virtual Machine （ SVM ）の LUN は、 Windows ホストではディスクとして表示されます。追加した新しいディスクは、ホストでは自動的に検出されません。手動の再スキャンをトリガーしてディスクを検出するには、次の手順を実行します。</block>
  <block id="d16c566049378cf49448803dfc6ab25d" category="list-text">Windows コンピュータの管理ユーティリティを開きます。 [ スタート ]&gt;[ 管理ツール ]&gt;[ コンピュータの管理 ] を選択します。</block>
  <block id="b1babb2780a260f54d7e9f21602773df" category="list-text">ナビゲーションツリーでストレージノードを展開します。</block>
  <block id="678149d88ae91abbb05c5df448a4e8af" category="list-text">[ ディスクの管理 ] をクリックします</block>
  <block id="35e2e6c4175353900be410088efcc1b9" category="list-text">［ アクション ］ &gt; ［ ディスクの再スキャン ］ の順にクリック</block>
  <block id="da663e5eac7f594bcac6564a22726142" category="paragraph"><block ref="da663e5eac7f594bcac6564a22726142" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8a056111a10f9e055d309c54e7ca2bb" category="paragraph">Windows ホストから初めてアクセスした時点では、新しい LUN にはパーティションやファイルシステムは設定されていません。LUN を初期化します。必要に応じて、次の手順を実行してファイルシステムで LUN をフォーマットします。</block>
  <block id="8db13bd6122ee1a2b04931073cb808d7" category="list-text">Windows ディスク管理を開始します。</block>
  <block id="18e601e3f0e159e918f7adb9fd89fb99" category="list-text">LUN を右クリックし、必要なディスクまたはパーティションのタイプを選択します。</block>
  <block id="605158a22ab35f7223fe6f37b0f761b7" category="list-text">ウィザードの指示に従います。この例では、ドライブ F ：がマウントされています。</block>
  <block id="74edf50412d8a6c920ebdf456ca74d6f" category="paragraph"><block ref="74edf50412d8a6c920ebdf456ca74d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8bce76f68494174fa21e44b39be75e7" category="paragraph">Linux クライアントで、 iSCSI デーモンが実行されていることを確認します。LUN のプロビジョニングが完了したら、以下の例として Ubuntu を使用した iSCSI 構成に関する詳細なガイダンスを参照してください。これを確認するには、シェルから lsblk cmd を実行します。</block>
  <block id="5800551032817b82a3780efc5c365b61" category="paragraph"><block ref="5d8610d622621cfaf5f5af9098efada8" category="inline-image-macro-rx" type="image"></block>
<block ref="0e5aea74b7dab4389459e8f03d7961e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b88883556cc41d9ed2a47bd0cfe1bb4" category="section-title">Cloud Volumes ONTAP NFS ボリュームを Linux クライアントにマウント</block>
  <block id="3a676f5d05c6d1f36341948d03289c3f" category="paragraph">Cloud Volumes ONTAP (DIY) ファイルシステムを Google Cloud VMware Engine 内の VM からマウントするには、次の手順に従います。</block>
  <block id="99ff74a348250b7148d219f224bc40b4" category="paragraph">以下の手順に従ってボリュームをプロビジョニングします</block>
  <block id="17d1d28660c0ff68f1ee26c3bc7c2e0d" category="list-text">Volumes （ボリューム）タブで、 Create New Volume （新規ボリュームの作成）をクリックします。</block>
  <block id="6fa266ccf8c1f303a7ed67b355770afb" category="list-text">[Create New Volume] ページで、ボリュームタイプを選択します。</block>
  <block id="8d7c2959a73ccf424e912497fa729dfa" category="paragraph"><block ref="8d7c2959a73ccf424e912497fa729dfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e89e2106ea79d032d48e99a6498e2584" category="list-text">ボリュームタブで、ボリューム上にマウスカーソルを置き、メニューアイコン（ º ）を選択してから、マウントコマンドをクリックします。</block>
  <block id="1367b1db6f5a641c16b673b4f75f02de" category="paragraph"><block ref="1367b1db6f5a641c16b673b4f75f02de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8a4175c7cb7e059193f8bdcafc1395b0" category="list-text">[ コピー ] をクリックします .</block>
  <block id="e059ff9407d5207f003eae103b4c7a3a" category="list-text">指定された Linux インスタンスに接続します。</block>
  <block id="b3bcde31f03d76e154f81e6b5221b007" category="list-text">Secure Shell （ SSH ）を使用してインスタンスの端末を開き、適切なクレデンシャルでログインします。</block>
  <block id="42d35ecc4606c7783372ab3953fb10d6" category="list-text">次のコマンドを使用して、ボリュームのマウントポイント用のディレクトリを作成します。</block>
  <block id="2432c695bbc97e5283e213ba846e86dc" category="paragraph"><block ref="2432c695bbc97e5283e213ba846e86dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5cbcad6705273d58a27b5b92fdc1700" category="list-text">前の手順で作成したディレクトリに Cloud Volumes ONTAP NFS ボリュームをマウントします。</block>
  <block id="f505f299a6f5e1e9f6b91adec6ef8f38" category="paragraph"><block ref="4aa22d1032194bb618fa2b2a8bbc5d82" category="inline-image-macro-rx" type="image"></block>
<block ref="73581b61100d82e506cc05faa5fc45c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f43b203ec7020e7ea0e408d9d67255fc" category="doc">Azure VMware 解決策（ AVS ）を使用した Azure NetApp Files の設定</block>
  <block id="f9a184882060f3e5a8b6045e2a53107f" category="paragraph">解決策共有は、 Azure VMware Azure NetApp Files SDDC 環境で作成された VM からマウントできます。Azure NetApp Files では SMB プロトコルと NFS プロトコルがサポートされているため、ボリュームを Linux クライアントにマウントして Windows クライアントにマッピングすることもできます。Azure NetApp Files ボリュームは、 5 つの簡単な手順で設定できます。</block>
  <block id="5bb6f16c69df9b9f54bddaaa5e32b415" category="paragraph">Azure NetApp Files と Azure VMware 解決策は、同じ Azure リージョンに配置する必要があります。</block>
  <block id="8c8b1c25fd4bcb4102a3a834f721ec3e" category="section-title">Azure NetApp Files ボリュームを作成してマウント</block>
  <block id="763b2af90e10e00124392e31d5792be5" category="paragraph">Azure NetApp Files ボリュームを作成してマウントするには、次の手順を実行します。</block>
  <block id="e56fb44cec3cde26b63f919055458c3a" category="list-text">Azure ポータルにログインし、 Azure NetApp Files にアクセスします。Azure NetApp Files サービスへのアクセスを確認し、 Azure NetApp Files リソースプロバイダを登録するには、 _az プロバイダ登録 -- namespace Microsoft.NetApp – wait_command を使用します。登録が完了したら、ネットアップアカウントを作成します。</block>
  <block id="792c2610bbb56b5803bae91a54f34f51" category="inline-link-macro">Azure NetApp Files 共有</block>
  <block id="a7ad1b2194256789e815facefa65206d" category="paragraph">詳細な手順については、を参照してください <block ref="8dd8f38a60f74263b1cf35e18285061e" category="inline-link-macro-rx"></block>。このページでは、ステップバイステップのプロセスについて説明します。</block>
  <block id="710954ec785b2a7f67c2ef1c3f2f9d19" category="paragraph"><block ref="710954ec785b2a7f67c2ef1c3f2f9d19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe57bd1c78e967b463574e3089a42968" category="list-text">ネットアップアカウントが作成されたら、必要なサービスレベルとサイズの容量プールを設定します。</block>
  <block id="3928a91ce2a9b26c809bec745d6b9daf" category="paragraph">詳細については、を参照してください <block ref="e7281cc99a6c9a39d5a16325a46f1f7c" category="inline-link-macro-rx"></block>。</block>
  <block id="7ffd44a691267afdf7cc1178ab6115f8" category="paragraph"><block ref="7ffd44a691267afdf7cc1178ab6115f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42e9b5ee697da49886fd18e89e6ab1af" category="inline-link-macro">サブネットを Azure NetApp Files に委譲します</block>
  <block id="ee13d45546639cd210b35ce3665b6885" category="list-text">Azure NetApp Files の委任されたサブネットを設定し、ボリュームを作成する際にこのサブネットを指定します。委任されたサブネットを作成する詳細な手順については、を参照してください <block ref="ad52de6b143679c946d36f9e4248f40c" category="inline-link-macro-rx"></block>。</block>
  <block id="70a08a2f18d96817bf63302571e62634" category="paragraph"><block ref="70a08a2f18d96817bf63302571e62634" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96501b128e8ffab4b107cd6ffa7da649" category="list-text">容量プールブレードの下のボリュームブレードを使用して、 SMB ボリュームを追加します。SMB ボリュームを作成する前に、 Active Directory Connector が設定されていることを確認してください。</block>
  <block id="f676bcdffa60a69ff49ba9ffdbb2b912" category="paragraph"><block ref="f676bcdffa60a69ff49ba9ffdbb2b912" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9095b4995e678294045e2a1501d1db3" category="list-text">[Review + Create] をクリックして、 SMB ボリュームを作成します。</block>
  <block id="e48925dc65abf32faa19c5d430cf6d6d" category="paragraph">アプリケーションが SQL Server の場合は、 SMB 継続的可用性を有効にします。</block>
  <block id="be1613efbff068fd23ee511fe4e6dc51" category="paragraph"><block ref="be1613efbff068fd23ee511fe4e6dc51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2b999c81e324f553ec9720c334325ee" category="paragraph"><block ref="b2b999c81e324f553ec9720c334325ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe5eed95829ff2b525461ee72a9f3f23" category="inline-link-macro">Azure NetApp Files のパフォーマンスに関する考慮事項</block>
  <block id="2c5ce17dd48f2551465b828065fd8300" category="paragraph">サイズまたはクォータ別の Azure NetApp Files ボリュームのパフォーマンスの詳細については、を参照してください <block ref="ffec162f488d413e68dfe18d328e177e" category="inline-link-macro-rx"></block>。</block>
  <block id="bef7cec065f33ededdd1b50d74800b72" category="list-text">接続が確立されると、ボリュームをマウントしてアプリケーションデータに使用できるようになります。</block>
  <block id="8b3c17098d0d024937d60849b3bd8edb" category="paragraph">これを行うには、 Azure ポータルで Volumes ブレードをクリックし、マウントするボリュームを選択して、マウント手順にアクセスします。パスをコピーし、ネットワークドライブのマッピングオプションを使用して、 Azure VMware 解決策 SDDC で実行されている VM にボリュームをマウントします。</block>
  <block id="413fcfe1d831f95cd95f8f3bb9030eec" category="paragraph"><block ref="413fcfe1d831f95cd95f8f3bb9030eec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e50c675280580c3249f58f2f3eefdb86" category="paragraph"><block ref="e50c675280580c3249f58f2f3eefdb86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13c8bc9575bbdc3a8a30021320abbd69" category="list-text">Azure VMware 解決策 SDDC で実行されている Linux VM に NFS ボリュームをマウントする場合も、同じ手順を使用します。ボリュームの形状変更機能または動的なサービスレベル機能を使用して、ワークロードの要件を満たします。</block>
  <block id="ff817c6ff423e680ddf0a8398efdfb5a" category="paragraph"><block ref="ff817c6ff423e680ddf0a8398efdfb5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da94ac228f6efdf07fe7e43b1441faf2" category="paragraph">詳細については、を参照してください <block ref="ea07f7f3cbdf3d62072fbe16546616d3" category="inline-link-macro-rx"></block>。</block>
  <block id="29f8b77f5f7c79b566706e0d55c9de8b" category="doc">Amazon VMware マネージドクラウド（ VMC ）向けネットアップソリューション</block>
  <block id="7e0686a26bc7a91429819c2aeb7b414a" category="doc">Azure VMware 解決策（ AVS ）向けネットアップソリューション</block>
  <block id="4859596b2360db2dac4c6a687efe10d2" category="doc">AWS に新しい Cloud Volumes ONTAP インスタンスを導入（自分で実行）</block>
  <block id="ddf355809a57f794eb4f9cff41a1ad86" category="paragraph">Cloud Volumes ONTAP 共有および LUN は、 AWS SDDC 環境の VMware クラウドで作成された VM からマウントできます。Cloud Volumes ONTAP では iSCSI 、 SMB 、 NFS の各プロトコルがサポートされているため、このボリュームをネイティブの AWS VM Linux Windows クライアントにマウントすることもでき、 iSCSI 経由でマウントする場合は、 Linux クライアントまたは Windows クライアントからブロックデバイスとして LUN にアクセスできます。Cloud Volumes ONTAP ボリュームは、いくつかの簡単な手順で設定できます。</block>
  <block id="091112e3dbffea1fef77b4b6bbcec4d3" category="paragraph">ディザスタリカバリや移行の目的でオンプレミス環境からクラウドにボリュームをレプリケートするには、サイト間 VPN または DirectConnect を使用して、 AWS へのネットワーク接続を確立します。オンプレミスから Cloud Volumes ONTAP へのデータのレプリケートについては、本ドキュメントでは扱いません。オンプレミスシステムと Cloud Volumes ONTAP システム間でデータをレプリケートする方法については、を参照してください <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>。</block>
  <block id="c4fab68ae07564acd6ecd9b911dfff79" category="admonition">を使用します <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Cloud Volumes ONTAP インスタンスのサイズを正確に設定します。また、オンプレミスのパフォーマンスを監視して、 Cloud Volumes ONTAP サイジングツールの入力として使用することもできます。</block>
  <block id="44ca838e7d04a1071dc78602ef005cb3" category="list-text">NetApp Cloud Central にログインします。 Fabric View 画面が表示されます。Cloud Volumes ONTAP タブを探し、 Go to Cloud Manager を選択します。ログインすると、キャンバス画面が表示されます。</block>
  <block id="6b0e3e8cb8d190a2310f526f49f7908f" category="paragraph"><block ref="6b0e3e8cb8d190a2310f526f49f7908f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="613b8a42b8ee051cdae0288a52604a55" category="list-text">Cloud Manager のホームページで、 Add a Working Environment をクリックし、 AWS をクラウドとして選択し、システム構成のタイプを選択します。</block>
  <block id="1ce9ef4a253b6301539d9cab4fca67b6" category="paragraph"><block ref="1ce9ef4a253b6301539d9cab4fca67b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1552a04c8237c4a2d938cca2db53683" category="list-text">環境名と admin クレデンシャルなど、作成する環境の詳細を指定します。Continue をクリックします。 .</block>
  <block id="525c0dbff313821edbeaa46a9b5d88dd" category="paragraph"><block ref="525c0dbff313821edbeaa46a9b5d88dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fdbae44a4deac52e923aa6480a3f1f2" category="list-text">クラウドデータセンス、クラウドバックアップ、 Cloud Insights など、 Cloud Volumes ONTAP 導入用のアドオンサービスを選択します。Continue をクリックします。 .</block>
  <block id="7191330ca38db1397356e7619c4baf63" category="paragraph"><block ref="7191330ca38db1397356e7619c4baf63" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5908a77615c1d6294f872ff6f0e9ec5c" category="list-text">HA Deployment Models ページで、 Multiple Availability Zones 設定を選択します。</block>
  <block id="e2dff93e99a18f3bbf601965a86556d3" category="paragraph"><block ref="e2dff93e99a18f3bbf601965a86556d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5eee77262911549d8a2fd262ee2a983d" category="list-text">Region &amp; VPC ページで、ネットワーク情報を入力し、 Continue をクリックします。</block>
  <block id="94a6592c275cad51dc739b4ab70338db" category="paragraph"><block ref="94a6592c275cad51dc739b4ab70338db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6f20610782706f69940c617f7154ffe" category="list-text">[Connectivity and SSH Authentication] ページで、 HA ペアとメディエータの接続方法を選択します。</block>
  <block id="d121b588f00dfd906d6291024c708f8d" category="paragraph"><block ref="d121b588f00dfd906d6291024c708f8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a012735965bc67df3b6e4c64b7b894f" category="list-text">フローティング IP アドレスを指定し、 Continue （続行）をクリックします。</block>
  <block id="bc0e2f9513cce33557343a1867d4bdfb" category="paragraph"><block ref="bc0e2f9513cce33557343a1867d4bdfb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b2221e159f51173ae2b52e02587cc42" category="list-text">フローティング IP アドレスへのルートを含める適切なルーティングテーブルを選択し、 Continue （続行）をクリックします。</block>
  <block id="5486a792746fe5fbf546c327f6be2773" category="paragraph"><block ref="5486a792746fe5fbf546c327f6be2773" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e18f42f3f9ea4d4f2e8df33f334d9939" category="list-text">Data Encryption ページで、 AWS で管理する暗号化を選択します。</block>
  <block id="143c5081e907e69e16f1df952eafae3e" category="paragraph"><block ref="143c5081e907e69e16f1df952eafae3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a25e3ac90ce2b5cc921531efdc5963e" category="list-text">ライセンスオプションとして、「従量課金制」または「 BYOL for using an existing license 」を選択します。この例では、 ［ 従量課金制 ］ オプションを使用します。</block>
  <block id="e3750564d3942e5c1d3cec322e411d5e" category="paragraph"><block ref="e3750564d3942e5c1d3cec322e411d5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df531dd5efab87543ed07d56595eca08" category="list-text">AWS SDDC 上の VMware クラウドで実行されている VM に導入するワークロードのタイプに基づいて、複数の事前設定パッケージから選択できます。</block>
  <block id="30e80bd4d8d23ac64059627389a8b348" category="paragraph"><block ref="30e80bd4d8d23ac64059627389a8b348" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce4ab7c38fc244e8d1e30dd47a1c578d" category="paragraph"><block ref="ce4ab7c38fc244e8d1e30dd47a1c578d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc498db1b5b048e74d02bcfa90076dfe" category="paragraph"><block ref="bc498db1b5b048e74d02bcfa90076dfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8427c8fe11e3a00ca10a2cf45a96dd90" category="paragraph"><block ref="8427c8fe11e3a00ca10a2cf45a96dd90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31574a22471145d2a1ea069062aa95ec" category="list-text">CVO インスタンスを選択してボリュームを作成し、 Create Volume （ボリュームの作成）オプションをクリックします。適切なサイズを選択し、包含アグリゲートを選択するか、高度な割り当てメカニズムを使用して特定のアグリゲートに配置します。このデモでは、 SMB がプロトコルとして選択されます。</block>
  <block id="d657856abbf9bb39436a3f6f849251ea" category="paragraph"><block ref="d657856abbf9bb39436a3f6f849251ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="976543d01a4b5d38482c487005aadc68" category="list-text">ボリュームのプロビジョニングが完了すると、 Volumes （ボリューム）ペインにボリュームが表示されます。CIFS 共有はプロビジョニングされるため、ユーザまたはグループにファイルおよびフォルダに対する権限を付与し、ユーザが共有にアクセスしてファイルを作成できることを確認する必要があります。</block>
  <block id="eac2d4365044c30420d99e4450f5b3da" category="paragraph"><block ref="eac2d4365044c30420d99e4450f5b3da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ea4081e5d5395a0dd61744757f9abb9" category="list-text">ボリュームが作成されたら、 mount コマンドを使用して、 AWS SDDC ホストの VMware Cloud で実行されている VM から共有に接続します。</block>
  <block id="7786302dcdbb8e27839c1d68acb8c3ba" category="list-text">次のパスをコピーし、 Map Network Drive オプションを使用して、 AWS SDDC の VMware Cloud で実行されている VM にボリュームをマウントします。</block>
  <block id="fff9636198d4c8106d5edeb1a72f789c" category="paragraph"><block ref="97606ae260ebd0d0acdf4aac70a2a0b5" category="inline-image-macro-rx" type="image"></block>
<block ref="b4382417b1dd50929cfd78b7e90bc2aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27c47ada1e7cb796a499ede048474b99" category="section-title">LUN をホストに接続します</block>
  <block id="70ac69b194f074f8b2ce79ee769a0c96" category="paragraph">Cloud Volumes ONTAP LUN をホストに接続するには、次の手順を実行します。</block>
  <block id="4a8c2e183609aa00cfce8401be26e193" category="list-text">Cloud Manager のキャンバスページで、 Cloud Volumes ONTAP 作業環境をダブルクリックしてボリュームを作成および管理します。</block>
  <block id="298c5ecf2fc7c7ab04d3ff27df17c420" category="list-text">Add Volume （ボリュームの追加） &gt; New Volume （新規ボリューム）をクリックし、 iSCSI を選択して Create Initiator Group （イニシエータグループのContinue をクリックします。 .</block>
  <block id="a3f6544e066d08b352bdd873e84efd9f" category="paragraph"><block ref="d08d8d37d464a0090209067a27ccf9bf" category="inline-image-macro-rx" type="image"></block>
<block ref="dd9a8ac9d2dee64126f68f4ab9b10f3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6297ccc26d99397b36875f005bb1b800" category="list-text">ボリュームのプロビジョニングが完了したら、ボリュームを選択し、ターゲット IQN をクリックします。iSCSI Qualified Name （ IQN ）をコピーするには、 Copy （コピー）をクリックします。ホストから LUN への iSCSI 接続をセットアップします。</block>
  <block id="c5a9ec38aba893e2a0d701ba2f45a50e" category="paragraph">AWS SDDC 上の VMware Cloud にあるホストでも同じ処理を実行するには、次の手順を実行します。</block>
  <block id="2cbe60394fdca23a31c3a05a49aba035" category="list-text">AWS の VMware クラウドでホストされる VM への RDP</block>
  <block id="213e827694caf7236290f845284dcc05" category="list-text">ターゲットタブで検出されたターゲットを選択し、ログオンまたは接続をクリックします。</block>
  <block id="04d63507299c2b866ddad09b32b37fb3" category="list-text">[ マルチパスを有効にする ] を選択し、コンピュータの起動時に [ この接続を自動的に復元する ] または [ この接続をお気に入りターゲットのリストに追加する ] を選択します。Advanced （詳細設定）をクリック</block>
  <block id="15c42f0d55e1a75b7606d8cd1d0f0840" category="paragraph">[+]<block ref="f87da6f2c46cbdbedc31faf67374f8f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11f54f9bd2797dc115ca9e98fb0116d" category="paragraph">SVM の LUN は、 Windows ホストではディスクとして表示されます。追加した新しいディスクは、ホストでは自動的に検出されません。手動の再スキャンをトリガーしてディスクを検出するには、次の手順を実行します。</block>
  <block id="733dc90ee8ecde5a3fe64fd837d0eec1" category="paragraph"><block ref="733dc90ee8ecde5a3fe64fd837d0eec1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b173d8aceed1850c1882fee5f7479d4" category="paragraph"><block ref="5b173d8aceed1850c1882fee5f7479d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1085f8441673a34397360c417066d18f" category="paragraph">Linux クライアントで、 iSCSI デーモンが実行されていることを確認します。LUN のプロビジョニングが完了したら、 Linux ディストリビューション向けの iSCSI 構成に関する詳しいガイダンスを参照してください。たとえば、 Ubuntu の iSCSI 構成が見つかります <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>。これを確認するには、シェルから lsblk cmd を実行します。</block>
  <block id="af16b968e0e3b3975cdcefb5cdd9858a" category="paragraph">Cloud Volumes ONTAP （ DIY ）ファイルシステムを VMC 内の VM から AWS SDDC にマウントするには、次の手順を実行します。</block>
  <block id="9e770ba792bd4db694940294a77cccee" category="list-text">前の手順で作成したディレクトリに、 NetApp ONTAP NFS ボリュームの Amazon FSX をマウントします。</block>
  <block id="2b9f5ac2397a7a0e82ca568de7f62512" category="paragraph"><block ref="c1b4b180fa34b46779c12a4e278fa487" category="inline-image-macro-rx" type="image"></block>
<block ref="cf487bf9f5a361811181e443893feb53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6120544c737d67dd31f47d101fe21a84" category="doc">クラウドプロバイダでの仮想化環境の設定</block>
  <block id="f4f7adb7cbe18f2cdd82be75a52b0417" category="paragraph">サポートされている各ハイパースケーラで仮想化環境を設定する方法については、こちらで詳しく説明しています。</block>
  <block id="e647d88b9bd859d2c3e943c24b4fef00" category="paragraph">オンプレミスと同様に、 VM と移行を作成する本番環境に適した VMware Cloud on AWS を計画することが重要です。</block>
  <block id="162e9e1fd4657b8d9588a5ae8c8e6e66" category="paragraph">このセクションでは、 AWS SDDC で VMware Cloud をセットアップおよび管理する方法と、ネットアップストレージの接続に使用できるオプションについて説明します。</block>
  <block id="d6d7fade0a5d1cd7723c64125e595b08" category="paragraph">セットアッププロセスは、次の手順に分けることができます。</block>
  <block id="389544cc8199f2ddd936397695d0dbe9" category="inline-link-macro">VMware Cloud for AWS を導入して設定</block>
  <block id="b4f284d3b5bb40ee91901933b8f7ef5f" category="inline-link-macro">VMware Cloud を FSX ONTAP に接続します</block>
  <block id="00ce356ad004b72efc4b99389b52af63" category="paragraph">オンプレミスと同様に、 Azure VMware 解決策を計画することは、 VM と移行を作成する本番環境に欠かせません。</block>
  <block id="491aa8f554f95207a4b7d47f89777e13" category="paragraph">このセクションでは、 Azure VMware 解決策をセットアップおよび管理する方法と、ネットアップストレージの接続に使用できるオプションについて説明します。</block>
  <block id="3d24cd3e433bf1992e011c9f92c3fab6" category="inline-link-macro">リソースプロバイダを登録し、プライベートクラウドを作成</block>
  <block id="a1123889b6465e93a2209c2a0ca667ef" category="inline-link-macro">新しい ExpressRoute 仮想ネットワークゲートウェイまたは既存の ExpressRoute 仮想ネットワークゲートウェイに接続します</block>
  <block id="ae1764c7cb70aed2d4548c424d7bf34a" category="inline-link-macro">ネットワーク接続を検証し、プライベートクラウドにアクセス</block>
  <block id="9883d049f97d69a9f2326d61585d8fbe" category="paragraph">オンプレミスと同様に、 VM と移行を作成する本番環境に成功するには、 Google Cloud VMware Engine （ GCVE ）の計画が不可欠です。</block>
  <block id="6ad49d2b544134f2192d1612a572bdd6" category="paragraph">このセクションでは、 GCVE のセットアップと管理方法、およびネットアップストレージの接続に使用できるオプションとの組み合わせについて説明します。</block>
  <block id="a74a86037d1564ce62843a1252f6ad37" category="admonition">Cloud Volume と Cloud Volumes ONTAP サービスを GCVE に接続する方法としてサポートされているのは、ゲスト内ストレージだけです。</block>
  <block id="11a31c6d83a723b3ea9c348c22e86238" category="inline-link-macro">GCVE を導入および設定します</block>
  <block id="3e5cc29621d2619be0d7b1569da6909c" category="inline-link-macro">GCVE へのプライベートアクセスを有効にします</block>
  <block id="4dab2f9796b0af6304d00e21e2b9dfb4" category="inline-link-macro">AWS 上の VMware Cloud</block>
  <block id="02b412692a538ee9dc2534f0f9c73dc1" category="paragraph"><block ref="560d5b2cd40977bd7b77b31d7088f657" category="inline-link-macro-rx"></block> AWS エコシステム内の VMware ベースのワークロードにクラウドネイティブのエクスペリエンスを提供します。各 VMware Software-Defined Data Center （ SDDC ）は Amazon Virtual Private Cloud （ VPC ）内で動作し、フル VMware スタック（ vCenter Server を含む）、 NSX ベースの Software-Defined Networking 、 VSAN ソフトウェア定義ストレージ、およびワークロードにコンピューティングリソースとストレージリソースを提供する 1 つ以上の ESXi ホストを提供します。</block>
  <block id="dc77b78f59a0c38a9a2e8927dc05e916" category="paragraph">このセクションでは、 AWS で VMware Cloud をセットアップおよび管理する方法について説明します。また、 AWS で NetApp ONTAP を使用する場合は Amazon FSX 、ゲスト内ストレージを使用する場合は Cloud Volumes ONTAP と組み合わせて使用する方法についても説明します。</block>
  <block id="3712f34e1b7039d6d9bfb255ecc54445" category="paragraph">セットアッププロセスは、次の 3 つの部分に分けることができます。</block>
  <block id="f54d8dbbc1cb20fd37a59a4563644ef8" category="inline-link-macro">Amazon Web Services アカウント</block>
  <block id="4ca1486cd3276884e41ad4b36080c10b" category="list-text">に登録します <block ref="ab3390028f6599a1b73b747febbf672d" category="inline-link-macro-rx"></block>。</block>
  <block id="020e995219c3fad42714462fc9368253" category="inline-link-macro">マイ VMware</block>
  <block id="4f87cd22b54abb602d4264ede77c75fd" category="list-text">に登録します <block ref="6fb1d438d7363efa930c55af527a6c23" category="inline-link-macro-rx"></block> アカウント：</block>
  <block id="252c0d3625c410f643362d13f1e35681" category="paragraph">まだ作成していない場合は、 AWS アカウントが必要です。新規または既存の手順では、多くの手順を実行するためにアカウント内で管理者権限が必要です。を参照してください <block ref="d01b332d778720bc2fe2a9a15e6ba01d" category="inline-link-macro-rx"></block> をクリックしてください。</block>
  <block id="e1ed167660991d514f55d806a323f3b5" category="paragraph">VMware のクラウドポートフォリオ（ AWS 上の VMware Cloud を含む）にアクセスするには、 VMware の顧客アカウントまたは My VMware アカウントが必要です。VMware アカウントをまだ作成していない場合は作成します <block ref="aefb6f511cceca70505b3e5bf76155fe" category="inline-link-macro-rx"></block>。</block>
  <block id="60fa505f14fb504e941cbc61b74d644a" category="section-title">VMware Cloud で SDDC をプロビジョニングします</block>
  <block id="6d931b72d8efc3fd87b7fdd5127cbba7" category="paragraph">VMware アカウントを設定して適切なサイジングを実行したら、 AWS サービスで VMware Cloud を使用するための次の一歩として Software-Defined Data Center を導入します。SDDC を作成するには、そのホストとして AWS リージョンを選択し、 SDDC に名前を付け、 SDDC に含める ESXi ホストの数を指定します。AWS アカウントがない場合でも、単一の ESXi ホストを含むスターター構成の SDDC を作成できます。</block>
  <block id="7e70ad389301fa9d8936c18cefd85b53" category="list-text">既存または新規に作成した VMware クレデンシャルを使用して、 VMware Cloud Console にログインします。</block>
  <block id="28570a642842f2bfa7db5cc3679fd904" category="paragraph"><block ref="28570a642842f2bfa7db5cc3679fd904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53722f60844c899c63607413f74e8dd8" category="list-text">AWS のリージョン、導入環境、およびホストタイプと SDDC 名を設定します。</block>
  <block id="5ec07ba481e6291d3af5e3ca61f27f57" category="paragraph"><block ref="5ec07ba481e6291d3af5e3ca61f27f57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5c464b97b208b8c43e9fdd315c80793" category="list-text">目的の AWS アカウントに接続し、 AWS クラウド形成スタックを実行します。</block>
  <block id="b6822d593b3a1b683cb4e513b210c080" category="paragraph"><block ref="941b74b5e4d054f44fb05f89bfb30732" category="inline-image-macro-rx" type="image"></block>
<block ref="5ca301c5ba248bc9f9566d74470fcc6b" category="inline-image-macro-rx" type="image"></block>
<block ref="54108005ae53e37fa06b081374d6ea43" category="inline-image-macro-rx" type="image"></block>
<block ref="9f7f4a317cf9d46aa6a2aa8f441279ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59e9afc055ce73e7e6154ea7609eec59" category="admonition">この検証ではシングルホスト構成を使用します。</block>
  <block id="3f68cef60baccc27cfef6b618e56f809" category="list-text">VMC 環境を接続する AWS VPC を選択します。</block>
  <block id="49e131b27a342d4970e86a31a127d41c" category="paragraph"><block ref="49e131b27a342d4970e86a31a127d41c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="102a37b9412553c4ae6b25a174592fbb" category="list-text">VMC 管理サブネットを構成します。このサブネットには、 vCenter や NSX などの VMC 管理サービスが含まれます。SDDC 環境への接続が必要な他のネットワークと重複するアドレス空間を選択しないでください。最後に、以下に示す CIDR サイズの推奨事項に従います。</block>
  <block id="0e8db488f9554136a65dd18025db8cf0" category="paragraph"><block ref="0e8db488f9554136a65dd18025db8cf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a541610269aad8edaf8defd851246b08" category="list-text">SDDC 構成を確認して承認し、 [Deploy the SDDC] をクリックします。</block>
  <block id="a8246981b8dc3e6123523500b3b1371d" category="paragraph"><block ref="a8246981b8dc3e6123523500b3b1371d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bb7bef7f28887197cfca7059ef2d6d3" category="paragraph">導入プロセスの完了には、通常約 2 時間かかります。</block>
  <block id="e9dcc1b6680c77f105c83d040009d685" category="paragraph"><block ref="e9dcc1b6680c77f105c83d040009d685" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79b6ae1d041f5cd8b33d3f351b301275" category="list-text">完了すると、 SDDC を使用できるようになります。</block>
  <block id="9013490d3a116eed1c849197a6c8aac0" category="paragraph"><block ref="9013490d3a116eed1c849197a6c8aac0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e149dd16e33c6137fe08782e96c9b226" category="inline-link-macro">VMC コンソールから SDDC を展開します</block>
  <block id="086760513a416fbc6578703211523314" category="paragraph">SDDC の導入の詳細な手順については、を参照してください <block ref="7279ebe13e8b8c4ee89b8961f2bf1157" category="inline-link-macro-rx"></block>。</block>
  <block id="1d583a1a8ff1ca8ae3360c7e33ecd984" category="doc">Azure に新しい Cloud Volumes ONTAP を導入</block>
  <block id="ed1019c297fadb83e87437230788320c" category="paragraph">解決策共有および LUN は、 Azure VMware Cloud Volumes ONTAP SDDC 環境で作成された VM からマウントできます。Cloud Volumes ONTAP は iSCSI 、 SMB 、 NFS の各プロトコルをサポートしているため、このボリュームは Linux クライアントおよび Windows クライアントにもマウントできます。Cloud Volumes ONTAP ボリュームは、いくつかの簡単な手順で設定できます。</block>
  <block id="e9cac40069a313b824541cda06c18a06" category="paragraph">ディザスタリカバリや移行の目的でオンプレミス環境からクラウドにボリュームをレプリケートするには、サイト間 VPN または ExpressRoute を使用して、 Azure へのネットワーク接続を確立します。オンプレミスから Cloud Volumes ONTAP へのデータのレプリケートについては、本ドキュメントでは扱いません。オンプレミスシステムと Cloud Volumes ONTAP システム間でデータをレプリケートする方法については、を参照してください <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>。</block>
  <block id="1563f27024f7b2b0a96be687f878206d" category="paragraph"><block ref="1563f27024f7b2b0a96be687f878206d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f067fbf4a3196796318f7e878eaa2a3" category="list-text">Cloud Manager のホームページで、 Add a Working Environment をクリックし、クラウドとして Microsoft Azure を選択し、システム構成のタイプを選択します。</block>
  <block id="e59c8066b7736d6ede98e2b57d619b60" category="paragraph"><block ref="e59c8066b7736d6ede98e2b57d619b60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21568dd1e2a5acafeee9d119cd012876" category="list-text">Cloud Volumes ONTAP の最初の作業環境を作成する際、 Cloud Manager はコネクタの導入を求めます。</block>
  <block id="4c3665ca095a8a103c69fac1ac46fb59" category="paragraph"><block ref="4c3665ca095a8a103c69fac1ac46fb59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54ae357a0d5e74ebab86e52641490fc0" category="list-text">コネクタが作成されたら、 [ 詳細（ Details ） ] および [ 資格情報（ Credentials ） ] フィールドを更新します。</block>
  <block id="9b971596a6ee599483fd04c84d2ce18d" category="paragraph"><block ref="9b971596a6ee599483fd04c84d2ce18d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf5341803b0061ef190495343f39fa02" category="list-text">環境名と admin クレデンシャルなど、作成する環境の詳細を指定します。オプションのパラメータとして、 Azure 環境のリソースグループタグを追加します。完了したら、 [ 続行 ] をクリックします。</block>
  <block id="350a5c2219e5e14fd23dda8372344842" category="paragraph"><block ref="350a5c2219e5e14fd23dda8372344842" category="inline-image-macro-rx" type="image"></block></block>
  <block id="360a69a0b184770c2409949f2c7e1140" category="list-text">クラウドデータセンス、クラウドバックアップ、 Cloud Insights など、 Cloud Volumes ONTAP 導入用のアドオンサービスを選択します。サービスを選択し、 Continue （続行）をクリックします。</block>
  <block id="11728d9ffc9e6944adf4891d5543e154" category="paragraph"><block ref="11728d9ffc9e6944adf4891d5543e154" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ee060e03da823e605453fbfa27743d77" category="list-text">Azure の場所と接続を設定します。使用する Azure のリージョン、リソースグループ、 VNet 、およびサブネットを選択します。</block>
  <block id="4549d76a3daf0d322686b6d4f6fb1490" category="paragraph"><block ref="4549d76a3daf0d322686b6d4f6fb1490" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1c88093dde70f0165ade30b74c908ad" category="list-text">ライセンスオプションとして、「従量課金制」または「 BYOL for using existing license 」を選択します。この例では、 ［ 従量課金制 ］ オプションを使用します。</block>
  <block id="10085b1c84507f0da366d741a248d728" category="paragraph"><block ref="10085b1c84507f0da366d741a248d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2c782d387cdd1de07d0119c2794edc8" category="list-text">さまざまなタイプのワークロードに使用できる事前設定されたパッケージをいくつか選択できます。</block>
  <block id="942b902e3715b75e8e6257349bbe93ff" category="paragraph"><block ref="942b902e3715b75e8e6257349bbe93ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c7055bfbaac9b0236d0bedccfb616d0" category="list-text">サポートのアクティブ化と Azure リソースの割り当てに関する 2 つの契約に同意します。 Cloud Volumes ONTAP インスタンスを作成するには、 Go をクリックします。</block>
  <block id="c19dadb8117ac0d88e543accbb1c1096" category="paragraph"><block ref="c19dadb8117ac0d88e543accbb1c1096" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6bb322a7578acfb8670b3ce8bc96fc9" category="paragraph"><block ref="b6bb322a7578acfb8670b3ce8bc96fc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02cbbc24385dbe83fb42a1bd0c5668da" category="paragraph"><block ref="02cbbc24385dbe83fb42a1bd0c5668da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d923f79d8112841c7df8503e86f0af4a" category="list-text">SMB ボリュームの作成は簡単なプロセスです。CVO インスタンスを選択してボリュームを作成し、 Create Volume （ボリュームの作成）オプションをクリックします。適切なサイズを選択し、包含アグリゲートを選択するか、高度な割り当てメカニズムを使用して特定のアグリゲートに配置します。このデモでは、 SMB がプロトコルとして選択されます。</block>
  <block id="a74d409c32c4bc504768c6a7607fc409" category="paragraph"><block ref="a74d409c32c4bc504768c6a7607fc409" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8923d310a6b50c677ed6f68410181b46" category="paragraph"><block ref="8923d310a6b50c677ed6f68410181b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="776a8d832701253eb40b056e68086fcd" category="list-text">ボリュームが作成されたら、 mount コマンドを使用して、 Azure VMware 解決策 SDDC ホストで実行されている VM から共有に接続します。</block>
  <block id="70307f46aa9c37929516c971f3445caa" category="list-text">次のパスをコピーし、ネットワークドライブのマッピングオプションを使用して、 Azure VMware 解決策 SDDC で実行されている VM にボリュームをマウントします。</block>
  <block id="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="paragraph"><block ref="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d1f50043685559ea05d7c21ae5a6d8a" category="paragraph"><block ref="1d1f50043685559ea05d7c21ae5a6d8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e7b38e3108ed39835e616f3a8eef4d9" category="paragraph">LUN をホストに接続するには、次の手順を実行します。</block>
  <block id="06fcf6729491b5106094916e154fb565" category="paragraph"><block ref="06fcf6729491b5106094916e154fb565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7af0094f03c81886be499600b8563647" category="paragraph">Azure VMware 解決策 SDDC にあるホストでも同じ処理を実行するには、次の手順を実行します。</block>
  <block id="640e587a72f6b61dc8d20a6de477db96" category="list-text">Azure VMware 解決策 SDDC にホストされている VM への RDP</block>
  <block id="2d5b864b177738fa7a03f083ae03d2a3" category="paragraph">* 注： * Windows ホストからクラスタ内の各ノードへの iSCSI 接続が確立されている必要があります。ネイティブ DSM では、使用する最適なパスが選択されます。</block>
  <block id="829bd9f13853ee7a86f5805c316df650" category="paragraph"><block ref="829bd9f13853ee7a86f5805c316df650" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d378c726809748df2090ec116c7232b4" category="paragraph"><block ref="d378c726809748df2090ec116c7232b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b3a58a7b9961d5d214b65da735d2f89" category="list-text">ウィザードの指示に従います。この例では、ドライブ E ：がマウントされています</block>
  <block id="586f9ee0f7d5544a894ea05b9df312d7" category="paragraph"><block ref="586f9ee0f7d5544a894ea05b9df312d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ff716a75c3423262418c90aad971f10" category="paragraph"><block ref="6ff716a75c3423262418c90aad971f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e3fe132749fe21d23cf75f00317a6fe" category="doc">AWS で VMware Cloud を使用して、 NetApp ONTAP 用に Amazon FSX を設定します</block>
  <block id="5f19d821dc2e2e3a8e9418909df59733" category="paragraph">Amazon FSX for NetApp ONTAP ファイル共有および LUN は、 AWS の VMware クラウドにある VMware SDDC 環境内で作成された VM からマウントできます。また、このボリュームは、 Linux クライアントにマウントして NFS または SMB プロトコルを使用して Windows クライアントにマッピングすることもできます。また、 iSCSI 経由でマウントした場合、 Linux クライアントまたは Windows クライアントから LUN にブロックデバイスとしてアクセスできます。NetApp ONTAP ファイルシステム用の Amazon FSX は、次の手順ですばやく設定できます。</block>
  <block id="190b27040d3191ccf35bdb35221f0682" category="admonition">パフォーマンスを向上させ、アベイラビリティゾーン間でのデータ転送料金を回避するには、 NetApp ONTAP 向け Amazon FSX と AWS 上の VMware Cloud を同じアベイラビリティゾーンに配置する必要があります。</block>
  <block id="f8caa19e45e4a42ea7bc10cad5d49ae8" category="section-title">ONTAP ボリューム用に Amazon FSX を作成してマウントします</block>
  <block id="e765d7d83fde51af5391c87cc45dccf2" category="paragraph">NetApp ONTAP ファイルシステム用に Amazon FSX を作成してマウントするには、次の手順を実行します。</block>
  <block id="43935f267f64b4ca1a3f1803272df64b" category="inline-link-macro">Amazon FSX コンソール</block>
  <block id="4d33567207f0232b86c9bec4b4f38d45" category="list-text">を開きます <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block> ファイルシステムの作成を選択して ' ファイルシステム作成ウィザードを開始します</block>
  <block id="df08dda7dc18ddb7de0e9ad5001a9f04" category="list-text">[Select File System Type] ページで、 [Amazon FSX for NetApp ONTAP ] を選択し、 [Next] をクリックします。Create File System ページが表示されます。</block>
  <block id="c40ea60211b89b2179fe7a947527ff66" category="paragraph"><block ref="c40ea60211b89b2179fe7a947527ff66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f29804f0e866cb47ba2fa233a71a54fd" category="list-text">Virtual Private Cloud （ VPC ；仮想プライベートクラウド）のネットワークセクションで、ルーティングテーブルとともに適切な VPC と優先サブネットを選択します。この場合、ドロップダウンから vmcfsx2.vPC が選択されます。</block>
  <block id="628892e49fa967795d4d8d3269c5bb31" category="paragraph"><block ref="628892e49fa967795d4d8d3269c5bb31" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf9c04e1d81f05e344db236ac47ea588" category="list-text">作成方法として、標準作成を選択します。[ クイック作成 ] を選択することもできますが、このドキュメントでは [ 標準作成 ] オプションを使用します。</block>
  <block id="e3c13c0fe612a941f86617c0ad730fca" category="paragraph"><block ref="e3c13c0fe612a941f86617c0ad730fca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e47c53bc440aebf2328e497b46953118" category="paragraph"><block ref="e47c53bc440aebf2328e497b46953118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed02b1594feb57e5c5c1ca0678086dd" category="list-text">「セキュリティと暗号化」セクションの「暗号化キー」で、ファイルシステムの保存データを保護する AWS Key Management Service （ AWS KMS ）暗号化キーを選択します。File System Administrative Password に、 fsxadmin ユーザのセキュアなパスワードを入力します。</block>
  <block id="450514d9ec3a47df8e580605e80579b7" category="paragraph"><block ref="450514d9ec3a47df8e580605e80579b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b969656105cc9174e398fa5754382d5b" category="list-text">仮想マシンで、 vsadmin で REST API または CLI を使用して ONTAP を管理するために使用するパスワードを指定します。パスワードを指定しない場合は、 SVM の管理に fsxadmin ユーザを使用できます。Active Directory セクションで、 SMB 共有をプロビジョニングするために Active Directory を SVM に追加してください。Default Storage Virtual Machine Configuration セクションで、この検証でストレージの名前を指定します。 SMB 共有は自己管理 Active Directory ドメインを使用してプロビジョニングされます。</block>
  <block id="0b0a8d3b6da586b1c3d7ace81f086743" category="paragraph"><block ref="0b0a8d3b6da586b1c3d7ace81f086743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89a8b582feabb26f60740f7b0a57aaef" category="list-text">Default Volume Configuration セクションで、ボリュームの名前とサイズを指定します。これは NFS ボリュームです。Storage Efficiency の場合、 ONTAP の Storage Efficiency 機能（圧縮、重複排除、コンパクション）をオンにするには Enabled を、オフにするには Disabled を選択します。</block>
  <block id="2cfdc5814e94a8d05a802a6b639158b7" category="paragraph"><block ref="2cfdc5814e94a8d05a802a6b639158b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59ed30f46b9afae4f90b77ac3ed74f8e" category="list-text">Create File System ページに表示されるファイルシステム設定を確認します。</block>
  <block id="08ef5aaea85c8112d5d0e368443ee4fe" category="list-text">ファイルシステムの作成をクリックします。</block>
  <block id="d385818e8551a5f93e9591daf3cf7c22" category="paragraph"><block ref="aae4a315cf943820b378b71447a7994a" category="inline-image-macro-rx" type="image"></block>
<block ref="e34db9249abae41534adba1bed16b8d1" category="inline-image-macro-rx" type="image"></block>
<block ref="f1c6728d54b85d98dd49bf5dc91e4f97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f5cc47067a5c4b536ab91f1a843de82" category="inline-link-macro">Amazon FSX for NetApp ONTAP の利用を開始する</block>
  <block id="e37ec80b6a23f377fd957d8c83c7a7b5" category="paragraph">詳細については、を参照してください <block ref="01eec31289b39ab7b89a00515912c371" category="inline-link-macro-rx"></block>。</block>
  <block id="af62c8c40f4b51eaee5cfbcfdb7bffaa" category="paragraph">上記のようにファイルシステムを作成したら、必要なサイズとプロトコルでボリュームを作成します。</block>
  <block id="5eb9e90ab2c5435bcefd918c8c8a7304" category="list-text">を開きます <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block>。</block>
  <block id="4cdc643691b84580850903954cdca1d1" category="list-text">左側のナビゲーションペインで、 [ ファイルシステム ] を選択し、ボリュームを作成する ONTAP ファイルシステムを選択します。</block>
  <block id="05c0eed2abbd9c20871b6af0eb7b1e38" category="list-text">Volumes （ボリューム）タブを選択します。</block>
  <block id="511e546bcb3da3ea3db700200e857ebf" category="list-text">Create Volume （ボリュームの作成）タブを選択します。</block>
  <block id="328a4173ff8b40f0204a78c6a579b01e" category="list-text">Create Volume （ボリュームの作成）ダイアログボックスが表示されます。</block>
  <block id="b1734fefd5bf5fc9e481a277d683ca10" category="paragraph">デモ用として、このセクションで NFS ボリュームを作成します。このボリュームは、 AWS 上の VMware クラウドで実行されている VM に簡単にマウントできます。nfsdemovol01 は次のように作成されます。</block>
  <block id="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="paragraph"><block ref="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72e172d843c1baf9acb881337f0bb2cc" category="section-title">FSX ONTAP ボリュームを Linux クライアントにマウントします</block>
  <block id="682dccf32ec3d6c1e1ca2548a43c4245" category="paragraph">前の手順で作成した FSX ONTAP ボリュームをマウントします。AWS SDDC 上の VMC 内の Linux VM から、次の手順を実行します。</block>
  <block id="a8dc83c93fa2350d1419b44103864f2c" category="list-text">Secure Shell （ SSH ）を使用してインスタンスの端末を開き、適切なクレデンシャルを使用してログインします。</block>
  <block id="454d9d1fe6ad680e393543d5e7b11669" category="list-text">次のコマンドを使用して、ボリュームのマウントポイント用のディレクトリを作成します。</block>
  <block id="6631f82f4a955cf7fe5644adadf79e47" category="paragraph"><block ref="6631f82f4a955cf7fe5644adadf79e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2774f9046ee4873805e1f044fa12fe85" category="list-text">実行したら、 df コマンドを実行してマウントを検証します。</block>
  <block id="d06051412d6da4495ca1a69429ea4fdf" category="paragraph"><block ref="d06051412d6da4495ca1a69429ea4fdf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0927b028b8b35cb7421cd2d29ebac0ab" category="section-title">FSX ONTAP ボリュームを Microsoft Windows クライアントに接続します</block>
  <block id="49a305dd021166bf8a508fb51b3fce24" category="paragraph">Amazon FSX ファイルシステム上のファイル共有を管理およびマッピングするには、共有フォルダ GUI を使用する必要があります。</block>
  <block id="0f51d6ad9d95d24bf6d5b0e18d947382" category="list-text">[ スタート ] メニューを開き、 [ 管理者として実行 ] を使用して fsmgmt.msc を実行します。これにより、共有フォルダ GUI ツールが開きます。</block>
  <block id="0186f9c0fa21b0c8ab82fadf036afe8f" category="list-text">アクション &gt; すべてのタスクをクリックし、別のコンピュータに接続を選択します。</block>
  <block id="f5cf362d19da392bad46d1cb4bbea453" category="list-text">別のコンピュータの場合は、 Storage Virtual Machine （ SVM ）の DNS 名を入力します。たとえば、 FSXSMBTESTING01.FSXTESTING.LOCAL はこの例で使用されています。</block>
  <block id="882da317003fa80717e3939e41c5aa32" category="admonition">TP が Amazon FSX コンソールで SVM の DNS 名を検索し、 Storage Virtual Machines を選択してから、 endpoints までスクロールして SMB DNS 名を検索します。[OK] をクリックします。共有フォルダのリストに Amazon FSX ファイルシステムが表示されます。</block>
  <block id="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="paragraph"><block ref="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd517d0d40877562e2dae460910a5260" category="list-text">共有フォルダツールの左ペインで [ 共有 ] を選択すると、 Amazon FSX ファイルシステムのアクティブな共有が表示されます。</block>
  <block id="e4fb530e581118e4aa66166f33242547" category="paragraph"><block ref="e4fb530e581118e4aa66166f33242547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b994a2e22edf9cb0de792e6a494da514" category="list-text">新しい共有を選択し、共有フォルダの作成ウィザードを完了します。</block>
  <block id="9630a309cdca9ed17b688fe15c03a200" category="paragraph"><block ref="f821d910b54d4df166bfb6c9a0fbeac1" category="inline-image-macro-rx" type="image"></block>
<block ref="1456921fb33e6c835f2ea077607c478a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed3796b20dc1d1a4f1756d0cb0f45489" category="inline-link-macro">SMB 共有の作成</block>
  <block id="dc77f3b6074a456c2be3f16b862db081" category="paragraph">Amazon FSX ファイルシステムでの SMB 共有の作成と管理の詳細については、を参照してください <block ref="a85495f11ff3e696252abf798d30d57d" category="inline-link-macro-rx"></block>。</block>
  <block id="470140537c670eb8edb32bf6e8b2bad5" category="list-text">接続が確立されると、 SMB 共有を接続してアプリケーションデータに使用できるようになります。これを行うには、共有パスをコピーし、 Map Network Drive オプションを使用して、 AWS SDDC 上の VMware Cloud で実行されている VM にボリュームをマウントします。</block>
  <block id="0542af5401c04588abf9b665f31829b6" category="paragraph"><block ref="0542af5401c04588abf9b665f31829b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6c5856c2845517bb6408529fb90b57e" category="section-title">iSCSI を使用して、 NetApp ONTAP LUN の FSX をホストに接続します</block>
  <block id="716fd43b3bc7735b075d056d4ac18dc4" category="paragraph">FSX の iSCSI トラフィックは、前のセクションで説明したルートを介して、 VMware Transit Connect/AWS Transit Gateway を経由します。NetApp ONTAP 用に Amazon FSX 内の LUN を設定するには、該当するマニュアルを参照してください <block ref="70da71f7286decf7407c5db884b5344a" category="inline-link-macro-rx"></block>。</block>
  <block id="32139f76f200f13f9078d49f80c95815" category="paragraph">Linux クライアントでは、 iSCSI デーモンが実行されていることを確認します。LUN のプロビジョニングが完了したら、（例として） Ubuntu を使用した iSCSI 構成に関する詳細なガイダンスを参照してください。 <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>。</block>
  <block id="102b54837bec429c2bc9f3f9fee8a857" category="paragraph">このドキュメントでは、 iSCSI LUN を Windows ホストに接続する方法を示します。</block>
  <block id="29980d065df6792c6cf2015646e8744d" category="section-title">NetApp ONTAP の FSX で LUN をプロビジョニングします。</block>
  <block id="6da38655de350d44c878e17adb0fd12c" category="list-text">ONTAP ファイルシステムの FSX の管理ポートを使用して、 NetApp ONTAP CLI にアクセスします。</block>
  <block id="6f8dec9d607d68b3712504d90548dc7f" category="list-text">サイジング結果から得られるように、必要なサイズの LUN を作成します。</block>
  <block id="c31d63ac510efc7c433e07d70ef0a11a" category="paragraph">この例では、 5g （ 5368709120 ）の LUN を作成しました。</block>
  <block id="e3de6fee1eaf0d0777dc125d42255a4b" category="list-text">必要な igroup を作成して、どのホストが特定の LUN にアクセスできるかを制御します。</block>
  <block id="8c92602adf53776d90c46162f150dd3c" category="paragraph">2 つのエントリが表示されました。</block>
  <block id="e71def0bc16c2989d418764ced77c368" category="list-text">次のコマンドを使用して、 LUN を igroup にマッピングします。</block>
  <block id="fd29357379ec9a1916e7512ba9cba2d5" category="list-text">新しくプロビジョニングした LUN を Windows VM に接続します。</block>
  <block id="15bea41b01d7287439a04eb0c57a5ef5" category="paragraph">AWS SDDC 上の VMware クラウド上にある Windows ホストに新しい LUN の接続を行うには、次の手順を実行します。</block>
  <block id="eabaddae6242a6352bd11a6bdf29b55a" category="list-text">AWS SDDC 上の VMware Cloud でホストされる Windows VM への RDP</block>
  <block id="debd85c1c5da22a2c5e207ae0ad4b91a" category="list-text">サーバーマネージャ &gt; ダッシュボード &gt; ツール &gt; iSCSI イニシエータと進み、 iSCSI イニシエータのプロパティダイアログボックスを開きます。</block>
  <block id="43237019bec64292757878b08a9d1a63" category="list-text">[ マルチパスを有効にする ] を選択し、 [ コンピュータの起動時にこの接続を自動的に復元する ] または [ この接続をお気に入りターゲットのリストに追加する ] を選択します。Advanced （詳細設定）をクリック</block>
  <block id="6aa775ce454f9bfcd13c7e20b90531e7" category="paragraph"><block ref="6aa775ce454f9bfcd13c7e20b90531e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc2a4ed37392086accdd3db98b75509" category="paragraph">Storage Virtual Machine （ SVM ）の LUN は、 Windows ホストではディスクとして表示されます。追加した新しいディスクは、ホストでは自動的に検出されません。手動の再スキャンをトリガーしてディスクを検出するには、次の手順を実行します。</block>
  <block id="3ba2e4c8502f30b8e6d44fc88ebe784a" category="paragraph"><block ref="3ba2e4c8502f30b8e6d44fc88ebe784a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="405bdc4379d9776fbda741356a79c543" category="paragraph">Windows ホストから初めてアクセスした時点では、新しい LUN にはパーティションやファイルシステムは設定されていません。LUN を初期化し、必要に応じて、次の手順を実行してファイルシステムで LUN をフォーマットします。</block>
  <block id="848c01bbaad78639e22ba05626884091" category="paragraph"><block ref="848c01bbaad78639e22ba05626884091" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e1c36a2c24e0aaf7844ec890c15e430" category="paragraph">主要なハイパースケーラにおけるネットアップストレージサポートの組み合わせを理解している。</block>
  <block id="c567300e15e9f9b873771e56c72c938b" category="admonition">1- 現在プライベートプレビュー中です</block>
  <block id="6a3b9d31df0a58cc23207c2af925ef0f" category="paragraph">Azure VMware 解決策を使用するには、まず、特定されたサブスクリプションにリソースプロバイダを登録します。</block>
  <block id="58c59ab4d5d488609913efa7b1daaa31" category="list-text">Azure ポータルにサインインします。</block>
  <block id="5d704d400396fefbe3427ee665a0ec16" category="list-text">Azure ポータルのメニューで、すべてのサービスを選択します。</block>
  <block id="eff35df9bedc80337261af1399e526a2" category="list-text">[ すべてのサービス ] ダイアログボックスで、サブスクリプションを入力し、 [ サブスクリプション ] を選択します。</block>
  <block id="41825376d695df481d13f37e3e1587db" category="list-text">表示するには、サブスクリプションリストからサブスクリプションを選択します。</block>
  <block id="4d3e5a69b8f8c0bec64cf18db73fff95" category="list-text">[ リソースプロバイダ ] を選択し、検索結果に「 Microsoft.AVS 」と入力します。</block>
  <block id="2bf384915bc11a9360bdf9792dc43bf3" category="list-text">リソースプロバイダが登録されていない場合は、 [ 登録 ] を選択します。</block>
  <block id="0b4b8a7bf2e1e647f3be6dde423b9b79" category="paragraph"><block ref="0b4b8a7bf2e1e647f3be6dde423b9b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb08f4992bb541aec19da4c688d0239" category="paragraph"><block ref="bdb08f4992bb541aec19da4c688d0239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="382da60e8008eed186472cc1a3c3ca37" category="list-text">リソースプロバイダの登録が完了したら、 Azure ポータルを使用して Azure VMware 解決策プライベートクラウドを作成します。</block>
  <block id="397065cbdc87787d17122a18f5c5088d" category="list-text">新規リソースを作成を選択する。</block>
  <block id="39d2b5824a6dce05a74b5a60d5769656" category="list-text">[Search the Marketplace] テキストボックスに Azure VMware 解決策と入力し、検索結果から選択します。</block>
  <block id="d090262ac8690f612cbc8bd5fc83b11c" category="list-text">Azure VMware 解決策ページで、 Create を選択します。</block>
  <block id="4a62c7a4f3f3f4a3927621c33c12bb63" category="list-text">[ 基本設定 ] タブのフィールドに値を入力し、 [ レビュー ] 、 [ 作成 ] の順に選択します。</block>
  <block id="2a01d572b1447155c310cabafac3fae9" category="paragraph">注：</block>
  <block id="7c1ec568c35f8a03d9cfd64b465a4e4f" category="list-text">クイックスタートのために、計画フェーズで必要な情報を収集します。</block>
  <block id="d61ffacba4094067e86b90bcf3739fcf" category="list-text">既存のリソースグループを選択するか、プライベートクラウド用の新しいリソースグループを作成します。リソースグループは、 Azure リソースを導入および管理する論理コンテナです。</block>
  <block id="81d6141ddb9ac3b3888dce83fbf00cf6" category="list-text">CIDR アドレスが一意で、他の Azure Virtual Network やオンプレミスネットワークと重複しないことを確認してください。CIDR はプライベートクラウド管理ネットワークであり、 vCenter Server や NSX Manager などのクラスタ管理サービスに使用されます。ネットアップでは、 /22 アドレススペースを使用することを推奨します。この例では、 10.21.0.0/22 が使用されています。</block>
  <block id="266811324b3ca32d24624ba571c07de8" category="paragraph"><block ref="266811324b3ca32d24624ba571c07de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd710e77504d5568fd5079361107a7eb" category="paragraph">プロビジョニングプロセスには約 4~5 時間かかります。プロセスが完了したら、 Azure ポータルからプライベートクラウドにアクセスして、導入が成功したことを確認します。導入が完了すると、「成功しました」のステータスが表示されます。</block>
  <block id="411f20742da0d4f8cdc568d7aee8fab3" category="paragraph">Azure VMware 解決策プライベートクラウドには Azure Virtual Network が必要です。Azure VMware 解決策はオンプレミスの vCenter をサポートしていないため、既存のオンプレミス環境と統合するには追加の手順が必要です。ExpressRoute 回線および仮想ネットワークゲートウェイのセットアップも行う必要があります。クラスタのプロビジョニングが完了するのを待っている間に、新しい仮想ネットワークを作成するか、既存の仮想ネットワークを使用して Azure VMware 解決策に接続します。</block>
  <block id="aa86eba8b2b706f81a805eb35b834541" category="paragraph"><block ref="aa86eba8b2b706f81a805eb35b834541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7714bc43e9a27f2c98a38e6b6d7f3d8" category="doc">パブリッククラウドプロバイダ向けのネットアップストレージオプション</block>
  <block id="8db50e5729f7a5d770aaceef947a2982" category="paragraph">主要な 3 種類のハイパースケーラにおけるストレージとしてのネットアップのオプションをご確認ください。</block>
  <block id="60ce80493de8468bdfd597af1c219a9f" category="paragraph">AWS は、次の構成でネットアップストレージをサポートします。</block>
  <block id="5f18b04dd7d7089a2177c4c930d8d57f" category="paragraph">Azure は、以下の構成でネットアップストレージをサポートします。</block>
  <block id="74eb4c6138d4b8cd8399b01966c5af28" category="section-title">GCP のネットアップストレージオプション</block>
  <block id="8f08ff97ca555f50f0d05fdf950a0568" category="paragraph">Google Cloud は、次の構成でネットアップストレージをサポートします。</block>
  <block id="5c2d9a62bb25b00981f59e22e27bfd17" category="doc">ネットワーク接続を検証し、 Azure VMware 解決策プライベートクラウドにアクセスします</block>
  <block id="40228f700f5965975e4aff8c6c2ff4b3" category="paragraph">Azure VMware 解決策では、オンプレミスの VMware vCenter でプライベートクラウドを管理することはできません。代わりに、ジャンプホストが Azure VMware 解決策 vCenter インスタンスに接続する必要があります。指定したリソースグループにジャンプホストを作成し、 Azure VMware 解決策 vCenter にサインインします。このジャンプホストは、接続用に作成された同じ仮想ネットワーク上の Windows VM であり、 vCenter と NSX Manager の両方にアクセスできる必要があります。</block>
  <block id="d88c36b93ae5dcb2646d56c57f27bf0e" category="paragraph"><block ref="d88c36b93ae5dcb2646d56c57f27bf0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44f5524c6ac4144dbabf7a4d365b837b" category="paragraph">仮想マシンをプロビジョニングしたら、 Connect オプションを使用して RDP にアクセスします。</block>
  <block id="443f53614721177f7c44df93d426a919" category="paragraph"><block ref="443f53614721177f7c44df93d426a919" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36cb4e54805ffde727ffbc809183608e" category="paragraph">新しく作成したジャンプホスト仮想マシンから、クラウド管理者ユーザを使用して vCenter にサインインします。クレデンシャルにアクセスするには、 Azure ポータルにアクセスし、（プライベートクラウド内の管理オプションで） Identity に移動します。プライベートクラウド vCenter と NSX Manager の URL とユーザー資格情報は、ここからコピーできます。</block>
  <block id="9620acd59a8e7ad0f318754391c40c4e" category="paragraph"><block ref="9620acd59a8e7ad0f318754391c40c4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73d88630b730fa00c46338a0aef4c2d3" category="paragraph">Windows 仮想マシンでブラウザを開き、 vCenter Web Client の URL にアクセスします <block ref="2db127a24dc88638a76677b404bda5a4" category="inline-link-rx"></block> admin ユーザのユーザ名に「 * cloudadmin@vsphere.loca l * 」と入力し、コピーしたパスワードを貼り付けます。同様に、 Web クライアントの URL を使用して NSX Manager にアクセスすることもできます <block ref="bb142e18a679100de3817fcefaa25b07" category="inline-link-rx"></block> admin ユーザ名を使用し、コピーしたパスワードを貼り付けて新しいセグメントを作成したり、既存の階層ゲートウェイを変更したりできます。</block>
  <block id="4a6e0ba5b4d42fb0f658bdfdbbea32fc" category="admonition">Web クライアントの URL は、プロビジョニングされる SDDC ごとに異なります。</block>
  <block id="49848931415b32db238a2dd1daddf3a7" category="paragraph"><block ref="49848931415b32db238a2dd1daddf3a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f65f698ac6bac1ada03193e1cdabb8" category="paragraph"><block ref="87f65f698ac6bac1ada03193e1cdabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec3eeb836273dbc92b27ce718a90b212" category="inline-link-macro">オンプレミス環境から Azure VMware 解決策へのピアリング</block>
  <block id="097529edf2feb9ed1237427eaa3b2599" category="paragraph">これで、 Azure VMware 解決策 SDDC の導入と設定が完了しました。ExpressRoute グローバルリーチを活用して、オンプレミス環境を Azure VMware 解決策プライベートクラウドに接続します。詳細については、を参照してください <block ref="29749340a5d7bf5df1867a3f2d2723a1" category="inline-link-macro-rx"></block>。</block>
  <block id="ae6569fd64694b91a054cbdfdfef84d2" category="paragraph">新しい Azure Virtual Network （ VNet ）を作成するには、 Azure VNet Connect （ Azure VNet 接続）タブを選択します。または、 Create Virtual Network ウィザードを使用して、 Azure ポータルから手動で作成することもできます。</block>
  <block id="34b04201ae997eaabb6802b04d5c1708" category="list-text">Azure VMware 解決策プライベートクラウドに移動し、管理オプションで接続にアクセスします。</block>
  <block id="da40ae630b63a930be4e1230efc306e1" category="list-text">Azure VNet Connect を選択します。</block>
  <block id="40292c219898a1253befc6301234575a" category="list-text">新しい VNet を作成するには、 Create New オプションを選択します。</block>
  <block id="f98e10d9ba9ac83ac2adeacde774d051" category="paragraph">この機能により、 VNet を Azure VMware 解決策プライベートクラウドに接続できます。VNet は、 ExpressRoute 経由で Azure VMware 解決策で作成されたプライベートクラウドに必要なコンポーネント（ジャンプボックス、 Azure NetApp Files などの共有サービス、クラウドボリューム ONTAP など）を自動的に作成することで、この仮想ネットワークのワークロード間の通信を有効にします。</block>
  <block id="0314a97a9eb0aae73531717ef45ad195" category="paragraph">* 注： * VNet アドレス空間はプライベートクラウド CIDR と重複しないようにしてください。</block>
  <block id="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="paragraph"><block ref="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="inline-image-macro-rx" type="image"></block></block>
  <block id="206843027dd7ebe90f425f9ee4765a01" category="list-text">新しい VNet の情報を入力または更新し、 OK を選択します。</block>
  <block id="26c6d54522f3fd79684f463116e9634b" category="paragraph"><block ref="26c6d54522f3fd79684f463116e9634b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="027524e66bad6099279342bf8d8f6dd4" category="paragraph">指定したアドレス範囲とゲートウェイサブネットを使用した VNet は、指定したサブスクリプションとリソースグループに作成されます。</block>
  <block id="5ecf2fb7501138eaa14be97a59d2a773" category="inline-link-macro">Azure で VMware プライベートクラウド用のネットワークを設定します</block>
  <block id="5da6ff60860f48de7bb7f4467c28f26f" category="admonition">VNet を手動で作成する場合は、適切な SKU と ExpressRoute をゲートウェイタイプとして使用して仮想ネットワークゲートウェイを作成します。導入が完了したら、認証キーを使用して、 ExpressRoute 接続を、 Azure VMware 解決策プライベートクラウドを含む仮想ネットワークゲートウェイに接続します。詳細については、を参照してください <block ref="4807c1aea8c93bde3104bd4ecfa22a07" category="inline-link-macro-rx"></block>。</block>
  <block id="d77d7a022616e70a9987aa0974241779" category="paragraph">プライベートクラウドのプロビジョニングが完了したら、プライベートクラウドへのプライベートアクセスを設定して、高スループットで低レイテンシのデータパス接続を実現します。</block>
  <block id="256431e41a96deb49bcd86b1ca56393e" category="inline-link-macro">GCP ドキュメント</block>
  <block id="e4cf8d7f33a9dafc85be0439cd8fbc4d" category="paragraph">これにより、 Cloud Volumes ONTAP インスタンスが実行されている VPC ネットワークが、 GCVE プライベートクラウドと通信できるようになります。これを行うには、に従ってください <block ref="9cd64b8fb1b43e7f674c1b78b2a86f74" category="inline-link-macro-rx"></block>。クラウドボリュームサービスの場合は、テナントホストプロジェクト間で 1 回限りのピアリングを実行して、 VMware エンジンと Cloud Volumes Service 間の接続を確立します。詳細な手順については、次の手順を実行してください <block ref="04a9f04edfdd7b0a53da57f015378c5a" category="inline-link-macro-rx"></block>。</block>
  <block id="e6945148d9a888e52db99c5ebce86868" category="paragraph"><block ref="e6945148d9a888e52db99c5ebce86868" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3eb3a1c6330fe124fc0706cbdd91df" category="paragraph">CloudOwner@gve.loca ユーザを使用して vCenter にサインインします。クレデンシャルにアクセスするには、 VMware Engine ポータルにアクセスし、 Resources にアクセスして、適切なプライベートクラウドを選択します。[Basic info] セクションで、 vCenter ログイン情報（ vCenter Server 、 HCX Manager ）または NSX ログイン情報（ NSX Manager ）の [View] リンクをクリックします。</block>
  <block id="6f32389268763bedb9e6716b5f0973d0" category="paragraph"><block ref="6f32389268763bedb9e6716b5f0973d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ec2407381a4f65d228483b566b6907f" category="paragraph">Windows 仮想マシンでブラウザを開き、 vCenter Web Client の URL にアクセスします <block ref="d325f0342d122dda054a3ca8b0c44019" category="inline-link-rx"></block> admin ユーザのユーザ名として CloudOwner@gve.loca を使用し、コピーしたパスワードを貼り付けます。同様に、 Web クライアントの URL を使用して NSX Manager にアクセスすることもできます <block ref="c694eb5be92097a8fdea8cdda0ad5ea5" category="inline-link-rx"></block> admin ユーザ名を使用し、コピーしたパスワードを貼り付けて新しいセグメントを作成したり、既存の階層ゲートウェイを変更したりできます。</block>
  <block id="3a9cff0eb1abb119c1c264dbfff216f6" category="paragraph">オンプレミスネットワークから VMware Engine プライベートクラウドに接続する場合は、クラウド VPN または Cloud Interconnect を利用して適切な接続を行い、必要なポートが開いていることを確認します。詳細な手順については、次の手順を実行してください <block ref="6fe8ac83365e22e24c5c8eb9edc2d548" category="inline-link-macro-rx"></block>。</block>
  <block id="b433f901707e7fd0f6d64371dfca4af9" category="paragraph"><block ref="b433f901707e7fd0f6d64371dfca4af9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="989afab9e0dfcc6d523ddb1d23145834" category="paragraph"><block ref="989afab9e0dfcc6d523ddb1d23145834" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c0dd0de38e3c9e55ef5f52e46641376" category="doc">VMware Engine を使用して Cloud Volumes Service を設定します</block>
  <block id="8e12272d11d90cdb919c737591f398f6" category="paragraph">Cloud Volumes Service 共有は、 VMware エンジン環境で作成された VM からマウントできます。Cloud Volumes Service では SMB プロトコルと NFS プロトコルがサポートされているため、ボリュームを Linux クライアントにマウントして Windows クライアントにマッピングすることもできます。Cloud Volumes Service ボリュームは簡単な手順で設定できます。</block>
  <block id="992031e7435f44536a649bfc9de30683" category="paragraph">Cloud Volume Service と Google Cloud VMware Engine のプライベートクラウドは同じリージョンに配置する必要があります。</block>
  <block id="a0c391dc49c440fc9962168353cedde3" category="inline-link-macro">ガイド</block>
  <block id="e9676faeb0b33249abc3a47d95e55ed8" category="paragraph">Google Cloud Marketplace で NetApp Cloud Volumes Service for Google Cloud を購入、有効化、設定するには、次の手順を実行します <block ref="c9eb1a9870bc9f20357f50bf16ec5704" category="inline-link-macro-rx"></block>。</block>
  <block id="84c877bb77a313d307054a0824ffff03" category="section-title">CVS NFS ボリュームを GCVE プライベートクラウドに作成する</block>
  <block id="1ec5bbc38708de3f8cfad6d6ca608742" category="paragraph">NFS ボリュームを作成してマウントするには、次の手順を実行します。</block>
  <block id="ca5470246976d59ea6a32d3e2094059d" category="list-text">Google クラウドコンソール内のパートナーソリューションから Cloud Volume にアクセスします。</block>
  <block id="45ab48bbbad4380f09ef6b41f9eb8f8a" category="paragraph"><block ref="45ab48bbbad4380f09ef6b41f9eb8f8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46577653160772df2b1548b726d7c9ce" category="list-text">Cloud Volume コンソールで、 Volumes （ボリューム）ページに移動し、 Create （作成）をクリックします。</block>
  <block id="4a43547530a8ef079adc80160de3dde9" category="paragraph"><block ref="4a43547530a8ef079adc80160de3dde9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="825700271a3acfeaf96fa0bfb5f15b65" category="list-text">[Create File System] ページで、チャージバックメカニズムに必要なボリューム名と課金ラベルを指定します。</block>
  <block id="8a81559c79124aa1a1cd2093faed73ee" category="paragraph"><block ref="8a81559c79124aa1a1cd2093faed73ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4bbe773302576667095a132b75c48fc" category="list-text">適切なサービスを選択します。GCVE は、 CVS パフォーマンスと希望するサービスレベルを選択して、アプリケーションワークロードの要件に基づいてレイテンシの向上とパフォーマンスの向上を実現します。</block>
  <block id="184fe9f42c4d5eaab1cc6079778040c2" category="paragraph"><block ref="184fe9f42c4d5eaab1cc6079778040c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492d6cb3c36c984d9f52d9461c5b69b" category="list-text">ボリュームおよびボリュームパスに Google Cloud のリージョンを指定（プロジェクト内のすべての Cloud Volume でボリュームパスが一意である必要があります）</block>
  <block id="594c2b024401023acd7deae8f3cb8ceb" category="paragraph"><block ref="594c2b024401023acd7deae8f3cb8ceb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4b0697a6c38463b0b06d7dc66b16b74" category="list-text">ボリュームのパフォーマンスレベルを選択します。</block>
  <block id="aebc437f9bb3656c19ecebe1becc99fa" category="paragraph"><block ref="aebc437f9bb3656c19ecebe1becc99fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd9c26fe6b5f33ab2b0002050ff831d8" category="list-text">ボリュームのサイズとプロトコルのタイプを指定します。このテストでは、 NFSv3 が使用されています。</block>
  <block id="e5ba61d9c8c666d452e9e78256762019" category="paragraph"><block ref="e5ba61d9c8c666d452e9e78256762019" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3a8099bd03f7da2c641e049e354ea1" category="list-text">この手順では、ボリュームにアクセスできる VPC ネットワークを選択します。VPC ピアリングが実行されていることを確認します。</block>
  <block id="d3dba730ef6d3f046910d94696ca086d" category="paragraph">ヒント： VPC ピアリングが行われていない場合は、ピアリングコマンドの説明を示すポップアップボタンが表示されます。Cloud Shell セッションを開き、適切なコマンドを実行して、 Cloud Volumes Service プロデューサーと VPC をピアリングします。事前に VPC ピアリングを準備する場合は、以下の手順を参照してください。</block>
  <block id="ecf942f7df1f072f5910afb3fa45f36e" category="paragraph"><block ref="ecf942f7df1f072f5910afb3fa45f36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ed1352ea98f362074fa7855ec6bb89c" category="list-text">適切なルールを追加してエクスポートポリシールールを管理し、対応する NFS バージョンのチェックボックスを選択します。</block>
  <block id="3ae650d16c298e2f5dc9e005a2f8934a" category="paragraph">注：エクスポートポリシーを追加しないと、 NFS ボリュームへのアクセスは許可されません。</block>
  <block id="2f6d29a5c21fb51bb181c4b97241a955" category="paragraph"><block ref="2f6d29a5c21fb51bb181c4b97241a955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a194552e035de341a4a7c99a1c687956" category="list-text">[ 保存 ] をクリックしてボリュームを作成します。</block>
  <block id="fe18028768c2ffc16d5cb32aa5b70d5b" category="paragraph"><block ref="fe18028768c2ffc16d5cb32aa5b70d5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3588b0992732355d67655af9f6450c5d" category="section-title">VMware Engine で実行されている VM に NFS エクスポートをマウントする</block>
  <block id="87397baf86d56e19a3bdac712966da5d" category="paragraph">NFS ボリュームのマウントを準備する前に、プライベート接続のピアステータスが Active と表示されていることを確認してください。ステータスが Active になったら、 mount コマンドを使用します。</block>
  <block id="c9f09539bbf502703a4f5e2d480a5972" category="paragraph">NFS ボリュームをマウントするには、次の手順を実行します。</block>
  <block id="726f902a0b5536d71345114fb942d81b" category="list-text">クラウドコンソールで、 Cloud Volume &gt; Volumes に移動します。</block>
  <block id="1feaf778ab1cf141cf92a316d53e1365" category="list-text">Volumes （ボリューム）ページに移動します</block>
  <block id="76d2df71caae5e1ec3f81822829504f5" category="list-text">NFS エクスポートをマウントする NFS ボリュームをクリックします。</block>
  <block id="4fc82f44f951748bf462898e43d08054" category="list-text">右にスクロールし、 [ 詳細を表示 ] の下にある [ 指示のマウント ] をクリックします。</block>
  <block id="692afb2fddb72a6cfc89dd1df12945ab" category="paragraph">VMware VM のゲスト OS 内からマウントプロセスを実行するには、次の手順を実行します。</block>
  <block id="2c7df76595ada01b5b08659283021aa7" category="list-text">SSH クライアントと SSH を使用して仮想マシンに接続します。</block>
  <block id="2b64d099377e2935e786009804205feb" category="list-text">インスタンスに NFS クライアントをインストールします。</block>
  <block id="d8aa2b3304fc65e5fd1cae735194aef6" category="list-text">Red Hat Enterprise Linux または SUSE Linux インスタンスの場合：</block>
  <block id="d610fa6d370a8d35fb4c26359f086aa0" category="list-text">Ubuntu または Debian のインスタンスで次の手順を実行します。</block>
  <block id="9bc2e27c16ca55bfc1a7ba94b91a21dc" category="list-text">「 /nimCVSNFSol01 」などの新しいディレクトリをインスタンスに作成します。</block>
  <block id="9e21b9d85251decc0982b75506826828" category="paragraph"><block ref="9e21b9d85251decc0982b75506826828" category="inline-image-macro-rx" type="image"></block></block>
  <block id="174714918db1cc87ef113e3087cba5da" category="list-text">適切なコマンドを使用してボリュームをマウントします。ラボで使用するコマンドの例を次に示します。</block>
  <block id="1ec7767a139a3f95923511d7bf547a6c" category="paragraph"><block ref="811572ed35d4b134bc0d7769dd80ab6c" category="inline-image-macro-rx" type="image"></block>
<block ref="b780e126200cb608d0de968e965e9c71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3df234dd2e63d779a2d017bb1ef3375d" category="section-title">VMware Engine で実行されている VM に SMB 共有を作成してマウントします</block>
  <block id="400db805dd1f9fc929e5bf72fafb1661" category="paragraph">SMB ボリュームの場合は、 SMB ボリュームを作成する前に、 Active Directory 接続が設定されていることを確認してください。</block>
  <block id="94f9379544859ae4d8990b84731870aa" category="paragraph"><block ref="94f9379544859ae4d8990b84731870aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c62a73033a0e9f64b5b2b311ded0cc5" category="paragraph">AD 接続が確立されたら、必要なサービスレベルを指定してボリュームを作成します。適切なプロトコルを選択する以外に、 NFS ボリュームを作成する手順は同じです。</block>
  <block id="228ba1c797822b63cd7c6f54ca40b87e" category="paragraph"><block ref="228ba1c797822b63cd7c6f54ca40b87e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54cd15dd2d6121aa16f0b4b87b46ef2a" category="list-text">適切なサービスを選択します。GCVE として、 CVS パフォーマンスと希望するサービスレベルを選択し、ワークロード要件に基づいてレイテンシの向上とパフォーマンスの向上を実現します。</block>
  <block id="b8eb8307790a9b22c2f6997c097b344e" category="paragraph"><block ref="b8eb8307790a9b22c2f6997c097b344e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb91d5f8a608e41cd1f217e30a536437" category="paragraph"><block ref="cb91d5f8a608e41cd1f217e30a536437" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e5a0a3c08f102d8c49c1d811b71d97f" category="paragraph"><block ref="7e5a0a3c08f102d8c49c1d811b71d97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d1a06f98a1c133a8a0c74cc4222e23b" category="list-text">ボリュームのサイズとプロトコルのタイプを指定します。このテストでは、 SMB を使用します。</block>
  <block id="6eb5a9152f38c77efc6d14902aa7dec8" category="paragraph"><block ref="6eb5a9152f38c77efc6d14902aa7dec8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">手順</block>
  <block id="15adcf662b8b92c623f4256a65f605ed" category="paragraph">ヒント： VPC ピアリングが行われていない場合は、ピアリングコマンドの説明を示すポップアップボタンが表示されます。Cloud Shell セッションを開き、適切なコマンドを実行して、 Cloud Volumes Service プロデューサーと VPC をピアリングします。事前に VPC ピアリングを準備する場合は、こちらを参照してください <block ref="3b4469537a7b14dcfd28e3d301600ff6" category="inline-link-macro-rx"></block>。</block>
  <block id="7f88d48c3b0283642fe6b1f3f061d0fd" category="paragraph"><block ref="7f88d48c3b0283642fe6b1f3f061d0fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ac40323c41c29fb75f6e19c4c683e47" category="paragraph"><block ref="8ac40323c41c29fb75f6e19c4c683e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4990031dcfbd871d95ce4ae0321e7156" category="paragraph">SMB ボリュームをマウントするには、次の手順を実行します。</block>
  <block id="fd78728be3a82142558c815267b8daa0" category="list-text">SMB 共有をマッピングする SMB ボリュームをクリックします。</block>
  <block id="58dc78a5cd30078188f7c605e636a975" category="paragraph">VMware VM の Windows ゲスト OS からマウントプロセスを実行するには、次の手順を実行します。</block>
  <block id="3dcb4e26f80951bdb3beeb0a03a3ba83" category="list-text">[ スタート ] ボタンをクリックし、 [ コンピュータ ] をクリックします。</block>
  <block id="202bba1ab43a099f57e49b350eb2ad1a" category="list-text">[ ネットワークドライブの割り当て ] をクリックします。</block>
  <block id="7dea65bdd8e9fbcd8a5b7249c71e1f0b" category="list-text">[ ドライブ ] リストで、使用可能な任意のドライブ文字をクリックします。</block>
  <block id="695179e494f30a851f80409f824a80f8" category="list-text">フォルダボックスに、次のように入力します。</block>
  <block id="2653f3365feaf0a8bf80106cba1b9ad8" category="paragraph"><block ref="2653f3365feaf0a8bf80106cba1b9ad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cd95358048d9f5d18cf70f66126e1e7" category="paragraph">コンピュータにログオンするたびに接続するには、 [ サインイン時に再接続 ] チェックボックスをオンにします。</block>
  <block id="7968f043139de8ff0e5df4451c437426" category="list-text">完了をクリックします。</block>
  <block id="8902b5e2f0c169ccf7ad8b5c335531e5" category="paragraph"><block ref="8902b5e2f0c169ccf7ad8b5c335531e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="415be703c228d9c6838b18850a1d9f31" category="paragraph">ほとんどの IT 組織は、ハイブリッドクラウドファーストアプローチに準拠しています。このような組織は変革の段階にあり、お客様は現在の IT 環境を評価してから、評価と調査の演習に基づいてワークロードをクラウドに移行しています。</block>
  <block id="346972233965e89cf5b17c3907b35f86" category="paragraph">クラウドに移行するお客様の要因には、柔軟性とバースト性、データセンターの終了、データセンターの統合、サポート終了シナリオ、合併、 買収など。この移行の理由は、各組織とそれぞれのビジネス上の優先事項によって異なります。ハイブリッドクラウドに移行する際は、クラウドの導入と柔軟性を最大限に活用するために、クラウドに最適なストレージを選択することがきわめて重要です。</block>
  <block id="0c4a16ed987359b14dc407a858d1a78e" category="section-title">パブリッククラウドの VMware Cloud オプション</block>
  <block id="9789f0612fda153726aa8ad87265e4b9" category="section-title">Azure VMware 解決策の略</block>
  <block id="d788a5499d320b05602a6a0805c81403" category="image-alt">AVS</block>
  <block id="c7b818b90803789a74058cfb4396383d" category="paragraph">Azure VMware 解決策は、 Microsoft Azure パブリッククラウド内で VMware データセンターを完全に機能させるハイブリッドクラウドサービスです。Azure VMware 解決策は、 Microsoft がフルマネージドでサポートし、 VMware が Azure インフラを活用して検証した、ファーストパーティ製解決策です。つまり、 Azure VMware 解決策を導入すると、お客様のコンピューティング仮想化向けに VMware の ESXi を、ハイパーコンバージドストレージ用に vSAN を、 さらに NSX は、ネットワークとセキュリティを実現するだけでなく、 Microsoft Azure のグローバルプレゼンス、クラスをリードするデータセンター施設を活用し、ネイティブの Azure サービスとソリューションの豊富なエコシステムに近接しています。</block>
  <block id="22b0614f106e2b7c956c60c8fc0d35c3" category="image-alt">VM C</block>
  <block id="8641a2440fc22db60ec877f3a8946fa2" category="paragraph">VMware Cloud on AWS は、 VMware のエンタープライズクラスの SDDC ソフトウェアを AWS クラウドに提供し、ネイティブ AWS サービスへのアクセスを最適化します。VMware Cloud Foundation を基盤とする VMware Cloud on AWS は、 VMware のコンピューティング、ストレージ、ネットワーク仮想化製品（ VMware vSphere 、 VMware vSAN 、 VMware NSX ）と VMware vCenter Server の管理を統合し、専用の柔軟性の高いベアメタル AWS インフラストラクチャ上で実行できるように最適化されています。</block>
  <block id="8cb69aa5b1609d0a39f0fcd576c07df6" category="section-title">Google Cloud VMware Engine</block>
  <block id="5292de1147a4b3a1d5c63d057c4b0096" category="image-alt">「 gcve 」</block>
  <block id="1ffd600a1d8e07fe3b4bca16ae02167c" category="paragraph">Google Cloud VMware Engine は、 Google Cloud の高性能で拡張性の高いインフラストラクチャと VMware Cloud Foundation スタック（ VMware vSphere 、 vCenter 、 VSAN 、 NSX ）を基盤とした IaaS （ Infrastructure-as-a-Service ）ですこのサービスにより、アプリケーションの再構築やツールの再構築にかかるコスト、労力、リスクを伴わずに、クラウドへの迅速な移行を実現し、既存の VMware ワークロードをオンプレミス環境から Google Cloud Platform にシームレスに移行または拡張できます。VMware と緊密に連携して Google が販売およびサポートするサービスです。</block>
  <block id="3310d189628fa6ef843aac57894a6db2" category="admonition">SDDC プライベートクラウドと NetApp Cloud Volume コロケーション施設は、最小限のネットワークレイテンシで最高のパフォーマンスを提供します。</block>
  <block id="c771fce16e2ba5df07df53cc5ab0748f" category="section-title">ご存知ですか？</block>
  <block id="8bba30129de0461b328be1e49f02b4d9" category="paragraph">VMware SDDC を導入する際、使用するクラウドに関係なく、最初のクラスタには次の製品が含まれます。</block>
  <block id="7110e7a8682a9bc1c7105b83fe0cd9ea" category="list-text">コンピューティングの仮想化に使用する VMware ESXi ホストと、管理用の vCenter Server アプライアンス</block>
  <block id="7d7a80e207de2136f4f19820758703fc" category="list-text">各 ESXi ホストの物理ストレージ資産を組み込んだ VMware vSAN ハイパーコンバージドストレージ</block>
  <block id="d2852e9d73c0ef81033c835719128b81" category="list-text">管理のために NSX Manager クラスタを使用した仮想ネットワークとセキュリティのための VMware NSX</block>
  <block id="afb91ca7e7763c77e44a41cb5ad0f78b" category="paragraph">ストレージを大量に消費するワークロードをホストし、クラウドホスト型の VMware 解決策でスケールアウトする場合、デフォルトのハイパーコンバージドインフラでは、コンピューティングリソースとストレージリソースの両方で拡張を行う必要があります。</block>
  <block id="fdb27bea654a8d874baecced2be84a1b" category="paragraph">Azure NetApp Files 、 NetApp ONTAP 向け Amazon FSX 、 Cloud Volumes ONTAP （ 3 つの主要ハイパースケーラすべてに対応）、 Cloud Volumes Service for Google Cloud などの NetApp Cloud Volume と統合することで、お客様はストレージを個別に拡張できるオプションを利用できるようになりました。 また、必要に応じてコンピューティングノードを SDDC クラスタに追加します。</block>
  <block id="a752c3529f0285d457f3b33b3c80d9a4" category="list-text">VMware では、アンバランスなクラスタ構成を推奨していません。そのため、ストレージを拡張するとホストが増え、 TCO が増加します。</block>
  <block id="c231690c8e9fabbd819ec1805becb157" category="list-text">アプリケーションの要件、パフォーマンス、コストに合わせて複数のパフォーマンス階層を提供するオプションはありません。</block>
  <block id="5d4c92ddd5fe9a6044b25c17d3368207" category="list-text">クラスタホスト上に構築された VSAN のストレージ容量の制限に非常に簡単に到達できます。NetApp Cloud Volume を使用して、アクティブなデータセットをホストするか、またはティアクーラデータを永続的ストレージにホストするかに応じてストレージを拡張できます。</block>
  <block id="c1cf68955de5fa20274b29fa4a2a863f" category="paragraph">Azure NetApp Files 、 NetApp ONTAP 向け Amazon FSX 、 Cloud Volumes ONTAP （ 3 つの主要なハイパースケーラすべてで利用可能）、および Cloud Volumes Service for Google Cloud は、ゲスト VM と組み合わせて使用できます。このハイブリッドストレージアーキテクチャは、ゲストオペレーティングシステムとアプリケーションバイナリデータを保持する VSAN データストアで構成されます。アプリケーションデータは、ゲストベースの iSCSI イニシエータを介して VM に接続されます。または、 Amazon FSX for NetApp ONTAP 、 Cloud Volume ONTAP 、 Azure NetApp Files 、 Cloud Volumes Service for Google Cloud と直接通信する NFS/SMB マウントを使用して VM に接続されます。この構成では、 VSAN と同様にストレージ容量の問題を簡単に解決できます。使用可能な空きスペースは、使用する余裕容量およびストレージポリシーによって異なります。</block>
  <block id="1a5208bfffc624ccf99dfcbbf2078050" category="paragraph">次に、 AWS 上の VMware Cloud 上の 3 ノード SDDC クラスタについて考えてみましょう。</block>
  <block id="fab7fb31baaec1ccac4fe688e1a4c5d4" category="list-text">3 ノード SDDC の合計物理容量は 31.1TB （各ノードのおおよその 10TB ）です。</block>
  <block id="ca189b47c3a1dfe1adbd1519688e4cc8" category="list-text">追加のホストが追加される前に保持されるスラックスペース = 25% = （ .25 x 31.1TB ） = 7.7TB 。</block>
  <block id="999b2c719df3f3e524bb10fb76521726" category="list-text">余裕期間を計算した後の使用可能な物理容量 = 23.4TB</block>
  <block id="2e1f3b31385d3304e1cda70b9cd8ed4c" category="list-text">使用可能な有効な空きスペースは、適用するストレージポリシーによって異なります。</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">例：</block>
  <block id="2f5e6d9b0a4708c4d137ba14ac704a7b" category="list-text">RAID 0 = 有効な空きスペース = 23.4TB （使用可能な物理容量 / 1 ）</block>
  <block id="df6b502d4d7283ef27d3821b69836c2d" category="list-text">RAID 1 = 有効な空きスペース = 11.7TB （使用可能な物理容量 / 2 ）</block>
  <block id="921c660c11d4880048f3ef723f079e17" category="list-text">RAID 5 = 有効な空きスペース = 17.5TB （使用可能な物理容量 / 1.33 ）</block>
  <block id="e3bdc3102c3de4f73860c229550bc6f4" category="paragraph">そのため、 NetApp Cloud Volume をゲスト接続ストレージとして使用すると、パフォーマンスとデータ保護の要件を満たしながら、ストレージを拡張して TCO を最適化できます。</block>
  <block id="571c0d425ce03c2532e7d9f34ca87cb1" category="section-title">覚えておいてください</block>
  <block id="8e6eaed3852a3b311ab6ed1b8b6fc239" category="list-text">ハイブリッドストレージモデルでは、ホスト自体にも近接しているため、特定のレイテンシ要件に対処するために、 VSAN データストアにティア 1 または高優先度のワークロードを配置します。トランザクションのレイテンシが許容されるワークロード VM には、ゲスト内メカニズムを使用します。</block>
  <block id="43ff7a71a2ea2fc47a29d410cd1e4944" category="list-text">NetApp SnapMirror ® テクノロジを使用して、オンプレミスの ONTAP システムから Cloud Volumes ONTAP または Amazon FSX for NetApp ONTAP にワークロードデータをレプリケートすることで、ブロックレベルのメカニズムによって移行を簡易化できます。これは、 Azure NetApp Files および Cloud Volume サービスには適用されません。Azure NetApp Files または Cloud Volume サービスにデータを移行するには、使用するファイルプロトコルに応じて、 NetApp XCP 、 Cloud Sync 、 rysnc 、 robocopy を使用してください。</block>
  <block id="d3c0fd4b510310b9bd00463208eade94" category="list-text">テストでは、該当する SDDC からストレージにアクセスする際のレイテンシが 2 ～ 4 ミリ秒増加しました。ストレージをマッピングする際には、このレイテンシをアプリケーション要件に考慮してください。</block>
  <block id="b83cf0bc9b65a0fcd5f49d4c96dceea8" category="list-text">テストフェイルオーバーおよび実際のフェイルオーバー時にゲスト接続ストレージをマウントする場合は、 iSCSI イニシエータが再設定されていること、 SMB 共有の DNS が更新されていること、および NFS マウントポイントが fstab で更新されていることを確認してください。</block>
  <block id="1b4048870ed334dbc2e7d6f09a814188" category="list-text">ゲスト内の Microsoft Multipath I/O （ MPIO ；マルチパス I/O ）、ファイアウォール、ディスクタイムアウトのレジストリ設定が VM 内で適切に設定されていることを確認します。</block>
  <block id="00b23e82efc2ec82b134496e575a934c" category="section-title">ネットアップのクラウドストレージのメリット</block>
  <block id="80def6ec4d999fc4d082800c8c33f6ec" category="paragraph">ネットアップのクラウドストレージには次のようなメリットがあります。</block>
  <block id="2e594db552f7cd9c7f02d87507dbb471" category="list-text">コンピューティングとストレージの別々にストレージを拡張できるため、コンピューティングとストレージの密度が向上します。</block>
  <block id="479f9f236fc4cffa74f2e94b654bbeeb" category="list-text">ホスト数を削減し、全体的な TCO を削減できます。</block>
  <block id="108dd736471686a2b8b87154d73cbc5b" category="list-text">コンピューティングノードの障害は、ストレージのパフォーマンスには影響しません。</block>
  <block id="a85e0a264279b851fbcec367c181932e" category="list-text">Azure NetApp Files のボリュームの形状変更と動的なサービスレベル機能を使用すると、安定状態のワークロードのサイジングによってコストを最適化し、オーバープロビジョニングを防止できます。</block>
  <block id="4e24ca7789e0b9320e302b8efa2caf9f" category="list-text">Cloud Volumes ONTAP の Storage Efficiency 、クラウド階層化、インスタンスタイプの変更機能を使用すると、ストレージの追加や拡張を最適な方法で行うことができます。</block>
  <block id="d7a87fa8fc914cf57f38eff05d53faa2" category="list-text">ストレージリソースのオーバープロビジョニングは、必要な場合にのみ発生します。</block>
  <block id="940eacbcb0faa8c3b1e0d995c154f693" category="list-text">効率的な Snapshot コピーとクローンにより、パフォーマンスに影響を与えることなく迅速にコピーを作成できます。</block>
  <block id="a9e4a9fcd1f9bf0a9d0d0b2c0f198db5" category="list-text">Snapshot コピーからの迅速なリカバリを使用して、ランサムウェア攻撃に対処できます。</block>
  <block id="caf9b805c37cab661d4e3a26b7f71109" category="list-text">複数のリージョン間で効率的なブロック転送ベースのリージョナルディザスタリカバリと統合されたバックアップブロックレベルを提供することで、 RPO と RTO が向上します。</block>
  <block id="658fb5ef00749e8af5a974f612adea9b" category="section-title">前提条件</block>
  <block id="a9e63f2a8549d717b777806268a0c0cb" category="list-text">SnapMirror テクノロジやその他の関連するデータ移行メカニズムが有効になっている。オンプレミスから任意のハイパースケーラクラウドまで、さまざまな接続オプションがあります。適切なパスを使用し、関連するネットワークチームと連携します。</block>
  <block id="478a13ed02b948c9cfd89a6197062012" category="admonition">ストレージの計画とサイジング、および必要なホスト数については、ネットアップの解決策アーキテクトと対応するハイパースケーラクラウドアーキテクトに相談してください。Cloud Volumes ONTAP サイジングツールを使用してストレージインスタンスのタイプや適切なサービスレベルを最終決定する前に、ストレージのパフォーマンス要件を特定することを推奨します。</block>
  <block id="c748546b5854ecb146d9caa41d781bdb" category="section-title">詳細なアーキテクチャ</block>
  <block id="1a8ac44404b1e5888d83801ac116ff66" category="inline-image-macro">エンタープライズハイブリッドクラウドアーキテクチャ</block>
  <block id="855b05f645c80247a3f11392cab187c2" category="paragraph"><block ref="855b05f645c80247a3f11392cab187c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd558e50adcdcb0d667a4790f70f75a9" category="paragraph">GCP で GCVE 環境を設定するには、 GCP コンソールにログインし、 VMware Engine ポータルにアクセスします。</block>
  <block id="fb33f758c28f8ef8d56e41f74b4c47ab" category="paragraph">[New Private Cloud] ボタンをクリックして、 GCVE プライベートクラウドに必要な設定を入力します。「場所」で、 CV/CVO を導入するリージョン / ゾーンにプライベートクラウドを導入して、最高のパフォーマンスと最小のレイテンシを確保してください。</block>
  <block id="63b31ca49de01854f780d1e1722cd1c1" category="paragraph">前提条件</block>
  <block id="d79b0ab3cbae1dcd79007a97d26af5b1" category="list-text">VMware Engine Service Admin IAM ロールを設定します</block>
  <block id="72a7f08f840ab91a28a2558393971c47" category="inline-link-macro">VMware Engine API アクセスおよびノードクォータを有効にします</block>
  <block id="88e3e4c9b1c9efec399f7dda7a0c5887" category="list-text"><block ref="88e3e4c9b1c9efec399f7dda7a0c5887" category="inline-link-macro-rx"></block></block>
  <block id="a88d670b04af96a871dad56001e8f742" category="list-text">CIDR 範囲がオンプレミスサブネットやクラウドサブネットと重複しないようにしてください。CIDR 範囲は /27 以上である必要があります。</block>
  <block id="33d7d6c631c2d2cb3608445ef761fe16" category="paragraph"><block ref="33d7d6c631c2d2cb3608445ef761fe16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65bdc0673006b33d0c876e18a9a98787" category="paragraph">注：プライベートクラウドの作成には、 30 分から 2 時間かかります。</block>
  <block id="44f55a60cc8f70d1e10efc62b75eeddc" category="doc">ハイパースケーラにおける VMware 向けネットアップソリューション</block>
  <block id="f21c97f5b239021bb3f13d148516abb4" category="paragraph">クラウドを選択して、ネットアップに任せてください。</block>
  <block id="c1304f98c6be845a236d7a27951ece4f" category="paragraph"><block ref="c1304f98c6be845a236d7a27951ece4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca4ac823f3f130f3c78d6ac26ba9f46b" category="admonition">特定のハイパースケーラの機能を確認するには、そのハイパースケーラに適したタブをクリックします。</block>
  <block id="addac5e706b2148d9c7b3bbe2d2fcdde" category="paragraph">次のオプションから選択して、目的のコンテンツのセクションに移動します。</block>
  <block id="06262015df4851b380189212274a0e3e" category="inline-link-macro">ハイパースケーラ構成における VMware</block>
  <block id="7f08237a127b62af444f720f15216cee" category="list-text"><block ref="7f08237a127b62af444f720f15216cee" category="inline-link-macro-rx"></block></block>
  <block id="c774c23e9a97e08bfa096f1cbf18cc17" category="inline-link-macro">ネットアップストレージオプション</block>
  <block id="d3fc27ff58dc3a0d839a16af858e7999" category="list-text"><block ref="d3fc27ff58dc3a0d839a16af858e7999" category="inline-link-macro-rx"></block></block>
  <block id="833413440fbbe13837d8b58256cfba65" category="paragraph">オンプレミスと同様に、 VM と移行を作成する本番環境に適したクラウドベースの仮想化環境を計画することが重要です。</block>
  <block id="94772ee4b241fe0706c3aaef6e3a4505" category="inline-link-macro">サポートされているネットアップストレージオプション</block>
  <block id="67b586cdf9703ba67abe711415768cc0" category="paragraph">にアクセスしてください <block ref="01a9bd21bfc714c8dec8aabc5b88eda7" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="8a69f1bae52e494c6960f92a27390dcf" category="paragraph">VMware Cloud を FSX ONTAP に接続するには、次の手順を実行します。</block>
  <block id="7ca6fbd8bbb6725fab7413e4179738f6" category="list-text">VMware Cloud の導入が完了して AWS VPC に接続されているため、 Amazon FSX for NetApp ONTAP を、元の接続済み VPC ではなく新しい VPC に導入する必要があります（以下のスクリーンショットを参照）。接続された VPC に FSX （ NFS および SMB のフローティング IP ）が導入されている場合、これらの IP にはアクセスできません。Cloud Volumes ONTAP のような iSCSI エンドポイントは、接続された VPC からは正常に機能します。</block>
  <block id="da6646a18f048724eb432bf61285ca7f" category="paragraph"><block ref="da6646a18f048724eb432bf61285ca7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85dd65f7163e587c050ea8931a368ae" category="list-text">同じリージョンに別の VPC を導入し、その新しい VPC に Amazon FSX for NetApp ONTAP を導入します。</block>
  <block id="c78834afa7d24e921aa4d756d0a6409f" category="paragraph">VMware Cloud コンソールで SDDC グループを構成すると、 FSX が導入された新しい VPC に接続するために必要なネットワーク設定オプションが有効になります。手順 3 で、「グループ用の VMware トランジット接続の構成に添付ファイルおよびデータ転送ごとの料金が発生する」がチェックされていることを確認し、「グループの作成」を選択します。このプロセスが完了するまでに数分かかることがあります。</block>
  <block id="f91a2b452c63b5ccfcb4c39c2957c74e" category="paragraph"><block ref="ca83e0582a449c1b4399270025e1cc4a" category="inline-image-macro-rx" type="image"></block>
<block ref="9232dff72050e533bd1e173e5a0dd48c" category="inline-image-macro-rx" type="image"></block>
<block ref="5a108f597862e683ab9463f7c3ba6df6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fae60fbb10da5c3df46ec8ae03cd29b5" category="inline-link-macro">外部 VPC を接続する手順</block>
  <block id="784ad3266f853af20763bb78f5eec87a" category="list-text">新しく作成した VPC を作成した SDDC グループに接続します。[External VPC （外部 VPC ） ] タブを選択し、に従います <block ref="19928d01a63fe78e1303b296c2046666" category="inline-link-macro-rx"></block> をグループに追加します。このプロセスが完了するまでに 10~15 分かかることがあります。</block>
  <block id="14466a85376e8776f891db4cb3c38c6c" category="paragraph"><block ref="dd1eb585a08c833cec9544c048af36b6" category="inline-image-macro-rx" type="image"></block>
<block ref="38542de5661e382aba9345fe6e5a991b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8acea1c4fcca87631ca127e2bc757f13" category="inline-link-macro">AWS 転送ゲートウェイ</block>
  <block id="77508ef16874a250b66be2f90fc59918" category="list-text">外部 VPC プロセスの一環として、 AWS コンソールから Resource Access Manager を使用して新しい共有リソースにアクセスするように求められます。共有リソースはです <block ref="ccce2323414354d76e9cea0c1df9221b" category="inline-link-macro-rx"></block> VMware Transit Connect によって管理されます。</block>
  <block id="ac81300f843e6b91377e64a8edb819c2" category="paragraph"><block ref="63de05888c0a11205c33fd560dba3bc5" category="inline-image-macro-rx" type="image"></block>
<block ref="0455c56bd9863ddfae4079b5aabd42e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf415daee6d6f894a54f025534ba071" category="list-text">トランジットゲートウェイ添付ファイルを作成します。</block>
  <block id="e222d36183b455bb51f289144826c239" category="paragraph"><block ref="e222d36183b455bb51f289144826c239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b6693c4eff7f7923c59277702b441a9" category="list-text">VMC コンソールに戻り、 VPC 接続を受け入れます。この処理が完了するまでに約 10 分かかることがあります。</block>
  <block id="64d5d06ed03c085c4f5ce23ff6eeddac" category="paragraph"><block ref="64d5d06ed03c085c4f5ce23ff6eeddac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9b85dc0e557eb865bfa9ae84e251623" category="list-text">[External VPC （外部 VPC ） ] タブで、 [Routes] 列の編集アイコンをクリックし、次の必要なルートを追加します。</block>
  <block id="ae6434a5ebe0bad2f978fef8e0ed9efe" category="inline-link-macro">フローティング IP</block>
  <block id="06651ace1eab88d681ca9a8852bf26e2" category="list-text">NetApp ONTAP の Amazon FSX のフローティング IP 範囲のルート <block ref="14a98976d888daccbd07561411cfd6fa" category="inline-link-macro-rx"></block>。</block>
  <block id="5e16e681111a1a5b2dc805d69827532f" category="list-text">Cloud Volumes ONTAP のフローティング IP 範囲のルート（該当する場合）。</block>
  <block id="efffbab523616433e2c1ea67cbcaab53" category="list-text">新しく作成される外部 VPC アドレススペースのルート。</block>
  <block id="daa8a39ba75e8ac01fd26d579ce35fd9" category="paragraph"><block ref="daa8a39ba75e8ac01fd26d579ce35fd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="853349bb92eccb477b47eef3b8a5d9e2" category="inline-link-macro">ファイアウォールルール</block>
  <block id="499ca5dd26dbcc4c89a04ac771b316a6" category="inline-link-macro">詳細な手順</block>
  <block id="14c6314f2ae331d7f9a01ac04a75cd2b" category="list-text">最後に、双方向トラフィックを許可します <block ref="0756551700fd3215666355892b2f3692" category="inline-link-macro-rx"></block> FSX/CVO へのアクセスに必要です。以下の手順に従ってください <block ref="583f77470215de8611ddf3fba5fc6512" category="inline-link-macro-rx"></block> SDDC ワークロード接続用のコンピューティングゲートウェイファイアウォールルール用。</block>
  <block id="098b98cba4d6766e7de663adf0fdabb0" category="paragraph"><block ref="098b98cba4d6766e7de663adf0fdabb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f4480b9caed7d956fd6071b4cce03b9" category="list-text">管理ゲートウェイとコンピューティングゲートウェイの両方にファイアウォールグループを設定したら、次の手順で vCenter にアクセスできます。</block>
  <block id="f1c1b29fad3f2bdb9d8d054686b86542" category="paragraph"><block ref="f1c1b29fad3f2bdb9d8d054686b86542" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8b86f112029b19bf6451ba4624a4090" category="paragraph">次の手順では、 Amazon FSX ONTAP または Cloud Volumes ONTAP が要件に応じて設定されていること、およびストレージコンポーネントを VSAN からオフロードして導入を最適化するようにボリュームがプロビジョニングされていることを確認します。</block>
  <block id="e7441dbfabeaebba75ddd1bf2bcf25e9" category="section-title">ユースケース 1 ：ストレージの最適化</block>
  <block id="b9a8c3d27aa6638e02992c8b76fea769" category="paragraph">RVtools の出力を使用したサイジングの演習では、馬力（ vCPU / vMem ）のスケールがストレージと平行になっていることが常に明らかです。多くの場合、組織は、ストレージスペースを必要とするだけでなく、クラスタのサイズを十分に拡張して処理能力を必要とする状況に遭遇します。</block>
  <block id="cb575e0b8e023ca0a1789ea03bdb86fd" category="paragraph">NetApp Cloud Volume を統合することで、組織は vSphere ベースのクラウド解決策を簡単な移行アプローチで実現できます。再プラットフォーム化や IP の変更は不要で、アーキテクチャの変更も必要ありません。また、この最適化により、ホストの数を vSphere で必要な量以上に抑えながらストレージの設置面積を拡張できます。ただし、ストレージ階層、セキュリティ、ファイルは変更されません。これにより、導入を最適化し、全体的な TCO を 35 ～ 45% 削減できます。この統合により、ウォームストレージから本番環境レベルのパフォーマンスまで、ストレージを数秒で拡張できます。</block>
  <block id="9ae8084cfbf8c00bc50891fe51bb70b4" category="section-title">ユースケース 2 ：クラウドへの移行</block>
  <block id="40c30ee45ee11e766ec77dfd0d98cef0" category="paragraph">企業は、次のような理由から、オンプレミスのデータセンターからパブリッククラウドへのアプリケーション移行を迫られています。設備投資（ CAPEX ）から運用コスト（ OPEX ）に移行するための資金調達ディレクティブや、すべてをクラウドへ移行するというトップダウンの指示など、さまざまな理由があります。</block>
  <block id="4744ec437cce262edc7110652b69ab21" category="paragraph">スピードが重要な場合は、合理化された移行アプローチのみが可能です。これは、クラウド固有の IaaS プラットフォームに適応するためのアプリケーションの再プラットフォーム化とリファクタリングが低速でコストがかかるためですが、多くの場合、数か月かかることがあります。ネットアップの Cloud Volume とゲスト接続ストレージ用の帯域幅効率に優れた SnapMirror レプリケーションを組み合わせることで、アプリケーションと整合性のある Snapshot コピーと HCX 、クラウド固有の移行（例 Azure Migrate ）、または VM のレプリケーションに使用するサードパーティ製品）。この移行は、時間のかかる I/O フィルタメカニズムを使用する場合よりも簡単です。</block>
  <block id="d393e254c1adb8df50cfc41394c68645" category="section-title">ユースケース 3 ：データセンターの拡張</block>
  <block id="90c724dd3ba1ec0f533f7fb73a10323a" category="paragraph">季節によって変動する需要の急増や、わずかに変動する有機的な成長によってデータセンターの容量が上限に達し解決策た場合、 NetApp Cloud Volume と一緒にクラウドホスト型の VMware 環境に移行するのは簡単です。NetApp Cloud Volume を利用すると、アベイラビリティゾーン全体の高可用性と動的な拡張機能を提供することで、ストレージの作成、レプリケーション、拡張が非常に簡単に行えます。NetApp Cloud Volume を活用すると、ストレッチクラスタが不要になるため、ホストクラスタの容量を最小限に抑えることができます。</block>
  <block id="0b95336d0f31a3bd4775f96c750bb9bc" category="section-title">ユースケース 4 ：クラウドへのディザスタリカバリ</block>
  <block id="c2aee451a27e7cf3993f462ee5b760e9" category="paragraph">従来のアプローチでは、災害が発生した場合、クラウドに複製された VM は、クラウドに復元する前にクラウド独自のハイパーバイザプラットフォームに変換する必要があります。これは、危機的な状況では対処できません。</block>
  <block id="772dec0515d132f26bfa87cb31b5758d" category="paragraph">SnapCenter を使用してゲスト接続ストレージに NetApp Cloud Volume を使用し、オンプレミスからの SnapMirror レプリケーションとパブリッククラウド仮想化ソリューションを使用することで、ディザスタリカバリに対する優れたアプローチを考案できます。これにより、完全に一貫性のある VMware SDDC インフラ上で VM レプリカをリカバリできるようになり、クラウド固有のリカバリツールも利用できます Azure Site Recovery を参照）、または Veeam などの同等のサードパーティツールが必要です。また、このアプローチにより、ランサムウェアからのディザスタリカバリ訓練やリカバリも迅速に実行できます。また、テスト用や災害時に、ホストをオンデマンドで追加することで、フル本番環境に拡張することもできます。</block>
  <block id="24d0e6ab8003b406cf7e3f42363acbf5" category="section-title">ユースケース 5 ：アプリケーションの最新化</block>
  <block id="59e56fb67c730af04acf8a13665cadb3" category="paragraph">アプリケーションがパブリッククラウドに配置されたら、組織は数百もの強力なクラウドサービスを活用して最新化と拡張を実現したいと考えています。NetApp Cloud Volume を使用すると、アプリケーションデータが vSAN にロックされず、 Kubernetes などの幅広いユースケースでデータを移動できるため、最新化は簡単なプロセスです。</block>
  <block id="eea420abccd820355b4bddd3524ae083" category="paragraph">オールクラウドとハイブリッドクラウドのどちらをターゲットとしている場合でも、 NetApp Cloud Volume は、アプリケーションワークロードを導入、管理するための優れたオプションを提供し、ファイルサービスとブロックプロトコルに加えて、データ要件をアプリケーションレイヤとシームレスにすることで TCO を削減します。</block>
  <block id="cd51ff9774803e84c79e8ab19bb7ffd2" category="paragraph">どのようなユースケースでも、任意のクラウドやハイパースケーラを NetApp Cloud Volume と組み合わせることで、オンプレミスと複数のクラウドにわたるクラウドのメリット、一貫したインフラ、運用、ワークロードの双方向の移動、エンタープライズクラスの容量とパフォーマンスを迅速に実現できます。</block>
  <block id="2993778cba8ea9a69af4ff9dc7e18fb8" category="paragraph">ストレージの接続に使用する一般的なプロセスや手順は同じです。新しい名前で変更されたデータの位置にすぎません。ツールやプロセスはすべて変わらないので、 NetApp Cloud Volume を使用すれば導入全体を最適化できます。</block>
  <block id="5f1bd6ade489565bebba9a771b93fe70" category="paragraph">ハイブリッドクラウドまたはクラウドファーストの導入を計画する際に IT 組織にとって重要なユースケースの概要。</block>
  <block id="0812fc943ecbd9a54d88fb25729d0aa5" category="section-title">一般的なユースケース</block>
  <block id="f136615e6f2c1b330afb72bf4a45b4a4" category="paragraph">ユースケースには次のものがあり</block>
  <block id="3481fb80f122383c65ff8c6c8fd8c943" category="list-text">ディザスタリカバリ、 SVM</block>
  <block id="4127bac8297e2af8866315910651ce47" category="list-text">データセンターのメンテナンス時にワークロードをホストする。 * ローカルのデータセンターでプロビジョニングされたリソース以外に追加のリソースが必要になる、迅速なバースト。</block>
  <block id="20b1c73b5938d2d878aa1d96fee7f1b2" category="list-text">VMware サイトの拡張</block>
  <block id="5fe13b2b805496310dbaa281d7325877" category="list-text">クラウドへの迅速な移行</block>
  <block id="b278a6d011d590bb350b9cb81c21a732" category="list-text">開発 / テスト、および</block>
  <block id="bc262005b263505cc0464e05c4324687" category="section-title">IT の旅の中で</block>
  <block id="cfdb9aabb4aedf8cad2e330ba5a516a3" category="paragraph">ほとんどの組織は、変革と最新化への移行を進めています。このプロセスの一環として、企業は既存の VMware への投資を活用しながら、クラウドのメリットを活用し、移行プロセスをできるだけシームレスに実行する方法を模索しています。このアプローチでは、データがすでにクラウドにあるため、最新化への取り組みが非常に簡単になります。</block>
  <block id="0362604333fcf179ebf8b873f8f8c0ec" category="paragraph">次のシナリオを考えてみましょう。</block>
  <block id="b401aa039e47ba98bfaca10532e40d08" category="paragraph">CPU とメモリ用にわずか 5 台のホストが必要ですが、ストレージには多くのニーズがあり、ストレージ要件を満たすために 12 台のホストが必要です。この要件は、ストレージを増設するだけで追加の処理能力を購入する必要があるため、財務面での拡張性に大きな転換を実現できます。</block>
  <block id="7c25e9d8a9748905f5d456e20a93b413" category="paragraph">クラウドの導入と移行を計画する場合は、最適なアプローチを評価し、投資の総削減に最も簡単な方法をとることが常に重要です。あらゆるアプリケーション移行で最も一般的かつ簡単なアプローチは、仮想マシン（ VM ）やデータ変換がない場所でリホスト（リフトアンドシフト）を行うことです。NetApp Cloud Volume と VMware の Software-Defined Data Center （ SDDC ）を併用し、 vSAN を補完することで、移行と切り替えが容易になります。</block>
  <block id="e673b6ab6c5649a4df8e874aaa9017b9" category="sidebar">サポートされる構成</block>
  <block id="5d7b876a73a9025080fbf6dd921d1fdd" category="sidebar">データ移行とデータ保護</block>
  <block id="9b699c59be5ba510cd9c430a31843b23" category="sidebar">データ移行</block>
  <block id="ef55a9d1028eac237813e753d20134df" category="sidebar">パブリッククラウド向け VMware</block>
  <block id="27c378e12a7c59dc5aa13b13cc6cecff" category="sidebar">ハイパースケーラクラウド上の VMware クラウド</block>
  <block id="452b0b090c1c37a0d467a8df764fd81f" category="sidebar">ハイパースケーラクラウドにおけるネットアップストレージ</block>
  <block id="2190ab0d2f6281b2f3a73e0fc8e1f560" category="sidebar">まとめ</block>
  <block id="75fcfea0185575f935a7f5f149efd8ca" category="sidebar">VMware ハイブリッドクラウドのユースケース</block>
  <block id="e251010eb0cac5793d760ab2e5f51473" category="sidebar">ユースケースの概要</block>
  <block id="6f4bb0fa6fee4cf4ae1b8b1fc16e17cb" category="sidebar">レガシー NetApp HCI ソリューション</block>
  <block id="4a7272ea95323d5fef2e377b91b5f16d" category="inline-link-macro">ゲスト接続ストレージとしての FSX ONTAP</block>
  <block id="3017a9031d66c55b0258c102decfd1b9" category="inline-link-macro">Cloud Volumes ONTAP （ CVO ）をゲスト接続ストレージとして活用</block>
  <block id="1ffaf40c19facb6829b48b667d1dcaa3" category="inline-link-macro">ゲスト接続ストレージとしての Azure NetApp Files （ ANF</block>
  <block id="9bb210767ccb9c085c816c82f3b6b1cb" category="inline-link-macro">Cloud Volumes Service （ CVS ）をゲスト接続ストレージとして使用できるようになりました</block>
  <block id="712d83d9ce8f26363e9bfd1cba104b88" category="sidebar">NetApp E シリーズおよび Commvault Data Platform V11</block>
  <block id="aa8156dc9f7aa240e4f412f2f5fedaf5" category="sidebar">を使用した E シリーズおよび EF シリーズリファレンスアーキテクチャおよびストレージのベストプラクティス Veeam Backup Replication 9.5 のリリース</block>
  <block id="74e4bedcc2ff5b37a8770caa0ef72975" category="sidebar">NetApp E シリーズストレージを使用した Veritas NetBackup の導入</block>
  <block id="029f60716c50acd9acf9ce4a9394c91a" category="sidebar">HyTrust を使用したマルチテナントインフラストラクチャ向けの NIST セキュリティ制御</block>
  <block id="e63695c4dea40eefb2ef481c7b242192" category="open-title">すべての変更</block>
  <block id="6fb2815b4c371ee082a84cc14539d4cb" category="open-title">エンタープライズアプリケーション</block>
  <block id="fb0ad99371abb3d02d60add8160c6dd9" category="section-title">NetApp Cloud Manager を使用した CVO と Connector の AWS 認証の要件</block>
  <block id="5edbe8c55546db896b55871b44a39263" category="cell">* 日付 *</block>
  <block id="12cd1425f32ad289dba28e35ae9096fb" category="cell">* 解決策エリア *</block>
  <block id="b96941ac46daa357b1782f017746a57b" category="cell">* 変更の概要 *</block>
  <block id="f63616bb6a8255ed08089231c746f285" category="cell">12/062021</block>
  <block id="16784caec2e047ddf59bd5a51bd35a73" category="cell">2021年11月15日</block>
  <block id="1c20ad7a11d1c2856906d55171b50126" category="cell">新しいビデオデモ「 Astra Control を使用した CI / CD パイプラインでのデータ保護」を NVA-1160 に追加</block>
  <block id="5cdb842b21b9f980df2b3ab63ee9a9e6" category="cell">新しいコンテンツ： ConFluent Kafka のベストプラクティス</block>
  <block id="38562890365e144b467ec2813a6377f2" category="cell">2021 年 11 月 2 日</block>
  <block id="dfd39862c9cc158ad7b0e4e1e9a3024a" category="cell">2021 年 10 月 29 日</block>
  <block id="e7c456cd85cc15bd3faf7b65c0833d3e" category="cell">新しいコンテンツ： TR-4657 - ネットアップのハイブリッドクラウドデータソリューション： Spark と Hadoop</block>
  <block id="815425a7766095190649a3f9ecbc1828" category="cell">2021年10月26日</block>
  <block id="8493c4f1797303a6de2524a60adcf058" category="cell">2021年10月18日</block>
  <block id="ade15f89ccc27958a743a992cea8c574" category="cell">TR-4908 - 『 Hybrid Cloud Database Solutions with SnapCenter 』</block>
  <block id="622eda32248f1c4d1fc31dd78ec74c4a" category="cell">2021年10月14日</block>
  <block id="f6ecd264493db5fac4b21f19be4eb69d" category="cell">VMware VCF ブログシリーズに、ネットアップのパート 1~4 を追加</block>
  <block id="83a11da06ed8a3e338b5e8d2991cae0c" category="cell">2021年10月4日</block>
  <block id="c95696f6146a5b8b56c74d4349687ec6" category="cell">新しいビデオデモ「 Astra Control Center を使用したワークロードの移行」を NVA-1160 に追加</block>
  <block id="4f41bdb2ec81835b66ffbbd18feea656" category="cell">2021 年 9 月 23 日</block>
  <block id="32ff1e0d02ec482c64fdac1af2a49372" category="cell">新しいコンテンツ： NetApp XCP 向けのネットアップのベストプラクティス</block>
  <block id="42246d8ef9280d19cf1326197310630a" category="cell">2021 年 9 月 21 日</block>
  <block id="10c87c454d38afc0644c8c1fb75fa524" category="cell">VMware vSphere 管理者、 VMware vSphere 自動化向けの新しいコンテンツまたは ONTAP</block>
  <block id="faaef04f2f0bb7bed9504fc3d357ba59" category="cell">2021年9月9日</block>
  <block id="80245b1f322b07a9fcd385bb375d8182" category="cell">NVA-1160 に、 OpenShift で F5 BIG-IP ロードバランサを統合</block>
  <block id="023cd4d7ed373df0d803d414e2e452bf" category="cell">2021年8月5日</block>
  <block id="afb6b7f715f1bf6492efb8f3c279ddd7" category="cell">NVA-1160 - NetApp Astra Control Center on Red Hat OpenShift に新しいテクノロジ統合を追加</block>
  <block id="2cd99fd0d69d62395a72dc7d4684299c" category="cell">2021 年 7 月 21 日</block>
  <block id="e88b179e97a156d13d1c9c4163513205" category="cell">07/02/2021</block>
  <block id="9f99e3ea14c0a44dde0fd7db13fa3bef" category="cell">TR-487- 『 SQL Server on Azure NetApp Files ： Real Deployment View 』</block>
  <block id="83d39ff0c36403ca3e183af9ca091a71" category="cell">2021年6月16日</block>
  <block id="2891cb0fe31606ff172d0be4ec81732f" category="cell">新しいビデオデモ「 OpenShift Virtualization のインストール：ネットアップでの Red Hat OpenShift 」を追加しました</block>
  <block id="77d29c989f99997794df55b2d9053ae8" category="cell">新しいビデオデモ「 OpenShift による仮想マシンの導入： NetAppp を使用した Red Hat OpenShift 」を追加しました</block>
  <block id="fab25e19f7e186358ed7f1268e7af3b4" category="cell">2021年6月14日</block>
  <block id="96da300b5faf4ae3a5ca09afabba4273" category="cell">解決策に Azure NetApp Files ： Microsoft SQL Server を追加</block>
  <block id="67c877d4abd9acdbb0fa62c3720b6d60" category="cell">2021年6月11日</block>
  <block id="a14851e0e2cb4c8e9176cdea01500288" category="cell">新しいビデオデモ「 Astra Trident を使用したワークロードの移行」と NVA-1160 に SnapMirror を追加</block>
  <block id="c5d2015481e39976c67e40778a449a2d" category="cell">2021年6月9日</block>
  <block id="c4aad26d0bd9fb92610a1b5b3390bd46" category="cell">ネットアップを使用した Red Hat OpenShift での Kubernetes の高度なクラスタ管理に関する NVA-1160 に新しいユースケースを追加しました</block>
  <block id="53977250e4a69cab3688fcbede8fb73a" category="cell">2021年5月28日</block>
  <block id="9c23aa040a3dc51dbbf59463247f4fec" category="cell">NVA-11460 の OpenShift Virtualization に新しいユースケースを追加しました NetApp ONTAP の略</block>
  <block id="c02e5ac689072495b8af780302105253" category="cell">2021年5月27日</block>
  <block id="f5abcac882b8caa17d3af1c14144f503" category="cell">NetApp ONTAP を使用した OpenShift で、 NVA-1160 マルチテナンシーに新しいユースケースを追加しました</block>
  <block id="3202abe9084b2d9ec5b0b162721978e7" category="cell">2021年5月26日</block>
  <block id="d58aa75910c54a80c6ba4de7e7f6949f" category="cell">ネットアップで NVA-1160 Red Hat OpenShift を追加</block>
  <block id="a0be3ecb819e8e7215f946964346f547" category="cell">2021年5月25日</block>
  <block id="95a74db23b085df59ef6412199e9e791" category="cell">ブログ「 Installing NetApp Trident on Red Hat OpenShift – How to Solve the Docker ‘ toomanyrequests ’問題！」を追加</block>
  <block id="2dec0489948dbe7f63f68743a085e98c" category="cell">2021年5月19日</block>
  <block id="0db377921f4ce762c62526131097968f" category="cell">全般</block>
  <block id="9045bfbeff51b83f9752fe549021a181" category="cell">FlexPod ソリューションへのリンクを追加</block>
  <block id="0a40e3c91a3a55c9a37428c6d194d0e5" category="cell">AI</block>
  <block id="af3192eaae3cb09641db4adcc45ed625" category="cell">AI コントロールプレーン解決策を PDF から HTML に変換しました</block>
  <block id="8ff5be8d16e86e5284f8ba8a3428459a" category="cell">2021年5月17日</block>
  <block id="a88789a4f83f213b256b57eb0884fd1d" category="cell">解決策フィードバックタイルをメインページに追加しました</block>
  <block id="027fb9451c491d9dcfb7db05f552788d" category="cell">2021年5月11日</block>
  <block id="3e62d5f1a7f1b6907ad1ecaf11282dac" category="cell">NFS への Oracle 19C for ONTAP の自動導入が追加されました</block>
  <block id="d2422eca0ff6f19afb6e1206b15fbe01" category="cell">2021年5月10日</block>
  <block id="85c96a5f13e6dea61e003704f8d456e2" category="cell">新しいビデオ： How to use VVOLs with NetApp and VMware Tanzu Basic 、パート 3</block>
  <block id="29e9b684dbbdf5cc1828da82a146781d" category="cell">2021年5月6日</block>
  <block id="508db167da7d74fc86c3f8024ce04558" category="cell">FlexPod データセンター上の Oracle 19C RAC データベースへのリンクを追加しました FC 経由で Cisco UCS と NetApp AFF A800 を使用</block>
  <block id="85fbf94a3ecf9a3af4a93f80a3681fe1" category="cell">2021年5月5日</block>
  <block id="608f33919f16e9a23bd532ad6bcf480a" category="cell">FlexPod Oracle NVA （ 1155 ）と Automation のビデオを追加しました</block>
  <block id="4dc6e14d2ad9dafd2cd72f8c77d22bea" category="cell">2021年5月3日</block>
  <block id="3d21a9c32818fc58b044121ce91e053c" category="cell">デスクトップ仮想化</block>
  <block id="4174d4c17e4b11e07d8dd581e16ba56c" category="cell">FlexPod デスクトップ仮想化ソリューションへのリンクを追加</block>
  <block id="b3cae16f1f895f4f9ceae98617a3bf0d" category="cell">2021年4月30日</block>
  <block id="2764512d2fc00264d149a6142151aa1a" category="cell">ビデオ： How to use VVOLs with NetApp and VMware Tanzu Basic 、パート 2</block>
  <block id="4996fa0acf5cc54e889a50e9bdd2e56b" category="cell">2021年4月26日</block>
  <block id="9c5316849ca2429400f8979f0ee0d963" category="cell">ブログ「 Using VMware Tanzu with ONTAP to Accelerate Your Kubernetes Journey. 」を追加</block>
  <block id="911da11d01e00e9aa94c5b03b2e6e2cc" category="cell">2021年4月6日</block>
  <block id="06cfdb63e0660d09f203a21e28520a1e" category="cell">「このリポジトリについて」を追加</block>
  <block id="32edd80de3642c58e1a05df5f3e458e1" category="cell">2021年3月31日</block>
  <block id="bbb1c8f8182403001f2e1f69085ca2ad" category="cell">エッジでの TR-4886 - AI 推論の項「 NetApp ONTAP with Lenovo ThinkSystem 解決策 Design 」を追加</block>
  <block id="d61c9a3748e1dd56535fbdaaa3e39eab" category="cell">2021年3月29日</block>
  <block id="8575a367028bec3e86e25b102a8dced1" category="cell">NetApp Storage 解決策で NVA-1157 - Apache Spark ワークロードを追加しました</block>
  <block id="8f10e64b04f6cc56cf66fd4f4eb0f4d9" category="cell">2021年3月23日</block>
  <block id="7998f8ad3cabe02af607385cae780ce1" category="cell">ビデオ： How to use VVOLs with NetApp and VMware Tanzu Basic 、パート 1</block>
  <block id="f86fe8ec70f2003923e4000589747208" category="cell">2021年3月9日</block>
  <block id="eea51e9c0dffabdea48ada8f53bbf0f5" category="cell">E シリーズの内容を追加し、 AI の内容を分類</block>
  <block id="0b218fa381bfd1c86fff15d165ab23a0" category="cell">2021年3月4日</block>
  <block id="932af944058a758da919ca59d1af640b" category="cell">新しいコンテンツ： NetApp 解決策の自動化の導入</block>
  <block id="4be9c930c1a8a198115d499cb3223d9e" category="cell">2021年2月18日</block>
  <block id="0c560038af98c5401dd10202e7937acd" category="cell">TR-4597 VMware vSphere for ONTAP を追加しました</block>
  <block id="aa1c3ec5e6dcfb94555ff987f061f1a0" category="cell">2021年2月16日</block>
  <block id="3ecf1285a084b58473a7873e3f33e74a" category="cell">AI Edge 推論の自動導入手順が追加されました</block>
  <block id="8138d0c3e613508050b6fec12c4322c7" category="cell">2021年2月3日</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="cell">SAP</block>
  <block id="91171755730ad15e6d79b5cb6682a8f1" category="cell">SAP と SAP HANA のすべてのコンテンツのランディングページを追加</block>
  <block id="e5099bd65458f8a8556c830ac4759296" category="cell">2021年2月1日</block>
  <block id="09689218a7f330554f4e28a18e9e14a6" category="cell">ネットアップ VDS を使用した VDI で、 GPU ノードのコンテンツを追加</block>
  <block id="c487c48f1528e49e3cb129fdbdd79990" category="cell">2021年1月6日</block>
  <block id="868f7f9e78f90bcf0597030ffefd449b" category="cell">新しい解決策： NVIDIA DGX A100 システムと Mellanox Spectrum イーサネットスイッチを搭載した NetApp ONTAP AI （設計と導入）</block>
  <block id="0663765430d1ca93138f13429aef7c37" category="cell">2020年12月22日</block>
  <block id="a4aae8f8849c453c6c67080c5d013301" category="cell">ネットアップソリューションリポジトリの初版リリース</block>
  <block id="18a2eb3f7faf7c44e3062e78cbeff089" category="inline-link-macro">SAP ソリューションリポジトリ</block>
  <block id="412b2ee09f2fbaf8cddb69ee6fe43a2e" category="admonition">SAP および SAP HANA の更新の詳細については、の各ソリューションに表示される「更新履歴」のコンテンツを参照してください <block ref="c4ed54a973fb1aa472c2443732d93c13" category="inline-link-macro-rx"></block>。</block>
  <block id="b98a6acc7ef428f1ae11e5177447df8c" category="paragraph">クラウドの場合は、オンプレミスとクラウドの間の接続が直接接続（ AWS ）、 ExpressRoute （ Azure ）、クラウドインターコネクト（ GCP ）の場合にも、同様のオンプレミス移行ワークフローに従うことができます。</block>
  <block id="76e3e2a4e56301dafc50613d96fd624e" category="section-title">導入手順 - NAS</block>
  <block id="62e9f0426675b856daf874c75830c213" category="inline-link-macro">「 XCP の前提条件」</block>
  <block id="4f6583b152ef684b4492414bcdcdf877" category="list-text">のセクションで説明した前提条件を満たしていること <block ref="958d961a425946e5195ca036cea97fab" category="inline-link-macro-rx"></block></block>
  <block id="0957326f089aaf98a5b7b9110a2675cd" category="section-title">導入手順 - hdfs/MapRFS のデータ移行</block>
  <block id="1f43fc63f63aad0b707e06b0753182a1" category="paragraph">このセクションでは、 Hadoop ファイルシステムの NAS へのデータ転送という新しい XCP 機能について説明します。この機能は、 HDFS / MapRFS から NFS にデータを移行するか、その逆を行います。</block>
  <block id="368666825ffae5710ab122fb63937cee" category="paragraph">MapRFS/HDFS 機能の場合は、ルート以外のユーザ環境で次の手順を実行する必要があります。通常、 root 以外のユーザは HDFS 、 MapR 、または HDFS および MapRFS ファイルシステムを変更する権限を持つユーザです。</block>
  <block id="9adbc05b1436b3e8962253577f1e6441" category="list-text">CLI またはユーザの .bashrc ファイルと 'XCP コマンドを使用して 'CLASSPATH 'hadoop home ' Nhdfsa_libjvm_path ' lm_library_path ' および Nhdfsa_LIBhdfsa_path 変数を設定します</block>
  <block id="2a0eda7a7937e303f9e18a57a033fcb8" category="list-text">Nhdfsa_lidbhdfs_path は、 libhdfs.so ファイルを指しています。このファイルは、 Hadoop ディストリビューションの一部として HDFS / MapRFS ファイルとファイルシステムを操作し操作するための HDFS API を提供します。</block>
  <block id="13682a0461e750a2dfb4e86c2ddc1165" category="list-text">Nhdfs_libjvm_path は、 libjvm.so ファイルを指しています。これは JRE の場所にある共有 Java 仮想マシンライブラリです。</block>
  <block id="60ce276a5dde3f2d2e92b1986a2eb339" category="list-text">クラスパスは、 Hadoop クラスパス– glob 値を使用してすべての jar ファイルを指します。</block>
  <block id="84cbf778b2572cae5eba01d0ca330078" category="list-text">LD_LIBRARY_PATH は、 Hadoop のネイティブライブラリフォルダの場所を指しています。</block>
  <block id="68207eb9f168add2309e88b5223d57c6" category="paragraph">Cloudera クラスタに基づいて、次のサンプルを参照してください。</block>
  <block id="91328810a5559a740f522f4c5a1da5f1" category="paragraph">このリリースでは、 HDFS から NFS への XCP スキャン、コピー、および検証処理とデータ移行がサポートされます。データレイククラスタの 1 つのワーカーノードと複数のワーカーノードからデータを転送できます。1.8 リリースでは、 root ユーザと root 以外のユーザがデータを移行できるようになりました。</block>
  <block id="dee4c2c7e685015e9f3cc1ad197f3ab5" category="section-title">導入手順 - root 以外のユーザが HDFS / MaprFS データを NetApp NFS に移行します</block>
  <block id="5983f77acc016b8138698b32b0ab0405" category="list-text">導入の手順から 1 ～ 9 の手順を実行します。</block>
  <block id="c2765e27844a39bfc897cb964eec8711" category="list-text">次の例では、 HDFS から NFS にデータを移行します。</block>
  <block id="e6f549e8013d1f24b8756cd11ff3083e" category="list-text">HDFS 内に（「 hadoop fs -copyFromLocal 」を使用して）フォルダとファイルを作成します。</block>
  <block id="2433ce85404dd68893a2e4abb99843e4" category="list-text">HDFS フォルダで権限をチェックします。</block>
  <block id="befab6065ddb441f0b260ac75a8e84c8" category="list-text">NFS でフォルダを作成し、権限を確認します。</block>
  <block id="02341ea695e862c3a2d89461b1b8bf37" category="list-text">XCP を使用して HDFS から NFS にファイルをコピーし、権限を確認します。</block>
  <block id="46742b2c1e11cf6a3e230ec3da7e6800" category="admonition">XCP ファイル分析のアーキテクチャの概要、統計情報ビューなどの GUI ベースのダッシュボードビュー、およびファイル配布ビューの詳細については、ブログの投稿を参照してください<block ref="924a0428223d35821b584a5368c0e3e5" category="inline-link-rx"></block>。</block>
  <block id="21bd6427119f8d9a06a7c5bce95d28ac" category="paragraph">XCP 1.6 では、カスタマイズされたグラフを作成するための GUI に制限があります。必要なグラフを作成するには、 CLI を使用して対応するフィルタを指定して XCP スキャンコマンドを実行します。次の例を参照してください。</block>
  <block id="7e9b65699b01d35aeff9dc16008da7a5" category="paragraph">XCP コピーと同期のテストでは、導入時に使用したのと同じテストベッドを使用しました。8K 、 16K 、 1MB の 3 セットのファイルを 100 万個作成し、変更をリアルタイムで実行しました。XCP sync 関数は、ソースからターゲットへの差分増分更新をファイルレベルで実行します。増分更新操作には、既存のファイルとフォルダの名前変更、既存のファイルへのデータの追加、ファイルとフォルダの削除、ハードリンク、ソフトリンク、マルチリンクの追加の 4 つの操作があります。テスト目的では、名前変更、追加、削除、およびリンク操作に注目しました。つまり、 100 万ファイルに対して、名前変更、追加、削除などの変更処理が 10% から 90% の変更率で実行されたことになります。</block>
  <block id="f599c9e924e3b854abd0ab58126fed43" category="paragraph">以前のバージョンと比較して、 XCP 1.6.3 および 1.7 でパフォーマンスが向上しています。次のセクションでは、 XCP 1.6.3 と 1.7 の間での 8K 、 16K 、 1MB の各ファイルの同期パフォーマンスの比較を示します。</block>
  <block id="b53776fdc2fd9fc721aaa6f03fd3d6a0" category="paragraph">次の図は、 XCP 1.6.3 での XCP 同期パフォーマンスと 1.7 （ 8K サイズが 100 万ファイルの場合）の結果を示しています。</block>
  <block id="5b201508f1de849d630f98c0001fdc29" category="paragraph">次の図は、 XCP 1.6.1 での XCP 同期パフォーマンスの結果を示しています。 1MB のファイルサイズが 100 万ファイルの 1.5 です。</block>
  <block id="61b90da0c91ea6cb7c16bfaca41b4920" category="paragraph">このパフォーマンス検証に基づいて、オンプレミスとクラウドでのデータ移行には XCP 1.7 を使用することを推奨します。</block>
  <block id="d0ecdc77c2c944d380e9fef0e01eb119" category="paragraph">これは '-fmt' コマンドを使用するカスタム・レポートですすべてのディレクトリがスキャンされ、ディレクトリの名前、パス、およびサイズが CSV ファイルにダンプされます。サイズ列は、スプレッドシートアプリケーションでソートできます。</block>
  <block id="1c026a57d7676d346dd0d44a2f595c1d" category="list-text">* スキャン * NAS および MapR / HDFS データのレイアウトの概要を提供します。</block>
  <block id="6b2c974b2ada5fba492b8dcda598b1f9" category="paragraph">次の図は、 GUI からの NetApp XCP ファイル分析通信を示しています。</block>
  <block id="2d3aa3941d30870beb3abde613ce14b1" category="paragraph">XCP 1.7 に含まれるライブソース移行のサポートにより、使用中のデータソースからの移行（読み取りおよび書き込みアクティビティ）が可能になります。移行ジョブで使用されているファイル（ copy や sync running など）は XCP によって除外され、スキップされたファイルの情報は XCP ログにキャプチャされます。</block>
  <block id="b9611b870758eac97bd0c3bcb3fc8026" category="list-text">Azure NetApp ボリュームごと、またはクラウドの Cloud Volume Service （プレミアムサービスレベル）用に、 XCP カタログ用にオンプレミスで NFS 共有を 1 つ作成します。</block>
  <block id="7d131526ee2a04107bbc50d52a29a7d7" category="cell">2021 年 12 月 21/2021 年です</block>
  <block id="c65463900a520919b522c30b6256e475" category="cell">新しいビデオデモ「 NetApp Astra Control を活用した、事後分析の実施とアプリケーションの NVA-1160 へのリストア」を追加しました</block>
  <block id="5df9589990c71ed42c69a8bcc053d0d4" category="inline-link-macro">ビデオ： NetApp Astra Control を活用して、事後分析とアプリケーションのリストアを実行</block>
  <block id="51d1589966ca772274944bc0cd6b15bc" category="cell"><block ref="51d1589966ca772274944bc0cd6b15bc" category="inline-link-macro-rx"></block></block>
  <block id="fb12e7f50899cc1254f9a6f1e0341423" category="summary">アプリケーションのクローンを作成して事後分析を行い、 Astra Control Center を使用して CI / CD パイプラインでアプリケーションを復元します</block>
  <block id="bc42bbaf219349a2ba37dfd4709b2003" category="doc">NetApp Astra Control を活用して、事後分析とアプリケーションのリストアを実行</block>
  <block id="10b5b21ed1ee90eca305b558caf7d03b" category="open-title">移動</block>
  <block id="07b0eade4402d209b5dbe587a8ad3f6f" category="doc">AWS に仮想化環境を導入して設定</block>
  <block id="a724b4fc4c5f79672a5c572466d5e001" category="doc">Azure 向けネットアップゲスト接続ストレージオプション</block>
  <block id="ae295ef15cb155f8a1af7d255e34298d" category="doc">AWS 用のネットアップゲスト接続ストレージオプション</block>
  <block id="ade1814101b0113034e0f446307b3db3" category="doc">Google Cloud Platform GCVE のネットアップ機能</block>
  <block id="6eb516b97eae0ab93b8d6aab35fbb764" category="section-title">GCVE のネットアップストレージオプション</block>
  <block id="1d8249c60cae81d82fc5bfb80167babc" category="list-text">1 つの VSAN 環境のみが可能です。そのため、すべてのストレージトラフィックが本番環境のワークロードと直接競合します。</block>
  <block id="63b9fbe67e7dd9b9f7623683244cb7f8" category="doc">Azure AVS 向けのネットアップの機能</block>
  <block id="1f0a2077c33b91b3daaaea05c7fadc07" category="section-title">Azure で AVS を設定する</block>
  <block id="cdac9a2e7f1dc52240712d4a191378e8" category="section-title">AVS 向けのネットアップストレージオプション</block>
  <block id="cf3ac5a0dae3780b356e57c121b3eab0" category="doc">Google Cloud Platform （ GCP ）への仮想化環境の導入と構成</block>
  <block id="ba756c1a2b93ad97a639914aae828a16" category="doc">ネットアップの AWS VMC 向け機能</block>
  <block id="8658ccb747e94ac624861f5761a34716" category="section-title">AWS で VMC を設定しています</block>
  <block id="e9f84da32eb512bd768458a738ed8aa6" category="section-title">VMC のネットアップストレージオプション</block>
  <block id="bb01fec2870d3f698517f8471454637b" category="doc">Azure に仮想化環境を導入して設定</block>
  <block id="c9b6ad26821d78c27282a65584d5f485" category="summary">ネットアップは、堅牢な仮想化環境向けに、オンプレミスとクラウドの両方で、多数のベストプラクティスとソリューションを提供しています。</block>
  <block id="ba64ee63cc4950b57bfb868fabec0db3" category="doc">ネットアップの仮想化ソリューション</block>
  <block id="c775b248c55d253008c58d1ecd60e66f" category="doc">エンドユーザコンピューティング（ EUC ） / 仮想デスクトップインフラ（ VDI ）ソリューション</block>
  <block id="599725d881295777d3740ac33e953ced" category="paragraph">仮想デスクトップをオンプレミスとクラウドのどちらに導入する場合でも、ネットアップにはニーズに対応するためのさまざまな EUC / VDI ソリューションが用意されています。</block>
  <block id="75fc33fcc3ef968fd3bf30c8da19bf9b" category="section-title">ネットアップの仮想デスクトップサービス（ VDS ）</block>
  <block id="0593c3151fa252cdb4e997dd1255c608" category="paragraph">ネットアップの仮想デスクトップサービス（ VDS ）は、主要なパブリッククラウドとプライベートクラウドで Remote Desktop Services （ RDS ）のオーケストレーションを実現します。</block>
  <block id="3b96d802308faf1d6ff7e5563ea3d29b" category="paragraph">VDS で利用できるソリューション：</block>
  <block id="2ccf8775db4706ac42c0a600eca82163" category="list-text"><block ref="2ccf8775db4706ac42c0a600eca82163" category="inline-link-macro-rx"></block></block>
  <block id="d4a0768ddf4ac449658ace06000fa76e" category="section-title">VMware Horizon を使用したエンドユーザコンピューティング</block>
  <block id="959f3d9cc20e0e9bfbc01c2d36cdc894" category="paragraph">ネットアップでは、複数のコンピューティング構成にまたがる VMware Horizon の検証済みアーキテクチャを提供しています。利用可能なソリューションは次のとおりです。</block>
  <block id="01606c27121f18cf231b4700ddf252e1" category="list-text"><block ref="01606c27121f18cf231b4700ddf252e1" category="inline-link-macro-rx"></block></block>
  <block id="4e5b466ff852e362d888b555cdcf62b7" category="list-text"><block ref="4e5b466ff852e362d888b555cdcf62b7" category="inline-link-macro-rx"></block></block>
  <block id="06e0780100d16763670aed1df8526b2e" category="list-text"><block ref="06e0780100d16763670aed1df8526b2e" category="inline-link-macro-rx"></block></block>
  <block id="128fc080215971e783f68c8be31bd85d" category="list-text"><block ref="128fc080215971e783f68c8be31bd85d" category="inline-link-macro-rx"></block></block>
  <block id="bf647454e36069fd16f1a7a35cf6a865" category="sidebar">はじめに</block>
  <block id="624e816c7f229d54827ad7bc018eb8da" category="sidebar">サポートされているストレージオプション</block>
  <block id="40d267fad784266cb59c36d76573e7c6" category="sidebar">NetApp on AWS （ VMC ）</block>
  <block id="e7060d0555f178d672a4197df38e1d39" category="sidebar">仮想化環境を構成します</block>
  <block id="2408eed8aca98d53134097e8990c8225" category="sidebar">ゲスト接続ストレージオプション</block>
  <block id="a64cd881ec955d17faa5e396a891e1e6" category="sidebar">NetApp on Azure （ AVS ）</block>
  <block id="d1b0ccc0fc426266cf228929d5424ce4" category="sidebar">ネットアップ on Google Cloud Platform （ GCVE ）</block>
  <block id="b84034a4ed4e546b39d5bd268ff06eaa" category="sidebar">導入 / ベストプラクティス</block>
  <block id="b0f878715a3d12827d6fb02b0df1f23c" category="sidebar">ネットアップと VMware ：基本事項</block>
  <block id="690359e9e894d87f3144da561090e3f0" category="sidebar">VMware vSphere 管理者向けの NetApp ONTAP のメリット</block>
  <block id="584132370dee3f2fccd2ca59888bee18" category="sidebar">パブリッククラウドで VMware を使用</block>
  <block id="631ed8aac33a641d62d751c3abd77c57" category="sidebar">NetApp for AWS VMC</block>
  <block id="9f5fbecd7c791f090de17716e147c3a5" category="sidebar">NetApp for Azure AVS</block>
  <block id="b2ab132403a71f074bc776eb29725292" category="sidebar">ネットアップの Google Cloud Platform GCVE</block>
  <block id="07a2344d318341cbbdb1983d22dc80f0" category="sidebar">セキュリティデータ保護</block>
  <block id="10e5369e04057873bcce3de87e2c6187" category="sidebar">VMware Site Recovery Manager （ SRM ）と NetApp ONTAP 9</block>
  <block id="eccb6fc5c04122d7aef60d899a77089e" category="sidebar">その他のリソース</block>
  <block id="5e4af7ed70d1a211f16d528dcdfc6474" category="sidebar">Virtual Desktop Solutions の略</block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">このティアストレージのテストでは、プロデューサーワークロードとコンシューマーワークロード向けに、 NetApp StorageGRID セットアップを使用して、 3 ノードから 4 ノードのノードを使用しました。テストによると、完了までの時間とパフォーマンス結果は StorageGRID ノードの数に直接比例しました。StorageGRID セットアップには、少なくとも 3 つのノードが必要でした。</block>
  <block id="2c8105fbc386e60a03fe0cf5390eb0ce" category="inline-link-macro">次は、流暢な 3 コネクタです。</block>
  <block id="40acd085e3c223b35d81906b1c904f46" category="paragraph"><block ref="40acd085e3c223b35d81906b1c904f46" category="inline-link-macro-rx"></block></block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID は、ハイパフォーマンスで対費用効果の高いオブジェクトストレージプラットフォームです。階層型ストレージを使用することで、ローカルストレージやブローカーの SAN ストレージに格納されている ConFluent Kafka にあるデータのほとんどが、リモートのオブジェクトストアにオフロードされます。この構成では、クラスタのリバランシング、拡張、縮小、障害が発生したブローカーの交換にかかる時間とコストを削減することで、運用が大幅に改善されます。オブジェクトストレージは、オブジェクトストア階層にあるデータの管理に重要な役割を果たします。そのため、適切なオブジェクトストレージを選択することが重要です。</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID は、ノードベースの分散グリッドアーキテクチャを使用して、インテリジェントでポリシーベースのグローバルデータ管理を実現します。数ペタバイトの非構造化データと数十億のオブジェクトを、ユビキタスなグローバルオブジェクトネームスペースと高度なデータ管理機能を組み合わせることでシンプルに管理できます。単一コールのオブジェクトアクセスは、サイト間を拡張し、高可用性アーキテクチャを簡素化しながら、サイトやインフラストラクチャの停止に関係なく、オブジェクトへの継続的なアクセスを保証します。</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">マルチテナンシーを使用すると、複数の非構造化クラウドアプリケーションやエンタープライズデータアプリケーションを同じグリッド内で安全に処理できるため、 NetApp StorageGRID の ROI とユースケースが向上します。メタデータベースのオブジェクトライフサイクルポリシーを使用して複数のサービスレベルを作成し、複数の地域にわたるデータの保持、保護、パフォーマンス、ローカリティを最適化できます。ユーザは、データ管理ポリシーを調整し、トラフィック制限を監視および適用して、絶えず変化する IT 環境で要件が変化した場合に備えて、システムを停止することなくデータランドスケープに再調整できます。</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID Grid Manager はブラウザベースのグラフィカルインターフェイスで、世界中に分散された複数のサイトにまたがる StorageGRID システムの設定、管理、監視を、 1 つの画面で実行できます。</block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">StorageGRID グリッドマネージャインターフェイスでは、次のタスクを実行できます。</block>
  <block id="a1d8b1b1990901cd5a97dd0f3dee2da9" category="inline-link-macro">ILM ポリシー</block>
  <block id="37e0a993cc0a3c5aacb623e412befc5b" category="inline-link-macro">ILM ルール</block>
  <block id="0beeefc6ac257658ea119788351ad268" category="paragraph">StorageGRID には、オブジェクトのレプリカコピーを保持し、特定のパフォーマンスおよびデータ保護要件に応じて 2+1 や 4+2 などの EC （イレイジャーコーディング）スキームを使用してオブジェクトを格納するなどの、柔軟なデータ管理ポリシーが用意されています。ワークロードと要件が時間の経過とともに変化する場合、 ILM ポリシーも時間の経過とともに変化する必要があることがよくあります。ILM ポリシーの変更は中核的な機能であり、絶えず変化する環境に StorageGRID のお客様がすばやく簡単に適応できるようにします。を確認してください <block ref="b2ddd4069e5288685e27e7989fb1a613" category="inline-link-macro-rx"></block> および <block ref="7593bc4c70a5537fc14593339f7e6540" category="inline-link-macro-rx"></block> StorageGRID でセットアップする。</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712 、 SG5760 、 SG6060 、 SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID は、ストレージノードを追加することでパフォーマンスを拡張します。ストレージノードには、 VM 、ベアメタル、またはなどの専用アプライアンスを指定できます <block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block>。今回のテストでは、 SGF6024 アプライアンスを使用した最小サイズの 3 ノードグリッドで、 Apache Kafka の主要なパフォーマンス要件を超えました。Kafka クラスタを追加のブローカーとともに拡張すれば、ストレージノードを追加してパフォーマンスと容量を高めることができます。</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">StorageGRID でのトラフィック分類</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID には QoS 機能が組み込まれています。トラフィック分類ポリシーを使用すると、クライアントアプリケーションからのさまざまなタイプの S3 トラフィックを監視できます。次に、ポリシーを作成して適用し、イン / アウト帯域幅、読み取り / 書き込み同時要求の数、または読み取り / 書き込み要求の速度に基づいて、このトラフィックに制限を設けることができます。</block>
  <block id="611f69baa46f691eeeb33645e83f0fcb" category="paragraph">Apache Kafka は、 Java と Scala で書かれたストリーム処理を使用したソフトウェアバスのフレームワーク実装です。リアルタイムデータフィードを処理するための、スループットが高く、低レイテンシの統合プラットフォームを提供することを目的としています。Kafka は外部システムに接続して Kafka Connect からデータをエクスポートし、インポートすることができます。また、 Java のストリーム処理ライブラリである Kafka ストリームが提供されます。Kafka では、効率性を重視して最適化されたバイナリの TCP ベースのプロトコルを使用しています。また、ネットワーク往復のオーバーヘッドを軽減するために、メッセージを自然にまとめてグループ化する「メッセージセット」抽象化に依存しています。これにより、より大規模なシーケンシャルディスク処理や、大容量のネットワークパケット、連続するメモリブロックが実現し、 Kafka では、バースト性の高いランダムメッセージ書き込みをリニア書き込みに変換することができます。次の図は、 Apache Kafka の基本的なデータフローを示しています。</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Apache Kafka のユースケース</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka は、メッセージング、 Web サイトのアクティビティ追跡、指標、ログ集約、ストリーム処理に最もよく使用されています。 イベントのソーシングとロギングのコミット</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka はスループットの向上、組み込みのパーティショニング、レプリケーション、およびフォールトトレランスを実現しており、大規模なメッセージ処理アプリケーションに適した解決策となっています。</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka では、リアルタイムのパブリッシュサブスクライブフィードのセットとして、追跡パイプラインでユーザのアクティビティ（ページビュー、検索）を再構築できます。</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka は、多くの場合、運用監視データに使用されます。これには、分散アプリケーションからの統計情報を集約して、運用データの一元化フィードを作成する作業が含まれます。</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">多くの人が、ログアグリゲーション解決策の代わりに Kafka を使用しています。ログアグリゲーションは、一般にサーバから物理ログファイルを収集して処理のために一元的な場所（ファイルサーバや HDFS など）に配置します。Kafka は、ファイルの詳細を抽象化し、ログやイベントデータをメッセージのストリームとしてより明確に抽象化します。これにより、低レイテンシの処理が可能になり、複数のデータソースと分散データ消費のサポートが容易になります。</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Kafka のユーザの多くは、複数のステージで構成されるパイプラインでデータを処理しています。 Kafka のトピックから生の入力データが消費され、さらに消費やフォローアップ処理のために、集約、エンリッチ化、または新しいトピックへと変換されます。たとえば、ニュース記事を推薦するための処理パイプラインでは、 RSS フィードから記事のコンテンツをクロールし、それを「記事」トピックに公開することができます。さらに処理を行うと、このコンテンツをノーマライズまたは重複排除し、クレンジングされた記事コンテンツを新しいトピックにパブリッシュすることができます。また、最終的な処理段階では、このコンテンツをユーザーに推奨しようとする場合があります。このような処理パイプラインでは、個々のトピックに基づいてリアルタイムのデータフローのグラフが作成されます。</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">イベントソースとは、状態の変化を時系列のレコードとしてログに記録するアプリケーション設計のスタイルです。Kafka は、非常に大容量の格納ログデータをサポートしているため、この形式のアプリケーションのバックエンドとして最適です。</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka は分散システム用の一種の外部コミットログとして機能します。ログはノード間でデータをレプリケートするのに役立ち、障害が発生したノードがデータをリストアする際の再同期メカニズムとして機能します。Kafka のログコンパクション機能は、このユースケースに対応しています。</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="section-title">矛盾する</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Conflicent Platform は、 Kafka を完成させるエンタープライズ対応プラットフォームです。高度な機能を備えており、アプリケーションの開発と接続を高速化し、ストリーム処理による変換を可能にし、大規模なエンタープライズ運用を簡易化し、厳しいアーキテクチャ要件に対応します。ConFluent では、 Apache Kafka を作成した元のクリエイターが開発したサービスを利用して、 Kafka のメリットをエンタープライズクラスの機能で拡張しながら、 Kafka の管理や監視の負担を軽減することができます。現在、 Fortune 100 企業の 80% 以上がデータストリーミングテクノロジを採用しており、そのほとんどが Conluent 社を使用しています。</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">以下の図は、 ConFluent Kafka Platform のコンポーネントを示しています。</block>
  <block id="4f9143a5adb8a0385a1c660d201ef274" category="inline-link-macro">次は、流暢な検証です。</block>
  <block id="d566a24bfcb09090b96a073132a83173" category="paragraph"><block ref="d566a24bfcb09090b96a073132a83173" category="inline-link-macro-rx"></block></block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka は、 1 日に数兆ものイベントを処理できる、コミュニティで分散されたイベントストリーミングプラットフォームです。Kafka は、当初はメッセージングキューとして構築され、分散コミットログの抽象化に基づいています。Kafka は、 2011 年に LinkedIn で作成されオープンソースとなって以来、メッセージキューから本格的なイベントストリーミングプラットフォームへと進化してきました。Confluent Platform で Apache Kafka を配布します。Coneluent Platform は、 Kafka を補完するための追加のコミュニティ機能と商用機能を備えています。これらの機能は、本番環境の運用者と開発者の両方のストリーミングエクスペリエンスを大規模に向上させるように設計されています。</block>
  <block id="e1c012d650a6912ddb72ab0ee914d169" category="paragraph">本ドキュメントでは、次のコンテンツを提供することで、ネットアップのオブジェクトストレージ製品での上位階層型ストレージの使用に関するベストプラクティスのガイドラインについて説明します。</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">ネットアップオブジェクトストレージとの競合検証– NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">階層型ストレージのパフォーマンステスト</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">ネットアップのストレージシステムを使用する場合のベストプラクティスのガイドラインを参照してください</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">階層型ストレージが優れている理由</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">この記事は流暢なものです</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">競合製品は、多くのアプリケーション、特にビッグデータ、分析、ストリーミングワークロードに対応するデフォルトのリアルタイムストリーミングプラットフォームになっています。階層型ストレージを使用すると、ユーザは Conluent プラットフォームのストレージからコンピューティングを分離できます。データをより対費用効果の高い方法で保存し、ほぼ無制限のデータ量を保存し、オンデマンドでワークロードを増減できます。また、データやテナントのリバランシングなどの管理タスクが容易になります。S3 互換のストレージシステムでは、これらすべての機能を活用して、すべてのイベントのデータを 1 箇所で民主化できるため、複雑なデータエンジニアリングは不要です。Kafka に階層化ストレージを使用すべき理由については、を参照してください <block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block>。</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">階層化ストレージに NetApp StorageGRID を使用する理由</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID は、業界をリードするネットアップのオブジェクトストレージプラットフォームです。StorageGRID は、ソフトウェアで定義されるオブジェクトベースのストレージ解決策で、 Amazon Simple Storage Service （ S3 ） API などの業界標準のオブジェクト API をサポートします。StorageGRID は、大規模な非構造化データを格納および管理し、セキュアでデータ保持性に優れたオブジェクトストレージを実現します。コンテンツは適切なタイミングで適切な場所の適切なストレージ階層に配置されるため、グローバルに分散されるリッチメディアのワークフローを最適化し、コストを削減できます。</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">StorageGRID の最大の差別化要因は、ポリシーベースのデータライフサイクル管理を可能にする情報ライフサイクル管理（ ILM ）ポリシーエンジンです。ポリシーエンジンでは、メタデータを使用して、データの有効期間全体の格納方法を管理できます。これにより、最初はパフォーマンスを最適化し、データの経過に応じてコストと保持性を自動的に最適化できます。</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">階層型ストレージを有効にします</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">階層型ストレージの基本的な目的は、データストレージのタスクをデータ処理から分離することです。この分離によって、データストレージ階層とデータ処理階層を別々に拡張しやすくなります。</block>
  <block id="e963c7bc15c18e21f60a9969d876e3e8" category="paragraph">流暢な層ストレージの解決策は、 2 つの要因で競合する必要があります。まず、リスト操作の不整合やオブジェクトを使用できないことがあるなど、一般的なオブジェクトストアの整合性と可用性のプロパティを回避または回避する必要があります。次に、階層型ストレージと Kafka のレプリケーションとフォールトトレランスモデルの間の相互作用を正しく処理する必要があります。これには、ゾンビのリーダーが引き続きオフセット範囲を階層化する可能性も含まれます。ネットアップのオブジェクトストレージは、整合性のあるオブジェクトを使用できるようにするとともに、 HA モデルによって、オフセット範囲を階層化するために使用できるストレージにします。ネットアップのオブジェクトストレージを使用すると、オブジェクトの可用性に一貫性があり、オフセット範囲を階層化するために使用される階層化ストレージには HA モデルが採用されています。</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">階層型ストレージでは、ストリーミングデータの末尾付近での低レイテンシの読み取りや書き込みにハイパフォーマンスプラットフォームを使用できます。また、 NetApp StorageGRID などの低コストで拡張性に優れたオブジェクトストレージを使用して、高スループットの履歴読み取りを実行することもできます。また、ネットアップストレージコントローラを搭載した Spark に関するテクニカル解決策もご用意しています。詳細はこちらをご覧ください。Kafka がリアルタイムの分析パイプラインにどのように適しているかを次の図に示します。</block>
  <block id="c7e421673ed217d2262c482dc24d0995" category="paragraph"><block ref="c7e421673ed217d2262c482dc24d0995" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66b784e6401c98dcf152747d22976bf7" category="paragraph">次の図は、 NetApp StorageGRID が ConFluent Kafka のオブジェクトストレージ層にどのように適合するかを示しています。</block>
  <block id="2c3dbe3ccb3831e313d1d072656fa861" category="inline-link-macro">次の例は、解決策アーキテクチャの詳細です。</block>
  <block id="adcb27f49e58936cf868bc3cc2726dd7" category="paragraph"><block ref="adcb27f49e58936cf868bc3cc2726dd7" category="inline-link-macro-rx"></block></block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">矛盾する検証</block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">NetApp StorageGRID で、 Conluent Platform 6.2 の階層型ストレージを使用して検証を実施しました。ネットアップと流暢なチームがこの検証に協力し、検証に必要なテストケースを実施しました。</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">競合するプラットフォームの設定</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">検証には次のセットアップを使用しました。</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">検証には、 3 台の zookeepers 、 5 台のブローカー、 5 台のテストスクリプトを実行するサーバ、 256GB の RAM を搭載した tools サーバ、 16 個の CPU を使用しました。ネットアップストレージの場合は、 4 つの SGF6024 を搭載した SG1000 ロードバランサで StorageGRID を使用しました。ストレージとブローカーは、 100GbE 接続経由で接続されています。</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">次の図に、流暢な検証に使用される設定のネットワークトポロジを示します。</block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">ツールサーバは、要求をノードに送信するアプリケーションクライアントとして機能します。</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">検証 StorageGRID には HTTP プロトコルを使用しましたが、 HTTPS も使用できます。アクセスキーとシークレットキーは、「 confliclus.tir.s3.cred.file.path 」パラメータで指定したファイル名に格納されます。</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">ネットアップオブジェクトストレージ - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">単一サイト構成を StorageGRID で検証用に設定しました。</block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">検証テスト</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">以下の 5 つの検証ケースを完了しました。これらのテストは、 Trogdor フレームワークで実行されます。最初の 2 つは機能テストで、残りの 3 つはパフォーマンステストです。</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">このテストでは、階層化ストレージのニーズに応じて、オブジェクトストア API のすべての基本的な処理（ GET / PUT / DELETE など）が適切に機能するかどうかを確認します。これは、すべてのオブジェクトストアサービスが次のテストよりも先に実施されることを想定した基本的なテストです。合格または不合格の自己主張的なテストです。</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">このテストでは ' エンド・ツー・エンドの階層型ストレージ機能が ' 合格または不合格のアサート型テストで適切に機能するかどうかを判断しますテストでは、デフォルトで階層化が有効になっており、ホットセットサイズが大幅に縮小されたテストトピックが作成されます。新しく作成されたテストトピックへのイベントストリームが生成され、ブローカーがセグメントをオブジェクトストアにアーカイブするのを待機し、イベントストリームを消費して、消費されたストリームが生成されたストリームと一致することを検証します。イベントストリームに生成されるメッセージの数は設定可能で、テストのニーズに応じてユーザが十分な大きさのワークロードを生成できます。ホットセットのサイズを小さくすることで、消費者がアクティブなセグメントの外部でフェッチしたファイルはオブジェクトストアからのみ提供されます。これにより、オブジェクトストアの読み取りの正確性をテストできます。このテストは、オブジェクトストアフォールト挿入の有無にかかわらず実施しました。StorageGRID のいずれかのノードでサービスマネージャサービスを停止し、エンドツーエンド機能がオブジェクトストレージで機能することを検証することで、ノード障害をシミュレートしました。</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">ワークロードベンチマークを消費</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">このテストでは、セグメントをアーカイブすることにより、オブジェクトストアへの書き込みワークロードを間接的に生成しました。コンシューマグループがセグメントを取得すると、読み取りワークロード（セグメント読み取り）がオブジェクトストレージから生成されました。このワークロードはテストスクリプトで生成されました。このテストでは、並列スレッドでのオブジェクトストレージの読み取りと書き込みのパフォーマンスをチェックしました。階層化機能の正確性テストと同様に、オブジェクトストアフォールト挿入を使用したテストと使用しなかったテストを実施しました。</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">保存ワークロードベンチマーク</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">このテストでは、トピックの保持ワークロードが多い場合のオブジェクトストアの削除パフォーマンスを確認しました。保持ワークロードは、テストトピックと並行して多数のメッセージを生成するテストスクリプトを使用して生成されました。テストトピックでは、サイズベースおよび時間ベースの強力な保持設定を使用してイベントストリームをオブジェクトストアから継続的にパージするように設定しました。その後、セグメントがアーカイブされました。その結果、ブローカーによるオブジェクトストレージの削除や、オブジェクトストアの削除処理のパフォーマンス収集が行われ、大量の削除が発生していました。</block>
  <block id="0c7a4422707cf3f11c73c66ea0d5d215" category="inline-link-macro">前のバージョン：サイジング</block>
  <block id="f902aefc255b4eb6b31c283ad42816de" category="paragraph"><block ref="f902aefc255b4eb6b31c283ad42816de" category="inline-link-macro-rx"></block></block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">このドキュメントでは、検証テスト、階層型ストレージのパフォーマンス結果、調整、 S3 コネクタの堪能、セルフバランシング機能など、ネットアップストレージでの Conluent Tiered Storage の使用に関するベストプラクティスを紹介しています。ILM ポリシー、検証のための複数のパフォーマンステストと業界標準の S3 API を使用した流暢なパフォーマンスを考慮した場合、 NetApp StorageGRID オブジェクトストレージは流暢な階層化ストレージに最適な選択肢です。</block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Conluent Platform の無限のストレージ</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">競合する階層型ストレージ - ベストプラクティスとサイジング</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Conluent Platform 用の Amazon S3 シンクコネクタ</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Kafka のサイジング</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">StorageGRID のサイジング</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Kafka のユースケース</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">統合されたプラットフォーム 6.0 の自律分散 Kafka クラスター</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="a5091aedd97daf7c5a5297fa5d73a469" category="cell">2021 年 12 月</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">競合する自己バランシングクラスタ</block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">Kafka クラスタを以前に管理していたことがある場合、パーティションを別のブローカーに手動で再割り当てすることで、ワークロードがクラスタ全体に分散されるようにするという問題に慣れている方がよいでしょう。Kafka を大規模に導入している組織では、大容量のデータを変更するのが難しく、面倒でリスクが伴う可能性があります。特に、ミッションクリティカルなアプリケーションをクラスタの上に構築する場合、リスクが高くなります。しかし、 Kafka を使用するケースが最小であっても、処理に時間がかかり、人為的ミスが発生しやすくなります。</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">このラボでは、流暢な自己分散クラスタ機能をテストし、クラスタトポロジの変更や不均衡な負荷に基づいてリバランシングを自動化しました。一括リバランシングテストは、ノード障害や拡張ノードでブローカー間のデータのリバランシングが必要になった場合に、新しいブローカーを追加する時間を測定するのに役立ちます。従来の Kafka 構成では、クラスタの拡張に合わせてデータの再分散量が増える一方で、階層型ストレージでは少量のデータしかリバランシングされません。この検証に基づき、階層型ストレージのリバランシングには数秒から数分かかりますが、従来の Kafka アーキテクチャでは、クラスタの拡張に伴ってリニアに拡張されます。</block>
  <block id="c9e4cfc44588cc591252c88cad0a3a09" category="paragraph">セルフバランシングクラスタでは、パーティションの再調整が完全に自動化され、 Kafka のスループットが最適化され、ブローカーの拡張が高速化され、大規模なクラスタを実行する際の運用上の負担が軽減されます。安定した状態では、自己バランシングクラスタがブローカー間のデータのスキューを監視し、パーティションを継続的に再割り当てしてクラスタのパフォーマンスを最適化します。プラットフォームをスケールアップまたはスケールダウンすると、新しいブローカーが存在することを自己分散クラスタが自動的に認識したり、古いブローカーが削除されたことを確認したり、後続のパーティションの再割り当てをトリガーしたりします。これにより、ブローカーの追加や運用停止が容易になり、 Kafka クラスタの柔軟性が根本的に向上します。これらの利点は、手動操作、複雑な計算、またはパーティションの再割り当てが一般的に発生する人的ミスのリスクを必要としないことです。その結果、データのリバランシングが完了するまでの時間が大幅に短縮され、クラスタを常時監視するのではなく、価値の高いイベントストリーミングプロジェクトに集中できます。</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">サイジング</block>
  <block id="5ffdfbbb428796f516e072e038d107b0" category="inline-link-macro">Previous ：ベストプラクティスのガイドライン</block>
  <block id="49575973ec85e64724d2a45d401f32b3" category="paragraph"><block ref="49575973ec85e64724d2a45d401f32b3" category="inline-link-macro-rx"></block></block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Kafka サイジングは、シンプル、きめ細かい、リバース、およびパーティションの 4 つの構成モードで実行できます。</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">シンプル</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">シンプルモードは、 Apache Kafka を初めて使用するユーザや初期状態のユースケースに適しています。このモードでは、スループット MBps 、読み取りファンアウト、保持、リソース利用率（デフォルトは 60% ）などの要件を指定します。オンプレミス（ベアメタル、 VMware 、 Kubernetes 、 OpenStack ）やクラウドなどの環境にも移行できます。Kafka クラスタのサイジングは、この情報に基づいて、ブローカーに必要なサーバ数、 Zookeeper 、 Apache Kafka Connect Workers 、スキーマレジストリ、 REST プロキシ、 ksqlDB 、および Conluent コントロールセンターを提供します。</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">階層型ストレージの場合、 Kafka クラスタのサイジングのためのきめ細かい構成モードを検討してください。Granular モードは、経験豊富な Apache Kafka ユーザや明確に定義されたユースケースに適しています。このセクションでは、プロデューサ、ストリームプロセッサ、およびコンシューマのサイジングについて説明します。</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">プロデューサー</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Apache Kafka の開発者（ネイティブクライアント、 REST プロキシ、 Kafka コネクタなど）については、次の情報を参照してください。</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">* 名前。 * Spark 。</block>
  <block id="0ae6d6b48753e01bf1ae73bb86ee6276" category="list-text">* 開発者の種類。 * アプリケーションまたはサービス、プロキシ (REST 、 MQTT 、その他 ) 、および既存のデータベース (RDBMS, NoSQL 、その他 ) 。「わからない」を選択することもできます。</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">* 平均スループット。 * 1 秒あたりのイベント数（ 1 、 000 、 000 など）。</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">* 最大スループット。 * 1 秒あたりのイベント数（ 4 、 000 、 000 など）。</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">* 平均メッセージサイズ。 * バイト単位、非圧縮（最大 1MB 、 1000 など）。</block>
  <block id="dd6d45bc2ad71619bde2260f1776e9b2" category="list-text">* メッセージ形式。 * Avro 、 JSON 、プロトコルバッファ、バイナリ、テキスト、 「わからない」など。</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">* 複製係数 * オプションは 1 、 2 、 3 （流暢な推奨）、 4 、 5 です。 または 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">* 保持時間。 * 1 日（例：）。Apache Kafka にデータを保存しておく期間を教えてください。無期限には、任意の単位で -1 を入力します。無制限の保持期間を 10 年と想定しています。</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">[ ブローカー数を減らし、 Infinite Storage を許可するための階層化ストレージを有効にする ] のチェックボックスをオンにします。</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">階層型ストレージが有効になっている場合は ' リテンションフィールドによって ' ブローカにローカルに保存されるデータのホットセットが制御されますアーカイブ保持フィールドは、アーカイブオブジェクトストレージにデータを格納する期間を制御します。</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">* アーカイブ・ストレージの保存期間 * 1 年（例：）データをアーカイブストレージに保存する期間無期限の任意の単位を指定して -1 を入力します。無制限の保持期間を 10 年と想定しています。</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">* 成長乗数 * 1 （例：）。このパラメータの値が現在のスループットに基づく場合は、 1 に設定します。追加の増加に基づいてサイズを決定するには、このパラメータに増加率を設定します。</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">* プロデューサーインスタンスの数。 * 10 （例：）実行されるプロデューサーインスタンスの数はいくつですか？この値は、 CPU 負荷をサイジング計算に含めるために必要です。空白の値は、 CPU 負荷が計算に組み込まれていないことを示します。</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">この入力例に基づいて、サイジングはプロデューサーに次のように影響します。</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">非圧縮バイト単位の平均スループット： 1Gbps圧縮されていないバイト数のピークスループット： 4Gbps圧縮されたバイト数の平均スループット： 400MBps 。圧縮バイトの最大スループット： 1.6GBps 。デフォルトの 60% の圧縮率に基づいています（この値は変更できます）。</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">必要なホットセットストレージの合計数 :31 、 104TB ( レプリケーションを含む ) 、圧縮。必要なオフブローカーアーカイブストレージの合計： 378 、 432TB 、圧縮使用 <block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> StorageGRID のサイジングの場合：</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">Stream Processors は、 Apache Kafka のデータを使用し、 Apache Kafka に生成するアプリケーションまたはサービスを記述する必要があります。ほとんどの場合、これらは ksqlDB ストリームまたは Kafka ストリームで構築されます。</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">* 名前。 * Spark streamer 。</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">* 処理時間。 * このプロセッサーは 1 つのメッセージを処理するのにどれくらいかかりますか？</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 ミリ秒（シンプルでステートレスな変換）（例）、 10 ミリ秒（ステートフルなメモリ内動作）</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100ms （ステートフルネットワークまたはディスク処理）、 1000ms （サードパーティ製 REST コール）</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">このパラメータをベンチマークして、その所要時間を正確に把握しました。</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">* 出力保持 * 1 日（例）ストリームプロセッサは Apache Kafka に出力を返します。この出力データを Apache Kafka にどれくらいの期間保存しますか？無期限の任意の単位を指定して -1 を入力します。</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">［ ブローカー数を減らし、 Infinite Storage を許可するには、 ［ 階層型ストレージを有効にする ］ チェックボックスをオンにします。</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">* アーカイブ・ストレージの保存期間 * 1 年（例：）データをアーカイブストレージに保存する期間無期限の任意の単位を指定して -1 を入力します。無制限の保持期間を 10 年と想定しています。</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">* 出力パススルー率。 * 100 （例：）ストリームプロセッサは Apache Kafka に出力を返します。Apache Kafka に出力されるインバウンドスループットの割合を教えてください。たとえば、インバウンドスループットが 20Mbps で、この値が 10 の場合、出力スループットは 2Mbps になります。</block>
  <block id="d1a6a4732f959b58cd8c77edcf10b31b" category="list-text">この機能はどのアプリケーションから読み取られますか。「 Spark 」を選択すると、販売担当者タイプに基づいたサイジングで使用された名前になります。上記の入力に基づいて、ストリームプロセッサインスタンスとトピックパーティションの推定にサイジングを行うと、次のような効果が期待できます。</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">このストリームプロセッサアプリケーションには、次の数のインスタンスが必要です。受信するトピックでは、多くのパーティションが必要になる場合があります。このパラメータを確認するには、 [ 流暢 ] に連絡してください</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">平均スループットで 1 、 000 、増加率なし</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">4 、 000 ：増加率のないピークスループット</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1 、 000 ：平均スループットと増加率</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">4 、 000 ：最大スループットで増加率</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">消費者</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Apache Kafka のデータを利用していて、 Apache Kafka にデータを生成していないアプリケーションやサービスについて説明してください。たとえば、ネイティブのクライアントや Kafka Connector などです。</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">* 名前 . * Spark consumer 。</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">* 処理時間。 * この消費者は、 1 つのメッセージを処理するのにどれくらいの時間がかかりますか。</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 ミリ秒（シンプルでステートレスなロギングなどのタスク）</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 ミリ秒（データストアへの高速書き込み）</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 ミリ秒（データストアへの書き込み速度が遅い）</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000 ミリ秒（サードパーティの REST コール）</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">その他のベンチマークされたプロセスの中には、既知の期間があります。</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">* 消費者タイプ。 * アプリケーション、プロキシ、シンクを既存のデータストア（ RDBMS 、 NoSQL など）に。</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">この機能はどのアプリケーションから読み取られますか。このパラメータは、以前に決定したプロデューサーおよびストリームのサイジングを使用して接続します。</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">上記の入力に基づいて、コンシューマインスタンスとトピックパーティションの推定サイズを決定する必要があります。コンシューマアプリケーションには、次の数のインスタンスが必要です。</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">平均スループットで 2 、 000 、増加率はゼロ</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">8 、 000 ：ピークスループットで、増加率はゼロです</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">平均スループットで 2 、 000 、増加率も含まれます</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">8 、 000 ：最大スループット。増大の乗数も含まれます</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">受信トピックでは、この数のパーティションも必要になる場合があります。確認のため、流暢な連絡をします。</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">生産者、ストリームプロセッサ、および消費者の要件に加えて、次の追加要件を提供する必要があります。</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">* 再構築時間。 * 例： 4 時間。Apache Kafka ブローカーホストで障害が発生すると、そのデータは失われ、障害が発生したホストと交換するために新しいホストをプロビジョニングすると、この新しいホストをどのくらいの速さで再構築する必要がありますか？値が不明な場合は、このパラメータを空白のままにします。</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">* リソース使用率目標（パーセンテージ）。 * 例： 60 。平均スループット中にホストをどの程度使用しますか？Conluent の自己バランシングクラスタを使用していない場合は、 60% の使用率を推奨します。この場合、使用率が高くなります。</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">環境の説明</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">* どの環境でクラスターを実行しますか？ * Amazon Web Services 、 Microsoft Azure 、 Google クラウドプラットフォーム、オンプレミスのベアメタル、 VMware オンプレミス、 OpenStack をオンプレミスで運用するのか、 Kubernates をオンプレミスで運用するのか</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">* ホストの詳細。 * コアの数： 48 （例：）、ネットワークカードのタイプ（ 10GbE 、 40GbE 、 16GbE 、 1GbE 、またはその他のタイプ）。</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">* ストレージボリューム。 * ホスト： 12 （例：）。ホストあたりのハードドライブまたは SSD の数はいくつですか。競合するホストごとに 12 台のハードドライブを推奨します。</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">* ストレージ容量 / ボリューム（ GB 単位）。 * 1000 （例：）。1 つのボリュームストアでギガバイト単位のストレージ容量はどれくらいですか？競合する場合は 1TB のディスクを使用します。</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">* ストレージ構成 * ストレージ・ボリュームの構成方法競合製品は、 Conluent のすべての機能を活用するために RAID10 を推奨しています。JBOD 、 SAN 、 RAID 1 、 RAID 0 、 RAID 5 、 その他のタイプもサポートされています。</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">* 単一ボリュームのスループット（ Mbps ）。 * 125 （例：）1 つのストレージボリュームで 1 秒あたりのメガバイト数で読み取りまたは書き込みを行うことができる速度はどれくらいですか。競合するハードディスクドライブは、通常 125 Mbps のスループットを持つ標準ハードディスクドライブをお勧めします。</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">* メモリ容量（ GB ）。 * 64 （例）。</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">環境変数を決定したら、 Size my Cluster （マイクラスタのサイズ）を選択します。前述の例に基づいて、 Con裕福 な Kafka のサイジングを決定しました。</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">* Apache Kafka * Broker count ： 22 。クラスタはストレージバウンドです。階層型ストレージを有効にして、ホスト数を減らし、ストレージを無制限にすることを検討してください。</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">* Apache ZooKeeper. * Count ： 5 ； Apache Kafka Connect Workers ： Count ： 2 ； Schema Registry ： Count ： 2 ； REST Proxy ： Count ： 2 ； ksqlDB ： Count ： 2 ； Conluent Control Center ： Count ： 1 。</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">ユースケースを考慮せずに、プラットフォームチームにリバースモードを使用する。パーティションモードを使用して、 1 つのトピックに必要なパーティションの数を計算します。を参照してください<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> リバースモードとパーティションモードに基づいたサイジングの場合</block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">検証に基づくと、 S3 オブジェクトストレージにはデータを格納するのがベストプラクティスです。</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">高スループットの SAN （特に FC ）を使用して、ブローカーのホットデータやローカルディスクを保持できます。これは、階層型ストレージの構成が流暢であるためです。 ブローカーデータディレクトリに格納されているデータのサイズは、オブジェクトストレージにデータが移動される際のセグメントサイズと保持時間に基づいています。</block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">* Kafka のチューニング。 * 階層型ストレージのパフォーマンスを向上させるには、 TierFetcherNumThreads と TierArchiverNumThreads を増やします。一般的なガイドラインとして、 TierFetcherNumThreads を増やして物理 CPU コア数に合わせ、 TierArchiverNumThreads を CPU コア数の半分に増やします。たとえば、サーバープロパティで、 8 つの物理コアを持つマシンがある場合、 conflicent.tier.fetcher.threads=8 と、 conflicent.tier.Archiver .num.threads=4 を設定します。</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">* トピックが削除されるまでの時間です。 * トピックが削除されると、オブジェクトストレージ内のログセグメントファイルの削除はすぐには開始されません。デフォルト値の 3 時間を指定した時間間隔が設定されているため、この時間が経過するとファイルが削除されます。この間隔の値を変更するには、設定 confluent.tier.topic.delete.check.interval.ms を変更します。トピックまたはクラスタを削除する場合は、それぞれのバケット内のオブジェクトを手動で削除することもできます。</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">* 階層型ストレージの内部トピックに関する ACL 。 * オンプレミス環境に推奨されるベストプラクティスは、階層型ストレージに使用される内部トピックについて、 ACL 承認者を有効にすることです。このデータへのアクセスをブローカーユーザのみに制限するには、 ACL ルールを設定してください。これにより、内部トピックが保護され、階層化されたストレージデータおよびメタデータへの不正アクセスを防止できます。</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">ユーザ「 &lt;Kafka&gt; 」を、導入環境の実際のブローカプリンシパルに置き換えます。</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">たとえば ' コマンド confliclus-tier-state は ' 階層型ストレージの内部トピックに ACL を設定します現在、階層化ストレージに関連する内部トピックは 1 つだけです。この例では、内部トピックのすべての処理にプリンシパル Kafka 権限を提供する ACL を作成しています。</block>
  <block id="c7aa1f1ea2c8ad1712056dd97321d808" category="inline-link-macro">次：サイジング</block>
  <block id="de8a38c4c90ce81d8c4b82c44500e504" category="paragraph"><block ref="de8a38c4c90ce81d8c4b82c44500e504" category="inline-link-macro-rx"></block></block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">このセクションでは、流暢な検証に使用するハードウェアおよびソフトウェアについて説明します。この情報は、ネットアップストレージを使用した流暢なプラットフォームの導入に該当します。次の表に、テストに使用した解決策アーキテクチャと基本コンポーネントを示します。</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">5 台のツールサーバ</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">階層化ストレージ向けの NetApp StorageGRID</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">StorageGRID ソフトウェア</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">SGF6024 × 4</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">100GbE × 4 （ブローカーと StorageGRID インスタンス間のネットワーク接続）</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">矛盾点 3 コネクタ</block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Amazon S3 Sink Connector は、 Apache Kafka のトピックから Avro 、 JSON 、またはバイト形式の S3 オブジェクトにデータをエクスポートします。Amazon S3 シンクコネクタは、 Kafka から定期的にデータをポーリングし、 S3 にアップロードします。ユーザは、各 Kafka パーティションのデータをチャンクに分割するために使用します。データのチャンクはそれぞれ S3 オブジェクトとして表されます。キー名は、トピック、 Kafka パーティション、およびこのデータチャンクの開始オフセットをエンコードします。</block>
  <block id="e621a272d292cd32516db52fc07b5855" category="inline-link-macro">次は、流暢な自己リバランシングクラスタです。</block>
  <block id="56b9b2115a3169192950ec86c26f6add" category="paragraph"><block ref="56b9b2115a3169192950ec86c26f6add" category="inline-link-macro-rx"></block></block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">自己リバランシングクラスタが競合しています</block>
  <block id="a02c6dbd226d5506c1b4b07f6d383615" category="list-text">「 -parallel 」オプションを指定した XCP コピーは、 CPU の数に基づいています。ほとんどの XCP データ転送および移行処理には、デフォルトのパラレルスレッド数（ 7 ）で十分な場合があります。XCP Windows のデフォルトでは、並列プロセスの数は CPU の数と同じです。「 -parallel 」オプションの最大数は、コア数以下にする必要があります。</block>
  <block id="740950b0e27cdd5def3c4295d5840851" category="list-text">データ転送の開始には 10GbE が適しています。ただし、 25GbE と 100GbE でテストした結果、データ転送が向上し、大容量のファイルサイズのデータ転送に推奨されています。</block>
  <block id="ef1ee9d1f1e9874aca751251bbce31bf" category="inline-link-macro">前：流暢な検証。</block>
  <block id="6d08115c54837de983d3ddc9dcd8f038" category="paragraph"><block ref="6d08115c54837de983d3ddc9dcd8f038" category="inline-link-macro-rx"></block></block>
  <block id="d7023badac36eeb28bf29785a97c493c" category="inline-link-macro">前のバージョン：解決策アーキテクチャの詳細。</block>
  <block id="258ee3f437d6a20985ccf4e13065a097" category="paragraph"><block ref="258ee3f437d6a20985ccf4e13065a097" category="inline-link-macro-rx"></block></block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam 、 Joseph Kandatilparamil 、 NetApp Rankesh Kumar 、 Conluent</block>
  <block id="524a5aa4f422c84af378b5418bb1539b" category="inline-link-macro">前：流暢な自己リバランシングクラスタ。</block>
  <block id="ae7f441436d5c9a5dc4278e4ea2b87e8" category="paragraph"><block ref="ae7f441436d5c9a5dc4278e4ea2b87e8" category="inline-link-macro-rx"></block></block>
  <block id="b583dc49832a978014ef0d14fe7ef1ce" category="paragraph">ワークフローの移行、クラウドへの拡張 / バースト対応、バックアップ / リストア、ディザスタリカバリなど、ネットアップが各ハイパースケーラに VMware 環境を提供するソリューションの詳細については、こちらをご覧ください。</block>
  <block id="bf3f0fd9ec5faf81793c3abc5e3b9127" category="admonition">この環境ゲスト接続ストレージのみ。</block>
  <block id="8ad188089680179dea816084001d7bf0" category="sidebar">AI と分析のワークフローに対応した E シリーズと BeeGFS を使用したデータ移動</block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">* NFS 設定 *</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">* FC / FCoE 設定 *</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">* iSCSI 設定 *</block>
  <block id="120c02d2aa6cda1e3b75902fb4fc0b53" category="doc">ハイブリッドクラウド、デスクトップ仮想化、コンテナソリューションの新機能</block>
  <block id="9db3527848e891e0a9340c443515e770" category="doc">ネットアップと VMware のソリューションを今すぐ始めましょう</block>
  <block id="c4c3630750312520bc4b93c16056bfd7" category="doc">NVIDIA を使用した NetApp EF シリーズ AI</block>
  <block id="e6ee072aeeb0647d8c0cfe75e4cde51d" category="paragraph">ネットアップと NVIDIA が提供する EF シリーズ AI 統合インフラソリューションの概要</block>
  <block id="f512fcc18626023378bfe28dce07116d" category="list-text"><block ref="f512fcc18626023378bfe28dce07116d" category="inline-link-macro-rx"></block></block>
  <block id="ae02a3224f15623423f197426c44a26d" category="list-text"><block ref="ae02a3224f15623423f197426c44a26d" category="inline-link-macro-rx"></block></block>
  <block id="8ce1a272bf4c47418ea6d69083f2df4f" category="inline-link-macro">BeeGFS 導入ガイド</block>
  <block id="7991adac41b3f0e292dee61e87c39052" category="list-text"><block ref="7991adac41b3f0e292dee61e87c39052" category="inline-link-macro-rx"></block></block>
  <block id="9d2ca817bb7dd69d6f7dc09932a53524" category="summary">ネットアップの人工知能ソリューションは、 AI / ML 分野全体でネットアップストレージの機能を実証する、戦略的かつ技術的なソリューションのセットです。</block>
  <block id="b54a1e289898cf21f63715dfe64025b7" category="doc">ネットアップの人工知能ソリューション</block>
  <block id="2bbac71d034e7a7a1fca44c7500e187b" category="doc">NVIDIA を使用した NetApp ONTAP AI</block>
  <block id="4618b9225719de309c0b0f5aa4718c7b" category="paragraph">ネットアップと NVIDIA が提供する ONTAP AI 統合インフラソリューションの概要</block>
  <block id="ab9d770eb05e7725141740f508566fce" category="section-title">NVIDIA DGX A100 システムを搭載した NetApp ONTAP AI</block>
  <block id="7c962be0dc8fdf28c1c4279fe5256a22" category="section-title">NVIDIA DGX A100 システムと Mellanox を搭載した NetApp ONTAP AI Spectrum Ethernet スイッチ</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">英語</block>
  <block id="37ce0afb395b0346118a74c4f05f20a7" category="list-text"><block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block>&amp;f ： @face_souction _mktg= [AI 、分析、人工知能 ] + [AI blogs on NetApp.com ]</block>
  <block id="191ea533aa1478d35c965840430fbfe6" category="summary">ネットアップの最新データ分析ソリューションは、 AI 環境全体でネットアップストレージの機能を実証する、戦略的およびテクノロジ的な機能のセットです。</block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="doc">ネットアップの最新データ分析ソリューション</block>
  <block id="22169240c9a4c0ab61a4ed13c981c5ef" category="sidebar">AI ワークロード向けの統合インフラ</block>
  <block id="8508ab1994a5679882beb6400778e8ba" category="sidebar">NVIDIA を使用した EF シリーズ AI</block>
  <block id="ec820f861118408d42b077dbf109f374" category="sidebar">NetApp E シリーズストレージを使用した IBM Spectrum Scale</block>
  <block id="b63ada7ec650c01320cddeda05deb779" category="sidebar">Lenovo ThinkSystem を使用したエッジネットアップでの AI 推論</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">AI 向け NetApp ONTAP および Lenovo ThinkSystem SR670</block>
  <block id="e5c3eeefe82172631e21562a8d3672a5" category="sidebar">AI 向け NetApp AFF A800 および富士通サーバ PRIMERGY GX2570 M5</block>
  <block id="2fa3e2a0ff5682666455eed0a7b1b569" category="sidebar">データレイクとデータパイプライン</block>
  <block id="6ac39037a7efa2708d15c0e0e20fb188" category="sidebar">自動運転ワークロードのための StorageGRID データレイク</block>
  <block id="eeb4980c2a89f07abf1a0b927066b23c" category="sidebar">AI に対応した E シリーズと BeeGFS を使用したデータ移動</block>
  <block id="13f985aafb32ac9e387186e5a437f96e" category="sidebar">データキャッシング機能を備えたハイブリッドクラウド AI</block>
  <block id="ac82c7a9ef13f3b604553ccfe1a5bd76" category="sidebar">オーケストレーションと管理</block>
  <block id="3cd04d0e6cf45786c9e94148f213b537" category="sidebar">NetApp AI コントロールプレーンを使用して、 AI パイプラインとワークスペースオーケストレーションを実現</block>
  <block id="447e8e0102d91009c125adb678cd7fb5" category="sidebar">Iguazio による MLRun パイプライン</block>
  <block id="71e6eb0dc5951ca93effe179d000f534" category="sidebar">感情分析</block>
  <block id="cfff43e76ea0e95d290a279bdb279a2e" category="sidebar">クリックスルーレート予測 - Azure での分散トレーニング</block>
  <block id="29931fafbbc65eabe1029aee9a3a5a85" category="sidebar">LANE 検出 - Azure の分散トレーニング</block>
  <block id="7656ac1f9ee1e1763f07a285578d922a" category="sidebar">NVIDIA Jarvis を使用した会話型 AI</block>
  <block id="8f0148532a5b5382ec4f005c8a96a4fa" category="sidebar">自動運転</block>
  <block id="f869ce5572b45e50fe014954c4248d60" category="sidebar">ヘルスケア - Diagnostic Imaging （診断イメージング）</block>
  <block id="951b9c6690c2a4c1228ada2a9980d5a8" category="sidebar">クレジットカード詐欺検出</block>
  <block id="f0b83f1f7d211bfb4e278dafd2d6b4fa" category="sidebar">NetApp Storage 解決策を使用した Apache Spark ワークロード</block>
  <block id="6bf79bc16e8a34cf5698aabd27cecef1" category="sidebar">最新のデータ分析解決策の概要</block>
  <block id="cd47dd01745339787e4c7300389401f2" category="sidebar">ベストプラクティス</block>
  <block id="1bd369d8fc8172d625ac41a1815aa09d" category="sidebar">ConFluent Kafka のベストプラクティスです</block>
  <block id="3ed3645b4e41749082a0692a758a3132" category="sidebar">ハイブリッドクラウドソリューション - Spark と Hadoop のユースケース</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">ブログ： Use XCP for Data Migration from a Data Lake and HPC to ONTAP NFS</block>
  <block id="9cb9fe27a24f987a1889d5fc1d5d139e" category="sidebar">『 NetApp E-Series Deployment Guide 』を参照して BeeGFS を導入します</block>
  <block id="d064ecad73d9352507092f40af924057" category="cell">02/02/2022</block>
  <block id="c0598da0ea2338576f8d67854c56e3f6" category="cell">ランディングページを作成し、 AI と最新のデータ分析のためのコンテンツをより効率的に整理</block>
  <block id="84c45df200c907852c1e92875618b432" category="cell">2022 年 1 月 22 日</block>
  <block id="b385810d0a927b9d15a69218e3fb38c4" category="cell">TR ： AI と分析のワークフローに対応する E シリーズと BeeGFS を使用したデータ移動を追加</block>
  <block id="89d5e6802ef5a3ae4296f49d4d6bc447" category="sidebar">その他のリソース</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">ブログ： Apache Spark は NetApp Data Analytics Playground で再生されます</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV ： Big Data Analytics プレイリスト</block>
  <block id="0a2866cc3e2ba203c7e2e3ebeca395be" category="sidebar">UNIX および NFS を使用する NetApp clustered Data ONTAP での SAP と Oracle の運用 Data ONTAP</block>
  <block id="4e36e97d23b00520e4b573859ee4cb26" category="list-text"><block ref="4e36e97d23b00520e4b573859ee4cb26" category="inline-link-macro-rx"></block></block>
  <block id="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link"><block ref="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link-rx"></block></block>
  <block id="b17e2a7e5f42c90b40de5971850339ae" category="list-text">TR-4597 ：『 VMware vSphere for ONTAP 』<block ref="5938ff9651f6c5e53544676ba8504afc" category="inline-link-rx"></block></block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">この検証では、 4 台のサーバを Network Shared Disk （ NSD; ネットワーク共有ディスク）サーバとして使用して、 GPFS 用の物理ディスクを提供しました。GPF は、次の図に示すように、 NFS エクスポートとしてエクスポートするために NSD ディスクの上に作成されます。XCP を使用して、 GPFS でエクスポートされた NFS から NetApp NFS ボリュームにデータをコピーしました。</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">NetApp ONTAP NFS への GPF</block>
  <block id="823313a32a4a1131e0469fac26acbdac" category="inline-link-macro">前の図： Data Mover 解決策 for AI</block>
  <block id="c4e4b7ebe157b09b7d1a0db25078dc45" category="paragraph"><block ref="c4e4b7ebe157b09b7d1a0db25078dc45" category="inline-link-macro-rx"></block></block>
  <block id="9a1bdf4376c8448278cf38263e4da8c7" category="paragraph"><block ref="9a1bdf4376c8448278cf38263e4da8c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">GPF の要点</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">GPFS では、次のノードタイプが使用されます。</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">* 管理ノード。 * ノード間の通信に管理コマンドが使用するノード名を含むオプションのフィールドを指定します。たとえば ' 管理ノード mastr-51.netapp.com` は ' クラスタ内の他のすべてのノードにネットワーク・チェックを渡すことができます</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">* クォーラムノード。クォーラムの取得元のノードのプールにノードが含まれているかどうかを判断します。少なくとも 1 つのノードがクォーラムノードとして必要です。</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">* マネージャノード。 * ノードがノードプールの一部であるかどうかを示します。このプールからファイルシステムマネージャとトークンマネージャを選択できます。複数のノードをマネージャーノードとして定義することをお勧めします。マネージャとして指定するノードの数は、ワークロードと所有する GPFS サーバライセンスの数によって異なります。大規模な並列ジョブを実行する場合は、 Web アプリケーションをサポートする 4 ノードクラスタよりも多くのマネージャノードが必要になることがあります。</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*NSD サーバ。 *GPFS で使用する各物理ディスクを準備するサーバ。</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">* プロトコルノード。 *Secure Shell （ SSH; セキュアシェル）プロトコルを介して、 NFS と GPFS データを直接共有するノード。このノードには GPFS サーバーライセンスが必要です。</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">GPFS 、 NFS 、および XCP の操作のリスト</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">このセクションでは、 GPFS を作成し、 NFS エクスポートとして GPFS をエクスポートし、 XCP を使用してデータを転送する操作について説明します。</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">GPFS を作成します</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">GPFS を作成するには、次の手順を実行します。</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">Linux 版のスペクトルスケールデータアクセスをいずれかのサーバにダウンロードしてインストールします。</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">すべてのノードに前提条件パッケージ（シェフなど）をインストールし、すべてのノードで Security-Enhanced Linux （ SELinux ）を無効にする。</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">インストールノードをセットアップし、管理ノードと GPFS ノードをクラスタ定義ファイルに追加します。</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">マネージャーノード、クォーラムノード、 NSD サーバー、および GPFS ノードを追加します。</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">GUI 、管理ノード、 GPFS ノードを追加し、必要に応じて GUI サーバを追加します。</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">別の GPFS ノードを追加し、すべてのノードのリストを確認します。</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">クラスタ定義ファイル内のすべての GPFS ノードで設定するクラスタ名、プロファイル、リモートシェルバイナリ、リモートファイルコピーバイナリ、およびポート範囲を指定します。</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">GPFS 構成設定を表示し、追加の管理ノードを追加します。</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">データ収集を無効にし、 IBM サポートセンターにデータパッケージをアップロードします。</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">インストールの前に、 NTP を有効にし、構成を事前確認します。</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">NSD ディスクを構成、作成、およびチェックする。</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">GPFS を作成します。</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">GPFS をマウントします。</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">GPFS に必要な権限を確認して提供します。</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">「 dd 」コマンドを実行して、 GPFS の読み書きを確認します。</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">GPFS を NFS にエクスポートする</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">GPFS を NFS にエクスポートするには、次の手順を実行します。</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">GPFS を /etc/exports ファイルを介して NFS としてエクスポートします</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">必要な NFS サーバパッケージをインストールします。</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">NFS サービスを開始します。</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">NFS クライアントを検証するために、 GPFS 内のファイルをリストします。</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">NFS クライアントを設定します</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">NFS クライアントを設定するには、次の手順を実行します。</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">GPFS を /etc/exports ファイルを使用して NFS としてエクスポートします。</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">NFS クライアントサービスを開始します。</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">NFS クライアントで NFS プロトコルを使用して GPFS をマウントします。</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">NFS Mounted フォルダ内の GPFS ファイルのリストを検証します。</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">XCP を使用して、 GPFS エクスポート NFS から NetApp NFS にデータを移動します。</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">NFS クライアントで GPFS ファイルを検証します。</block>
  <block id="ae2b7fcf15ee142a2de2b3ba9573b414" category="inline-link-macro">次の例： HDFS と MapR - FS を ONTAP NFS に接続。</block>
  <block id="545d9ad8cb56e65641eb4e8083301a39" category="paragraph"><block ref="545d9ad8cb56e65641eb4e8083301a39" category="inline-link-macro-rx"></block></block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">このセクションでは、 NetApp XCP を使用して GPFS を設定し、 NFS にデータを移動するために必要な詳細な手順について説明します。</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">NFS に対する GPF - 詳細な手順</block>
  <block id="b523cc107fd56956277d38d32b34c938" category="inline-link-macro">前のページ：ビジネス上のメリット</block>
  <block id="c415260b3bf5ed05c37515a8e4e526f3" category="paragraph"><block ref="c415260b3bf5ed05c37515a8e4e526f3" category="inline-link-macro-rx"></block></block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">GPFS を設定します</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">いずれかのサーバに Linux 用 Spectrum Scale Data Access をダウンロードしてインストールします。</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">すべてのノードに前提条件パッケージ（シェフとカーネルヘッダーを含む）をインストールします。</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">すべてのノードで SELinux を無効にする。</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">インストールノードをセットアップします。</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">管理ノードと GPFS ノードをクラスタ定義ファイルに追加します。</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">マネージャノードと GPFS ノードを追加します。</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">クォーラムノードと GPFS ノードを追加します。</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">NSD サーバと GPFS ノードを追加します。</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">GUI 、管理ノード、および GPFS ノードを追加します。</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">別の GUI サーバを追加します。</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">別の GPFS ノードを追加します。</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">すべてのノードを検証およびリストします。</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">クラスタ定義ファイルでクラスタ名を指定します。</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">プロファイルを指定します。</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">GPFS で使用するリモートシェルバイナリを指定します。引数には -r を使用します。</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">GPFS で使用するリモートファイルコピーバイナリを指定します。「 -rc 引数」を使用します。</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">すべての GPFS ノードに設定するポート範囲を指定します。「 -e 引数」を使用します。</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">GPFS 構成設定を表示します。</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">管理ノードを追加</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">NTP を有効にします。</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">インストール前に設定を事前確認します。</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">NSD ディスクを設定します。</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">NSD ディスクを作成します。</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">NSD ディスクのステータスを確認します。</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">GPFS に必要な権限を確認して付与します。</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">「 dd 」コマンドを実行して、 GPFS の読み取りと書き込みを確認します。</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">GPFS を NFS にエクスポートするには、次の手順を実行します。</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">NFS クライアントを検証するために、 GPFS 内のファイルをリストします。</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">NFS クライアントを設定します</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">NFS クライアントにパッケージをインストールします。</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">NFS マウントフォルダ内の GPFS ファイルのリストを確認します。</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">XCP を使用して、 GPFS でエクスポートされた NFS から NetApp NFS にデータを移動します。</block>
  <block id="96a4b9abe25ad94a1d4ab8e0d2237ef6" category="inline-link-macro">次のページ： MapR - FS to ONTAP NFS 。</block>
  <block id="742eb558b5f30d090f7c3ae58b2a554e" category="paragraph"><block ref="742eb558b5f30d090f7c3ae58b2a554e" category="inline-link-macro-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">このセクションでは、この解決策のビジネス上の利点について説明します。</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">ビジネス上のメリット</block>
  <block id="aaff67cd4222a3be5071cf651cab3d48" category="inline-link-macro">従来： HDFS と MapR - FS から ONTAP NFS へ。</block>
  <block id="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="paragraph"><block ref="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="inline-link-macro-rx"></block></block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">ビッグデータ分析から AI にデータを移動することには、次のようなメリットがあります。</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">異なる Hadoop ファイルシステムと GPFS から Unified NFS ストレージシステムにデータを抽出する機能</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Hadoop 統合によりデータ転送を自動化します</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Hadoop ファイルシステムからデータを移動するためのライブラリ開発コストを削減することです</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">NIPAM を使用して、 1 つのデータソースからの複数のネットワークインターフェイスの集約スループットによる最大パフォーマンス</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">データを転送するための、スケジュールされた方法とオンデマンドの方法</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">ONTAP データ管理ソフトウェアを使用した、ユニファイド NFS データ用のストレージ効率化およびエンタープライズ管理機能</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">データ転送用の Hadoop メソッドにより、データ移動のコストがゼロになります</block>
  <block id="a3b97091403bff3b38419087acb1c19e" category="inline-link-macro">次の手順： NFS への GPFS - 詳細な手順。</block>
  <block id="5e982872ec65785f5d685290b9c40026" category="paragraph"><block ref="5e982872ec65785f5d685290b9c40026" category="inline-link-macro-rx"></block></block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">このセクションでは、 NetApp XCP を使用して MapR FS データを ONTAP NFS に移動するために必要な手順について説明します。</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR - FS から ONTAP NFS へ</block>
  <block id="59b0eb4059face89ab060ea59984c8a7" category="inline-link-macro">前の手順： GPFS から NFS へ - 詳細な手順</block>
  <block id="13f1dc977877024b0f36272f1af2b238" category="paragraph"><block ref="13f1dc977877024b0f36272f1af2b238" category="inline-link-macro-rx"></block></block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">MapR ノードごとに 3 つの LUN をプロビジョニングし、すべての MapR ノードの LUN の所有権を付与します。</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">インストール時に、 MapR FS に使用されている MapR クラスタディスク用に新しく追加された LUN を選択します。</block>
  <block id="f7dc1a091cd04b392f9a99c5390b9ce2" category="inline-link">MapR 6.1 のドキュメント</block>
  <block id="24cb5309ea8c5a7c3244adf133110ecf" category="list-text">に従って MapR クラスタをインストールします<block ref="a38d60fa0425a18b5925139ceca806ea" category="inline-link-rx"></block>。</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">「 hadoop jar xxx 」などの MapReduce コマンドを使用して、基本的な Hadoop 動作をチェックします。</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">MapR - FS で顧客データを保持します。たとえば、 Teragen を使用して MapR -FS に約 1 テラバイトのサンプルデータを生成しました。</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">MapR - FS を NFS エクスポートとして設定します。</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">すべての MapR ノードで nlockmgr サービスを無効にします。</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">MapR から特定のフォルダをエクスポートします。これは、「 /opt/MapR /conf/exports 」ファイルのすべての MapR ノードにあります。サブフォルダをエクスポートするときは、異なる権限を持つ親フォルダをエクスポートしないでください。</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">MapR - FS NFS サービスを更新します。</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">仮想 IP 範囲を MapR クラスタ内の特定のサーバまたはサーバセットに割り当てます。次に、 MapR クラスタが NFS データアクセス用の特定のサーバに IP を割り当てます。IP を使用することで高可用性が実現します。つまり、特定の IP を持つサーバまたはネットワークで障害が発生した場合に、 IP 範囲内の次の IP を NFS アクセスに使用できます。</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">すべての MapR ノードからの NFS アクセスを提供する場合は、各サーバに一連の仮想 IP を割り当て、各 MapR ノードのリソースを NFS データアクセスに使用できます。</block>
  <block id="fa6899b17d5e71a360316c355d34c8b3" category="paragraph"><block ref="fa6899b17d5e71a360316c355d34c8b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb6de965ede92bf8bb036bb8fea6eba" category="paragraph"><block ref="8cb6de965ede92bf8bb036bb8fea6eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="031b138609c608ed553a74b2a1c439e1" category="paragraph"><block ref="031b138609c608ed553a74b2a1c439e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">各 MapR ノードに割り当てられている仮想 IP を確認し、 NFS データアクセスに使用します。</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">NFS をエクスポートした MapR FS をマウントするには、 NFS の動作を確認するために割り当てられた仮想 IP を使用します。ただし、 NetApp XCP を使用したデータ転送では、この手順は必要ありません。</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">MapR FS NFS ゲートウェイから ONTAP NFS にデータを転送するように NetApp XCP を設定します。</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">XCP のカタログの場所を設定します。</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">ライセンスファイルを「 /opt/NetApp/xFiles/XCP 」にコピーします。</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">XCP activate コマンドを使用して XCP をアクティブにします。</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">ソースで NFS エクスポートを確認します。</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">複数のソース IP と複数のデスティネーション IP （ ONTAP LIF ）から、複数の MapR ノードから XCP を使用してデータを転送します。</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">ストレージコントローラ上の負荷分散を確認します。</block>
  <block id="93a2605b6bf89fdb9970a6dbc77dee03" category="paragraph"><block ref="93a2605b6bf89fdb9970a6dbc77dee03" category="inline-link-macro-rx"></block></block>
  <block id="b446e9930ab89aa25e7b422c4c23d83f" category="inline-link-macro">前のバージョン： MapR - FS to ONTAP NFS 。</block>
  <block id="185bcaf9470b338d9a2b58870d7bd2bd" category="paragraph"><block ref="185bcaf9470b338d9a2b58870d7bd2bd" category="inline-link-macro-rx"></block></block>
  <block id="ca79886b03835c933143f8eb102ac932" category="list-text">NetApp In-Place Analytics Module Best Practices 』を参照してください</block>
  <block id="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link"><block ref="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link-rx"></block></block>
  <block id="026671d583a546d6b62291e018f78bf7" category="paragraph"><block ref="026671d583a546d6b62291e018f78bf7" category="inline-link-rx"></block></block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">『 NetApp FlexGroup Volume Best Practices and Implementation Guide 』にある、ボリュームへの移行に関するセクション</block>
  <block id="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link"><block ref="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link-rx"></block></block>
  <block id="f473bc55fb079f0338493530316efc6f" category="paragraph"><block ref="f473bc55fb079f0338493530316efc6f" category="inline-link-rx"></block></block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">バージョン 3.0 以降</block>
  <block id="b9365bb9132d1eb8770275a763fc5d69" category="cell">2022 年 1 月</block>
  <block id="e4005842db89b4abb778385f9a8a758f" category="cell">NetApp XCP を使用して、 HDFS と MapR FS から NFS にデータを直接移動する。</block>
  <block id="d835981d77534f5f20446d4648ad7e5b" category="cell">2020年1月</block>
  <block id="637f51ce71f8f8cadc4b75dfda96d45c" category="cell">デフォルトのデータムーバーに XCP が含まれています。NFS データ転送に MapR - FS を追加し、 NFS データ転送に GPFS を追加しました。</block>
  <block id="a10ba827ae758dee0e50d44366fd3d6d" category="cell">2018年11月</block>
  <block id="4b3608ccf8a7154699127b487cc49627" category="paragraph">このドキュメントでは、ビッグデータ分析やハイパフォーマンスコンピューティング（ HPC ）システムからデータを移動して、人工知能（ AI ）ワークフローで使用できるようにする方法について説明します。AI は通常、 NFS エクスポートを介して NFS データを処理します。ただし、ビッグデータ分析とハイパフォーマンスコンピューティング（ HPC ）のプラットフォームに AI データが格納されている可能性があります。これは、 Hadoop 分散ファイルシステム（ HDFS ）、バイナリ大容量オブジェクト（ Blob ）、 S3 ストレージ、 IBM の General Parallel File System （ GPFS ）などです。本ドキュメントでは、 Hadoop ネイティブのコマンド、 NetApp In-Place Analytics Module （ NIPAM ）、および NetApp XCP を使用して、ビッグデータ分析プラットフォームと GPFS から NFS にデータを移動する方法について説明します。このドキュメントでは、ビッグデータや HPC から AI にデータを移動することで得られるビジネス上のメリットについても説明します。</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">このページでは、 AI の運用を目的としたビッグデータ分析からデータにアクセスする際にお客様が直面する可能性のある課題について説明します。</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="doc">お客様の課題</block>
  <block id="14fd125cf7cc7e6f58e0a07d30ecda87" category="paragraph"><block ref="14fd125cf7cc7e6f58e0a07d30ecda87" category="inline-link-macro-rx"></block></block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">AI 運用のためにビッグデータ分析からデータにアクセスしようとすると、お客様は次のような課題に直面することがあります。</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">お客様のデータは、データレイクリポジトリに格納されています。データレイクには、構造化データ、非構造化データ、半構造化データ、ログ、マシン間データなど、さまざまなタイプのデータを格納できます。これらのデータタイプはすべて AI システムで処理する必要があります。</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">AI は Hadoop ファイルシステムには対応していません。一般的な AI アーキテクチャでは、 HDFS データと HCFS データに直接アクセスできないため、 AI に対応したファイルシステム（ NFS ）に移行する必要があります。</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">データレイクのデータを AI に移行するには、通常、特別なプロセスが必要です。データレイク内のデータ量は非常に多くなる可能性があります。効率性、スループット、コスト効率に優れた方法でデータを AI システムに移動する必要がある。</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">データを同期中です。お客様がビッグデータプラットフォームと AI の間でデータを同期したい場合は、ビッグデータを使用して処理されたデータを分析処理に使用できることがあります。</block>
  <block id="02c553e123c56e4cba5728b7e83bb80b" category="inline-link-macro">次： Data Mover の解決策。</block>
  <block id="205e8a4d3382497ff57947382c577faa" category="paragraph"><block ref="205e8a4d3382497ff57947382c577faa" category="inline-link-macro-rx"></block></block>
  <block id="2ea9ecb649c5974bc03036a15d95f5bf" category="summary">Data Mover 解決策 for AI は、お客様のニーズに基づいて AI 運用の Hadoop データを処理します。ネットアップは、 NIPAM を使用して HDFS から NFS にデータを移動します。あるユースケースでは、クラウド内の GPU クラウドインスタンスからデータを処理するために、データをオンプレミスの NFS に移動し、別のお客様が Windows Azure ストレージ Blob から Cloud Volumes Service に移動する必要がありました。</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">AI 向け Data Mover 解決策</block>
  <block id="2337521acd1f46c410245430b841caa8" category="inline-link-macro">前のバージョン： Data Mover の解決策。</block>
  <block id="ee202fa3d5706f12ab6d57e9cb4b4cba" category="paragraph"><block ref="ee202fa3d5706f12ab6d57e9cb4b4cba" category="inline-link-macro-rx"></block></block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">次の図は、 Data Mover の解決策の詳細を示しています。</block>
  <block id="27f83ed51cc554467134084d77b0e050" category="paragraph"><block ref="27f83ed51cc554467134084d77b0e050" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">Data Mover 解決策を構築するには、次の手順が必要です。</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN は HDFS を提供し、 NAS は NIPAM 経由で本番データレイククラスタに NFS ボリュームを提供します。</block>
  <block id="0fad6dd0225bf5a5e9c668c30ea5d38a" category="list-text">お客様のデータは HDFS と NFS にあります。NFS データは、ビッグデータ分析や AI 処理に使用される他のアプリケーションの本番データにすることができます。</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">NetApp FlexClone テクノロジは、本番用 NFS ボリュームのクローンを作成し、オンプレミスの AI クラスタにプロビジョニングします。</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">HDFS SAN LUN からのデータは、 NIPAM および「 hadoop distcp 」コマンドによって NFS ボリュームにコピーされます。NIPAM は、複数のネットワークインターフェイスの帯域幅を使用してデータを転送します。この処理によってデータコピー時間が短縮され、より多くのデータを転送できるようになります。</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">どちらの NFS ボリュームも、 AI 処理用に AI クラスタにプロビジョニングされます。</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">オンプレミスの NFS データを処理するために、クラウド内の GPU を使用する場合は、 NFS ボリュームが NetApp SnapMirror テクノロジを使用して NetApp Private Storage （ NPS ）にミラーリングされ、 GPU のクラウドサービスプロバイダにマウントされます。</block>
  <block id="c590e653cde69438d43731b18edd533c" category="list-text">お客様は、 GPU のデータをクラウドサービスプロバイダから EC2 / EMR 、 HDInsight 、または DataProc サービスで処理したいと考えています。Hadoop データムーバーは、 NIPAM および「 hadoop distcp 」コマンドを使用して、 Hadoop サービスから Cloud Volume サービスにデータを移動します。</block>
  <block id="8cae7d7989a25f83bf9df9952b16ed2b" category="list-text">Cloud Volumes Service データは、 NFS プロトコルを使用して AI にプロビジョニングされます。 AI で処理されたデータは、オンプレミスの場所に送信し、 NIPAM 、 SnapMirror 、 NPS を通じて、 NVIDIA クラスタに加えてビッグデータ分析にも使用できます。</block>
  <block id="980894bd0921c687decdf218e89107e2" category="paragraph">このシナリオでは、 NAS システム内のファイル数が多く、オンプレミスのネットアップストレージコントローラで AI 処理を実行するために必要なリモートサイトにデータが配置されています。このシナリオでは、 XCP Migration Tool を使用してデータをより高速に移行することをお勧めします。</block>
  <block id="002cfe6c68deff9c2fcb4fbb3820a5ff" category="paragraph">ハイブリッドユースケースのお客様は、 Cloud Sync を使用してオンプレミスのデータを NFS 、 CIFS 、 S3 のデータからクラウドに移行し、その逆も、 NVIDIA クラスタ内の GPU などを使用して AI 処理を行うことができます。NetApp ONTAP NFS への NFS データ移行には、 Cloud Sync と XCP Migration Tool の両方が使用されます。</block>
  <block id="22033f5439b399254e73f6f3588b9b9e" category="inline-link-macro">次： NetApp ONTAP NFS への GPFS の追加。</block>
  <block id="f56cb05715de107bd001dd11a41b0cf6" category="paragraph"><block ref="f56cb05715de107bd001dd11a41b0cf6" category="inline-link-macro-rx"></block></block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">ビッグデータクラスタでは、 MapR -FS 、 Windows Azure Storage Blob 、 S3 、 Google ファイルシステムなどの HDFS または HCFS にデータが格納されます。ネットアップは、ソース側で hadoop distcp コマンドを使用し、データを NIPAM の支援によって NetApp ONTAP NFS エクスポートにコピーするソースとして、 HDFS 、 MapR FS 、 S3 を使用してテストを実施しました。</block>
  <block id="6d1963202b436934d6b74acc8232dc94" category="inline-link-macro">前：お客様の課題</block>
  <block id="501ee0e125dd4449de2b29015fab6f3e" category="paragraph"><block ref="501ee0e125dd4449de2b29015fab6f3e" category="inline-link-macro-rx"></block></block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">ビッグデータクラスタでは、 MapR -FS 、 Windows Azure Storage Blob 、 S3 、 Google ファイルシステムなどの HDFS または HCFS にデータが格納されます。ソース側で「 hadoop distcp 」コマンドを使用し、データを NIPAM の助けを得て NetApp ONTAP NFS エクスポートにコピーするソースとして、 HDFS 、 MapR FS 、および S3 を使用してテストを実施しました。</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">次の図は、 HDFS ストレージで稼働している Spark クラスタから、 NVIDIA が AI 処理を行えるようにするための NetApp ONTAP NFS ボリュームへの、一般的なデータ移動を示しています。</block>
  <block id="d824b1bb9493b5a6c5a2e74871468633" category="paragraph"><block ref="d824b1bb9493b5a6c5a2e74871468633" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">「 hadoop distcp 」コマンドは、 MapReduce プログラムを使用してデータをコピーします。NIPAM は MapReduce と連携して、データをコピーする際の Hadoop クラスタのドライバとして機能します。NIPAM では、 1 つのエクスポートのために複数のネットワークインターフェイスに負荷を分散できます。このプロセスにより、 HDFS または HCFS から NFS にデータをコピーするときに、複数のネットワークインターフェイスにデータを分散させることにより、ネットワークスループットが最大になります。</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM は MapR でサポートまたは認定されていません。</block>
  <block id="e68fb74f51fcafb391476c585b1e434d" category="inline-link-macro">次のステップ： Data Mover 解決策 for AI</block>
  <block id="1f4c259e626baca3c7947e6f3db323d4" category="paragraph"><block ref="1f4c259e626baca3c7947e6f3db323d4" category="inline-link-macro-rx"></block></block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">このホワイトペーパーでは、 NetApp XCP と NIPAM を使用して、ビッグデータ分析データと HPC データを AI に移行するためのガイドラインを説明します。また、ビッグデータや HPC から AI にデータを移行することで得られるビジネス上のメリットについても説明します。</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732 ：『 Big data analytics data to 人工知能』</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">このドキュメントでは、ビッグデータ分析データと HPC データを AI に移行する方法について説明します。AI は、 NFS エクスポートを介して NFS データを処理しますが、お客様の AI データは、 HDFS 、 Blob 、 S3 ストレージなどのビッグデータ分析プラットフォームや、 GPFS などの HPC プラットフォームに格納されていることがよくあります。このホワイトペーパーでは、 NetApp XCP と NIPAM を使用して、ビッグデータ分析データと HPC データを AI に移行するためのガイドラインを説明します。また、ビッグデータや HPC から AI にデータを移行することで得られるビジネス上のメリットについても説明します。</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">概念とコンポーネント</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">ビッグデータ分析ストレージ</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">ビッグデータ分析は、 HDFS の主要なストレージプロバイダです。お客様は多くの場合、 Windows Azure Blob Storage 、 MapR File System （ MapR - FS ）、 S3 オブジェクトストレージなどの Hadoop 対応ファイルシステム（ HCFS ）を使用しています。</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">一般的な並列ファイルシステム</block>
  <block id="432f31a1b9dc5a8ef1f048ea3f4f98c8" category="paragraph">IBM の GPFS は、 HDFS の代わりとなるエンタープライズファイルシステムです。GPF は、アプリケーションがブロックサイズとレプリケーションレイアウトを決定できる柔軟性を備えており、優れたパフォーマンスと効率を実現します。</block>
  <block id="2aff401779cc49866458a642f15c0181" category="inline-link">TR-4382 ：『 NetApp In-Place Analytics Module 』</block>
  <block id="ae1165a7ed0006d2dae65ea849898810" category="paragraph">NetApp In-Place Analytics Module （ NIPAM ）は、 NFS データにアクセスする Hadoop クラスタのドライバとして機能します。接続プール、 NFS InputStream 、ファイル・ハンドル・キャッシュ、 NFS OutputStream の 4 つのコンポーネントで構成されています。詳細については、を参照してください<block ref="aedae5b2590b798973be1ab298f44ab7" category="inline-link-rx"></block></block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Hadoop 分散コピー</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy （ DistCp ）は、クラスタ間およびクラスタ内の大規模なコピー作業に使用される分散コピーツールです。このツールは、データの配信、エラー処理、およびレポートに MapReduce を使用します。ファイルとディレクトリのリストが展開され、タスクをマッピングしてソースリストからデータをコピーするように入力されます。次の図は、 HDFS と HDFS 以外の間の DistCp 処理を示しています。</block>
  <block id="1a76b3e0f1199267d461c961d30d07a5" category="paragraph"><block ref="1a76b3e0f1199267d461c961d30d07a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp は、追加のドライバを使用せずに 2 つの HDFS システム間でデータを移動します。ネットアップは HDFS 以外のシステム向けのドライバを提供しています。NFS デスティネーションの場合、 NIPAM は、データのコピー時に Hadoop DistCp が NFS デスティネーションとの通信に使用するデータをコピーするためのドライバを提供します。</block>
  <block id="05fc55cae9e8b2a7fb40e978e4971707" category="paragraph">NetApp Cloud Volumes Service は、卓越したパフォーマンスを発揮するクラウドネイティブのファイルサービスです。このサービスを利用すると、お客様はリソースのスピンアップとスピンダウンを迅速に行い、ネットアップの機能を使用して生産性を高め、スタッフのダウンタイムを短縮し、市場投入までの期間を短縮できます。Cloud Volumes Service は、データセンター全体の設置面積を削減し、ネイティブのパブリッククラウドストレージを消費しないため、ディザスタリカバリやクラウドへのバックアップに最適な選択肢です。</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP は、高速で信頼性の高いネットアップおよびネットアップからネットアップへのデータ移行を可能にするクライアントソフトウェアです。このツールは、あらゆる NAS システムからネットアップストレージコントローラに大量の非構造化 NAS データをコピーするために設計されています。XCP Migration Tool では、マルチコアのマルチチャネル I/O ストリーミングエンジンが使用されており、データの移行、ファイルやディレクトリの一覧表示、スペースレポートなど、多数の要求を並行して処理できます。これは、デフォルトのネットアップデータ移行ツールです。XCP を使用して、 Hadoop クラスタと HPC から NetApp NFS ストレージにデータをコピーできます。次の図は、 Hadoop クラスタと HPC クラスタから XCP を使用した NetApp NFS ボリュームへのデータ転送を示しています。</block>
  <block id="cd7e68aa30250a331c260fee49ff230e" category="paragraph"><block ref="cd7e68aa30250a331c260fee49ff230e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bce96270b79327e5daf4c0745d66023" category="paragraph">NetApp Cloud Sync は、 NFS 、 S3 、 CIFS のデータをオンプレミスストレージとクラウドストレージ間でシームレスかつセキュアに転送して同期する、ハイブリッドデータレプリケーションソフトウェアサービスです。このソフトウェアは、データの移行、アーカイブ、コラボレーション、分析などに使用されます。データが転送されると、 Cloud Sync はソースとデスティネーションの間でデータを継続的に同期します。次に、デルタを転送します。また、自社ネットワーク内、クラウド内、オンプレミス内でもデータを保護できます。このソフトウェアは従量課金制モデルをベースとしており、対費用効果の高い解決策を提供し、データ転送の監視とレポートの機能を提供します。</block>
  <block id="cbba30a09e75669ecb5b3b2d83a25284" category="inline-link-macro">次のステップ：お客様の課題</block>
  <block id="63aa417c654afafebdbdfcaf7a13c8b6" category="paragraph"><block ref="63aa417c654afafebdbdfcaf7a13c8b6" category="inline-link-macro-rx"></block></block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">この解決策では、ネットアップがデータレイク（ HDFS ）と MapR クラスタデータから ONTAP NFS へのデータ移行を検証しました。データは MapR - FS と HDFS に存在します。NetApp XCP は、 HDFS や MapR FS などの分散ファイルシステムから ONTAP NFS にデータを直接移行する新しい機能を導入しました。</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS と MapR - FS を ONTAP NFS に接続</block>
  <block id="9577f33e5dfe124ba394a5c90a123928" category="inline-link-macro">旧称： NetApp ONTAP NFS への GPFS 。</block>
  <block id="a503c5d00affd8b681837e8b44490492" category="paragraph"><block ref="a503c5d00affd8b681837e8b44490492" category="inline-link-macro-rx"></block></block>
  <block id="9c02792070008c1748647d8bdbe24432" category="paragraph">この解決策では、ネットアップがデータレイク（ HDFS ）と MapR クラスタデータから ONTAP NFS へのデータ移行を検証しました。データは MapR - FS と HDFS に存在します。NetApp XCP は、 HDFS や MapR FS などの分散ファイルシステムから ONTAP NFS にデータを直接移行する新しい機能を導入しました。XCP は、非同期スレッドと HDFS C API 呼び出しを使用して、 MapR FS と HDFS の間でデータを通信および転送します。次の図は、データレイク（ HDFS ）と MapR FS から ONTAP NFS へのデータ移行を示しています。この新機能により、ソースを NFS 共有としてエクスポートする必要がなくなります。</block>
  <block id="4581f9b32af32647aa31b2f9d57f6f1f" category="paragraph"><block ref="4581f9b32af32647aa31b2f9d57f6f1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">お客様が HDFS と MapR FS から NFS に移行するのはなぜですか。</block>
  <block id="b075c8e6a9009d582333c59e237e3646" category="paragraph">Cloudera や Hortonworks などの Hadoop ディストリビューションのほとんどは HDFS ディストリビューションと MapR ディストリビューションを使用してデータを格納しています。HDFS と MapR - FS データは、機械学習（ ML ）とディープラーニング（ DL ）に活用できるデータサイエンティストにとって価値ある分析情報を提供します。HDFS と MapR FS のデータは共有されないため、他のアプリケーションでは使用できません。顧客は、共有データ、特に顧客の機密データが複数のアプリケーションで使用される銀行業界を探しています。最新バージョンの Hadoop （ 3.x 以降）は NFS データソースをサポートしており、サードパーティ製ソフトウェアを追加することなくアクセスできます。新しい NetApp XCP 機能を使用すると、データを HDFS および MapR FS から NetApp NFS に直接移動して、複数のアプリケーションへのアクセスを提供できます</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">テストは Amazon Web Services （ AWS ）で実施され、 MapR ノード 12 台と NFS サーバ 4 台を使用した初期パフォーマンステストで MapR FS から NFS にデータを転送しました。</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">サイズ</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">vCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">メモリ</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">ネットワーク</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">NFS サーバ</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge のサイズ</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8 台の 7 、 500 NVMe SSD</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">MapR ノード</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en. 12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">7 、 500 NVMe SSD × 4</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">初期テストでは 20Gbps のスループットを達成し、 2PB のデータを 1 日あたり転送可能でした。</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link">TR-4863 ：『 Best Practice Guidelines for NetApp XCP - Data Mover 、 File Migration 、 and Analytics 』</block>
  <block id="6371d61614d0beaedb75e85d2c297d8f" category="paragraph">HDFS を NFS にエクスポートせずに HDFS データを移行する方法の詳細については、の「 Deployment Steps - NAS 」を参照してください<block ref="6a602f6a965c96a94215a45f0077e771" category="inline-link-rx"></block>。</block>
  <block id="aa722a0d50c9e3bfe81a7128f0e649d7" category="inline-link-macro">次は、ビジネス上のメリットです。</block>
  <block id="4e39bc17db35d21d84b6fb1e9786fdb5" category="paragraph"><block ref="4e39bc17db35d21d84b6fb1e9786fdb5" category="inline-link-macro-rx"></block></block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">ビッグデータ分析データを人工知能に</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">NFS に対する GPF - 詳細な手順</block>
  <block id="75afdb5cd8c025ed0681bdb302fcdcda" category="cell">NVA-1160 に「 OperatorHub および Ansible による Astra Control Center のインストール」という新しいセクションを追加しました</block>
  <block id="593fdc7a2167cd2ada3e71219ceb0ecb" category="paragraph">詳細については、 Astra Trident の Web サイトをご覧ください<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>。</block>
  <block id="3d930ae98e9d9fc9a418d6b8e5e5639f" category="cell">21.12.60</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="2bb7e89d50aed884078c4b7857f5bb39" category="cell">4.6 EUS 、 4.7 、 4.8</block>
  <block id="1e90637438eb06672159d2998d220e86" category="open-title">OperatorHub を使用する</block>
  <block id="bff0144772c74d96da07b6ccefb79f96" category="list-text">ネットアップサポートサイトにログインし、最新バージョンの NetApp Astra Control Center をダウンロードします。そのためには、ネットアップアカウントにライセンスを関連付ける必要があります。tarball をダウンロードしたら、 admin ワークステーションに転送します。</block>
  <block id="baac643870c95006b4243d078606a15d" category="list-text">インストールを開始する前に、 Astra Control Center イメージをイメージレジストリにプッシュします。この手順では、 Docker または Podman のいずれかを使用して実行します。両方の手順については、この手順で説明します。</block>
  <block id="455cbd59356abfa16dcf7666d4ae6c2b" category="list-title">ポドマン</block>
  <block id="ee9b41d8a22021826def077c661525f4" category="list-text">公開されていないプライベートイメージレジストリを使用する場合は、イメージレジストリ TLS 証明書を OpenShift ノードにアップロードします。そのためには、 TLS 証明書を使用して OpenShift -config ネームスペースに ConfigMap を作成し、クラスタイメージ構成にパッチを適用して証明書を信頼できるようにします。</block>
  <block id="9c656c969a87783fcf4b94b721f34bc9" category="list-text">Astra Control Center 用の名前空間 NetApp-acc-operator' を作成します</block>
  <block id="788e8355bdd3a21f3a9017a0610940f4" category="list-text">クラスタ管理者アクセスで Red Hat OpenShift GUI コンソールにログインします。</block>
  <block id="3d68b5654b778f026ac691bc6ed70cc5" category="list-text">[ 演算子 ]&gt;[ 演算子ハブ ] の順に移動し、 Astra を検索します。</block>
  <block id="dc7add750562c445f72d8d016a79ae29" category="list-text">NetApp-acc-operator' タイルを選択し、 [ インストール ] をクリックします。</block>
  <block id="c80be3093b470ca8092538e58a261952" category="image-alt">ACC オペレータタイル</block>
  <block id="c65c283737dc37cea2358a91588ff272" category="list-text">インストールオペレータ画面で、デフォルトのパラメータをすべて受け入れて、「インストール」をクリックします。</block>
  <block id="3677d31e24a1853c961f3f1a9a39a1d6" category="image-alt">ACC オペレータの詳細</block>
  <block id="ba14525c4ccc9b2f692d062104885b19" category="image-alt">ACC オペレーターがインストールを待機します</block>
  <block id="fea3120ff933c367a5882d58dbbe8a08" category="list-text">オペレータのインストールが完了したら、 [View Operator] をクリックします。</block>
  <block id="a573acc0621ea72a06ce987a341768bf" category="image-alt">ACC オペレータによるインストールが完了しました</block>
  <block id="f99196bf6b988223fab800f28cf0323c" category="list-text">次に、オペレーターの Astra Control Center タイルで [Create Instance] をクリックします。</block>
  <block id="11f7c569d04eecd142ba5989efcc2da3" category="image-alt">ACC インスタンスを作成します</block>
  <block id="02780e148f03f25db76204c23985d753" category="list-text">[Create AstraeControl] フォームフィールドに入力し '[Create] をクリックします</block>
  <block id="e31f3b85c5179d88bcf0629842c5342f" category="list-text">必要に応じて、 Astra Control Center インスタンス名を編集します。</block>
  <block id="3336a2124154da151aecfe1809d7c821" category="list-text">必要に応じて、 AutoSupport を有効または無効にします。Auto Support 機能の保持を推奨します。</block>
  <block id="14ddbb7fd85c2907073b06492b95191b" category="list-text">Astra Control Center の FQDN を入力します。</block>
  <block id="fbcd656fecc902b1994e346dc0627266" category="list-text">Astra Control Center のバージョンを入力します。デフォルトで最新のバージョンが表示されます。</block>
  <block id="311a20c50b8e2d72cf9b31eb6339bff4" category="list-text">Astra Control Center のアカウント名を入力し、管理者の詳細（名、姓、メールアドレスなど）を入力します。</block>
  <block id="163e6534daeb1cbd7c56b20a9477802f" category="list-text">ボリューム再利用ポリシーを入力します。デフォルトは Retain です。</block>
  <block id="5863d7f52b409374d0d80b1bcbba68fd" category="list-text">Image Registry に、レジストリの FQDN と、イメージをレジストリにプッシュする際に指定した組織名を入力します（この例では「 astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra` 」）。</block>
  <block id="95279718d2829cd5ed7772d6f0a77ca9" category="list-text">認証が必要なレジストリを使用する場合は、 [ イメージレジストリ ] セクションにシークレット名を入力します。</block>
  <block id="b8f9ae819a2d6559f55aed837fdc2a47" category="list-text">Astra Control Center のリソース制限のスケーリングオプションを設定します。</block>
  <block id="3b489b9fd690a8cdf710454d0ccb5288" category="list-text">デフォルト以外のストレージクラスに PVC を配置する場合は、ストレージクラス名を入力します。</block>
  <block id="6b9265a82fa5bd326052ec55e040a54a" category="list-text">CRD 処理の環境設定を定義します。</block>
  <block id="90aa5928482975bc6ff56f0eaf052451" category="open-title">自動化された [Ansible ]</block>
  <block id="b8571b33af3335fed61ab0d7985d007f" category="list-text">Ansible コンテンツをホストする GitHub リポジトリをクローニングします。</block>
  <block id="5ed95667cae604c0ddee2dbf04f423fe" category="list-text">ネットアップサポートサイトにログインし、最新バージョンの NetApp Astra Control Center をダウンロードします。そのためには、ネットアップアカウントにライセンスを関連付ける必要があります。tar ファイルをダウンロードしたら、ワークステーションに転送します。</block>
  <block id="6238d4091e12ffa6643c0dc68d72ceab" category="list-text">Astra Control Center をインストールする OpenShift クラスタに管理者としてアクセスできる kubeconfig ファイルを作成または取得します。</block>
  <block id="b736c713f352ab43e7543fda4589e96f" category="list-text">ディレクトリを na_Astra_control_site に変更します。</block>
  <block id="4f31682e7040024757006eed6ba0344a" category="list-text">変数 / 変数 .yml ファイルを編集し、必要な情報を入力します。</block>
  <block id="8d1e5f9175948d3e6f932794744cde16" category="section-title">インストール後の手順</block>
  <block id="8b70487815961b708f216595f5817311" category="paragraph">2022 年 1 月にリリースされた最新バージョンの Astra Trident は 22.01 です。Trident のどのバージョンがサポートされているかを確認できます Kubernetes ディストリビューションのテストに使用<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>。</block>
  <block id="b5d9e69ac9444a6a1cfd78cf106c057e" category="list-text">インストールアーカイブを管理ワークステーションにダウンロードし、内容を展開します。Trident の最新バージョンは 22.01 で、ダウンロードできます<block ref="defadeb91446b93776c7f5696677985c" category="inline-link-rx"></block>。</block>
  <block id="89c771069f269704306d4ca7b118cc7d" category="paragraph">ただし NFSv3 については、クライアントとサーバ間の同時処理をネゴシエートするメカニズムはありません。したがって ' サーバが接続のウィンドウ・サイズを小さくしなくても NFS 接続の最適なパフォーマンスを確保できるように ' クライアント側 sunrpc スロット・テーブル・エントリーの最大数は ' サーバ上でサポートされている値と手動で同期する必要があります</block>
  <block id="9c2d7353683234845149cb6710dc11f8" category="paragraph">ONTAP でサポートされる sunrpcslot table エントリの最大数は 128 です。つまり、 ONTAP は、一度に 128 個の NFS 要求を同時に処理できます。ただし、 Red Hat CoreOS / Red Hat Enterprise Linux では、接続ごとに最大 65 、 536 の sunrpc スロットテーブルエントリがデフォルトでサポートされます。この値を 128 に設定する必要があります。これは OpenShift のマシン構成オペレータ（ MCO ）を使用して実行できます。</block>
  <block id="88cd6afaae477b942c9ab5d396e43cfb" category="paragraph">OpenShift ワーカーノードで最大 sunrpc スロットテーブルエントリを変更するには、次の手順を実行します。</block>
  <block id="e7a7478f209d8b5dcaf38a593ce749b3" category="list-text">MCO が作成されたら、すべてのワーカーノードに設定を適用し、 1 つずつ再起動する必要があります。プロセス全体には約 20~30 分かかります。「 OC GET MCP 」を使用してマシン構成が適用されているかどうかを確認し、ワーカーのマシン構成プールが更新されていることを確認します。</block>
  <block id="068d2023b916134a0573aaad841124e4" category="paragraph">ワーカーノードで iSCSI サービスを実行するように設定するには、次の手順を実行します。</block>
  <block id="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link"><block ref="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link-rx"></block></block>
  <block id="086fce5f74cc93b0516aadec33636e09" category="paragraph"><block ref="086fce5f74cc93b0516aadec33636e09" category="inline-link-rx"></block></block>
  <block id="0611f127a7e1e7ef5bbd782030c2e34a" category="paragraph">NetApp ONTAP で作成されたプロジェクトごとに異なる SVM が作成されたら、各 SVM を異なる Trident バックエンドにマッピングする必要があります。Trident のバックエンド構成は、 OpenShift クラスタリソースへの永続的ストレージの割り当てを促進します。また、マッピング先の SVM の詳細が必要です。これは、バックエンドのプロトコルドライバである必要があります。必要に応じて、ストレージでのボリュームのプロビジョニング方法を定義したり、ボリュームのサイズやアグリゲートの使用などを制限したりできます。Trident バックエンドの定義に関する詳細はこちらをご覧ください<block ref="47a77763732c6cebe093a4a4d61aaa5b" category="inline-link-rx"></block>。</block>
  <block id="891c9b8b0ce367c5e377a1ec23199619" category="paragraph">Trident バックエンドを設定したら、次の手順として StorageClasses を設定します。バックエンドと同じ数のストレージクラスを構成して、各ストレージクラスが 1 つのバックエンドにしかボリュームをスピンアップできない。ストレージクラスを定義する際に StoragePools パラメータを使用して、ストレージクラスを特定の Trident バックエンドにマッピングできます。ストレージクラスを定義する詳細については、を参照してください<block ref="1266deb20a7d7c4814b1225e5e572606" category="inline-link-rx"></block>。そのため、 StorageClass から Trident バックエンドへの 1 対 1 のマッピングで、 1 つの SVM をポイントします。これにより、そのプロジェクトに割り当てられた StorageClass を経由するすべてのストレージ要求が、そのプロジェクト専用の SVM によって処理されます。</block>
  <block id="b09383080793dfb527084933760af6ed" category="paragraph"><block ref="b09383080793dfb527084933760af6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f372cf1de9e60f6875a0b24a5c28b07" category="list-text">スナップショットの詳細を入力し、 [ 次へ ] をクリックして、 [ スナップショット ] をクリックします。Snapshot の作成には約 1 分かかり、作成が完了するとステータスを確認できるようになります。</block>
  <block id="42dd75b4fbc849903d5d179a8e68d570" category="paragraph"><block ref="42dd75b4fbc849903d5d179a8e68d570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0929177ba68c50d4dd73a2a3311ac885" category="paragraph"><block ref="0929177ba68c50d4dd73a2a3311ac885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f789c3d3aacfbd2d2f99ba395ddb8bc5" category="list-text">バックアップの詳細を入力し、バックアップファイルを保存するオブジェクトストレージバケットを選択して次へをクリックします。詳細を確認したら、バックアップをクリックします。アプリケーションのサイズとデータによっては、バックアップに数分かかることがあり、バックアップが正常に完了したあとでバックアップのステータスを確認できるようになります。</block>
  <block id="4ba6af660a8dd39dc1d12fb6ee80ba81" category="paragraph"><block ref="4ba6af660a8dd39dc1d12fb6ee80ba81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b1fda3b0f36b6fd708a9871e1c19c50" category="section-title">アプリケーションのリストア</block>
  <block id="344aed2ab37311beed01bbd40d93caed" category="paragraph">ボタンを押すだけで、アプリケーションを同じクラスタ内の元のネームスペースまたはリモートクラスタにリストアし、アプリケーションを保護してディザスタリカバリに使用できます。</block>
  <block id="8ac352fe46a0c45e744688191b7df581" category="list-text">アプリケーションを復元するには、 [ アプリ ] &gt; [ 管理 ] タブに移動し、該当するアプリをクリックします。アプリケーション名の横にあるドロップダウン・メニューをクリックし '[ リストア ] をクリックします</block>
  <block id="84eb14028ce6ae6f2bf17b71ebe50c69" category="paragraph"><block ref="84eb14028ce6ae6f2bf17b71ebe50c69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b33d7fda666bdb32a2be1f3783106a3c" category="list-text">リストアネームスペースの名前を入力し、リストア先のクラスタを選択して、既存の Snapshot からリストアするかアプリケーションのバックアップからリストアするかを選択します。次へをクリックします。</block>
  <block id="7bbb08271e6b60bc55d6817c7e100528" category="paragraph"><block ref="7bbb08271e6b60bc55d6817c7e100528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9242e3e5428d2ddbd81dece3073767a" category="list-text">レビューペインで「 restore 」と入力し、詳細を確認した後で「 Restore 」をクリックします。</block>
  <block id="7d6d73878ae09dbfd1e5ee7a0ecab66c" category="inline-image-macro">Astra Control Center 復元のレビュー</block>
  <block id="b862f033546ae8bdc1bb091ad8b57023" category="paragraph"><block ref="b862f033546ae8bdc1bb091ad8b57023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b86c631d7b3beb0163beee546245df6" category="list-text">新しいアプリケーションは、 Astra Control Center が選択したクラスタ上のアプリケーションを復元している間、 Restoring 状態になります。アプリケーションのすべてのリソースが Astra によってインストールおよび検出されると、アプリケーションは Available 状態になります。</block>
  <block id="81d066be6d2211bf186bc1960361d8e3" category="paragraph"><block ref="81d066be6d2211bf186bc1960361d8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4600d44abb914105737c3d4a802b87c" category="section-title">アプリケーションのクローニング</block>
  <block id="5394f3451a07ae7dbe101ceb0725a004" category="paragraph">アプリケーションは、開発 / テストやアプリケーションの保護およびディザスタリカバリ目的で、元のクラスタまたはリモートクラスタにクローニングできます。同じストレージバックエンドで同じクラスタ内にあるアプリケーションをクローニングする場合、 NetApp FlexClone テクノロジを使用します。 FlexClone テクノロジを使用すると、 PVC のクローンを瞬時に作成し、ストレージスペースを節約できます。</block>
  <block id="04783413cee5e3c613efc7939cea3560" category="list-text">アプリケーションをクローンするには、 [ アプリケーション（ Apps ） ] &gt; [ 管理（ Managed ） ] タブに移動し、該当するアプリケーションをクリックします。アプリケーション名の横にあるドロップダウンメニューをクリックし、 Clone をクリックします。</block>
  <block id="1cfafd65804d582aac709fefcd3e60cd" category="paragraph"><block ref="1cfafd65804d582aac709fefcd3e60cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="654c7a62842024ed8e405ed0ac9c4377" category="list-text">新しいネームスペースの詳細を入力し、クローニング先のクラスタを選択します。クローンを既存の Snapshot 、バックアップ、またはアプリケーションの現在の状態から作成するかどうかを選択します。詳細を確認したら、 [ 次へ ] をクリックして、 [ レビューペインに複製 ] をクリックします。</block>
  <block id="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="paragraph"><block ref="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60bae26bb7c1e8711f1e39a45fc7b6c7" category="paragraph"><block ref="60bae26bb7c1e8711f1e39a45fc7b6c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d656f81a685df3697a812158d0bd2f21" category="paragraph">NetApp Astra Trident は、コンテナや Kubernetes ディストリビューション向けの、 Red Hat OpenShift などのオープンソースで完全にサポートされているストレージオーケストレーションツールです。詳細については、 Astra Trident の Web サイトをご覧ください<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>。</block>
  <block id="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="list-text"><block ref="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="inline-link-macro-rx"></block></block>
  <block id="ea1c9e7b76d8b7cc203b9f6a9633e241" category="list-text"><block ref="ea1c9e7b76d8b7cc203b9f6a9633e241" category="inline-link-macro-rx"></block></block>
  <block id="4105298f144b4b0e636460eede523df0" category="inline-link-macro">Ansible による Astra Control Center の自動インストール</block>
  <block id="64295ddd382f7876d307bac08ad539fe" category="cell"><block ref="64295ddd382f7876d307bac08ad539fe" category="inline-link-macro-rx"></block></block>
  <block id="bd6059cd679908cdb2d015167d51a3fe" category="cell"><block ref="bd6059cd679908cdb2d015167d51a3fe" category="inline-link-macro-rx"></block></block>
  <block id="6dc07ae6ad84b77b5d06f9d3fff5b819" category="cell"><block ref="6dc07ae6ad84b77b5d06f9d3fff5b819" category="inline-link-macro-rx"></block></block>
  <block id="e32276e1eed6ff0e76971afd985cea2d" category="cell"><block ref="e32276e1eed6ff0e76971afd985cea2d" category="inline-link-macro-rx"></block></block>
  <block id="77697d49d0c6b79e2642435a36c8c1e0" category="cell"><block ref="77697d49d0c6b79e2642435a36c8c1e0" category="inline-link-macro-rx"></block></block>
  <block id="60f031c992a9c99aa5413bddb0ecc644" category="cell"><block ref="60f031c992a9c99aa5413bddb0ecc644" category="inline-link-macro-rx"></block></block>
  <block id="13a82ffd84cedcd28833f58d716b4c3c" category="cell"><block ref="13a82ffd84cedcd28833f58d716b4c3c" category="inline-link-macro-rx"></block></block>
  <block id="74d542ee52cd8400c9b9307ed9a99c12" category="list-text">Astra DevOps のユースケース：</block>
  <block id="3da7df001d5e1f907d2527f52c6ccc00" category="inline-link-macro">NetApp Astra Control を使用すれば、 Kubernetes の CI / CD パイプラインに保護機能を簡単に統合できます</block>
  <block id="3f1cbb7eb907b7cb7f46877360d4a588" category="list-text"><block ref="3f1cbb7eb907b7cb7f46877360d4a588" category="inline-link-macro-rx"></block></block>
  <block id="fa4bd1682f261cdd55edf3e8e7dbfef6" category="inline-link-macro">DevOps とネットアップ： Astra Control を使用して、事後分析とアプリケーションのリストアを実行</block>
  <block id="1188d1aaa4a5f54ec1dab3da3576377a" category="list-text"><block ref="1188d1aaa4a5f54ec1dab3da3576377a" category="inline-link-macro-rx"></block></block>
  <block id="ce932b248d7f57bcada97c64dd7429a7" category="inline-link-macro">NetApp Astra Control Center ：アプリケーションのデータ管理を容易にするボタン</block>
  <block id="0d47bfb381dd96470ac538b5a112db04" category="list-text"><block ref="0d47bfb381dd96470ac538b5a112db04" category="inline-link-macro-rx"></block></block>
  <block id="6546814199e52492fa0efe5fbff08d5a" category="paragraph">この解決策 では、 SnapCenter で現在サポートされているすべてのデータベースがサポートされます。ここでは、 Oracle データベースと SQL Server データベースのみを示します。この解決策は仮想データベースワークロードに対して検証済みですが、ベアメタルワークロードもサポートされています。</block>
  <block id="f2a59783d2b5c7be84fec0d6de7a5ae9" category="cell">2022 年 8 月 3 日</block>
  <block id="eab6f1cc9736be0f5d62999f998bf36a" category="cell">新しいビデオデモ「 Accelerate Software Development with Astra Control and NetApp FlexClone Technology 」を追加</block>
  <block id="5df42c63d444f6e9e40d96be8f17ac6f" category="cell">2022 年 1 月 3 日</block>
  <block id="9fe0dbff6457627765d03955bd1659be" category="inline-link-macro">ビデオ： Accelerate Software Development with Astra Control and NetApp FlexClone Technology</block>
  <block id="a0eaa75e3e2b8c6220db02697d4acf1f" category="cell"><block ref="a0eaa75e3e2b8c6220db02697d4acf1f" category="inline-link-macro-rx"></block></block>
  <block id="d5ca81c242aff843ea151d778578cbfc" category="admonition">レジストリに信頼されていない証明書を使用している場合は、シェルスクリプトを編集し、 podman push コマンドに「 --tls-verify=false 」を使用します。「 podman push $registry/ $ 」（ echo $astraalImage | sed's /^[^\\/]\\/'/')--tls-verify=false 」）。</block>
  <block id="ec72a928f8eedfaa788b44b6935b50fe" category="doc">Astra Control と NetApp FlexClone テクノロジでソフトウェア開発を高速化：ネットアップを使用した Red Hat OpenShift</block>
  <block id="b4360d9dcce9e932e3b5b09fdc524745" category="list-text"><block ref="b4360d9dcce9e932e3b5b09fdc524745" category="inline-link-macro-rx"></block></block>
  <block id="fdab91853bf925f2256c6d39ec3f5351" category="section-title">GCP での GCVE の設定</block>
  <block id="9e98cd6f2c1243193cfc50a29bbe3bd4" category="list-text"><block ref="9e98cd6f2c1243193cfc50a29bbe3bd4" category="inline-link-macro-rx"></block></block>
  <block id="553bafb094b811158ae732981f2dbb4e" category="list-text"><block ref="553bafb094b811158ae732981f2dbb4e" category="inline-link-macro-rx"></block></block>
  <block id="202373c4c91793dc8fb54647ff8a2241" category="list-text"><block ref="202373c4c91793dc8fb54647ff8a2241" category="inline-link-macro-rx"></block></block>
  <block id="9597c351929448a6eea4162c4f4a80db" category="list-text"><block ref="9597c351929448a6eea4162c4f4a80db" category="inline-link-macro-rx"></block></block>
  <block id="e8318a9e631a084c73ef782e37caec2d" category="list-text"><block ref="e8318a9e631a084c73ef782e37caec2d" category="inline-link-macro-rx"></block></block>
  <block id="169210ceac9b94f0632cd1182961e949" category="open-title">CVO シングルノードの導入</block>
  <block id="610db6bf34b03f7873afe01d4eec8e58" category="paragraph">このセクションでは、 AWS （ Amazon Web Services ）上でシングルノードの NetApp CVO （ Cloud Volumes ONTAP ）を導入 / 構成するための、さまざまな Terraform 構成ファイルを提供しています。</block>
  <block id="4a537f87e89ac00b1276af84fa6f2da9" category="paragraph">Terraform ドキュメント :<block ref="e2ea72ce6afb985e72624e098135e8e1" category="inline-link-rx"></block></block>
  <block id="c69eb42cd732c6d937af674afc73ba24" category="paragraph">テンプレートを実行するには、次の手順を実行します。</block>
  <block id="0b2fc5bb85de930f6b1d839951f8df6d" category="list-text">リポジトリをクローニングします。</block>
  <block id="6f5cc42a3e67b7edb3a2d4b86ebfae01" category="list-text">目的のフォルダに移動します</block>
  <block id="71046100fbc383dd8cd1cdd6160f6d6d" category="list-text">CLI から AWS クレデンシャルを設定する。</block>
  <block id="4a4f9b0378c89fa21da9e5528c8a7f47" category="list-text">AWS アクセスキー ID [None] ：アクセスキー</block>
  <block id="6bbb2ea6e07d16e69748545bf2ee6a6d" category="list-text">AWS Secret Access Key [None] ： secretkey</block>
  <block id="7a31be9d48b53cd82a7160af0cd58fbe" category="list-text">デフォルトのリージョン名 [None] ： us-west-2</block>
  <block id="276bf14207394167e2ed4e3eed448680" category="list-text">デフォルトの出力形式は [None] ： json です</block>
  <block id="dd08960caafad89635926c55a0efd3a4" category="list-text">変数 /AWS_CVO-SILE_Node_deployment.tfvar' の変数値を更新します</block>
  <block id="e962d97debd0a377828855d79b5ccf66" category="admonition">変数「 AWS_Connector_deploy_bool 」の値を true または false に設定することで、コネクタを導入することができます。</block>
  <block id="88cefa0997a2272107223ee543b114db" category="list-text">Terraform リポジトリを初期化して、すべての前提条件をインストールし、導入の準備をします。</block>
  <block id="046372e4315eccae02c5be2caaac1ac5" category="list-text">terraform validate コマンドを使用して、 terraform ファイルを確認します。</block>
  <block id="144930ffd88cabf8795c7d4a6698e4ac" category="list-text">設定を事前に実行して、導入で想定されるすべての変更をプレビューします。</block>
  <block id="50a325adfbe874e5e14b044244efa49e" category="list-text">導入を実行</block>
  <block id="3125f7b5833c80fbd03966accb540bf8" category="paragraph">展開を削除します</block>
  <block id="58c9aaf9cf3d4d0215afe012b77aa1bc" category="paragraph">「コネクタ」</block>
  <block id="251861170f071d1ebe67b948f5026905" category="paragraph">CVO 導入用の NetApp AWS Connector インスタンスの Terraform 変数。</block>
  <block id="496ee322ba138fdbc777e5ab2e30145e" category="cell">* 名前 *</block>
  <block id="7464a7978b1ad9e7f36e5f0181e97eb5" category="cell">* タイプ *</block>
  <block id="22d8f94f4a088cb8d7c83ec5f44a03af" category="cell">* AWS_Connector_deploy_bool *</block>
  <block id="c26f15e86e3de4c398a8273272aba034" category="cell">ブール値</block>
  <block id="95ab4e4a16c4f585ede4d3c63167c1ee" category="cell">（必須）コネクタの配置を確認します。</block>
  <block id="e15fa495ec49ba53e0ba45d555c24027" category="cell">* AWS_Connector_name*</block>
  <block id="27118326006d3829667a400ad23d5d98" category="cell">文字列</block>
  <block id="5548283861d04af602b7193306751df7" category="cell">（必須） Cloud Manager Connector の名前。</block>
  <block id="8c3a0cf46a98725e12d666e2e13dc06d" category="cell">* AWS_connector_region *</block>
  <block id="efb4f51f6b08f54633b02a06b94210f2" category="cell">（必須） Cloud Manager Connector を作成するリージョン。</block>
  <block id="358040941579fe064f522f5b1eac2a33" category="cell">* AWS_Connector_key_name*</block>
  <block id="5c2f4db5972ecd2062c5f449f09c661f" category="cell">（必須）コネクタインスタンスに使用するキーペアの名前。</block>
  <block id="0e46676177a5b007dfeefb6ada2b65af" category="cell">* AWS_connector_company *</block>
  <block id="a7f1f5d73f372170ea283996e464af43" category="cell">（必須）ユーザの会社名。</block>
  <block id="9b9081642589bb52bb20161632edc5a6" category="cell">* AWS_Connector_instance_type *</block>
  <block id="ddd1c9b22f94863b3de9a1b551188553" category="cell">（必須）インスタンスのタイプ（ t3.xlarge など）。少なくとも 4 つの CPU と 16 GB のメモリが必要です。</block>
  <block id="f8a700002db36fadde1ab9526f2cf8c3" category="cell">* AWS_connector_subnet_id *</block>
  <block id="76788966b37b9b0df0b8ed78ad67eea9" category="cell">（必須）インスタンスのサブネットの ID 。</block>
  <block id="fafb089eb14a5fe730cfadfd7bed4b4f" category="cell">* AWS_Connector_security_group_id *</block>
  <block id="52df26383575ad500acf38cc3df88e36" category="cell">* AWS_Connector_iAM_instance_profile_name *</block>
  <block id="59409115b42184ffa519bd9aa24b6816" category="cell">（必須）コネクタのインスタンスプロファイルの名前。</block>
  <block id="8953ca5d18d5f2c4a85fdfe10d30a002" category="cell">* AWS_Connector_account_id *</block>
  <block id="bba7484e58b18e8edafdbe619961f73f" category="cell">（オプション）コネクタを関連付けるネットアップアカウントの ID 。指定しない場合、 Cloud Manager は最初のアカウントを使用します。アカウントが存在しない場合、 Cloud Manager は新しいアカウントを作成します。アカウント ID は、 Cloud Manager のアカウントタブにあります<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>。</block>
  <block id="1918f44c178eed586b6fa7d6739af317" category="cell">* AWS_connector_public_ip_bool *</block>
  <block id="a4472307f162bdf147f02784bf81ab9d" category="cell">（任意）インスタンスにパブリック IP アドレスを関連付けるかどうかを指定します。指定しない場合は、サブネットの設定に基づいて関連付けが行われます。</block>
  <block id="9fb01bbff06d549bce01928fa2f7784c" category="paragraph">「シングルノードインスタンス」</block>
  <block id="d166b6e004666a5a8daa6db1c3cf1a13" category="paragraph">単一の NetApp CVO インスタンスの Terraform 変数。</block>
  <block id="19afa3a1ac092d450f21236f1973c705" category="cell">* CVO-NAME *</block>
  <block id="59935a520838700b451a3757f31fd4ac" category="cell">（必須） Cloud Volumes ONTAP 作業環境の名前。</block>
  <block id="ff855355eebbbfbd54d2734a61c43fd4" category="cell">* CVF_REGION *</block>
  <block id="b50ada32f992aba9f7055658a79132f2" category="cell">（必須）作業環境を作成するリージョン。</block>
  <block id="0e9b90f836062c3007935370ef18245f" category="cell">* CVO-subnet_id *</block>
  <block id="6c7cb9b4623284c101253ed002625e53" category="cell">（必須）作業環境を作成するサブネット ID 。</block>
  <block id="a99ec45accc4987a7eb2eff5219f96b3" category="cell">* CVO-vPC_id *</block>
  <block id="a179f6c6854fc89c6f118f4d8c201cad" category="cell">（オプション）作業環境を作成する VPC ID 。この引数を指定しない場合は、指定したサブネット ID を使用して VPC が計算されます。</block>
  <block id="26ff13994e5fbad1e11fc231bc73a5b6" category="cell">* CVO-svm_password* をクリックします</block>
  <block id="c82a889260bdc28c6136ddc6639a4f2e" category="cell">（必須） Cloud Volumes ONTAP の管理パスワード。</block>
  <block id="3815749b59fbccfa0077df4f90c8aa1e" category="cell">* CVF_Writing _speed_state *</block>
  <block id="e382698236dcb1567d375a4be3b12c2f" category="cell">（オプション） Cloud Volumes ONTAP の書き込み速度設定： [ 「 normal 」、「 high 」。デフォルトは「 normal 」です。</block>
  <block id="197b0ef64aabdc02a240f3f472eb4da2" category="open-title">CVO HA の導入</block>
  <block id="a082a9d97b4465f73e12cde3444a5296" category="paragraph">このセクションでは、 AWS （ Amazon Web Services ）のハイアベイラビリティペアに NetApp CVO （ Cloud Volumes ONTAP ）を導入 / 構成するための、さまざまな Terraform 構成ファイルを提供しています。</block>
  <block id="b31736be0fe5e59cc4905aa080c9ab16" category="list-text">変数 /AWS_CVO-HA_DEVELOT.tfvars の変数値を更新します。</block>
  <block id="ff8f4d628633e3ceb42dcca91ef2948e" category="paragraph">HA ペア</block>
  <block id="f7fbe4e66ae4cece99ae14a24f1c44ef" category="paragraph">HA ペアの NetApp CVO インスタンスの変数はテラフォームされます。</block>
  <block id="018a56af12514193b08f44d59f92fe83" category="cell">* CVO-is_HA *</block>
  <block id="93d83a3a243548e55fb126d283923435" category="cell">（オプション）作業環境が HA ペアであるかどうかを示します（ [true 、 false] ）。デフォルトは false です。</block>
  <block id="cea330e4ead03fcfec439b1f44be7c07" category="cell">* CVO-node1 _subnet_id *</block>
  <block id="3a0cbf54e2a847cd873a45840f9965f5" category="cell">（必須）最初のノードを作成するサブネット ID 。</block>
  <block id="d5d3a5e1275b1995e05472c7bfbcb53f" category="cell">* CVO-node2 _subnet_id *</block>
  <block id="5691678a4c059b3a4ebad0f4c6bf6bb5" category="cell">（必須） 2 つ目のノードを作成するサブネット ID 。</block>
  <block id="4377aa272f4cf89d4bbd39432ffb3b0e" category="cell">* CVF_Failover_mode *</block>
  <block id="9d76030e2a28826bff45ea1dff4d6920" category="cell">（任意） HA の場合、 HA ペアのフェイルオーバーモード： [PrivateIP] 、 [FloatingIP] 。「 PrivateIP 」は 1 つのアベイラビリティゾーン用で、「 FloatingIP 」は複数のアベイラビリティゾーン用です。</block>
  <block id="80c8a57adaed641642cd870951a1d4ed" category="cell">* CVO-mediator_subnet_id *</block>
  <block id="49ef0197555436f78dd87f582e510523" category="cell">（オプション） HA の場合は、メディエーターのサブネット ID 。</block>
  <block id="3efb524d034b1e223cb9d31a64f9bbc4" category="cell">* CVO-mediator_key_pair_name *</block>
  <block id="224733036290c1421bed8ad8de688956" category="cell">（オプション） HA の場合は、メディエーターインスタンスのキーペアの名前。</block>
  <block id="069dcc590a2acf756e6ca7f92d7d8355" category="cell">* CVO-cluster_floating_IP *</block>
  <block id="6325a8aefd56c67fab1d0d83b4cb8a2e" category="cell">（任意） HA FloatingIP の場合、クラスタ管理のフローティング IP アドレス。</block>
  <block id="618070e07e603612f24fa88a7ab583a8" category="cell">* CVO-data_floating_IP *</block>
  <block id="d8abdbcf87e3308c6a8e731ef574625c" category="cell">（任意） HA FloatingIP の場合は、データフローティング IP アドレス。</block>
  <block id="f115ec8cf476ea0198405ca27346e423" category="cell">* CVO-data_floating_ip2 *</block>
  <block id="754296c6c8a8cf70377730f6f126f24a" category="cell">* CVO-SVM_floating_IP *</block>
  <block id="797d132b963a11de245eae1725911bfe" category="cell">（オプション） HA FloatingIP の場合、 SVM 管理のフローティング IP アドレス。</block>
  <block id="418ba9c064c1fb64b11195c729d6a8b1" category="cell">* CVO-ROT_ROTLE_IDS*</block>
  <block id="4ee29ca12c7d126654bd0e5275de6135" category="cell">リスト</block>
  <block id="671a800e3791f7531a319e8b81e97c44" category="cell">（任意） HA FloatingIP の場合、フローティング IP で更新されるルートテーブル ID のリスト。</block>
  <block id="5d4a46c0a4567f819ba5935256b18297" category="open-title">FSX の導入</block>
  <block id="d43e39ffb05b35b72664b10dd8b8eb09" category="paragraph">このセクションには、 AWS （ Amazon Web Services ）上で NetApp ONTAP FSX を導入 / 設定するための、さまざまな Terraform 構成ファイルが含まれています。</block>
  <block id="171cc8e4954beec5176905189f71a708" category="list-text">デフォルトの出力形式 [None] ：</block>
  <block id="cbc2cee2851524f322f8d71e55d32a64" category="list-text">変数 /AWS_FSX_deployment.tfvars の変数値を更新します</block>
  <block id="05bf1719b762d4d80bcb0e545b3db1d2" category="paragraph">NetApp AWS Connector インスタンスの Terraform 変数。</block>
  <block id="618716470abe9536903f3c6781c4ac81" category="paragraph">「 FSX インスタンス」</block>
  <block id="5869d95322d3c435fd999596f0cf2303" category="paragraph">NetApp ONTAP FSX インスタンスの Terraform 変数。</block>
  <block id="c64f672849455d583204c525f5ea39ad" category="cell">* FSX_NAME*</block>
  <block id="af87bb54b839634f865f7bd7e2be203a" category="cell">* FSX_REGION *</block>
  <block id="02a52209be6996bc01fd629ac6a5b472" category="cell">* FSX_primary_subnet_id *</block>
  <block id="5dcd0d05819e117f52d439bebd6d2b42" category="cell">（必須）作業環境を作成するプライマリサブネット ID 。</block>
  <block id="0531247f461759a809214a03ea2f5f74" category="cell">* fsx_secondary_subnet_id *</block>
  <block id="b2184e9a131868dbc2332805652a0f02" category="cell">（必須）作業環境を作成するセカンダリサブネット ID 。</block>
  <block id="a333cc205644905efae2cf71519da619" category="cell">* fsx_account_id *</block>
  <block id="323c4fdc16ad2dd9e846afbcd4b69b10" category="cell">（必須） FSX インスタンスを関連付けるネットアップアカウントの ID 。指定しない場合、 Cloud Manager は最初のアカウントを使用します。アカウントが存在しない場合、 Cloud Manager は新しいアカウントを作成します。アカウント ID は、 Cloud Manager のアカウントタブにあります<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>。</block>
  <block id="7355bef79bff8e33a86af33fe4dcca8e" category="cell">* FSX_workspace_id *</block>
  <block id="97377fef3f33f9c8d1fb21c0d81cdf92" category="cell">（必須）作業環境の Cloud Manager ワークスペースの ID 。</block>
  <block id="ab77fdca353b13807c947d554712d8eb" category="cell">* FSX_admin_password *</block>
  <block id="c4bd49cb0034d697fd71cae233c3966c" category="cell">* FSX_Throughput _capacity *</block>
  <block id="e1ae53e33bf94a13f7d73cf885059ea6" category="cell">（任意）スループットの容量。</block>
  <block id="011dda542c81d29bda593f0cf6fafdfa" category="cell">* FSX_storage_capacity_size *</block>
  <block id="16b74c686b794890297f7ff7a9c98c9f" category="cell">（オプション）最初のデータアグリゲートの EBS ボリュームサイズGB の場合、単位は [100 または 500] です。TB の場合、単位は [1,2,4,8,16] です。デフォルトは「 1 」です。</block>
  <block id="da7d44d0ad606f586a3b1f567c8502d6" category="cell">* FSX_storage_capacity_size_unit *</block>
  <block id="5ec54d3d7d1db9fbf915daed12667b29" category="cell">（オプション） ['GB' または 'TB'] 。デフォルトは「 TB 」です。</block>
  <block id="07cc738168b47a86b740bc01e210b442" category="cell">* FSX_cloudmanager_aws _credential _name *</block>
  <block id="48dbb4d925fe4a46f28c0a8466a2f628" category="cell">（必須） AWS クレデンシャルアカウント名。</block>
  <block id="2fbb88fe90f9183c7eab541bc808795f" category="summary">このページでは、テラフォームを使用してネットアップのボリュームをクラウドプロバイダ（ AWS 、 Azure 、 GCP ）に自動で導入する方法について説明します。</block>
  <block id="8eece2f5500ed61d5d5d24d6b8cc6da5" category="doc">Terraform による Cloud Volume オートメーション</block>
  <block id="e11da9afe91d381489a365c86cc614ab" category="section-title">前提条件</block>
  <block id="95332f844502bac70e3783f2d906688c" category="list-text">Terraform &gt;=0.13</block>
  <block id="82410a61f302c6bdce619218d5036674" category="list-text">Cloud Manager アカウント</block>
  <block id="77913a2ff2c55b56fd6d981e7d7d2303" category="list-text">クラウドプロバイダアカウント– AWS 、 Azure</block>
  <block id="8fdcd620b2871b4f496213f43c8ee21f" category="list-text">ホストマシン（ Terraform がサポートするすべての OS ）</block>
  <block id="e5da768f23935e9c380799d86e27d695" category="section-title">プロバイダのドキュメント</block>
  <block id="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-macro"><block ref="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-rx"></block></block>
  <block id="b78f34c8bc7d03e88e2a6d7d8907ef93" category="paragraph">Cloud Manager の Terraform プロバイダのドキュメントは、次の URL から入手できます。 <block ref="05e9b3cbe087530696c6230448ff6b71" category="inline-link-macro-rx"></block></block>
  <block id="ef335030cde4c62e318574aa31ee49f7" category="section-title">プロバイダバージョンの制御</block>
  <block id="cc6d892dc2fbac39a7a00c3d822275b8" category="paragraph">プロバイダのバージョンを制御することもできます。これは、 Terraform 設定の required_providers ブロックによって制御されます。</block>
  <block id="bf4e80680b83752f1f57ca7d4e99d09b" category="paragraph">構文は次のとおりです。</block>
  <block id="c26cc3bad4e19f3604486c6e2d4dee15" category="paragraph">プロバイダバージョン管理の詳細については、こちらをご覧ください。</block>
  <block id="c335a311e2b771c143fbe09512d98021" category="section-title">実行中の特定のモジュール</block>
  <block id="0d6f6c74055e04156e36ddb127070a54" category="open-title">ANF</block>
  <block id="3f5bad999be275e4e9cf0728a13bf09c" category="paragraph">このセクションでは、 Azure に ANF （ Azure NetApp Files ）ボリュームを導入 / 設定するためのさまざまな Terraform 設定ファイルを示します。</block>
  <block id="61d66a29b98e4203b3fc2ea2884a6c5f" category="paragraph">Terraform ドキュメント :<block ref="745f55dd9f8ecc62d59e6b03ca9efbb7" category="inline-link-rx"></block></block>
  <block id="369baedac810ebc745ed2edf7754972b" category="list-text">Azure CLI にログインします（ Azure CLI がインストールされている必要があります）。</block>
  <block id="443ff7602b19f9692863937e763e1ad2" category="list-text">vars/azure_anf.tfvars の変数値を更新します</block>
  <block id="95f6ca118177fad8a1dd7e7abb74ce56" category="admonition">既存の VNet およびサブネットを使用して ANF ボリュームを導入することもできます。変数「 vnet_creation_bool 」と「 subnet_creation_bool 」の値を false に設定し、「 subnet_id_for _anf_vol 」を指定します。これらの値を true に設定して新しい VNet とサブネットを作成する場合にも、新しく作成したサブネットからサブネット ID が自動的に取得されます。</block>
  <block id="cb01f53471a55574a36eafb375d9493a" category="paragraph">単一のネットアップ ANF ボリュームに対応する Terraform 変数。</block>
  <block id="98bcef9bf5f44342e688bc29fb3fcbca" category="cell">* AZ_location*</block>
  <block id="4b05afb76d83065313c3740cd392a5ca" category="cell">（必須）リソースが存在する、サポートされている Azure の場所を指定します。これを変更すると、新しいリソースが強制的に作成されます。</block>
  <block id="861c040d5ed0212e4bc2aa4f92a2b861" category="cell">* AZ_PREFIX *</block>
  <block id="e6f149d38df85bed35faeca44370c01c" category="cell">（必須）ネットアップボリュームを作成するリソースグループの名前。これを変更すると、新しいリソースが強制的に作成されます。</block>
  <block id="7aa7ec2fc803d9041e6dfd5e142dcd23" category="cell">* AZ_vnet_address_space *</block>
  <block id="c8b090fd446e4181ed79e8e50bed7b91" category="cell">（必須） ANF ボリューム導入用として新しく作成した VNet で使用するアドレススペースです。</block>
  <block id="c5b9420927a71e0bcd6f4c621c66910f" category="cell">* AZ_subnet_address_prefix *</block>
  <block id="94c126b468fd9c408abdff2cccd827a4" category="cell">（必須） ANF ボリューム導入用に新しく作成した VNet で使用するサブネットアドレスプレフィックスです。</block>
  <block id="3c3133cb45a10a4ec442a4589636bfe1" category="cell">* AZ_volume_path *</block>
  <block id="c8fb8ccec1ede566cac7b410b7623186" category="cell">（必須）ボリュームの一意のファイルパス。マウントターゲットの作成時に使用します。これを変更すると、新しいリソースが強制的に作成されます。</block>
  <block id="5e51835c1dd28fa3cab3636a6beb8016" category="cell">* az _capacity_pool_size *</block>
  <block id="a0faef0851b4294c06f2b94bb1cb2044" category="cell">整数</block>
  <block id="32c4a6ca695ae0fd3f41efe5ab8d3ffc" category="cell">* az_vnet_creation_bool *</block>
  <block id="27226c864bac7454a8504f8edb15d95b" category="cell">ブール値</block>
  <block id="55a1cc8d235c0ca9bd0cf384e2db1fb2" category="cell">（必須）新しい VNet を作成する場合は、このブール値を「 true 」に設定します。既存の VNet を使用するには、このパラメータを「 false 」に設定します。</block>
  <block id="be85fde9f0fcdf86be8ede4b5939a9bf" category="cell">* az_subnet_creation_bool *</block>
  <block id="4b079d5e017c7403047fbbd37df93368" category="cell">（必須）新しいサブネットを作成するには、このブーリアンを「 true 」に設定します。既存のサブネットを使用する場合は 'false に設定します</block>
  <block id="bb74e9c4e24089c59a6af0a7a016b586" category="cell">* az _subnet_id_for _anf_vol *</block>
  <block id="52c0fe6a129fdcf33be82680a15b2d37" category="cell">（必須）「 subnet_creation_bool 」を true に設定して既存のサブネットを使用する場合に、サブネット ID を指定します。false に設定する場合は、デフォルト値のままにします。</block>
  <block id="8376cf4b94c63b51d5e0113c299a75a0" category="cell">* AZ_NetApp_POOL_SERVICE_LEVEL *</block>
  <block id="061fce6317efb41fcda88b5333cb0cc2" category="cell">（必須）ファイルシステムのターゲットパフォーマンス。有効な値は 'Premium'Standard' または Ultra です</block>
  <block id="cd145efde532a4a27c5b6687f4b5f1c0" category="cell">* AZ_NetApp_vol_SERVICE_LEVEL *</block>
  <block id="d655c67b837d5b3363d556955802b670" category="cell">* AZ_NetApp_vol_protocol *</block>
  <block id="9e2a44ac250e0b60bce77fba70ebfd70" category="cell">（オプション）リストで表されるターゲットボリュームプロトコル。サポートされる単一の値には 'CIFS'nfsv3' または 'NFSv4.1 があります引数が定義されていない場合、デフォルトは「 nfsv3 」です。これを変更すると、新しいリソースが強制的に作成され、データが失われます。</block>
  <block id="cac15590a2775bfeaf5f70c36186a840" category="cell">* AZ_NetApp_vol_security_style *</block>
  <block id="80f43a817b6716a1a82af5fe18f178cd" category="cell">（任意）ボリュームセキュリティ形式。有効値は「 Unix 」または「 NTFS 」です。指定されない場合 ' 単一プロトコル・ボリュームは 'nfsv3' または 'nfsv3' ボリュームの場合は 'UNIX' にデフォルトで作成されますが 'CIFS' の場合は 'NTFS' にデフォルト設定されますデュアル・プロトコル・ボリュームでは ' 指定しない場合 'ntfs_' の値になります</block>
  <block id="b095a46d015fe5581a97472eedb3e645" category="cell">* AZ_NetApp_vol_storage_quota *</block>
  <block id="aaff31e02103a31c6f08943798a84789" category="cell">（必須）ファイルシステムに許可される最大ストレージクォータ（ギガバイト単位）。</block>
  <block id="7bc40f4d4f846e8c7177d752ac52b775" category="open-title">ANF データ保護</block>
  <block id="56978261632f1f36ad5f3f3ea6d2cb4b" category="paragraph">このセクションでは、 Azure でデータ保護を使用して ANF （ Azure NetApp Files ）ボリュームを導入 / 設定するためのさまざまな Terraform 設定ファイルについて説明します。</block>
  <block id="9b3e184737a0a337479622611ba072b7" category="list-text">vars/azure_anf_data_protection_tfvars の変数値を更新します。</block>
  <block id="bf052e3d77cd2cde5fa905542df51c46" category="paragraph">「 ANF データ保護」</block>
  <block id="17745d8782266e5f08c77485447c8727" category="cell">* AZ_alt_location *</block>
  <block id="3bfeadf4c47a658ca94a6066aee32aaa" category="cell">（必須）セカンダリボリュームを作成する Azure の場所</block>
  <block id="2558355ccfd79f11c2c7771d473c28a9" category="cell">* AZ_vnet_primary_address_space *</block>
  <block id="cc551875f8711aaffc6141f504677c0b" category="cell">（必須） ANF プライマリボリューム導入用として新しく作成した VNet が使用するアドレススペース。</block>
  <block id="ea5f0cd471c631d7531bb7fd3b5bac8a" category="cell">* AZ_vnet_secondary_address_space *</block>
  <block id="fffcb59495331e54049ce33d3dcdf943" category="cell">（必須） ANF セカンダリボリューム導入用として新しく作成した VNet が使用するアドレススペース。</block>
  <block id="88220764f0745e8a07a6578ee5a34962" category="cell">* AZ_subnet_primary_address_prefix *</block>
  <block id="02b00c599f6c249474a4fa82513b5ae3" category="cell">（必須） ANF プライマリボリューム導入用に新しく作成した VNet で使用するサブネットアドレスプレフィックスです。</block>
  <block id="1bef049d5f330664e35cad0a064c3b9c" category="cell">* AZ_subnet_secondary_address_prefix *</block>
  <block id="1b60506e52e47ecc443e5be52dca93d7" category="cell">（必須） ANF セカンダリボリューム導入用に新しく作成した VNet で使用するサブネットアドレスプレフィックスです。</block>
  <block id="897362b63a34b0eb8e1453709c1f8403" category="cell">* AZ_volume_path_primary *</block>
  <block id="1240d8345e0d2e3e79133040103d900c" category="cell">（必須）プライマリボリュームの一意のファイルパス。マウントターゲットの作成時に使用します。これを変更すると、新しいリソースが強制的に作成されます。</block>
  <block id="b9dd6d654f6dd5777451c38ccbb3a90f" category="cell">* AZ_volume_path_secondary *</block>
  <block id="2d48913a4e9f87154afa26a5629292ac" category="cell">（必須）セカンダリボリュームの一意のファイルパス。マウントターゲットの作成時に使用します。これを変更すると、新しいリソースが強制的に作成されます。</block>
  <block id="06c1e84417c5bf369b90b26dd5249917" category="cell">* AZ_capacity pool_size_primary *</block>
  <block id="3d618d26614058ac7e5a064cbe202b90" category="cell">* AZ_capacity pool_size_secondary *</block>
  <block id="900391b8f681698a00a1d7681c809eae" category="cell">* az_vnet_primary_creation_bool *</block>
  <block id="ee71ed057be46b5303595075681242b3" category="cell">（必須）プライマリボリューム用の新しい VNet を作成する場合は、このブーリアンを「 true 」に設定します。既存の VNet を使用するには、このパラメータを「 false 」に設定します。</block>
  <block id="1f3233bfcd515798625102d02489c9c2" category="cell">* az_vnet_secondary_creation_bool *</block>
  <block id="8a5a92fb6843cb45a9752dac34d8056a" category="cell">（必須）セカンダリボリューム用の新しい VNet を作成する場合は、このブーリアンを「 true 」に設定します。既存の VNet を使用するには、このパラメータを「 false 」に設定します。</block>
  <block id="0276da5ab0cbfd3afccac3236ff88906" category="cell">* az_subnet_primary_creation_bool *</block>
  <block id="ba2f66ccca4d07fb389900a4c72596a7" category="cell">（必須）このブール値を「 true 」に設定して、プライマリボリュームの新しいサブネットを作成します。既存のサブネットを使用する場合は 'false に設定します</block>
  <block id="78a2830c902a8a1eb6bbedc95b8e859d" category="cell">* az_subnet_secondary_creation_bool *</block>
  <block id="1b869ff43f405cb5056d067f1ce0ea2c" category="cell">（必須）セカンダリボリュームの新しいサブネットを作成するには、このブーリアンを「 true 」に設定します。既存のサブネットを使用する場合は 'false に設定します</block>
  <block id="004f2f461ceadcb0d344b03f2f00c53d" category="cell">* az _primary_subnet_id_for _anf_vol *</block>
  <block id="387a4516572f71aa24490f3bbfc695ef" category="cell">（必須）「 subnet_primary_creation_bool 」を true に設定して既存のサブネットを使用する場合に、サブネット ID を指定します。false に設定する場合は、デフォルト値のままにします。</block>
  <block id="2e9685846dda27855273fdf064f9e6ab" category="cell">* AZ_SECONDARY _subnet_id_on_anf_vol *</block>
  <block id="bf5c8bfc6d7cc2d5fe6e7931244a30eb" category="cell">（必須）「 subnet_secondary_creation_bool 」を true に設定して既存のサブネットを使用する場合に備えて、サブネット ID を指定します。false に設定する場合は、デフォルト値のままにします。</block>
  <block id="ac839f935b4bbb6bed9bda28a8e642c6" category="cell">* AZ_NetApp_POOL_SERVICE_LEVEL_PRIMARY *</block>
  <block id="8cb34f1d64a5bf358b0d3a349ca5bc2f" category="cell">* AZ_NetApp_POOL_SERVICE_LEVEL_SECONDARY *</block>
  <block id="7ad9306273877be4925eef5c298c8082" category="cell">* AZ_NetApp_vol_SERVICE_LEVEL_PRIMARY *</block>
  <block id="5614656fa00c06faf1c3484531a679a9" category="cell">* AZ_NetApp_vol_SERVICE_LEVEL_SECONDARY *</block>
  <block id="4f517398039e7c48806d41487b9419bc" category="cell">* AZ_NetApp_vol_protocol_primary *</block>
  <block id="82b777cb90770b16388fa42e12e046ab" category="cell">* AZ_NetApp_vol_protocol_secondary *</block>
  <block id="59783d86d863461df5e6d03ac2bb42df" category="cell">* AZ_NetApp_vol_storage_quota_policy_primary *</block>
  <block id="de8fa216337d1b3497efb08ceeb2ba75" category="cell">* AZ_NetApp_vol_storage_QUOTA_SECONDARY *</block>
  <block id="0b11ea56e0e5211214ff431c4e076717" category="cell">* AZ_DP_replication_frequency *</block>
  <block id="79ce3fc5fe45b145bb343376fe5351b9" category="cell">（必須）レプリケーション頻度。サポートされる値は「 10 分」、「時間単位」、「日単位」です。値は大文字と小文字が区別されます。</block>
  <block id="c623b4e11f7cb20ff0b7c24a72d3f0ef" category="open-title">ANF デュアルプロトコル</block>
  <block id="d25220d03f7afcb6f5edcbc46e369d45" category="paragraph">このセクションでは、 Azure でデュアルプロトコルを有効にした ANF （ Azure NetApp Files ）ボリュームを導入 / 設定するためのさまざまな Terraform 設定ファイルについて説明します。</block>
  <block id="9568461c901e88398bed16e11ad813d3" category="list-text">vars/azure_anf_dual_protocol.tfvars の変数値を更新します。</block>
  <block id="d263b475ab751de671d08455b33997c1" category="paragraph">デュアルプロトコルが有効な単一の ANF ボリューム用の Terraform 変数。</block>
  <block id="b183512797a1d9ea69a8dab9e27df52c" category="cell">* AZ_NetApp_vol_protocol1 *</block>
  <block id="20fd02f6a193c7aeaee651654a332933" category="cell">（必須）ターゲットボリュームプロトコル。リストで表されます。サポートされる単一の値には 'CIFS'nfsv3' または 'NFSv4.1 があります引数が定義されていない場合、デフォルトは「 nfsv3 」です。これを変更すると、新しいリソースが強制的に作成され、データが失われます。</block>
  <block id="cc032be5baf5b9484eb2d659f4e314c6" category="cell">* AZ_NetApp_vol_protocol2 *</block>
  <block id="910944ff76e7b2acfc482a34501df6f5" category="cell">* AZ_SMB_server_username *</block>
  <block id="152372e48ac8f85f2e4908c5a1489a78" category="cell">（必須） ActiveDirectory オブジェクトを作成するユーザ名。</block>
  <block id="239e5edf090c4c70025b340f651694cc" category="cell">* AZ_SMB_server_password *</block>
  <block id="7b05e834084d190fe540481374f4fe0d" category="cell">（必須） ActiveDirectory オブジェクトを作成するためのユーザパスワード。</block>
  <block id="4e2be381ec92158458ceef11bdf41ef7" category="cell">* AZ_SMB_SERVER_NAME*</block>
  <block id="533dd582bfe3528b9b6ae4ff1889bd8f" category="cell">（必須） ActiveDirectory オブジェクトを作成するサーバ名。</block>
  <block id="f17c01535ba9f04720700d5e0d17172a" category="cell">* AZ_SMB_DNS_servers *</block>
  <block id="e70256203c6e23fcee3efa8d56fcfa85" category="cell">（必須） ActiveDirectory オブジェクトを作成するための DNS サーバ IP 。</block>
  <block id="bdf618611712c6caa6fd0340470ee9f2" category="open-title">Snapshot からの ANF ボリューム</block>
  <block id="174e6e8f24023c93c7c470267f4c2376" category="paragraph">このセクションでは、 Azure 上の Snapshot から ANF （ Azure NetApp Files ）ボリュームを導入 / 設定するためのさまざまな Terraform 設定ファイルを示します。</block>
  <block id="215d5ed09cbe3ca5b10c6d616024053a" category="list-text">vars/azure_anf_volume_from_snapshot.tfvars の変数値を更新します。</block>
  <block id="a753ff452c91c6e4de63b907e8253e05" category="paragraph">Snapshot を使用する単一の ANF ボリューム用の変数を Terraform します。</block>
  <block id="57bd49c8f9a43967f48ec8f1f3ca2846" category="cell">* AZ_SNAPSHOT_ID *</block>
  <block id="ff461cb79e6adda28ae488782f0da97f" category="cell">（必須）新しい ANF ボリュームを作成する際に使用する Snapshot ID 。</block>
  <block id="04107ff6b0460381c55ff620a1021254" category="list-text">変数 \azure_CVO-SILE_NODE_deployment.tfvars の変数を更新します。</block>
  <block id="73b95097cc4819b49af28734c8da85f9" category="paragraph">単一ノードの Cloud Volumes ONTAP （ CVO ）用の Terraform 変数。</block>
  <block id="3226e634f46cb19ab313171144dd34bd" category="cell">* refresh_token *</block>
  <block id="d687ff26916f17fd879c87b138961b29" category="cell">（必須） NetApp Cloud Manager の更新トークン。これは NetApp Cloud Central から生成できます。</block>
  <block id="2c64afa8a46290b632eba256c644932c" category="cell">* AZ_Connector_name *</block>
  <block id="3eb8706ea09733709f78eddf34865fc5" category="cell">* AZ_Connector_location *</block>
  <block id="758699b195f5916d500521462cf30da9" category="cell">（必須） Cloud Manager Connector を作成する場所。</block>
  <block id="1fab22f54c2298a6c193e9dbf02a5f40" category="cell">* AZ_Connector_subscription_id *</block>
  <block id="3eaa20b60039584fbaada041b1e9c27b" category="cell">（必須） Azure サブスクリプションの ID 。</block>
  <block id="15a22866556f3e50073015243ddd7953" category="cell">* AZ_Connector_company *</block>
  <block id="d6da30a455e4a736b78aebafd5a574ec" category="cell">* AZ_Connector_resource_group *</block>
  <block id="7869ff24b2017b68dfcffe9346969d04" category="cell">（必須）リソースが作成される Azure 内のリソースグループ。</block>
  <block id="9ddf31c7bd196ef12b5afc14819332ae" category="cell">* AZ_Connector_subnet_id *</block>
  <block id="a41a332f5c3dda90835d004d4471e0a8" category="cell">（必須）仮想マシンのサブネットの名前です。</block>
  <block id="dabe6b258248c0eefb5e7f8ef812c828" category="cell">* AZ_Connector_vnet_id *</block>
  <block id="5209c2acb9f23446cfa41482e2ff8ee2" category="cell">（必須）仮想ネットワークの名前。</block>
  <block id="d00bbff7436422db546132791ca30dd2" category="cell">* AZ_Connector_network_security_group_name *</block>
  <block id="b5033b19e9c2388be995930fb1c49365" category="cell">（必須）インスタンスのセキュリティグループの名前。</block>
  <block id="54dee4dedf4b10ae9a250e887c349324" category="cell">* AZ_Connector_associate_public_IP_address *</block>
  <block id="c954a4a98e68d0734dcd6d7ad00db3f5" category="cell">（必須）仮想マシンにパブリック IP アドレスを関連付けるかどうかを指定します。</block>
  <block id="d363651cb914dfbc47f512db8ce8a9c0" category="cell">* AZ_Connector_account_id *</block>
  <block id="53b73bbe0bca0a3d51fbda15ecc058db" category="cell">（必須）コネクタを関連付けるネットアップアカウントの ID 。指定しない場合、 Cloud Manager は最初のアカウントを使用します。アカウントが存在しない場合、 Cloud Manager は新しいアカウントを作成します。アカウント ID は、 Cloud Manager のアカウントタブにあります<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>。</block>
  <block id="b851f892237fb399ca9999caee142ccf" category="cell">* AZ_Connector_admin_password *</block>
  <block id="aa98915ce83ffe89562020e5b4d9a376" category="cell">（必須）コネクタのパスワード。</block>
  <block id="1b9c1e319401f16966d7280c81cdc8dc" category="cell">* AZ_Connector_admin_username*</block>
  <block id="e0f32faffed9caaca61e86caae050f17" category="cell">（必須）コネクタのユーザ名。</block>
  <block id="425624e10c5de04d471a55e4a8b35e31" category="cell">* AZ_CVO-NAME *</block>
  <block id="52ebf6980a494c352ee150c2b801af6e" category="cell">* AZ_CVF_location*</block>
  <block id="8da06548b40415fd473a86a6dba80f82" category="cell">* AZ_CVO-subnet_id *</block>
  <block id="f71ced0388b772479b4e5fba15c83077" category="cell">* AZ_CVO-vnet_id *</block>
  <block id="7d2219b61301dda6352db570bb7c5034" category="cell">* AZ_CVO-vnet_resource_group *</block>
  <block id="fecf56abdc6b5472c8da399cad7791b3" category="cell">（必須）仮想ネットワークに関連付けられた Azure 内のリソースグループ。</block>
  <block id="c63d2e90acb0448db277b1b5b8a8d1fa" category="cell">* AZ_CVO-data_encryption_type*</block>
  <block id="e472a1445850887a7f62ae832b27693a" category="cell">（必須）作業環境に使用する暗号化のタイプ： [Azure] 、 [none] 。デフォルトは「 azure 」です。</block>
  <block id="a09db82d06138c721102bb24bf44745c" category="cell">* AZ_CVO-storage_type *</block>
  <block id="0f0f84813d06e378040fbcf33a733c2c" category="cell">（必須）最初のデータ・アグリゲートのストレージ・タイプ： ['Premium_LRS'Standard_LRS'StandardSSD_LRS]デフォルトは 'Premium_LRS' です</block>
  <block id="2dc6453586c69ea950eec68d5ac9658c" category="cell">* AZ_CVO-svm_svm_svm_name * をクリックします</block>
  <block id="404c8599d393a19d0cd6354f8b6ae58c" category="cell">* AZ_CVO-workspace_id *</block>
  <block id="ec0d845babe316d32a485960e8788bd0" category="cell">（必須） Cloud Volumes ONTAP を導入する Cloud Manager ワークスペースの ID 。指定しない場合、 Cloud Manager は最初のワークスペースを使用します。ID は、の [ ワークスペース（ Workspace ） ] タブで確認できます<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>。</block>
  <block id="868f934d26dc5bf64ab570c48f38be79" category="cell">* AZ_CVF_capacity _tier *</block>
  <block id="e8dcbe7d10f08e94b9057a584009a175" category="cell">（必須）最初のデータ・アグリゲートのデータ階層化を有効にするかどうかを指定します（ [`lob`,'none`] ）デフォルトは「 BLOB 」です。</block>
  <block id="25390bc170c676096ec93edd61a5dca6" category="cell">* AZ_CVF_Writing _speed_state *</block>
  <block id="b632952868dfa1143652e0c226514318" category="cell">（必須） Cloud Volumes ONTAP の書き込み速度設定： [`normal`,`high`]デフォルトは「 normal 」です。この引数は HA ペアには関係ありません。</block>
  <block id="52742ffdac7415fc1d35c1a6d0d9fb7a" category="cell">* AZ_CVF_ONTAP_VERSION *</block>
  <block id="90e696b73ff714675fc926a955cc68e1" category="cell">（必須）必要な ONTAP のバージョン。「 use_latest_version 」が true に設定されている場合は無視されます。デフォルトでは最新バージョンが使用されます。</block>
  <block id="39a41303384652e186a359e5d96e8014" category="cell">* AZ_CVF_INSTANY_TYPE *</block>
  <block id="fb03bbd04a925d04740ba3d3eae2e8b6" category="cell">（必須）選択したライセンスタイプに応じて使用するインスタンスのタイプ。 Explore ： [`Standard_DS3_v2'Standard ： [`Standard_DS4_v2'Standard_DS13_v2'Standard_L8s_v2'Premium ： ['Standard_DS5_v2''Standard_DS14_v2'v2''Pay_DS3_v2''''PAY'v2 インスタンスタイプごとに定義された BYOL ：すべてのライセンスタイプサポートされるインスタンスタイプの詳細については、 Cloud Volumes ONTAP リリースノートを参照してください。デフォルトは 'Standard_DS4_v2' です</block>
  <block id="c0abbc4097de55ad558bd265d5e19b2e" category="cell">* AZ_CVF_LICENSE_TYPE *</block>
  <block id="337fb3a0d6e4f27fa4187c6e10b9d41b" category="cell">（必須）使用するライセンスのタイプ。シングルノードの場合： [`azure-CO-EXPLORT-paygo`,`azure-CO-standard-paygo`,azure-CO-Premium-paygo`,`azure-paygo`]HA の場合 : [`azure-HA-COT -standard-paygo`, azure-HA-COT -Premium-paygo`, azure-HA-COT -Premium-BYOL `, HA-capacity-paygo`]デフォルトは「 azure-CO-standard-paygo 」です。「 Capacity-paygo 」または「 HA-Capacity-paygo 」を使用して、「 Bring Your Own License Type Capacity Based 」または「 Freemium 」を選択します。「 Bring Your Own License Type Node-Based 」を選択した場合は、「 azure-CO-Premium-BYOL 」または「 azure-HA-CO-Premium-BYOL 」を使用します。</block>
  <block id="5e952a0432dfc8995121e15b76aa554a" category="cell">* AZ_CVF_NSS_ACCOUNT *</block>
  <block id="c3ae78309504c231f8afd5bc3790d119" category="cell">（必須）この Cloud Volumes ONTAP システムで使用するネットアップサポートサイトのアカウント ID 。ライセンスタイプが BYOL で、 NSS アカウントが指定されていない場合、 Cloud Manager は最初の既存の NSS アカウントの使用を試みます。</block>
  <block id="e7e63db47174977525dadf7a52fc6b39" category="cell">* AZ_tenant_id *</block>
  <block id="66093475775d81b74da52f4377ff5ce5" category="cell">（必須） Azure に登録されているアプリケーション / サービスプリンシパルのテナント ID 。</block>
  <block id="7934d010494793aec0f365d710cdf720" category="cell">* AZ_application_id *</block>
  <block id="587bfaa720a64e832c9eef635797e8d8" category="cell">（必須） Azure に登録されているアプリケーション / サービスプリンシパルのアプリケーション ID 。</block>
  <block id="67830019a9948cfd51759684b5f8a262" category="cell">* AZ_application_key *</block>
  <block id="56d6515673e3c08156696c47a943c020" category="cell">（必須） Azure に登録されているアプリケーション / サービスプリンシパルのアプリケーションキー。</block>
  <block id="522a4529185faee9fa34a9398ab7263f" category="list-text">変数 \azure_CVF_HA_deployment.tfvars の変数を更新します。</block>
  <block id="e2da3e968f76091801635ce624569dcb" category="paragraph">HA ペア・インスタンス</block>
  <block id="86ed32721429fbcc7b5e123836e3ebcd" category="paragraph">HA ペアの Cloud Volumes ONTAP （ CVO ）の変数は Terraform です。</block>
  <block id="72170ff3a9ca936d7855297f0bbd1eeb" category="cell">（必須）選択したライセンスタイプに応じて使用するインスタンスのタイプ。 Explore ： [`Standard_DS3_v2'Standard ： [`Standard_DS4_v2'Standard_DS13_v2'Standard_L8s_v2'Premium ： [`Standard_DS5_v2', 'Standard_DS14_v2''BYOL ： PAYGO 用に定義されたすべてのインスタンス・タイプサポートされるインスタンスタイプの詳細については、 Cloud Volumes ONTAP リリースノートを参照してください。デフォルトは 'Standard_DS4_v2' です</block>
  <block id="b515d8e49b6ef626aa91dbd970708132" category="cell">（必須）使用するライセンスのタイプ。シングルノードの場合： [`azure-CO-EXPLOR-paygo, azure-CO-standard-paygo, azure-CO-Premium-pole-BYOL 、 capacity-paygo`]HA の場合： [`azure-HA-COT-standard-paygo, azure-HA-CO-Premium-paygo, azure-HA-CO-Premium-BYOL 、 HA-capacity-paygo`]デフォルトは「 azure-CO-standard-paygo 」です。「 Capacity-paygo 」または「 HA-Capacity-paygo 」を使用して、「 Bring Your Own License Type Capacity Based 」または「 Freemium 」を選択します。「 Bring Your Own License Type Node-Based 」を選択した場合は、「 azure-CO-Premium-BYOL 」または「 azure-HA-CO-Premium-BYOL 」を使用します。</block>
  <block id="728aafab2377ad85ce4ae3f6a4b3dd33" category="cell">（必須）インスタンスのセキュリティグループの ID 。複数のセキュリティグループをで区切って指定できます。</block>
  <block id="fbd9a83d6df239351ac0498cbaa58065" category="paragraph">この解決策 では、 Terraform モジュールを使用して、 AWS （ CVO シングルノード、 CVO HA 、 FSX ONTAP ）および Azure （ CVO シングルノード、 CVO HA 、 ANF ）への Cloud Volume の自動導入を文書化しています。コードは、から入手できます<block ref="d07ec9f91b2ccc52b0d628a1b144c1d8" category="inline-link-rx"></block></block>
  <block id="0db20ddc31a427cc02802395aa53db7f" category="cell">（必須）容量プールサイズ（ TB ）。</block>
  <block id="c47acd947f63c78f7729c5c176778d53" category="paragraph">データ保護が有効になっている単一の ANF ボリューム用の変数を Terraform します。</block>
  <block id="ca7ce11916c29a2c94b4fd33dc0b6313" category="paragraph">このセクションでは、 Azure 上にシングルノード CVO （ Cloud Volumes ONTAP ）を導入 / 構成するための各種 Terraform 構成ファイルを紹介します。</block>
  <block id="7bd8d7a58d3957cf7697ceb3467bffae" category="cell">（必須）作業環境を作成する場所。</block>
  <block id="a5ab436e757f5af2106d5ed5e5dd9df0" category="cell">（必須） Cloud Volumes ONTAP システムのサブネットの名前。</block>
  <block id="353190ef77d18ad13aeb6b4f0f3ddd66" category="paragraph">このセクションでは、 Azure 上で CVO （ Cloud Volumes ONTAP ） HA （ハイアベイラビリティ）を導入 / 構成するためのさまざまな Terraform 構成ファイルを取り上げます。</block>
  <block id="3adefdd7d79d9a7c848b2dd81fd4feff" category="paragraph">このセクションでは、 GCP （ Google Cloud Platform ）でシングルノードの NetApp CVO （ Cloud Volumes ONTAP ）を導入 / 構成するための、さまざまな Terraform 構成ファイルについて説明します。</block>
  <block id="b05dddcb6f00ee8dba8395d241b9d24d" category="list-text">GCP 認証キー JSON ファイルをディレクトリに保存します。</block>
  <block id="44b4381353a1686f5b81f73f018d336c" category="list-text">変数 /GCP_CVP_SILE_Node_deployment.tfvar' の変数値を更新します</block>
  <block id="2ac544064187c52d64d3eec81700dd42" category="admonition">変数「 gCP_Connector_deploy_bool 」の値を「 true 」または「 false 」に設定することで、コネクタの配置を選択できます。</block>
  <block id="283162995c6eba560352663fa7cafbb3" category="paragraph">NetApp GCP Connector インスタンスの CVO 導入用の Terraform 変数。</block>
  <block id="c0b4a62bb4903159c66ef5fd828dbb35" category="cell">* gCP_Connector_deploy_bool *</block>
  <block id="3448a02a5105e0eeb2a6243836814f36" category="cell">* GCP_Connector_name *</block>
  <block id="982137a628765a4ede6a620653ab8bf6" category="cell">* gCP_Connector_project_id *</block>
  <block id="816194da363b92545a1114d46c4943f1" category="cell">（必須）コネクタを作成する GCP PROJECT_ID 。</block>
  <block id="49a94de7b7e8762f961e471d657496eb" category="cell">* gCP_Connector_zone *</block>
  <block id="ff9633a62f1e60af63fc951afd6966bc" category="cell">（必須）コネクタを作成する GCP ゾーン。</block>
  <block id="c667eb31817317b5455e6a8883f4664a" category="cell">* gp_connector_company*</block>
  <block id="9d1203849926481ebb6be1fb1d6ec3de" category="cell">* gCP_Connector_service_account_email*</block>
  <block id="d4a302e18b412231fe06e54e038aed80" category="cell">（必須） Connector インスタンスの SERVICE_ACCOUNT の電子メール。このサービスアカウントは、コネクタによるクラウドボリューム ONTAP の作成を許可するために使用されます。</block>
  <block id="0e3852268e0e5a3a486b8fcf6e3ae1c1" category="cell">* gCP_Connector_service_account_path *</block>
  <block id="f863e677d176e63d3642e53ae6b336b5" category="cell">（必須） GCP 認証に使用する service_account JSON ファイルのローカルパス。このサービスアカウントは、 GCP でコネクタを作成するために使用します。</block>
  <block id="cfd7e4961aa34c5626712429d469ed18" category="cell">* gCP_Connector_account_id *</block>
  <block id="231d57c65fc42941f6a520976dc80ec3" category="cell">（オプション）コネクタを関連付けるネットアップアカウントの ID 。指定しない場合、 Cloud Manager は最初のアカウントを使用します。アカウントが存在しない場合、 Cloud Manager は新しいアカウントを作成します。アカウント ID は、 Cloud Manager のアカウントタブにあります<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>。</block>
  <block id="9ea10c86ddbbfa93db9af98d0a38e7d7" category="paragraph">GCP 上の単一の NetApp CVO インスタンスの Terraform 変数。</block>
  <block id="9d8a021dcdac02b1cffc5ee14bc79241" category="cell">* GCP_CVO-NAME *</block>
  <block id="bc023aad2be985e1a3252a959cb2c43b" category="cell">* GCP_CVO-PROJECT_ID *</block>
  <block id="c7a61709c9cf6aa90f854f8e30110412" category="cell">（必須） GCP プロジェクトの ID 。</block>
  <block id="6f74a6834cfd9c72b6694ae9ecb7f332" category="cell">* GCP_CVP_ZONE *</block>
  <block id="dea2d3525e8ec98bbd9a7931a8ed9921" category="cell">（必須）作業環境を作成するリージョンのゾーン。</block>
  <block id="2c09e34e29e9c5f65d5d8ac921fd8105" category="cell">* GCP_CVP_GCP_SERVICE_ACCOUNT *</block>
  <block id="77853ddcc7178537c8d9c0301b71c991" category="cell">（必須）コールドデータを Google Cloud Storage に階層化できるようにするための、 GCP_SERVICE_ACCOUNT 電子メール。</block>
  <block id="ffb5588c947a413a01016a81af9ddbc7" category="cell">* GCP_CVO-svm_svm_password* をクリックします</block>
  <block id="9507c3b760db1c7e6c8d1674933449e4" category="cell">* GCP_CVP_Workspace_id *</block>
  <block id="4efb152d95f2b6b19ca1387a26e8f750" category="cell">（オプション） Cloud Volumes ONTAP を導入する Cloud Manager ワークスペースの ID 。指定しない場合、 Cloud Manager は最初のワークスペースを使用します。ID は、の [ ワークスペース（ Workspace ） ] タブで確認できます<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>。</block>
  <block id="7cbf1746ddada50a540811a75b633bfa" category="cell">* GCP_CVP_LICENSE_TYPE *</block>
  <block id="108ccbda23ae580baf5fb86c14613837" category="cell">（任意）使用するライセンスのタイプ。シングルノードの場合： [ 容量 - 給与 ] 、 [ GCP - COT - EXPLORTe-paygo ] 、 [GCP - COT - standard-paygo] 、 [GCP - COT - Premium-paygo] 、 [GCP - COT - Premium-BYOL ] 、 HA の場合： [ HA キャパシティ - ペイゴー ] 、 [ GCP - HA - ベッド - 探検 - ペイゴー ] 、 [GCP - HA - ベビーベッド - スタンダード - ペイゴー ] 、 [GCP - HA - ベビーベッド - プレミアム - ペイゴー ] 、 [GCP - HA - ベビーベッド - プレミアム - BYOL ] 。デフォルトは、単一ノードの場合は「 capacity-paygo 」、 HA の場合は「 ha-capacity-paygo 」です。</block>
  <block id="ec6c16de8b82f3fc6c55f03f1d9a0848" category="cell">* GCP_CVP_capacity package_name *</block>
  <block id="564565c1364213fe3ffcef055b61947b" category="cell">（オプション）容量パッケージの名前： ['Essential','Professional','Freemium'] 。デフォルトは「 Essential 」です。</block>
  <block id="ac245610a2b7e434b78946f9ab069afe" category="paragraph">このセクションでは、 GCP （ Google Cloud Platform ）のハイアベイラビリティペアで NetApp CVO （ Cloud Volumes ONTAP ）を導入 / 構成するための、さまざまな Terraform 構成ファイルについて説明します。</block>
  <block id="00c7a940cc525046dc63cee112a8ef2d" category="list-text">変数 /GCP_CVP_HA_deployment.tfvars の変数値を更新します。</block>
  <block id="657426021b9624d6c24fae901c9998c1" category="paragraph">GCP の HA ペアの NetApp CVO インスタンスの Terraform 変数。</block>
  <block id="2a20062f50c253ff821e16ab60e9bd71" category="cell">* GCP_CVP_is_HA *</block>
  <block id="c7d1d567eb3eec5faac1c3efbf5c63d6" category="cell">* GCP_CVP_node1 _ZONE *</block>
  <block id="2cb70db8c1982b17ac705ceace5b64ae" category="cell">（オプション）ノード 1 のゾーン。</block>
  <block id="b231cdca0a533a8afcbf95810dcdd937" category="cell">* GCP_CVP_node2 _ZONE *</block>
  <block id="2aad8f424dde09a3fb42570367a156de" category="cell">（オプション）ノード 2 のゾーン。</block>
  <block id="7dd3bb55d8d71efcb06fc86bbb29993a" category="cell">* GCP_CVP_mediator_zone *</block>
  <block id="767c5594dfa391fbb74bd9360557a0a8" category="cell">（オプション）メディエーター用のゾーン。</block>
  <block id="4ecd0da4e352bb336bd4c5925e627fbb" category="cell">* GCP_CVP_vPC_id *</block>
  <block id="0a49d29112682612dc74e881a68deed0" category="cell">（オプション） VPC の名前。</block>
  <block id="eedae790807f6f5998c1d5b2eccfcf91" category="cell">* GCP_CVP_subnet_id *</block>
  <block id="dbb13624053bb884443eb3a8a891a35e" category="cell">（オプション） Cloud Volumes ONTAP のサブネットの名前。デフォルトは「 default 」です。</block>
  <block id="5fbbd2383d042b5ab01878b936e467ff" category="cell">* GCP_CVP_vpc0_Node_or_data_connectivity*</block>
  <block id="24239aec58a00d53d32147d2e71cca4d" category="cell">（オプション） NIC 1 の VPC パス。ノードとデータの接続に必要です。共有 VPC を使用する場合は、 netwrok_project_id を指定する必要があります。</block>
  <block id="b1dd5e2b134fc3db50406e05c7ae6c38" category="cell">* GCP_CVP_vpc1_cluster_connectivity*</block>
  <block id="714e5d0cdfde4cbf4df83df266c672e7" category="cell">（オプション） NIC 2 の VPC パス。クラスタ接続に必要です。</block>
  <block id="f8d315b03e4b926495b923dfe4b49b23" category="cell">* GCP_CVP_vpc2_HA_Connectivity *</block>
  <block id="5c144c2c76f5d988024f4d7398060d71" category="cell">（オプション） HA 接続に必要な NIC 3 の VPC パス。</block>
  <block id="1366961106ddc181e83c467cf5559a14" category="cell">* GCP_CVP_vpc3_data_replication *</block>
  <block id="b4be5ce15bf4e51acd3167c47e79955f" category="cell">（オプション）データレプリケーションに必要な NIC4 の VPC パス。</block>
  <block id="065308400ba1fac48f2ca62781d79dff" category="cell">* GCP_CVP_SUBnet0_Node_or_data_connectivity*</block>
  <block id="2a33bb449fd47fa1f379b60f3e1473ca" category="cell">（任意）ノードおよびデータ接続に必要な NIC1 のサブネットパス。共有 VPC を使用する場合は、 netwrok_project_id を指定する必要があります。</block>
  <block id="da8a35439720c0bc705f001b954bd61e" category="cell">* GCP_CVP_SUBnet1_cluster_connectivity*</block>
  <block id="01b515c3b8d74ae94df6572b47a3f06d" category="cell">（オプション）クラスタ接続に必要な NIC 2 のサブネット・パス</block>
  <block id="7ea43f4ca8d2a868f20df11b9e0b39b2" category="cell">* GCP_CVP_SUBnet2_HA_connectivity *</block>
  <block id="a35bd275122015b3834d13c0dc72b87f" category="cell">（任意） HA 接続に必要な NIC 3 のサブネットパス。</block>
  <block id="16c5273854a933d221200af8f06d106a" category="cell">* GCP_CVP_SUBnet3_data_replication *</block>
  <block id="b36fab455a4e11803791a090935906af" category="cell">（任意）データ複製に必要な NIC4 のサブネット・パス</block>
  <block id="e69179170f564daf56d8694c1c5d35fe" category="cell">* GCP_CVP_GCP_volume_size *</block>
  <block id="eb01714b284e762b9c44adfa5575690c" category="cell">（オプション）最初のデータアグリゲートの GCP ボリュームサイズ。GB の場合、単位は [100 または 500] です。TB の場合、単位は [1,2,4,8] です。デフォルトは「 1 」です。</block>
  <block id="4c767d9b6ddddf4abeaece5590c0b101" category="cell">* GCP_CVP_GCP_volume_size_unit *</block>
  <block id="944ce323a5a1ffb09543fd409911cc88" category="open-title">CVS ボリューム</block>
  <block id="ffcc65b297748299934a184d39035ae4" category="paragraph">このセクションでは、 GCP （ Google Cloud Platform ）で NetApp CVS （ Cloud Volume サービス）ボリュームを導入 / 設定するためのさまざまな Terraform 設定ファイルについて説明します。</block>
  <block id="732c3eabba1449281a4fddb59dbddcac" category="paragraph">Terraform ドキュメント :<block ref="35b7d5c9a11899e5d5e07079551e8cef" category="inline-link-rx"></block></block>
  <block id="d203294ba4c28418657d90a7f8a7510d" category="list-text">変数 /gcp_cvs_volume_.tfvars の変数値を更新します</block>
  <block id="40686c9084c59387baf48000dd09e6ab" category="paragraph">「 CVS ボリューム」</block>
  <block id="3efdf9b0e7f4af483444f271367d6361" category="paragraph">NetApp GCP CVS ボリュームの Terraform 変数。</block>
  <block id="0ffdc0b2b4889601b216ab5087650d46" category="cell">* gcp_cvs_name *</block>
  <block id="8ff48dd93ed73eb9adc26090e58ed80b" category="cell">（必須） NetApp CVS ボリュームの名前。</block>
  <block id="b6759cef3cfc5890deb6a790f73c8b79" category="cell">* gcp_cvs_project_id *</block>
  <block id="b0257576709acc899b5376a171c3cd98" category="cell">（必須） CVS ボリュームを作成する GCP project_id 。</block>
  <block id="447b0e81ae249b907128b7ea83e045c5" category="cell">* gcp_cvs_gcp_service_account_path *</block>
  <block id="820ecb1b7a653c1e2dece0176d15eaed" category="cell">（必須） GCP 認証に使用する service_account JSON ファイルのローカルパス。このサービスアカウントは、 GCP で CVS ボリュームを作成するために使用します。</block>
  <block id="6cb8bdefdf91cd2d80f6d9849de25fb8" category="cell">* gcp_cvs_region *</block>
  <block id="ec9461de174e3ad866c58b577c94034b" category="cell">（必須） CVS ボリュームを作成する GCP ゾーン。</block>
  <block id="fc944aa114b94de895d84f5375000c0b" category="cell">* gcp_cvs_network *</block>
  <block id="23a1cb77eeeabfd36bbab18e5de9f0dc" category="cell">（必須）ボリュームのネットワーク VPC 。</block>
  <block id="31681a1878caf611cea11e159a4fc1aa" category="cell">* gcp_cvs_size *</block>
  <block id="6f84d4d0c83121512056657a2dc0e808" category="cell">（必須）ボリュームのサイズは、 1024~102400 で（ GiB 単位）。</block>
  <block id="5c1eb3efe4738cb21efadc992aeeef81" category="cell">* gcp_cvs_volume_path *</block>
  <block id="bacdc6093d23e2f886b0cb0609418030" category="cell">（オプション）ボリュームのボリュームパスの名前。</block>
  <block id="0467ee670bdb8fff57da77368d6d5385" category="cell">* gcp_cvs_protocol_types *</block>
  <block id="b91db1bd1a57ea4c9953036d82a63e95" category="cell">（必須）ボリュームの protocol_type 。NFS の場合は「 NFSv3 」または「 NFSv4 」を、 SMB の場合は「 CIFS 」または「 MB 」を使用します。</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">NetApp Interoperability Matrix Tool で確認できます</block>
  <block id="1479ddf58c038ab7d220ff734c74deaf" category="list-text">に記載されている NFS v4.1 と相互運用性に関する表の注を参照してください<block ref="8813559f5b95abb5411182be29200aff" category="inline-link-rx"></block> をサポートするには、特定の ESXi パッチレベルが必要です。</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">HTTPS 接続 - HTTPS 経由の SOAP 接続に使用する VP および SRA</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">ONTAP クラスタへの接続に使用します</block>
  <block id="6f3666cf392f9aa79924b94f433b64ed" category="doc">NetApp SnapCenter Plug-in for VMware vSphere - VMware への導入</block>
  <block id="a1dd31a3dca44eb1fe27b895521130ae" category="inline-link-macro">次のセクション：「追加情報 - SnapCenter Plug-in for VMware vSphere - 解決策 Prerequisites 」</block>
  <block id="874d68c7d23e9e2e452ff6efaf757dee" category="paragraph"><block ref="874d68c7d23e9e2e452ff6efaf757dee" category="inline-link-macro-rx"></block></block>
  <block id="7dcf4233280fcc0e80d2c5b8ce82af91" category="paragraph">NetApp SnapCenter ソフトウェアは、使いやすいエンタープライズプラットフォームで、アプリケーション、データベース、ファイルシステム全体でデータ保護をセキュアに調整、管理できます。</block>
  <block id="7dc8c97b0d6d3055290baa0eb36dbfa5" category="paragraph">SnapCenter Plug-in for VMware vSphere を使用 SnapCenter すると、 VMware vCenter に直接登録されている VM とデータストアのバックアップ、リストア、および接続処理を実行し、バックアップおよびマウント処理を実行できます。</block>
  <block id="00389b40803806e30e1877e1a0469e22" category="inline-link">NetApp SnapCenter Plug-in for VMware vSphere の概要</block>
  <block id="10408567d24e2dd65731b1e2f0508a5d" category="doc">VMware vSphere 用のネットアップ SnapCenter プラグインの前提条件 - 解決策 の必要条件</block>
  <block id="0a70bb0111bccb302f68cc327b0527f8" category="inline-link-macro">前のバージョン：追加情報 - SnapCenter Plug-in for VMware vSphere - 導入。</block>
  <block id="dc69c4899210bca949880d9753e92b35" category="paragraph"><block ref="dc69c4899210bca949880d9753e92b35" category="inline-link-macro-rx"></block></block>
  <block id="8eaab69b7b060fb16ac9ba9484edb36e" category="inline-link-macro">次の手順：追加情報 - SnapCenter Plug-in for VMware vSphere - バックアップワークフロー</block>
  <block id="4602e4aeb078cfce115f5bcaf3d65ba7" category="paragraph"><block ref="4602e4aeb078cfce115f5bcaf3d65ba7" category="inline-link-macro-rx"></block></block>
  <block id="d3b0a496a8cf35e38aa2e2195dec2f94" category="doc">NetApp SnapCenter Plug-in for VMware vSphere - リストアワークフロー</block>
  <block id="e7f47d4d003703cc37a3f472bf362522" category="doc">NetApp SnapCenter Plug-in for VMware vSphere - バックアップワークフロー</block>
  <block id="b80c59ad5be93a14a5e884c9617272bd" category="inline-link-macro">前のリリース： VMware vSphere 向け追加情報 SnapCenter プラグイン - 解決策 の前提条件</block>
  <block id="b8c179b73c48ccf857c179c753fc7866" category="paragraph"><block ref="b8c179b73c48ccf857c179c753fc7866" category="inline-link-macro-rx"></block></block>
  <block id="7889fbe4fe01425f9ecdef9442f812b8" category="inline-link-macro">次の手順：追加情報 - SnapCenter Plug-in for VMware vSphere - リストアワークフロー</block>
  <block id="907647e9678147c153e1b1f855122048" category="paragraph"><block ref="907647e9678147c153e1b1f855122048" category="inline-link-macro-rx"></block></block>
  <block id="3e23a542d0c1cb3dc87ca41f7ec8dc9c" category="doc">NetApp SnapCenter Plug-in for VMware vSphere - SQL Server のリストアワークフロー</block>
  <block id="d16efdedacbd64c8b85d50f0b58e4c60" category="inline-link-macro">前のバージョン：追加情報 ： SnapCenter Plug-in for VMware vSphere - リストアワークフロー</block>
  <block id="553f0bde4f032f393b8659c8440bae26" category="paragraph"><block ref="553f0bde4f032f393b8659c8440bae26" category="inline-link-macro-rx"></block></block>
  <block id="eee0a010c96cd5f8a48024b64979138a" category="inline-link-macro">前のバージョン：追加情報 - SnapCenter Plug-in for VMware vSphere - バックアップワークフロー</block>
  <block id="db5a03b9e1de0d20dc54468940b207eb" category="paragraph"><block ref="db5a03b9e1de0d20dc54468940b207eb" category="inline-link-macro-rx"></block></block>
  <block id="5f01983db70d04ee21145e7d21902fb2" category="inline-link-macro">次の手順：追加情報 - SnapCenter Plug-in for VMware vSphere - SQL リストアワークフロー</block>
  <block id="724a2f2542f99df4a44d9ad7cfb15363" category="paragraph"><block ref="724a2f2542f99df4a44d9ad7cfb15363" category="inline-link-macro-rx"></block></block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">方向（ Direction ）</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">インバウンド</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083 年</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">内部のみ</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">双方向</block>
  <block id="d56302f459af314c7996db681d5b4696" category="cell">2022年3月29日</block>
  <block id="ee0b2b1b7d5e8eb309b29d0051f84d0c" category="cell">新しいTR『DevOps with NetApp Astra』を追加</block>
  <block id="a32ca451a300bb4e3c6b19cb1592126a" category="inline-link-macro">ネットアップAstraを使用したDevOps</block>
  <block id="cb6bb56e7a1df42aff4aeae660a2df10" category="cell"><block ref="cb6bb56e7a1df42aff4aeae660a2df10" category="inline-link-macro-rx"></block></block>
  <block id="73677e8d319e77c91f647e668e868ecb" category="paragraph">詳細については、OpenShiftのWebサイトを参照してください<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>。</block>
  <block id="f582083d849d313b57029bcb7e14f0b5" category="paragraph">詳細については、ネットアップのWebサイトを参照してください<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>。</block>
  <block id="8fe0ec287a8d48a38a4f1454d62282f5" category="paragraph">NetApp Astra Control Centerは、オンプレミス環境に導入され、信頼性の高いネットアップのデータ保護テクノロジを基盤とするステートフルKubernetesワークロード向けに、豊富なストレージサービスとアプリケーション対応データ管理サービスを提供します。</block>
  <block id="54fe0fc00087535e613994102131f164" category="paragraph">Astra Tridentは、コンテナやKubernetesディストリビューション向けの、完全にサポートされているオープンソースのストレージオーケストレーションツールです。｛k8s_distribution_name｝などが挙げられます。</block>
  <block id="8f98c507505a202b216bb930f143954d" category="paragraph">ネットアップには、Astra TridentとAstra Controlで認定された複数のストレージプラットフォームがあり、コンテナ化されたアプリケーションのデータをプロビジョニング、保護、管理できます。</block>
  <block id="1268e1be2d69bcbe60fed1b018c4c7be" category="list-text">NetApp Element ストレージシステムは、拡張性に優れた環境におけるブロックベース（iSCSI）のユースケースを対象としています。</block>
  <block id="c64f419c58469b610f6840042d2d188c" category="admonition">ネットアップのポートフォリオに含まれる各ストレージシステムでは、データ管理とオンプレミスサイトとクラウド間の移動の両方を容易に行えるため、データはアプリケーションの配置場所になります。</block>
  <block id="8d866fd138999801041cd8ebf044c39f" category="paragraph">次のページでは、｛solution _name｝解決策 で検証されたネットアップストレージシステムに関する追加情報 を使用しています。</block>
  <block id="31190025c7f2a3470ada77c7c360ad75" category="list-text"><block ref="31190025c7f2a3470ada77c7c360ad75" category="inline-link-macro-rx"></block></block>
  <block id="15155104ed4dffb0c6f48a716c490eb6" category="list-text"><block ref="15155104ed4dffb0c6f48a716c490eb6" category="inline-link-macro-rx"></block></block>
  <block id="8bd43c9f55116966ac61fd08aa3cd4bf" category="list-text">パブリッククラウドとのシームレスな統合により、データの階層化と保護を実現ONTAP は、あらゆる環境に対応する堅牢なデータ保護機能も備えています。</block>
  <block id="d06c8b79097ede1a26446d68bec0ca39" category="paragraph">ONTAP の詳細については、を参照してください<block ref="b961dc88c1ac3ab8c78f9fff5ef05edb" category="inline-link-rx"></block>。</block>
  <block id="a95908309fdc4765216365a8dc7d2561" category="paragraph">どちらのシステムも、NetApp ONTAP データ管理ソフトウェアを搭載しています。NetAppは、シンプルで可用性の高いクラウド統合ストレージ管理を実現する業界最先端のデータ管理ソフトウェアで、データファブリックのニーズに合わせてエンタープライズクラスのスピード、効率性、セキュリティを提供します。</block>
  <block id="158de41b0c768154e1c26d384097971b" category="paragraph">ONTAP Select は、お客様の環境のハイパーバイザーに導入できる、ソフトウェアで定義された NetApp ONTAP の導入です。VMware vSphereまたはKVMにインストールでき、ハードウェアベースのONTAP システムの全機能とエクスペリエンスを提供します。</block>
  <block id="87517df6852cb879fffc1e5811e773eb" category="paragraph">ネットアップは、ステートフルなコンテナ化アプリケーションとそのデータのオーケストレーション、管理、保護、移行を支援するための製品を多数提供しています。</block>
  <block id="a4d4eca64bc27dfd5dc959bc05745797" category="paragraph"><block ref="a4d4eca64bc27dfd5dc959bc05745797" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c60042e38b748289146bd910731af5f0" category="paragraph">NetApp Astra Controlは、ネットアップのデータ保護テクノロジを基盤とするステートフルKubernetesワークロード向けに、充実したストレージサービスとアプリケーション対応データ管理サービスを提供します。Astra Control Service は、クラウドネイティブの Kubernetes 環境でステートフルワークロードをサポートするために利用できます。Astra Control Centerは、｛k8s_distribution_name｝などのエンタープライズKubernetesプラットフォームをオンプレミスで導入する場合に、ステートフルワークロードをサポートするために使用できます。詳細については、 NetApp Astra Control の Web サイトをご覧ください<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>。</block>
  <block id="40de36ed0c5ebc385749ac6095c24949" category="paragraph">NetApp Astra Tridentは、コンテナ向けのオープンソースで完全にサポートされているストレージオーケストレーションツールであり、｛k8s_distribution_name｝などのKubernetesディストリビューションに対応しています。詳細については、 Astra Trident の Web サイトをご覧ください<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>。</block>
  <block id="ccbb3765ebd50818c2e13a7aba362360" category="paragraph">次のページには、｛solution _name｝解決策 でアプリケーションおよび永続的ストレージの管理用に検証されたネットアップ製品に関する追加情報 があります。</block>
  <block id="9dc16d6a3e39a8a9654ccfa622d163cf" category="list-text"><block ref="9dc16d6a3e39a8a9654ccfa622d163cf" category="inline-link-macro-rx"></block></block>
  <block id="65b4726a91c7e38728e01572140c82b3" category="list-text"><block ref="65b4726a91c7e38728e01572140c82b3" category="inline-link-macro-rx"></block></block>
  <block id="61e8a38bc32bac1a07ee434aa2849ff7" category="paragraph">NetApp Astra Control Centerは、Astra Tridentストレージオーケストレーションツールを導入して、NetApp ONTAP ストレージシステムにストレージクラスとストレージバックエンドで構成されている｛k8s_distribution_name｝クラスタにインストールできます。</block>
  <block id="ca272f711326de89f484505d0ad670ab" category="paragraph">Astra Tridentの詳細については、を参照してください <block ref="fdebacf9b174a956e59f11468f6dd03c" category="inline-link-macro-rx"></block>。</block>
  <block id="c46717c86eab6ada72e202311e47bf46" category="paragraph">クラウド接続環境では、 Cloud Insights を使用して高度なモニタリングとテレメトリを提供します。Cloud Insights 接続がない場合は、限定的な監視と計測（7日間の指標）を使用でき、オープン指標エンドポイントを介してKubernetesの標準の監視ツール（PrometheusとGrafana）にエクスポートされます。</block>
  <block id="b5348ca8ff6fec2e5b760e7176813e60" category="paragraph">Astra Control Center の有料版に加え、 90 日間の評価ライセンスも提供されています。評価版は、EメールとSlackコミュニティチャネルを通じてサポートされます。お客様は、これらのリソース、その他のナレッジベース記事、および製品サポートダッシュボードから入手できるドキュメントにアクセスできます。</block>
  <block id="8b05a70d35504af755eb73a78fd137f0" category="paragraph">Astraポートフォリオの詳細については、を参照してください <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>。</block>
  <block id="82c67e38528d52fd46de6b6ba7370337" category="paragraph">Astra Tridentは、迅速な開発サイクルを実現し、Kubernetesと同様、年間4回リリースされます。</block>
  <block id="ed42e52f359216f47260ed1d21ef331c" category="paragraph">20.04 リリース以降、 Trident のセットアップは Trident オペレータによって実行されます。オペレータが大規模な導入を容易にし、Tridentのインストールの一部として導入されるポッドの自己修復などの追加サポートを提供します。</block>
  <block id="ef55276f0238c6b1a3f893bc026b5644" category="summary">ネットアップコンテナソリューションは、Kubernetesベースの人気の高いコンテナオーケストレーションツールの多くを検証済みで導入し、ネットアップのストレージ管理システムやソフトウェアと統合します。</block>
  <block id="d56bc5e4affc2f557b7bb79afe47b1be" category="doc">ネットアップのコンテナソリューション</block>
  <block id="6fd40b989d7667b2025880aec23fdf21" category="paragraph">このリファレンスガイドでは、ネットアップによって検証済みの、さまざまなデータセンター環境におけるGoogle CloudのAnthosの導入を検証します。また、ネットアップストレージシステムとのストレージ統合についても、永続的ストレージの管理には Astra Trident ストレージオーケストレーションツールを、ステートフルアプリケーションの管理と保護には NetApp Astra Control Center を活用して詳しく説明しています。最後に、解決策検証と実際の使用事例をいくつか確認して文書化します。</block>
  <block id="7768400c23564e6141f156e229944614" category="summary">Anthosは、開発とITの運用を単一プラットフォーム上に統合することで、オンプレミスとハイブリッドクラウドのインフラにわたってアプリケーションを一貫した方法で構築、導入、管理します。Anthosは、GKE Kubernetesクラスタを仮想またはベアメタルフォーマットでデータセンター環境に直接導入します。</block>
  <block id="346f4310b75e0cc51fdf8a1db6149978" category="doc">Anthosの概要</block>
  <block id="89ef90a5be38c2b656627392eee1a2a9" category="paragraph">ネットアップのAnthosは、信頼性に優れた信頼性の高い方法でオンプレミスのGoogle Kubernetes Engine（GKE）環境を導入するための、検証済みのベストプラクティスに基づくハイブリッドクラウドアーキテクチャです。このNetApp Verified Architectureリファレンスドキュメントは、NetApp解決策 をベアメタル環境と仮想環境に導入した場合のAnthosの設計ガイドと導入検証の両方を対象としています。本ドキュメントで説明しているアーキテクチャは、ネットアップとGoogle Cloudのエキスパートによる検証を受けたもので、エンタープライズデータセンター環境でAnthosを実行するメリットを提供します。</block>
  <block id="72efb373513d77a08aa5dd7e375a418f" category="section-title">Anthos の場合</block>
  <block id="5b1a0b45a2d6518143a0c9b299e736b4" category="paragraph">Anthosは、Kubernetesを使用したハイブリッドクラウド対応データセンター解決策 です。最新のハイブリッドクラウドインフラを構築、管理しつつ、アプリケーション開発に重点を置いた即応性に優れたワークフローを採用できます。オープンソーステクノロジを基盤とした解決策を基盤とする Anthos は、 VMware vSphere ベースのインフラにオンプレミスで稼働し、 Google Cloud の Anthos GKE との接続と相互運用が可能です。コンテナ、サービスメッシュ、その他の変革テクノロジを採用することで、ローカルおよびクラウドベースの環境で一貫したアプリケーション開発サイクルと本番環境対応のワークロードを体験できるようになります。次の図は、 Anthos 解決策と、オンプレミスのデータセンターに導入し、クラウドのインフラと相互接続する方法を示しています。</block>
  <block id="42fc2dc2813b6a8c6bbca7ebe6d3f51e" category="paragraph">Anthos の詳細については、 Anthos の Web サイトを参照してください<block ref="bcfc39c80df16a8beb60f78ea034be9d" category="inline-link-rx"></block>。</block>
  <block id="ed4b514e0a9558c7acbec81ecc5fe0e1" category="list-text">* Google Cloud Marketplace for Kubernetes Applications 。 * キュレーションされたコンテナアプリケーションのカタログを利用して、簡単に導入できます。</block>
  <block id="b2f70465e1ea6dcdc0843dc8ed3b7f55" category="list-text">* Anthos * に移行。オンプレミスからクラウドへの物理サービスと VM の自動移行を実現します。</block>
  <block id="52bc26b321a0b4cd1f91f7961a0783c8" category="list-text">*Stackdriver. * クラウド・インスタンスのロギングと監視のために Google が提供する管理サービス。</block>
  <block id="9d1fde4a5ff757f9279ca3b948ce8cb2" category="paragraph"><block ref="9d1fde4a5ff757f9279ca3b948ce8cb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4777b2291cea091fd5877d9051ff1a3" category="section-title">Anthosの導入方法</block>
  <block id="0b7914a951055f790f36ed2e8e90bf01" category="section-title">VMware上のAnthosクラスタ</block>
  <block id="1702288bedca391f972e58fc0561e9ed" category="paragraph">VMware vSphere環境に導入されるAnthosクラスタは、ほとんどのエンドユーザ向けKubernetesワークロードの導入、保守、拡張が容易です。</block>
  <block id="6f2ed4f8e4ebad80d7a306a0dc285156" category="paragraph">ネットアップとともに導入されるVMware上のAnthosクラスタの詳細については、このページを参照してください <block ref="2f8f1280f6424b00276dc85d82fdb14f" category="inline-link-macro-rx"></block>。</block>
  <block id="45a6d5427a773bd692ba6faf09ae9200" category="paragraph">ベアメタルサーバに導入されたAnthosクラスタはハードウェアに依存しないため、お客様に合わせて最適化されたコンピューティングプラットフォームを選択できます。</block>
  <block id="00d32067724b7191cb5b0ffaf99cc3fe" category="list-text">kubectl コマンドを実行して ' ストレージ・クラスを作成します</block>
  <block id="36a95a56c85c06906ce9ed37f6c88bbe" category="list-text">'kubectl' コマンドを発行して 'PVC を作成します作成中の元のボリュームのサイズによっては作成にしばらく時間がかかることがあるため、作成が完了した時点でこのプロセスを監視できます。</block>
  <block id="f9d11737e933d637293dde1af50cc17c" category="inline-link-macro">本ドキュメント</block>
  <block id="8e6bdc78726b4f56217f2db215176c4c" category="paragraph">Astra Trident のインストールと設定を行い、 Astra Control Center をサポートするには、を参照してください <block ref="a26f48e8d5c30c46f5b177e7942c3e6b" category="inline-link-macro-rx"></block>。</block>
  <block id="5a45cefd7ffdd292bbc23212059fae63" category="paragraph">クラウド接続環境では、 Cloud Insights を使用して高度なモニタリングとテレメトリを提供します。Cloud Insights 接続がない場合は、限定的な監視と計測（7日間の指標）を使用でき、オープン指標エンドポイントを介してKubernetesの標準の監視ツール（PrometheusとGrafana）にエクスポートされます。</block>
  <block id="f7606168abf643ab18d0fa39eaf87445" category="admonition">サイトに各OpenShiftをインストールし、永続的ストレージ専用のSVMを用意することがベストプラクティスです。マルチサイト環境では、追加のストレージシステムが必要です。</block>
  <block id="cdcf8f111b01a0c0037e638c481f80b0" category="admonition">Dockerをインストールする場合は、20.10よりも前のバージョンのDockerが必要です。また、Podmanをインストールする環境には、バージョン3.0よりも前のpodmanが必要です。</block>
  <block id="bcd2576f09ac9988bca57ac067028342" category="section-title">インストール後の手順</block>
  <block id="f1712afd3ab64493ad6802bfa9e5be87" category="list-text">「acc-operator-controller-manager」ログをチェックし、インストールが完了したことを確認します。</block>
  <block id="da44b5941c7cfd27a6f5686a3168f332" category="list-text">CRDで提供された管理者メールアドレスを使用してAstra Control Center GUIに初めてログインする場合は、パスワードを変更する必要があります。</block>
  <block id="d46a5e1e10f8a4a33306d0696cef14f5" category="summary">このリファレンスガイドで解決策 は、ネットアップとエンジニアリングパートナーの検証を受け、複数のデータセンター環境に導入する場合のAnthosの導入を検証しました。</block>
  <block id="9d171bf7d3d65afb2e7e56d43b4b9ed5" category="doc">NVA-1165：ネットアップを使用したAnthos</block>
  <block id="e961a4cbc5c7e2be5e3f72a578aeb4da" category="paragraph">ネットアップ、Alan Cowles氏とNikhil Kulkarni氏</block>
  <block id="9b3053daf2ec8e22b4a577982f08f107" category="paragraph">NetApp解決策 を搭載したAnthosは、以下のユースケースでお客様に卓越した価値を提供するように設計されています。</block>
  <block id="cbc828fed325d3834b2bf3b1f2b5e639" category="inline-link">Kubevirt</block>
  <block id="341508ebeee3f32bbf4f6fee6cb456a0" category="list-text">エンタープライズコンテナと仮想化ワークロードのパワーを、vSphere上またはとベアメタル上に仮想的に導入されたAnthosで活用できます<block ref="3149dc0a8051bd1d167afbb1fe9775d9" category="inline-link-rx"></block>。</block>
  <block id="de800fedc3b1bf6c4cf497db01ca193d" category="list-text">ネットアップストレージとKubernetes向けオープンソースストレージオーケストレーションツールであるAstra Tridentとともに使用されるAnthosの特徴を強調した実際の構成とユースケース</block>
  <block id="22acab0d08b6253aa6c7d6be2fd3f4d3" category="paragraph">NetApp解決策 を搭載したAnthosは、以下の主要コンポーネントで構成されています。</block>
  <block id="c6e52ea38355d1c4527e874a4c673b5b" category="section-title">オンプレミスのAnthos</block>
  <block id="385c65f480dfcbc7cb530a2c6c807ae9" category="paragraph">オンプレミスのAnthosは、VMware vSphereハイパーバイザーや、選択したベアメタルインフラに導入可能な、完全にサポートされているエンタープライズ向けKubernetesプラットフォームです。</block>
  <block id="b73ed4ba665437210c3da7d43d6618bf" category="paragraph">Astra Tridentは、オープンソースで、Anthosを含むコンテナやKubernetesディストリビューション向けの完全にサポートされているストレージオーケストレーションツールです。</block>
  <block id="87f76f310cf20e85a098d49fa77367e5" category="cell">VMware上のAnthosクラスタ</block>
  <block id="bdca6efb043178ef172612dd1e173dde" category="cell">1.10</block>
  <block id="eb5d694ff9583283fe6d0190a39d5f7a" category="cell">6.7U3、7.0U3</block>
  <block id="5b9abd64aa4865a31820ebec932e54f2" category="section-title">Anthos Readyストレージパートナープログラム：</block>
  <block id="02046ad0e82ff27f6e1774aa588fd853" category="cell">展開タイプ</block>
  <block id="1552eec8291d257c4b855dcfa425d802" category="cell">ストレージシステム</block>
  <block id="6a5025e8000765df098a91023b66544a" category="cell">Astra Tridentバージョン</block>
  <block id="888a77f5ac0748b6c8001822417df8b6" category="cell">プロトコル</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="cell">VMware</block>
  <block id="955ddf0f7e289ee80cdea4b5324b620d" category="cell">22.01</block>
  <block id="c07ee5debf5f3a3fef16c1ee5e8e4942" category="cell">NAS</block>
  <block id="e5db66c80967b6fa50a1eede0ce50e2f" category="cell">マルチライター、ボリューム拡張、スナップショット</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="cell">SAN</block>
  <block id="4c606f506efd3b3bef3499e3342b5933" category="cell">Raw Block、Volume Expansion、Snapshot</block>
  <block id="231afe47f3f37d3808096b36c28b4ded" category="cell">要素（ Element ）</block>
  <block id="a2da3c930443e5d1421caec9ee18a376" category="cell">ベアメタル</block>
  <block id="ddffa1813009160db4406c9ef143dd1e" category="section-title">ネットアップとストレージの統合</block>
  <block id="de3b8bd79707b5ac064727a07d81d808" category="paragraph">ハードウェアに依存しないベアメタル上のAnthos機能により、お客様に合わせて最適化されたコンピューティングプラットフォームを選択でき、さらに多くのメリットがあります。</block>
  <block id="b872ec62b57abae84b75461c58e0a0a7" category="list-text">*既存のインフラストラクチャに対応したサーバを使用して、設備投資と管理コストを削減できます。</block>
  <block id="2c912ca37607e38556f15eebae425241" category="paragraph">Google Cloudは、Anthos Readyプラットフォームパートナープログラムを通じて、新しいリリースのAnthosを使用したパートナーサーバプラットフォームの更新検証を定期的に要求しています。現在検証済みのサーバプラットフォームとサポートされているAnthosのバージョンの一覧が表示されます<block ref="3b2369e07f297fb9367d6c18ca70e2ac" category="inline-link-rx"></block>。</block>
  <block id="6a655d9810c4c5ea4ab7a5520d43ca6f" category="paragraph">以下の表は、ネットアップとネットアップパートナーのエンジニアが、ベアメタル環境でのAnthosの検証にテストしたサーバプラットフォームを示しています。</block>
  <block id="c0bd7654d5b278e65f21cf4e9153fdb4" category="cell">製造元</block>
  <block id="529a05ca6c1263aab080ec4f20754411" category="cell">メーカー</block>
  <block id="7b1d1185b835814de783483f686e9825" category="cell">シスコ</block>
  <block id="21f20abdc637c3f2ef02355079dac15d" category="cell">UCS</block>
  <block id="8746d13b8a20e92a40041de84ef0df6f" category="cell">B200 M5</block>
  <block id="3cd9b23ed31110b2ebcbcc8c9a1dc8c0" category="cell">HPE</block>
  <block id="dcaa84314614529edc3d258cff7f565a" category="cell">ProLiant</block>
  <block id="76cca00a6b1e58467cea8165c904fe4f" category="cell">DL360</block>
  <block id="c5c8661ff74179fd251af29468f2ee7d" category="paragraph">次の表に、ネットアップとパートナー各社が解決策 の検証に使用してきたLinuxオペレーティングシステムをまとめます。</block>
  <block id="b8e7b465df7c5979dc731d06e84ce2cf" category="cell">リリース。</block>
  <block id="97f1ca2cfbf4529686b9719bf26e07c0" category="cell">Anthosのバージョン</block>
  <block id="6762f053abca7510f6648c71492724a7" category="cell">8/4</block>
  <block id="6a3bfb64d8c5e16ce63f46624e637b30" category="cell">18.04 LTS</block>
  <block id="d4a5ee60a5a19102b6c00749a050feaf" category="cell">20.04 LTS</block>
  <block id="26181b11798a17989dc697461dc3e9d0" category="section-title">追加のハードウェア</block>
  <block id="629f0a0ce45378aa8d3f93d405eb19cc" category="paragraph">ネットアップとパートナーのエンジニアは、検証済みの解決策 としてベアメタルにAnthosを導入するために、ネットアップとストレージ用のデータセンターコンポーネントを追加でテストしました。</block>
  <block id="9e5fa7e53550abb6c768c926e7888df7" category="paragraph">次の表に、これらの追加インフラコンポーネントに関する情報を示します。</block>
  <block id="b763f3ad097c7d9beb9849be170a627a" category="cell">Hardware Nameの略</block>
  <block id="8c692721fdfc559bf4689567aa48fb47" category="cell">Nexus社</block>
  <block id="5cb4ead83aaa15a241ef0e8c36f0678c" category="cell">C9336C-FX2</block>
  <block id="2f72e4f4112efeb63b9fb0ed1eefd1c9" category="cell">A250</block>
  <block id="8bb152d8bbc90b878b63c05b6b953334" category="section-title">追加のソフトウェア</block>
  <block id="effae9170216f08fb6cb3265a4cae9cc" category="paragraph">次の表に、検証環境に導入されているその他のソフトウェアバージョンを示します。</block>
  <block id="91c8cbe28b4928f6ea19ea8d1894623a" category="cell">ソフトウェア名</block>
  <block id="604081aa29d106416ce93ba7c42a41e3" category="cell">NXOS</block>
  <block id="55e62f54b487de5f2a89d645f80d77b4" category="cell">9.3 （ 5 ）</block>
  <block id="e0f2ed66fa5adfb40b7738ba72a899c9" category="paragraph">Anthos Readyプラットフォームの検証では、ネットアップとパートナーチームがWorld Wide Technology（WWT）を担当し、以下の図に基づいてラボ環境を構築しました。この図を参考に、サーバタイプ、オペレーティングシステム、ネットワークデバイス、 および解決策 に導入されているストレージシステム。</block>
  <block id="f8caba75d33af6e6a5a53160c246688e" category="paragraph"><block ref="f8caba75d33af6e6a5a53160c246688e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7a2b443f8714e7071c1d55a3bd2715f" category="section-title">インフラサポートリソース</block>
  <block id="f8f0e385abfb7fc517b1b9b4e9e8d19e" category="paragraph">Anthosをベアメタルに導入する前に、以下のインフラを導入する必要があります。</block>
  <block id="957478b81604fc0a340d863f3b89a2da" category="summary">ネットアップには、Anthos上に導入されるアプリケーション用のストレージプロビジョニングに対応するTrident Storage Orchestratorが認定しているストレージプラットフォームがいくつかあります。</block>
  <block id="f623f7fc1ffb9cfc3afddcf52e2fec23" category="paragraph">ネットアップには、Anthos上に導入されたアプリケーション用のストレージをプロビジョニングするために、ネットアップのAstra Tridentストレージオーケストレーションツールで認定されているストレージプラットフォームが複数あります。</block>
  <block id="0c5e049b7be7649501696f84472d6820" category="paragraph"><block ref="0c5e049b7be7649501696f84472d6820" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e2719bf8f96a980f38256b7a4060368" category="list-text">Ansibleプレイブックを使用してAstra Control Centerを導入するには、AnsibleがインストールされたUbuntu / RHELマシンが必要です。説明に従って、手順 に従います<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Ubuntuおよびの場合<block ref="94346839427703f278bfb2bc5962a814" category="inline-link-rx"></block> RHEL の場合：</block>
  <block id="bf98d9390f43e942cd74d874e3bf6d68" category="list-text">ディレクトリを'na_Astra_control_siteに変更します</block>
  <block id="cfcf9f0f05f9790927b65e14214edc6e" category="list-text">プレイブックを実行して Astra Control Center を導入します。Playbookには、特定の構成用のroot権限が必要です。</block>
  <block id="3c0e37ba6fc2025cda3b9ec88b955aab" category="paragraph">このプレイブックを実行しているユーザがrootである場合、またはパスワードを使用しないsudoが設定されている場合は、次のコマンドを実行してプレイブックを実行します。</block>
  <block id="6b682acdf6e246de63c54d6f90044faa" category="paragraph">ユーザにパスワードベースのsudoアクセスが設定されている場合は、次のコマンドを実行してこのPlaybookを実行し、sudoパスワードを入力します。</block>
  <block id="bbdfa4f0841eb6d317a11ae76992b8b8" category="summary">このセクションでは、ネットアップ環境でAnthosをカスタマイズするユーザ向けに、ロードバランサのオプションを説明します。</block>
  <block id="b935e49429349d1edf159cd09a0b8ff5" category="paragraph">以下のページでは、NetApp解決策 を搭載したAnthosで検証済みのロードバランサオプションについて、追加情報 を紹介します。</block>
  <block id="fbc20d9fb2c2f042edf73e3b39b3278a" category="paragraph"><block ref="fbc20d9fb2c2f042edf73e3b39b3278a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1bcd982a417f561201a3262b52a84d7" category="list-text">* NetApp SnapLock 。*指定された期間にわたって上書きまたは消去できない特殊なボリュームに書き込むことにより、書き換え不可能なデータを効率的に管理します。</block>
  <block id="99634a0c579c45d299cfbb8b818c51bb" category="paragraph"><block ref="99634a0c579c45d299cfbb8b818c51bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678cbe37bb872d145128736b4650ef68" category="paragraph">ネットアップは、堅牢なオールフラッシュ（AFF ）およびスケールアウトハイブリッド（FAS ）ストレージプラットフォームを提供し、低レイテンシのパフォーマンス、統合データプロテクション、マルチプロトコルのサポートを通じて、お客様のニーズに合わせてカスタマイズします。</block>
  <block id="a150469d40f75f1df1e87a9558f50769" category="paragraph">どちらのシステムも、NetApp ONTAP データ管理ソフトウェアを搭載しています。NetApp Data Managementソフトウェアは、可用性が高く、クラウドと統合されたシンプルなストレージ管理を実現する業界最先端のデータ管理ソフトウェアで、データファブリックのニーズに合わせてエンタープライズクラスのスピード、効率性、セキュリティを提供します。</block>
  <block id="a9b90f3200d3b94ea47e85db3a435816" category="paragraph">ネットアップのAFF プラットフォームとFAS プラットフォームの詳細については、をクリックしてください<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>。</block>
  <block id="7bfa2a7b059f09c3a772620888e93ef4" category="list-text">バックアップの詳細を入力し、バックアップファイルを保持するオブジェクトストレージバケットを選択して、次へをクリックします。詳細を確認したら、[バックアップ]をクリックします。アプリケーションとデータのサイズによっては、バックアップに数分かかることがあります。バックアップが正常に完了すると、バックアップのステータスは「available」になります。</block>
  <block id="bf6a757407fc5616f49930e56f86f233" category="list-text">アプリケーションをクローンするには、[アプリケーション（Apps）]&gt;[管理（Managed）]タブに移動し、該当するアプリケーションをクリックします。アプリケーション名の横にあるドロップダウンメニューをクリックし、 Clone をクリックします。</block>
  <block id="9b6757a6af2937cac7096646ee8dedb8" category="paragraph">F5 BIG-IPは、L4-L7ロードバランシング、SSL/TLSオフロード、DNS、ファイアウォールなど、高度な本番環境レベルのトラフィック管理とセキュリティサービスを幅広く提供するApplication Delivery Controller（ADC）です。これらのサービスにより、アプリケーションの可用性、セキュリティ、パフォーマンスが大幅に向上します。</block>
  <block id="402c558f65f9d58557e4d79511d71f01" category="paragraph">F5 BIG-IPは、オンプレミスのAnthosで最初に提供されているロードバランサソリューションの1つで、NetApp解決策 を搭載したAnthosの初期のReadyパートナー検証で使用されていました。</block>
  <block id="b662a8c121a377d9111fe64265c8d819" category="paragraph">この解決策 は、VMware vSphereに導入された仮想アプライアンスを使用します。F5 BIG-IP 仮想アプライアンスのネットワークは、ネットワーク環境に基づいて、 2 アームまたは 3 アームの構成で設定できます。本ドキュメントでの導入は、 2 つの設定に基づいています。Anthosで仮想アプライアンスを使用するための構成方法については、こちらをご覧ください<block ref="f18a28d0c935319437c4d1b1e33e5728" category="inline-link-rx"></block>。</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">を入力します</block>
  <block id="37f438df6a6d5ba4c17ef8ca58562f00" category="cell">F5キー</block>
  <block id="90524e294c6b7accf9b320977f3f5baa" category="cell">BIG-IP VE</block>
  <block id="bc75f10c94df92e80198364d879456ab" category="cell">15.0.1-0.0.11</block>
  <block id="c2c889e06ea18c0e72996bc4b43c8115" category="cell">16.1.0-0.0.19</block>
  <block id="674751c31a2db2596bf7788e2953b80f" category="paragraph">F5 BIG-IPをインストールするには、次の手順を実行します。</block>
  <block id="ee5cd6f83412e93266bf30ff048db6ff" category="list-text">から Virtual Application Open Virtual Appliance （ OVA ；仮想アプリケーションオープン仮想アプライアンス）ファイルをダウンロードします F5 キー<block ref="cafae381bde5e2381c6df42a3aa937c6" category="inline-link-rx"></block>。</block>
  <block id="fff9995f30a825c5d3e5709e7b78117a" category="admonition">アプライアンスをダウンロードするには、 F5 に登録する必要があります。これらは、 Big IP Virtual Edition ロードバランサ用の 30 日間のデモライセンスを提供します。アプライアンスを本番環境に導入するには、 10Gbps の永続的ライセンスを推奨します。</block>
  <block id="1a104d04970b6b80d8cf31f554404f4d" category="list-text">インフラストラクチャリソースプールを右クリックし、[Deploy OVF Template]を選択します。手順 1 でダウンロードした OVA ファイルを選択するためのウィザードが起動します。次へをクリックします。</block>
  <block id="fdf7304b13d736c791bc745a330e7309" category="image-alt">Big IP Appliance を導入します</block>
  <block id="fbd07b7802c1a124a9359b27b9f46968" category="list-text">ウィザードの次の画面では、環境で使用する仮想ネットワークをカスタマイズできます。[External] フィールドに VM_Network を選択し、 [Management] フィールドに [Management_Network] を選択します。内部および HA は、 F5 BIG-IP アプライアンスの高度な設定に使用され、設定されていません。これらのパラメータは単独で使用することも、インフラストラクチャ以外の分散ポートグループに接続するように設定することもできます。次へをクリックします。</block>
  <block id="93353313944577e80d34c3d9491db6ce" category="list-text">アプライアンスの概要画面を確認し、すべての情報が正しい場合は、 Finish をクリックして展開を開始します。</block>
  <block id="68b984a73f20c874fb80feeaa4621109" category="list-text">仮想アプライアンスを導入したら、右クリックして電源をオンにします。管理ネットワークで DHCP アドレスが割り当てられている必要があります。アプライアンスはLinuxベースで、VMware Toolsが導入されているため、vSphereクライアントで受信したDHCPアドレスを表示できます。</block>
  <block id="d92e443c00989a23096c72b760af7de8" category="list-text">Web ブラウザを開き、前の手順で確認した IP アドレスでアプライアンスに接続します。デフォルトのログインは admin/admin で、初回ログイン後はすぐに admin パスワードを変更するように要求されます。新しいクレデンシャルでログインする必要がある画面に戻ります。</block>
  <block id="dbe135d0d5ae1eb2c137c81f0ce0bdfb" category="image-alt">BIG-IP 設定</block>
  <block id="bdb0e3e1ff63b6d5f08545e207448035" category="list-text">最初の画面で、セットアップユーティリティを完了するように指示されます。[ 次へ ] をクリックして ' ユーティリティを開始します</block>
  <block id="8523c09995ae3cfb4593cd6c4e09029f" category="list-text">次の画面では、アプライアンスのライセンスを有効にするよう求められます。Activate をクリックして開始します。次のページでメッセージが表示されたら、ダウンロード用に登録したときに受け取った 30 日間の評価ライセンスキーか、アプライアンスの購入時に取得した永久ライセンスのいずれかを貼り付けます。次へをクリックします。</block>
  <block id="38d2bfb14ed98f122ce9d9b9cdb2a127" category="admonition">デバイスがアクティベーションを実行するには、管理インターフェイスで定義されたネットワークがインターネットに接続できる必要があります。</block>
  <block id="6ba845d7cd0e966d0a2a21209623a5b4" category="list-text">次の画面では、エンドユーザライセンス契約（ EULA ）が表示されます。ライセンスの条件に同意する場合は、 [ 同意する ] をクリックします。</block>
  <block id="c14be37e927625fe613c8c559de70df1" category="list-text">次の画面では、これまでに行われた設定変更を確認するまでの経過時間がカウントされます。Continue （続行）をクリックして、初期設定を再開します。</block>
  <block id="3c3d807fce3ffcb905b00324d2f7e2b9" category="list-text">設定変更ウィンドウが閉じ、セットアップユーティリティにリソースプロビジョニングメニューが表示されます。このウィンドウには、現在ライセンスされている機能、および仮想アプライアンスと各実行サービスの現在のリソース割り当てが表示されます。</block>
  <block id="117c183bcbd703e6b0520f843e971c9b" category="list-text">左側の [ プラットフォーム（ Platform ） ] メニューオプションをクリックすると、プラットフォームをさらに変更できます。変更内容には、 DHCP を使用して設定された管理 IP アドレスの設定、アプライアンスをインストールするホスト名とタイムゾーンの設定、 SSH からのアクセスの保護などがあります。</block>
  <block id="fad130ca7ff2a3734a8b7547b3ebc404" category="list-text">次に、標準ネットワーク機能を設定できる [ ネットワーク ] メニューをクリックします。[ 次へ ] をクリックして、標準ネットワーク構成ウィザードを開始します。</block>
  <block id="37f1b31abf7679b5f5e495d8796a48a7" category="admonition">このページの「自己IPアドレス」、「ネットマスク」、「フローティング」の各IPアドレスには、プレースホルダとして使用するルーティング不可のIPを入力できます。また、 3 段階の設定を導入する場合は、仮想ゲスト用の分散ポートグループとして設定された内部ネットワークにも接続できます。ウィザードを続行するには、これらの手順を完了する必要があります。</block>
  <block id="c3966f18c8da763e8d9f315b3e44811e" category="list-text">環境に複数の仮想アプライアンスを導入する場合は、次のページで内部 HA ネットワークを設定できます。続行するには、 Self-IP Address フィールドと Netmask フィールドに値を入力し、 VLAN インターフェイスとしてインターフェイス 1.3 を選択し、 OVF テンプレートウィザードで定義された HA ネットワークにマッピングする必要があります。</block>
  <block id="0d469ac29aab926968093104ad6265df" category="list-text">次のページでは、 NTP サーバを設定できます。次へをクリックして、 DNS セットアップに進みます。DNS サーバとドメインの検索リストは、 DHCP サーバによってすでに入力されている必要があります。[ 次へ ] をクリックしてデフォルトを受け入れ、続行します。</block>
  <block id="97a60c27b370d45c17075cff06f473a3" category="list-text">ウィザードの残りの部分については、 [Next] をクリックして、詳細なピアリング設定を行います。この設定は、このマニュアルでは説明していません。完了をクリックしてウィザードを終了します。</block>
  <block id="0953ce81fac634b21f33efe8dee24c28" category="list-text">Anthos 管理クラスタと環境内に導入されているユーザクラスタごとに、個別のパーティションを作成します。左側のメニューで [ システム ] をクリックし、 [ ユーザー ] に移動して、 [ パーティションリスト ] をクリックします。</block>
  <block id="616e4c989df3c842830310568b54cee6" category="section-title">Anthosとの統合</block>
  <block id="c0018d5f0e0d9decd39a8059cc2bc473" category="paragraph">このページには、ネットアップを使用したAnthosでの解決策 の検証とユースケースが含まれています。</block>
  <block id="fdd1d4ba64f526087e6e49e35a884fbd" category="summary">このセクションは、実環境のユーザがこの解決策 を本番環境に導入するときに実行する必要があるカスタマイズ（カスタムロードバランサインスタンスの導入など）に特化しています。</block>
  <block id="90f687894749dad073416489141eb43f" category="list-text">ネットアップAstra Tridentドキュメント</block>
  <block id="7cfc9495aac39bbaa5defc76b7f4e8db" category="list-text">VMwareドキュメントのAnthosクラスタ</block>
  <block id="f5266df5a7db89637cf0d7391221b756" category="inline-link"><block ref="f5266df5a7db89637cf0d7391221b756" category="inline-link-rx"></block></block>
  <block id="1bdc624c553dda22bc7a529bda2dd06b" category="paragraph"><block ref="1bdc624c553dda22bc7a529bda2dd06b" category="inline-link-rx"></block></block>
  <block id="9ee8ef3c59727b8b17070caf87743214" category="list-text">『Anthos on bare metal Documentation』</block>
  <block id="bc10096da41c680de98ecf3f1def7d17" category="inline-link"><block ref="bc10096da41c680de98ecf3f1def7d17" category="inline-link-rx"></block></block>
  <block id="d642746f7d7a37b7cb340d9a62d751a5" category="paragraph"><block ref="d642746f7d7a37b7cb340d9a62d751a5" category="inline-link-rx"></block></block>
  <block id="10a641cf7647f6970bad748b52bb253b" category="paragraph"><block ref="10a641cf7647f6970bad748b52bb253b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f640668ae5a8fc28f807fe0d6b9128b" category="paragraph">この方法では、ノード障害のあとにボリュームの再配分が発生しても、ログアウトして新しい場所にリダイレクトしてログインした場合を超えてホスト接続には影響はありません。iSCSI ログインリダイレクションを使用する NetApp Element ソフトウェアクラスタは、無停止アップグレードと運用が可能な自己回復型スケールアウトアーキテクチャです。</block>
  <block id="206188ac4e8ec83453b82a36311f1a25" category="paragraph">VMware上のAnthosクラスタは、エンドユーザのプライベートデータセンターに導入されているGoogle Kubernetes Engineの拡張機能です。組織は、オンプレミスのKubernetesクラスタ内のGoogle Cloud内のコンテナで実行するように設計されたものと同じアプリケーションを導入できます。VMware上のAnthosクラスタは、データセンター内の既存のVMware vSphere環境に導入できます。これにより、資本コストを削減し、導入と拡張の処理をより迅速に実行できます。</block>
  <block id="b107e7085d2931bbe4118d8c5eed9643" category="paragraph">VMware環境にAnthosクラスタを導入するには、次のコンポーネントが必要です。</block>
  <block id="d17685a3ddd89e969b430984ce944772" category="paragraph"><block ref="d17685a3ddd89e969b430984ce944772" category="inline-image-macro-rx" type="image"></block></block>
  <block id="348ed6380fe1c4753877d1f13d95d39a" category="paragraph">VMware上のAnthosクラスタには次のようなメリットがあります。</block>
  <block id="cf97925041bebbd35543bc4fc24fa499" category="list-text">*高度なマルチテナンシー。*各エンドユーザには、独自の開発環境に必要な仮想リソースを使用して、独自のユーザクラスタを割り当てることができます。</block>
  <block id="a6c34625dcf8367e84732b5219f81cb7" category="list-text">*開発して公開。*アプリケーションの開発中にオンプレミス環境を使用できます。これにより、ローカルデータセンターのプライバシーでアプリケーションをテストしてから、クラウドで公開することができます。</block>
  <block id="4418ae814387892bd88d45091a182234" category="list-text">* vSphere High Availability。*ホスト障害時のシステム停止を避けるため、VMware vSphereを使用すると、ホストをクラスタ化して高可用性を構成することができます。ホストの障害によってシステムが停止した VM は、クラスタ内の他のホストでまもなくリブートされ、サービスがリストアされます。</block>
  <block id="44da02789c784d2615f858b0e9007c1d" category="inline-link">NetApp FlexPod の略</block>
  <block id="08edd2123939d5309dced149763a50ee" category="inline-link">NetApp HCI</block>
  <block id="58d64ca3570be3edd23e4165a8c0d9ee" category="paragraph">次の表は、VMware環境でのAnthosクラスタの検証で、ネットアップとネットアップパートナーのエンジニアによってテストされたサーバプラットフォームを示しています。これには、などのソリューションが含まれます<block ref="5ea2f6a45afb6a8f064f7631dd737389" category="inline-link-rx"></block> Cisco UCSサーバおよびを使用する場合<block ref="3ff4d1b07fc6ed14e7fcf7636d0ad5aa" category="inline-link-rx"></block> ハイブリッドクラウドインフラプラットフォーム：</block>
  <block id="bcb24d33d2a22de9b0c3e9f38becc496" category="cell">できません</block>
  <block id="9f80c25863c6e1e85d8d5492b437cb64" category="cell">C410</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="section-title">オペレーティングシステム</block>
  <block id="69da39b403ff0537d2282cb291d4397c" category="paragraph">VMware上のAnthosクラスタは、お客様が選択したvSphere 6とvSphere 7の環境の両方に導入でき、現在のデータセンターインフラに合わせた導入が可能です。</block>
  <block id="23d300c91b3d48f94c1e7f5953ad3e5e" category="cell">7.0U3</block>
  <block id="89f7e5d7117ac9eb1ece116273f5f012" category="paragraph">ネットアップをフル検証済みの解決策 として導入したAnthosには、ネットアップとパートナーのエンジニアによって、ネットワークとストレージ用のデータセンターコンポーネントが追加でテストされています。</block>
  <block id="fe02a8fc8838381700e175498b8e1db0" category="cell">Mellanoxのサイト</block>
  <block id="92666505ce75444ee14be2ebc2f10a60" category="cell">SN</block>
  <block id="d7a84628c025d30f7b2c52c958767e76" category="cell">2010年</block>
  <block id="bf07aaec06ff922b8a11ef624141bfdb" category="cell">S410</block>
  <block id="dd4a9a41d8672c9659041812469e1df2" category="paragraph">次の表に、検証環境で導入されたソフトウェアバージョンの一覧を示します。</block>
  <block id="da0d53141f6343167596fe8598964773" category="cell">Software Name（ソフトウェア名）</block>
  <block id="3c537b8d673e06e2107129b600143391" category="cell">4.1（3e）</block>
  <block id="f932bed2d12442d21507b51d22b88dd7" category="cell">1.8</block>
  <block id="c1770c414b5c19c253a48e36fa2da50f" category="paragraph">Anthos Readyプラットフォームの検証では、以下の図に基づいてラボ環境が構築されました。このテストでは、導入した複数のユーザクラスタと、複数のネットアップストレージシステムおよびストレージバックエンドをテストできました。</block>
  <block id="c1c59b2c25178eb5f3956ae189dc384b" category="paragraph"><block ref="c1c59b2c25178eb5f3956ae189dc384b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13d18f8604b3585f7ab88b87766a8d38" category="paragraph">Anthosを導入する前に、以下のインフラを導入する必要があります。</block>
  <block id="92b7a761f185f74bf3bf9d2229c67a28" category="list-text">クラスタを動的に拡張する必要がある場合に、ネットワークアドレスのリースをオンデマンドで提供するために使用できるDHCPサーバ。</block>
  <block id="8256d4d5c73a64213343972bedd38f45" category="section-title">Anthosは、3ノード以上のESXiクラスタに導入します</block>
  <block id="150754dbd257c09eef8557a399e5ebc2" category="paragraph">Anthosクラスタノードを複数のハイパーバイザーノードに分散するには、VMとホストのアフィニティを有効にします。</block>
  <block id="659aed3f7f249a658860ff0d51cdef11" category="paragraph">アフィニティグループを設定するには、使用しているVMware vSphereのバージョンに応じた以下の該当するリンクを参照してください。</block>
  <block id="bfe724d354657c9ac5cef22bd231f66f" category="inline-link">vSphere 7.0のドキュメント：「Using DRS Affinity Rules</block>
  <block id="10c2b11d36730909ac14bcf903f9c456" category="paragraph"><block ref="0817a5be4b4f4733045646ef5cffc66c" category="inline-link-rx"></block>。<block ref="211975e132e07e8f3a0d0d18ff3759e5" category="inline-link-rx"></block>。</block>
  <block id="a272bae97494286f198c532bb9579161" category="list-text">次に、イメージレジストリ TLS 証明書を OpenShift ノードにアップロードします。そのためには、TLS証明書を使用して「OpenShift -config」ネームスペースにConfigMapを作成し、証明書を信頼できるようにクラスタイメージ構成にパッチします。</block>
  <block id="306235ad6a87783a223e0ba03145dc12" category="doc">プライベートイメージレジストリを作成しています</block>
  <block id="56a0195518edf56f84e2b789302cf485" category="paragraph">この手順 ドキュメントでは、Astra TridentとNetApp ONTAP が提供する永続的ボリュームを使用してバックアップされた、プライベートイメージレジストリを作成します。</block>
  <block id="13bb7c6596c212587d7a35708de351f2" category="admonition">Astra Control Center では、 Astra コンテナに必要なイメージをホストするためにレジストリが必要です。次のセクションでは、Red Hat OpenShiftクラスタにプライベートレジストリをセットアップし、Astra Control Centerのインストールをサポートするために必要なイメージをプッシュする手順について説明します。</block>
  <block id="83806e2d09a78bbe33b3e817a88df12b" category="list-text">入力オペレータOpenShiftレジストリルートにデフォルトのTLS証明書を使用している場合は、次のコマンドを使用してTLS証明書を取得できます。</block>
  <block id="6714b6fa43a8d03bcbfeb657bd27788d" category="list-text">OpenShift の内部レジストリは認証によって制御されます。すべてのOpenShiftユーザはOpenShiftレジストリにアクセスできますが、ログインユーザが実行できる操作はユーザ権限によって異なります。</block>
  <block id="489c81c1a0ec76cf6ab9a12890120550" category="list-text">サービスアカウントにパッチを適用するには、次のコマンドを実行します。</block>
  <block id="ec0c98e5e0be835a1df04b40b6c8e96c" category="list-text">OpenShiftノードとは別にワークステーションからイメージをプッシュまたはプルするには、次の手順を実行します。</block>
  <block id="872c01365a01300e2a8a772cd65e51b1" category="summary">このページでは、シーソーロードバランサのインストールおよび設定手順について説明します。</block>
  <block id="1ffbf83c6ff924ed568f0f88c922ac88" category="paragraph">このページには、Seesaw管理対象ロードバランサのインストールおよび設定手順がリストされています。</block>
  <block id="aa2bdb165616b7814c712fd55ecd1ce8" category="paragraph">次のテキストは、GKE-Adminクラスタ用パーティションの設定例です。コメントを解除して変更する必要がある値は、次の太字で表示されます。</block>
  <block id="b7e1a8e2925f8cb0b4f88b8532edd6d7" category="admonition">このファイルは、ロードバランサが基盤となるクラスタに提供するネットワークのゲートウェイとネットマスク、およびロードバランサを実行するために導入された仮想マシンの管理IPとホスト名を提供します。</block>
  <block id="5137c3284aa2dc8893ef670919f28a5f" category="list-text">インストールを開始する前に、 Astra Control Center イメージをイメージレジストリにプッシュします。この手順では、 Docker または Podman のいずれかを使用して実行します。両方の手順については、この手順で説明します。</block>
  <block id="123a55fe7e6f2398763a03f409e2c1de" category="admonition">または、サービスアカウントのトークンを使用して、サービスアカウントを作成し、（プッシュアクセスまたはプルアクセスが必要かどうかに応じて）レジストリエディタまたはレジストリビューアロールを割り当て、レジストリにログインすることもできます。</block>
  <block id="a917b1e998a1fed8ddebd661c3ff12b3" category="list-text">シェルスクリプトファイルを作成し、そのファイルに次の内容を貼り付けます。</block>
  <block id="f2f27bc59d06be1e1f58b94160cf9949" category="admonition">「kubeadmin」ユーザを使用してプライベートレジストリにログインしている場合は、パスワードの代わりにトークンを使用します。-「docker login -u OCP -user -p token astra-registry.apps.ocp-vmw.cie.netapp.com`」</block>
  <block id="61dbdb9822ed0d400254915ff02a4ee9" category="admonition">または、サービスアカウントを作成し、（プッシュ/プルアクセスが必要かどうかに応じて）レジストリエディタまたはレジストリビューアの役割を割り当て、サービスアカウントのトークンを使用してレジストリにログインします。</block>
  <block id="37a5c97f291196f8c672c75798a29beb" category="admonition">ルートとともに入力オペレータからのデフォルト TLS 証明書を含む OpenShift 内部レジストリを使用している場合は、前の手順に従って、ルートホスト名に証明書をパッチする必要があります。入力オペレータから証明書を抽出するには、コマンド「oc extract secret/router-ca --keys=tls.crt-n OpenShift ingress-operator」を使用します。</block>
  <block id="08e6bc541e2517b4105b8ac0ccbfe0f3" category="list-text">NetApp-acc-operator'ネームスペースのイメージレジストリにログインするためのクレデンシャルを含むシークレットを作成します</block>
  <block id="e1e6f0b52690f367570b6c16ddf92d98" category="list-text">NetApp-acc-operator'タイルを選択し、Installをクリックします。</block>
  <block id="1c17ca035fc060e6a6c77e025e8f27a1" category="list-text">インストールオペレータ画面で、すべてのデフォルトパラメータを受け入れて、インストールをクリックします。</block>
  <block id="5fa86531d41ab8ca8bee80ba657a599d" category="list-text">オペレータのインストールが完了したら、View Operator（オペレータの表示）をクリックします。</block>
  <block id="72c52a676e647d2aa400f12fe446f9f1" category="list-text">次に、オペレータのAstra Control Centerタイルで[インスタンスの作成]をクリックします。</block>
  <block id="500c99ec2ed1582312d17f1ea94ab5d0" category="list-text">[Create AstraeControl]フォームフィールドに入力し'[Create]をクリックします</block>
  <block id="097026a522eed2b2c71f07efd97bcf31" category="list-text">Astra Control Centerのアカウント名を入力し、管理者の詳細（名、姓、メールアドレスなど）を入力します。</block>
  <block id="ad2acc92f46f11a5d2a5ace0c933a44c" category="list-text">Image Registryに、レジストリのFQDNと、イメージをレジストリにプッシュする際に指定した組織名を入力します（この例では「astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra`」）。</block>
  <block id="3e99f691e1f9756e43f68a0aa28e61e0" category="list-text">認証が必要なレジストリを使用する場合は、[イメージレジストリ]セクションにシークレット名を入力します。</block>
  <block id="f009662483a899fd0d4b99ff5f1912f3" category="list-text">Astra Control Centerのリソース制限のスケーリングオプションを設定します。</block>
  <block id="c8a326f53d0d33a113452a303c243987" category="summary">ネットアップと Google Cloud は数年前から強力な関係を築いてきました。ネットアップは最初に、 Cloud Volumes ONTAP と Cloud Volumes Service を使用してクラウドデータサービスを Google Cloud に導入しました。この関係をさらに強化するために、解決策プラットフォームをオンプレミスの Google Cloud Anthos で使用できるようになりました。オンプレミス環境は、ハイパーバイザーベースのハイブリッドマルチクラウド Kubernetes NetApp HCI を VMware vSphere 上に導入した環境です。次に、ネットアップは、NetApp Astra Trident、ONTAP 、NFSプロトコル向けAnthos Ready認定を受けて、コンテナ向けの動的な永続的ストレージを提供しています。</block>
  <block id="f989491ea62ea4778f84ec6b21a68adf" category="paragraph">ネットアップと Google Cloud は数年前から強力な関係を築いてきました。ネットアップは最初に、 Cloud Volumes ONTAP と Cloud Volumes Service を使用して Google Cloud 向けのクラウドデータサービスを導入しました。この関係をさらに強化するために、解決策プラットフォームをオンプレミスの Google Cloud Anthos で使用できるようになりました。オンプレミス環境は、ハイパーバイザーベースのハイブリッドマルチクラウド Kubernetes NetApp HCI を VMware vSphere 上に導入した環境です。次に、ネットアップは、NetApp Astra Trident、ONTAP 、NFSプロトコル向けAnthos Ready認定を受けて、コンテナ向けの動的な永続的ストレージを提供しています。</block>
  <block id="1349318f8c0f3a02420c7453ca5cda7d" category="paragraph">Anthosは、お客様の環境のベアメタルサーバに直接インストールできるようになりました。これにより、お客様はハイパーバイザを使用せずにGoogle Cloudをローカルデータセンターに拡張できます。さらに、NetApp ONTAP ストレージオペレーティングシステムとNetApp Astra Tridentの機能を活用すれば、コンテナ向けの永続的ストレージを統合して、プラットフォームの機能を拡張できます。</block>
  <block id="2b9593caebc55ca069d98dcb7a3473c8" category="list-text">NetApp Astra Tridentを使用して、要求された永続的ボリュームをNetApp ONTAP からプロビジョニングして接続します。</block>
  <block id="c0724935c9b9fa3acfd0441317cac5e4" category="list-text">永続ボリュームの接続解除および再接続機能を検証します。</block>
  <block id="05053a6eeca3d00f1ffdaead4d65118f" category="list-text">ノード上の他のポッドから永続ボリュームへのマルチ接続、読み取り専用アクセスを検証する。</block>
  <block id="d7b2cdc877c7db996d45c651b4e7834a" category="paragraph">このドキュメントでは、NetApp ONTAP ストレージプラットフォームを、Kubernetes向けオープンソースストレージオーケストレーションツールであるNetApp Astra Tridentを使用してベアメタルプラットフォーム上のGoogle CloudのAnthosに構成し、検証して、ステートフルアプリケーションコンテナ向けの永続的ストレージの導入と管理を実現する方法について説明します。</block>
  <block id="4ed7e16612fd7090efc8d89c68421b74" category="paragraph">ONTAP 9.7 ソフトウェアを実行する NetApp AFF A300 ストレージシステムを設置し、 Anthos ワーカーノードと同じ Nexus 9K スイッチペアに物理的に接続しました。これらのネットワークアップリンクをインターフェイスグループ（ a0a ）に集約し、ワーカーノードがストレージシステムと対話できるよう適切なデータネットワーク VLAN をタグ付けしました。Storage Virtual Machine （ SVM ）は、 NFS プロトコルをサポートするデータ LIF と Trident のストレージ処理専用の SVM を使用して作成されたもので、ベアメタルクラスタの Anthos に導入されたコンテナに永続的ストレージを提供します。この永続ボリュームは、ネットアップが提供したTrident 20.10によって提供されました。Tridentは、完全にサポートされているKubernetes向けオープンソースストレージオーケストレーションツールの最新リリースです。</block>
  <block id="6a5e993e443aa30456050e2589b6e1a7" category="paragraph">NetApp Astra Tridentは、オープンソースで、Google Cloud AnthosなどのコンテナやKubernetesディストリビューション向けに完全にサポートされているストレージオーケストレーションツールです。NetApp ONTAP ソフトウェアを含む、ネットアップのストレージポートフォリオ全体と連携します。Trident は CSI に完全に準拠しているため、ストレージ管理者の手を煩わせることなく、ネットアップのストレージシステムからストレージをプロビジョニングして管理できるので、 DevOps ワークフローが高速化されます。Trident は、 Kubernetes API エンドポイントと直接通信するオペレータとして導入され、 NetApp ストレージシステム上でボリュームを作成および管理することによって、コンテナのストレージ要求を永続ボリューム要求（ PVC ）の形式で処理します。</block>
  <block id="eb3bc37ad07db70234f55e02bb4fa499" category="paragraph">NetApp Astra Tridentの詳細については、を参照してください<block ref="9f564c4a71f7ad715885fb9db4485dda" category="inline-link-rx"></block> ページ</block>
  <block id="3752e68cccc911651920465532b3d6b4" category="paragraph">ハードウェアに依存しないベアメタル上のAnthos機能により、ユースケースに最適化されたコンピューティングプラットフォームを選択できます。したがって、既存のインフラに合わせて、設備投資を削減できます。</block>
  <block id="fb5205026c598f136a15ad6c49fc1826" category="paragraph">次の表に、解決策 の実装に必要なストレージハードウェアコンポーネントの最小数を示します。ただし、使用するハードウェアモデルはお客様の要件に応じて異なる場合があります。</block>
  <block id="0e98dfa85df93b279e4fd456b30409cf" category="admonition">このマルチOS環境は、ベアメタル解決策 上のサポートされているOSバージョンのAnthosとの相互運用性を示しています。導入のために、お客様が 1 つまたは一部のオペレーティングシステムで標準化されると予想されます。</block>
  <block id="65ffe919dd9568cce4454508d8e543bd" category="paragraph">ネットアップのベアメタル環境に導入された Anthos は、インフラをカスタマイズできるため、コンテナベースのワークロードを効率的に実行できる堅牢なプラットフォームを提供します。お客様は、サーバインフラとサポート対象のオペレーティングシステムを自由に使用したり、既存のインフラに解決策を導入したりできます。NetApp ONTAP とNetApp Astra Tridentの統合により、これらの環境の機能と柔軟性が大幅に向上し、コンテナ向けの永続的ストレージを効率的にプロビジョニングおよび管理することで、ステートフルなアプリケーションワークロードをサポートします。Google Cloud のポテンシャルをネットアップのデータセンターに拡大することで、完全にサポートされ、可用性と拡張性に優れ、フルマネージドの Kubernetes 解決策を活用してアプリケーションワークロードの開発と運用を行うことができます。</block>
  <block id="96bef5489c133651bd324f8029d14586" category="paragraph"><block ref="96bef5489c133651bd324f8029d14586" category="inline-link-macro-rx"></block></block>
  <block id="8b682694b3e16be71600ae19c5a6e2fe" category="doc">NetApp Astra Controlを活用して、事後分析とアプリケーションのリストアを実行</block>
  <block id="7715f0efda43c06909ce1afad9f650b6" category="inline-link-macro">次のステップ：追加情報 ：ネットアップAstraを使用したDevOps</block>
  <block id="5d74a508c84dc62d2e7a448ba2c651fa" category="paragraph"><block ref="5d74a508c84dc62d2e7a448ba2c651fa" category="inline-link-macro-rx"></block></block>
  <block id="97e84aad4ef505e4cda6422dc1c95990" category="doc">追加情報 ：ネットアップのAstraを使用したDevOps</block>
  <block id="0221d1074d249c254f0679e761454a05" category="inline-link"><block ref="0221d1074d249c254f0679e761454a05" category="inline-link-rx"></block></block>
  <block id="40454fb96e27a719bd7a751c4ec47d16" category="paragraph"><block ref="40454fb96e27a719bd7a751c4ec47d16" category="inline-link-rx"></block></block>
  <block id="5eae6f5974c9d4195ebe0cf8b607647e" category="list-text">Ansibleのドキュメント</block>
  <block id="015674032a5c43c779a74ee9e3dbfc94" category="inline-link"><block ref="015674032a5c43c779a74ee9e3dbfc94" category="inline-link-rx"></block></block>
  <block id="f13ae695d1de0b91201bca0cd4e87c69" category="paragraph"><block ref="f13ae695d1de0b91201bca0cd4e87c69" category="inline-link-rx"></block></block>
  <block id="f89c93af274397315016bac75d215351" category="inline-link"><block ref="f89c93af274397315016bac75d215351" category="inline-link-rx"></block></block>
  <block id="9e4287aba38224954e73e528ce96bb47" category="paragraph"><block ref="9e4287aba38224954e73e528ce96bb47" category="inline-link-rx"></block></block>
  <block id="7a42c46751036b34f81738e60f1b7e97" category="list-text">Rancherドキュメント</block>
  <block id="6483799d4ba7ad61fe06633600d8824a" category="inline-link"><block ref="6483799d4ba7ad61fe06633600d8824a" category="inline-link-rx"></block></block>
  <block id="b8e7a2183995014079b38a90770a02ea" category="paragraph"><block ref="b8e7a2183995014079b38a90770a02ea" category="inline-link-rx"></block></block>
  <block id="d7c98030ea1f0ace5cb1fc0a5954a87c" category="list-text">Kubernetesのドキュメント</block>
  <block id="1c333560e2edbd1cefb05f127658b17f" category="doc">Astra Control Centerを使用したCI / CDパイプラインでのデータ保護</block>
  <block id="943b2a1ab5485e1a2db3098051987614" category="summary">FlexCloneテクノロジを使用した迅速な導入</block>
  <block id="065cb44483a670695f374bc25a1f01b4" category="doc">ユースケースの検証：ネットアップAstraを使用したDevOps</block>
  <block id="438d983a4a02b97c1363407ba1bb3dbd" category="paragraph">ネットアップAstraを使用してDevOps向けに検証されたユースケースは次のとおりです。</block>
  <block id="47d55e9f9b259c93da777f74a5e832ee" category="inline-link-macro">NetApp Astra Controlにより、CI / CDパイプラインへの保護を統合</block>
  <block id="86ebb4e5f51da406d6b6170528e02c8c" category="list-text"><block ref="86ebb4e5f51da406d6b6170528e02c8c" category="inline-link-macro-rx"></block></block>
  <block id="a9e51e0a4f30c204f900ee62c24b54e8" category="inline-link-macro">アストラ制御を活用して、事後分析とアプリケーションの復元を容易にします</block>
  <block id="5ea6f0d962656bf6d901dedc10e9da49" category="list-text"><block ref="5ea6f0d962656bf6d901dedc10e9da49" category="inline-link-macro-rx"></block></block>
  <block id="6c9a3a62fc54ba1feccaee9df9c39f88" category="inline-link-macro">ネットアップのFlexCloneでソフトウェア開発を高速化</block>
  <block id="001bc4e878f5da889174d53f10bc3a58" category="list-text"><block ref="001bc4e878f5da889174d53f10bc3a58" category="inline-link-macro-rx"></block></block>
  <block id="69955eeaaa4d02c4d90d3119741235a0" category="inline-link-macro">次のビデオとデモ- NetApp Astraを使用したDevOps</block>
  <block id="d2ed0f238fb1fa6e7a14606baf24c2ab" category="paragraph"><block ref="d2ed0f238fb1fa6e7a14606baf24c2ab" category="inline-link-macro-rx"></block></block>
  <block id="d0f564d49f74b4698141e88cbce5ad41" category="summary">ネットアップには、Astra TridentとAstra Controlで認定された複数のストレージプラットフォームがあり、コンテナ化されたアプリケーションのデータをプロビジョニング、保護、管理し、DevOpsのスループットを定義して最大化するのに役立ちます。</block>
  <block id="b43c4021858544ebd3a492d082a7f349" category="doc">ネットアップストレージシステムの概要</block>
  <block id="e3775ded02e90946eb22f7f559238e62" category="list-text"><block ref="e3775ded02e90946eb22f7f559238e62" category="inline-link-macro-rx"></block></block>
  <block id="9111d84a5d538f39612bb42cb2a729aa" category="inline-link-macro">次：ネットアップのストレージ統合の概要</block>
  <block id="1139e8039447d6c6f83fa4a35ea79999" category="paragraph"><block ref="1139e8039447d6c6f83fa4a35ea79999" category="inline-link-macro-rx"></block></block>
  <block id="70806b7246c09c2ec58c7947d781ebdf" category="doc">NetApp Astra Controlの概要</block>
  <block id="3d4bc8fb320a39f7369e26aa8dd43ff9" category="paragraph">Astra Control Centerのインストールと操作の詳細については、のマニュアルを参照してください <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>。</block>
  <block id="778aa9cc77239e29447d4ec0991d37ed" category="section-title">Astra Control Center自動化</block>
  <block id="1c3dabdc1df77100ef6e17757091285e" category="paragraph">Astra Control Centerには、プログラム経由でアクセスするための完全に機能するREST APIが用意されています。任意のプログラミング言語またはユーティリティを使用して、Astra Control REST APIエンドポイントとやり取りできます。このAPIの詳細については、のドキュメントを参照してください <block ref="bb2ca4e10b1254bc49d4388c68f9edb7" category="inline-link-macro-rx"></block>。</block>
  <block id="5d9f4b40183d98a25c3ab751a2c22032" category="paragraph">すぐに利用できる、Astra Control REST APIと連携するためのソフトウェア開発ツールキットを探している場合、ネットアップはAstra Control Python SDKツールキットを提供しています。このツールキットはこちらからダウンロードできます <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>。</block>
  <block id="22082fb9e9a42ddec66d9e75b3a3e61f" category="paragraph">環境に適したプログラミングでない場合に構成管理ツールを使用するには、ネットアップが公開しているAnsibleプレイブックのクローンを作成して実行します <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>。</block>
  <block id="d10e08b0a3edeee9dca36ed4d8843516" category="inline-link-macro">次：ユースケースの検証：ネットアップアストラを使用したDevOps</block>
  <block id="05caddd89629dc542b78549ec8132f7e" category="paragraph"><block ref="05caddd89629dc542b78549ec8132f7e" category="inline-link-macro-rx"></block></block>
  <block id="b75bc3343d170f8dd97d55a434b978ed" category="doc">アストラ制御を使用すると、事後分析やアプリケーションのリストアが容易になります</block>
  <block id="3bbc946d425216e518cab3d8bcac2d2e" category="inline-link-macro">最初のユースケース</block>
  <block id="3693bda9c9f6c60fbcfaa68a3c84d1c0" category="paragraph">を参照してください <block ref="378d294ca149bdd5226353f2fb623f62" category="inline-link-macro-rx"></block>では、ネットアップのAstra Control Centerを使用してKubernetesでアプリケーションを保護する方法を紹介しました。このセクションでは、NetApp AstraツールキットのPython SDKを使用して、Astra Controlを介したアプリケーションバックアップを開発ワークフローに直接統合する方法について説明します。このアプローチにより、継続的統合/継続的導入（CI / CD）プロセスでオンデマンドバックアップを自動化することで、開発環境と本番環境の保護が可能になります。アプリケーションと整合性のあるデータ保護のこの追加レイヤーがCI / CDパイプラインと本番アプリケーションに追加されたことで、プロセスに何か問題が発生しても開発プロセスは安全になり、ビジネス継続性のプラクティスが促進されます。</block>
  <block id="93cf0eac312e112dec7819cf9726e08d" category="paragraph">従来のワークフローでは、アプリケーションを新しいバージョンにアップグレードするときにエラーが発生した場合、開発チームはお客様から提供されたバグレポートに基づいて問題 のトラブルシューティングをリアルタイムで試みます。また、最初に問題が発生したときに、チームはアプリケーションを並列デバッグ環境に再配置して、そのプロセスをオフラインにすることもできます。以前のバージョンの古いコードベースを本番環境に再導入することで、アプリケーションを作業順序に復元できます。</block>
  <block id="63cbc205a471137f16d61f24cd16531d" category="image-alt">従来のワークフロー</block>
  <block id="cd78d769508976f182829ab0d59eb537" category="paragraph">このアプローチは機能しますが、問題が発生したときに本番環境で使用されていたバージョンと破損した本番アプリケーションの状態が一致していることを確認する必要があります。また、リポジトリからコードを取得し、マシンイメージを再展開してアプリケーションを良好な稼働状態に復元することで、動作確認済みビルドを本番環境にプロモートするための時間も必要になります。また、このシナリオでは、本番環境のデータベース自体が、障害のあるコードによって破損していないかどうかを考慮しませんでした。データベースデータのバックアッププロセスが別に用意されているのは理想的ですが、公開時にアプリケーションの状態と整合性があると仮定する必要があります。ここでは、Astra Controlを使用して、ステートフルでアプリケーションと整合性のあるバックアップ、リストア、クローンを作成することのメリットが、まさにその価値を示しています。</block>
  <block id="8b8ad5ef011a096e139bfa3245f80536" category="paragraph">まず、アストラ制御を使用して、アプリケーションの状態に関する事後分析を容易に行うことができます。そのためには、アプリケーションと整合性のある方法で、バグのある本番バージョンを並行テスト環境にクローニングします。この環境をバグ非表示状態にしておくと、リアルタイムで問題のトラブルシューティングを行うことができます。</block>
  <block id="f94a2c6cdc2965b0f258d8215d1d28e0" category="paragraph">さらに、Astra Controlでは、インプレースリストア機能がサポートされているため、本番アプリケーションを最後の許容可能なバックアップ（コードのバージョンが古い場合）にリストアできます。復元されたバージョンは、以前に割り当てられた入力IPを含む、アプリケーションと一貫性のあるステートフルな方法で、以前のバグのある本番アプリケーションの位置を想定しています。そのため、フロントエンドにアクセスするお客様は、バックアップバージョンへの移行を認識しません。</block>
  <block id="1b0d7d8dcdf6d93ab2d330cc2396dfbc" category="image-alt">事後分析のワークフロー</block>
  <block id="204890df83c01d375e4f4b6a724cc278" category="section-title">ユースケースの検証の前提条件</block>
  <block id="93323e0f22b5aab17967ba48325ffbfa" category="paragraph">前提条件として、次のツールまたはプラットフォームを導入および設定しました。</block>
  <block id="f4f24690df38094196eebb86cb8ae057" category="list-text">Red Hat OpenShift Container Platform：</block>
  <block id="727324215fe79d6ac06ad699c15bc8b6" category="list-text">NetApp ONTAP システムにバックエンドを設定して、OpenShiftにNetApp Astra Tridentをインストールします。</block>
  <block id="229afb3c2926b78c5616a952d849e68c" category="list-text">NetApp ONTAP バックエンドをポイントするデフォルトのストレージクラスが設定されている</block>
  <block id="ba5452097a4c1be15b1efd3a6b26349f" category="list-text">OpenShiftクラスタにNetApp Astraコントロールセンターをインストール。</block>
  <block id="81c0c009a723f32f259a76657c0df955" category="list-text">OpenShiftクラスタをAstra Control Centerにマネージドクラスタとして追加。</block>
  <block id="6500a898faeb0dbf12368cd5d4c62b66" category="list-text">OpenShiftクラスタにJenkinsをインストールしました。</block>
  <block id="76046924ab57dbfe48ac94a0d7cd184f" category="list-text">本番環境にインストールされたMagentoアプリケーション。このユースケースの本番環境は、Red Hat OpenShiftクラスタで「ジェント本番環境」という名前のネームスペースです。</block>
  <block id="7e5531e0bbdbf2a1b4736169f5261238" category="list-text">本番アプリケーションはAstra Control Centerによって管理されます。</block>
  <block id="be3750e953403822ff53f62de7d378c9" category="list-text">Astra Controlでキャプチャされた、本番アプリケーションの正常なバックアップ。</block>
  <block id="a571d6a950aa43dc09919def5e2f001a" category="section-title">クローニングとリストアのパイプライン</block>
  <block id="c04ae281a30f44b5bfe0091b23da26f7" category="paragraph">アプリケーションが新しいバージョンにアップグレードされたことを考慮して、本番環境のアプリケーション（「Magent-prod」）はアップグレード後に意図したとおりに動作しません。フロントエンドクエリから返されるデータがリクエストと一致しないか、データベースが実際に破損しているとします。パイプラインをクローニングしてリストアするには、次の手順を実行します。</block>
  <block id="8c2af21e6b34f2b1071040d4d1cfcb1c" category="image-alt">アプリが失敗しました</block>
  <block id="6b1006b72a3e1550c386243b3965f2dc" category="list-text">Jenkinsにログインし、[新しいアイテム]、[パイプライン]の順にクリックしてパイプラインを作成します。</block>
  <block id="42c6ce7c0a0da42cf240660b7916b661" category="list-text">Jenkinsfileからパイプラインをコピーします<block ref="8676dd4f33dff00c4bf2944921591642" category="inline-link-rx"></block>。</block>
  <block id="64b46adfefce359622cb0f4882c6c1bd" category="list-text">パイプラインをJenkinsパイプラインセクションに貼り付け、保存をクリックします。</block>
  <block id="68d9707b516a968ed4c0757cbe9d5a9f" category="list-text">Jenkinsパイプラインのパラメータに、本番環境の現在のMagentoアプリケーションバージョン、Astra Control Center FQDN、APIトークン、本番環境とデバッグ環境のインスタンスIDとアプリケーション名またはネームスペース、ソースクラスタ名とデスティネーションクラスタ名など、それぞれの詳細を入力します。このユースケースのために、本番環境は「メント本番」と呼ばれるネームスペースであり、デバッグ環境はRed Hat OpenShiftクラスタで構成される「メントデバッグ」と呼ばれるネームスペースです。</block>
  <block id="0aada8c0ec6d36d56210caa3cac9e025" category="list-text">[今すぐ構築]をクリックしますパイプラインが実行を開始し'ステップを進めますアプリケーションは、最初に現在の状態でデバッグ環境にクローニングされ、その後、動作確認済みのバックアップにリストアされます。</block>
  <block id="4413dc875e85526bf92964b740f23064" category="image-alt">事後分析パイプライン</block>
  <block id="4abbf0b75dc539f2afebf5014fbe6ea8" category="list-text">クローニングしたアプリケーションのバージョンがバグを含むことを確認します。</block>
  <block id="cbcf57aecdb6a6d216d8239a690bc2f6" category="image-alt">アプリのクローン作成に失敗しました</block>
  <block id="e73e23a9c5f896c3c98ea35a77116dfe" category="list-text">本番環境が稼働中のバックアップにリストアされ、本番環境のアプリケーションが想定どおりに動作することを確認します。</block>
  <block id="b24fb6cbfbfd8a2620eab1cb8f9d1563" category="image-alt">本番アプリケーションをリストアしました</block>
  <block id="cbd612409ffde58db700aacbf7ea15ca" category="paragraph">これら2つのオペレーションを同時に行うことで、通常の業務に迅速に復帰できます。このユースケースの実際の動作を確認するには、ビデオをご覧ください <block ref="f5eb99e953852b5d0acfc08abd7c4f00" category="inline-link-macro-rx"></block>。</block>
  <block id="847338f2bbcf0d01da4eec4011f6ad14" category="summary">このテクニカルレポートでは、コンテナ化されたアプリケーションを使用する場合に、ネットアップがDevOpsのユースケースを複数の面で簡単かつ効率的に作成する方法を説明します。まずは、ネットアップのストレージシステムの詳細と、ネットアップのKubernetesプラットフォームとの統合を紹介するAstraポートフォリオを活用します。最後に、解決策検証と実際の使用事例をいくつか確認して文書化します。</block>
  <block id="322f410c2f08f93c29982d4bf9cabcc0" category="doc">TR-4919：『DevOps with NetApp Astra』</block>
  <block id="ede7528f12f050f41a167a0f19204ecb" category="paragraph">ネットアップのAstra解決策 を使用したDevOpsは、次のユースケースにおいて、卓越した価値をお客様に提供するように設計されています。</block>
  <block id="2dcb73ff09329212051362094e88c1a7" category="list-text">サポートされているKubernetesディストリビューションに導入されたアプリケーションや開発環境の導入と管理が容易です。</block>
  <block id="c267f4560fe6c3f4bee2d0420cdd7977" category="list-text">DevOpsワークフローの実際のユースケースと、ネットアップが提供するツールやメソッドの例について説明し、これらの手法の採用や利用を簡易化する方法を紹介します。</block>
  <block id="52d3258544cd838f0c52461847e6943b" category="list-text">アプリケーションと整合性のあるSnapshot、バックアップ、クローンを使用してDevOpsエクスペリエンスを向上する方法をご紹介します。</block>
  <block id="6071498e95e7692ffc4f3f66e80e1fe2" category="list-text">ワークフローが中断されないように、スタック内のすべてのレイヤで高可用性を実現します。</block>
  <block id="0fd2f931dbf65015445450e54266b6dd" category="list-text">エンドユーザ向けの導入と管理の手順が簡単です。</block>
  <block id="683aa4d78ced60b9236f9cc2f4eaf1eb" category="list-text">APIベースのプログラム可能なインフラで、マイクロサービスや開発者の即応性に対応します。</block>
  <block id="440bd390f196ecee0d5c1bbc242f74c1" category="list-text">ワークロードのニーズに基づいて、インフラを個別に、自動化された方法で拡張できます。</block>
  <block id="e1151e572983d1f8759759f2765ccd80" category="list-text">DevOpsワークフロー向けの永続的データセットと並行してアプリケーションを保護することで、再導入や手動によるデータコピーに頼ることなく、製品化サイクルを短縮できます。</block>
  <block id="556e90029d54aba834e233882cb7bdb5" category="paragraph">このテクニカルレポートでは、これらの機能と課題を認識し、さまざまなネットアップ製品ポートフォリオを使用してコンテナ化されたアプリケーションのDevOpsユースケースを改善、簡易化するプロセスについて説明します。</block>
  <block id="3c4a3a2e21fd3a1caee264afd78ccaa4" category="paragraph">NetApp解決策 を使用したDevOpsには、次の主要コンポーネントが含まれています。</block>
  <block id="26ebb4a3d87e964eeae59f74f1cf7565" category="section-title">DevOpsの手法</block>
  <block id="d113ef32a81ded7eb94b33e9a12344d3" category="paragraph">DevOpsの手法は、自動化され、反復可能で容易に管理できる運用に重点が置かれます。この運用では、開発ワークフローが強化され、エンドユーザがコードを開発する環境を制御できるようになります。この解決策 には、ネットアップテクノロジがこのような運用の最大のメリットになる例とユースケースがいくつかあります。</block>
  <block id="301a5e3f98e4b9ad41275bc224cd61ec" category="paragraph">現在、多数のコンテナオーケストレーションプラットフォームが使用されています。これらのプラットフォームのほとんどはKubernetesをベースにしていますが、それぞれに長所と短所があります。そのため、DevOpsワークフロー用のコンテナオーケストレーションプラットフォームを選択する際には、機能セットと統合について理解することが重要です。ネットアップは、NetApp Astra製品スイートを通じて、本格的なDevOpsユースケース向けに次のプラットフォームをサポートしています。</block>
  <block id="6c00bd8314a0e887501377d7e80e84a0" category="list-text"><block ref="41493d18eda2456ccaff840381cd2ba9" category="inline-link-rx"></block> 4.6.8以降</block>
  <block id="82033d4b30c6027097326898ed36b593" category="inline-link">ランチマー</block>
  <block id="30fad75d887172c8bd19dcc5febd9364" category="list-text"><block ref="f47c99eede6f9eae831133d1e9b5034b" category="inline-link-rx"></block> 2.5以上</block>
  <block id="22bd2466d697a7c77e319d9a31c2166f" category="list-text"><block ref="fe8d70118059c4a67994e27a008bb3e0" category="inline-link-rx"></block> 1.20以降</block>
  <block id="a56837df79ae6671b6b511c330431135" category="inline-link">VMware Tanzu Kubernetesグリッド</block>
  <block id="b2bc0f20995d2c98d2f854eb51c195c7" category="list-text"><block ref="3f98585591c50cc93953cd157cf0939c" category="inline-link-rx"></block> 1.4以降</block>
  <block id="a1c1bb4994628000cfe61563bf4ff4f5" category="inline-link">VMware Tanzu Kubernetes Grid統合エディション</block>
  <block id="a75ee0eed3c5f01371e94695f023b820" category="list-text"><block ref="948fe538658bc79d22a37c7852e43c83" category="inline-link-rx"></block> 1.12.2+</block>
  <block id="fba78f40ce7eabf1a8bf79ee5c44bd8e" category="inline-link-macro">次のステップ：DevOpsの概要</block>
  <block id="a9d268e4b26cd47b2d7a0aa5a816a1c8" category="paragraph"><block ref="a9d268e4b26cd47b2d7a0aa5a816a1c8" category="inline-link-macro-rx"></block></block>
  <block id="44a18520ed05f9b0b2e06135a4ff7518" category="summary">DevOpsの概要と、このテクニカルレポートの潜在的なユースケースを紹介します。</block>
  <block id="74b9fd8d0b2ef1c2b396580a2afd59ae" category="doc">DevOpsの概要</block>
  <block id="d5df4eecbaafa5d83d7698ba92c7cecd" category="paragraph">ここ数年、ソフトウェアを開発している組織がDevOpsの概念をすでに採用しています。DevOpsの手法は組織の壁を取り払い、開発チームと運用チームをより緊密に連携させます。DevOpsの手法は、サービス提供の高速化、可用性の向上、サービスとアプリケーションの安定化を可能にし、チームの生産性を向上させます。また、自動化フレームワークの採用は、大規模なアプリケーションの構築、テスト、運用、完全に自動化されたインフラプラットフォームやスタックの管理など、成功の鍵となる要素でもあります。以下に、DevOpsの一般的なユースケースをいくつか紹介します。DevOpsの実践で実践している実践的な経験を強化するために、ネットアップのソリューションを導入することができます。</block>
  <block id="e7ccc944261680ee4a52d724dd1ca1c5" category="section-title">DevOpsのユースケース</block>
  <block id="e4fd3fc8a04e3e1d2e788cd1b017e1f2" category="paragraph">DevOpsには一般に認められた単一の定義はありませんが、DevOps組織向けのソリューションには、一般に、大規模な実装、繰り返し、管理を容易にする同様の構成や理念が含まれています。以降のセクションでは、ネットアップのソリューションで実現するDevOpsワークフローのユースケースについて説明します。</block>
  <block id="020a9588f0f051f7f9ff59fabaffa365" category="section-title">継続的統合、継続的導入、継続的導入（CI / CD）</block>
  <block id="b1a2676c9ceea5e6ef4c514562097e9a" category="paragraph">継続的統合、継続的導入、継続的導入（CI / CD）は、コードの更新、テスト、導入を一貫して自動化する方法を確立することで、コーディング手法の実装と変革を開発者に奨励するコーディング哲学です。ほとんどのDevOpsワークフローでCI / CDを実装する最も一般的な方法は、CI / CDパイプラインを使用する方法であり、この方法を実現するために役立つサードパーティ製のソフトウェアアプリケーションがいくつかあります。</block>
  <block id="3ff91355eb24188940a49b15da87cb74" category="image-alt">CI / CDイメージ</block>
  <block id="64d92cb8c4c053363095cf796a7b89ba" category="paragraph">CI / CDタイプのワークフローに役立つ一般的なアプリケーションの例を次に示します。</block>
  <block id="418f66e40d28aac0fa315742070e645f" category="inline-link">アルゴCD</block>
  <block id="2e54334c0a5ce2e3e5a5845df3ab3ada" category="inline-link">Jenkins</block>
  <block id="e1500a23f27fb897c6cdf5caab04195d" category="inline-link">テクトン</block>
  <block id="4d094d290ed5b2a855427290709addea" category="paragraph"><block ref="ff7d5093e53bbd8006cbcaaeb044f69a" category="inline-link-rx"></block>
<block ref="0d8e72f4ae085bb6c45eba7c3f144090" category="inline-link-rx"></block>
<block ref="313a601d85cff2a8e7d85ce0f552cc73" category="inline-link-rx"></block></block>
  <block id="2c14caaf080b9d4ff53b1e0d7364a348" category="paragraph">このテクニカルレポートの後半で紹介するユースケースの中には、Jenkinsで紹介したものもありますが、CI / CDの主な原理は、組織が独自の方法で実装したどのツールにも適用できます。</block>
  <block id="af41549605744cf23f27cbc14458bf82" category="section-title">コードとしてのインフラ</block>
  <block id="3e9f73de1e8a89473ea5df8ed9ad7651" category="paragraph">Infrastructure as codeは、自動化されたコマンド、API、およびソフトウェア開発キット（SDK）を通じてITリソースのプロビジョニングと管理を支援します。この概念は、開発者が目標を達成できなくなる可能性のある物理データセンターやリソースの制限を取り除くことで、DevOpsエクスペリエンスを大幅に向上させます。</block>
  <block id="9b2cf15c50955773c7604b77322b057e" category="image-alt">コードとしてのインフラの画像</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="inline-link">Python</block>
  <block id="d51d5ee15f404c2f4f7863bebcde1fac" category="inline-link">Ansible</block>
  <block id="14590850b4107a6f92feb1af739b82eb" category="inline-link">パペット</block>
  <block id="10feac82bf81358ba2b3681989464290" category="paragraph">エンドユーザーは、などのプログラミング言語を頻繁に使用します<block ref="11022d613ff738bd6763caad4acd7f7e" category="inline-link-rx"></block> などの自動化ツールを使用できます<block ref="9790ec336069075a6bee003fe52e73bb" category="inline-link-rx"></block> または<block ref="82158671408fe4876cefcfa78b9fd777" category="inline-link-rx"></block> 必要に応じて開発者が呼び出すことができる、自動化された反復可能なインフラ拡張アクションを作成するため。</block>
  <block id="25d4b1e166882d63d2b4f8c8919a7513" category="paragraph">NetApp ONTAP とAstra Controlには、パブリック向けのAPIとAnsibleモジュールまたはソフトウェア開発ツールキットが含まれているため、運用を自動化しやすく、DevOpsプロセスへの統合が容易です。</block>
  <block id="137a72e2db1a693e6a6d286f154ddc67" category="inline-link-macro">次のセクション：「NetApp Storage Systems Overview」</block>
  <block id="436a9385e01c8134ffa76de0039b69e9" category="paragraph"><block ref="436a9385e01c8134ffa76de0039b69e9" category="inline-link-macro-rx"></block></block>
  <block id="72a943bda30daac28d5a7097897df424" category="summary">ネットアップは、コンテナベースの環境における永続的データのオーケストレーションや管理を支援する、さまざまな製品を提供しています。</block>
  <block id="d9ac8f9dec3643254ee6240ba67244f5" category="list-text"><block ref="d9ac8f9dec3643254ee6240ba67244f5" category="inline-link-macro-rx"></block></block>
  <block id="dd2387c2fbbd7ec35d40da2a116c5349" category="list-text"><block ref="dd2387c2fbbd7ec35d40da2a116c5349" category="inline-link-macro-rx"></block></block>
  <block id="0218e43406cb3e0a01af575972d39479" category="inline-link-macro">次：ユースケースの検証：ネットアップアストラを使用したDevOps</block>
  <block id="138b9ec9c8120fa5dbf98537df5269d4" category="paragraph"><block ref="138b9ec9c8120fa5dbf98537df5269d4" category="inline-link-macro-rx"></block></block>
  <block id="ae5d1fe148e47e375a2109cb3f29045a" category="paragraph">のドキュメントを参照してください <block ref="a57add0d538360cd0adbee43a89f028d" category="inline-link-macro-rx"></block> Astra Tridentの導入と使用方法</block>
  <block id="dc51ad14ee45a258aa1e6606251cf967" category="doc">ビデオとデモ：NetApp Astraを使用したDevOps</block>
  <block id="cd70acb1d118792e37e49b5dc15142ad" category="paragraph">次のビデオでは、このドキュメントで説明する機能の一部を紹介します。</block>
  <block id="47a3fe612643a48831699e345fc50086" category="inline-link-macro">ビデオ：Integrate Data Protection in CI / CD Pipeline with Astra Control</block>
  <block id="b137de00495bfd71913e4fe2ecc2fbb5" category="list-text"><block ref="b137de00495bfd71913e4fe2ecc2fbb5" category="inline-link-macro-rx"></block></block>
  <block id="11a855b91bda336c24ae0014cf0b01aa" category="list-text"><block ref="11a855b91bda336c24ae0014cf0b01aa" category="inline-link-macro-rx"></block></block>
  <block id="760ebcab0161b35f2cbcee21a65a788a" category="list-text"><block ref="760ebcab0161b35f2cbcee21a65a788a" category="inline-link-macro-rx"></block></block>
  <block id="c6b924f851b08c850fe2e53f34ada256" category="doc">NetApp FlexCloneテクノロジでソフトウェア開発を高速化</block>
  <block id="e071982902994eb194aeef35d4e7d131" category="paragraph">Kubernetesクラスタに導入されたアプリケーションをクローニングすると、開発者は、パートナーと環境を共有したり、現在作業しているバージョンを妨げずに開発環境で新しいバージョンのコードをテストしたりすることで、ワークフローを迅速化したいと考えています。これは非常に便利なツールです。Kubernetesアプリケーションのステートフルでアプリケーションと整合性のあるクローニングは、NetApp Astra Controlに含まれる主要な機能であり、アプリケーションのバックアップとリストアに加えて提供されます。さらに、同じストレージバックエンドを使用して同じKubernetesクラスタ内でアプリケーションをクローニングした場合、Astra Controlでは、永続的データボリュームの重複に対してNetApp FlexCloneテクノロジがデフォルトで使用されるため、処理時間が大幅に短縮されます。このプロセスを短縮することで、クローニングした環境のプロビジョニングが完了し、数秒で使用できるようになります。そのため、開発者はテスト環境や開発環境を再導入する場合と比べて、作業を一時的に中断することなく再開できます。さらに、NetApp Astra Controlで使用できるすべての機能をAPIで呼び出すことができるため、Ansibleなどの自動フレームワークに簡単に統合できます。このため、クローニング手順 を開始するためにプレイブックまたはロールに必要な変更はわずかなため、環境のステージング時間をさらに短縮できます。</block>
  <block id="130a289acaa6c63f08a152e232264781" category="section-title">NetApp FlexCloneテクノロジとは</block>
  <block id="de7fc3e1378f3d66008013e37abfc654" category="paragraph">NetApp FlexCloneテクノロジは、NetApp FlexVol の書き込み可能なポイントインタイムSnapshotベースのコピーです。ほぼ瞬時にプロビジョニングされ、ソースボリュームのデータがすべて含まれます。新しいボリュームのデータがソースボリュームと異なる状態になるまで、追加のストレージスペースは消費されません。ステージング目的でデータの複数のコピーが有用で、ストレージシステムでボリュームのプロビジョニングに使用できるリソースが限られている場合、開発環境やテンプレートベースの環境でよく使用されます。従来のストレージシステムではデータを何度もコピーする必要があるため、ストレージスペースや時間が大幅に消費されるため、NetApp FlexCloneテクノロジを使用するとストレージに依存するタスクを高速化できます。</block>
  <block id="66b43b8d36a821005edbb505f73e703f" category="image-alt">FlexCloneイメージ</block>
  <block id="b9ca5ba97cf75d3dafb51f78e073770a" category="inline-link">ネットアップのドキュメント</block>
  <block id="b9c059adc88329f807d19beff36c402c" category="paragraph">NetApp FlexCloneテクノロジの詳細については、のページを参照してください<block ref="26a4454b15f9e59c91953aae4d5cca61" category="inline-link-rx"></block>。</block>
  <block id="c2bdd689dbc313e32552cbc9e519673e" category="list-text">Red Hat OpenShift 4.6.8+、Rancher 2.5+、Kubernetes 1.19+などのサポートされるKubernetesディストリビューション。</block>
  <block id="17909bff47021a48534aa137533988cb" category="list-text">ネットアップアストラコントロールセンター21.12以降</block>
  <block id="f6e864ce20ae64f2d8e8d9788960ddcb" category="list-text">NetApp ONTAP システム。ネットアップのTrident経由でストレージバックエンドを設定します。</block>
  <block id="02de8f49568cea93a498f8b7b321a4e4" category="list-text">Ansible 2.9以降</block>
  <block id="0f466e306fc4825f1141ddc130ca599a" category="list-text">NetApp Astra Controlの管理対象アプリケーションとしてクローニングする環境用のテンプレート。</block>
  <block id="3e36385ca501623e48219eaf55547185" category="section-title">ユースケースの概要</block>
  <block id="c7af167d0f4082e772505e76bb547621" category="paragraph">このユースケースでは、次のワークフローのような情報が表示されます。</block>
  <block id="fc1fa3a113fd483da9a2a706cef62740" category="image-alt">ワークフローイメージ</block>
  <block id="3056a7af3144c13993f45fa84e78699e" category="list-text">ユーザがAnsibleプレイブックを実行して、新しいステージング環境を作成します。</block>
  <block id="c48538a3317fc98bc2fa8cf73553ca0b" category="list-text">Ansibleは、uri -APIモジュールを使用してAstra Controlに呼び出し、クローニング処理を実行します。</block>
  <block id="af27beb3ef227700c87619b941ef922d" category="list-text">Astra Controlは、プロビジョニング済みのテンプレート環境でクローニング処理を実行して、新しい管理対象アプリケーションを作成する。</block>
  <block id="afec891492c1e0c4d92776aa8fbb7a37" category="admonition">この環境は、開発中の単一のスタンドアロンアプリケーションである場合もあれば、Jenkins CI/CDパイプラインなどの開発環境全体である場合もあります。</block>
  <block id="b120622a84d96b41ece4bf14a2afc42c" category="list-text">次に'ユーザは'コードのバージョンを'Giteaなどのオンラインリポジトリからクローン開発環境にプルします</block>
  <block id="58b9c8dff15389cfc89079bed15b0353" category="list-text">新しいバージョンのアプリケーションは、NetApp Astra Controlによって導入および管理されます。</block>
  <block id="512473ae00b91f234459da9d54a73d63" category="admonition">どちらのプロセスも自動化できます。</block>
  <block id="45469e0108aa4b426d8e379bf3e01032" category="list-text">ユーザーは、このクローン環境で新しいコードを開発できます。</block>
  <block id="290324e3d59e2f7053c0f9e9e6e0efa3" category="list-text">ユーザーが開発作業に満足したら、ホストされているリポジトリにコードを戻すことができます。</block>
  <block id="30d4a5dfd238538be60a29a62c199938" category="paragraph">ここで紹介する使用事例は、クローンを作成する特定の環境またはアプリケーション用のゴールデンテンプレートの存在によって異なります。この環境では、ワードプレス展開用に、Magento展開用に、Giteaを持つJenkins CI/CD環境用に、DevToolsというタイトルの3つのテンプレートを作成しました。</block>
  <block id="c30f4e03a21fface6aa43659a4078d71" category="image-alt">テンプレートイメージ（Templates Image）</block>
  <block id="1107495525479f3871a68bae36a3f17b" category="paragraph">各環境はNetApp Astra制御によって管理され、ネットアップONTAP ストレージシステムに現在格納されている永続的ボリュームは、ネットアップAstra Tridentが提供するNFSバックエンドを使用している。</block>
  <block id="2ba3749d66f6540154024e19b4d99cc9" category="section-title">ユースケースの検証</block>
  <block id="7a73c2eecaec86daa9aee3eff521b699" category="list-text">ネットアップのソリューションエンジニアリングチームが提供するAnsibleツールキットをクローニングします。これには、クローニングのロールとアプリケーションの更新に関するプレイブックが含まれます。</block>
  <block id="6264ab91acf969dcae78c1602bca2059" category="list-text">'vars/clone_vars.yml'を編集し、Astra Control環境に適したグローバル値を入力します。</block>
  <block id="240e34a15ccbba0aea72efc21aaab86d" category="admonition">入力する必要があるグローバル環境値は、NetApp Astra ControlのAPIアクセスメニューにあるユーザプロファイルアイコンで確認できます。</block>
  <block id="f35821a1d6caaf6d90163620f4ea7458" category="image-alt">APIアクセスイメージ</block>
  <block id="25037aa69bc75f53a1077e99016fcb35" category="list-text">グローバル変数が完成したら、複製する特定のアプリケーションの値を選択できます。DevTools環境を'Alan - DevTools'という個人環境にクローンを作成するには'次の手順を実行します</block>
  <block id="3c88bcd7ff9904c39c203d75df0f43aa" category="admonition">クローン作成プロセスでNetApp FlexCloneテクノロジを活用するには'src-cluster'とdest-cluster'を同じにする必要があります</block>
  <block id="7701b76fd4e9f02523bba989b59e089f" category="list-text">プレイブックを実行してアプリケーションをクローニングできるようになりました。</block>
  <block id="b843fd904e687b09c9fea5652dd26835" category="admonition">記載されたプレイブックは、rootユーザ、またはsudoプロセスを介して「-K」引数を渡してエスカレーションできるユーザが実行する必要があります。</block>
  <block id="47261a281b6d461c0e208fcdd564b6ef" category="list-text">プレイブックの実行が完了すると、クローニングされたアプリケーションがAstra Control Centerコンソールに表示されます。</block>
  <block id="4ebfaaa8ab1aa4f1a8e1f0e4c080a066" category="image-alt">アプリイメージをクローニングしました</block>
  <block id="d7d808da7950a8d4bece269105013664" category="list-text">ユーザは、アプリケーションが導入されたKubernetes環境にログインし、アプリケーションが新しいIPアドレスで公開されていることを確認して、開発作業を開始できます。</block>
  <block id="ba87075b7677acd5c3798c45d5899095" category="paragraph">この使用例とアプリケーションのアップグレード例のデモについては、を参照してください <block ref="c3446aeb84c085acd211fbde68c1be91" category="inline-link-macro-rx"></block>。</block>
  <block id="a7f77f303480f7b7143a247c228eaebb" category="doc">Astra ControlとNetApp FlexCloneテクノロジでソフトウェア開発を高速化</block>
  <block id="2f1df67ff878abb3db18e3010bcc2920" category="paragraph">DevOpsワークフローの最も一般的な用途の1つは、継続的統合と継続的導入（CI / CD）パイプラインです。開発者が新しいコードをコミットする際に、アプリケーションでテストスイートの自動構築、統合、実行を行うことができます。通常、DevOpsエンジニアやサイト信頼性エンジニア（SRE）は、新機能の開発、回帰テスト、バグ修正、品質エンジニアリングなど、開発プロセスのさまざまな機能に特化したパイプラインを備えています。</block>
  <block id="1413f73ce604910297e839d41a24e9f9" category="paragraph">チームの自動化レベルが上がると、本番環境のアプリケーションの変化のペースが圧倒的に高まります。そのため、一部のチームは、本番環境のアプリケーションやサービスの保護を希望しています。コードおよびコンテナイメージを保護するだけでなく、アプリケーションの状態、構成データ（アプリケーションに関連付けられたKubernetesオブジェクトやリソースなど）、およびアプリケーションの永続データも保護したいと考えています。</block>
  <block id="8322f060ae0335cf0232ac3b55da6556" category="paragraph">このユースケースでは、まず新しいバージョンのアプリケーションをステージング環境に導入してから本番環境に導入する、本番への昇格パイプラインについて詳しく見ていきます。この例は、主要なパブリッククラウドとオンプレミス環境に同様に当てはまります。アプリケーションの1つのバージョンの展開を示していますが、パイプラインは、青/緑、カナリアデプロイメントなどの他の戦略でも使用できます。CI/CDパイプラインの一部として、アプリケーションの完全なバックアップを作成してアプリケーションを保護します。本番環境のアプリケーションと、そのデータ、状態、設定をアプリケーションに対応したバックアップでバックアップすると、多数のDevOpsワークフローに役立ちます。</block>
  <block id="13c258a59936aa47a4215b1c02921c7d" category="image-alt">ネットアップAstraを使用したDevOpsのユースケース1アーキテクチャ</block>
  <block id="fcd7f001e9274fdefb14bff91c799306" category="inline-link">Magento</block>
  <block id="0e8625d3981b9d26e0866da357d318c8" category="inline-link">NetApp Astra Control Python SDK</block>
  <block id="e5c0235557a0821c530e70a6ac76e817" category="paragraph">このユースケースの検証に使用したアプリケーションはです<block ref="ca8bdc27f15f815590190c112abb55a0" category="inline-link-rx"></block>は、Webベースのフロントエンドを備えたEコマース解決策 、検索および分析機能用のElasticsearchインスタンス、ショッピングインベントリとトランザクションの詳細をすべて追跡するMariaDBデータベースです。このコンテナ化されたアプリケーションは、Red Hat OpenShiftクラスタにインストールされました。アプリケーション内のすべてのポッドで、永続ボリュームを使用してデータを格納しました。永続ボリュームは、コンテナストレージインターフェイスに準拠したKubernetes向けストレージオーケストレーションツールであるNetApp Astra Tridentによって自動的に作成され、ネットアップストレージシステムでストレージをプロビジョニングできるようになりました。さらに、Astra Control Centerのアプリケーション保護機能を利用するために、問題のアプリケーションはAstra Controlによって管理されました。Astra Controlは、永続的ボリュームに保存されたデータとともに、アプリケーションの状態を保存したアプリケーションのバックアップをトリガするために使用されました。使用しました<block ref="d0b4b6e44937c3a38c218d58868f48cf" category="inline-link-rx"></block> アプリケーションのバックアップを開始するプロセスを自動化するために、CI / CDパイプラインに導入されました。このパイプラインは、という一般的なCI / CDツールを使用して作成、実行されました <block ref="2362760839a75356cff2ce591e8175c5" category="inline-link-rx"></block>]を選択すると、アプリケーションの構築、保護、導入のためのフローが自動化されます。</block>
  <block id="be6d35c56a8d9c9eda054648f5aaf778" category="paragraph">CI/CDパイプラインに保護機能を導入するための前提条件と手順 について説明します。</block>
  <block id="019b3399490601533f0c22df26617506" category="list-text">ネットアップのOpenShiftにTridentをインストールし、バックエンドからNetApp ONTAP システムを構成</block>
  <block id="32714d2e851023befd52d2dafcb3df12" category="list-text">NetApp ONTAP バックエンドをポイントするデフォルトのストレージクラスが設定されている</block>
  <block id="4feccdee8cd5d15c137a63228c1e8035" category="list-text">OpenShiftクラスタにNetApp Astraコントロールセンターをインストール</block>
  <block id="89a7002b85e3c07334367a744cb41016" category="list-text">OpenShiftクラスタをAstra Control Centerにマネージドクラスタとして追加</block>
  <block id="f485827022df06c2991a88b97eeb4e48" category="list-text">JenkinsをOpenShiftクラスタにインストールし、Dockerエンジンがインストールされたエージェントノードで構成します</block>
  <block id="e6b72ced375884adc1f139800a859ef1" category="section-title">アプリケーションをインストールしています</block>
  <block id="cd03481692ef65344c4dd7bf363bc056" category="paragraph">まず、ステージング環境と本番環境にアプリケーションを最初にインストールします。このユースケースでは、この手順が前提条件となるため、手動で実行します。CI / CDパイプラインは、アプリケーションの新しいバージョンリリースの結果として、以降のビルドおよび導入ワークフローに使用されます。</block>
  <block id="2ee68ca17059fe4d4ab06d0230bed0c3" category="paragraph">この使用事例の本番環境は「Magent-prod」という名前のネームスペースであり、対応するステージング環境はRed Hat OpenShiftクラスタ上で構成される「Magent-staging」という名前のネームスペースです。アプリケーションをインポートするには、次の手順を実行します。</block>
  <block id="05586ccfd2c7dbe7b3226b21240add7c" category="list-text">bitnami helmチャートを使用して、生産環境にMagentoアプリケーションをインストールします。ジェントポッドとMariaDBポッドにRWX PVSを使用します。</block>
  <block id="14224ce39d8587f380c4b992c668c24d" category="admonition">Magento bitnami Helmチャートには、Magento GUIサービスを公開するためのロードバランササービスが必要です。使用しました <block ref="6beef47e42ff9b3760535f361acb6931" category="inline-link-macro-rx"></block> この例では、オンプレミスのロードバランササービスを提供します。</block>
  <block id="4750ba228d6f73ce1e9d9e27f0cd2ca5" category="list-text">数分後に、すべてのポッドとサービスが実行されていることを確認します。</block>
  <block id="3a0715e577e143188e1e748efe2fca27" category="list-text">ステージング環境についても同じ手順 を繰り返します。</block>
  <block id="e684201cc94f2e04edf2353711b58fe5" category="section-title">Astra Control CenterでMagentoアプリケーションを管理します</block>
  <block id="e9758d5e82771fcca93395ce3a7c1d40" category="list-text">[アプリケーション]に移動し、[検出されたアプリケーション]タブを選択します。</block>
  <block id="082833c45c4a99b63cbf53365495e0d2" category="list-text">本番環境でMagentoアプリケーション(「Magent-prod`」)の省略記号をクリックし、「管理」をクリックします。</block>
  <block id="28a12dc4e9b29cb97bfaf36914e9983a" category="list-text">Magentoアプリケーションは、Astra Control Centerによって管理されるようになりました。Astra Controlでサポートされているすべての操作をアプリケーションで実行できます。アプリケーションのバージョンも記録します。</block>
  <block id="4ef629c07108e88861fc4036780e9a1f" category="image-alt">アップグレード前のMagentoバージョンチェック</block>
  <block id="c03f75891d5e0356b60d3752df0f0444" category="list-text">ステージング環境でMagentoアプリケーションを管理するための手順を繰り返します(「Magent-staging」)。</block>
  <block id="881e2f21543c210893e098f6383f4199" category="section-title">保護機能を統合したCI / CDパイプライン</block>
  <block id="841e01ce1d424839fd87eed89e1ce154" category="paragraph">新しいバージョンのアプリケーションを使用する場合は、CI / CDパイプラインを使用してコンテナイメージを作成し、ステージング環境と本番環境の両方のバックアップを作成し、新しいバージョンのアプリケーションをステージング環境に導入し、本番環境への昇格の承認を待ちます。 その後、新しいバージョンのアプリケーションを本番環境に導入します。CI / CDパイプラインを使用するには、次の手順を実行します。</block>
  <block id="88ba71f9d62d24eeb2decfe9cd30cfb1" category="list-text">Jenkinsにログインし、必要なクレデンシャルを作成します。Magento作成する場合は1つ、MariaDB管理作成する場合は1つ、MariaDBルート作成する場合は3つ目です。</block>
  <block id="9743ff34b00bc2d03fdc0b6ee11b0781" category="list-text">Manage Jenkins &gt; Manage Credentialsと進み、適切なドメインをクリックします。</block>
  <block id="5efc31d04501ec1bfbc5b2e785ac7cc2" category="list-text">[資格情報の追加]をクリックし、[種類]を[パスワードと有効範囲を使用するユーザー名]に設定して[グローバル]に設定します。ユーザー名、パスワード、および資格情報のIDを入力し、[OK]をクリックします。</block>
  <block id="5ff08be42358b0ed5a5235096ccfa397" category="image-alt">クレデンシャルの作成</block>
  <block id="ef7b482a4875dec8ec53a6a7ecea081b" category="list-text">他の2つのクレデンシャルについても同じ手順 を繰り返します。</block>
  <block id="955b68bae8db1bc3b2abbf6ada3710be" category="list-text">ダッシュボードに戻り、[新しいアイテム]をクリックしてパイプラインを作成し、[パイプライン]をクリックします。</block>
  <block id="027f0bd54326a6b14e6c7daf65d07f5c" category="list-text">Jenkinsfileからパイプラインをコピーします<block ref="94d69998dfd97a76d20ae02a64c629ae" category="inline-link-rx"></block>。</block>
  <block id="843730ff8981a034040c0f42fdaa48ce" category="list-text">Helmチャートバージョン、アップグレード先のMagentoアプリケーションバージョン、Astraツールキットバージョン、Astra Control Center FQDN、APIトークン、インスタンスIDなど、Jenkinsパイプラインのパラメータをそれぞれの詳細に入力します。本番環境とステージング環境の両方でDockerレジストリ、ネームスペース、MagentoのIPを指定し、作成したクレデンシャルのクレデンシャルIDも指定します。</block>
  <block id="3f52d6cbc878f43533503f2bd5a61952" category="list-text">[今すぐ構築]をクリックしますパイプラインが実行を開始し'ステップを進めますアプリケーションイメージは最初にビルドされ、コンテナレジストリにアップロードされます。</block>
  <block id="059d6fb9b965d0897c20fb2482659279" category="image-alt">パイプラインの進捗状況</block>
  <block id="ed2c1f4dfcf187d5140cf31e58801b4f" category="list-text">アプリケーションのバックアップは、Astra Controlを使用して開始します。</block>
  <block id="633d66eb7984b86ee4487b6a10ffc34a" category="image-alt">バックアップを開始しました</block>
  <block id="75b0ba1236c133f891fdd36b2e3913f3" category="list-text">バックアップステージが正常に完了したら、Astra Control Centerからのバックアップを確認します。</block>
  <block id="2b3a33094c5c31ac6cc6be770417a07c" category="image-alt">バックアップが完了しました</block>
  <block id="fec272abe380f3502ef64cbc2cc652bf" category="list-text">新しいバージョンのアプリケーションがステージング環境に展開されます。</block>
  <block id="4576032c05f55b22a040f067151cde6f" category="image-alt">ステージングによる導入が開始されました</block>
  <block id="4d4659ee9b2600243399d4aceca7c670" category="list-text">この手順が完了すると、ユーザが本番環境への導入を承認するまで待機します。この段階では、QAチームがいくつかの手動テストを実行し、本番環境を承認すると仮定します。次に、[承認]をクリックして、新しいバージョンのアプリケーションを本番環境に展開できます。</block>
  <block id="e30db45e8514d0d8f662187e28b8b5ec" category="image-alt">プロモーションを待っています</block>
  <block id="3a7b15850615e9fd306b379f77e0e016" category="list-text">本番アプリケーションが目的のバージョンにアップグレードされていることも確認します。</block>
  <block id="f11253856e2b859c46731353f46b732e" category="image-alt">本番アプリケーションがアップグレードされました</block>
  <block id="70817285f3f68722fd851dde7464feb2" category="paragraph">CI / CDパイプラインの一環として、アプリケーションに対応した完全なバックアップを作成してアプリケーションを保護できることを実証しました。アプリケーション全体が本番への昇格パイプラインの一部としてバックアップされているため、高度に自動化されたアプリケーションの導入について、自信を持って実行できます。アプリケーションのデータ、状態、設定を含むこのアプリケーション対応バックアップは、多数のDevOpsワークフローに役立ちます。予期しない問題が発生した場合は、アプリケーションの前のバージョンにロールバックすることが重要なワークフローとなります。</block>
  <block id="94ec4ad32f9ba408876eabf1a42f6901" category="paragraph">Jenkinsツールを使用してCI / CDワークフローをデモしましたが、コンセプトはさまざまなツールや戦略に簡単かつ効率的に外挿できます。このユースケースの実際の動作を確認するには、ビデオをご覧ください <block ref="2eda593691b1da530fed5bfcba32a663" category="inline-link-macro-rx"></block>。</block>
  <block id="b36bddb7c9d9a83be2a0353a3a744767" category="paragraph">ネットアップには、Astra TridentとAstra Controlで認定された複数のストレージプラットフォームがあり、コンテナ化されたアプリケーションのデータをプロビジョニング、保護、管理できます。</block>
  <block id="963b3936c1baa510ebca7a5496ece873" category="paragraph">ネットアップは、ステートフルなコンテナ化アプリケーションとそのデータのオーケストレーション、管理、保護、移行を支援するさまざまな製品を提供しています。</block>
  <block id="8a52e85b93902c27be7f0b5fa8493e52" category="paragraph">NetApp Astra Control は、ネットアップのデータ保護テクノロジを基盤とするステートフル Kubernetes ワークロード向けの充実したストレージサービスとアプリケーション対応データ管理サービスを提供します。Astra Control Service は、クラウドネイティブの Kubernetes 環境でステートフルワークロードをサポートするために利用できます。Astra Control Centerは、｛k8s_distribution_name｝などのエンタープライズKubernetesプラットフォームをオンプレミスで導入する場合に、ステートフルワークロードをサポートするために使用できます。詳細については、 NetApp Astra Control の Web サイトをご覧ください<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>。</block>
  <block id="6026755482efeb14efb7399db02c4e5e" category="paragraph">Astra Tridentは、コンテナやKubernetesディストリビューション向けの、完全にサポートされているオープンソースのストレージオーケストレーションツールです。｛k8s_distribution_name｝などが挙げられます。Trident は、 NetApp ONTAP や Element ストレージシステムを含むネットアップストレージポートフォリオ全体と連携し、 NFS 接続と iSCSI 接続もサポートします。Trident を使用すると、ストレージ管理者の手を煩わせることなく、エンドユーザがネットアップストレージシステムからストレージをプロビジョニングして管理できるため、 DevOps ワークフローが高速化されます。</block>
  <block id="0e60ae06a3d7bec5f8950d8ea76b57d4" category="paragraph">Tridentの最新バージョンは2022年4月に22.04にリリースされました。Trident のどのバージョンがサポートされているかを確認できます Kubernetes ディストリビューションのテストに使用<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>。</block>
  <block id="b453397e87e54278a4cd32ac644d5934" category="sidebar">パートナーソリューションについて</block>
  <block id="ff94fd25dea669a1eb9fc9bad5af5e80" category="sidebar">Red Hat OpenShiftのWebサイト</block>
  <block id="8cf2142329e586b4350d53a76071db82" category="sidebar">Anthos Webサイト</block>
  <block id="a5860a0f10641c9e31f8301d3f3ae548" category="sidebar">コンテナ向けリソースについて</block>
  <block id="e2ed9dce9d5bb40e79fc6d3008de22ff" category="sidebar">Anthos with NetAppの特長</block>
  <block id="500ce409f120039287d7670f42ff1821" category="sidebar">ネットアップでDevOpsを実現</block>
  <block id="59b5f97219239806c778ffff9bda8ad0" category="sidebar">ユースケースの検証</block>
  <block id="1a4f47ee7c7d8b59e68be952ac121268" category="sidebar">Anthosの高度な構成オプション</block>
  <block id="b0ed101b405f642695988c7ef3313b52" category="sidebar">アーカイブされたソリューション</block>
  <block id="9eb662185982de390339607d2ee459a4" category="summary">Google CloudのCloud Volumes Service は、さまざまな方法でデータをネイティブに保護します。</block>
  <block id="52aa20c1efa9dfeda78d72f4c056c23f" category="doc">Google CloudのCloud Volumes Service でデータを保護する方法</block>
  <block id="c0db72d078098472051229dbdb83118e" category="inline-link-macro">前へ：概要。</block>
  <block id="78dad9c3bba77d55493b24502dbe6a1d" category="paragraph"><block ref="78dad9c3bba77d55493b24502dbe6a1d" category="inline-link-macro-rx"></block></block>
  <block id="9967209a1408f78f781d93dd0cdf88c4" category="section-title">セキュアなアーキテクチャとテナンシーモデル</block>
  <block id="9ba9e0f1cce71f64d3188bfdc502a43d" category="inline-link-macro">「Cloud Volumes Service アーキテクチャ」</block>
  <block id="33186704f78f73f32736a9ba7f8ddc85" category="inline-link">プライベートサービスへのアクセス</block>
  <block id="5971da0242ce7b616ff2972978613cef" category="inline-link-macro">「テナンシーモデル」</block>
  <block id="01760cb04e3a4a93404ab2c878b036db" category="inline-link-macro">「共有VPC」</block>
  <block id="e70da8f06ec706ed45906f411481eda0" category="paragraph">このアーキテクチャでは、テナント（セクションを参照） <block ref="0a088dd892133b6a77304655c2b8b829" category="inline-link-macro-rx"></block>）は、ユーザーが明示的に接続していない限り、互いに完全に分離されたGoogle Cloudプロジェクトとして定義されます。テナントを使用すると、Cloud Volumes Service ボリュームプラットフォームを使用して、データボリューム、外部ネームサービス、その他の重要な解決策 を他のテナントから完全に分離できます。Cloud Volumes Service プラットフォームはVPCピアリングを通じて接続されるため、その分離環境 も接続されます。共有VPCを使用して、複数のプロジェクト間でのCloud Volumes Service ボリュームの共有を有効にすることができます（を参照） <block ref="c2426c8c5bcdce9adb82a8906c5a3478" category="inline-link-macro-rx"></block>）。SMB共有およびNFSエクスポートにアクセス制御を適用することで、データセットを表示または変更できるユーザまたはユーザを制限できます。</block>
  <block id="35a0e1620a03f33da8739635aaa3b607" category="section-title">コントロールプレーンの強力なアイデンティティ管理</block>
  <block id="4504de40d15959838801111af31d224e" category="inline-link">IDアクセス管理（IAM）</block>
  <block id="d242c9a4fc4e118d87391841845ef44b" category="paragraph">Cloud Volumes Service 構成が行われるコントロールプレーンでは、を使用してアイデンティティ管理を管理します<block ref="490163f8d94b8a8397824811fb91c5ec" category="inline-link-rx"></block>。IAMは、Google Cloudプロジェクトインスタンスに対する認証（ログイン）と許可（権限）を制御できる標準サービスです。すべての設定は、TLS 1.2暗号化を使用したセキュアなHTTPS転送を介してCloud Volumes Service APIで実行され、セキュリティを強化するためにJWTトークンを使用して認証が実行されます。Cloud Volumes Service 用のGoogleコンソールUIは、ユーザ入力をCloud Volumes Service API呼び出しに変換します。</block>
  <block id="688247a9da881160b1073a4b76442640" category="section-title">セキュリティ強化-攻撃面の制限</block>
  <block id="4901056002c8d64da3b67da6a5a2dbbb" category="paragraph">効果的なセキュリティの一部は、サービスで使用できる攻撃対象の数を制限することです。攻撃対象には、保管データ、転送中転送、ログイン、データセット自体など、さまざまなものが含まれます。</block>
  <block id="733e720a346376b07eb9adac497c4063" category="inline-link-macro">"サービスオペレーション"</block>
  <block id="aa6187208cb06e0a43851ee1783a370c" category="paragraph">マネージドサービスを使用すると、本質的に設計上の攻撃対象の一部が削除されます。の説明に従って、インフラストラクチャ管理を行います <block ref="ddbc8ce5f4099ff7254959018f566688" category="inline-link-macro-rx"></block> は専用チームによって処理され、人間が実際に構成に触れる回数を減らすために自動化されます。これにより、意図的なエラーや意図しないエラーの数を減らすことができます。必要なサービスだけが互いにアクセスできるように、ネットワークは遮断されます。暗号化はデータストレージに組み込まれており、Cloud Volumes Service 管理者はデータプレーンだけにセキュリティ上の注意を払う必要があります。APIインターフェイスの背後にあるほとんどの管理を隠すことで、攻撃対象を制限することでセキュリティを実現します。</block>
  <block id="d8d81a048343e815b76f916e1c58e636" category="section-title">ゼロトラストモデル</block>
  <block id="d2c4e1022fc22d0780bd913d3f16498e" category="paragraph">ITセキュリティの考え方は、これまでは信頼されていましたが、その信頼性は確認されており、脅威を軽減するために外部メカニズム（ファイアウォールや侵入検知システムなど）のみに依存していることが明示されてきました。しかし、攻撃や侵害は、フィッシング、ソーシャルエンジニアリング、内部の脅威など、ネットワークに侵入したり破壊的になったりするための検証を提供する方法によって、環境内での検証をバイパスするように進化しています。</block>
  <block id="853f80d22a64d4fff24c05d305e800a8" category="paragraph">ゼロ・トラストは、セキュリティの新しい方法論になりました。現在のテーマは「すべてを検証しながらは何も信頼しない」です。 したがって、デフォルトではアクセスは許可されません。この問題は、標準ファイアウォールや侵入検知システム（IDS）など、さまざまな方法で実施されています。また、次の方法も適用されています。</block>
  <block id="d07f4106373448c16aedf0c01749e560" category="list-text">強力な認証方法（AESで暗号化されたKerberosトークンやJWTトークンなど）</block>
  <block id="4bbee6cac6b31b494ade66a9fc2f16e7" category="list-text">単一の強力なアイデンティティソース（Windows Active Directory、Lightweight Directory Access Protocol（LDAP）、Google IAMなど）</block>
  <block id="da31693a70531052458cd4eff104672d" category="list-text">ネットワークのセグメント化とセキュアマルチテナンシー（デフォルトではテナントのみにアクセス可能）</block>
  <block id="a8ce5780cff146b27ae2c2b3fddc0447" category="list-text">最小限の権限付きアクセスポリシーで詳細なアクセス制御を実現します</block>
  <block id="493f70c348ea51d5c7cb8a28593df5a1" category="list-text">デジタル監査と紙の記録を使用した、信頼できる専任管理者の限定リスト</block>
  <block id="fd5070ec3e2f12398e4de9b77b900cbf" category="paragraph">Google Cloudで実行されているCloud Volumes Service は、「何も信用しない、すべてを検証する」というスタンスを実装することで、ゼロトラストモデルに準拠しています。</block>
  <block id="d7f2615c71a1567cc13cf3a7f7de0aea" category="section-title">暗号化</block>
  <block id="83c3a5400dd4f14665a803a22add4a9d" category="inline-link-macro">「保存データの暗号化」</block>
  <block id="a37154afafe65368d5170741a4669261" category="inline-link-macro">「SMB暗号化」</block>
  <block id="e688fd1eb8866f914263d3493c30ccbb" category="inline-link-macro">「リージョン間レプリケーション」</block>
  <block id="c05431edaaaefc20b48a7cd96f110e5d" category="inline-link-macro">「転送中のデータ暗号化」</block>
  <block id="48aa29a35d8e13e796333876f4ea9f62" category="inline-link-macro">「Google Cloudネットワーク」</block>
  <block id="31d64d3cd8b2a692701b32dd6a611c76" category="paragraph">保存データを暗号化する（を参照） <block ref="ce3046d8bb0cfdf8a89295f31068c29b" category="inline-link-macro-rx"></block>）転送には、NetApp Volume Encryption（NVE）および転送中のXTS-AES-256暗号を使用します <block ref="9963d74c8d0d381d9818a5c550dd7163" category="inline-link-macro-rx"></block> またはNFS Kerberos 5pをサポート。リージョン間レプリケーションの転送はTLS 1.2暗号化で保護されているので、安心して実行できます（を参照） <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>）。さらに、Googleネットワークは暗号化された通信も提供します（を参照） <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block>）を使用してください。転送暗号化の詳細については、を参照してください <block ref="0e3bb83173de6418179f08aaa25b48dd" category="inline-link-macro-rx"></block>。</block>
  <block id="db57ea7882be0cb73c78bf1ba25a6823" category="section-title">データ保護とバックアップ</block>
  <block id="48b5832efbf50440742eee7bfd02733b" category="inline-link-macro">Cloud Volumes Service バックアップ</block>
  <block id="cdb185875636a141b69ddabde6df7040" category="paragraph">セキュリティとは、攻撃の防御だけではありません。また、攻撃が発生した場合や発生した場合にどのように復旧するかについても説明します。この戦略には、データ保護とバックアップが含まれます。Cloud Volumes Service には、システム停止時に他のリージョンにレプリケートする方法が用意されています（を参照） <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>）またはデータセットがランサムウェア攻撃の影響を受ける場合。を使用して、Cloud Volumes Service インスタンス以外の場所へのデータの非同期バックアップを実行することもできます <block ref="92f2015a7a07a74ffc21a27b08fadbb0" category="inline-link-macro-rx"></block>。定期的なバックアップにより、セキュリティイベントの緩和にかかる時間を短縮し、管理者にとってコストと不安を軽減できます。</block>
  <block id="3b0aab94fdc89c539c78fcbbf0190080" category="section-title">業界をリードするSnapshotコピーでランサムウェアを迅速に軽減</block>
  <block id="e7d51c7f9901730a4f176b908516d9f0" category="inline-link-macro">「不変のSnapshotコピー」</block>
  <block id="613542b40dc5d23e9b7129726e6901e9" category="inline-link-macro">「サービスオペレーション」</block>
  <block id="06646d879e1be0df7191f42262dc1293" category="paragraph">Cloud Volumes Service では、データ保護とバックアップに加えて、書き換え不可のSnapshotコピーもサポートしています（を参照） <block ref="46dfee0c3fc63af00a088b428ebe2c09" category="inline-link-macro-rx"></block>）ランサムウェア攻撃からのリカバリを可能にするボリューム（を参照） <block ref="f545e9c9b1aa4e21f947ee53ac36de63" category="inline-link-macro-rx"></block>）問題 を検出してから数秒以内に、システム停止を最小限に抑えることができます。リカバリ時間と影響はSnapshotスケジュールによって異なりますが、ランサムウェア攻撃ではわずか1時間の差分しか提供しないSnapshotコピーを作成できます。Snapshotコピーは、パフォーマンスや容量使用率にほとんど影響を与えず、データセットを保護するリスクが低く、効果も高くなります。</block>
  <block id="f21f1562468eeb7bb67162f8fc79596c" category="inline-link-macro">次に、セキュリティに関する考慮事項と攻撃対象を示します。</block>
  <block id="d6cb5b8910b7e61e1d2a16900dff7414" category="paragraph"><block ref="d6cb5b8910b7e61e1d2a16900dff7414" category="inline-link-macro-rx"></block></block>
  <block id="9b6e8c1f1a4d79991136cfd2b3fde77a" category="summary">Cloud Volumes Service を使用すると、SMBユーザとUNIXユーザのIDを管理するために、Cloud Volumes Service インスタンスを外部のActive Directoryサーバに接続できます。Cloud Volumes Service でSMBを使用するには、Active Directory接続を作成する必要があります。</block>
  <block id="d099e6eafff98e1042c1029849e2db1b" category="doc">Active Directory接続の作成に関する考慮事項</block>
  <block id="1ca3bc7ee6e687110fa43103bcff28e9" category="inline-link-macro">以前のバージョン：デュアルプロトコル/マルチプロトコル</block>
  <block id="90e9716dfe1097d996980af0b2d435b6" category="paragraph"><block ref="90e9716dfe1097d996980af0b2d435b6" category="inline-link-macro-rx"></block></block>
  <block id="b092138563f7b68473c3bf2a6a23a434" category="inline-link">プライベート Google アクセス</block>
  <block id="dd1f65c08f03e8278da92a88b4c609b5" category="inline-link">Google CloudでActive Directoryを使用する際のベストプラクティス</block>
  <block id="758d9a1746e1f53cf6e7882ed864c1a4" category="paragraph">この構成には、セキュリティについて考慮する必要があるいくつかのオプションがあります。外部Active Directoryサーバは、オンプレミスインスタンスでもクラウドネイティブでもかまいません。オンプレミスのActive Directoryサーバを使用している場合は、ドメインを外部ネットワーク（DMZや外部IPアドレスなど）に公開しないでください。代わりに、を使用して、セキュアなプライベートトンネルまたはVPN、一方向フォレストトラスト、またはオンプレミスネットワークへの専用ネットワーク接続を使用します<block ref="76bc9bf9d2d87bee997fb1ade7da1eaa" category="inline-link-rx"></block>。詳細については、Google Cloudのドキュメントを参照してください<block ref="28831e2b31059cd3ce2ee26e8b5c8fcf" category="inline-link-rx"></block>。</block>
  <block id="22900d9fe4089ff2f29ada31dfd82836" category="admonition">CVS-SWを使用するには、Active Directoryサーバを同じリージョンに配置する必要があります。CVS-SWで別の地域へのDC接続を試みた場合、試行は失敗します。CV-SWを使用する場合は、Active Directory DCを含むActive Directoryサイトを作成し、Cloud Volumes Service でサイトを指定して、リージョン間のDC接続の試行を回避してください。</block>
  <block id="9f69695f33b67147c3fd64e477aa784b" category="section-title">Active Directoryのクレデンシャル</block>
  <block id="2ae640f39e0e652f621ec44b74e57892" category="paragraph">NFS用のSMBまたはLDAPが有効な場合、Cloud Volumes Service はActive Directoryコントローラと通信して、認証に使用するマシンアカウントオブジェクトを作成します。これは、Windows SMBクライアントがドメインに参加する方法とまったく異なり、Active Directoryの組織単位（OU）への同じアクセス権を必要とします。</block>
  <block id="d5b16e2c41dd06274f88cd52182d8034" category="paragraph">多くの場合、セキュリティグループでは、Cloud Volumes Service などの外部サーバでWindows管理者アカウントを使用できません。場合によっては、セキュリティのベストプラクティスとして、Windows Administratorユーザが完全に無効になっていることもあります。</block>
  <block id="e33d961644188dff361a3a61603aee23" category="section-title">SMBマシンアカウントの作成に必要な権限</block>
  <block id="7274d74c9decfd509d3c2a9c91098fca" category="inline-link">マシンアカウントオブジェクトを作成および変更する権限を委譲しました</block>
  <block id="da90c2a52e7d047f641621a25fcd43c7" category="paragraph">Cloud Volumes Service マシンオブジェクトをActive Directoryに追加するには、ドメインに対する管理者権限を持つアカウント、またはが必要です<block ref="39a1d8c5f0c0a4ae053b3e24111592ed" category="inline-link-rx"></block> 指定したOUに移動する必要があります。Active Directoryの制御の委任ウィザードでこれを行うには、次のアクセス権限を持つコンピュータオブジェクトの作成/削除へのユーザーアクセスを提供するカスタムタスクを作成します。</block>
  <block id="db3317ceb65be02e43db6f277e0ad94e" category="list-text">読み取り / 書き込み</block>
  <block id="9da76760248a4997f94bdd63f1c04f01" category="list-text">すべての子オブジェクトを作成/削除します</block>
  <block id="858ac25470b9539b8e2bb4d6958fde5b" category="list-text">すべてのプロパティの読み取り/書き込み</block>
  <block id="e798906fb7bcd7b0403d97d21044e339" category="list-text">パスワードの変更/リセット</block>
  <block id="4eb6bcf48028313e542c0964c09b46b9" category="paragraph">これにより、定義済みのユーザのセキュリティACLがActive DirectoryのOUに自動的に追加され、Active Directory環境へのアクセスが最小限に抑えられます。ユーザを委任した後、そのユーザ名とパスワードをActive Directoryクレデンシャルとしてこのウィンドウに入力できます。</block>
  <block id="66d939bc6b363153976bbd24624850b8" category="admonition">Active Directoryドメインに渡されるユーザ名とパスワードは、マシンアカウントオブジェクトのクエリおよび作成時にKerberos暗号化を利用してセキュリティを強化します。</block>
  <block id="8575c9ec9ca166098f9d546c3c12e9b1" category="section-title">Active Directory接続の詳細</block>
  <block id="452740f6c26f32def386962441d5cb2c" category="inline-link">Active Directory接続の詳細</block>
  <block id="af31d4ab1f284e1f94d3522fd1fa36fe" category="paragraph">。<block ref="9255123c1378b2d08be170075ba389b5" category="inline-link-rx"></block> 管理者がマシンアカウントの配置に関する特定のActive Directoryスキーマ情報を指定するためのフィールドを指定します。次に例を示します。</block>
  <block id="353000b4dd170de2ebede38bb7420e40" category="list-text">* Active Directory接続タイプ。リージョン内のActive Directory接続を、Cloud Volumes Service またはCVS -パフォーマンスサービスタイプのボリュームに使用するかどうかを指定するために使用します。既存の接続で正しく設定しないと、使用または編集時に正しく機能しないことがあります。</block>
  <block id="d5cc4c55027c65e3b8d52c15d308935d" category="list-text">*ドメイン。* Active Directoryドメイン名。</block>
  <block id="c3fab9d188d8e1e4a9e0ba27a52306c6" category="inline-link">考慮事項</block>
  <block id="925e235ec5866cd9c094261d9e20eec4" category="list-text">*サイト。* Active Directoryサーバを特定のサイトに制限して、セキュリティとパフォーマンスを確保します<block ref="cae534855afa8eaefaa37d26edea88d5" category="inline-link-rx"></block>。Cloud Volumes Service では現在、Cloud Volumes Service インスタンスとは別のリージョンにあるActive Directoryサーバへの認証要求の許可がサポートされていないため、複数のActive Directoryサーバがリージョンにまたがっている場合は、この設定が必要です。（たとえば、Active DirectoryドメインコントローラはCVS -パフォーマンスのみがサポートするリージョンにありますが、CVS - SWインスタンスにSMB共有が必要です）。</block>
  <block id="bc3a6531a92e21b83c95f7d7044fd498" category="list-text">* DNSサーバ。*名前検索で使用するDNSサーバ。</block>
  <block id="44ea07387884d17ba7d18393d327374b" category="inline-link-macro">Active DirectoryでのCloud Volumes Service の表示</block>
  <block id="32b5af659fee51ef98e34710303d53ba" category="list-text">* NetBIOS名（オプション）。*必要に応じて、サーバのNetBIOS名。これは、Active Directory接続を使用して新しいマシンアカウントを作成するときに使用されます。たとえば、NetBIOS名がCVS - Eastに設定されている場合、マシンアカウント名はCVS - East -｛1234｝になります。を参照してください <block ref="0bba591d00c255586e052c023629a690" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="00a4c212426e322a34af5aeccdc494f7" category="list-text">*組織単位(OU)。*コンピュータアカウントを作成するための特定のOU。この機能は、マシンアカウントの制御を特定のOUに委任する場合に便利です。</block>
  <block id="06852342816b885474a42d89311e2113" category="list-text">*AES暗号化。*AD認証用AES暗号化を有効にするチェックボックスをオンまたはオフにすることもできます。Active Directory認証用のAES暗号化を有効にすると、ユーザとグループの検索時にCloud Volumes Service からActive Directoryへの通信がセキュリティで保護されます。このオプションを有効にする前に、ドメイン管理者に問い合わせて、Active DirectoryドメインコントローラがAES認証をサポートしていることを確認してください。</block>
  <block id="7d51d6a8b37a2763f6c84b7b3a3a7e97" category="admonition">デフォルトでは、ほとんどのWindowsサーバで弱い暗号（DESやRC4-HMACなど）は無効になりませんが、弱い暗号を無効にするように選択した場合は、Cloud Volumes Service Active Directory接続がAESを有効にするように設定されていることを確認してください。そうしないと、認証エラーが発生します。AES暗号化を有効にしても弱い暗号は無効になりませんが、Cloud Volumes Service SMBマシンアカウントにAES暗号のサポートが追加されます。</block>
  <block id="3da975567fcd6ebd164f43cca13384f2" category="section-title">Kerberos Realmの詳細</block>
  <block id="9a62ab6b4d79a99749d02cd8af945f25" category="paragraph">このオプションはSMBサーバには適用されません。Cloud Volumes Service システムでNFS Kerberosを設定するときに使用されます。これらの詳細を入力すると、NFS Kerberos Realmが設定され（Linuxではkrb5.confファイルと同様）、Cloud Volumes Service ボリュームの作成時にNFS Kerberosが指定されている場合にActive Directory接続がNFS Kerberos Distribution Center（KDC；Kerberos配布センター）として機能するために使用されます。</block>
  <block id="e53ab7e80d5d436b4a496f0c2bef7cb2" category="admonition">現在、Windows以外のKDCはCloud Volumes Service との使用でサポートされていません。</block>
  <block id="f447ac856e7e72435904956e3b15f433" category="section-title">地域</block>
  <block id="38da42463bdc613d24159bd6e0405ba6" category="paragraph">リージョンを使用すると、Active Directory接続が存在する場所を指定できます。このリージョンはCloud Volumes Service ボリュームと同じである必要があります。</block>
  <block id="4dfb982db9679a6eec578ccd86af978a" category="list-text">*このセクションでは、LDAPを使用するローカルNFSユーザを許可するオプションもあります。*このセクションでは、LDAPを使用するローカルNFSユーザを許可するオプションもあります。NFS（拡張グループ）の16グループの制限を超えてUNIXユーザグループメンバーシップのサポートを拡張する場合は、このオプションを選択しないでください。ただし、拡張グループを使用するには、UNIX ID用のLDAPサーバを設定する必要があります。LDAPサーバがない場合は、このオプションを選択しないでください。LDAPサーバがあり、ローカルUNIXユーザ（rootなど）も使用する場合は、このオプションを選択します。</block>
  <block id="5059a39455b0e2649d69d289516cdf1b" category="section-title">バックアップユーザ</block>
  <block id="0e051a51493712b34966f346e858a0c3" category="inline-link">そのユーザアクセスの監査を有効にします</block>
  <block id="d3980aa1c5f0625161c9b0fb5a6cace0" category="paragraph">このオプションを使用すると、Cloud Volumes Service ボリュームに対するバックアップ権限を持つWindowsユーザを指定できます。一部のアプリケーションでNASボリュームのデータを正しくバックアップおよびリストアするには、バックアップ権限（SeBackupPrivilege）が必要です。このユーザにはボリューム内のデータへのアクセスレベルが高いため、考慮する必要があります<block ref="b5fba80299f6d29935863b6604a98277" category="inline-link-rx"></block>。有効にすると、Event Viewer &gt; Windows Logs &gt; Securityに監査イベントが表示されます。</block>
  <block id="70136e0b9257bc91e1eb5216b32580de" category="paragraph"><block ref="70136e0b9257bc91e1eb5216b32580de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6833e65d65b96c0d79b7fc114c9a2968" category="section-title">セキュリティ権限ユーザ</block>
  <block id="63a19a4d390181634079ba6ba20fe287" category="inline-link">たとえば、SQL Serverなどです</block>
  <block id="c9a97779c6062109c66675cc5368a6b8" category="inline-link">ユーザのユーザアクセスを監査する</block>
  <block id="296bdd6f36456d0f48d21431f3bd7853" category="paragraph">このオプションを使用すると、Cloud Volumes Service ボリュームに対するセキュリティの変更権限を持つWindowsユーザを指定できます。一部のアプリケーションにはセキュリティ権限（SeSecurityPrivilege）が必要です <block ref="cef5278acd430b226f8e7bcad71f9075" category="inline-link-rx"></block>)を使用して、インストール時に権限を適切に設定します。この権限は、セキュリティログを管理するために必要です。この権限はSeBackupPrivilegeほど強力ではありませんが、ネットアップでは推奨しています<block ref="2238ada9972b35c5f01addc7598ffd7a" category="inline-link-rx"></block> 必要に応じて、この権限レベルで設定します。</block>
  <block id="f044d72e46ac4189129dc6e27333c449" category="inline-link">新しいログオンに割り当てられた特別な権限</block>
  <block id="1384ec27890f8bac59aae8edf1ff83e9" category="paragraph">詳細については、を参照してください<block ref="791e82319c9cb432525cbf92f3a07623" category="inline-link-rx"></block>。</block>
  <block id="3fc6256a9aed6803167ff54873f78a00" category="paragraph">Active Directoryでは、通常のマシンアカウントオブジェクトとしてCloud Volumes Service が表示されます。命名規則は次のとおりです。</block>
  <block id="864917f152404280b59cd43c564f6733" category="list-text">CIFS/SMBおよびNFS Kerberosでは、個別のマシンアカウントオブジェクトが作成されます。</block>
  <block id="79adcd3b0eb62b997e160c91e737deb2" category="list-text">NFSでLDAPが有効になっている場合、Kerberos LDAPバインド用にActive Directoryにマシンアカウントが作成されます。</block>
  <block id="2ed35f8c3fa643ff6b7226a2163085c5" category="list-text">LDAPを使用したデュアルプロトコルボリュームでは、LDAPとSMBのCIFS / SMBマシンアカウントが共有されます。</block>
  <block id="3028cc04aacef3f671388051ac5a05cf" category="list-text">CIFS / SMBマシンアカウントでは、マシンアカウントの名前付け規則として、name-1234（ランダムな4桁のIDに10文字未満の名前をハイフンで付加）を使用します。Active Directory接続では、NetBIOS名の設定で名前を定義できます（「」を参照）<block ref="7d2ad38c1c26cdc0446a7f473a720f92" category="inline-xref-macro-rx"></block>」）をクリックします。</block>
  <block id="b3330aabe270fd3b52fec421dc299283" category="list-text">NFS Kerberosでは、命名規則としてnfs-name-1234を使用します（最大15文字）。15文字を超える文字が使用されている場合、名前はnfs-truncated-name-1234になります。</block>
  <block id="50b0fcc303b033d01b24dbb96023de81" category="list-text">NFSのみのCVS - LDAPが有効なパフォーマンスインスタンスは、CIFS / SMBインスタンスと同じ命名規則を使用してLDAPサーバにバインドするためのSMBマシンアカウントを作成します。</block>
  <block id="d4895b82fd7385bed173b438d89c807e" category="inline-link-macro">「デフォルトの非表示共有」</block>
  <block id="6d7a9f810c1df414bda9e341201f414b" category="list-text">SMBマシンアカウントを作成すると、デフォルトの非表示の管理共有が表示されます（を参照） <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>）も作成されます（c$、admin$、ipc$）が、ACLが割り当てられておらず、アクセスできない共有です。</block>
  <block id="e1547130d9a70017a557e263270469eb" category="list-text">マシンアカウントオブジェクトはデフォルトではCN=Computersに配置されますが、必要に応じて別のOUを指定できます。「」を参照してください<block ref="99b866e46eaefba106810f4a564a9de4" category="inline-xref-macro-rx"></block>「Cloud Volumes Service のマシンアカウントオブジェクトを追加または削除するために必要なアクセス権については、を参照してください。</block>
  <block id="5a1324cda45cd652ecb95755709fd8e1" category="paragraph">Cloud Volumes Service によってSMBマシンアカウントがActive Directoryに追加されると、次のフィールドが設定されます。</block>
  <block id="650ca2f93573bbd3b4e7f2e4fc5d536e" category="list-text">CN（指定したSMBサーバ名を使用）</block>
  <block id="493629591f73624fd57b9ff00cb6d94e" category="list-text">dNSHostName（SMBserver.domain.comを使用）</block>
  <block id="ed877e9b9c0c0bb19ecf1f342cdda00f" category="list-text">msDs-SupportedEncryptionTypes（AES暗号化が有効でない場合は、DES-CBC_MD5、RC4_HMAC_MD5を許可します。AES暗号化が有効の場合は、DES-CBC_MD5、RC4_HMAC_MD5、AES128_CTS_HMAC_SHA1、AES256_CTC_HMAC_SHA1 96を許可します）</block>
  <block id="987e945fa65d0a9e76f890e3892961cc" category="list-text">名前（SMBサーバ名を使用）</block>
  <block id="6c4b390273352496044f436350e3e996" category="list-text">sAMAccountName（SMBserver$を使用）</block>
  <block id="603c37960edbea70b7dd05f369016869" category="list-text">servicePrincipalName（Kerberosのホスト/ smbserver.domain.comおよびホスト/ smbserver SPNを使用）</block>
  <block id="e4d5beb18aee5989e4944d5f91b181e4" category="paragraph">マシンアカウントで弱いKerberos暗号化タイプ(enctype)を無効にする場合は、マシンアカウントのmsDS-SupportedEncryptionTypes値を次の表のいずれかの値に変更してAESのみを許可することができます。</block>
  <block id="d7b35b0eb85a800cd27ae4d86378e957" category="cell">msDs-SupportedEncryptionTypesの値</block>
  <block id="b20e97401d06f2734903c9c8ce3bd34e" category="cell">暗号化タイプが有効です</block>
  <block id="3afb17e90ee63072dfd4ad5496e22ecf" category="cell">des_cbc_md5</block>
  <block id="427e6bbc6e437e1008a5c41adc923d0e" category="cell">RC4_HMAC</block>
  <block id="16105c1a0d76dfdb5c1df287b56762db" category="cell">AES128_CTS_HMAC_SHA1 96のみ</block>
  <block id="bdacd7093a31449b44a8d708a5a055de" category="cell">AES256_CTS_HMAC_SHA1_96のみ</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="ea8f561ef42d9f42f97782208f239797" category="cell">AES128_CTS_HMAC_SHA1_96およびAES256_CTS_HMAC_SHA1_96です</block>
  <block id="34173cb38f07f89ddbebc2ac9128303f" category="cell">30</block>
  <block id="bbfe7622403fb2a786b158ba768ac4ca" category="cell">DES_CBC_MD5、RC4_HMAC、AES128_CTS_HMAC_SHA1 96およびAES256_CTS_HMAC_SHA1 96</block>
  <block id="adfa4c5560980c9b2841dda24bda5935" category="paragraph">SMBマシンアカウントのAES暗号化を有効にするには、Active Directory接続の作成時にAD認証のAES暗号化を有効にするをクリックします。</block>
  <block id="fd0625de17999274e1465433cabc43a7" category="inline-link">Cloud Volumes Service のドキュメントを参照してください</block>
  <block id="9e167fdd1e36cc753653d71cef598f95" category="paragraph">NFS KerberosのAES暗号化を有効にするには、<block ref="a1ea73992eb480d81ba9d6fd0002e272" category="inline-link-rx"></block>。</block>
  <block id="c36c6a3451be9921bddbe958fc50f971" category="inline-link-macro">次の手順：その他のNASインフラストラクチャサービスの依存関係（KDC、LDAP、DNS）。</block>
  <block id="0a243881b9403f37a34293a498b9dcb8" category="paragraph"><block ref="0a243881b9403f37a34293a498b9dcb8" category="inline-link-macro-rx"></block></block>
  <block id="5e64a4b25a4f107aefb7d4e2a56b9dfb" category="summary">NAS共有にCloud Volumes Service を使用する場合は、正常に機能するために外部との依存関係が必要になることがあります。これらの依存関係は、特定の状況下で有効になっています。</block>
  <block id="f4b5e0cbc9d84ca994a4dc85d6f45205" category="doc">その他のNASインフラストラクチャサービスの依存関係（KDC、LDAP、およびDNS）</block>
  <block id="619169033066c83ff7d1cc580d748cd6" category="inline-link-macro">前の手順：Active Directory接続を作成する際の考慮事項</block>
  <block id="a67d66e488b843722a2bb6124e92d2c0" category="paragraph"><block ref="a67d66e488b843722a2bb6124e92d2c0" category="inline-link-macro-rx"></block></block>
  <block id="c4c97073fa9e6d604787db13592331a3" category="paragraph">NAS共有にCloud Volumes Service を使用する場合は、正常に機能するために外部との依存関係が必要になることがあります。これらの依存関係は、特定の状況下で有効になっています。次の表に、さまざまな設定オプションと、必要な依存関係を示します。</block>
  <block id="c9b3a27f085427ada9b946daa430f1f8" category="cell">必須の依存関係です</block>
  <block id="954898296a4e7ec7e15ab65964b50da0" category="cell">NFSv3のみ</block>
  <block id="e69d896f8231ad7dd96dd4937ba18d07" category="cell">NFSv3 Kerberosのみ</block>
  <block id="6040c1d5c15727690384a7cd3e8d3fa4" category="cell">Windows Active Directory：* KDC * DNS * LDAP</block>
  <block id="b88d0e1e32f67294d9d45e05a25495e7" category="cell">NFSv4.1のみ</block>
  <block id="1cc44815edb1648976dd6fa410f26802" category="cell">クライアントIDマッピング設定（/etc/idmap.conf）</block>
  <block id="c2e2e93edfc9ea6acddd551b71be27bf" category="cell">NFSv4.1 Kerberosのみ</block>
  <block id="411c501ecf4d59f4ef8d7e9c444b838a" category="list-text">Windows Active Directory：KDC DNS LDAP</block>
  <block id="59b6dd4c5b36405b29c64750f1e82401" category="cell">SMBのみ</block>
  <block id="11a431c64d07fefe0bbb5880e03069c5" category="cell">Active Directory：* KDC * DNS</block>
  <block id="420da7f0cb45485c925482687369c1ad" category="cell">マルチプロトコルのNAS（NFSおよびSMB）</block>
  <block id="b756e6f6a894749273e32e03e551180c" category="list-text">クライアントIDマッピングの設定（NFSv4.1のみ、/etc/idmap.conf）</block>
  <block id="8777a112bd8b1e9205dda0717a12965b" category="section-title">マシンアカウントオブジェクトのKerberos keytabのローテーション/パスワードがリセットされます</block>
  <block id="b8333cf0e11040ea157a74560b3a6d77" category="paragraph">SMBマシンアカウントの場合、Cloud Volumes Service はSMBマシンアカウントのパスワードリセットを定期的にスケジュールします。これらのパスワードはKerberos暗号化を使用してリセットされ、毎週日曜日の午後11時から午前1時までのランダムな時刻にスケジュールされます。これらのパスワードは、Kerberosキーのバージョンをリセットし、Cloud Volumes Service システムに格納されているキータブをローテーションし、Cloud Volumes Service で実行されるSMBサーバのセキュリティを強化するのに役立ちます。マシンアカウントのパスワードはランダム化され、管理者には知られていません。</block>
  <block id="6df7123d2b1a64b11c7df1c2b837f752" category="paragraph">NFS Kerberosマシンアカウントの場合、パスワードのリセットは、新しいkeytabが作成され、KDCと交換されたときにのみ行われます。現在、Cloud Volumes Service では実行できません。</block>
  <block id="7631991924ea0015e269781ad88bd8d3" category="section-title">LDAPおよびKerberosで使用するネットワークポート</block>
  <block id="52d1b9583b81da6bee6ba24d74c4018b" category="inline-link">セキュリティに関する考慮事項についてのCloud Volumes Service のドキュメント</block>
  <block id="2363dee608bcd9f6ce7f980bfdad5789" category="section-title">LDAP</block>
  <block id="d0a2de9b178b436803f7732ff69d0c14" category="paragraph">Cloud Volumes Service はLDAPクライアントとして機能し、UNIX IDのユーザおよびグループ検索に標準のLDAP検索クエリを使用します。Cloud Volumes Service が提供する標準のデフォルトユーザ以外のユーザとグループを使用する場合は、LDAPが必要です。また、ユーザプリンシパル（user1@domain.comなど）でNFS Kerberosを使用する場合も、LDAPが必要です。現在、Microsoft Active Directoryを使用するLDAPのみがサポートされています。</block>
  <block id="2eaa173e56517db74fb0eb92806a0877" category="inline-link">RFC-2307 -bis</block>
  <block id="50af1bf8bee07c6cb1c61e9c19599403" category="paragraph">Active DirectoryをUNIX LDAPサーバとして使用するには、UNIX IDに使用するユーザおよびグループに、必要なUNIX属性を設定する必要があります。Cloud Volumes Service では、に基づいて属性を照会するデフォルトのLDAPスキーマテンプレートが使用されます<block ref="54011f528a38d24d58a7f02f98da0d00" category="inline-link-rx"></block>。このため、次の表に、ユーザとグループにデータを入力するために最低限必要なActive Directory属性と、それぞれの属性がどのような目的で使用されているかを示します。</block>
  <block id="a6e75b8341b03d08fb1d6817635b1d47" category="inline-link">デュアルプロトコルアクセスの管理</block>
  <block id="c0f3d72f07b570cdf3f5d1376c72a389" category="paragraph">Active DirectoryでのLDAP属性の設定の詳細については、を参照してください<block ref="c2741a8ac44d0c827e11ee9004dcd081" category="inline-link-rx"></block></block>
  <block id="f2bbdf9f72c085adc4d0404e370f0f4c" category="cell">属性</block>
  <block id="b12c51b935d86f01d092fb23a1fa4f9f" category="cell">機能</block>
  <block id="e266bea072e01571abba7fc5075c2c86" category="cell">UID *</block>
  <block id="0689aaddc7bfae9cad3778f6d706bd7a" category="cell">UNIXユーザ名を指定します</block>
  <block id="525f84e25602ba8efb61d7b8ca793b7c" category="cell">uidNumber *</block>
  <block id="604edb3bb733537b2d6c63b0b84fa1ec" category="cell">UNIXユーザの数値IDを指定します</block>
  <block id="825c2f924ee564de1d57d2b63edd800d" category="cell">gidNumber *</block>
  <block id="eb91949970817d632278971bdf06baef" category="cell">UNIXユーザのプライマリグループの数値IDを指定します</block>
  <block id="18b5aa92067bde95c39c3039f02bf70e" category="cell">objectclass *</block>
  <block id="ce41297dde1628c606d60ef2bbe154cd" category="cell">使用するオブジェクトのタイプを指定します。Cloud Volumes Service では、オブジェクトクラスのリストに「user」を含める必要があります（デフォルトではほとんどのActive Directory展開に含まれています）。</block>
  <block id="db108aa570113ecd6745a2e272d68544" category="cell">アカウントに関する一般的な情報（実際の名前、電話番号など、「gecos」とも呼ばれる）</block>
  <block id="17a12df2f12fa6f25328eb6c9fcffedf" category="cell">unixUserPassword</block>
  <block id="4306442303f7519026403fc1912e8e2e" category="cell">これを設定する必要はありません。NAS認証のUNIX ID検索では使用されません。設定すると、設定されたunixUserPasswordの値がプレーンテキストになります。</block>
  <block id="d146b96a250f5bcf84b56d2a0f8a2f87" category="cell">unixHomeDirectory</block>
  <block id="1208d15552f3ca8721989c162201e0de" category="cell">ユーザがLinuxクライアントからLDAPに照らして認証する場合のUNIXホームディレクトリへのパスを定義します。UNIXホームディレクトリの機能にLDAPを使用する場合は、このオプションを設定します。</block>
  <block id="0693ba16c955b74875d26f79148b66f0" category="cell">loginShellの略</block>
  <block id="61940c4af8b62a3bb77f4ab0eb491c08" category="cell">ユーザがLDAPに対して認証を行うときに、Linuxクライアントのbash/profileシェルへのパスを定義します。</block>
  <block id="9ed4554644da662e0634bf83a7e18666" category="paragraph">*は、Cloud Volumes Service で適切に機能するために属性が必要であることを示します。残りの属性はクライアント側でのみ使用します。</block>
  <block id="ac975e575ff07bee5423d326c261e07e" category="cell">CN *</block>
  <block id="b982e168cd50ef73d1f3ce851cb4ddac" category="cell">UNIXグループ名を指定します。LDAPでActive Directoryを使用する場合は、オブジェクトの作成時に設定されますが、あとで変更することもできます。この名前を他のオブジェクトと同じにすることはできません。たとえば、user1という名前のUNIXユーザがLinuxクライアント上のuser1という名前のグループに属している場合、Windowsでは、同じcn属性を持つ2つのオブジェクトは許可されません。これを回避するには、Windowsユーザの名前を一意の名前（user1やunixなど）に変更します。Cloud Volumes Service のLDAPでは、UNIXユーザ名にuid属性を使用します。</block>
  <block id="dc1d913bf6d70def379cf9f0d70abace" category="cell">UNIXグループの数値IDを指定します。</block>
  <block id="1afbf0b9465b3d5c13329cd43dda4e9e" category="cell">使用するオブジェクトのタイプを指定します。Cloud Volumes Service では、オブジェクトクラスのリストにグループを含める必要があります（この属性はデフォルトでほとんどのActive Directory展開に含まれています）。</block>
  <block id="5e4db984d78b91a65e9096eebf726d40" category="cell">memberUid</block>
  <block id="6cd5795a9ccf8fa0d1da852e88da95cd" category="cell">UNIXグループのメンバーであるUNIXユーザを指定します。Cloud Volumes Service のActive Directory LDAPでは、このフィールドは必要ありません。Cloud Volumes Service LDAPスキーマでは、グループメンバーシップにMemberフィールドを使用します。</block>
  <block id="cadd4e3eefdff4ed3ad7de830179c314" category="cell">メンバー*</block>
  <block id="defbfcaae1980c16f810c5ddaa1ecb87" category="cell">グループメンバーシップ/セカンダリUNIXグループに必要です。このフィールドには、WindowsユーザをWindowsグループに追加します。ただし、WindowsグループにUNIX属性が入力されていない場合、UNIXユーザのグループメンバーシップリストには含まれません。NFSで使用できる必要があるグループは、次の表に示す必要なUNIXグループ属性を設定する必要があります。</block>
  <block id="14476f6ea303cd9ac37328cb484a1fa1" category="section-title">LDAPバインド情報</block>
  <block id="af0c1d97230a1daa0f7341dc35f53a29" category="paragraph">LDAPでユーザを照会するには、Cloud Volumes Service がLDAPサービスにバインド（ログイン）する必要があります。このログインには読み取り専用権限があり、LDAP UNIX属性を照会してディレクトリを検索するために使用されます。現在のところ、LDAPバインドはSMBマシンアカウントを使用した場合にのみ可能です。</block>
  <block id="4a9b831487cab83d7de4d5a515e0eadd" category="paragraph">LDAPを有効にできるのは「CVS -パフォーマンス」インスタンスのみで、NFSv3、NFSv4.1、またはデュアルプロトコルボリュームでのみです。LDAP対応ボリュームを導入するには、Cloud Volumes Service ボリュームと同じリージョンにActive Directory接続を確立する必要があります。</block>
  <block id="c41605f9de6fa81e35ab98dd9e8b1b02" category="paragraph">LDAPを有効にすると、特定の状況で次のような状況が発生します。</block>
  <block id="f9f5dcaa4945ab96d402d905be4ed78c" category="list-text">Cloud Volumes Service プロジェクトにNFSv3またはNFSv4.1のみを使用する場合は、Active Directoryドメインコントローラに新しいマシンアカウントが作成され、Cloud Volumes Service 内のLDAPクライアントはマシンアカウントのクレデンシャルを使用してActive Directoryにバインドします。NFSボリュームおよびデフォルトの非表示の管理共有用にSMB共有は作成されません（を参照） <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>）共有ACLを削除しておきます。</block>
  <block id="f3dad67ce399cefb4b495c573d3ddcb8" category="list-text">Cloud Volumes Service プロジェクトにデュアルプロトコルボリュームを使用する場合は、SMBアクセス用に作成された1つのマシンアカウントのみを使用して、Cloud Volumes Service のLDAPクライアントがActive Directoryにバインドされます。追加のマシンアカウントは作成されません。</block>
  <block id="7168c010de7dd97d077c0e69f48cfbb5" category="list-text">専用のSMBボリュームを個別に作成する場合（LDAPを使用するNFSボリュームの有効化前と無効化後）、LDAPバインド用マシンアカウントはSMBマシンアカウントと共有されます。</block>
  <block id="248e702975c1b53305536e1e9c698e19" category="list-text">NFS Kerberosも有効になっている場合は、2つのマシンアカウントが作成されます。1つはSMB共有またはLDAPバインド用、もう1つはNFS Kerberos認証用です。</block>
  <block id="738deb1a3cec2cc7d670e7de69d3a7c6" category="section-title">LDAPクエリ</block>
  <block id="a204dba492103f34b09fe60e7ab98921" category="paragraph">LDAPバインドは暗号化されますが、LDAPクエリは共通のLDAPポート389を使用してプレーンテキストでワイヤ経由で渡されます。この既知のポートは、現在Cloud Volumes Service では変更できません。その結果、ネットワーク内のパケットスニファにアクセスできるユーザは、ユーザ名、グループ名、数値ID、およびグループメンバーシップを確認できます。</block>
  <block id="d10f3c8108e06d8e622b7a6fb88adb08" category="inline-link-macro">「パケットのスニッフィング/トレースに関する考慮事項」</block>
  <block id="b046f19aab64225d509f228ccd32fb2c" category="paragraph">ただし、Google Cloud VMは他のVMのユニキャストトラフィックをスニファできません。LDAPトラフィックにアクティブに参加している（バインド可能な）VMのみが、LDAPサーバからのトラフィックを表示できます。Cloud Volumes Service でのパケットスニファの詳細については、を参照してください <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="d815e456141423f092087c21cd312f23" category="section-title">LDAPクライアント設定のデフォルト</block>
  <block id="1c1b57ee3fb14f95067e88e579a44eec" category="paragraph">Cloud Volumes Service インスタンスでLDAPを有効にすると、デフォルトで特定の設定の詳細を使用してLDAPクライアント設定が作成されます。場合によっては、オプションがCloud Volumes Service に適用されない（サポートされない）か、設定できないことがあります。</block>
  <block id="cc2eacdb2cc579f99a0f4359e61ed258" category="cell">LDAPクライアントオプション</block>
  <block id="31ce3cdcd67850870b616f75b555bbc5" category="cell">デフォルト値</block>
  <block id="216a8093d27a97d2912ed6822d19d410" category="cell">変更は可能ですか？</block>
  <block id="ffe990396bf99448f8fe6e6fa1c3c3ea" category="cell">LDAPサーバリスト</block>
  <block id="0b22102603051537f2c4bfccc964b74e" category="cell">クエリに使用するLDAPサーバ名またはIPアドレスを設定します。これはCloud Volumes Service では使用されません。代わりに、Active Directoryドメインを使用してLDAPサーバを定義します。</block>
  <block id="9ba66a9f92056682b7d86a38b4bc18c0" category="cell">未設定</block>
  <block id="f490d3302e7cd81f3dafead6c8311b60" category="cell">Active Directoryドメイン</block>
  <block id="63dfe9dc44b2881b25560d6d5bd5dff6" category="cell">LDAPクエリに使用するActive Directoryドメインを設定します。Cloud Volumes Service は、DNSのLDAPのSRVレコードを利用して、ドメイン内のLDAPサーバを検索します。</block>
  <block id="6575821e7d2ff9eec297128f6e66933a" category="cell">Active Directory接続で指定されているActive Directoryドメインに設定します。</block>
  <block id="00227bc990a551282373139d6439feb4" category="cell">優先されるActive Directoryサーバ</block>
  <block id="01d685ed68515214956910d3e26f1c71" category="cell">LDAPで使用する優先Active Directoryサーバを設定します。Cloud Volumes Service ではサポートされていません。代わりに、Active Directoryサイトを使用してLDAPサーバの選択を制御します。</block>
  <block id="f41520c4ef898fb19bb93ee749be3fdd" category="cell">未設定。</block>
  <block id="b626ddcd91311f0f7c4622fdcb7ba05e" category="cell">SMBサーバクレデンシャルを使用してバインド</block>
  <block id="cb97b8ae4a5bb23e8ffa9e1547fe5078" category="cell">SMBマシンアカウントを使用してLDAPにバインドします。現在、Cloud Volumes Service でサポートされているLDAPバインド方式はのみです。</block>
  <block id="f827cf462f62848df37c5e1e94a4da74" category="cell">正しいです</block>
  <block id="d95e3278cf3c7f4cd1d7e40c5a89e7a7" category="cell">スキーマテンプレート</block>
  <block id="33387315b367e8397cc901a4bf37ad44" category="cell">LDAPクエリに使用するスキーマテンプレート。</block>
  <block id="16165a1c7229a30ce1a980b0e648d65f" category="cell">MS-AD-BIS を参照してください</block>
  <block id="b825dd7cf8df99909db6f3117c567721" category="cell">LDAPサーバポート</block>
  <block id="731fba188f3670e36bac64d2ca64db37" category="cell">LDAPクエリに使用するポート番号。Cloud Volumes Service では現在、標準のLDAPポート389のみが使用されています。LDAPS /ポート636は、現在サポートされていません。</block>
  <block id="c86a7ee3d8ef0b551ed58e354a836f2b" category="cell">389</block>
  <block id="9a76dbbba394b04594907973bb6c192e" category="cell">LDAPSが有効になっています</block>
  <block id="98c3437e89f8128c7359f6b999731fcc" category="cell">LDAP over Secure Sockets Layer（SSL）をクエリおよびバインドに使用するかどうかを制御します。現在、Cloud Volumes Service ではサポートされていません。</block>
  <block id="3452a15eecd4e9b3215025c747cfce4e" category="cell">クエリタイムアウト（秒）</block>
  <block id="4fbc7a2f8fb9f56de093d04afac67fa3" category="cell">クエリがタイムアウトしました。クエリに指定した値よりも長い時間がかかると、クエリが失敗します。</block>
  <block id="4211f908e9b523117776324e2349a87c" category="cell">最小バインド認証レベル</block>
  <block id="cf6cfd37577ec3f1cc20caa7fb10bd45" category="cell">サポートされる最小バインドレベルを指定します。Cloud Volumes Service はLDAPバインドにマシンアカウントを使用し、デフォルトではActive Directoryは匿名バインドをサポートしないため、このオプションはセキュリティ上の理由から有効になりません。</block>
  <block id="7079c72c21415131774625ba1d64f4b0" category="cell">匿名</block>
  <block id="58384d924f3205aaac5f4a09d3b33801" category="cell">バインド DN</block>
  <block id="4d73cec492ef07eaddad38a4a553639d" category="cell">シンプルバインドが使用されている場合にバインドに使用されるユーザ/識別名（DN）。Cloud Volumes Service は、LDAPバインドにマシンアカウントを使用しますが、現在のところ単純なバインド認証はサポートしていません。</block>
  <block id="6c22befafec962f5002017b68e639f92" category="cell">ベースDN</block>
  <block id="413689794b4599826344869870d6e0a7" category="cell">LDAP検索に使用するベースDN。</block>
  <block id="796658213567ec39e68bd43e48ac6eff" category="cell">Active Directory接続に使用するWindowsドメイン（DN形式）（DC=domain、DC=local）</block>
  <block id="30e8b85f236e0c0e7b13a8a98bd46d6f" category="cell">ベースの検索範囲</block>
  <block id="26cbec2c997dd79e69cd5279817c5506" category="cell">ベースDN検索の検索範囲。値には、base、onelevel、subtreeのいずれかを指定できます。Cloud Volumes Service ではサブツリー検索のみがサポートされます。</block>
  <block id="187c471e7dfcb7890077311c532fffd0" category="cell">サブツリー</block>
  <block id="de20d00fd9f0840e6c05dce6aca169e4" category="cell">ユーザDN</block>
  <block id="4ddd431d35193d0d6dc9555aeecf86e1" category="cell">ユーザがLDAPクエリの検索を開始するDNを定義します。現在Cloud Volumes Service ではサポートされていないため、すべてのユーザ検索はベースDNから開始されます。</block>
  <block id="389048eda41eb7c0e810c83269814943" category="cell">ユーザの検索範囲</block>
  <block id="0c5e0f35296916ccacc860481c53c663" category="cell">ユーザDN検索の検索範囲。値には、base、onelevel、subtreeのいずれかを指定できます。Cloud Volumes Service では、ユーザ検索範囲の設定はサポートされていません。</block>
  <block id="68a7f97c57468e034a3f8016831c3c54" category="cell">グループDN</block>
  <block id="5874ce023df38d8485da62d095f714f5" category="cell">グループ検索でLDAPクエリが開始されるDNを定義します。現在Cloud Volumes Service ではサポートされていないため、すべてのグループ検索はベースDNから開始されます。</block>
  <block id="c76b264e7f1c2aadf6b61ca4a7b9dc52" category="cell">グループの検索範囲</block>
  <block id="2d21b088cabd39a7f25a62fc99148f20" category="cell">グループDN検索の検索範囲。値には、base、onelevel、subtreeのいずれかを指定できます。Cloud Volumes Service では、グループ検索範囲の設定はサポートされていません。</block>
  <block id="9819b4f0996b3e603488836501e3318e" category="cell">ネットグループDN</block>
  <block id="b5e1f3448b6d3c978f83c2d3d12a2d1e" category="cell">ネットグループ検索でLDAPクエリの開始に使用するDNを定義します。現在Cloud Volumes Service ではサポートされていないため、ネットグループ検索はすべてベースDNから開始されます。</block>
  <block id="de25b155c30a2cba210598b604a5b8c8" category="cell">ネットグループ検索範囲</block>
  <block id="334dde86dbe71e59b3c942c6a2384d70" category="cell">ネットグループDN検索の検索範囲。値には、base、onelevel、subtreeのいずれかを指定できます。Cloud Volumes Service では、ネットグループ検索範囲の設定はサポートされていません。</block>
  <block id="e2bdddbf27283c0eca38d39759107a44" category="cell">LDAPでstart_tlsを使用します</block>
  <block id="24788f1c660aa47d895fa832d61d2fcf" category="cell">Start TLSを使用して、証明書ベースのLDAP接続をポート389経由で行います。現在、Cloud Volumes Service ではサポートされていません。</block>
  <block id="cb64fc71803a6196ec2185116e525243" category="cell">ホスト単位のネットグループ検索を有効にします</block>
  <block id="d92aed09a16438d9bc4cf2735e54815f" category="cell">ネットグループをすべてのメンバーの一覧に展開するのではなく、ホスト名によるネットグループ検索を有効にします。現在、Cloud Volumes Service ではサポートされていません。</block>
  <block id="ae1e3e9f0f050830d9ad4ff1441a4080" category="cell">ホスト単位のネットグループDN</block>
  <block id="6dc9eeb7bc11f937a1c509e27237db6f" category="cell">ホスト単位のネットグループ検索がLDAPクエリを開始するDNを定義します。ホスト単位のネットグループは、現在Cloud Volumes Service ではサポートされていません。</block>
  <block id="0b5200ff3b38841dd95a404d7e6ff385" category="cell">ホスト単位のネットグループ検索範囲</block>
  <block id="4ce621e884478e7fc52e17ed91eed525" category="cell">ホスト単位のネットグループDN検索の検索範囲。値には、base、onelevel、subtreeのいずれかを指定できます。ホスト単位のネットグループは、現在Cloud Volumes Service ではサポートされていません。</block>
  <block id="19a0fc26f19842a9f7bc78040d0c381c" category="cell">クライアントセッションのセキュリティ</block>
  <block id="16ed23b379774b2be1797f8efa0fe9a5" category="cell">LDAPリファーラルキャッシュ</block>
  <block id="a408a02f7b8e36f4913d8dc2debb2b95" category="cell">複数のLDAPサーバを使用している場合、リファーラル追跡を使用すると、クライアントが最初のサーバでエントリが見つからなかったときに、リスト内の他のLDAPサーバを参照することができます。これは現在、Cloud Volumes Service ではサポートされていません。</block>
  <block id="5f362229a019eb903f4b21e28b15a1f5" category="cell">グループメンバーシップフィルタ</block>
  <block id="55ad576cc6cd581d8a2f558d69828312" category="cell">LDAPサーバからグループメンバーシップを検索するときに使用するカスタムのLDAP検索フィルタを提供します。Cloud Volumes Service では現在サポートされていません。</block>
  <block id="b735835c02ee9b8eba41846beea27bc6" category="section-title">LDAPを使用した非対称ネームマッピング</block>
  <block id="10d248b3ae3729560e0f9f75ff23f70e" category="paragraph">デフォルトでは、Cloud Volumes Service は、WindowsユーザとUNIXユーザを、特別な設定なしで双方向に同一のユーザ名でマッピングします。有効なUNIXユーザ（LDAPを使用）がCloud Volumes Service で検出されると、1：1のネームマッピングが発生します。たとえば、Windowsユーザjohnsmithが使用されている場合、Cloud Volumes Service がLDAPで「johnsmith」という名前のUNIXユーザを検索できた場合、そのユーザのネームマッピングは成功し、「johnsmith」によって作成されたすべてのファイルおよびフォルダに正しいユーザ所有権が表示されます。 また'johnsmithに影響を与えるすべてのACLは'NASプロトコルの使用に関係なく使用されますこれは対称ネームマッピングと呼ばれます。</block>
  <block id="a4e6c429f8e2b5bc009025d9469cd6bd" category="paragraph">非対称ネームマッピングは、WindowsのユーザIDとUNIXのユーザIDが一致しない場合に使用します。たとえば'WindowsユーザjohnsmithがUNIX IDがjsmithの場合'UNIXのバリエーションをCloud Volumes Service に通知する必要がありますCloud Volumes Service は現在、静的なネームマッピングルールの作成をサポートしていないため、ファイルとフォルダの適切な所有権と予期される権限を確保するために、LDAPを使用してWindows IDとUNIX IDの両方のユーザのIDを検索する必要があります。</block>
  <block id="159e0e9db457fce00641b7a639cdfef9" category="paragraph">デフォルトでは、Cloud Volumes Service のネームマップデータベースのインスタンスのns-switchに「ldap」が含まれているため、非対称名にLDAPを使用してネームマッピング機能を提供するために必要なのは、Cloud Volumes Service の検索内容を反映するためにユーザ/グループの属性の一部のみです。</block>
  <block id="5083578eb1523417a04b030704e11a97" category="paragraph">次の表に、非対称ネームマッピング機能のためにLDAPに入力する必要がある属性を示します。ほとんどの場合、Active Directoryはすでに設定されています。</block>
  <block id="2e4b53007a09bf23d9111917c46d1902" category="cell">Cloud Volumes Service 属性</block>
  <block id="009097a0950f2d6565c2cb446aa081dd" category="cell">Cloud Volumes Service がネームマッピングに使用する値</block>
  <block id="df642bb30c436da15b0b74923cb45806" category="cell">WindowsからUNIX objectClass</block>
  <block id="75f68f87af42701b9e548f875f39cefe" category="cell">使用するオブジェクトのタイプを指定します。（ユーザ、グループ、posixAccountなど）</block>
  <block id="2b731e8ed189a8b7587c21b21d6620cf" category="cell">userを含める必要があります（必要に応じて、他の値を複数含めることもできます）。</block>
  <block id="288eebd1d2cddc03953f475edbcb2d5f" category="cell">WindowsからUNIXへの属性</block>
  <block id="1b356493e583b25fdd7b1e44d6a4df0d" category="cell">作成時にWindowsユーザ名を定義します。Cloud Volumes Service では、これをWindowsからUNIXへのルックアップに使用します。</block>
  <block id="5ce0ca6d681fede8d46460fed64bf8ef" category="cell">ここでは変更は必要ありません。sAMAccountNameはWindowsログイン名と同じです。</block>
  <block id="e7d22294bdcb7133967c3548ece982e5" category="cell">UID</block>
  <block id="d93b9102027ae26f7bbfa53ff0cd3f28" category="cell">UNIXユーザ名を定義します。</block>
  <block id="abd2101078216980cdcf2dc6f87172b9" category="cell">必要なUNIXユーザ名。</block>
  <block id="78e7065e65f76fc53c1953f598d424de" category="paragraph">Cloud Volumes Service では現在、LDAP検索でドメインプレフィックスが使用されないため、LDAPネームマップ検索で複数のドメインLDAP環境が正常に機能しません。</block>
  <block id="1a19ad8ba3f26bc83d40bf699210c5b3" category="paragraph">次の例は、Windows名が「asymmetric」で、UNIX名が「unix-user」で、SMBとNFSの両方からファイルを書き込む際の動作を示しています。</block>
  <block id="cf613896f3bf97cfe22b19367188faac" category="paragraph">次の図に、LDAP属性がWindowsサーバからどのように見えているかを示します。</block>
  <block id="bb859b3ee7438471d7bd0441aec37b09" category="paragraph"><block ref="bb859b3ee7438471d7bd0441aec37b09" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74a3bb1b92afc37821849f4d2c6a2e08" category="paragraph">NFSクライアントからは、UNIX名を照会できますが、Windows名は照会できません。</block>
  <block id="9a9b54fd5d17009b1290538bd0bea332" category="paragraph">ファイルがNFSから「unix-user」として書き込まれると、NFSクライアントから次のような結果になります。</block>
  <block id="2d78fc711a4a8afa3553c40cb81a7f5a" category="paragraph">Windowsクライアントでは、ファイルの所有者が適切なWindowsユーザに設定されていることを確認できます。</block>
  <block id="dd276babf175f2baaf7d31c63630e9ce" category="paragraph">逆に、WindowsユーザがSMBクライアントから「asymmetric」で作成したファイルの場合、次のテキストに示すように、適切なUNIX所有者が表示されます。</block>
  <block id="840e343f2946d2e3ecafb4d3af6751c5" category="paragraph">SMB：</block>
  <block id="7369fcede1216c5a449bffa4016f597a" category="paragraph">NFS ：</block>
  <block id="1a2ced64ce54d0878867c66c1264ef73" category="section-title">LDAPチャネルバインド</block>
  <block id="7bc3122060898b084ade9ae81cb840d5" category="inline-link">マイクロソフトセキュリティアドバイザリADV190023</block>
  <block id="9c2bd50d1c3b17373f80735ce60e0d91" category="paragraph">Windows Active Directoryドメインコントローラの脆弱性により、<block ref="9230172696f08489abbbe06ad2878984" category="inline-link-rx"></block> DCによるLDAPバインドの許可方法を変更します。</block>
  <block id="c389bcb5002ce56cb9cf28680eb6ff4c" category="paragraph">Cloud Volumes Service による影響は、どのLDAPクライアントでも同じです。Cloud Volumes Service では現在、チャネルバインドはサポートされていません。Cloud Volumes Service はネゴシエーションを通じてデフォルトでLDAP署名をサポートしているため、LDAPチャネルバインドを問題 にすることはできません。チャネルバインドが有効な状態でLDAPにバインドする問題がある場合は、「ADV190023」の修正手順に従って、Cloud Volumes Service からのLDAPバインドを成功させるようにしてください。</block>
  <block id="ed5f2bdecbd4bd349d09412d1ff6a6fb" category="section-title">DNS</block>
  <block id="8cc300201cbc74e712f45393efb60e69" category="inline-link">動的DNS</block>
  <block id="80052c998ef6da49a98a2d9004c75c33" category="paragraph">Active DirectoryとKerberosはどちらも、ホスト名からIP / IPを経由したホスト名解決で、DNSに依存します。DNSでは、ポート53を開く必要があります。Cloud Volumes Service では、DNSレコードに変更を加えたり、現在のところの使用をサポートしていません<block ref="2df544fb17221302fef729d1eb6bd715" category="inline-link-rx"></block> ネットワークインターフェイス。</block>
  <block id="5f36386498075ef9c05d674112b69981" category="inline-link">Windows DNSを保護</block>
  <block id="e3aa134886f9dad39f14489844fe7763" category="paragraph">Active Directory DNSを設定して、DNSレコードを更新できるサーバを制限できます。詳細については、を参照してください<block ref="1abda701cc77717e0b1a0b391ec2fed8" category="inline-link-rx"></block>。</block>
  <block id="e8ba0470f4bd2498fbecdead3ab1b183" category="paragraph">Googleプロジェクト内のリソースは、既定ではGoogle Cloud DNSを使用しますが、Active Directory DNSには接続されていません。クラウドDNSを使用するクライアントは、Cloud Volumes Service から返されたUNCパスを解決できません。Active Directoryドメインに参加しているWindowsクライアントは、Active Directory DNSを使用するように設定され、このようなUNCパスを解決できます。</block>
  <block id="71870bac7a9267067ab69566f75d36c3" category="inline-link">クライアントでSMB NetBIOS名を解決できないのはなぜですか？</block>
  <block id="b0ffc266c9e05cd7ae80810305b932bf" category="paragraph">クライアントをActive Directoryに参加させるには、Active Directory DNSを使用するようにそのDNS設定を構成する必要があります。必要に応じて、Active Directory DNSに要求を転送するようにCloud DNSを設定することができます。を参照してください<block ref="d568657413aac86de4b237a9edcddc2d" category="inline-link-rx"></block>を参照してください。</block>
  <block id="a0c7db04deaabb45ee60d5a501e67eb8" category="admonition">Cloud Volumes Service は現在DNSSECをサポートしておらず、DNSクエリはプレーンテキストで実行されます。</block>
  <block id="c3a18bc4fd14cf11bc551540f29f6375" category="section-title">ファイルアクセスの監査</block>
  <block id="cc6e776769986190d1536969ad7e5307" category="paragraph">現在、Cloud Volumes Service ではサポートされていません。</block>
  <block id="5cffe1f133f0ed3a472da05d0b1d3f0d" category="section-title">アンチウイルスによる保護</block>
  <block id="2b91875198ddd07e9b4cff7f1fe46663" category="paragraph">Cloud Volumes Service で、クライアントからNAS共有へのウィルススキャンを実行する必要があります。現在のところ、Cloud Volumes Service とウィルス対策はネイティブで統合されていません。</block>
  <block id="f0e8b8e3bd62a1e919cd1935e44bf79c" category="inline-link-macro">次：サービスの処理。</block>
  <block id="fba0107176535938bcee4c0774160668" category="paragraph"><block ref="fba0107176535938bcee4c0774160668" category="inline-link-macro-rx"></block></block>
  <block id="fd7d290d66c64aa2fc13dd9bbca9c540" category="summary">Cloud Volumes Service では、適切なアクセス権限を維持しながら、SMBクライアントとNFSクライアントの両方で同じデータセットを共有できます。デュアルプロトコルこれを行うには、プロトコル間でIDマッピングを調整し、中央のバックエンドLDAPサーバを使用してUNIX IDをCloud Volumes Service に提供します。Windows Active Directoryを使用すると、WindowsとUNIXの両方のユーザに使いやすさを提供できます。</block>
  <block id="d27d01220b09abd6dc8be87dd2b7f8d4" category="doc">デュアルプロトコル/マルチプロトコル</block>
  <block id="8c14d6d170254470aea76e2185e26901" category="inline-link-macro">Previous：SMB。</block>
  <block id="692e0ebc2797e7ae1a9618bdac0b5c02" category="paragraph"><block ref="692e0ebc2797e7ae1a9618bdac0b5c02" category="inline-link-macro-rx"></block></block>
  <block id="9a5ba82ef925964774fad34d380585ce" category="inline-link">デュアルプロトコル</block>
  <block id="afbf550dbb927e70d6e5e81aba4cf54e" category="paragraph">Cloud Volumes Service では、適切なアクセス権限を維持しながら、SMBクライアントとNFSクライアントの両方で同じデータセットを共有できます <block ref="090248040bf8d7cbf59e0f5bcb2aeb23" category="inline-link-rx"></block>）。これを行うには、プロトコル間でIDマッピングを調整し、中央のバックエンドLDAPサーバを使用してUNIX IDをCloud Volumes Service に提供します。Windows Active Directoryを使用すると、WindowsとUNIXの両方のユーザに使いやすさを提供できます。</block>
  <block id="65bd83537129be15c8027ec94bec5bd3" category="section-title">Access Control の略</block>
  <block id="b481dc764d87d694bd99e41051212b98" category="inline-link-macro">“ローカル/ BUILTIN管理者/バックアップ権限を持つアカウント”</block>
  <block id="4349221797619aa2539cd1d814d55cf3" category="inline-link">MMC /コンピュータの管理</block>
  <block id="ab67de3b2d37b16da324871c9cd7f96b" category="list-text">*共有アクセス制御。* NAS共有にアクセスできるクライアントまたはユーザーおよびグループを決定します。NFSの場合は、エクスポートへのクライアントアクセスを制御するエクスポートポリシーとルールがあります。NFSエクスポートはCloud Volumes Service インスタンスから管理されます。SMBは、CIFS / SMB共有と共有ACLを利用して、ユーザレベルおよびグループレベルでより細かく制御します。を使用して設定できるのは、SMBクライアントからのみ共有レベルのACLです<block ref="dbc4cec831b164bbb509e51caacd0209" category="inline-link-rx"></block> Cloud Volumes Service インスタンスに対する管理者権限を持つアカウントを使用する場合（を参照） <block ref="c9946e41ec7364b03516e2beacd1b339" category="inline-link-macro-rx"></block>）。</block>
  <block id="1020ac8238c0e64a401514745b8a3c6a" category="list-text">*ファイルアクセス制御。*ファイルまたはフォルダレベルで権限を制御し、常にNASクライアントから管理します。NFSクライアントは、従来のモードビット（rwx）またはNFSv4 ACLを使用できます。SMBクライアントはNTFS権限を利用します。</block>
  <block id="dcfd17a407b936210845de342300e631" category="paragraph">NFSとSMBの両方にデータを提供するボリュームのアクセス制御は、使用しているプロトコルによって異なります。デュアルプロトコルの権限については、「」を参照してください<block ref="7251f6a3aba1b22d43e125a8c39f6f0a" category="inline-xref-macro-rx"></block>」</block>
  <block id="20d918db09dacfd5fbfbaadfaede2f80" category="section-title">ユーザマッピング</block>
  <block id="c9677302c2548820abda217b496a541b" category="paragraph">クライアントがボリュームにアクセスすると、Cloud Volumes Service は受信ユーザを反対方向の有効なユーザにマッピングしようとします。これは、プロトコルを使用して適切なアクセスを決定し、アクセスを要求しているユーザが実際に誰であるかを確認するために必要です。</block>
  <block id="7e9b11fc569fee58c3b42b689df2fbec" category="paragraph">たとえば、「joe」という名前のWindowsユーザがSMB経由でUNIXアクセス権を持つボリュームにアクセスしようとすると、Cloud Volumes Service は「joe」という名前の対応するUNIXユーザを検索します。存在する場合、Windowsユーザ「joe」としてSMB共有に書き込まれるファイルは、NFSクライアントからはUNIXユーザ「joe」と表示されます。</block>
  <block id="b9e4f77748fb373f23ad2bc9eb2d3de0" category="paragraph">また、「joe」という名前のUNIXユーザがWindows権限を持つCloud Volumes Service ボリュームへのアクセスを試みる場合、そのUNIXユーザは有効なWindowsユーザにマッピングできる必要があります。そうしないと、ボリュームへのアクセスが拒否されます。</block>
  <block id="98b9b81e4ad07f5198dd8381a0c5d43c" category="inline-link">AD接続の作成</block>
  <block id="d6210f83492bb730b32d0e719a1d5100" category="paragraph">現時点では、LDAPを使用した外部UNIX IDの管理でサポートされているのはActive Directoryのみです。このサービスへのアクセスの設定の詳細については、を参照してください<block ref="cfe0f81fca904ab10d3dcbbfceb0f3de" category="inline-link-rx"></block>。</block>
  <block id="7fc7c5bf3cd7f453807f2e17dc846957" category="section-title">アクセス許可モデル</block>
  <block id="94b74cdf7c7dc9ef00fc04cf642127d9" category="paragraph">デュアルプロトコルのセットアップを使用する場合、Cloud Volumes Service では、ボリュームのセキュリティ形式を使用してACLのタイプを決定します。これらのセキュリティ形式は、Cloud Volumes Service ボリュームの作成時に選択したNASプロトコル、またはデュアルプロトコルの場合に選択したセキュリティ形式に基づいて設定されます。</block>
  <block id="b3544688f5ad40244fc991f13471c525" category="list-text">NFSのみを使用している場合は、Cloud Volumes Service ボリュームでUNIX権限が使用されます。</block>
  <block id="95b899e9e3d21a94ae7e8ce04eac3bb3" category="list-text">SMBのみを使用する場合、Cloud Volumes Service ボリュームはNTFS権限を使用します。</block>
  <block id="51c16477dee3c257c4930e8614eda5ba" category="paragraph">デュアルプロトコルボリュームを作成する場合は、ボリュームの作成時にACL形式を選択できます。この決定は、必要な権限管理に基づいて行う必要があります。ユーザがWindows / SMBクライアントから権限を管理している場合は、NTFSを選択します。ユーザがNFSクライアントおよびchmod / chownを使用することを希望する場合は、UNIXセキュリティ形式を使用します。</block>
  <block id="fd859db4ea28a81227f07e2c125fc927" category="inline-link-macro">次の手順：Active Directory接続を作成する際の考慮事項</block>
  <block id="bc695a7a8573373413beec401ab691e1" category="paragraph"><block ref="bc695a7a8573373413beec401ab691e1" category="inline-link-macro-rx"></block></block>
  <block id="451abeb07875465ff669fc3bfc502564" category="summary">特にストレージ管理者の管理権限がないクラウドでは、クラウドプロバイダが提供するサービスにデータを信頼することが何よりも重要です。このドキュメントでは、NetApp Cloud Volumes Service がGoogle Cloudで提供しているセキュリティサービスの概要について説明します。</block>
  <block id="85f174d487aef272a0a9ea0f980e4827" category="doc">TR-4918：『Security Overview - NetApp Cloud Volumes Service in Google Cloud』</block>
  <block id="09f7873d6f07efaef82aef2b95f42e0a" category="paragraph">ネットアップ、Oliver Krause、Justin Parisi</block>
  <block id="1e06922fd676ae97f9dc69dbbfc93992" category="section-title">文書の範囲</block>
  <block id="c2f1a37c5b3a149d2e79ad5a41c86139" category="inline-link">Cloud Volumes Service はGoogle Cloudで提供されます</block>
  <block id="c2197b5184a5af948e5dc6e6dcf6e5c3" category="paragraph">特にストレージ管理者の管理権限がないクラウドでは、クラウドプロバイダが提供するサービスにデータを信頼することが何よりも重要です。本ドキュメントでは、ネットアップが提供するセキュリティソリューションの概要について説明します<block ref="b29f7971c7793aea2bb4311fa5c38ee0" category="inline-link-rx"></block>。</block>
  <block id="f2b84afd0523a6df7547c404aa3647d8" category="section-title">対象読者</block>
  <block id="75ff467aeacdad8bd3ed9fe31431d022" category="paragraph">このドキュメントの対象読者には、次の役割が含まれますが、これらに限定されません。</block>
  <block id="3487d2ed085064f5b68318d25038bcd6" category="list-text">クラウドプロバイダ</block>
  <block id="203ea32883f92321782cc1a312345903" category="list-text">ストレージ管理者</block>
  <block id="7e89bd35a6b8558a95e9e4ec446df00d" category="list-text">ストレージアーキテクト</block>
  <block id="528efe83de18ec1cf2eb982cc641bb89" category="list-text">フィールド用リソース</block>
  <block id="a6205b388d7b872550efc1a57461e045" category="list-text">ビジネス上の意思決定者</block>
  <block id="d9a404dc3c51a0dfc2360a6f7f97c00c" category="inline-link-macro">「お問い合わせください。」</block>
  <block id="ec45e675f8dd5d470d6edacfc9ac6a2d" category="paragraph">このテクニカルレポートの内容について不明な点がある場合は、を参照してください <block ref="bbd2d7f57ba5e479a6b271845e2b7ec0" category="inline-link-macro-rx"></block></block>
  <block id="b54d58d7e43c404563f91e38d3efbcac" category="cell">略語</block>
  <block id="0b890b1926b90387673882e6ccae7fdc" category="cell">定義（ Definition ）</block>
  <block id="e898e7a5df4dec909ad011657b510e2d" category="cell">CVS -ソフトウェア</block>
  <block id="3b558136fa0b6447d030d5fd2d28765b" category="cell">Cloud Volumes Service 、サービスタイプCVS</block>
  <block id="439d7969e09b4b31626fcf209b8fdcb7" category="cell">CVS - パフォーマンス</block>
  <block id="3da305112390b1f2d5e6ad8818e00065" category="cell">Cloud Volume Service、サービスタイプCVS -パフォーマンス</block>
  <block id="041159b903daf7d5923837346de98407" category="cell">PSA</block>
  <block id="eb2108209f61048e4b7ebba4b61f91ee" category="inline-link-macro">次のステップ：Google CloudのCloud Volumes Service でデータを保護する方法をご紹介します。</block>
  <block id="4c9538193c211d1d025b959f6407da23" category="paragraph"><block ref="4c9538193c211d1d025b959f6407da23" category="inline-link-macro-rx"></block></block>
  <block id="60298c0c8282022dec640948e48114c1" category="summary">Cloud Volumes Service チームはGoogle Cloudでバックエンドサービスを管理し、複数の戦略を使用してプラットフォームを保護し、不要なアクセスを防止します。</block>
  <block id="d5558f87207ef258cc599e6b4f31fa1f" category="doc">サービスの処理</block>
  <block id="23fa70110ac44a6aa038c42f52919e60" category="inline-link-macro">Previous：その他のNAS Infrastructureサービスの依存関係（KDC、LDAP、DNS）。</block>
  <block id="09db248feade063e1b222ff7a6fa8bae" category="paragraph"><block ref="09db248feade063e1b222ff7a6fa8bae" category="inline-link-macro-rx"></block></block>
  <block id="01f3694459a5570182960c35de3adea0" category="paragraph">お客様ごとに固有のサブネットが割り当てられ、デフォルトで他のお客様から遮断されたアクセス権が付与される。Cloud Volumes Service の各テナントは、データを完全に分離するために独自のネームスペースとVLANを取得する。ユーザが認証されると、Service Delivery Engine（SDE；サービス提供エンジン）はそのテナントに固有の設定データのみを読み取ることができます。</block>
  <block id="3efd389b601ec82d2d3d7d1fe8c7a952" category="section-title">物理的セキュリティ</block>
  <block id="e6cbbd1872a42cfa36ceca16da55e6af" category="paragraph">事前承認が必要な場合、ケージとラックにアクセスできるのは、オンサイトエンジニアとネットアップ認定のフィールドサポートエンジニア（FSE）のみです。ストレージとネットワークの管理は許可されていません。ハードウェアのメンテナンス作業を実行できるのは、これらのオンサイトリソースのみです。</block>
  <block id="f4cc7ff420af18ead26b06b01e65be30" category="paragraph">オンサイトエンジニアの場合は、作業仕様書（SOW）のチケットが発行されます。この作業内容には、ラックIDとデバイスの場所（RU）、その他すべての詳細情報が含まれます。NetApp FSEの場合、サイト訪問チケットはColoで発行する必要があります。チケットには、監査を目的とした訪問者の詳細、日付、時刻が含まれています。FSEのSOWは、社内でネットアップに通知されます。</block>
  <block id="e6da80db21921cfa31a2ec8ae71c8a44" category="section-title">運用チーム</block>
  <block id="575c886f27b4fd6adbc422b9466a7d77" category="paragraph">Cloud Volumes Service の運用チームは、クラウドボリュームサービス向けの生産エンジニアリングとサイト信頼性エンジニア（SRE）、およびハードウェア向けのネットアップフィールドサポートエンジニアとパートナーで構成されています。すべての運用チームメンバーは、Google Cloudでの作業が認定されており、発行されたチケットごとに詳細な作業記録が保持されています。また、各意思決定が適切に精査されるように、厳格な変更管理および承認プロセスが用意されています。</block>
  <block id="62b92b1afcd6e99ad8ef6fc6e66fe1c6" category="paragraph">SREチームは、コントロールプレーンと、UI要求からCloud Volumes Service のバックエンドハードウェアおよびソフトウェアにデータをルーティングする方法を管理します。SREチームは、ボリュームやinodeの最大数などのシステムリソースも管理します。SREは、カスタマーデータとやり取りしたり、カスタマーデータにアクセスしたりすることはできません。SREは、バックエンドハードウェアに対する新しいディスク交換要求やメモリ交換要求などのReturn Material Authorizations（RMA）との調整も行います。</block>
  <block id="20ac318b6aafb241498518b27a204f2d" category="section-title">お客様の責任</block>
  <block id="5b18708f6a9b76d94aad073287e9c4aa" category="paragraph">Cloud Volumes Service のお客様は、組織のActive Directoryとユーザーの役割管理だけでなく、ボリュームとデータの操作も管理します。お客様は管理者ロールを割り当てられ、ネットアップとGoogle Cloudが提供する2つの事前定義されたロール（管理者とビューア）を使用して、同じGoogle Cloudプロジェクト内の他のエンドユーザに権限を委譲できます。</block>
  <block id="70612d623f8ac2ccbad1aa9289e54eb2" category="paragraph">管理者は、お客様のプロジェクト内の任意のVPCを、お客様が適切と判断したCloud Volumes Service にピアリングできます。Google Cloud Marketplaceサブスクリプションへのアクセスの管理、およびデータプレーンへのアクセス権を持つVPCの管理は、お客様の責任において行ってください。</block>
  <block id="1e9614b8d81927a9e9bad94fe64884d6" category="section-title">悪意のあるSRE保護</block>
  <block id="1ced9b3b1b2408070d8594c7310def52" category="paragraph">Cloud Volumes Service は、悪意のあるSREが存在するシナリオやSRE資格情報が侵害された場合に、どのように保護するのかという懸念事項があります。</block>
  <block id="0cf58dc2d9a00ecaeb191e61685b36e5" category="paragraph">本番環境へのアクセスには、限られた数のSRE担当者のみが使用されます。管理者権限は、経験豊富な一部の管理者にも制限されています。Cloud Volumes Service の運用環境で実行されるすべてのアクションは記録され、ベースラインまたは疑わしいアクティビティへの異常は、セキュリティ情報およびイベント管理（SIEM）脅威インテリジェンスプラットフォームによって検出されます。その結果、悪意のあるアクションを追跡し、Cloud Volumes Service バックエンドに過剰な損害が発生する前に軽減することができます。</block>
  <block id="9893b21aa64e031fdfd6920fef8147a3" category="section-title">ボリュームのライフサイクル</block>
  <block id="1135939baa7babe550972f3d2430315f" category="paragraph">Cloud Volumes Service は、サービス内のオブジェクトのみを管理し、ボリューム内のデータは管理しません。データ、ACL、ファイル所有者などを管理できるのは、ボリュームにアクセスしているクライアントだけです。これらのボリューム内のデータは保存中も暗号化され、Cloud Volumes Service インスタンスのテナントのみにアクセスできます。</block>
  <block id="dd04bd242a373a0c9b066d0704ba4d66" category="paragraph">Cloud Volumes Service のボリュームライフサイクルはcreate-update-deleteです。ボリュームは、ボリュームが削除されるまでボリュームのSnapshotコピーを保持します。Cloud Volumes Service 内のボリュームを削除できるのは、検証済みのCloud Volumes Service 管理者だけです。管理者がボリューム削除を要求した場合、削除の確認のためにボリューム名を入力する手順が追加で必要になります。ボリュームを削除すると、そのボリュームは削除され、リカバリできなくなります。</block>
  <block id="1744c1e09f5b1b7990b7f2b80a7a9500" category="paragraph">Cloud Volumes Service 契約を終了した場合、ネットアップは特定の期間が経過したボリュームに削除マークを付けます。この期間が終了する前に、お客様の要求に応じてボリュームをリカバリできます。</block>
  <block id="13e637fe96062929286b911c16b3c2df" category="section-title">認定資格</block>
  <block id="af06a002abcc2b02896192d8fd1052cd" category="inline-link">コンプライアンス：データ セキュリティ とデータプライバシー</block>
  <block id="258a58248bd2280e3d97717c4150b3cf" category="paragraph">Google Cloud向けCloud Volume サービスは、現在ISO/IEC 27001：2013およびISO/IEC 27018：2019規格に準拠しています。サービスは最近、SOC2 Type Iアテステーションレポートを受信しました。ネットアップの データ セキュリティ への取り組みとプライバシーに関する詳細については、を参照してください<block ref="751448d9ace7c1569cfa25749b75ea26" category="inline-link-rx"></block>。</block>
  <block id="4e94c8ad46c8aef1ca637841dfbe2159" category="section-title">GDPR</block>
  <block id="ee69241049506ca93a3a1cd627e44851" category="inline-link">お客様との契約</block>
  <block id="15655a5f67808f893102ffa3cbde3b01" category="inline-link">カスタマーデータ処理補遺</block>
  <block id="cd0ae90a69c7d21d42b18252b9e1707d" category="inline-link">標準契約条項</block>
  <block id="de315e46a9bdf4936de71254f87d2fe0" category="paragraph">プライバシーに対する当社のコミットメントとGDPRへの準拠は、当社のさまざまな方法で提供されています <block ref="c2118342007d8714fcb1b4f6106c575c" category="inline-link-rx"></block>などです<block ref="7f657124cd056ea8e74c57dcafd4df75" category="inline-link-rx"></block>が含まれます <block ref="85bd1a4ed188bfd53fcaef2fb6e1962a" category="inline-link-rx"></block> 欧州委員会が提供します。また、当社のプライバシーポリシーには、当社の企業行動規範に規定されている中核的な価値観に裏付けられたこれらのコミットメントを定めています。</block>
  <block id="648d64814699b339816911e595b789cd" category="inline-link-macro">次：追加情報 、バージョン履歴、連絡先情報。</block>
  <block id="259ea0e5275404f9f6b7793a369cf8d5" category="paragraph"><block ref="259ea0e5275404f9f6b7793a369cf8d5" category="inline-link-macro-rx"></block></block>
  <block id="81e9930d895d3e301d9d41dffc998bf4" category="summary">クラウド解決策 を信頼する一部は、アーキテクチャとその保護方法を理解していることです。このセクションでは、GoogleのCloud Volumes Service アーキテクチャのさまざまな側面を紹介し、データのセキュリティ保護に関する潜在的な懸念を軽減するとともに、最も安全な導入を実現するために追加の設定手順が必要な領域について説明します。</block>
  <block id="cce1d49f67059a9bd1ae8d0bdb0c40c6" category="inline-link-macro">前の手順：セキュリティに関する考慮事項と攻撃対象</block>
  <block id="64ff582fefc046b48708216a4686161c" category="paragraph"><block ref="64ff582fefc046b48708216a4686161c" category="inline-link-macro-rx"></block></block>
  <block id="e5a9d7217b1490853e4230120cdedb32" category="paragraph">Cloud Volumes Service の一般的なアーキテクチャは、コントロールプレーンとデータプレーンの2つの主要コンポーネントに分類できます。</block>
  <block id="650717c72d7a99e6505592f83821e4ed" category="section-title">コントロールプレーン</block>
  <block id="b2b6e947ec64376b51417e89ab29e213" category="paragraph">Cloud Volumes Service のコントロールプレーンは、Cloud Volumes Service 管理者とネットアップの標準の自動化ソフトウェアが管理するバックエンドインフラです。このプレーンはエンドユーザに対して完全に透過的であり、ネットワーキング、ストレージハードウェア、ソフトウェアアップデートなどが含まれており、Cloud Volumes Service などのクラウド常駐解決策 に価値を提供します。</block>
  <block id="52a0e67f81bfbe486860a8219dfb3707" category="section-title">データプレーン</block>
  <block id="9d4d4fccf74cab21d8073077985a0cf6" category="paragraph">Cloud Volumes Service のデータプレーンには、実際のデータボリュームとCloud Volumes Service の全体的な設定（アクセス制御、Kerberos認証など）が含まれています。データプレーンは、エンドユーザとCloud Volumes Service プラットフォームの消費者の制御下に完全にあります。</block>
  <block id="099a80e29da5319c76116b6b2b41b2bf" category="paragraph">各平面の保護および管理方法には、異なる違いがあります。以降のセクションでは、Cloud Volumes Service アーキテクチャの概要から始めて、これらの違いについて説明します。</block>
  <block id="69259c19ec0d9503c7d352a664a85953" category="inline-link-macro">次の例は、Cloud Volumes Service のアーキテクチャです。</block>
  <block id="06ef1ecb5da986ebfb9901831437a0d8" category="paragraph"><block ref="06ef1ecb5da986ebfb9901831437a0d8" category="inline-link-macro-rx"></block></block>
  <block id="9114bfd7ba3e781df4e595c0a3199bfb" category="summary">データのセキュリティを確保する方法を理解する最初のステップは、リスクと潜在的な攻撃対象を特定することです。</block>
  <block id="d446619c29484b970941bed7884dfd57" category="doc">セキュリティに関する考慮事項と攻撃対象</block>
  <block id="9835bd91d6121b399eb4318f5f6aecab" category="inline-link-macro">前のページ：Google CloudのCloud Volumes Service でデータを保護する方法</block>
  <block id="00bbf283b6d94328be9e19fd69a5e57d" category="paragraph"><block ref="00bbf283b6d94328be9e19fd69a5e57d" category="inline-link-macro-rx"></block></block>
  <block id="da24915274d8feb20f2be6f37c42bb43" category="paragraph">データのセキュリティを確保する方法を理解する最初のステップは、リスクと潜在的な攻撃対象を特定することです。これには、次のものが含まれます（ただし、これらに限定されません）。</block>
  <block id="1f48f12466296c53740ed0375b4d0111" category="list-text">管理とログイン</block>
  <block id="78b73d10586b526c3f0d3f97bd32dfba" category="list-text">保存データ</block>
  <block id="42517361027a563c9ab61d813badc939" category="list-text">転送中のデータ</block>
  <block id="58be36e591707c2a60f9bed405a8ef25" category="list-text">ネットワークとファイアウォール</block>
  <block id="3a7d83d110f5fe7d4f435b9594806caf" category="list-text">ランサムウェア、マルウェア、ウイルス</block>
  <block id="417a78919920edf51d22038b236740f1" category="paragraph">攻撃の対象となる面を理解することで、環境のセキュリティを強化できます。Google CloudのCloud Volumes Service は、これらのトピックの多くをすでに考慮しており、管理者の介入なしにデフォルトでセキュリティ機能を実装しています。</block>
  <block id="70e43ccaf26985ea09dd44568ea9f36b" category="section-title">セキュアなログインの確保</block>
  <block id="67fe2a3de92df4f2c45227cff1adea77" category="paragraph">重要なインフラコンポーネントを保護するには、承認されたユーザのみがログインして環境を管理できるようにすることが不可欠です。不良なアクターが管理資格情報に違反した場合、そのアクターは城へのキーを持ち、必要な操作（構成の変更、ボリュームとバックアップの削除、バックドアの作成、スナップショットスケジュールの無効化）を実行できます。</block>
  <block id="3a2f2973e275ef04d08d1dda935f1ee0" category="paragraph">Cloud Volumes Service for Google Cloudを使用すると、ストレージサービス（StaaS）の難読化により、不正な管理ログインを防止できます。Cloud Volumes Service はクラウドプロバイダによって完全に管理されており、外部からのログインはできません。セットアップと設定の処理はすべて完全に自動化されているため、ごくまれな状況を除いて、人間の管理者がシステムを操作する必要はありません。</block>
  <block id="22b01eb5fb8c08ffb16c6ef9ef8b71b6" category="inline-link-macro">「Cloud Volumes Service アーキテクチャ」</block>
  <block id="b019d60ff2b9589700c94d2d71d13c8f" category="paragraph">ログインが必要な場合、Google CloudのCloud Volumes Service は、システムにログインするためのアクセス権を持つ信頼できる管理者のごく短いリストを保持することで、ログインを保護します。このゲートキーピングは、アクセス権を持つ潜在的な不正アクターの数を減らすのに役立ちます。さらに、Google Cloudネットワークは、ネットワークセキュリティの層の背後にあるシステムを隠し、外部に必要なものだけを公開します。Google CloudのCloud Volumes Service アーキテクチャについては、を参照してください <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="582157e9744c945cab3000f99e5c51f4" category="section-title">クラスタの管理とアップグレード</block>
  <block id="ac816ab3f2fb9ede37e87c223bf39690" category="paragraph">潜在的なセキュリティリスクを持つ2つの領域には、クラスタ管理（不正なアクターに管理者アクセス権がある場合に発生する動作）とアップグレード（ソフトウェアイメージが侵害された場合に発生する動作）があります。</block>
  <block id="e3f83199a3d154c9a938a90ed76188d4" category="section-title">ストレージ管理の保護</block>
  <block id="e9406b6097629a60364e6b24a83dd40b" category="inline-link-macro">「サービスオペレーション」</block>
  <block id="a16c40cfa1517a64fe23c8a84e7fca32" category="paragraph">ストレージサービスとして提供されるため、クラウドデータセンターの外部にあるエンドユーザがアクセスするリスクが軽減され、管理者のリスクを高めることができます。代わりに、顧客がデータアクセスプレーンを対象とした唯一の設定が行われます。各テナントは固有のボリュームを管理し、テナントが他のCloud Volumes Service インスタンスにアクセスすることはできません。このサービスは自動化によって管理され、セクションで説明するプロセスを通じて、信頼できる管理者のごく一部にシステムへのアクセス権が付与されます <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="bc94b58452719d0cfedd1ceb30c4fd53" category="paragraph">CVS -パフォーマンスサービスタイプでは、リージョンに障害が発生した場合に別のリージョンにデータを保護するオプションとして、リージョン間のレプリケーションを提供できます。このような場合は、Cloud Volumes Service を影響を受けない領域にフェイルオーバーしてデータアクセスを維持できます。</block>
  <block id="b8bb5b62315a69e1364d070de73bbfa5" category="section-title">サービスのアップグレード</block>
  <block id="a5e1144c0e37d7facbd53bdffaa58f52" category="paragraph">更新プログラムは、脆弱なシステムの保護に役立ちます。各アップデートには、セキュリティの強化機能とバグ修正が含まれており、攻撃対象となる面を最小限に抑えるソフトウェアの更新は、中央リポジトリからダウンロードされ、更新が許可される前に検証されて、公式イメージが使用されていること、およびアップグレードが不正なアクターによって侵害されていないことを確認します。</block>
  <block id="79f1689ccfaec67bc50dd620185adbac" category="paragraph">Cloud Volumes Service を使用すると、クラウドプロバイダチームが更新を処理できるため、管理者チームは、プロセスの自動化と完全なテストに精通したエキスパートが設定とアップグレードに精通することで、リスクの危険性を回避できます。アップグレードは無停止で実行され、Cloud Volumes Service は全体的な最善の結果を得るために最新の更新を維持します。</block>
  <block id="6a274e2791c8f2a1f59a7a6f87261122" category="paragraph">これらのサービスのアップグレードを実行する管理者チームの詳細については、を参照してください <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="eeae9bcc33a487e1224ffb4815f79821" category="section-title">保存データを保護</block>
  <block id="11062b94d57add7cf5c44a9ec7e9274c" category="paragraph">保管データの暗号化は、ディスクが盗難、返却、転用された場合に機密データを保護するために重要です。Cloud Volumes Service のデータは、ソフトウェアベースの暗号化を使用して保存データを保護します。</block>
  <block id="ad04a8dc3b058793f75e8c97c787ceea" category="list-text">Googleで生成されたキーは、CVS-SWに使用されます。</block>
  <block id="b114edcfa107ab9d459e2e75aea2cfdb" category="inline-link">FIPS 140-2認定番号4144</block>
  <block id="855bcb8730de4b24527a09801b103d97" category="list-text">CVSパフォーマンスの場合、ボリューム単位のキーはCloud Volumes Service に組み込まれたキー管理ツールに格納されます。このキー管理ツールでは、NetApp ONTAP CryptoModを使用してAES-256暗号化キーが生成されます。CryptoModは、CMVP FIPS 140-2の検証済みモジュールのリストに表示されています。を参照してください<block ref="c8bf3ef21e8efdca1f27a1e57e809607" category="inline-link-rx"></block>。</block>
  <block id="a934c8bfa11942a4baa792ed229b8bb8" category="paragraph">2021年11月より、CVSパフォーマンス向けにプレビューによる顧客管理暗号化（CMEK）機能が提供されました。この機能を使用すると、ボリュームごとのキーを、Google Key Management Service（KMS）でホストされているプロジェクトごとのリージョンごとのマスターキーで暗号化できます。KMSを使用すると、外部キー管理ツールを接続できます。</block>
  <block id="08a22fe6e00e4ceb40cd56453b4a5864" category="paragraph">アーキテクチャの詳細については、を参照してください <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="fb787119808b111e9df5553be31361c8" category="section-title">転送中のデータを保護</block>
  <block id="8255b8a6d9844c87b5ecd1d2287b2f60" category="paragraph">保存データを保護するだけでなく、Cloud Volumes Service インスタンスとクライアントまたはレプリケーションターゲットの間で転送中のデータも保護する必要があります。Cloud Volumes Service では、Kerberosを使用したSMB暗号化、パケットの署名と封印、データ転送のエンドツーエンド暗号化に使用するNFS Kerberos 5pなどの暗号化方式を使用して、NASプロトコルで転送中のデータを暗号化できます。</block>
  <block id="c42b0018cf60c30c0490998e63dfdac1" category="paragraph">Cloud Volumes Service ボリュームのレプリケーションにはTLS 1.2が使用され、AES-GCM暗号化方式を利用できます。</block>
  <block id="17882f1649689ee4f6fcf4aeba6d150b" category="paragraph">TelnetやNDMPなどのセキュアでないインフライトプロトコルのほとんどは、デフォルトで無効になっています。ただし、DNSはCloud Volumes Service によって暗号化されないため（DNSセキュリティはサポートされません）、可能な場合は外部ネットワーク暗号化を使用して暗号化する必要があります。を参照してください <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block> 転送中のデータの保護に関する詳細については、を参照してください。</block>
  <block id="4bb00cc1adfaf9a4b73ae2593bc7d4e8" category="inline-link-macro">「NASプロトコル」。</block>
  <block id="d47f2c6bf1e6a3776038244ab35f5415" category="paragraph">NASプロトコルの暗号化については、を参照してください <block ref="386abb448925212e530f9be720946265" category="inline-link-macro-rx"></block></block>
  <block id="46dc4f8fa1d2951250a02fa29fccc4cb" category="section-title">NAS権限のユーザとグループ</block>
  <block id="4a6786c54b7ea4a860834c0ffda11c7f" category="paragraph">クラウドでデータを保護するには、適切なユーザ認証とグループ認証が必要になります。この場合、データにアクセスするユーザは環境内の実ユーザとして検証され、グループには有効なユーザが含まれます。これらのユーザとグループは、初回の共有アクセスとエクスポートアクセスに加え、ストレージシステム内のファイルとフォルダの権限検証も提供します。</block>
  <block id="52c7382ae7438c8a3366ad6f38d5d2a4" category="paragraph">Cloud Volumes Service では、SMB共有およびWindows形式の権限に対して、Active Directoryベースの標準のWindowsユーザ認証およびグループ認証を使用します。このサービスでは、NFSエクスポート、NFSv4 ID検証、Kerberos認証、NFSv4 ACL用のLDAPなど、UNIXユーザおよびグループのUNIX IDプロバイダも利用できます。</block>
  <block id="59935480b9f5ac6361a1a360ad8a9ec2" category="admonition">現在のところ、Cloud Volumes Service for LDAP機能ではActive Directory LDAPのみがサポートされています。</block>
  <block id="7c47e0b7c3aa389a1b437364885d5562" category="section-title">ランサムウェア、マルウェア、ウィルスの検出、防止、および軽減</block>
  <block id="b647cba0e4b0ad0f479019e47713c5a2" category="paragraph">ランサムウェア、マルウェア、ウィルスは管理者にとって常に脅威であり、これらの脅威の検出、防止、および軽減は、エンタープライズ組織にとって常に最重要課題です。重要なデータセットでランサムウェアが1回発生すると、数百万ドルのコストがかかる可能性があるため、リスクを最小限に抑えるために何ができるかを実行することが有益です。</block>
  <block id="ba1e21a6e8310b88e0349770718e717c" category="inline-link">ランサムウェアの自動検出</block>
  <block id="b80fb0d337605da9f0fdaf2687c3de1e" category="paragraph">Cloud Volumes Service には、現在、アンチウイルス保護やなどのネイティブの検出や防止対策は含まれていませんが<block ref="2ed126fbf9f5caf3d13a90f230e3475a" category="inline-link-rx"></block>では、定期的なSnapshotスケジュールを有効にすることで、ランサムウェアのイベントから迅速にリカバリする方法がいくつかあります。Snapshotコピーは変更不可で、ファイルシステム内の変更されたブロックへの読み取り専用ポインタであり、ほぼ瞬時に作成されます。パフォーマンスへの影響は最小限で、データが変更または削除された場合にのみスペースを消費します。Snapshotコピーのスケジュールは、許容されるRecovery Point Objective（RPO；目標復旧時点）やRecovery Time Objective（RTO；目標復旧時間）に合わせて設定できます。また、ボリュームあたり最大1、024個のSnapshotコピーを保持できます。</block>
  <block id="e9c1c7d4ca860adb553d87c2c1d9ef35" category="inline-link">『NetApp解決策 for Ransomware』</block>
  <block id="85ebd62090617323187e9e7827c343e7" category="paragraph">Cloud Volumes Service では、Snapshotのサポートは追加料金なしで利用でき（Snapshotコピーによって保持される変更されたブロックやデータのストレージ料金を除く）、ランサムウェア攻撃が発生した場合には、攻撃が発生する前にSnapshotコピーにロールバックするために使用できます。Snapshotのリストアは完了までに数秒しかかかりませんが、リストア完了後は通常どおりデータを提供できます。詳細については、を参照してください<block ref="e347ba4858ee244fead32d2fe59a64dd" category="inline-link-rx"></block>。</block>
  <block id="7994d1312e8f4fe2cdf2f7e13347d8bf" category="paragraph">ランサムウェアによるビジネスへの影響を回避するには、次のようなマルチレイヤアプローチが必要です。</block>
  <block id="7aa2bd35ac13684bd5c9434296dd6b03" category="list-text">エンドポイント保護</block>
  <block id="9cdff1d919782c79338864086178c7b0" category="list-text">ネットワークファイアウォールによる外部の脅威からの保護</block>
  <block id="eb4079f2ecc7735fcfaa169c5562cbfd" category="list-text">データの異常を検出します</block>
  <block id="aac3c67c846910bdfd381a7101344e96" category="list-text">重要なデータセットの複数のバックアップ（オンサイトおよびオフサイト）</block>
  <block id="3845e8b5ec9d78bcebac29ec50d8077f" category="list-text">バックアップの定期的なリストアテスト</block>
  <block id="a550fe6fd1b40af5260e9636cdea66fd" category="list-text">変更不可の読み取り専用NetApp Snapshotコピー</block>
  <block id="533a4f72ffc639d4cc87d034dfe92f2c" category="list-text">重要なインフラに対する多要素認証</block>
  <block id="b1d3b419f981a509b3c5203c7546b96b" category="list-text">システムログインのセキュリティ監査</block>
  <block id="4e329c801824e6bdc0209c98146064c3" category="paragraph">このリストは、完全なものではありませんが、ランサムウェア攻撃の可能性を扱う際の青写真としては適しています。Google CloudのCloud Volumes Service では、ランサムウェアのイベントを保護してその影響を軽減する方法を複数提供しています。</block>
  <block id="2fdb508dbc71674add1fe7fc21ccbf8e" category="section-title">変更不可のSnapshotコピー</block>
  <block id="1682a7464d9210c8161ec78abc8010e2" category="paragraph">Cloud Volumes Service は、データを削除した場合や、ランサムウェア攻撃によってボリューム全体が影響を受けた場合に、カスタマイズ可能なスケジュールで作成された書き換え不可の読み取り専用Snapshotコピーを標準で提供します。以前の正常なSnapshotコピーへのSnapshotのリストアは高速で、Snapshotスケジュールの保持期間とRTO/RPOに基づいてデータ損失を最小限に抑えます。Snapshotテクノロジによるパフォーマンスへの影響はごくわずかです。</block>
  <block id="c0bd33c36fff1f6dbb2bf9253a7f40dd" category="paragraph">Cloud Volumes Service のSnapshotコピーは読み取り専用であるため、ランサムウェアが大量に発生してデータセットにデータが拡散し、Snapshotコピーがランサムウェアによって感染した場合を除き、ランサムウェアに感染することはできません。そのため、ランサムウェアによるデータの異常を検出することも検討する必要があります。Cloud Volumes Service は、現在ネイティブでは検出機能を提供していませんが、外部監視ソフトウェアを使用することもできます。</block>
  <block id="9b641219ac63451505f5a25a887038d4" category="section-title">バックアップとリストア</block>
  <block id="5e2f84170723d4cfed011f9ebc6c557e" category="paragraph">Cloud Volumes Service は、標準のNASクライアントバックアップ機能（NFSまたはSMB経由のバックアップなど）を提供します。</block>
  <block id="0d69441d7fc21e56d3cf2eb944fbf6c1" category="inline-link">ボリュームのレプリケーション</block>
  <block id="161b127f579db2727ace94e4fb6f9e5b" category="inline-link">クラウドバックアップ</block>
  <block id="56a32ac982c7663e59f24c58cfb673d6" category="paragraph">ボリュームレプリケーションを実行すると、ソースボリュームの正確なコピーが作成されるため、ランサムウェアのイベントなどの災害が発生した場合に迅速にフェイルオーバーできます。</block>
  <block id="ae2679a66d07f8c7efd50d972a34a112" category="section-title">クロスリージョンレプリケーション</block>
  <block id="1a094951f7e9c42a89c4ef4b0b328eee" category="paragraph">CVS - Performanceを使用すると、Googleのネットワークで実行されているレプリケーションに使用される特定のインターフェイスを使用して、ネットアップが制御するバックエンドサービスネットワーク上でTLS1.2 AES 256 GCM暗号化を使用して、データ保護およびアーカイブのユースケース用にGoogle Cloudリージョン間でボリュームを安全に複製できます。プライマリ（ソース）ボリュームにはアクティブな本番データが格納され、セカンダリ（デスティネーション）ボリュームにレプリケートされてプライマリデータセットの正確なレプリカが提供されます。</block>
  <block id="f8e2c7b5b15f4332525ac9687a100a28" category="paragraph">最初のレプリケーションではすべてのブロックが転送されますが、更新ではプライマリボリューム内の変更されたブロックのみが転送されます。たとえば、プライマリボリュームにある1TBのデータベースがセカンダリボリュームにレプリケートされている場合、最初のレプリケーションでは1TBのスペースが転送されます。このデータベースの初期化と次の更新の間に数百行（仮定としては数MB）のデータがある場合、変更された行を持つブロックだけがセカンダリに複製されます（数MB）。これにより、転送時間を短縮し、レプリケーションの料金を抑えることができます。</block>
  <block id="fd25283b48ea77209e43fe9173df1354" category="paragraph">ファイルとフォルダに対する権限はすべてセカンダリボリュームにレプリケートされますが、共有のアクセス権限（エクスポートポリシーとルール、SMB共有と共有ACLなど）は別々に処理する必要があります。サイトフェイルオーバーの場合、デスティネーションサイトは同じネームサービスとActive Directoryドメイン接続を利用して、ユーザ、グループのIDおよび権限を一貫して処理する必要があります。災害が発生したときにセカンダリボリュームをフェイルオーバーターゲットとして使用するには、レプリケーション関係を解除します。これにより、セカンダリボリュームが読み書き可能に変換されます。</block>
  <block id="940c6fa9c7eb366ae4e471e545edb27b" category="paragraph">ボリュームのレプリカは読み取り専用で、書き換え不可のデータのコピーをオフサイトに保管します。このため、ウィルスに感染したデータやランサムウェアによってプライマリデータセットが暗号化された場合に、データを迅速にリカバリできます。読み取り専用データは暗号化されませんが、プライマリボリュームに影響があり、レプリケーションが実行された場合は、感染したブロックもレプリケートされます。影響を受けない古いSnapshotコピーをリカバリに使用できますが、SLAは、攻撃が検出されるまでの時間に応じて、約束されたRTO/RPOの範囲外になる可能性があります。</block>
  <block id="fe62647cc35dde214e0df1ae1fe9d0ab" category="inline-link">セキュリティに関する考慮事項</block>
  <block id="8ee215caafa31f1ecdd53056d288eb19" category="paragraph">Cloud Volumes Service はデータの保持性は高くなりますが、外部イベントによって原因 のデータが失われる可能性があります。ウィルスやランサムウェアなどのセキュリティイベントが発生した場合、バックアップとリストアは、データアクセスを迅速に再開するために不可欠なものになります。管理者が誤ってCloud Volumes Service ボリュームを削除した場合があります。また、ユーザは、データのバックアップバージョンを数カ月間保持し、Snapshotコピー用にボリューム内に余分なスペースを残しておくことがコストの課題となります。過去数週間にバックアップ・バージョンを維持して失われたデータをリストアする方法としてはSnapshotコピーを推奨しますが、Snapshotコピーはボリューム内に置かれており、ボリュームが失われると失われます。</block>
  <block id="a5cef37749b0ea6b89d13e2bfc190bcc" category="paragraph">Cloud Volumes Service バックアップを使用すると、Google Cloud Storage（GCS）にボリュームのコピーが生成されます。バックアップされるのはボリュームに格納されている実際のデータのみで、空きスペースはバックアップされません。増分データとして永久に機能するため、ボリュームの内容は1回転送され、以降も変更されたデータのみのバックアップが続行されます。従来のバックアップの概念と比較して、複数のフルバックアップを使用する場合に比べて、大量のバックアップストレージを節約し、コストを削減できます。バックアップスペースは、ボリュームと比べて月単位で少なくて済むため、バックアップバージョンの間隔を長くしておくのが理想的です。</block>
  <block id="d41618915810c18642064f885af2a835" category="paragraph">ユーザはCloud Volumes Service バックアップを使用して、同じリージョン内の同じボリュームまたは別のボリュームに任意のバックアップバージョンをリストアできます。ソースボリュームを削除した場合は、バックアップデータが保持され、個別に管理する必要があります（削除した場合など）。</block>
  <block id="3289695e643b478f0efa19edc74cf567" category="inline-link">Cloud Volumes Service バックアップのドキュメント</block>
  <block id="be7923d42a302a1a86fdaa9f096fde63" category="inline-link">サポートされる最大バックアップバージョン数</block>
  <block id="59aab28b54594c59dab8d19afd9478e4" category="inline-link">価格設定</block>
  <block id="9a647ae53ed9b2a783aef42530e1fe97" category="paragraph">プロジェクトのすべてのバックアップデータはGCSバケットに格納されます。GCSバケットはサービスによって管理され、ユーザには表示されません。各プロジェクトで異なるバケットを使用します。現在、バケットはCloud Volumes Service ボリュームと同じリージョンにありますが、その他のオプションについては現在説明しています。最新のステータスについては、のドキュメントを参照してください。</block>
  <block id="4e1c6d2a637d959db4ce4a09b3e5c580" category="paragraph">Cloud Volumes Service バケットからGCSへのデータ転送では、HTTPSとTLS1.2を使用したサービス内部のGoogleネットワークが使用されます。データはGoogleが管理するキーで保管中に暗号化されます。</block>
  <block id="5e467dce18f46b1803b06097fae60b82" category="inline-link">役割/ netappcloudvolumes .admin</block>
  <block id="d5588adba169169b3d9fbc3d40fa9e91" category="inline-link-macro">次は、アーキテクチャの概要です。</block>
  <block id="70c94a86f99e1aa5d40b6ca87c17a399" category="paragraph"><block ref="70c94a86f99e1aa5d40b6ca87c17a399" category="inline-link-macro-rx"></block></block>
  <block id="6ab0778deb23383f6063990e47d38567" category="summary">Cloud Volumes Service 内のすべてのボリュームはAES-256暗号化を使用して暗号化されます。つまり、メディアに書き込まれたすべてのユーザデータが暗号化され、ボリューム単位のキーでのみ復号化できます。</block>
  <block id="05a42723f4aebc1b8fea32f0da56f531" category="doc">保存データの暗号化</block>
  <block id="914e9cc2016ed2891bc115163b671205" category="inline-link-macro">Previous：転送中のデータの暗号化。</block>
  <block id="3ab72ed338391088a345040cc4ede7e0" category="paragraph"><block ref="3ab72ed338391088a345040cc4ede7e0" category="inline-link-macro-rx"></block></block>
  <block id="4a41d68019f2643468ef37e122fc87a9" category="list-text">CVS - SWの場合は、Googleで生成されたキーが使用されます。</block>
  <block id="68056df8fa340722ff859d534da347e4" category="list-text">CVS -パフォーマンスの場合は、ボリューム単位のキーが、Cloud Volumes Service に組み込まれているキー管理ツールに格納されます。</block>
  <block id="e23c4fadd8e7d70663bc3393bca7d576" category="inline-link">Google Key Management Service（KMS）：</block>
  <block id="387ccb6d293c8d2f51b2730c375c3f3a" category="paragraph">2021年11月より、顧客管理の暗号化キー（CMEK）機能のプレビューが提供されました。これにより、でホストされているプロジェクトごとのリージョンごとのマスターキーを使用して、ボリュームごとのキーを暗号化できます<block ref="145d140dc09dde7f8aacc53f1269c2de" category="inline-link-rx"></block> KMSを使用すると、外部キー管理ツールを接続できます。</block>
  <block id="1988a6b2308f38718c8100c2e344eb5c" category="inline-link">お客様が管理する暗号化キーを設定する</block>
  <block id="6a2064a5b36d77d1da28e1bb96fe613e" category="inline-link-macro">次の例はファイアウォールです。</block>
  <block id="d78ea12f26e93e819db4dd4772e8cb6e" category="paragraph"><block ref="d78ea12f26e93e819db4dd4772e8cb6e" category="inline-link-macro-rx"></block></block>
  <block id="13a2c7416db43025d8318ec9db325859" category="summary">転送中のデータはNASプロトコルレイヤで暗号化でき、Google Cloudネットワーク自体は暗号化されます。これについては、次の項で説明します。</block>
  <block id="f7ccd4455f141bba37dd989458bfd1f3" category="doc">転送中のデータ暗号化</block>
  <block id="44782cad8de83a97138ea3bcbd36c028" category="inline-link-macro">前の例：データプレーンアーキテクチャ。</block>
  <block id="9e17ee7c2f94201998bfd10292b5e098" category="paragraph"><block ref="9e17ee7c2f94201998bfd10292b5e098" category="inline-link-macro-rx"></block></block>
  <block id="8de1715de3864b137091fa8f6d71053f" category="section-title">Google Cloudネットワーク</block>
  <block id="a94ac9daf8e09a31f9e81f7de9ee7ab6" category="inline-link">転送中の暗号化</block>
  <block id="57d5b464e5bc1a25ae2337c72e492c88" category="paragraph">Google Cloudは、に記載されているように、ネットワークレベルでトラフィックを暗号化します<block ref="df3d10947a311abbd08a64a5cc9629d3" category="inline-link-rx"></block> Googleのドキュメントを参照してください。「Cloud Volume サービスアーキテクチャ」セクションで説明したように、Cloud Volumes Service は、ネットアップが管理するPSAプロデューサープロジェクトから提供されます。</block>
  <block id="4322a5ae7fc781564c1349bf92846311" category="paragraph">CVSソフトウェアの場合、プロデューサーテナントはGoogle VMを実行してサービスを提供します。ユーザーVMとCloud Volumes Service VM間のトラフィックは、Googleによって自動的に暗号化されます。</block>
  <block id="d3072f2789ba193441ddf485cc806a82" category="inline-link">IEEE 802.1AE暗号化（MACSec）</block>
  <block id="6141361c43c6e429fa93fd0f6f8b2dac" category="inline-link">カプセル化</block>
  <block id="2a5cd9c0503b957ff28d59f12a8bb05a" category="paragraph">CVSパフォーマンスのデータパスはネットワークレイヤでは完全に暗号化されていませんが、ネットアップとGoogleでは組み合わせて使用しています<block ref="83e770b09a2e800e59cae429b60dde07" category="inline-link-rx"></block>、<block ref="c5a2137e5d30663db35a2f990a0275f0" category="inline-link-rx"></block> （データ暗号化）、および物理的に制限されたネットワークを使用して、Cloud Volumes Service CVS -パフォーマンスサービスタイプとGoogle Cloudの間で転送されるデータを保護します。</block>
  <block id="95151e0beeb1cf14e98ed9e0e0ebc86f" category="section-title">NASプロトコル</block>
  <block id="7661437a0dea607fd6013193db5363be" category="paragraph">NFSおよびSMB NASプロトコルは、プロトコルレイヤでオプションのトランスポート暗号化を提供します。</block>
  <block id="198a269fc15076e5cc8ab572d6711771" category="section-title">SMB暗号化</block>
  <block id="69c2cd6d510299a43f241a4afbeef373" category="paragraph"><block ref="ebb0763fea63f976f4d3ea586b6fe491" category="inline-link-rx"></block> SMBデータをエンドツーエンドで暗号化し、信頼されていないネットワーク上での盗聴からデータを保護します。クライアント/サーバのデータ接続（smb3.x対応クライアントでのみ使用可能）とサーバ/ドメインコントローラの認証の両方に対して暗号化を有効にできます。</block>
  <block id="a8c42b910beec902a232a69b59a37847" category="paragraph">SMB暗号化が有効な場合、暗号化をサポートしていないクライアントは共有にアクセスできません。</block>
  <block id="72635a952bf12498ca4ca124b1a14d51" category="paragraph">Cloud Volumes Service は、SMB暗号化でRC4-HMAC、AES-128 - CTS-HMAC-SHA1、およびAES-256 - HMAC-SHA1セキュリティ暗号をサポートしています。SMBは、サーバによってサポートされている最も高い暗号化タイプとネゴシエートします。</block>
  <block id="980b28eb45b1ea66cdd07d05e78099a3" category="section-title">NFSv4.1 Kerberos</block>
  <block id="b97e4c9117cfcc0dd5d7a10e1a7a2631" category="inline-link">RFC7530</block>
  <block id="69a4f8e652e19cfdfb26e27d4447ae98" category="paragraph">NFSv4.1のCVSパフォーマンスでは、Kerberos認証を使用できます。を参照してください<block ref="526af9c532c496dd16998f764e15dc87" category="inline-link-rx"></block>。Kerberosはボリューム単位で有効にすることができます。</block>
  <block id="b2833929a77bd8c490997197ed3f00be" category="paragraph">Kerberosで現在使用可能な最も強力な暗号化タイプは、AES-256、HMAC-SHA1です。NetApp Cloud Volumes Service は、NFS用にAES-256 - HMAC-SHA1、AES-128 - HMAC-SHA1、DES3、およびDESをサポートしています。CIFS / SMBトラフィックではARCFOUR-MHMAC（RC4）もサポートされますが、NFSではサポートされません。</block>
  <block id="59417c70dd426d4c6a1a81a09043bb7b" category="paragraph">Kerberosでは、NFSマウントに対する3つの異なるセキュリティレベルが提供され、Kerberosセキュリティの強固な設定を選択できます。</block>
  <block id="710c8a535ea62cee124026e31e71a5bd" category="inline-link">Common Mount Options（共通マウントオプション）</block>
  <block id="224b49d2f24ee42bbb73b2ca635c6d9a" category="paragraph">RedHatの場合と同様です<block ref="1849b335749f623c227052141b2e8b11" category="inline-link-rx"></block> マニュアル：</block>
  <block id="babd6b3b4aea27ca41d56a231f2625af" category="paragraph">一般的に、Kerberosセキュリティレベルを高くするほど、クライアントとサーバが送信する各パケットのNFS操作の暗号化と復号化に時間を費やすので、パフォーマンスが低下します。多くのクライアントとNFSサーバは、CPUにAES-NIオフロードをサポートして全体的なエクスペリエンスを向上していますが、Kerberos 5p（完全なエンドツーエンドの暗号化）のパフォーマンスへの影響はKerberos 5（ユーザ認証）の影響よりも大幅に大きくなります。</block>
  <block id="986c123032dbfdac18bc180d1a2c3562" category="paragraph">次の表に、セキュリティとパフォーマンスの各レベルの違いを示します。</block>
  <block id="f12149bd43eabe8557e021017cfb9b1f" category="cell">セキュリティレベル</block>
  <block id="af75613ef5351b4f2563e49218c01d5b" category="cell">NFSv3：sys</block>
  <block id="d65540b3d2f3c15e237b23f6d4d823e5" category="list-text">最小のセキュリティ。数値のユーザIDまたはグループIDを含むプレーンテキスト</block>
  <block id="2310efb28386099d85b1dbcaf5f9c51f" category="list-text">UID、GID、クライアントIPアドレス、エクスポートパス、ファイル名を表示できる パケットキャプチャの権限</block>
  <block id="07b50706d3894aa894686195ddeed426" category="list-text">ほとんどの場合に最適です</block>
  <block id="54fcc149f825f18bfaaa374d6876e25a" category="cell">NFSv4.x - sys</block>
  <block id="3777f761befcdc3f42a4d77cde2962fe" category="list-text">NFSv3（クライアントID、名前文字列/ドメイン文字列の照合）よりも安全ですが、それでもテキストは表示されません</block>
  <block id="25199bb4f6f6a3eadd28c84579d0fcf7" category="list-text">UID、GID、クライアントIPアドレス、名前文字列、ドメインIDを表示できる パケットキャプチャでのエクスポートパス、ファイル名、権限</block>
  <block id="5145a8956e4807aeba5a7a4a1677c598" category="list-text">シーケンシャルワークロード（VM、データベース、大容量ファイルなど）に適している</block>
  <block id="bc96a40b0174b0ec2f9133e1e704d7cb" category="list-text">ファイル数が多い/メタデータが多い（30~50%悪化）</block>
  <block id="f25baf1a23f237c73f28b4834def4161" category="cell">NFS—krb5</block>
  <block id="0661ead41dc806181d0a0bff696e49df" category="list-text">すべてのNFSパケットのクレデンシャルのKerberos暗号化●GSSラッパー内のRPCコールでユーザ/グループのUID/GIDをラップします</block>
  <block id="b012a8b71e44e4c118c2a97f94c11c1f" category="list-text">マウントを要求しているユーザは、有効なKerberosチケット（ユーザ名とパスワード、または手動のキータブ交換）を必要とします。チケットは指定した期間が経過すると有効期限が切れ、ユーザはアクセスを再認証する必要があります</block>
  <block id="ab2293d06a9e3594a17eb02b827c471a" category="list-text">NFS処理またはmount / portmapper / NLMなどの補助プロトコル（エクスポートパス、IPアドレス、ファイルハンドル、権限、ファイル名を参照可能）の暗号化なし パケットキャプチャのatime / mtime）</block>
  <block id="6d140d250a49ec533ff2211674c16138" category="list-text">ほとんどの場合Kerberosに適しており、AUTH_SYSよりも深刻です</block>
  <block id="bc578f6162e4255fe0d1d4445ec8d975" category="cell">NFS—krb5i</block>
  <block id="7886fbf427a34b659783d690ee4ad3dd" category="list-text">マウントを要求しているユーザは、有効なKerberosチケット（ユーザ名/パスワードまたは手動のキータブ交換を使用）を必要とします。チケットは指定した期間が経過すると失効し、ユーザはアクセスを再認証する必要があります</block>
  <block id="49d02d7e5db8eb8139c3777891f63e2e" category="list-text">Kerberos GSSチェックサムが各パケットに追加されるため、パケットを傍受することはありません。チェックサムが一致する場合は、会話が許可されます。</block>
  <block id="0ea3431437c971e8ac8f271b60694b38" category="list-text">NFSペイロードは暗号化されないため、krb5pよりも優れています。krb5よりも追加されたオーバーヘッドのみが整合性のチェックサムです。krb5iのパフォーマンスはkrb5よりもそれほど悪くはないが、多少の低下が見られる。</block>
  <block id="facbd78bc28fa0b36f521d74ff5f0cec" category="cell">NFS–krb5p</block>
  <block id="d11093694c8bd1d8897446e4cf645e48" category="list-text">マウントを要求しているユーザは、有効なKerberosチケット（ユーザ名とパスワード、または手動のkeytab交換を使用）を必要とします。チケットは指定した期間が経過すると有効期限が切れ、ユーザはアクセスを再認証する必要があります</block>
  <block id="29af1c9e08784f1ef0e42433aef21eee" category="list-text">すべてのNFSパケットペイロードは、GSSラッパーで暗号化されます（パケットキャプチャではファイルハンドル、権限、ファイル名、atime/mtimeを確認できません）。</block>
  <block id="70aa40903816c1fda65618ae32c56d8b" category="list-text">整合性チェックが含まれます。</block>
  <block id="3e7dfd7567a414307d5fe93ea83ce4f6" category="list-text">NFSの処理タイプは表示されます（fsinfo、access、GETATTRなど）。</block>
  <block id="6b375be1f905197ba21c586647e973f4" category="list-text">補助プロトコル（マウント、portmap、NLMなど）は暗号化されません-（エクスポートパス、IPアドレスを参照可能）</block>
  <block id="6de6f14759a24d6fcb16973384e01c00" category="list-text">セキュリティレベルで最悪のパフォーマンス。krb5pは、暗号化や復号化がさらに必要です。</block>
  <block id="abac32415b4bfbaf4765dec9d36149cd" category="paragraph">Cloud Volumes Service では、設定されたActive DirectoryサーバがKerberosサーバおよびLDAPサーバとして使用されます（RFC2307互換スキーマからユーザIDを検索する場合）。それ以外のKerberosサーバまたはLDAPサーバはサポートされません。Cloud Volumes Service では、アイデンティティ管理にLDAPを使用することを強く推奨します。NFS Kerberosがパケットキャプチャにどのように表示されるかについては、を参照してください <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="656b94b95418723e2acea6b86dc53e48" category="inline-link-macro">次の例：保存データの暗号化</block>
  <block id="6ca1480f90da15333bae5670283ea19f" category="paragraph"><block ref="6ca1480f90da15333bae5670283ea19f" category="inline-link-macro-rx"></block></block>
  <block id="d1a7050a3a677e1c229160462a179103" category="doc">追加情報 、バージョン履歴、および連絡先情報</block>
  <block id="b67313323e9670f2b3cc78a36af15174" category="inline-link-macro">Previous：サービスの処理。</block>
  <block id="5390c35bfa9dd0545fb51b84c8af3252" category="paragraph"><block ref="5390c35bfa9dd0545fb51b84c8af3252" category="inline-link-macro-rx"></block></block>
  <block id="4780631a0451a6605045de3ace692cc6" category="list-text">Cloud Volumes Service 向けGoogle Cloudドキュメント</block>
  <block id="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link"><block ref="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link-rx"></block></block>
  <block id="8e65fc49f8ebbf3d9cc9651ce7940654" category="paragraph"><block ref="8e65fc49f8ebbf3d9cc9651ce7940654" category="inline-link-rx"></block></block>
  <block id="0e8aec42089c0c73812fa42d1888b3c8" category="list-text">Googleプライベートサービスへのアクセス</block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">ネットアップの製品マニュアル</block>
  <block id="f670e58416e680d41a98914939ff8b4d" category="list-text">暗号化検証モジュールプログラム—NetApp CryptoMod</block>
  <block id="904728949094c548bcec2129979a28a6" category="inline-link"><block ref="904728949094c548bcec2129979a28a6" category="inline-link-rx"></block></block>
  <block id="50dc6dd0a76419597a78231ee45ad7f5" category="paragraph"><block ref="50dc6dd0a76419597a78231ee45ad7f5" category="inline-link-rx"></block></block>
  <block id="fb35bc32af8e0bce21ef22bad9052b39" category="inline-link"><block ref="0ea855bd074e3e4be70d90c120079c12" category="inline-link-rx"></block></block>
  <block id="56f0874ab11ee024b4419753f2a3f06f" category="paragraph"><block ref="801eea2aa1601f12cc3d53d718ad33a7" category="inline-link-rx"></block></block>
  <block id="61eb0e8494826dc8f30af9122fd97664" category="list-text">TR-4616 ：『 NFS Kerberos in ONTAP 』</block>
  <block id="ed78f5221deba5e60a950d28a62de702" category="inline-link"><block ref="ed78f5221deba5e60a950d28a62de702" category="inline-link-rx"></block></block>
  <block id="d677acd46c811ecd9bac37aa26d8668c" category="paragraph"><block ref="d677acd46c811ecd9bac37aa26d8668c" category="inline-link-rx"></block></block>
  <block id="b56a5394775a9f077c12cb3e770d913c" category="cell">2022年5月</block>
  <block id="1bebe65011b1928d45d041533c04d2b1" category="paragraph">本テクニカルレポートの品質向上について、ご意見をお寄せください。</block>
  <block id="8b1418ea0c579605e873907335ca62c7" category="paragraph">mailto：doccomments@netapp.com [ doccomments@netapp.com ^]までお問い合わせください。件名にはテクニカルレポート4918を含めてください。</block>
  <block id="402d245fd6f48d88ea661814c622456e" category="summary">NASプロトコルは、ネットワーク上の複数のクライアントが、GCP上のCloud Volumes Service などのストレージシステム上の同じデータにアクセスするための方法です。NFSとSMBは定義済みのNASプロトコルであり、Cloud Volumes Service がサーバとして機能するクライアント/サーバベースで動作します。</block>
  <block id="900608117b1be22303e2a172c6d9b280" category="doc">NASプロトコルの基本</block>
  <block id="d23b6e095547133ec383cdcb0f080e6e" category="inline-link-macro">前のバージョン：NASプロトコルの概要。</block>
  <block id="8de032a7ba389eddc7880273654515a6" category="paragraph"><block ref="8de032a7ba389eddc7880273654515a6" category="inline-link-macro-rx"></block></block>
  <block id="b03874a8574793b2c634d05da5dae732" category="paragraph">NASプロトコルは、ネットワーク上の複数のクライアントが、GCP上のCloud Volumes Service などのストレージシステム上の同じデータにアクセスするための方法です。NFSとSMBは定義済みのNASプロトコルであり、Cloud Volumes Service がサーバとして機能するクライアント/サーバベースで動作します。クライアントは、アクセス要求、読み取り要求、および書き込み要求をサーバに送信します。サーバは、ファイルのロックメカニズムを調整し、権限を格納し、IDおよび認証要求を処理します。</block>
  <block id="86a29faa66a25c7e3fd290cf1e53761c" category="paragraph">たとえば、NASクライアントがフォルダに新しいファイルを作成する場合は、次の一般的なプロセスが実行されます。</block>
  <block id="817aaff54aa6b5cd0e96c54c0b20ea1d" category="list-text">クライアントは、ディレクトリに関する情報（権限、所有者、グループ、ファイルID、使用可能なスペース、 など）。要求元のクライアントとユーザが親フォルダに対して必要な権限を持っている場合、サーバは情報を返します。</block>
  <block id="9ec40c2869366ebe8cf1a8c690bb6471" category="list-text">ディレクトリ上のアクセス許可がアクセスを許可されている場合、クライアントは、作成されるファイル名がファイルシステムにすでに存在するかどうかをサーバに確認します。ファイル名がすでに使用されている場合は、の作成に失敗します。ファイル名が存在しない場合、サーバーはクライアントに処理を続行できることを通知します。</block>
  <block id="83a9d09522edde42d016b5f2649ad9b6" category="list-text">クライアントがサーバを呼び出して、ディレクトリハンドルとファイル名を指定してファイルを作成し、アクセス日時と変更日時を設定します。サーバは、一意のファイルIDをファイルに発行して、同じファイルIDで他のファイルが作成されないようにします。</block>
  <block id="4884742626257d3e2fee8f3fa6d74f9c" category="list-text">クライアントは、書き込み処理の前に、ファイル属性をチェックする呼び出しを送信します。権限で許可されている場合、クライアントは新しいファイルを書き込みます。プロトコル/アプリケーションでロックが使用されている場合、クライアントは、データ破損を防ぐために、ロック中に他のクライアントがファイルにアクセスできないようにするために、サーバにロックを要求します。</block>
  <block id="9f36fd781ab1b50b7d007cb7bbd31f1f" category="inline-link-macro">次の例：nfs。</block>
  <block id="e120d5e9a70a32a053802947c9767294" category="paragraph"><block ref="e120d5e9a70a32a053802947c9767294" category="inline-link-macro-rx"></block></block>
  <block id="432be93985cd954e5f755048381e528d" category="summary">NFSは、Request for Comments（RFC）で定義されたオープンIETF標準である分散ファイルシステムプロトコルで、誰でもこのプロトコルを実装できます。</block>
  <block id="ba3cb198ccc0137ff2861f85eff2b3ce" category="inline-link-macro">以前：NASプロトコルの基本原則_overview</block>
  <block id="2be8e5e3e57aed02dfb62a58afdadfad" category="paragraph"><block ref="2be8e5e3e57aed02dfb62a58afdadfad" category="inline-link-macro-rx"></block></block>
  <block id="b53dfc952aa9d99343d94971cf6c3fee" category="paragraph">Cloud Volumes Service 内のボリュームは、クライアントまたはクライアントのセットからアクセスできるパスをエクスポートすることによって、NFSクライアントに共有されます。これらのエクスポートをマウントするための権限は、Cloud Volumes Service 管理者が設定可能なエクスポートポリシーとルールによって定義されます。</block>
  <block id="0e3cb63bde3f98dbd812d470d8b100cf" category="paragraph">ネットアップのNFS実装はプロトコルのゴールドスタンダードとみなされ、無数のエンタープライズNAS環境で使用されています。以降のセクションでは、NFSと、Cloud Volumes Service で使用できる特定のセキュリティ機能、およびそれらの実装方法について説明します。</block>
  <block id="8b575afc20d2914501471190a68364ed" category="section-title">デフォルトのローカルUNIXユーザおよびグループ</block>
  <block id="c9f0864944a97085b2897c473c91dccc" category="paragraph">Cloud Volumes Service には、基本的な機能のさまざまなデフォルトUNIXユーザおよびグループが含まれています。このようなユーザおよびグループは、現在変更または削除できません。現在、新しいローカルユーザとローカルグループをCloud Volumes Service に追加することはできません。デフォルトのユーザとグループ以外のUNIXユーザおよびグループは、外部LDAPネームサービスによって提供する必要があります。</block>
  <block id="8002bcf6ec4e483483e32633f99bee00" category="paragraph">次の表に、デフォルトのユーザとグループ、および対応する数値IDを示します。LDAPまたはローカルクライアントでこれらの数値IDを再使用する新しいユーザまたはグループを作成しないことを推奨します。</block>
  <block id="0346306b31bbb7a0ae5245da13ec03c4" category="cell">デフォルトユーザ：数値ID</block>
  <block id="c782adef8851cb8855543f329d548bb2" category="cell">デフォルトグループ：数値ID</block>
  <block id="a38b2868ff594195dcec8e7fe562b0be" category="list-text">ルート：0</block>
  <block id="44b4512252320c293616b69743e2a445" category="list-text">pcuser：65534</block>
  <block id="95312f9502cf30aaff5cbbd3a4585a68" category="list-text">nobody：65535</block>
  <block id="39fff4671c3793536f3df78e41aed899" category="list-text">デーモン：1.</block>
  <block id="ffe991bd5946c28affb0a08326a88c3f" category="admonition">NFSv4.1を使用している場合、NFSクライアントでディレクトリリストコマンドを実行すると、rootユーザがnobodyと表示されることがあります。これは、クライアントのIDドメインマッピング設定が原因です。を参照してください <block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block> この問題 の詳細および解決方法については、を参照してください。</block>
  <block id="97d69dfca64d2bd85ec6cc9736cd662b" category="section-title">rootユーザ</block>
  <block id="767a04b899f673915ec8d6d78f549f3b" category="paragraph">Linuxの場合、rootアカウントはLinuxベースのファイルシステムのすべてのコマンド、ファイル、フォルダにアクセスできます。このアカウントの権限のため、セキュリティのベストプラクティスでは、rootユーザを何らかの方法で無効にしたり制限したりする必要があります。NFSエクスポートでは、エクスポートポリシーとルール、およびroot squashと呼ばれる概念を使用して、rootユーザがファイルやフォルダを経由する際の電力をCloud Volumes Service で制御できます。</block>
  <block id="7cd60419657f1f0735c557afd44724f0" category="inline-link">setuid / setgidコマンド（スティッキービット）</block>
  <block id="b95ee7e499b2b5ee7f9c911c9c86f8a2" category="paragraph">rootの引き下げにより、NFSマウントにアクセスしているrootユーザーは、匿名の数値ユーザー65534に引き下げられます（「」を参照）<block ref="07a7b24bc0f7cda943dc05060d1188d8" category="inline-xref-macro-rx"></block>」）に設定されており、現在、CVSパフォーマンスを使用する場合にのみ利用できます。この場合は、エクスポートポリシールールの作成時にrootアクセスにOffを選択します。rootユーザを匿名ユーザに引き下げた場合、chownまたはを実行できなくなります<block ref="451ac5d05b7e3e41db0c92126d9290ad" category="inline-link-rx"></block> NFSマウント内のファイルまたはフォルダ、およびrootユーザが作成したファイルまたはフォルダについては、anon UIDが所有者/グループとして表示されます。また、NFSv4 ACLをrootユーザが変更することはできません。ただし、rootユーザは引き続きchmodにアクセスでき、削除されたファイルは明示的な権限を持っていません。rootユーザーのファイルおよびフォルダのアクセス権へのアクセスを制限する場合は、NTFS ACLを持つボリュームを使用し、「root」という名前のWindowsユーザーを作成し、必要なアクセス権をファイルまたはフォルダに適用することを検討してください。</block>
  <block id="0b2cc4ee83c7e73e4426e294c95be2c7" category="section-title">匿名ユーザ</block>
  <block id="f489703ccadc6e9616bab479ace6cf03" category="paragraph">匿名（anon）ユーザIDは、有効なNFSクレデンシャルのないクライアント要求に割り当てられるUNIXユーザIDまたはユーザ名です。これには、rootの引き下げが使用されている場合のrootユーザが含まれます。Cloud Volumes Service のanonユーザは65534です。</block>
  <block id="48da046d67add0ab58d9cbc2c2da421c" category="paragraph">このUIDは、Linux環境では通常、ユーザ名「nobody」または「nfsnobody」に関連付けられます。Cloud Volumes Service はまた'ローカルUNIXユーザpcuserとして65534を使用します（を参照してください<block ref="21f1cd16f2baec63c7c604945762d1f2" category="inline-xref-macro-rx"></block>「）」と入力します。これは、有効な一致するUNIXユーザがLDAPで見つからない場合に、WindowsからUNIXへのネームマッピングのデフォルトフォールバックユーザでもあります。</block>
  <block id="1a64786b80a72f5b468ee5a6c27c19bb" category="paragraph">LinuxとCloud Volumes Service のUID 65534ではユーザ名が異なるため、NFSv4.1を使用する場合に65534にマッピングされたユーザの名前文字列が一致しないことがあります。その結果、一部のファイルやフォルダでは「nobody」がユーザーとして表示されることがあります。「」を参照してください<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>「この問題 の詳細と解決方法については、こちらをご覧ください。</block>
  <block id="093b885796f6b6edbf133d153a574ee0" category="section-title">アクセス制御/エクスポート</block>
  <block id="c40a72feaf9e622dcbd1a55edff6fdbf" category="paragraph">NFSマウントに対する最初のエクスポート/共有アクセスは、エクスポートポリシーに含まれるホストベースのエクスポートポリシールールによって制御されます。ホストIP、ホスト名、サブネット、ネットグループ、またはドメインが定義され、NFS共有へのアクセス、およびホストに許可されるアクセスレベルが許可されます。エクスポートポリシールールの設定オプションは、Cloud Volumes Service レベルによって異なります。</block>
  <block id="519377bf4a5b0a2078c3d66b249040aa" category="paragraph">CVS - SWの場合は、エクスポートポリシー設定に次のオプションを使用できます。</block>
  <block id="fdbbd602d808015eb2f536ce2add5b6e" category="list-text">*クライアント一致。* IPアドレスをカンマで区切ったリスト、ホスト名、サブネット、ネットグループ、ドメイン名をカンマで区切って指定します。</block>
  <block id="4984ee657e0bd2919476369a84dfe159" category="list-text">* RO/RWアクセスルール。*エクスポートへのアクセスレベルを制御するには、読み取り/書き込みまたは読み取り専用を選択します。</block>
  <block id="3a3236a433ddc1bb46fe40e058aad584" category="list-text">*ルートアクセス（オン/オフ）。*ルートスカッシュを設定します（「」を参照）<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>"詳細については、を参照してください。</block>
  <block id="0c1b0b2a02124e4f1e2111f36d28432e" category="list-text">*プロトコル・タイプ。* NFSマウントへのアクセスを特定のプロトコル・バージョンに制限します。ボリュームに対してNFSv3とNFSv4.1の両方を指定する場合は、両方を空白にするか、両方のチェックボックスをオンにします。</block>
  <block id="553de93bd85985676f0ef4762f4de2ab" category="list-text">* Kerberosセキュリティレベル（「Kerberosを有効にする」を選択した場合）。*読み取り専用アクセスまたは読み取り/書き込みアクセス用のkrb5、krb5i、およびkrb5pのオプションを提供します。</block>
  <block id="a98abf6af551f8564e89efb200e37032" category="section-title">所有権の変更（chown）とグループの変更（chgrp）</block>
  <block id="545978eda72a981e986a37d84621575d" category="paragraph">Cloud Volumes Service でNFSを使用すると、rootユーザに対してファイルとフォルダに対してchown / chgrpの実行のみを許可します。他のユーザーには「操作は許可されていません」というエラーが表示されます。これは、自分が所有しているファイルでもroot squashを使用する場合は、「」の項で説明されているようにしてください<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>」）、ルートはrootユーザに引き下げられ、chownおよびchgrpへのアクセスは許可されません。現時点では、Cloud Volumes Service でroot以外のユーザに対してchownとchgrpの両方を実行できるようにするための回避策はありません。所有権の変更が必要な場合は、デュアルプロトコルのボリュームを使用し、Windows側からアクセス権を制御するためにセキュリティ形式をNTFSに設定することを検討してください。</block>
  <block id="b40637b973f7941123dacf09ceef0fba" category="section-title">権限の管理</block>
  <block id="b48f3521890100492cddc30349f6e7b2" category="paragraph">Cloud Volumes Service では、UNIXセキュリティ形式を使用するボリュームのNFSクライアントに対する権限を制御するために、モードビット（rwxの場合に644、777など）とNFSv4.1 ACLの両方がサポートされます。標準の権限管理は、これら（chmod、chown、nfs4_setfaclなど）に対して使用し、これらをサポートするすべてのLinuxクライアントで機能します。</block>
  <block id="a4f4a04396f203764eb677e59aeea059" category="paragraph">また、NTFSに設定されたデュアルプロトコルボリュームを使用する場合、NFSクライアントはWindowsユーザへのCloud Volumes Service ネームマッピングを利用でき、NTFSアクセス権の解決に使用されます。これには、Cloud Volumes Service へのLDAP接続で数値IDからユーザ名への変換が必要です。Cloud Volumes Service では、Windowsユーザ名に正しくマッピングするために有効なUNIXユーザ名が必要です。</block>
  <block id="40c93306b7b5fa43d5bdeaaf6446b5c8" category="section-title">NFSv3にきめ細かなACLを提供</block>
  <block id="38244b1450366af1bc12c6d85adcf6d2" category="paragraph">モードビットのアクセス権はセマンティクス上の所有者、グループ、その他すべてのユーザにのみ適用され、基本的なNFSv3については、細かいユーザアクセス制御は行われません。Cloud Volumes Service は、POSIX ACLおよび拡張属性（chattrなど）をサポートしていないため、次のシナリオでのみ詳細なACLを使用できます。</block>
  <block id="15ad8d0b9866344d62ea9ffa4ae25982" category="list-text">有効なUNIXからWindowsへのユーザマッピングを使用するNTFSセキュリティ形式のボリューム（CIFSサーバが必要）。</block>
  <block id="c14f9a108935fe84b2ee2c80664062d4" category="list-text">管理クライアントを使用してACLを適用したNFSv4.1 ACL。</block>
  <block id="b90aebde70afe18a23fa55cafb7bd6e7" category="inline-link-macro">「LDAP」</block>
  <block id="fc96ac54908c774cd60159cf8c65272e" category="paragraph">どちらの方法でも、UNIX IDを管理するためにLDAP接続が必要です。また、有効なUNIXユーザおよびグループの情報が入力されている必要があります（を参照） <block ref="941c88f858b9781fbfe78651e071df70" category="inline-link-macro-rx"></block>）とは、CVSパフォーマンスインスタンスでのみ使用できます。NFSでNTFSセキュリティ形式のボリュームを使用するには、SMB接続を確立していない場合でも、デュアルプロトコル（SMBおよびNFSv3）またはデュアルプロトコル（SMBおよびNFSv4.1）を使用する必要があります。NFSv3マウントでNFSv4.1 ACLを使用するには、プロトコルタイプとして「both（nfsv3 / NFSv4.1）」を選択する必要があります。</block>
  <block id="b9fd9ad6fc3c3b72bb1d8b9db35c4ff8" category="inline-link">nfs4_acl - NFSv4アクセス制御リスト</block>
  <block id="8454ec39d80a4c7dced33aed7bc5cc3c" category="paragraph">通常のUNIXモードビットでは、NTFSまたはNFSv4.x ACLが提供する権限レベルは異なります。次の表に、NFSv3モードビットとNFSv4.1 ACLの権限の単位を比較します。NFSv4.1 ACLの詳細については、を参照してください<block ref="6f8990d4da30b2d9c1096f2d7fdec422" category="inline-link-rx"></block>。</block>
  <block id="04bf6ba29148b02f9bc0aece8b1ab976" category="cell">NFSv3 モードビット</block>
  <block id="ec969632045eaebe3e92b63bc00edf03" category="cell">NFSv4.1 ACL</block>
  <block id="b7073329ceba059aa3ad7875190c661f" category="list-text">実行時にユーザーIDを設定します</block>
  <block id="573fa671705c50ff1c121cd141dfeb90" category="list-text">実行時にグループIDを設定します</block>
  <block id="0ab8eb5c98bf5a8e01cc9dc03065fd63" category="list-text">スワップしたテキストを保存する(POSIXでは定義されていません</block>
  <block id="78e3e57905e586d5d03519b5883d9b49" category="list-text">所有者の読み取り権限</block>
  <block id="07ea3a6ddfd17ab896abc34a5fb98c32" category="list-text">所有者の書き込み権限</block>
  <block id="ef1c725ac00a8daafb96e6f926b38e84" category="list-text">ファイルの所有者の実行権限、またはディレクトリ内の所有者の検索（検索）権限</block>
  <block id="d51cc2a74a686e9f6b08108c215a677e" category="list-text">グループの読み取り権限</block>
  <block id="6750a7dbc586cfe9c3c1e6fc348bc47f" category="list-text">グループの書き込み権限</block>
  <block id="66471165b6102256624c1aaa1bf05ef9" category="list-text">ファイル上のグループの実行権限、またはディレクトリ内のグループの検索（検索）権限</block>
  <block id="860c8444d0dfe3bf1e1818fdbe8c3733" category="list-text">他のユーザーの読み取り許可</block>
  <block id="95663f359ae8aaa2910488b36c7168fb" category="list-text">他のユーザーの書き込み許可</block>
  <block id="54384d9f12231abb228dd692b2c7a689" category="list-text">ファイルに対する他のユーザーのアクセス許可を実行するか、ディレクトリ内の他のユーザーの検索(検索)アクセス許可を設定します</block>
  <block id="4d6deb7613496d18f12d0d0d0fe84ecb" category="paragraph">Access Control Entry（ACE;アクセス制御エントリ）タイプ（Allow/Deny/Audit）*継承フラグ* directory-inherit * file-inherit * no-propage-inherit * inherit-only</block>
  <block id="13640bb94453faf76256f49439337e2e" category="paragraph">Permissions * read-data（ファイル）/list-directories* write-data（ディレクトリ）* write-data（ファイル）/create-file（ディレクトリ）* append-data/create-subdirectory（ディレクトリ）* execute（ファイル）/change-directory（ディレクトリ）* delete * delete -child * read-write attributes * read-write -named-acl属性* read-write -acl属性* write-owner-acl属性*</block>
  <block id="0bfe97b6a2010bf8a46c30c256d9bc67" category="paragraph">最後に、NFSグループメンバーシップ（NFSv3とNFSv4.xの両方）は、RPCパケットの制限に従い、AUTH_SYSでのデフォルトの最大数である16に制限されています。NFS Kerberosでは、最大32のグループとNFSv4 ACLが提供され、ユーザおよびグループのACLをより細かく設定できるため（ACEごとに最大1024エントリ）、この制限は解消されます。</block>
  <block id="27aabeb671232f388e6288cf9395fda9" category="inline-link">NFSボリュームの作成と管理</block>
  <block id="75812520c9040a205064d0d2cb2263e9" category="section-title">NFSv3のユーザIDとグループID</block>
  <block id="b1695eaaf5db3491be45228e42d7894f" category="paragraph">NFSv3のユーザIDとグループIDは、名前ではなく数値IDでネットワークに送信される。NFSv3では、UNIXセキュリティ形式のボリュームでモードビットのみを使用する場合、これらの数値IDに対するCloud Volumes Service でのユーザ名の解決は行われません。NFSv4.1 ACLが存在する場合は、NFSv3を使用している場合でも、ACLを適切に解決するために数値ID検索と名前文字列検索が必要です。NTFSセキュリティ形式のボリュームでは、Cloud Volumes Service が数値IDを有効なUNIXユーザに解決してから、有効なWindowsユーザにマッピングして、アクセス権をネゴシエートする必要があります。</block>
  <block id="c88acee1e86a1d4e088392362c04bb3b" category="section-title">NFSv3のユーザIDとグループIDのセキュリティ制限</block>
  <block id="51d0cb09f5edabf17b3490e1b53d7b22" category="paragraph">NFSv3では、クライアントとサーバは、ユーザが数値IDで読み取りまたは書き込みを実行しようとしても、有効であることを確認する必要はありません。これは暗黙的に信頼されます。これにより、任意の数値IDをスプーフィングするだけで、ファイルシステムが侵害される可能性があります。このようなセキュリティホールを回避するために、Cloud Volumes Service にはいくつかのオプションがあります。</block>
  <block id="467b69ba310f54b371bbdbffe09e6497" category="list-text">NFSにKerberosを実装すると、ユーザはユーザ名とパスワードまたはkeytabファイルを使用して認証を受け、Kerberosチケットを取得してマウントにアクセスできるようになります。KerberosはCVS -パフォーマンスインスタンスで使用でき、NFSv4.1でのみ使用できます。</block>
  <block id="9120b024c7fefc321f0ebc6fee670c59" category="list-text">エクスポートポリシールールでホストのリストを制限することで、Cloud Volumes Service ボリュームにアクセスできるNFSv3クライアントを制限できます。</block>
  <block id="1b652183dcffb7bab733d50929de6844" category="list-text">デュアルプロトコルボリュームを使用し、NTFS ACLをボリュームに適用すると、NFSv3クライアントは数値IDを有効なUNIXユーザ名に解決して、マウントへのアクセスが正しく認証されるようになります。そのためには、LDAPを有効にし、UNIXのユーザおよびグループのIDを設定する必要があります</block>
  <block id="8d5c591e079f79f63fd9e9807dc0f747" category="list-text">rootユーザをスクワッシャすると、rootユーザがNFSマウントで実行できる損傷が制限されますが、リスクを完全に排除することはできません。詳細については、「」を参照してください<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>」</block>
  <block id="2013c75e17676506ba3c06142530277a" category="paragraph">最終的に、NFSセキュリティは、使用しているプロトコルのバージョンによって制限されます。NFSv3は、NFSv4.1よりもパフォーマンスが高いのに対し、セキュリティレベルは異なります。</block>
  <block id="1d9f0263509a5bc0f447962105bb1a92" category="paragraph">NFSv4.1は、次の理由から、NFSv3に比べてセキュリティと信頼性に優れています。</block>
  <block id="11d0cb4a0817a571de35b1a57bcd7b86" category="list-text">リースベースのメカニズムによる統合ロック</block>
  <block id="2a7079f12b8b7175a78aa4192442cceb" category="list-text">ステートフルセッション</block>
  <block id="78d4290f55bf351449981f773525bc0b" category="list-text">1つのポートですべてのNFS機能（2049）</block>
  <block id="53ec1aa3e51de041ca30580dcd5695db" category="list-text">TCPのみ</block>
  <block id="762c048886aaa3279e7ff7d4bbe56f5c" category="list-text">IDドメインマッピング</block>
  <block id="7e6be8eb2ba9a556864cfd20857c1565" category="list-text">Kerberos統合（NFSv3ではKerberosを使用できますが、NFSのみを使用でき、NLMなどの補助プロトコルは使用できません）</block>
  <block id="1f2bcbb2c0049fcc033a40cb665f19fc" category="section-title">NFSv4.1の依存関係</block>
  <block id="f83a89d33e724f74ff5a673c34fe9ac6" category="paragraph">NFSv4.1のセキュリティ機能に加えて、NFSv3を使用するために必要とされなかった外部の依存関係もいくつかあります（SMBでActive Directoryなどの依存関係が必要とされる方法と似ています）。</block>
  <block id="0e8ff8f10d56a8534800018ecdbcbfb7" category="paragraph">Cloud Volumes Service では、NFSv4.x ACLがサポートされています。NFSv4.x ACLは、次のような通常のPOSIX形式の権限とは異なる利点があります。</block>
  <block id="e7c21967cc185dee47ba9548ba30b26e" category="list-text">ファイルやディレクトリへのユーザアクセスの詳細な制御</block>
  <block id="a5e0d0cbd4020f568d08cdaed3dedd6b" category="list-text">NFS セキュリティが向上します</block>
  <block id="fd272c227f4884473fc1b4409d1fa6f0" category="list-text">CIFS / SMBとの相互運用性が向上しました</block>
  <block id="1c0d9e3bfe82d85776be6deeefb1b8d1" category="list-text">AUTH_SYSのセキュリティが設定された、ユーザあたり16個のグループに関するNFSの制限を削除</block>
  <block id="37c82add6470c2f73fad45f1e887f214" category="list-text">ACLはグループID（GID）の解決の必要性をバイパスします。これにより、実質的にGIDの制限を解除することができ、Cloud Volumes Service からではなくNFSクライアントからNFSv4.1 ACLが制御されます。NFSv4.1 ACLを使用するには、クライアントのソフトウェアバージョンでサポートされていること、および適切なNFSユーティリティがインストールされていることを確認してください。</block>
  <block id="f497540fbfe4bb6c8784249b7ca44322" category="section-title">NFSv4.1 ACLとSMBクライアントの互換性</block>
  <block id="b18893becc5c5979b433330d581d0502" category="paragraph">NFSv4 ACLはWindowsのファイルレベルのACL（NTFS ACL）とは異なりますが、同様の機能を備えています。ただし、マルチプロトコルNAS環境でNFSv4.1 ACLが存在し、デュアルプロトコルアクセス（同じデータセットでNFSおよびSMB）を使用している場合、SMB2.0以降を使用するクライアントは、WindowsのセキュリティタブでACLを表示または管理できません。</block>
  <block id="e24382a2de980eb4d0fad087c2279291" category="section-title">NFSv4.1 ACLの仕組み</block>
  <block id="65da9b80e25e8e6b76e6f95a27e33773" category="paragraph">参考のために、次の用語が定義されています。</block>
  <block id="3f33ebc7aedc435f5da6f0cdb363e903" category="list-text">*アクセス制御リスト(ACL)。*アクセス権エントリのリスト。</block>
  <block id="e8b619b2feea9964d68e458010421937" category="list-text">*アクセス制御エントリ(ACE)。*リスト内のアクセス許可エントリ。</block>
  <block id="e22c8ddaa933012f7b9658b15556e1d9" category="paragraph">クライアントがSETATTR操作でファイルにNFSv4.1 ACLを設定すると、Cloud Volumes Service は既存のACLに替わってそのACLをオブジェクトに設定します。ファイルにACLが設定されていない場合、ファイルのモード権限はOWNER@、GROUP@、およびEVERYONE@から計算されます。ファイルにSUID / SGID / STICKYのいずれかのビットが設定されている場合、それらのビットは影響を受けません。</block>
  <block id="bbfc3dd393a8c0fb0275a317ea92cdb6" category="paragraph">クライアントがGETATTR操作でファイルのNFSv4.1 ACLを取得すると、Cloud Volumes Service はオブジェクトに関連付けられたNFSv4.1 ACLを読み取り、ACEのリストを作成してクライアントに返します。ファイルにNT ACLまたはモードビットが設定されている場合は、モードビットからACLが構築されてクライアントに返されます。</block>
  <block id="e91b7b9c71eaf21c16d5232d74f4c5c3" category="paragraph">ACLにDENY ACEが存在する場合はアクセスが拒否され、ALLOW ACEが存在する場合はアクセスが許可されます。ただし、ACLにどちらのACEも存在しない場合も、アクセスが拒否されます。</block>
  <block id="85e34118580ac115f838cd805832291e" category="paragraph">セキュリティ記述子は、セキュリティACL（SACL）と随意ACL（DACL）で構成されます。NFSv4.1がCIFS / SMBと連動する場合は、DACLはNFSv4とCIFSに1対1でマッピングされます。DACLは、ALLOW ACEとDENY ACEで構成されます。</block>
  <block id="f26fe9c5bd9a38964b075295ff6b600f" category="paragraph">NFSv4.1 ACLが設定されたファイルまたはフォルダに対して基本的なchmodを実行すると、既存のユーザおよびグループのACLは維持されますが、デフォルトのOWNER@、GROUP@、およびEVERYONE@ ACLが変更されます。</block>
  <block id="51cdc67f907418899df11513b246dd1c" category="inline-link">継承フラグ</block>
  <block id="bfb9f4f4e0b3ee74bbf0624c3acb6f05" category="paragraph">NFSv4.1 ACLを使用するクライアントは、システム上のファイルとディレクトリにACLを設定し、そのACLを表示することができます。ACLが設定されているディレクトリ内にファイルやサブディレクトリを新しく作成すると、そのオブジェクトは、該当するACLでタグ付けされているACEをすべて継承します<block ref="efe32d9e162a0a9bfdfda1b55921a64c" category="inline-link-rx"></block>。</block>
  <block id="4ede33bb65432e74e322d690608c2334" category="paragraph">ファイルまたはディレクトリにNFSv4.1 ACLが設定されている場合、そのACLを使用して、ファイルまたはディレクトリへのアクセスにどのプロトコルが使用されるかに関係なく、アクセスが制御されます。</block>
  <block id="0d733f1633c2aa51a107a6e21dfd5644" category="paragraph">親ディレクトリのNFSv4 ACLのACEに正しい継承フラグが設定されていれば、ファイルやディレクトリは該当するACEを継承します（必要な変更が加えられる可能性があります）。</block>
  <block id="a61aaa9a4f599d5b80e71c232d23147a" category="paragraph">ファイルやディレクトリがNFSv4要求によって作成される場合、作成されるファイルやディレクトリのACLは、ファイル作成要求にACLが含まれているか、または標準のUNIXファイルアクセス権限のみが含まれているかによって異なります。また、親ディレクトリにACLが設定されているかどうかによっても異なります。</block>
  <block id="5ac8b682abcf5cc600bff1df60b6eeb0" category="list-text">要求に ACL が含まれる場合は、その ACL が使用されます。</block>
  <block id="68d4655ff3b6740e5735fd80c7910023" category="list-text">要求に標準の UNIX ファイルアクセス権限のみが含まれ、親ディレクトリに ACL がない場合は、クライアントのファイルモードを使用して標準の UNIX ファイルアクセス権限が設定されます。</block>
  <block id="2cf6ef9c801da66f5a80033edc51acf8" category="list-text">要求に標準UNIXファイルアクセス権限のみが含まれ、親ディレクトリに継承できないACLがある場合は、要求で渡されたモードビットに基づいてデフォルトのACLが設定されます。</block>
  <block id="c1eac2f9759f1dd2f7680287789d03f9" category="list-text">要求に標準 UNIX ファイルアクセス権限のみが含まれ、親ディレクトリに ACL がある場合、親ディレクトリの ACL の ACE に適切な継承フラグのタグが付けられていれば、それらの ACE が新しいファイルやディレクトリに継承されます。</block>
  <block id="1aeffd8cf8d8faca5f1d6379d7ad7b42" category="section-title">ACE権限</block>
  <block id="be30a66f742a1c4b197f654c5456f525" category="inline-link">方法: NFSv4 ACLを使用します</block>
  <block id="1e0ba766d5b81a0076401367c75ba49d" category="paragraph">NFSv4.1 ACLの権限では、大文字と小文字のアルファベットの一連の値（「rxtncy」など）を使用してアクセスが制御されます。これらの文字の値の詳細については、を参照してください<block ref="19e15d2b871d5802ed53b8bb943cfa1d" category="inline-link-rx"></block>。</block>
  <block id="e5db87d9c7835194478e833b1c2341a3" category="section-title">umaskおよびACLの継承が設定されたNFSv4.1 ACLの動作</block>
  <block id="2d01b8b9abf1cd5dd5dc3a87babfa478" category="inline-link">NFSv4 ACLでは、ACLを継承することができます</block>
  <block id="90f70b82033cb9c398aab9c2ab8e4b97" category="inline-link">ACL継承フラグ</block>
  <block id="b40177dea06ae321d6ba903c296a8bf4" category="paragraph"><block ref="a4a4eca6555a8c7e71d54636b6d02bd2" category="inline-link-rx"></block>。ACLの継承では、NFSv4.1 ACLが設定されているオブジェクトの下に作成されるファイルやフォルダに、の設定に基づいてACLを継承することができます<block ref="0dfdf6ea7cd5f3c14c3e752e09504ece" category="inline-link-rx"></block>。</block>
  <block id="e3847e2a1d0d27fe2e50f7b68080126e" category="inline-link">umask</block>
  <block id="391e42635de569b9fd15585f0b03777a" category="inline-link">RFC 5661</block>
  <block id="a5147a6538ae36d50a705033dee8e1ea" category="paragraph"><block ref="63bfc707387dfd47bf50e485c5b4d27f" category="inline-link-rx"></block> は、管理者とのやり取りなしでディレクトリ内にファイルやフォルダを作成する権限レベルを制御するために使用します。デフォルトでは、Cloud Volumes Service は継承されたACLをumaskによって上書きします。これは、の想定される動作です<block ref="c202d210fe4151f93fd56939449ae558" category="inline-link-rx"></block>。</block>
  <block id="c283f512453dfbe4a4d54a5de963c63a" category="section-title">ACLのフォーマット</block>
  <block id="af26ba96448cb4f36fa75d37c0c24884" category="paragraph">NFSv4.1 ACLには特定の形式があります。次の例は、ファイルに設定されたACEを示しています。</block>
  <block id="90bdfef72a7e9f73c8492c28764bfecc" category="paragraph">上記の例では、のACL形式のガイドラインに従います。</block>
  <block id="7d665626903fe1069f3c052eb3b93597" category="inline-link"><block ref="7d665626903fe1069f3c052eb3b93597" category="inline-link-rx"></block></block>
  <block id="192707027419e02a79fe3b9af5a845c4" category="paragraph">「A」のタイプは「許可」を意味します。 継承フラグはこの場合は設定されません。これは、プリンシパルがグループではなく、継承も含まれないためです。また、ACEは監査エントリではないため、監査フラグを設定する必要もありません。NFSv4.1 ACLの詳細については、を参照してください<block ref="588b628ed19e81b60db990218fbd0aa2" category="inline-link-rx"></block>。</block>
  <block id="767a03c18193757348519856b05f7d1c" category="paragraph">NFSv4.1 ACLが適切に設定されていない場合（またはクライアントとサーバが名前文字列を解決できない場合）、ACLが想定どおりに動作しないか、ACLの変更を適用できずにエラーがスローされる可能性があります。</block>
  <block id="e0ad83b43ccb7e44bcdb46bcdc1189d9" category="paragraph">エラーの例は次のとおりです。</block>
  <block id="bf837e35002530c307569ba2ec195e9a" category="section-title">明示的なDENY</block>
  <block id="68a14c985893a66fdf24403b891ddc6c" category="paragraph">NFSv4.1の権限では、OWNER、GROUP、およびEVERYONEに対する明示的なDENY属性を含めることができます。これは、NFSv4.1 ACLがdefault-denyであるためです。つまり、ACEによってACLが明示的に許可されなければ、ACLは拒否されます。明示的なDENY属性は、明示的なアクセスACEを上書きします。</block>
  <block id="22759a58413e45c1ab8a0a53300ea43c" category="paragraph">拒否ACEは'D'の属性タグで設定されます</block>
  <block id="3bce872a832106c5038ea04d532162ba" category="paragraph">次の例では、group@はすべての読み取りおよび実行権限を許可していますが、すべての書き込みアクセスは拒否されています。</block>
  <block id="8b4ed201924d12a3d0ec41f5538460b2" category="paragraph">DENY ACEは複雑で混乱を招く可能性があるため、できるかぎり使用しないでください。明示的に定義されていないACLは暗黙的に拒否されます。DENY ACEを設定すると、アクセスを許可されるはずのユーザがアクセスを拒否される場合があります。</block>
  <block id="fb976fa579c74ac9e0b64ac922a938d7" category="paragraph">上記の一連のACEは、モードビットの755に相当します。つまり、次のようになります。</block>
  <block id="de9d71e2841fbf06bf2e96e40b0655d0" category="list-text">所有者にはフルアクセス権があります。</block>
  <block id="391533122a44e47fc6d7eed8f3d46152" category="list-text">グループは読み取り専用です。</block>
  <block id="233c314243fd8ff0f129355150358c9b" category="list-text">読み取り専用のものもあります。</block>
  <block id="004367158d382df49675a222d852e2c2" category="paragraph">ただし、775と等しくなるように権限が調整されていても、EVERYONEに明示的なDENYが設定されているとアクセスが拒否される可能性があります。</block>
  <block id="c9533a3d4ca28b597d9e4f0b7c2d7d28" category="section-title">NFSv4.1 IDドメインのマッピングの依存関係</block>
  <block id="b8c7283821c3d4795f01644c47598298" category="paragraph">NFSv4.1では、セキュリティレイヤとしてIDドメインのマッピングロジックを利用して、NFSv4.1マウントへのアクセスを試みるユーザが、そのユーザの要求を実際に把握できるかどうかを検証します。このような場合は、NFSv4.1クライアントからのユーザ名とグループ名に名前文字列が付加されて、Cloud Volumes Service インスタンスに送信されます。ユーザ名/グループ名とID文字列の組み合わせが一致しない場合は'クライアントの/etc/idmapd.confファイルに指定されているデフォルトのnobodyユーザにユーザまたはグループが引き下げられます</block>
  <block id="5aec5d2b81e4e7bc2bb96b8eee7f6a1f" category="paragraph">このID文字列は、特にNFSv4.1 ACLやKerberosを使用している場合に、適切な権限を順守するための要件です。そのため、ユーザやグループの名前IDが正しく解決されるように、クライアントとCloud Volumes Service 間で一貫性を確保するためには、LDAPサーバなどのネームサービスサーバに依存する必要があります。</block>
  <block id="ea6c924c6846969cae29ab27aa4c3d9e" category="paragraph">Cloud Volumes Service は'静的なデフォルトIDドメイン名値defaultv4iddomain.comを使用しますNFSクライアントはデフォルトで'IDドメイン名設定のDNSドメイン名になりますが'/etc/idmapd.confでIDドメイン名を手動で調整できます</block>
  <block id="a524142e9e2e4c80b2545aea06b82fb6" category="paragraph">Cloud Volumes Service でLDAPが有効になっている場合、Cloud Volumes Service はNFS IDドメインを自動化して、DNSの検索ドメインに設定されている内容に変更します。クライアントは、別のDNSドメイン検索名を使用しない限り、変更する必要はありません。</block>
  <block id="13c371145cb8e423bcc06c41dafa7d27" category="paragraph">Cloud Volumes Service がローカルファイルまたはLDAPでユーザ名またはグループ名を解決できる場合は、ドメイン文字列が使用され、一致しないドメインIDが引き下げられてnobodyになります。ローカルファイルまたはLDAPでユーザ名またはグループ名が見つからない場合Cloud Volumes Service は、数値のID値が使用され、NFSクライアントが名前を適切に解決します（NFSv3の動作と似ています）。</block>
  <block id="2920d1231c77a15a148be7e24a4224a8" category="paragraph">クライアントのNFSv4.1 IDドメインを、Cloud Volumes Service ボリュームで使用されているものと一致するように変更しないと、次のような動作が発生します。</block>
  <block id="cf7f7139ed9bd9c2ce206642dd7fa858" category="list-text">Cloud Volumes Service 内にローカルエントリがあるUNIXユーザおよびグループ（ローカルのUNIXユーザとグループで定義されているrootなど）は、nobody値に引き下げられます。</block>
  <block id="b4aa27a84e1a2079915902824805faed" category="list-text">LDAP内にエントリがあるUNIXユーザおよびグループ（Cloud Volumes Service でLDAPを使用するように設定されている場合）は、NFSクライアントとCloud Volumes Service でDNSドメインが異なる場合、そのハッシュがnobodyに引き下げられます。</block>
  <block id="ef7ad0d3015777d2990a6af6b71f374b" category="list-text">ローカルエントリやLDAPエントリがないUNIXユーザおよびグループは、数値ID値を使用して、NFSクライアントで指定された名前に解決されます。クライアントに名前が存在しない場合は、数値IDのみが表示されます。</block>
  <block id="62dcf28b3972264f1b30c2bd51a03def" category="paragraph">上記のシナリオの結果を次に示します。</block>
  <block id="696c02f546b2ffcdac74d99c917daa24" category="paragraph">クライアントとサーバIDのドメインが一致した場合、同じファイルリストが表示されます。</block>
  <block id="406ef9702da9a43b3a7b54a25411d799" category="paragraph">この問題 とその解決方法の詳細については、「」を参照してください<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>」</block>
  <block id="feb3aa3308fe030fd35a38b78a2300bd" category="section-title">Kerberosの依存関係</block>
  <block id="40bbfae3ce12130d42058c7017ceb5ed" category="paragraph">NFSでKerberosを使用する場合は、Cloud Volumes Service で次の要件を満たす必要があります。</block>
  <block id="97a82eff6d3d292af521c01da598a578" category="list-text">Kerberosキー配布センターサービス（KDC）用のActive Directoryドメイン</block>
  <block id="7539d3051db830d97dee8f6d5d504289" category="list-text">LDAP機能のUNIX情報を入力したユーザおよびグループの属性を持つActive Directoryドメイン（Cloud Volumes Service のNFS Kerberosでは、正常に機能するためにユーザのSPNからUNIXユーザのマッピングが必要です）。</block>
  <block id="39780a85d8e7edcc28fd4bc1f6b379f9" category="list-text">Cloud Volumes Service インスタンスでLDAPが有効になっている</block>
  <block id="9b306ebe81f909f9a456adcadd197090" category="list-text">DNSサービスのActive Directoryドメインを指定します</block>
  <block id="3f1e5b600401b83c49c16e0c80170842" category="section-title">NFSv4.1およびnobodyユーザ/グループ</block>
  <block id="5c79e57a072b5ea9e69b08395268c3fe" category="paragraph">NFSv4.1設定でよく見られる問題の1つは、「user:group」の「nobody：nobody」の組み合わせによって所有されている「ls」を使用して一覧にファイルまたはフォルダが表示される場合です。</block>
  <block id="2436a7de6f774d774219a86839e40d54" category="paragraph">数値IDは「99」です。</block>
  <block id="89429eb5e6061e2e0b04707c39588b82" category="paragraph">場合によっては、ファイルに正しい所有者が表示されることもありますが、グループとして「nobody」が表示されることもあります。</block>
  <block id="8155be8c03c24d2ae2a39ba5b9659708" category="paragraph">誰もいないのですか？</block>
  <block id="01e2f333d529d07a7774464ebe7c0d52" category="paragraph">NFSv4.1のnobodyユーザはnfsnobodyユーザとは異なりますNFSクライアントが各ユーザーをどのように認識するかを表示するには'id'コマンドを実行します</block>
  <block id="bb1a16c53f7bf27e8010e55518128316" category="paragraph">NFSv4.1では'idmapd.confファイルによって定義されたデフォルトのユーザである'nobod'ユーザを使用する任意のユーザとして定義できます</block>
  <block id="25df38609547f38c12a30d2f7fa376e3" category="paragraph">なぜそうなるのでしょうか？</block>
  <block id="0c52fa2fe9ffee5f1757712d7b9151d3" category="paragraph">NFSv4.1の処理では、ネーム文字列マッピングによるセキュリティが重要な条件となるため、名前文字列が適切に一致しない場合のデフォルトの動作は、ユーザとグループが所有するファイルやフォルダに通常アクセスできないユーザの引き下げです。</block>
  <block id="ee345fce71ab8dd58d64ab30df90665d" category="paragraph">ファイルの一覧にユーザまたはグループの「nobody」が表示される場合は、通常、NFSv4.1の設定が誤っています。ここでは、大文字と小文字の区別が使用されます。</block>
  <block id="6f0eaeb67bf8645d4cb5b6d6634d62e9" category="paragraph">たとえば、user1@CVSDEMO.LOCA L（uid 1234、gid 1234）がエクスポートにアクセスしている場合、Cloud Volumes Service はuser1@CVSDEMO.LOCA L（uid 1234、gid 1234）を検索できる必要があります。Cloud Volumes Service のユーザがUSER1@CVSDEMO.LOCA Lの場合、ユーザは一致しません（大文字のUSER1と小文字のuser1）。多くの場合、クライアント上のメッセージファイルに次の情報が表示されます。</block>
  <block id="501dfba2ca7e696ebe3828fe0a72358d" category="paragraph">クライアントとサーバーは、ユーザーが実際に誰を要求しているかに同意する必要があります。そのため、Cloud Volumes Service が表示するユーザーと同じ情報がクライアントに表示されることを確認するには、次の項目を確認する必要があります。</block>
  <block id="c45f88d46edf246ef524b5ae57bfd939" category="list-text">*NFSv4.x ID domain.* Client:idmapd.confファイル。Cloud Volumes Service は「defaultv4iddomain.com」を使用しており、手動で変更することはできません。Cloud Volumes Service でNFSv4.1を使用する場合、DNS検索ドメインのIDドメインが、ADドメインと同じになるように変更されます。</block>
  <block id="4ad682a8c77e394fdf80dd7dc8013933" category="list-text">*ユーザー名と数値ID。*これは、クライアントがユーザー名を検索し、ネームサービススイッチ構成を利用する場所を決定します。client:nsswitch.conf'ローカルpasswdファイルとgroupファイルのいずれかまたは両方を使用します。Cloud Volumes Service では、この変更は許可されませんが、有効になっている場合は自動的にLDAPが構成に追加されます。</block>
  <block id="278ba27763f1a046a43e86bd394f831b" category="list-text">*グループ名と数値ID。*これは、クライアントがグループ名を検索し、ネームサービススイッチ構成を利用する場所を決定します。client:nsswitch.conf'ローカルpasswdおよびgroupファイルのいずれかまたは両方を使用します。Cloud Volumes Service では、この変更は許可されていませんが、有効になっている場合は自動的にLDAPが構成に追加されます。</block>
  <block id="6b9ce9cbf95dd872dc03e91534746dc9" category="paragraph">ほとんどの場合、クライアントからのユーザおよびグループの一覧に「nobody」が表示された場合、問題 はCloud Volumes Service とNFSクライアント間でのユーザまたはグループの名前ドメインIDの変換です。この状況を回避するには、LDAPを使用して、クライアントとCloud Volumes Service 間でユーザおよびグループの情報を解決します。</block>
  <block id="55c4b4ea1ecc6c7d5d39c90a0b42830f" category="section-title">クライアントでのNFSv4.1の名前ID文字列の表示</block>
  <block id="c194a1cc7281e9894e494f5ccc1267d9" category="paragraph">NFSv4.1を使用している場合、前述のように、NFS処理で実行される名前文字列のマッピングが存在します。</block>
  <block id="600a8e1223f644dfc8fc6d9eaf7c6585" category="inline-link">nfsidmap -l</block>
  <block id="315b0c6cb599d172afa3879fb5aff687" category="paragraph">/var/log/messagesを使用してNFSv4 IDを持つ問題 を検索することに加え、を使用することもできます<block ref="b0f2e0837ffda1ff0550aeef038779e7" category="inline-link-rx"></block> NFSクライアント上でコマンドを実行すると、NFSv4ドメインに適切にマッピングされているユーザ名が表示されます。</block>
  <block id="c72321f4072e32fa1625318fcee53b38" category="paragraph">たとえば、クライアントで検出されたユーザとCloud Volumes Service がNFSv4.xマウントにアクセスすると、次のようなコマンドが出力されます。</block>
  <block id="7fdd86c292924f1df8a7d9127ece25dc" category="paragraph">NFSv4.1 IDドメインに適切にマッピングされていないユーザ（この場合「netapp -user」）が同じマウントにアクセスしてファイルにアクセスしようとすると、「nobody：nobody」が割り当てられます（想定どおり）。</block>
  <block id="bf667093961d1f59e9282ef8a28d89f7" category="paragraph">「nfsidmap -l」の出力には、ユーザ「pcuser」が表示されますが、「NetApp-user」は表示されません。これは、エクスポートポリシールールの匿名ユーザ（「65534」）です。</block>
  <block id="5ec4dbbd0b1975ade000088ec562aebe" category="inline-link-macro">次：SMB。</block>
  <block id="a1989578ae6cff04ad5b049565c028a6" category="paragraph"><block ref="a1989578ae6cff04ad5b049565c028a6" category="inline-link-macro-rx"></block></block>
  <block id="f054dd8cc88786d8030b18d90271f377" category="summary">Cloud Volumes Service は、複数のTCPポートを公開してNFS共有とSMB共有を提供します。</block>
  <block id="c5381dc540506dbb210e2d300554e4cd" category="doc">ファイアウォール：</block>
  <block id="3081ff6911f8297ddc53dab3c34d0811" category="inline-link-macro">Previous：保存データの暗号化。</block>
  <block id="4591bc0b4ed2ba115e753bad56145791" category="paragraph"><block ref="4591bc0b4ed2ba115e753bad56145791" category="inline-link-macro-rx"></block></block>
  <block id="1e45092c94634e40f68ce647e16109a4" category="paragraph">Cloud Volumes Service は、複数のTCPポートを公開してNFS共有とSMB共有に対応します。</block>
  <block id="8ace993e6a8c37342617dbf22185890a" category="inline-link">NFSアクセスに必要なポート</block>
  <block id="259c7a7ef42d8165caa2c0238cb6f9fe" category="inline-link">SMBアクセスに必要なポート</block>
  <block id="48e54afcf03ca45bfe38f6b7ff58764a" category="inline-link">を設定します</block>
  <block id="2957bc03d53f1be7c11d427906ed1479" category="inline-link">DNSベースのDC検出</block>
  <block id="02d7b2e18b6bb033bf88be07d39aab4c" category="inline-link">Cloud Volumes Service への参加</block>
  <block id="934adb56d62c2e8a1334785cbb6d4987" category="inline-link">ここで説明したCloud Volumes Service CIDRsにポートを公開します</block>
  <block id="fa995eb117a30c2365b6a07bf00e36e4" category="inline-link-macro">次：NASプロトコルの概要</block>
  <block id="6160acafbed3bd228bd0703f2991a4cb" category="paragraph"><block ref="6160acafbed3bd228bd0703f2991a4cb" category="inline-link-macro-rx"></block></block>
  <block id="4a3327b1b286d1e67b6b26ccadab7e11" category="paragraph">mailto：doccomments@netapp.com [ doccomments@netapp.com ^]までお問い合わせください。件名にはテクニカルレポート4918を含めてください。</block>
  <block id="8a7d64073f6ea3e3562e48ad7babe165" category="summary">NASプロトコルには、NFS（v3およびv4.1）とSMB / CIFS（2.xおよび3.x）があります。CVSでは、これらのプロトコルを使用して、複数のNASクライアント間でデータへの共有アクセスが許可されます。また、Cloud Volumes Service は、NAS共有内のファイルやフォルダのIDおよび権限の設定をすべて満たしながら、NFSクライアントとSMB / CIFSクライアントへのアクセスを同時に提供（デュアルプロトコル）できます。</block>
  <block id="90654829f21fcf187b576a4c4bad0d65" category="doc">NASプロトコルの概要</block>
  <block id="571468eb1eb9e9369a3f638191a66df7" category="inline-link-macro">前のバージョン：ファイアウォール。</block>
  <block id="01d123c65f0dd57ade00e4f9754df7de" category="paragraph"><block ref="01d123c65f0dd57ade00e4f9754df7de" category="inline-link-macro-rx"></block></block>
  <block id="2ea1602d2ad8b38f601e3e9a049c625d" category="paragraph">NASプロトコルには、NFS（v3およびv4.1）とSMB / CIFS（2.xおよび3.x）があります。CVSでは、これらのプロトコルを使用して、複数のNASクライアント間でデータへの共有アクセスが許可されます。また、Cloud Volumes Service は、NAS共有内のファイルやフォルダのIDおよび権限の設定をすべて満たしながら、NFSクライアントとSMB / CIFSクライアントへのアクセスを同時に提供（デュアルプロトコル）できます。最高レベルのデータ転送セキュリティを維持するため、Cloud Volumes Service は、SMB暗号化とNFS Kerberos 5pを使用して転送中のプロトコル暗号化をサポートしています。</block>
  <block id="4fbbc372dd84225f54ba28f08d3ff4c7" category="admonition">デュアルプロトコルはCVSパフォーマンスでのみ使用できます。</block>
  <block id="51f1eaeaea4deb044aabf0797f51c5c0" category="inline-link-macro">次は、NASプロトコルの基本です。</block>
  <block id="fcb7e93b14f588cd063c2c111732d865" category="paragraph"><block ref="fcb7e93b14f588cd063c2c111732d865" category="inline-link-macro-rx"></block></block>
  <block id="be0bbf78cc02e3b8c5c134bc7dd71544" category="summary">Cloud Volumes Service に対する管理操作は、すべてAPIを通じて実行されます。GCPクラウドコンソールに統合されたCloud Volumes Service 管理でも、Cloud Volumes Service APIを使用します。</block>
  <block id="dd03419f7f2124dca2e83694ae1b7211" category="doc">コントロールプレーンのアーキテクチャ</block>
  <block id="1d2a3e9b2f45b43494c66482366a665a" category="inline-link-macro">以前のバージョン：Cloud Volumes Service アーキテクチャ。</block>
  <block id="f73a9343c8393a91c87eda2847dfab85" category="paragraph"><block ref="f73a9343c8393a91c87eda2847dfab85" category="inline-link-macro-rx"></block></block>
  <block id="791716f366839a73d41b8ac1ae95bad0" category="section-title">IDおよびアクセス管理</block>
  <block id="41dff7155cc7aeb11c06434f6a450bb3" category="inline-link">IAM</block>
  <block id="d0455114933a93b857dff40ad9829c80" category="paragraph">IDおよびアクセス管理 <block ref="3e7f3b73b3f103986fbe162302b5e57e" category="inline-link-rx"></block>）は、Google Cloudプロジェクトインスタンスへの認証（ログイン）と許可（権限）を制御できる標準サービスです。Google IAMには、許可の承認と削除に関する完全な監査証跡が用意されています。現在、Cloud Volumes Service ではコントロールプレーンの監査を提供していません。</block>
  <block id="697308a09680ed006fe009f5a90fd74c" category="section-title">承認/権限の概要</block>
  <block id="cb5b383a5c27210bdf8f2fd443c68ebb" category="inline-link">詳細な権限の一覧をここに入力します</block>
  <block id="f6c6a3fb346fa0197c1eeba05a4736c6" category="paragraph">IAMには、「netappcloudvolumes」と「netappcloudvolumes」という2つの事前定義された役割も用意されています。これらのロールは、特定のユーザまたはサービスアカウントに割り当てることができます。</block>
  <block id="6d90e176a60105dd03d5580c615cc5fe" category="paragraph">IAMユーザにCloud Volumes Service の管理を許可する適切なロールと権限を割り当てます。</block>
  <block id="010558e705f1d93db66b5a129431b39d" category="paragraph">きめ細かい権限の使用例を次に示します。</block>
  <block id="cf95655b33a1e3a77d897074d8353e7e" category="list-text">ボリュームを削除できないように、権限の取得/リスト/作成/更新だけを指定してカスタムロールを作成します。</block>
  <block id="fdc24340d58c0f0e7d38a4a3f6a7218c" category="list-text">「snapshot.*」権限のみを持つカスタム・ロールを使用して、アプリケーションと整合性のあるSnapshot統合を構築するために使用するサービス・アカウントを作成します。</block>
  <block id="b1ef9a9445de9905dc5e0ab77e08e183" category="list-text">特定のユーザーに'volumeereplication.*'を委任するカスタムロールを作成します</block>
  <block id="c33f7c2cbeaca5f1462c1b3e1c276145" category="section-title">サービスアカウント</block>
  <block id="303e96f80576360d0c7b07ae7528fa4b" category="inline-link">テラフォーム</block>
  <block id="b6d8efd38d2a5551a2c43104314740bd" category="paragraph">スクリプトまたはを使用してCloud Volumes Service API呼び出しを実行する<block ref="d99d6c9612fe6a2189c372e0abf640d5" category="inline-link-rx"></block>'roles/netappcloudvolumes .admin'ロールを持つサービスアカウントを作成する必要がありますこのサービスアカウントを使用して、Cloud Volumes Service API要求の認証に必要なJWTトークンを生成できます。これには、次の2つの方法があります。</block>
  <block id="87cacfdb2dd389d5d00fef712c2f874b" category="list-text">JSONキーを生成し、Google APIを使用してJWTトークンを取得します。これは最もシンプルなアプローチですが、手動のシークレット（JSONキー）管理が必要になります。</block>
  <block id="d77fb2baf15918343921ee724cfacb2f" category="inline-link">サービスアカウントのなりすまし</block>
  <block id="9d8270b5a4616fc246d5f96cccc9f61e" category="inline-link">アプリケーションのデフォルトクレデンシャル</block>
  <block id="c1f48ac217f6b993bda4f82835777177" category="list-text">使用<block ref="09540132e155f93461287a2e21a4e25d" category="inline-link-rx"></block> 「roles/iam.serviceAccountTokenCreator`」を指定します。コード（スクリプト、Terraformなど）はで実行されます<block ref="ffba44c35d88772fc8c63157b8dc0cf7" category="inline-link-rx"></block> また、サービスアカウントを偽装して権限を取得します。このアプローチは、Googleのセキュリティのベストプラクティスを反映しています。</block>
  <block id="01aa2fa55c64df5a4122b637c9ababc7" category="inline-link">サービスアカウントと秘密鍵を作成しています</block>
  <block id="a325b85a1545e8c507701fb5aa32e6b8" category="section-title">Cloud Volumes Service APIの略</block>
  <block id="d06e940dcf329e87ca49cb2a665f5fd8" category="inline-link">Google CloudドキュメントのCloud Volume API</block>
  <block id="de13c3e3b25af602f2652dd51a503a8a" category="paragraph">APIエンドポイントは、標準のHTTPS（TLSv1.2）機能を使用してネットアップによって処理および保護されます。</block>
  <block id="8eac7c9151aa7742216ac387e27479a7" category="section-title">JWTトークン</block>
  <block id="56ebd33e81a27d6c3c78f2f67f2d3c1a" category="inline-link">RFC-7519</block>
  <block id="f2c16a4802323f9b9c1ac55acf92645f" category="paragraph">APIへの認証は、JWTベアラートークンを使用して実行されます <block ref="89a64c0d993ae56a4af8e7ccde6ee59e" category="inline-link-rx"></block>）。有効なJWTトークンは、Google Cloud IAM認証を使用して取得する必要があります。そのためには、サービスアカウントのJSONキーを指定してIAMからトークンを取得する必要があります。</block>
  <block id="f45362733fe1dd1af3c58ae64471d466" category="section-title">監査ロギング</block>
  <block id="1ccbd48d467dc56358432c49ba82e95a" category="paragraph">現在、ユーザがアクセスできるコントロールプレーン監査ログはありません。</block>
  <block id="f2787c6d19935adb1d88d6c832b68083" category="inline-link-macro">次の図は、データプレーンのアーキテクチャです。</block>
  <block id="9025e4ef245b32ed6f318a902095bafc" category="paragraph"><block ref="9025e4ef245b32ed6f318a902095bafc" category="inline-link-macro-rx"></block></block>
  <block id="9dfacef1e7d01943a3363c481a0ab54f" category="summary">Cloud Volumes Service for Google Cloudは、Google Cloudプライベートサービスアクセスフレームワークを活用しています。このフレームワークでは、ユーザーはCloud Volumes Service に接続できます。このフレームワークでは、他のGoogleクラウド サービス のようなサービスネットワーキングとVPCピアリングの構成要素を使用して、テナント間の完全な分離を実現します。</block>
  <block id="65d49b550fb0a0afd0ad601dc275ea12" category="doc">データプレーンアーキテクチャ</block>
  <block id="bbabe197f6618c2911a8ad624a658a46" category="inline-link-macro">前のバージョン：コントロールプレーンのアーキテクチャ。</block>
  <block id="dfb92e74bf9227851402850c5c488e3c" category="paragraph"><block ref="dfb92e74bf9227851402850c5c488e3c" category="inline-link-macro-rx"></block></block>
  <block id="57e0a1cde7582cc59173756aff450054" category="paragraph">Cloud Volumes Service for Google CloudはGoogle Cloudを活用しています<block ref="466f20229cc0e1fa2efa2b4b45528417" category="inline-link-rx"></block> フレームワーク：このフレームワークでは、ユーザーはCloud Volumes Service に接続できます。このフレームワークでは、他のGoogleクラウド サービス のようなサービスネットワーキングとVPCピアリングの構成要素を使用して、テナント間の完全な分離を実現します。</block>
  <block id="fabc0e878e19ad7e95bb8e906ab9e8a1" category="inline-link">Cloud Volumes Service のアーキテクチャ</block>
  <block id="81001e33ae42635e6a292ced69cda439" category="paragraph">Cloud Volumes Service for Google Cloudのアーキテクチャの概要については、を参照してください<block ref="7e96ff285aa6f06b814f61dc37a8da61" category="inline-link-rx"></block>。</block>
  <block id="dcfa6d27a1891efb4ad8492d3a127b28" category="paragraph">ユーザVPC（スタンドアロンまたは共有）は、Cloud Volumes Service で管理されるテナントプロジェクト内のVPCとピア関係にあり、VPC間でボリュームをホストします。</block>
  <block id="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="paragraph"><block ref="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e3d4716c5a2ddac5bbd6a03d58d03af" category="paragraph">上の図は、3つのVPCネットワークがCloud Volumes Service に接続され、複数のCompute Engine VM（GCE1-7）がボリュームを共有しているプロジェクト（中央のCVSコンシューマプロジェクト）を示しています。</block>
  <block id="fbf1e8aceed7750d8ed8c4e7168cdb02" category="list-text">VPC1では、GCE1がボリュームAおよびBにアクセスできます</block>
  <block id="dc5d4ca9052ec8ea299a69ef985a32b0" category="list-text">VPC2は、GCE2とGCE4がボリュームCにアクセスできるようにします</block>
  <block id="3274f78cc9286288af4912642932b72e" category="list-text">3つ目のVPCネットワークは共有VPCで、2つのサービスプロジェクトで共有されます。これにより、GCE3、GCE4、GCE5、およびGCE6がボリュームDおよびEにアクセスできるようになります共有VPCネットワークは、CVS -パフォーマンスサービスタイプのボリュームでのみサポートされます。</block>
  <block id="be3759e5f4a6574585df9e1159c20c30" category="admonition">GCE7はどのボリュームにもアクセスできません。</block>
  <block id="597134b02aeec788dec5f24fa0adba89" category="paragraph">データは転送中（Kerberos暗号化やSMB暗号化を使用）と保管中（Cloud Volumes Service ）の両方で暗号化できます。</block>
  <block id="f8426b7150021bc2586e9c150051a408" category="inline-link-macro">次の例：転送中のデータ暗号化</block>
  <block id="39148875a23c5a4ea00752d82ac14b14" category="paragraph"><block ref="39148875a23c5a4ea00752d82ac14b14" category="inline-link-macro-rx"></block></block>
  <block id="3e7c5a939584e1a53201dd8eddfe85d1" category="summary">Cloud Volumes Service は、CloudSQL、Google Cloud VMware Engine（GCVE）、ファイルストアなど、他のGoogle Cloudネイティブサービスと同様に、Google PSAを使用してサービスを提供します。</block>
  <block id="16929468b925d0d420441bcbba519e7d" category="doc">Cloud Volumes Service アーキテクチャ</block>
  <block id="98cdf6a29cf39ecd5239e5071cb0dc88" category="inline-link">Google PSA</block>
  <block id="d4d6aaf620a68430d28b38f847f2a6af" category="inline-link">vPCネットワークピアリング</block>
  <block id="353164decd5aa0c4f58b4e56559e1b13" category="inline-link">アーキテクチャセクション</block>
  <block id="8055d5a25a1838f115c8636545abb21a" category="paragraph"><block ref="8055d5a25a1838f115c8636545abb21a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6f34964d3060f5dd66e2cc7c8711679" category="paragraph">点線の上の部分は、ボリュームのライフサイクルを制御するサービスのコントロールプレーンを示しています。点線の下の部分は、データプレーンを示しています。左側の青いボックスはユーザVPC（サービスコンシューマ）を示し、右側の青いボックスはネットアップが提供するサービスプロデューサーです。どちらもVPCピアリングを介して接続されます。</block>
  <block id="0d127864a05110e3053c2690dea7d914" category="section-title">テナンシーモデル</block>
  <block id="dc947df9f7b14883cbc411bc0a7de469" category="paragraph">Cloud Volumes Service では、個々のプロジェクトが固有のテナントとみなされます。つまり、ボリュームやSnapshotコピーの操作はプロジェクト単位で実行されます。つまり、すべてのボリュームは、で作成されたプロジェクトによって所有され、そのプロジェクトだけが、デフォルトでボリューム内のデータを管理およびアクセスできます。これは、サービスのコントロールプレーンビューと見なされます。</block>
  <block id="b9ea9f76a11191d80f8fe1abc9437eb6" category="section-title">共有 VPC</block>
  <block id="cc11b3be8b129e07961938139b138eb5" category="paragraph">データプレーンビューでは、Cloud Volumes Service を共有VPCに接続できます。ボリュームは、ホスティングプロジェクトまたは共有VPCに接続されたサービスプロジェクトのいずれかで作成できます。その共有VPCに接続されたすべてのプロジェクト（ホストまたはサービス）が、ネットワークレイヤのボリュームにアクセスできます（TCP / IP）。共有VPCでネットワーク接続を確立しているすべてのクライアントはNASプロトコルを使用してデータにアクセスできる可能性があるため、個々のボリュームでのアクセス制御（ユーザ/グループのアクセス制御リスト（ACL）やNFSエクスポートのホスト名/ IPアドレスなど）を使用して、データにアクセスできるユーザを制御する必要があります。</block>
  <block id="0b97558649d416ff7a157c6ebb3415d9" category="paragraph">Cloud Volumes Service は、顧客プロジェクトごとに最大5つのVPCに接続できます。コントロールプレーンでは、どのVPCに接続されているかに関係なく、作成されたすべてのボリュームをプロジェクトで管理できます。データプレーンではVPCが相互に分離され、各ボリュームは1つのVPCにのみ接続できます。</block>
  <block id="be52fe1bd184b72048acd2ba911bb069" category="paragraph">個々のボリュームへのアクセスは、プロトコル固有の（NFS / SMB）アクセス制御メカニズムによって制御されます。</block>
  <block id="a3328901555fee8fe9134fc5bd6e641b" category="paragraph">つまり、ネットワークレイヤでは、共有VPCに接続されているすべてのプロジェクトがボリュームを表示できますが、管理側では、コントロールプレーンでしか所有者プロジェクトにボリュームを表示できません。</block>
  <block id="90f3668b3811dddcb8de24b77c6a6d64" category="section-title">vPCサービスコントロール</block>
  <block id="d5fc4459a5e756d9c4ad2c88c260092b" category="paragraph">vPCサービスコントロールは、インターネットに接続され、世界中でアクセス可能なGoogleクラウド サービス の周辺にアクセス制御境界を確立します。これらのサービスは、ユーザIDを使用してアクセス制御を提供しますが、どのネットワークロケーション要求の送信元を制限することはできません。vPCサービスコントロールは、定義されたネットワークへのアクセスを制限する機能を導入することで、このギャップを解消します。</block>
  <block id="601553f09795c6051748c4f4f63ce893" category="paragraph">Cloud Volumes Service データプレーンは外部インターネットには接続されず、明確に定義されたネットワーク境界（境界）を持つプライベートVPCに接続されます。ネットワーク内では、各ボリュームはプロトコル固有のアクセス制御を使用します。外部ネットワーク接続は、Google Cloudプロジェクト管理者によって明示的に作成されます。ただし、コントロールプレーンはデータプレーンと同じ保護機能を提供しません。また、有効なクレデンシャル（）を持つ任意の場所から誰でもアクセスできます<block ref="f0e6a8c8639b1f1713f124143221142a" category="inline-link-rx"></block>）。</block>
  <block id="7755a392158406ad802334080cd41f73" category="paragraph">つまり、Cloud Volumes Service データプレーンは、VPCサービスコントロールをサポートする必要なく、ネットワークアクセス制御機能を提供します。VPCサービスコントロールは明示的に使用しません。</block>
  <block id="892d60d0a1c71243b5ddff2c66ed584c" category="section-title">パケットのスニッフィング/トレースに関する考慮事項</block>
  <block id="93b0389d05d1b6926967749b8692f2f6" category="paragraph">パケットキャプチャは、ネットワークの問題やその他の問題（NAS権限、LDAP接続など）のトラブルシューティングに役立ちますが、悪意を持ってネットワークIPアドレス、MACアドレス、ユーザ名およびグループ名、エンドポイントで使用されているセキュリティレベルなどの情報を取得することもできます。Google Cloudネットワーク、VPC、およびファイアウォールルールの設定方法が原因で、ユーザのログインクレデンシャルやを使用しないとネットワークパケットへの不要なアクセスを取得できなくなります <block ref="2a18c6d0cd80103144f47d02366a785f" category="inline-link-macro-rx"></block> クラウドインスタンスへ。パケットキャプチャはエンドポイント（仮想マシン（VM）など）でのみ可能であり、VPC内部のエンドポイントでのみ可能です。ただし、共有VPCまたは外部ネットワークトンネル/ IP転送を使用してエンドポイントへの外部トラフィックを明示的に許可している場合は除きます。クライアントの外部でトラフィックをスニファする方法はありません。</block>
  <block id="ce58b63a24bebe6bac29cfe248428477" category="paragraph"><block ref="ce58b63a24bebe6bac29cfe248428477" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c72e76f5c978aa82e296df17081b6836" category="admonition">unixUserPasswordはLDAPによって照会され、プレーンテキストではなくソルトハッシュで送信されます。デフォルトでは、Windows LDAPではunixUserPasswordフィールドは読み込まれません。このフィールドは、LDAPを使用してクライアントへの対話型ログインを行う必要がある場合にのみ必要になります。Cloud Volumes Service では、インスタンスへの対話型LDAPログインはサポートされていません。</block>
  <block id="01b21a51d124432b5b7fe641eae6a004" category="paragraph">次の図は、AUTH_SYSでNFSをキャプチャしたあとの、NFS Kerberos通信からのパケットキャプチャを示しています。トレースで使用できる情報が2つの違いと、転送中の暗号化を有効にすることでNASトラフィックの全体的なセキュリティが向上することに注意してください。</block>
  <block id="0d66010f122b3df766abd8a0cb2ff598" category="paragraph"><block ref="0d66010f122b3df766abd8a0cb2ff598" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ba81028f56cfd4f5e21c7102a8eff68" category="paragraph"><block ref="5ba81028f56cfd4f5e21c7102a8eff68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04aa3ce627dbf5b220c8aa6d4955fb34" category="section-title">VMネットワークインターフェイス</block>
  <block id="8ec45d68b7d371d25a3b82a76db3142b" category="inline-link">プロミスキャスモードです</block>
  <block id="e59b81e20588b0d3a3c495a545d75322" category="paragraph">攻撃者のトリックの1つとして、のVMに新しいNIC（ネットワークインターフェイスカード）を追加する方法があります<block ref="39c80826df1f145e2784d4b04af9d477" category="inline-link-rx"></block> （ポートミラーリング）を使用するか、既存のNICでプロミスキャスモードを有効にして、すべてのトラフィックをスニファします。Google Cloudで新しいNICを追加するには、VMを完全にシャットダウンする必要があります。これによりアラートが生成されるため、攻撃者はこのことに気づかれません。</block>
  <block id="b726bce4fa04e9b7a6d788f212f00c17" category="paragraph">また、NICをプロミスキャスモードに設定することはできず、Google Cloudでアラートをトリガーします。</block>
  <block id="5be5e913f29871f00d216882fc58f26a" category="inline-link-macro">次の図は、コントロールプレーンのアーキテクチャです。</block>
  <block id="f9f0b661819d64fded86dba6dee4dd6b" category="paragraph"><block ref="f9f0b661819d64fded86dba6dee4dd6b" category="inline-link-macro-rx"></block></block>
  <block id="599e7197321e9ab772426d7187714f67" category="summary">SMBは、Microsoftが開発したネットワークファイル共有プロトコルです。イーサネットネットワークを介して複数のSMBクライアントにユーザ/グループの認証、権限、ロック、およびファイル共有を一元的に提供します。</block>
  <block id="b4fdd997b1f33e0d4c6964444c2bf399" category="doc">SMB</block>
  <block id="b619a787e67dd6b7b38f5db3e4da5e80" category="inline-link-macro">前のバージョン：NFS。</block>
  <block id="d5c73fd283fc4c7fcf6fefda8649450f" category="paragraph"><block ref="d5c73fd283fc4c7fcf6fefda8649450f" category="inline-link-macro-rx"></block></block>
  <block id="e0a515b0910f55d3d1d5adda978e8e4f" category="paragraph"><block ref="395dbbdb78e4ae6be8daf8ab2b7828a7" category="inline-link-rx"></block> は、Microsoftが開発したネットワークファイル共有プロトコルです。ユーザ/グループの認証、権限、ロック、およびファイル共有を、イーサネットネットワークを介して複数のSMBクライアントに一元的に提供します。ファイルとフォルダは共有を通じてクライアントに提供されます。共有は、さまざまな共有プロパティを設定したり、共有レベルの権限を通じてアクセスを制御したりすることができます。SMBは、Windows、Apple、Linuxクライアントなど、このプロトコルをサポートする任意のクライアントに提供できます。</block>
  <block id="63f2e3eee09c9d71b23530e2205eb36a" category="paragraph">Cloud Volumes Service では、SMB 2.1および3.xバージョンのプロトコルがサポートされます。</block>
  <block id="cc4a835dfb2ac9e7ba402c068a4ef9a0" category="section-title">アクセス制御/ SMB共有</block>
  <block id="f122c057113b41c182d10fddf2a82817" category="list-text">Windowsユーザ名がCloud Volumes Service ボリュームへのアクセスを要求すると、Cloud Volumes Service はCloud Volumes Service 管理者が設定した方法を使用してUNIXユーザ名を検索します。</block>
  <block id="ac960a1b86a1625e4ff98dbb3feef120" category="list-text">外部UNIXアイデンティティ・プロバイダ（LDAP）が設定されていて、Windows/UNIXユーザ名が同一の場合、Windowsユーザ名は、追加の設定を必要とせずに1:1でUNIXユーザ名にマッピングされます。LDAPを有効にすると、Active Directoryを使用してユーザオブジェクトとグループオブジェクトのUNIX属性がホストされます。</block>
  <block id="3c60aff1fcf4407fc40492eebac8e37b" category="inline-link-macro">「LDAPを使用した非対称ネームマッピング」</block>
  <block id="e4adb9d6d8d5650dfb0663dde5495dff" category="list-text">Windows名とUNIX名が同じ設定にならない場合は、Cloud Volumes Service がLDAPネームマッピングの設定を使用できるようにLDAPを設定する必要があります（を参照） <block ref="1cca6755f54a82023ec645e8be5d4c82" category="inline-link-macro-rx"></block>）。</block>
  <block id="5205bf34161159f00d7f28cb5e6e2a89" category="list-text">LDAPが使用されていない場合、Windows SMBユーザは、Cloud Volumes Service で「pcuser」という名前のデフォルトのローカルUNIXユーザにマッピングされます。つまり'マルチプロトコルのNAS環境では'pcuserにマップされているユーザーによってWindowsに書き込まれたファイルは'UNIXの所有権をpcuserとして表示しますここでは'pcuserがLinux環境では'nobodyユーザー（UID 65534）となっています</block>
  <block id="0ff58f508b02c651e0b4ee271b1792d9" category="paragraph">SMBのみの導入では、「pcuser」のマッピングは引き続き有効ですが、Windowsのユーザとグループの所有権が正しく表示され、SMBのみのボリュームへのNFSアクセスは許可されないため、問題ありません。また、SMBのみのボリュームでは、NFSまたはデュアルプロトコルのボリューム作成後のボリュームへの変換はサポートされません。</block>
  <block id="9327392a148953617bfae88e7e46a666" category="paragraph">Windowsは、Active Directoryドメインコントローラでのユーザ名認証にKerberosを使用します。これには、Cloud Volumes Service インスタンスの外部にあるAD DCとのユーザ名/パスワードの交換が必要です。Kerberos認証は'\\servername'UNCパスがSMBクライアントによって使用され'次の場合に使用されます</block>
  <block id="61caea7c1c859702c330a0781763fd23" category="list-text">servernameにはDNS A/AAAAエントリがあります</block>
  <block id="de4327d512f4e62f9b3ae80f8bb719cc" category="list-text">servernameに対するSMB / CIFSアクセス用の有効なSPNが存在します</block>
  <block id="f5c19a901f7d9431872c0e8893aaa498" category="inline-link-macro">「Cloud Volumes Service がActive Directoryにどのように表示されるか」</block>
  <block id="93c756ce24f344cc333703bcd2e7a06e" category="paragraph">Cloud Volumes Service SMBボリュームを作成すると、セクションの定義に従ってマシンアカウント名が作成されます <block ref="087d516981f271a0b6f0df624ae1e840" category="inline-link-macro-rx"></block> Cloud Volumes Service は動的DNS（DDNS）を利用してDNSに必要なA/AAAAエントリとPTRエントリ、マシンアカウントプリンシパルの必要なSPNエントリを作成するため、そのマシンアカウント名もSMB共有アクセスパスになります。</block>
  <block id="aafa8c8c59e359a65d0c657f05772244" category="admonition">PTRエントリを作成するには、Cloud Volumes Service インスタンスIPアドレスの逆引き参照ゾーンがDNSサーバ上に存在している必要があります。</block>
  <block id="ecd31d9efcb752f09a0690c2f62bf88f" category="paragraph">たとえば、このCloud Volumes Service ボリュームはUNC共有パス「\\cvs-east-433d.cvsdemo.local」を使用します。</block>
  <block id="c6ee58936680de9d2229f523a4c54ffb" category="paragraph">Active Directoryでは、次のエントリがCloud Volume サービスによって生成されたSPNエントリです。</block>
  <block id="5c3c803198a53be899a500a43fcf1d24" category="paragraph"><block ref="5c3c803198a53be899a500a43fcf1d24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97422e33b69a5567af9908d5b2d397fc" category="paragraph">DNS前方/後方参照の結果は次のとおりです。</block>
  <block id="1d3d964bf7fdd6249507cb3738908e54" category="paragraph">必要に応じて、Cloud Volumes Service 内のSMB共有に対してSMB暗号化を有効または要求することで、より多くのアクセス制御を適用できます。いずれかのエンドポイントでSMB暗号化がサポートされていない場合、アクセスは許可されません。</block>
  <block id="e5e9be92303e18ef3f22dfa57dcbd0d3" category="section-title">SMB名エイリアスを使用する</block>
  <block id="500c4de8d7a022d507313e514b85d485" category="paragraph">場合によっては、エンドユーザがCloud Volumes Service で使用するマシンアカウント名を把握することがセキュリティ上の懸念事項になることがあります。また、単にエンドユーザへのアクセスパスを単純化することもできます。このような場合は、SMBエイリアスを作成できます。</block>
  <block id="6c7c194988807a9112adc7f6bc9b1dd5" category="paragraph">SMB共有パスのエイリアスを作成する場合は、DNSでCNAMEレコードと呼ばれるものを利用できます。たとえば'\\cvs-east-433d.cvsdemo.local'ではなく'`\\CIFS'という名前を使用して共有にアクセスするが'Kerberos認証を使用する場合は'A/AAAAレコードを指すDNSのCNAMEと'既存のマシンアカウントに追加されたSPNがKerberosアクセスを提供します</block>
  <block id="620b0e4f14250d32e58b3411c5fd3044" category="paragraph"><block ref="620b0e4f14250d32e58b3411c5fd3044" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a030a66483dc3115cd014273bad041d" category="paragraph">CNAMEを追加したあとのDNS前方参照の結果を次に示します。</block>
  <block id="97ec437207d5ac6fb22613655e7e395e" category="paragraph">新しいSPNを追加したあとのSPNクエリの結果を次に示します。</block>
  <block id="5730e2788651b014b918d2ee1bfdfe67" category="paragraph"><block ref="5730e2788651b014b918d2ee1bfdfe67" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df91b2b002b78b2f9f87c79b56293060" category="paragraph">パケットキャプチャでは、CNAMEに関連付けられたSPNを使用してセッション設定要求を確認できます。</block>
  <block id="8b36b24049a6cda34019fd47ea0273fc" category="paragraph"><block ref="8b36b24049a6cda34019fd47ea0273fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65cc39e4fb8a95d5fcc2098d620ff3b6" category="section-title">SMB認証ダイアレクト</block>
  <block id="fe9fdc3d8157e10bf5b31e8d28fe7827" category="inline-link">方言</block>
  <block id="c50c24feef6ada40d8e2f7be85359c0f" category="paragraph">Cloud Volumes Service では、次の機能がサポートされ<block ref="88f3097f4ad7d144185bbacf0330fbeb" category="inline-link-rx"></block> SMB認証の場合：</block>
  <block id="dfd5b430bc4db2c2836d0227ad9ac0c4" category="list-text">LM</block>
  <block id="d11322c1a7a2383491c23f13113c59ea" category="list-text">NTLM</block>
  <block id="d0952ee882764dd5c3105f5b23a3e505" category="list-text">NTLMv2</block>
  <block id="87b3695bfd6f672e2c7c4da7ca2b46a8" category="list-text">Kerberos</block>
  <block id="11012bc0af4eda341c391c39cf6aa27c" category="paragraph">SMB共有アクセスのKerberos認証は、使用できる最も安全な認証レベルです。AESおよびSMB暗号化が有効になっていると、セキュリティレベルがさらに向上します。</block>
  <block id="e5c584f1ac6fa07c9594321f8fc845e2" category="paragraph">Cloud Volumes Service では、LMおよびNTLM認証の下位互換性もサポートされています。Kerberosの設定が正しくない場合（SMBエイリアスの作成時など）、共有アクセスはより脆弱な認証方法（NTLMv2など）にフォールバックされます。これらのメカニズムは安全性が低いため、一部のActive Directory環境では無効になっています。より脆弱な認証方法が無効になっていて、Kerberosが適切に設定されていない場合、フォールバックする有効な認証方法がないため、共有アクセスは失敗します。</block>
  <block id="d87250f3f8075c2dfbcfe941d0c7bde9" category="inline-link">ネットワークセキュリティ：LAN Manager認証レベル</block>
  <block id="f4457a3dba045094cb39418e2233c8c1" category="paragraph">Active Directoryでサポートされている認証レベルの設定/表示については、を参照してください<block ref="d671b936eec72b8caa6e3a555955a849" category="inline-link-rx"></block>。</block>
  <block id="6ccfb9a0791b337d38ef8ff2cdf26cf8" category="section-title">アクセス許可モデル</block>
  <block id="b1728e361f14c53940f081871f87e6ee" category="section-title">NTFS /ファイル権限</block>
  <block id="3e5348fb86c26b3cabf2912e6e597902" category="paragraph">NTFS権限とは、NTFSロジックに準拠したファイルシステム内のファイルおよびフォルダに適用される権限です。NTFSアクセス権は'Basic'または'Advanced'で適用でき'アクセス制御の場合は'allow'または[Deny]に設定できます</block>
  <block id="80b0c49680a2b15ae6a40273fadefaa8" category="paragraph">基本的な権限は次のとおりです。</block>
  <block id="704a2a0ea2e007dae9f25d038a988076" category="list-text">フルコントロール</block>
  <block id="7f090bbab1cc7f9c08bf4e54d932d3c0" category="list-text">変更</block>
  <block id="3ed713666b4f5112539dd5ffb9376ff4" category="list-text">読み取りと実行</block>
  <block id="7a1a5f3e79fdc91edf2f5ead9d66abb4" category="list-text">読み取り</block>
  <block id="1129c0e4d43f2d121652a7302712cff6" category="list-text">書き込み</block>
  <block id="75484cb1059b92206b918bde1204007a" category="paragraph">ACEと呼ばれるユーザまたはグループに権限を設定すると、ACLに含まれます。NTFS権限では、UNIXモードビットと同じ読み取り/書き込み/実行の基本が使用されますが、所有権の取得、フォルダの作成/追加、データの書き込み、属性の書き込みなど、より詳細で拡張されたアクセス制御（特別な権限）にも拡張できます。</block>
  <block id="77636166006179e57dc5edc6df25b80c" category="paragraph">標準UNIXモードビットは、NTFSアクセス権と同じレベルの粒度を提供しません（ACL内の個々のユーザおよびグループオブジェクトにアクセス権を設定したり、拡張属性を設定したりすることなど）。ただし、NFSv4.1 ACLは、NTFS ACLと同じ機能を提供します。</block>
  <block id="9434d016806e0f50ac7f14efbfa3a3df" category="paragraph">NTFS権限は共有権限よりも限定的であり、共有権限と組み合わせて使用できます。NTFSの権限構造では、最も制限があります。このため、アクセス権を定義するときに、ユーザまたはグループに対する明示的な拒否もフルコントロールよりも優先されます。</block>
  <block id="c0ad12f90a714e04744ab070d26a9c80" category="paragraph">NTFSアクセス権はWindows SMBクライアントから制御されます。</block>
  <block id="ef950b5546945ec414f9da7909c4fe8a" category="section-title">共有権限</block>
  <block id="3df5ef25e4045d2e51c43effb69aa5de" category="paragraph">共有権限は、NTFS権限（読み取り/変更/フルコントロールのみ）よりも一般的で、NFSエクスポートポリシールールの仕組みと同様に、SMB共有への最初のエントリを制御します。</block>
  <block id="41123e00ec2463c8d7c60a10f3d3ede4" category="paragraph">NFSエクスポートポリシールールは、IPアドレスやホスト名などのホストベースの情報を介したアクセスを制御しますが、SMB共有権限は共有ACLでユーザおよびグループACEを使用してアクセスを制御できます。共有ACLは、WindowsクライアントまたはCloud Volumes Service 管理UIから設定できます。</block>
  <block id="7f455f054b3ad11fb335d2f9ec69e3ff" category="paragraph">デフォルトでは、共有ACLと初期ボリュームACLにはフルコントロールを使用したすべてのメンバーが含まれます。ファイルACLを変更する必要がありますが、共有内のオブジェクトのファイル権限によって共有権限が上書きされます。</block>
  <block id="8d37bee954f03966b12b65871768a438" category="paragraph">たとえば、ユーザにCloud Volumes Service ボリュームファイルACLへの読み取りアクセスのみが許可されている場合、次の図に示すように、共有ACLがフルコントロールを使用するEveryoneに設定されていても、ファイルおよびフォルダの作成アクセスは拒否されます。</block>
  <block id="47ff9e7720c14a2a27bfa4ce12bbd268" category="paragraph"><block ref="47ff9e7720c14a2a27bfa4ce12bbd268" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef46360b81c847c0d6f5015920fd5f3e" category="paragraph"><block ref="ef46360b81c847c0d6f5015920fd5f3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="316a22056a64a8465269d31ac436fc22" category="paragraph">セキュリティ上の最善の結果を得るには、次の手順を実行します。</block>
  <block id="09fced4bea14e9b030bd1179b95f3b89" category="list-text">共有およびファイルのACLからすべてのユーザを削除し、代わりにユーザまたはグループの共有アクセスを設定します。</block>
  <block id="8941d253e49282460162b7dac68ad2ba" category="list-text">個々のユーザではなくグループを使用してアクセス制御を行うと、管理が容易になり、グループ管理を通じてユーザの削除や追加を迅速に行うことができます。</block>
  <block id="f63df4fd4f9e10c567332b34b05d35ae" category="list-text">共有権限のACEに対する制限が厳しくなく、一般的な共有アクセスを許可し、ファイル権限を持つユーザとグループにロックダウンされて、より詳細なアクセス制御が可能になります。</block>
  <block id="afe52910905ef63730591f8a01bcb75e" category="list-text">明示的なDENY ACLは、ALLOW ACLより優先されるため、一般的に使用しないでください。ファイルシステムへのアクセスを迅速に制限する必要があるユーザまたはグループに対する明示的なDENY ACLの使用を制限してください。</block>
  <block id="9a2191ac8d9f65679cdf29455149f6cb" category="inline-link">ACLの継承</block>
  <block id="780d68252d03e9f7617f6bf5fe95c1ce" category="list-text">に注意を払ってください<block ref="19af65d9616f33b3ccaee367e8d4dc82" category="inline-link-rx"></block> 権限を変更する際の設定。ファイル数の多いディレクトリまたはボリュームの最上位で継承フラグを設定すると、そのディレクトリまたはボリュームの下の各ファイルに継承された権限が追加されます。 これにより、各ファイルの調整時に意図しないアクセス/拒否や権限の大幅な変更など、不要な動作が発生する可能性があります。</block>
  <block id="0c2104afa1bd6c96b5ccc9c7a7ee8a6a" category="section-title">SMB共有のセキュリティ機能</block>
  <block id="05ec24f8004d55ad7596b79266cd4691" category="paragraph">Cloud Volumes Service でSMBアクセスを使用するボリュームを最初に作成するときに、そのボリュームを保護するための一連の選択肢が表示されます。</block>
  <block id="53eaeead30ddbd2dcb1526241312aedf" category="paragraph">Cloud Volumes Service レベル（パフォーマンスまたはソフトウェア）に応じて、次の選択肢があります。</block>
  <block id="d65a6ba5ce40987a368f3f757b5721ae" category="list-text">*スナップショット・ディレクトリを表示する（CVS -パフォーマンスとCVS - SWの両方で利用可能）*このオプションはSMBクライアントがSMB共有内のスナップショット・ディレクトリにアクセスできるかどうかを制御します（\\server\share\~snapshotタブまたはPrevious Versionsタブ）。デフォルトの設定はチェックされませんボリュームのデフォルトは'~snapshot'ディレクトリへのアクセスを非表示にして拒否し'ボリュームの[以前のバージョン]タブにスナップショット・コピーは表示されません</block>
  <block id="9ebf5e1b6bf20c2942f0add8e979dd7a" category="paragraph"><block ref="9ebf5e1b6bf20c2942f0add8e979dd7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="baf0124343f1806f3ff44f011e92c73f" category="paragraph">セキュリティ上の理由、パフォーマンス上の理由（これらのフォルダをAVスキャンから非表示にする）、または設定上の理由から、エンドユーザに対してSnapshotコピーを非表示にすることが望ましい場合があります。Cloud Volumes Service スナップショットは読み取り専用であるため、これらのスナップショットが表示されていても、エンドユーザーはスナップショットディレクトリ内のファイルを削除または変更することはできません。Snapshotコピーが作成された時点のファイルまたはフォルダのファイル権限Snapshotコピー間でファイルまたはフォルダの権限が変更された場合、変更内容はSnapshotディレクトリ内のファイルまたはフォルダにも適用されます。ユーザとグループは、権限に基づいてこれらのファイルやフォルダにアクセスできます。Snapshotディレクトリ内のファイルの削除または変更はできませんが、ファイルまたはフォルダをSnapshotディレクトリからコピーすることは可能です。</block>
  <block id="2716bd858fb85bb9b111c5d51138cb40" category="list-text">* SMB暗号化を有効にします（CVS -パフォーマンスとCVS - SWの両方で利用可能）。* SMB暗号化は、SMB共有ではデフォルトで無効になっています（オフ）。このチェックボックスをオンにすると、SMB暗号化が有効になります。つまり、SMBクライアントとサーバ間のトラフィックが、ネゴシエートされたサポート対象の最大暗号化レベルで転送中に暗号化されます。Cloud Volumes Service は、SMBで最大AES-256暗号化をサポートしています。SMB暗号化を有効にした場合、SMBクライアントが気づくことがあるパフォーマンス低下はありません。約10~20%の範囲になります。ネットアップでは、パフォーマンスへの影響が許容されるかどうかをテストで確認することを強く推奨してい</block>
  <block id="ab7715a00a3e7691d84318bb2f1a3bc1" category="list-text">* SMB共有を非表示にします（CVS -パフォーマンスとCVS - SWの両方に利用できます）。*このオプションを設定すると、SMB共有パスが通常の閲覧から見えなくなります。つまり、共有パスがわからないクライアントは、デフォルトのUNCパス（例：\\cvs-smb）にアクセスすると共有を参照できません。このチェックボックスをオンにすると、SMB共有パスを明示的に知っているクライアント、またはグループポリシーオブジェクトによって定義された共有パスを持つクライアントだけが、このパスにアクセスできます（難読化によるセキュリティ）。</block>
  <block id="67699a5a5f5ec8d69977d9f44b521201" category="inline-link">アクセスベースの列挙（ABE）の仕組み</block>
  <block id="eb36f3383eadcd01f954bc9848b7de21" category="list-text">*アクセスベースの列挙（ABE）を有効にします（CVS - SWのみ）。* SMB共有を非表示にするのと似ています。ただし、共有やファイルは、オブジェクトへのアクセス権限がないユーザまたはグループに対してのみ表示されます。たとえば、Windowsユーザ「joe」に許可されているアクセス許可で少なくとも読み取りアクセスが許可されていない場合、Windowsユーザ「joe」はSMB共有またはファイルをまったく表示できません。このオプションはデフォルトでは無効になっており、チェックボックスを選択することで有効にできます。ABEの詳細については、ネットアップの技術情報アーティクルを参照してください<block ref="6d2d0139fec74415d85dc1015aa48640" category="inline-link-rx"></block></block>
  <block id="5ff6480cf15803c821d9cc9bb3dcbe5c" category="inline-link">継続的可用性を備えたSMB共有</block>
  <block id="17faa8cfb0bc70572c6d4f120cb6de10" category="list-text">*継続的可用性（CA）共有のサポートを有効にします（CVS -パフォーマンスのみ）。*<block ref="97476034cc2961d2c1c061d5bdcc519a" category="inline-link-rx"></block> Cloud Volumes Service バックエンドシステム内のノード間でロック状態をレプリケートすることで、フェイルオーバーイベント中のアプリケーションの停止を最小限に抑えることができます。これはセキュリティ機能ではありませんが、全体的な耐障害性は向上します。現在、この機能では、SQL ServerとFSLogixアプリケーションのみがサポートされています。</block>
  <block id="f816f594817af59eac10c8385f34d319" category="section-title">デフォルトの非表示共有</block>
  <block id="7ce84bf53b21b783ae6c62b61f60f9e3" category="inline-link">非表示の管理共有</block>
  <block id="31a7b0c828b1a1039c3fe9e855430acd" category="paragraph">Cloud Volumes Service でSMBサーバを作成すると、その場所に配置されます<block ref="e698db250309574e2563e69229bd950f" category="inline-link-rx"></block> データボリュームのSMB共有に加えて作成される（$命名規則を使用）。これには、C$（名前空間アクセス）とIPC$（Microsoft管理コンソール（MMC）へのアクセスに使用されるリモート手順 呼び出し（RPC）などのプログラム間の通信用の名前付きパイプの共有）が含まれます。</block>
  <block id="64667cec654fa57a129c5c1fe752d7ae" category="inline-link">Windowsは、これらの共有への匿名アクセスをデフォルトで禁止します</block>
  <block id="7962a42fa319b5ea9ccf0429193d4f3c" category="paragraph">IPC$共有には共有ACLは含まれておらず、変更することはできません。これはRPC呼び出しおよびにのみ使用されます<block ref="582b1e06ccfbbf9885ff446ec79f8b0f" category="inline-link-rx"></block>。</block>
  <block id="c2c8a4f76f99f203d14ee3c1adae3c40" category="paragraph">C$共有ではデフォルトでBUILTIN\Administratorsアクセスが許可されますが、Cloud Volumes Service 自動化によって共有ACLが削除され、C$共有へのアクセスによってCloud Volumes Service ファイルシステム内のマウントされたすべてのボリュームが可視化されるため、すべてのユーザにアクセスすることはできません。その結果'\\server\C$'への移動は失敗します</block>
  <block id="444613ce56f4180cf88b531783a9e3bc" category="section-title">ローカル/ BUILTIN管理者/バックアップ権限を持つアカウント</block>
  <block id="5659f387517ed75a127b9a6bda6f1329" category="paragraph">Cloud Volumes Service SMBサーバは、選択したドメインユーザおよびグループにアクセス権を適用するローカルグループ（BUILTIN\Administratorsなど）があることに、通常のWindows SMBサーバと同様の機能を維持します。</block>
  <block id="709eb202e09b717ba82624b788948428" category="inline-link">SeBackupPrivilegeおよびSeRestorePrivilege</block>
  <block id="03455d8db7797aab1e6e9efe9bf4d2a5" category="paragraph">バックアップユーザに追加するユーザを指定すると、そのActive Directory接続を使用するCloud Volumes Service インスタンスのBUILTIN\Backup Operatorsグループにユーザが追加され、が取得されます<block ref="3d66e5b4422b04db3b01ddbcafb3649a" category="inline-link-rx"></block>。</block>
  <block id="b5b39a908a856900d75e0b129fb9e349" category="inline-link">SMB共有上のSQL Server</block>
  <block id="52f5e8856edf4d634cf608cb64bec885" category="paragraph">Security Privilegeユーザにユーザを追加すると、そのユーザにはSeSecurityPrivilegeが付与されます。これは、などの一部のアプリケーションユースケースで役立ちます<block ref="b685ff2242ac25f5022af8207109cc39" category="inline-link-rx"></block>。</block>
  <block id="99c9211b9f5166d96d9e6613c4be9f77" category="paragraph"><block ref="99c9211b9f5166d96d9e6613c4be9f77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59976878f4cfcf8cd4a9bccf37270fec" category="paragraph">Cloud Volumes Service ローカルグループメンバーシップは、適切な権限を持つMMCを使用して表示できます。次の図に、Cloud Volumes Service コンソールを使用して追加されたユーザを示します。</block>
  <block id="9b02abec53251430b553f5124b676b1f" category="paragraph"><block ref="9b02abec53251430b553f5124b676b1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09e7cb53843328fd35bff1d1075e8e04" category="paragraph">次の表に、デフォルトのBUILTINグループのリストと、デフォルトで追加されるユーザ/グループを示します。</block>
  <block id="52087222d7968b7bd85e5698912f6cee" category="cell">ローカル/ BUILTINグループ</block>
  <block id="c899fa178e9ccd9c46154a79773b9e8e" category="cell">デフォルトのメンバー</block>
  <block id="f6c0ddae69a704e001f6cba9fba3f951" category="cell">builtin\Administrators*</block>
  <block id="6930162f33d7d3cc792907afc2d709d6" category="cell">Domain\Domain Adminsの略</block>
  <block id="291b9d53abc37bd4eeab64a68607df4f" category="cell">Builtin\Backup Operators*</block>
  <block id="f87e4b3cc74234e59b0d07ad558b2c05" category="cell">組み込みのゲスト</block>
  <block id="bea5dc29e529ecf572942e7f6cbbf19b" category="cell">Domain\Domainゲスト</block>
  <block id="bafee069f6320499a0f630485028a961" category="cell">Builtin\Power Usersの場合</block>
  <block id="d3ffae89384cc2219d9dc26887d6422c" category="cell">組み込みのドメインユーザ</block>
  <block id="a26444fe66f07a77f6e392ad714158ff" category="cell">Domain\Domain Usersの略</block>
  <block id="ee6df957412594fad1ce714d75089e5f" category="paragraph">*グループメンバーシップはCloud Volumes Service Active Directory接続設定で制御されます。</block>
  <block id="c648fec724703de3d038fda21e884ef7" category="paragraph">MMCウィンドウにはローカルユーザとローカルグループ（およびグループメンバー）を表示できますが、このコンソールからオブジェクトの追加や削除、グループメンバーシップの変更はできません。デフォルトでは、Cloud Volumes Service のBUILTIN\AdministratorsグループとAdministratorのみが追加されます。現時点では、これを変更することはできません。</block>
  <block id="39aedbfda9a943aea0e4c841bc68dc0a" category="paragraph"><block ref="39aedbfda9a943aea0e4c841bc68dc0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ae7d2b2ec0c231b6934886bf6690c9e" category="paragraph"><block ref="0ae7d2b2ec0c231b6934886bf6690c9e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="255c5bd3cdece4dd4a7891941d9c964e" category="section-title">MMC /コンピュータ管理アクセス</block>
  <block id="7f956759e187dbb2b65022241e8053cd" category="paragraph">Cloud Volumes Service のSMBアクセスはコンピュータの管理MMCへの接続を提供します。MMCを使用すると、共有の表示、共有ACLの管理、SMBセッションの表示と管理、および開いているファイルの表示を行うことができます。</block>
  <block id="e3d561744b3b4f6ab5953c2f96daaad7" category="paragraph">MMCを使用してCloud Volumes Service のSMB共有およびセッションを表示するには、現在ログインしているユーザがドメイン管理者である必要があります。他のユーザには、MMCを使用したSMBサーバの表示または管理へのアクセスを許可されているほか、Cloud Volumes Service SMBインスタンスで共有やセッションを表示しようとすると、[You do not have Permissions]ダイアログボックスが表示されます。</block>
  <block id="aaf8b324d80834b9d235cb6b6d84be89" category="paragraph">SMBサーバーに接続するには、[コンピューターの管理]を開き、[コンピューターの管理]を右クリックして、[別のコンピューターに接続]を選択します。コンピュータの選択ダイアログボックスが開き、SMBサーバ名（Cloud Volumes Service ボリューム情報に含まれています）を入力できます。</block>
  <block id="c34ce8bbe19f26cf58867de938f87920" category="paragraph">適切な権限を持つSMB共有を表示すると、Active Directory接続を共有するCloud Volumes Service インスタンス内の使用可能なすべての共有が表示されます。この動作を制御するには、Cloud Volumes Service ボリュームインスタンスでSMB共有を非表示オプションを設定します。</block>
  <block id="b939aeb87de29dc576ad4adc5fa19bce" category="paragraph"><block ref="b939aeb87de29dc576ad4adc5fa19bce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c57a1134332b8bafcaa5f411a65b4a49" category="paragraph"><block ref="c57a1134332b8bafcaa5f411a65b4a49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1325fb66f29e707e7e3402f0d45d59dc" category="paragraph">次の表に、MMCでサポートされる機能とサポートされない機能を示します。</block>
  <block id="241bac47978fca670a6b9c52e3432067" category="cell">サポートされている機能</block>
  <block id="fe2de21fdfcaf4ed19a251aab83bf0ff" category="cell">サポートされていない機能</block>
  <block id="ad338fe21209358afd2f29eee14817c6" category="list-text">共有を表示します</block>
  <block id="a5dc19ca94f052a57587a2f4f1433678" category="list-text">アクティブなSMBセッションを表示します</block>
  <block id="ff50826288707e494282b4cf6bec983b" category="list-text">開いているファイルを表示します</block>
  <block id="8c006cf58f2706f56d65e1431b1e128e" category="list-text">ローカルユーザとローカルグループを表示します</block>
  <block id="bad02cc8e307a9ac8bf6899188811a54" category="list-text">ローカルグループメンバーシップを表示します</block>
  <block id="5ab1c0d0251d23bc086198a8fc219a69" category="list-text">システムのセッション、ファイル、およびツリー接続のリストを列挙します</block>
  <block id="bd7ff4b31e7eade785d74789a052242c" category="list-text">開いているファイルを閉じます</block>
  <block id="3a6cd2ea18cf077c57b65c28c40f9851" category="list-text">開いているセッションを閉じます</block>
  <block id="e5ded1413b3fd0a1690184029acf1845" category="list-text">共有を作成 / 管理します</block>
  <block id="b4d1348a7ae3aa39ac1fbd299a07ebb9" category="list-text">新しいローカルユーザ / グループを作成しています</block>
  <block id="5c3d34e6fdaee1edee0722fcef147f8a" category="list-text">既存のローカルユーザ/グループの管理/表示</block>
  <block id="1c79052ffd16d848acb6278dd54f0d33" category="list-text">イベントまたはパフォーマンスログを表示します</block>
  <block id="eedf037c0977372c4f0adaa359d5f6e0" category="list-text">ストレージの管理</block>
  <block id="d5d1ca904ae55c0d5399eb923b8d6d21" category="list-text">サービスとアプリケーションの管理</block>
  <block id="dddaf61539328810b230a60430960038" category="section-title">SMBサーバのセキュリティ情報</block>
  <block id="7c7ff5a0c882bba2c6d86dc13caa6e49" category="paragraph">Cloud Volumes Service のSMBサーバでは、Kerberosのクロックスキュー、チケットの有効期間、暗号化など、SMB接続のセキュリティポリシーを定義する一連のオプションを使用します。</block>
  <block id="bdf80cb84c583e3d6af81c4778921102" category="paragraph">次の表に、これらのオプションとその機能、デフォルト設定、およびCloud Volumes Service で変更できるかどうかを示します。一部のオプションはCloud Volumes Service には適用されません。</block>
  <block id="708cc30ece03d9ba30511bea4ea09792" category="cell">セキュリティオプション</block>
  <block id="ad67361f283520dada90173b5fbfaad7" category="cell">Kerberosの最大クロックスキュー（分）</block>
  <block id="ebd83f9f3f1a10793a7aaf199f57a32b" category="cell">Cloud Volumes Service とドメインコントローラ間の最大時間スキューを指定します。時刻のずれが5分を超えるとKerberos認証は失敗します。これはActive Directoryのデフォルト値に設定されています。</block>
  <block id="e4da3b7fbbce2345d7772b0674a318d5" category="cell">5.</block>
  <block id="ccf9068a42f159a1b1cd3e07b84c5ecd" category="cell">Kerberosチケットの有効期間（時間）</block>
  <block id="34c1c29ec6cffe3b75b5f4db3cd4e12f" category="cell">Kerberosチケットの有効期間が終了しないと更新が必要になります。10時間以内に更新が行われない場合は、新しいチケットを取得する必要があります。Cloud Volumes Service は、これらの更新を自動的に実行します。Active Directoryのデフォルト値は10時間です。</block>
  <block id="b63288488b52af4af602d79dce8aa252" category="cell">Kerberosチケットの最大更新日数</block>
  <block id="082ea39c709884c3439c0b1e937ee15a" category="cell">新しい許可要求が必要になるまでKerberosチケットを更新できる最大日数。Cloud Volumes Service はSMB接続のチケットを自動的に更新します。Active Directoryのデフォルト値は7日です。</block>
  <block id="8f14e45fceea167a5a36dedd4bea2543" category="cell">7.</block>
  <block id="2127af947646b417ab67c66e82922af5" category="cell">Kerberos KDC接続タイムアウト（秒）</block>
  <block id="4a4dfa50ac48d9523d22b929a8df2e01" category="cell">KDC接続がタイムアウトするまでの秒数。</block>
  <block id="09b779421f875a0831c9165f7730b710" category="cell">受信SMBトラフィックに署名を要求します</block>
  <block id="8f4c5ae7b0c978c58bbe10790f9eb578" category="cell">SMBトラフィックに署名を要求するかどうかを設定します。trueに設定すると、署名をサポートしていないクライアントは接続に失敗します。</block>
  <block id="c77326ff7e3ae38e2b7ed07e3bff97e8" category="cell">ローカルユーザアカウントに複雑なパスワードを要求します</block>
  <block id="fab3a355aeb5f939ba8dcdc4ae0ea4b8" category="cell">ローカルSMBユーザのパスワードに使用します。Cloud Volumes Service ではローカルユーザの作成はサポートされないため、このオプションはCloud Volumes Service には適用されません。</block>
  <block id="a3ab2beb782b5f0d7b6d1eb3cacdff1f" category="cell">Active Directory LDAP接続にはstart_tlsを使用します</block>
  <block id="0e46800ed1870ec055aaa1a1193ff94e" category="cell">Active Directory LDAPのStart TLS接続を有効にするために使用します。現在、Cloud Volumes Service ではこの機能の有効化がサポートされていませ</block>
  <block id="b3734582301f762d04b757dd4bc38917" category="cell">は、KerberosのAES-128およびAES-256暗号化を有効にします</block>
  <block id="4f36af6c9bdde3ebcee7b34176ffe895" category="cell">Active Directory接続にAES暗号化を使用するかどうかを制御し、Active Directory接続の作成/変更時にActive Directory認証用のAES暗号化を有効にするオプションで制御します。</block>
  <block id="60a39bccb81f56ddfcbb75f0ffcd1fb6" category="cell">LM互換性レベル</block>
  <block id="a4ada97522d5a887e144bf5d59b41a79" category="cell">Active Directory接続でサポートされている認証ダイアレクトのレベル。「」を参照してください<block ref="17dc1460fa48a825f7967ddb6804d663" category="inline-xref-macro-rx"></block>」を参照してください。</block>
  <block id="cba8970659f15f342022079c22a97ee9" category="cell">NTLMv2 - krb</block>
  <block id="5e22abe32604d6b7925fa4768934bb5d" category="cell">受信CIFSトラフィックにSMB暗号化を要求します</block>
  <block id="ae7c4fcb353d520e8996acadf9c9c42f" category="cell">すべての共有でSMB暗号化が必要です。これはCloud Volumes Service では使用されません。代わりに、ボリューム単位で暗号化を設定します（「」を参照）<block ref="6931acdfb95dc44f28af40d26d20d65c" category="inline-xref-macro-rx"></block>」）をクリックします。</block>
  <block id="e00514b301b6206c1024de564d0d71fe" category="cell">クライアントセッションセキュリティ</block>
  <block id="b9e69cb6a219e02ada3e29b808558c45" category="inline-link-macro">「LDAPチャネルバインディング」</block>
  <block id="d16466e25f07f41d5c768e32becc9751" category="cell">LDAP通信の署名と封印を設定します。この機能は現在Cloud Volumes Service には設定されていませんが、今後のリリースでサポートする必要が生じる可能性があります。WindowsパッチによるLDAP認証の問題に対する修正については、セクションで説明しています <block ref="4bb24ef2f48443c7e6d43902d0f8498e" category="inline-link-macro-rx"></block>。</block>
  <block id="b4c17f5cf25d927d8fb7dbab5e1d84c5" category="cell">DC接続のSMB2有効化</block>
  <block id="31a7643648d0d4454c1fd8a860f1a12d" category="cell">DC接続にSMB2を使用します。デフォルトは有効です。</block>
  <block id="2cd88a3568a04efbfd46abb6cce9a411" category="cell">システム-デフォルト</block>
  <block id="6158881a00903bd45b66955e6487a27c" category="cell">LDAPリファーラル追跡</block>
  <block id="4ddc9ad0bd193ba15a48f662666ccd96" category="cell">セキュアなActive Directory接続にLDAPSを使用します</block>
  <block id="4182d7f699521f08b56835082e7caf27" category="cell">LDAP over SSLを有効にします。現在、Cloud Volumes Service ではサポートされていません。</block>
  <block id="b31e0a21b1fa97ab2faf1479ea00c9db" category="cell">DC接続には暗号化が必要です</block>
  <block id="23cc5b51f575d3c458ac112689f7a2f1" category="cell">DC接続を成功させるには暗号化が必要です。Cloud Volumes Service ではデフォルトで無効になっています。</block>
  <block id="595451bb2138edcd7bd73c4e11f8890d" category="inline-link-macro">次の例：デュアルプロトコル/マルチプロトコル</block>
  <block id="47b43136bb3740d6abdf3823c798bd7e" category="paragraph"><block ref="47b43136bb3740d6abdf3823c798bd7e" category="inline-link-macro-rx"></block></block>
  <block id="ebd8431a0b14e9588377860f5d21d80b" category="sidebar">アーキテクチャの概要</block>
  <block id="a20fe2a1eb3b2546487a96f1e639d4f3" category="sidebar">その他のNASインフラストラクチャサービスの依存関係（KDC、LDAP、DNS）</block>
  <block id="92e704fe041898cac086cd4a192a1815" category="cell">2022年5月20日</block>
  <block id="efae07e57b0f279c460d1361b379cf52" category="cell">SuperPODに関するBeeGFSの設計と導入に関する新しいガイドです</block>
  <block id="197d6fccbd337f46908b50e1ac3ece5d" category="sidebar">SuperPOD：ネットアップとNVIDIAの解決策</block>
  <block id="ed05ff1aa7ef3023c5dc2359de4e2d15" category="sidebar">ネットアップのBeeGFS（設計ガイド）</block>
  <block id="b877ddfe299c52df6f7a340fdcaa52eb" category="sidebar">ネットアップのBeeGFS（導入ガイド）</block>
  <block id="e6bec38fe69985a0817e3c0b2b3a0c20" category="cell">*コンテンツランディング・ページ*</block>
  <block id="b1dc18184f115680e9fe3b64295c4678" category="cell">AI ベースのソリューションのコレクション。AIランディングページには、コンテンツごとに人気の高いコンテンツが表示されます。</block>
  <block id="e68818392f0eda6e918ccb9e7537e282" category="inline-link-macro">AIコンテンツ</block>
  <block id="748eaad82fcc3f281aebd8c5467a4d91" category="cell"><block ref="748eaad82fcc3f281aebd8c5467a4d91" category="inline-link-macro-rx"></block></block>
  <block id="53840db4921094507c6397fb6ee31d58" category="cell">最新のデータ分析ソリューション（ Splunk SmartStore、Apache Sparkなど）。最新のデータ分析ランディングページでは、コンテンツごとに人気の高いコンテンツが表示されます。</block>
  <block id="1b1956b226e3085af9e004e60ce183b4" category="inline-link-macro">最新のデータ分析コンテンツ</block>
  <block id="16321f09e6ea361ef5515d5939fa73f1" category="cell"><block ref="16321f09e6ea361ef5515d5939fa73f1" category="inline-link-macro-rx"></block></block>
  <block id="87867e178542e6ed3cf6ea885807d4f1" category="cell">デスクトップ仮想化を含む、仮想化コアソリューションの集合体。仮想化のランディングページには、コンテンツ固有の「タイル」で表示される一般的なコンテンツが表示されます。</block>
  <block id="5654a75155b39867a9f4372fcc292bab" category="inline-link-macro">仮想化コンテンツ</block>
  <block id="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="cell"><block ref="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="inline-link-macro-rx"></block></block>
  <block id="24a8e607718680e8d1dd293b9d736add" category="cell">コンテナベースのソリューションの集合。仮想化のランディングページには、コンテンツ固有の「タイル」で表示される一般的なコンテンツが表示されます。</block>
  <block id="afb6dbef1b44c7f79b8883cae5cc3b30" category="inline-link-macro">コンテナコンテンツ</block>
  <block id="d76e9a2c09fc047c91b6cb4c2f340644" category="cell"><block ref="d76e9a2c09fc047c91b6cb4c2f340644" category="inline-link-macro-rx"></block></block>
  <block id="0cf49f958731e4b4c23d4b04f0802ba0" category="cell">ビジネスアプリケーションとデータベース</block>
  <block id="73c685140b2461529432f6e9628ef281" category="cell">ビジネスアプリケーションとデータベースソリューションの集合。SAPとSAP HANAのランディングページから、コンテンツ固有の「タイル」に表示される一般的なコンテンツが提供されます。このセクションでは、OracleおよびSQL Serverデータベースソリューションについても説明します。</block>
  <block id="ef0bea1a6ce6e68dd3ebae18ea2de71f" category="inline-link-macro">SAPおよびSAP HANAのコンテンツ</block>
  <block id="589c17157183d6295af608cccff7c8da" category="cell"><block ref="589c17157183d6295af608cccff7c8da" category="inline-link-macro-rx"></block></block>
  <block id="d7339a230985e723af5d49a6470f4fc8" category="cell">データ移行、データ保護、データ セキュリティ ソリューションの集合体。</block>
  <block id="d3d4dd76fc599d6c513fa0434537bc08" category="summary">ネットアップソリューションのすべてのコンテンツを解決策 の機能で紹介するブログシリーズです</block>
  <block id="4d46b81ad5db47d845e86c95088ff47a" category="doc">ネットアップのソリューション：ブログ</block>
  <block id="a93daa19938c1852de52ce10350307a4" category="paragraph">ネットアップのソリューションのさまざまな機能に特化したブログの概要を紹介しています。</block>
  <block id="bf20a476dd72893f0f21a3d56a601784" category="open-title">人工知能</block>
  <block id="e6c9e9316fee7048645938d93d674056" category="list-text"><block ref="e6c9e9316fee7048645938d93d674056" category="inline-link-macro-rx"></block></block>
  <block id="3e78754f8bb90f06073e18a2399d0b7f" category="list-text"><block ref="3e78754f8bb90f06073e18a2399d0b7f" category="inline-link-macro-rx"></block></block>
  <block id="821c35321bcc709868cdd0b7f31165ee" category="cell">2022年1月4日</block>
  <block id="b4ea7c36c784b6da08e2b44d82018c65" category="open-title">AWS / VMC</block>
  <block id="b9b37266c1f6c6a5244f3fef48f644e1" category="list-text">VMware Cloud for AWSを導入して設定</block>
  <block id="57669ed11798d25a8216675c3f0f6ecf" category="inline-link-macro">VMCの設定手順</block>
  <block id="fc835ae678d144f168b78fafb98286b2" category="paragraph">詳細を表示します <block ref="0bca421d9cd22e10e81bd0c987fad54b" category="inline-link-macro-rx"></block>。</block>
  <block id="9e88bf7f3ee359d8f536975aa39ab6a5" category="open-title">Azure / AVS</block>
  <block id="293193a848a4345d095f41ff490fd1a4" category="inline-link-macro">AVSの設定手順</block>
  <block id="e2501a40b45cdc3295c28e82fc2ffa18" category="paragraph">詳細を表示します <block ref="29745c898e96ab7473e2b2c19fa34fbf" category="inline-link-macro-rx"></block>。</block>
  <block id="7e7790ea083a371632d0764a881695f6" category="open-title">GCP/GCVE</block>
  <block id="e44b11e9adb07a14c72f48599f700cd4" category="inline-link-macro">GCVEの設定手順</block>
  <block id="0969e77be69a346b123e1b2c625e25b0" category="paragraph">詳細を表示します <block ref="7ffa56a4f5c5cf9fb86200a4dd2e1a5d" category="inline-link-macro-rx"></block>。</block>
  <block id="52be4c6acc8cca3a598e3a651421de3d" category="inline-link-macro">VMCのゲスト接続ストレージオプション</block>
  <block id="a8e9a5787febc7740af29cd0bebf2e95" category="inline-link-macro">AVSのゲスト接続ストレージオプション</block>
  <block id="2da991b20a7647acbdd67154515723cf" category="inline-link-macro">GCVEのゲスト接続ストレージオプション</block>
  <block id="5d49b0ee57ad4b529c897b49789aa965" category="paragraph">詳細を表示します <block ref="39710aaf95ad3f60e444c45fa2d1a561" category="inline-link-macro-rx"></block>。</block>
  <block id="685435b4b2388bd8f370b8fbb6ef6cc7" category="cell">*ゲスト接続*</block>
  <block id="8299249ba5f910704b6288ee7e271747" category="cell">* AWS *</block>
  <block id="eb35b03ceb49f5f06a4570454e08c34c" category="cell">CVO FSX ONTAP<block ref="999b20d9470091fda2e66b2dde5b0af7" category="inline-link-macro-rx"></block></block>
  <block id="1bdeba09294eb5abc383607bb93ff443" category="cell">* Azure *</block>
  <block id="06a1c60be3b7274c063385eaa240863f" category="cell">CVOのANF<block ref="f44f46a20eba78aa72ad4f68a0486a31" category="inline-link-macro-rx"></block></block>
  <block id="25bdffbd4ab087e994a0e54fe22ff6bd" category="cell">* GCP *</block>
  <block id="96e48152153beabed038aa4e41f2abf8" category="cell">CVO CVS<block ref="a54d2eac225d57696bf863778373ea0b" category="inline-link-macro-rx"></block></block>
  <block id="a46eb72d67c0cbcbbdfcde010fbc0b03" category="paragraph">ネットアップがAzureにもたらすソリューションの詳細をご確認ください。</block>
  <block id="d8732ebfbd98db5a8cd9db59aa5b0637" category="paragraph">VMwareは、クラウドワークロードを次の3つのカテゴリのいずれかに分類します。</block>
  <block id="2cb256015e8585083bd2350f010676fb" category="list-text">保護（ディザスタリカバリとバックアップ/リストアの両方を含む）</block>
  <block id="3bc026b815790a05493fa56fc4b8d8bd" category="list-text">拡張</block>
  <block id="2c0a3f21d3cbc96381e4c2fe29329ec1" category="paragraph">次のセクションで使用可能なソリューションを参照してください。</block>
  <block id="97740c0c87b83b324e18993ba93f0617" category="open-title">保護</block>
  <block id="e74fe990166c1a4bb77dde7f12823b5d" category="paragraph">近日公開！</block>
  <block id="3d98cfc43616995ea335b20aa9b10ef2" category="paragraph">Azureでは、ネイティブのAzure NetApp Files （ANF）サービスまたはCloud Volumes ONTAP （CVO）でゲスト接続ネットアップストレージをサポートしています。</block>
  <block id="8f53b5241aa3284f9058318dcbc2504d" category="section-title">Azure NetApp ファイル（ ANF ）</block>
  <block id="2295dc11d84df2756a1eaac36330b417" category="paragraph">Azure NetApp Files は、エンタープライズクラスのデータ管理とストレージをAzureに提供するため、ワークロードとアプリケーションを簡単に管理できます。パフォーマンスを低下させることなく、ワークロードをクラウドに移行して実行できます。</block>
  <block id="806f1ffa4d2e1d7ee40a30337658a5ef" category="paragraph">Azure NetApp Files は障害を取り除き、ファイルベースのアプリケーションをすべてクラウドに移行できるようにします。初めてアプリケーションを再設計する必要はなく、アプリケーションの永続的ストレージを複雑化することもありません。</block>
  <block id="12eb3a27c6c1134f55e12f1349b87a91" category="paragraph">このサービスはMicrosoft Azure Portalを通じて提供されるため、ユーザはMicrosoft Enterprise Agreementの一部としてフルマネージドサービスを利用できます。マイクロソフトが管理するワールドクラスのサポートにより、安心してご利用いただけます。この1つの解決策 で、マルチプロトコルワークロードをすばやく簡単に追加できます。従来の環境でも、WindowsとLinuxの両方のファイルベースアプリケーションを構築して導入できます。</block>
  <block id="7afda8c8e445dfa1015ae8245fa8026e" category="section-title">Cloud Volumes ONTAP （CVO）</block>
  <block id="8560d03d6d9a5398acd72a06a8fddd12" category="paragraph">Cloud Volumes ONTAP （CVO）は、ネットアップのONTAP ストレージソフトウェアを基盤に構築された、業界をリードするクラウドデータ管理解決策 です。Amazon Web Services（AWS）、Microsoft Azure、Google Cloud Platform（GCP）でネイティブに利用できます。</block>
  <block id="12f2a9cf238d1339eddfc43be9f107e1" category="paragraph">ソフトウェアで定義されるONTAP バージョンで、クラウドネイティブなストレージを消費し、クラウドとオンプレミスで同じストレージソフトウェアを使用できるため、まったく新しい方法でIT担当者のデータ管理を再トレーニングする必要がありません。</block>
  <block id="62c9becbf4c5643c0df4cbe868b09f0c" category="paragraph">CVOを使用すれば、エッジ、データセンター、クラウド間でシームレスにデータを移動し、ハイブリッドクラウドを統合できます。すべてを1画面の管理コンソールであるNetApp Cloud Managerで管理できます。</block>
  <block id="aafae379e910c7a153b831ce5122f5e8" category="paragraph">設計上、CVOは卓越したパフォーマンスと高度なデータ管理機能を備えており、クラウドで最も要件の厳しいアプリケーションにも対応できます</block>
  <block id="6db49f93b02d752e6b80616d15759056" category="inline-link-macro">ネットアップとVMwareのクラウドソリューション</block>
  <block id="a088d0b353502e225826d0feb3041d57" category="list-text"><block ref="a088d0b353502e225826d0feb3041d57" category="inline-link-macro-rx"></block></block>
  <block id="9e348c60eb79913385ed14a65efffff6" category="paragraph">詳細を表示します <block ref="be78464beb9b2a2b1696a7fe38c0e484" category="inline-link-macro-rx"></block>。</block>
  <block id="cb9ab2dcef988aa0eaa2da1d789cfdb4" category="section-title">解決策のユースケース</block>
  <block id="c9c270552e6f44a0219e4d2459cb4b90" category="paragraph">ネットアップと VMware のクラウドソリューションを使用すれば、多くのユースケースを Azure AVS で簡単に導入できます。SEケースは、VMwareが定義したクラウド領域ごとに定義されます。</block>
  <block id="3fac70d2bc4023bd8c5bb8f7c93b16e8" category="list-text">保護（ディザスタリカバリとバックアップ/リストアの両方を含む）</block>
  <block id="79e4e4c7346c156a268641272a85c01e" category="inline-link-macro">Azure AVS 向けネットアップソリューションをご覧ください</block>
  <block id="6626f21cba60531fb6ab33c5b686fd03" category="paragraph"><block ref="6626f21cba60531fb6ab33c5b686fd03" category="inline-link-macro-rx"></block></block>
  <block id="ef3abc0e33a9bba2f6844fc8bc6416c6" category="section-title">VMware環境向けのネットアップソリューション</block>
  <block id="7c56979dc4b16fa4dd69a289608a432d" category="paragraph">ハイブリッドクラウドモデルと「クラウドファースト」モデルのどちらで運用している場合でも、ネットアップは、クラウドモデルまたはハイブリッドクラウドモデルでワークロードを管理する最も一般的なユースケースに対応するためのさまざまなソリューションを提供しています。</block>
  <block id="14b428df74ec47d859b4b41c2a528f79" category="paragraph">各ハイパースケーラに対応するソリューションの詳細については、以下をご覧ください。</block>
  <block id="d7d90ddf3d849c680942374007293390" category="inline-link-macro">AWS / VMC向けソリューション</block>
  <block id="3efe4c396a8490c63650f3271e66c5ab" category="list-text"><block ref="3efe4c396a8490c63650f3271e66c5ab" category="inline-link-macro-rx"></block></block>
  <block id="902d95c8e7b033260ed791d46b121684" category="inline-link-macro">AzureとAVS向けのソリューション</block>
  <block id="a22d65ac7c37a480dfd6ea3cc467903d" category="list-text"><block ref="a22d65ac7c37a480dfd6ea3cc467903d" category="inline-link-macro-rx"></block></block>
  <block id="739e02805dc104b2c68811e1ea86f2e5" category="inline-link-macro">GCP/GCVE向けのソリューション</block>
  <block id="72792598cb09eae6cc992790a3677b2d" category="list-text"><block ref="72792598cb09eae6cc992790a3677b2d" category="inline-link-macro-rx"></block></block>
  <block id="4c27cd4763075e77fef142db7e967384" category="paragraph">ネットアップがAWSに提供するソリューションの詳細をご確認ください。</block>
  <block id="6619dc0097706121ef2efa1294da110b" category="example-title">AWSアカウントを登録</block>
  <block id="3f01bd52a695afbced7f2a43525ec966" category="example-title">My VMwareアカウントに登録します</block>
  <block id="f52c436d16c8976963f940ce7dfbd3b0" category="paragraph">AWSでは、ゲスト接続のネットアップストレージをネイティブのFSXサービス（FSX ONTAP ）またはCloud Volumes ONTAP （CVO）でサポートしています。</block>
  <block id="480bc55cb0b0c11472f598d17424afa2" category="section-title">FSX ONTAP の略</block>
  <block id="6df37dbe4c736ce113cfd677b79431d8" category="paragraph">Amazon FSX for NetApp ONTAP はフルマネージドサービスで、ネットアップの広く普及したONTAP ファイルシステムを基盤に、信頼性、拡張性、パフォーマンス、機能豊富なファイルストレージを提供します。FSX for ONTAP は、ネットアップファイルシステムの使い慣れた機能、パフォーマンス、機能、API操作に、AWSのフルマネージドサービスならではの即応性、拡張性、シンプルさを兼ね備えています。</block>
  <block id="f1afd8f76dc3ed417abd5daffa1d5a5f" category="paragraph">FSX for ONTAP は、機能豊富で高速で柔軟性に優れた共有ファイルストレージを提供します。このストレージは、AWSまたはオンプレミスで動作するLinux、Windows、macOSコンピューティングインスタンスから幅広くアクセスできます。FSX for ONTAP は、1ミリ秒未満のレイテンシでハイパフォーマンスのソリッドステートドライブ（SSD）ストレージを提供します。FSX for ONTAP を使用すると、SSDストレージに支払うデータの量がごくわずかであるのに、ワークロードでSSDレベルのパフォーマンスを実現できます。</block>
  <block id="dd29cd696f931f8230a783a5d65ab8c4" category="paragraph">ボタンをクリックするだけでファイルのスナップショット作成、複製、複製ができるため、FSX for ONTAP でのデータ管理が簡単になります。さらに、FSX for ONTAP は、データを低コストで柔軟なストレージに自動的に階層化し、容量のプロビジョニングや管理の必要性を軽減します。</block>
  <block id="697c147172074c2927997e2d7c472fc0" category="paragraph">また、FSX for ONTAP は、フルマネージドのバックアップとクロスリージョンディザスタリカバリのサポートにより、可用性と耐久性に優れたストレージを提供します。データの保護とセキュリティを容易にするため、ONTAP 対応FSXは、一般的な データ セキュリティ アプリケーションとウィルス対策アプリケーションをサポートしています。</block>
  <block id="461ab3a83d6c51e1cc25f42118f407bd" category="paragraph">詳細を表示します <block ref="f56028ac73883785be6a54941a0e4e64" category="inline-link-macro-rx"></block>。</block>
  <block id="3721bfebe60fa9888e0ea17bd294772d" category="paragraph">ネットアップと VMware のクラウドソリューションを使用すれば、多くのユースケースを AWS VMC に簡単に導入できます。ユースケースは、VMwareが定義したクラウド領域ごとに定義されます。</block>
  <block id="7c9a6204c3d04cd593127efe773bc82e" category="inline-link-macro">ネットアップの AWS VMC 向けソリューションをご覧ください</block>
  <block id="e9923439d335946afaff146da3d107ff" category="paragraph"><block ref="e9923439d335946afaff146da3d107ff" category="inline-link-macro-rx"></block></block>
  <block id="7c0dae765c7854235808e7e373346d06" category="paragraph">ネットアップがGCPに提供するソリューションの詳細をご確認ください。</block>
  <block id="370e7d693bc429e40244684cac20b0cf" category="list-text"><block ref="370e7d693bc429e40244684cac20b0cf" category="inline-link-macro-rx"></block></block>
  <block id="80d79003a84a32474624e54935709e67" category="paragraph">詳細を表示します <block ref="996ade122099ed78c4d5fea15d95f62c" category="inline-link-macro-rx"></block>。</block>
  <block id="80b43a415019d937ea5c38446043549a" category="paragraph">詳細を表示します <block ref="8e20eef09273fc2519292ca4ed666573" category="inline-link-macro-rx"></block>。</block>
  <block id="e67def868f3133574b28ffe738ad44c1" category="inline-link-macro">ネットアップの Google Cloud GCVE ソリューションをご覧ください</block>
  <block id="5e7670e99ae7db80618f16965d677af6" category="paragraph"><block ref="5e7670e99ae7db80618f16965d677af6" category="inline-link-macro-rx"></block></block>
  <block id="f0f52a47448cc3bc6237a09f83ad3e74" category="example-title">GCVE を導入して設定します</block>
  <block id="7973cdedf3e9a37ff146bc9fd29ff017" category="paragraph">GCPは、Cloud Volumes ONTAP （CVO）またはCloud Volumes Service （CVS）でゲスト接続のネットアップストレージをサポートします。</block>
  <block id="622f93ad4ff43627a425523c5e2538ad" category="section-title">Cloud Volumes Service （CVS）</block>
  <block id="b5a9beef520c0dd1f8e978800f35268e" category="paragraph">Cloud Volume サービス（CVS）は、高度なクラウドソリューションを提供するための包括的なデータサービスポートフォリオです。Cloud Volume サービスは、主要なクラウドプロバイダ向けに複数のファイルアクセスプロトコルをサポートしています（NFSとSMBのサポート）。</block>
  <block id="82c8cb0896f20daa9ddbb9d49332f9b6" category="paragraph">その他のメリットと機能としては、Snapshotによるデータ保護とリストア、オンプレミスとクラウドの間でデータをレプリケート、同期、移行するための特別な機能、専用フラッシュストレージシステムのレベルで一貫した高パフォーマンスが挙げられます。</block>
  <block id="443f43c84a8efb54c46feb5a61b1a9cc" category="paragraph">このドキュメントでは、VMwareのユースケースを使用してクラウドワークロードの参考資料について詳しく説明します。ユースケースは次のとおりです。</block>
  <block id="0198315ccfb9d5c56e9c865f01bee365" category="paragraph">ネットアップとVMwareのクラウドソリューションを使用すれば、さまざまなユースケースをハイパースケーラに簡単に導入できます。VMwareは、主なクラウドワークロードのユースケースを次のように定義しています。</block>
  <block id="e0525641cbca59e199eed50739c0c3b8" category="inline-link-macro">ネットアップのAWS / VMC向けソリューションをご確認ください</block>
  <block id="3a602723648efc3d9a864906b6ec2d9c" category="paragraph"><block ref="3a602723648efc3d9a864906b6ec2d9c" category="inline-link-macro-rx"></block></block>
  <block id="d18a9fea9b4ca38bf7f042e32420e14e" category="inline-link-macro">ネットアップのAzure / AVS向けソリューションをご覧ください</block>
  <block id="bd6708bcf0c060976324512475c1a212" category="paragraph"><block ref="bd6708bcf0c060976324512475c1a212" category="inline-link-macro-rx"></block></block>
  <block id="cac969404c87e9e141b320e34ee1ba4b" category="inline-link-macro">Google Cloud Platform（GCP）/ GCVE向けのネットアップソリューションをご覧ください</block>
  <block id="7f86100566a3de37a45dc2bd4ea422a0" category="paragraph"><block ref="7f86100566a3de37a45dc2bd4ea422a0" category="inline-link-macro-rx"></block></block>
  <block id="95adefbc130d345041c4487820a9ab16" category="summary">ネットアップのエンタープライズデータベースソリューションは、主要なエンタープライズデータベースに格納されたネットアップストレージの機能を実証する、戦略的およびテクノロジ的な機能のセットです。</block>
  <block id="e890f04973d00c3664a44f4cc586bb5d" category="doc">ネットアップのエンタープライズデータベースソリューション</block>
  <block id="809247403bb2b3e7178b69b038356678" category="inline-link-macro">vSphereのデータストアとプロトコルの機能：NFS</block>
  <block id="ff7854cc2ae62511b4a52320f31aa005" category="paragraph"><block ref="ff7854cc2ae62511b4a52320f31aa005" category="inline-link-macro-rx"></block></block>
  <block id="6309162dffb4a082a2a106613c448e9f" category="doc">ハイブリッドクラウド、仮想化、コンテナのビデオとデモ</block>
  <block id="ccf0b7773e492df3e851d36b689b69b1" category="paragraph">ハイブリッドクラウド、仮想化、およびコンテナソリューションの特定の機能を紹介するビデオとデモをご覧ください。</block>
  <block id="ab5efb952cd51767fdde3f548f7d3f18" category="paragraph">NetApp SnapCenter Plug-in for VMware vSphere の詳細については、を参照してください <block ref="39b49e6fd504a137658d6db31d129abd" category="inline-link-macro-rx"></block>。</block>
  <block id="0b59976821e81163a037c4ed7f21b209" category="paragraph"><block ref="0b59976821e81163a037c4ed7f21b209" category="inline-link-macro-rx"></block></block>
  <block id="4bff68299377013f00a500a01c7a2f19" category="list-text"><block ref="4bff68299377013f00a500a01c7a2f19" category="inline-link-macro-rx"></block></block>
  <block id="e5f4fe92e1832b16532011df56ee39a5" category="list-text"><block ref="c30f78a476776106411b5cd1ee097f4f" category="inline-link-macro-rx"></block></block>
  <block id="380fbb2dc2a4b42876553664c398fb3f" category="paragraph">ネットアップは、今日のビジネス上の課題に対処するソリューションを提供するにあたり、次の目標を達成したソリューションを提供しています。</block>
  <block id="008347e050bccf7e2812ae39dd816f41" category="list-text">検証済みの導入と設定手順を提供し、</block>
  <block id="4ef594072d2fdf53ad9ca6af7fe16569" category="list-text">簡単に利用できるソリューションを提供する</block>
  <block id="3f68e576fe6e3e328b5feeea03707572" category="list-text">予測可能な成果をもたらす解決策 環境を提供することは、お客様の企業全体で同じことを繰り返して容易に拡張することができます。</block>
  <block id="928a4532882b0eb0208abcae9b7fd6f0" category="paragraph">これらの目標を達成するためには、当社のソリューションを通じて提供されるインフラやアプリケーションの導入と構成を自動化によって簡易化することが何よりも重要です。ネットアップは、自動化を通じて解決策 消費を簡易化することに取り組んでいます。</block>
  <block id="d6d7e89b087a9e69ae7622847dc932e5" category="paragraph">ネットアップのソリューションには、Red Hat Ansible、H橋本、Microsoft PowerShellなどのオープンソースの自動化ツールが採用されており、アプリケーションの導入、クラウドのプロビジョニング、設定管理など、一般的なITタスクを自動化できます。ネットアップのソリューションは、一般に公開されている自動化アーティファクトを活用し、ネットアップが独自に開発した自動化機能を提供することで、解決策 の全体的な導入を簡易化します。</block>
  <block id="e532e5979d2ecc30b8177530683810e2" category="paragraph">自動化機能が利用可能な場合は、特定の自動化ツールを使用して解決策 や解決策 の手順を自動化するプロセスを、解決策 の資料で順を追って説明します。</block>
  <block id="aaac1ea7463ef799eaafc693b16b1f81" category="doc">NetApp解決策 自動化の導入</block>
  <block id="66bd3dbe1f46a5715420e201e457ff65" category="paragraph">ネットアップのソリューションで使用される一般的なタスクの多くに、NetApp解決策 の自動化機能でシンプルさと再現性が提供されます。</block>
  <block id="bf7d92f5ef43a7e0ab10c8d11d28ef6e" category="paragraph">解決策 の自動化を実行する前に、自動化の実行方法に合わせて環境を設定する必要があります。コマンドラインから、またはAWXやタワーなどのツールを使用して自動化を実行するオプションがあります。</block>
  <block id="dcdcb9b7436ca5ceca042e84e9c3ccf5" category="paragraph">以降のセクションでは、それぞれの環境について、環境を設定するために必要な手順について説明します。</block>
  <block id="60e34857d044a02ae86f645c2e97e40f" category="paragraph">&lt;stdin&gt;の未解決のディレクティブ：contains/rh-os-n _overview_stra_cc_install_manual.adoc[]</block>
  <block id="2b0a99e34b337bd6d8ed27dd9482c9e6" category="paragraph">&lt;stdin&gt;で未解決のディレクティブ：contains/rh-os-n _overview_stra_cc_install_Ansible .adoc[]</block>
  <block id="245ab73d4b9beb43ff76c082e9bc77db" category="open-title">AI /データ分析</block>
  <block id="901b32f6abd15fbb3d43fbd044218a64" category="open-title">エンタープライズアプリケーションとDB</block>
  <block id="71fbb346a6b64c94052f0e171d5d3eed" category="open-title">データ保護とデータ移行</block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">ネットアップのソリューションの多くの機能を紹介する一連のビデオとデモ</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">ネットアップのソリューション：ビデオとデモ</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">ネットアップのソリューションの特定の機能を紹介するビデオとデモの概要</block>
  <block id="ab440644113265a70e7e0bb7c44b2f63" category="paragraph">*ケーススタディ*</block>
  <block id="25aa061b5bc79f1f85182fd8ca1f3165" category="inline-link-macro">VMwareビデオコレクション</block>
  <block id="847fff0b97afdc8ceabb5c717634d413" category="list-text"><block ref="847fff0b97afdc8ceabb5c717634d413" category="inline-link-macro-rx"></block></block>
  <block id="55418abe87135e6107123ca2c087964c" category="sidebar">ハイパースケーラクラウドにおけるVMware向けネットアップソリューション</block>
  <block id="195b49c0610d30d327f5440759b7b642" category="sidebar">サポートされているソリューション</block>
  <block id="3ffbc70cc0bdd47bd7c4ed3cfa35be8a" category="sidebar">ゲスト接続ストレージとしてのFSX ONTAP</block>
  <block id="06e1970c26d133efed67d51224ceff1c" category="sidebar">セキュリティの概要- Google CloudでのNetApp Cloud Volumes Service （CVS</block>
  <block id="c252fd6dfe5fa6dc4ba36515512a8070" category="sidebar">ワークロード保護ソリューション</block>
  <block id="2579e0b6258e495e90e159e678bd55a8" category="sidebar">VMware Cloud on AWS：新しいリージョン、外付けストレージ、および購入オプション</block>
  <block id="f74a2791289e2f0411e5ffbd3e5a1d68" category="sidebar">NetApp Cloud Volumes Service を搭載したGoogle Cloud VMware Engine</block>
  <block id="30162ed78b6c10f731411f2fc440c24f" category="sidebar">Oracle の場合</block>
  <block id="51b19c4a2c13c8f8a69b0608959bdfca" category="sidebar">FlexPod データセンター上のOracle 19C RACデータベース</block>
  <block id="a71f76c3256e4c206a4841d8eb0fed35" category="sidebar">SQL サーバ</block>
  <block id="81d59bad51a910734812cab3d20641b0" category="sidebar">ハイブリッドクラウドデータベースソリューション</block>
  <block id="934553b3e6b7dd417ef37d2b3213dd00" category="sidebar">SAP SAP HANAの導入に最適です</block>
  <block id="1f036821b23def9a55e4116bdbd60c1b" category="sidebar">変更履歴</block>
  <block id="bb5dc731b06d417365e41cb2d0230213" category="sidebar">デモビデオ</block>
  <block id="f9cffb4fda587c713c06e50699299f0f" category="sidebar">解決策 ランディングページ</block>
  <block id="bf8e2974cd692b57a29e42874b662b52" category="sidebar">エンタープライズデータベース</block>
  <block id="84145683557fc8692113a2a97c3ec239" category="sidebar">VMwareを使用したネットアップのハイブリッドマルチクラウド</block>
  <block id="d4a3e435684aa9918c9dd0bada78d4fb" category="sidebar">VMCをAWS用に設定します</block>
  <block id="883512106f2cef4187ee5f6b5a94c6f8" category="sidebar">Azure向けAVSを設定する</block>
  <block id="a271625e92b27bca4202ba79dab27301" category="sidebar">GCVEをGCPに設定します</block>
  <block id="76862b378878c90a8052499ae898932f" category="sidebar">VMC用のゲスト接続ストレージ</block>
  <block id="5703f41cd5551fad387ed46631532278" category="sidebar">AVS対応のゲスト接続ストレージ</block>
  <block id="1f9511a418cf9a352bacd19d937a5237" category="sidebar">GCVE用のゲスト接続ストレージ</block>
  <block id="a0e8297bc18713002f47301829625ea1" category="sidebar">ネットアップがAWS / VMCに最適です</block>
  <block id="d530fb3a1e80511b2d7787728700d3fa" category="sidebar">NetApp for Azure / AVS</block>
  <block id="8d9d90a84ad6b34129f140e0b3e23326" category="sidebar">NetApp for GCP / GCVE</block>
  <block id="a3e92580de1a77cd25163bb63cd24a7d" category="inline-image-macro">リンク=<block ref="9b22e52230cfacf7992c01194e7a95d2" category="inline-link-rx"></block></block>
  <block id="f9da9dedda46425dea9fe2b0092e4b1a" category="paragraph"><block ref="f9da9dedda46425dea9fe2b0092e4b1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">このセクションでは、この解決策 で検証された3つのシナリオの概要を説明します。</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">テストと検証の計画</block>
  <block id="8e593eca45d74047c3d169456d36d74a" category="paragraph"><block ref="8e593eca45d74047c3d169456d36d74a" category="inline-link-macro-rx"></block></block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">この解決策 設計では、次の3つのシナリオが検証されました。</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">Kubernetes向けNetApp DataOpsツールキットを使用してオーケストレーションされたJupyterLabワークスペース内で、Protopia難読化を使用するかどうかに関係なく、推論タスクを実行します。</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">Kubernetesでの一括推論ジョブ。Protopia難読化を使用するかどうかにかかわらず、NetApp DataOps Toolkit for Kubernetesを使用してオーケストレーションされたデータボリュームを使用します。</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">Kubernetes向けNetApp DataOpsツールキットを使用してオーケストレーションされた、NVIDIA Triton Inference Serverインスタンスを使用した推論タスク。Triton推論APIを呼び出す前に、Protopia難読化を画像に適用して、ネットワーク経由で送信されるデータを難読化する必要がある一般的な要件をシミュレートしました。このワークフローは、信頼できるゾーン内でデータが収集され、推論のためにその信頼できるゾーンの外部に渡される必要があるユースケースに該当します。Protopia難読化を使用しないと'機密データが信頼ゾーンから離れることなく'このタイプのワークフローを実装できません</block>
  <block id="9a1eb36c3c2949c4b9618b70f9947341" category="paragraph"><block ref="9a1eb36c3c2949c4b9618b70f9947341" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">この検証では、rawイメージのセットを使用して、イメージ検出のユースケースに対して推論を実行しました。次に、同じイメージセットに対して、推論の前にProtopia難読化が追加された同じ推論タスクを実行しました。このタスクでは、Protopia難読化コンポーネントに異なる値のalphaを使用しています。</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">推論の精度の比較</block>
  <block id="c06030c36071611ee2f3a9a21205eaf8" category="paragraph"><block ref="c06030c36071611ee2f3a9a21205eaf8" category="inline-link-macro-rx"></block></block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">この検証では、rawイメージのセットを使用して、イメージ検出のユースケースに対して推論を実行しました。次に、同じイメージセットに対して、推論の前にProtopia難読化が追加された同じ推論タスクを実行しました。このタスクでは、Protopia難読化コンポーネントに異なる値のalphaを使用しています。Protopia難読化のコンテキストでは、アルファ値は適用される難読化の量を表し、アルファ値が大きいほど難読化のレベルが高くなります。次に、これらの異なる実行間の推論の精度を比較しました。</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">以下の2つの表に、ネットアップのユースケースとその概要を示します。</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopiaは、お客様と直接協力して、特定のユースケースに適したアルファ値を決定します。</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">フェースボックス(PyTorch)-</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">FDDBデータセット</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">Protopia難読化</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">アルファ</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">精度</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0.9337148153739079</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0.05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0.9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0.1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0.9024301009661478</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0.9081836283186224</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0.9073066107482036</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0.8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0.8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0.8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0.9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0.8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0.95</block>
  <block id="0f39c006b0d74178bc826c1d567a79dc" category="inline-link-macro">次の例は、難読化の速度です。</block>
  <block id="ca9c4b25b025c5564f5ffb65a712a47c" category="paragraph"><block ref="ca9c4b25b025c5564f5ffb65a712a47c" category="inline-link-macro-rx"></block></block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">このセクションでは、解決策 設計検証環境について説明します。</block>
  <block id="172ddae93475d6ccf42e145bb593da46" category="inline-link-macro">前：テストと検証の計画</block>
  <block id="9ea432ca0ec547aa219093f8f5f560cc" category="paragraph"><block ref="9ea432ca0ec547aa219093f8f5f560cc" category="inline-link-macro-rx"></block></block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">次の表に、解決策 設計検証環境の概要を示します。</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.1.6</block>
  <block id="b0f69588db488e358ab3c85429ab6b3a" category="cell">NetApp Astra Trident CSIドライバ</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">Kubernetes向けNetApp DataOpsツールキット</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="cell">NVIDIA Triton 推論サーバ</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3.</block>
  <block id="53e01217bc7db361f46a1f8e0e601655" category="paragraph"><block ref="53e01217bc7db361f46a1f8e0e601655" category="inline-link-macro-rx"></block></block>
  <block id="fcd8d375e90bbb5d8febe3b3eac09c2b" category="doc">追加情報 、確認応答、およびバージョン履歴の参照先</block>
  <block id="86a4acc956f71e307a08f732dd442d3f" category="paragraph"><block ref="86a4acc956f71e307a08f732dd442d3f" category="inline-link-macro-rx"></block></block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">NetApp ONTAP データ管理ソフトウェア—ONTAP 情報ライブラリ</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="2cd8f6bd0ec1bbc37315b8bc134e16c5" category="list-text">コンテナ向けNetApp Persistent Storage—NetApp Astra Trident</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia AI—Confidential Inference（機密情報推論）</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">NVIDIA Triton Inference Serverのドキュメント</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">PyTorchのフェイスボックス</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">ネットアップ、プリンシパルプロダクトマネージャー、Mark Cates氏</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">ネットアップ、テクニカルマーケティングエンジニア、Sufian Ahmad氏</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">最高技術責任者兼Protopia AI教授、Hadi Esmaeilzadeh氏</block>
  <block id="0844bd2427e754de1d07ca91d15284a5" category="cell">ドキュメントバージョン履歴</block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">データは保管中、転送中、コンピューティング中の3つの状態に存在します。AI推論サービスの重要な部分は、プロセス全体における脅威からのデータの保護である必要があります。推論の実行中にデータを保護することが重要です。これは、外部のお客様と推論サービスを提供するビジネスの両方の個人情報がこのプロセスによって公開される可能性があるためです。</block>
  <block id="fd8d4cefd4e31d8ce81b0b6c4cf90ae2" category="inline-link-macro">前のバージョン：難読化の速度。</block>
  <block id="12deb7181b69808aaa08117bd40978a3" category="paragraph"><block ref="12deb7181b69808aaa08117bd40978a3" category="inline-link-macro-rx"></block></block>
  <block id="4282c9ab06938351529fcc9258e39d5a" category="paragraph">データは、保管中、転送中、コンピューティング中の3つの状態に存在します。AI推論サービスの重要な部分は、プロセス全体における脅威からのデータの保護である必要があります。推論の実行中にデータを保護することが重要です。これは、外部のお客様と推論サービスを提供するビジネスの両方の個人情報がこのプロセスによって公開される可能性があるためです。Protopia AIは、今日の市場における機密性の高いAI推論を行うための、悪意のないソフトウェアのみの解決策 です。Protopiaを使用すると、AIには、AI / MLタスクを実行するために必要なデータレコードの変換された情報のみが渡されます。これ以外にも、データレコードには何も入力されません。この確率的変化はマスキングの形式ではなく、キュレーションされたノイズを使用してデータの表現を数学的に変更することに基づいています。</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">ONTAP 機能を備えたネットアップのストレージシステムは、ローカルSSDストレージと同等以上のパフォーマンスを提供します。また、NetApp DataOpsツールキットと組み合わせることで、データサイエンティスト、データエンジニア、AI / ML開発者、ビジネスまたはエンタープライズITの意思決定者に次のようなメリットをもたらします。</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">ディザスタリカバリ、ビジネス継続性、規制要件に対応するエンタープライズクラスのデータ保護とデータガバナンス。</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">データ管理操作の簡単な呼び出し。データサイエンティストのワークスペースのSnapshotコピーを迅速に作成し、Jupyterノートブック内のNetApp DataOpsツールキットからバックアップとトレーサビリティを実現します。</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">ネットアップとProtopia解決策 は、エンタープライズクラスのAI推論環境に最適な、柔軟性に優れたスケールアウトアーキテクチャを提供します。データ保護を実現し、オンプレミス環境とハイブリッドクラウド環境の両方で、AI推論の機密要件を満たすことができる機密情報のプライバシーを提供します。</block>
  <block id="6073423c521e84b849e3b84fa1cc380c" category="inline-link-macro">Next：追加情報 、確認応答、およびバージョン履歴の参照先。</block>
  <block id="9eebc409a853e8c97008be61e4a0b83a" category="paragraph"><block ref="9eebc409a853e8c97008be61e4a0b83a" category="inline-link-macro-rx"></block></block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">このセクションでは、検証を完了するために必要なタスクについて説明します。</block>
  <block id="c17e6835560e56c00184a993e1b0bfdb" category="paragraph"><block ref="c17e6835560e56c00184a993e1b0bfdb" category="inline-link-macro-rx"></block></block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">このセクションで説明するタスクを実行するには、次のツールをインストールして設定したLinuxまたはmacOSホストにアクセスできる必要があります。</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl（既存のKubernetesクラスタへのアクセスを設定）</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">インストールと設定の手順については、を参照してください<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block>。</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">インストール手順が記載されています<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block>。</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">シナリオ1–JupyterLabにおけるオンデマンド推論</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">AI / ML推論ワークロード用のKubernetesネームスペースを作成します。</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">NetApp DataOpsツールキットを使用して、推論を実行するデータを格納する永続的ボリュームをプロビジョニングします。</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">NetApp DataOpsツールキットを使用して、JupyterLabの新しいワークスペースを作成します。前の手順で作成した永続ボリュームを'--mount-pvcオプションを使用してマウントします必要に応じて'--nvidia -GPU'オプションを使用して'NVIDIA GPUをワークスペースに割り当てます</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">次の例では'永続ボリュームinerial-data'が'/home/jovyan/data'のJupyterLabワークスペースコンテナにマウントされています公式のProject Jupyterコンテナイメージを使用する場合、「/home/jovyan」はJupyterLab Webインターフェイス内の最上位ディレクトリとして表示されます。</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">「create jupyterlab」コマンドの出力で指定したURLを使用して、JupyterLabワークスペースにアクセスします。データディレクトリは、ワークスペースにマウントされた永続ボリュームを表します。</block>
  <block id="1f069f45990199d6afbe5926fb26f127" category="paragraph"><block ref="1f069f45990199d6afbe5926fb26f127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">「data」ディレクトリを開き、推論を実行するファイルをアップロードします。ファイルがデータディレクトリにアップロードされると、ワークスペースにマウントされた永続ボリュームに自動的に保存されます。ファイルをアップロードするには、次の図に示すように、[ファイルのアップロード]アイコンをクリックします。</block>
  <block id="f6d07c27f458648455903cf09530655f" category="paragraph"><block ref="f6d07c27f458648455903cf09530655f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">トップレベルのディレクトリに戻り、新しいノートブックを作成します。</block>
  <block id="59e51e40d73317a796f7d0b25d8fa003" category="paragraph"><block ref="59e51e40d73317a796f7d0b25d8fa003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">ノートブックに推論コードを追加します。次の例は、イメージ検出のユースケースの推論コードを示しています。</block>
  <block id="901ae9d6148669912b400c6d2647bfbf" category="paragraph"><block ref="901ae9d6148669912b400c6d2647bfbf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f10850488ed018cdad31f8ac9e8bab" category="paragraph"><block ref="45f10850488ed018cdad31f8ac9e8bab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">推測コードにProtopia難読化を追加します。Protopiaは、お客様と直接協力してユースケースに固有のドキュメントを提供しますが、本書では取り上げません。次の例は、Protopia難読化を追加した場合のイメージ検出の推論コードを示しています。</block>
  <block id="5a10342224477df560528e700989b536" category="paragraph"><block ref="5a10342224477df560528e700989b536" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20f77c05fa583bdc62074b26870e07e7" category="paragraph"><block ref="20f77c05fa583bdc62074b26870e07e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">シナリオ2–Kubernetesでのバッチ推論</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">新しい永続ボリュームに、推論を実行するデータを入力します。</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">NetApp DataOpsツールキットS3 Data Moverの機能</block>
  <block id="2933df0ebac7b47c349bd6bd7099fb90" category="paragraph">PVCにデータをロードする方法はいくつかあります。データがNetApp StorageGRID やAmazon S3などのS3互換オブジェクトストレージプラットフォームに現在格納されている場合は、を使用できます<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block>。また、JupyterLabワークスペースを作成し、JupyterLab Webインターフェイスを使用してファイルをアップロードする方法も簡単です。手順3～5を参照してください<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>」</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">バッチ推論タスク用のKubernetesジョブを作成します。次の例は、イメージ検出のユースケースに対するバッチ推論ジョブを示しています。このジョブは、一連のイメージ内の各イメージに対して推論を実行し、stdoutに推論の精度の指標を書き込みます。</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">推論ジョブが正常に完了したことを確認します。</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">推測ジョブにProtopia難読化を追加します。Protopiaの難読化を追加する手順は、このテクニカルレポートでは説明していませんが、Protopiaから直接追加できます。次の例は、アルファ値0.8を使用してProtopia難読化を行った場合のフェース検出のバッチ推論ジョブを示しています。このジョブは、一連のイメージ内の各イメージに対して推論を実行する前にProtopia難読化を適用し、stdoutに推論の精度指標を書き込みます。</block>
  <block id="7a1adb5cebbf78f3eddc08a64751149e" category="inline-link-macro">「推論の精度比較」</block>
  <block id="da2c9dc305dff324654e67571156b295" category="paragraph">このステップは、アルファ値0.05、0.1、0.2、0.4、0.6について繰り返しました。 0.8、0.9、および0.95。結果はに表示されます <block ref="af158494e4986d64d04037857fed2d1c" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">シナリオ3–NVIDIA Triton Inference Server</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">NetApp DataOpsツールキットを使用して、NVIDIA Triton Inference Serverのモデルリポジトリとして使用する永続的ボリュームをプロビジョニングします。</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">の形式で入力し</block>
  <block id="97be18cb741b4fd763ebe22e034705fa" category="list-text">の新しい永続ボリュームにモデルを保存します<block ref="bfcdc35d352d3deff6efdd3b8b2ac7ac" category="inline-link-rx"></block> これはNVIDIA Triton Inference Serverによって認識されます。</block>
  <block id="6c21d87641bab7a6c49bc29065185e4f" category="paragraph">PVCにデータをロードする方法はいくつかあります。簡単な方法としては、「」の手順3～5で説明しているように、JupyterLabワークスペースを作成し、JupyterLab Webインターフェイスを使用してファイルをアップロードする方法があります<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>。」</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">NetApp DataOpsツールキットを使用して、新しいNVIDIA Triton Inference Serverインスタンスを導入します。</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">推論タスクを実行するには、TritonクライアントSDKを使用します。次のPythonコードの抜粋では、Triton PythonクライアントSDKを使用して、フェース検出のユースケースに対する推論タスクを実行しています。この例では、推論のためにTriton APIを呼び出し、イメージを渡します。次に、Triton Inference Serverが要求を受信し、モデルを呼び出して、API結果の一部として推論出力を返します。</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">推測コードにProtopia難読化を追加します。Protopia難読化を追加する手順はProtopiaから直接確認できますが、この手順については本テクニカルレポートでは説明していません。次の例は、前述の手順5と同じPythonコードを示していますが、Protopia難読化が追加されています。</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">Triton APIに渡される前に、Protopia難読化が画像に適用されることに注意してください。このため、難読化されていない画像はローカルマシンから離れることはありません。難読化されたイメージだけがネットワークを通過します。このワークフローは、信頼できるゾーン内でデータが収集され、推論のためにその信頼できるゾーンの外部に渡す必要があるユースケースに該当します。Protopiaの難読化がなければ、機密データが信頼できるゾーンから離れることなく、このタイプのワークフローを実装することはできません。</block>
  <block id="38bb883cb543c747fc0f113099f5072d" category="inline-link-macro">次の例は、推論の精度の比較です。</block>
  <block id="1f2c820475fbde991c6219936a645aea" category="paragraph"><block ref="1f2c820475fbde991c6219936a645aea" category="inline-link-macro-rx"></block></block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">デジタル画像処理には多くの利点があり、多くの組織が視覚表現に関連するデータを最大限に活用できるようになっています。このネットアップとProtopia解決策 は、ML / DLのライフサイクル全体にわたってAI / MLデータを保護し、民営化するための、独自のAI推論設計を提供しています。お客様は機密データの所有権を維持し、プライバシーに関する懸念を解消して、拡張性と効率性を高めるためにパブリッククラウドまたはハイブリッドクラウドの導入モデルを使用できます。また、エッジでAI推論を導入することもできます。</block>
  <block id="b7aff368ab91b524750e403085893177" category="paragraph"><block ref="b7aff368ab91b524750e403085893177" category="inline-link-macro-rx"></block></block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">環境インテリジェンス</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">業界は、環境上の危険がある領域で地理空間分析を活用する方法が数多くあります。政府や公共事業部は、公衆衛生や天候に関する実用的な洞察を得ることができ、パンデミックや野生火災などの自然災害時の国民へのアドバイスを向上させることができます。たとえば、空港や病院などの公共スペースで新型コロナウイルス感染症の患者を特定する際に、該当する個人のプライバシーを侵害することなく、必要な安全対策を講じるために各当局および近隣の公衆に警告を出すことができます。</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">エッジデバイスのウェアラブル</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">軍事演習や戦場では、エッジでのAI推論をウェアラブルデバイスとして使用することで、兵士の健康状態を追跡し、運転者の行動を監視し、軍車に接近する際の安全および関連するリスクについて当局に警告しながら、兵士のプライバシーを守り、保護することができます。軍事の未来は、Internet of Battlefield Things（IOBT）とInternet of Military Things（IANMT）でハイテク化を進めています。この製品は、兵士が敵を特定し、高速エッジコンピューティングを使用して戦闘でより良いパフォーマンスを発揮するのに役立ちます。ドローンやウェアラブル・ギアなどのエッジデバイスから収集した視覚的なデータを保護し、保護することは、ハッカーや敵をベイに維持するために不可欠です。</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">非燃焼型避難作業</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">非戦闘員避難行動（Neos）は、米国市民および国民、DoD民間人、および指定された人（HN）および第3国国民（TCN）の避難を支援するために、国防総省によって実施されます。所定の管理制御では、主に手動による退避対象者スクリーニングプロセスが使用されます。ただし、高度に自動化されたAI / MLツールとAI / MLビデオ難読化テクノロジを組み合わせることで、避難先の識別、退避対象の追跡、脅威スクリーニングの精度、セキュリティ、速度を向上させることができます。</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">AI / ML分析のクラウド移行</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">データ保護</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link">TR-4886『エッジでのAI推論』</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">インテリジェンスとプライバシー</block>
  <block id="215649425fa669fb4825e25a6ace492e" category="paragraph">他の業界のエッジコンピューティングとAI推論のその他のユースケースについては、を参照してください<block ref="922342ea98ca297422c6dc441f974a04" category="inline-link-rx"></block> NetApp AIブログ、<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block>。</block>
  <block id="5318c453b0f0b1d5351026eca9f9899d" category="paragraph"><block ref="5318c453b0f0b1d5351026eca9f9899d" category="inline-link-macro-rx"></block></block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">このセクションでは、この解決策 を完了するために必要なさまざまな技術コンポーネントの概要を説明します。</block>
  <block id="2c6beb1e15771dbe426409f9b5d4aaf9" category="inline-link-macro">前のページ：解決策 Areas</block>
  <block id="8a26bc3756fc01f4b929845a326e9b9d" category="paragraph"><block ref="8a26bc3756fc01f4b929845a326e9b9d" category="inline-link-macro-rx"></block></block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">プロトピア</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AIは、今日の市場における機密性の高い推論のための、目立たないソフトウェア型解決策 を提供します。Protopia解決策 は、機密情報の漏洩を最小限に抑えることで、推論サービスに対する比類のない保護機能を提供します。AIには、データレコード内の情報のみが提供されます。この情報は、実際にはタスクを実行するために不可欠であり、それ以上何も必要ありません。ほとんどの推論タスクでは、すべてのデータレコードに存在するすべての情報が使用されるわけではありません。画像、音声、ビデオ、構造化された表形式データのどれをAIが消費しているかにかかわらず、Protopiaは推論サービスが必要としているものだけを提供します。特許取得済みのコアテクノロジーは、数学的にキュレーションされたノイズを使用してデータを変革し、特定のMLサービスでは必要のない情報を蓄積します。この解決策 はデータをマスクするのではなく、キュレーションされたランダムなノイズを使用してデータ表現を変更します。</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">Protopia解決策 は、モデルの機能に関して、入力フィーチャースペースの関連情報を保持する勾配ベースの摂動最大化方法としてリプレゼンテーションを変更する問題を計算します。このディスカバリプロセスは、MLモデルのトレーニング終了時に微調整パスとして実行されます。このパスによって確率分布のセットが自動的に生成されると、オーバーヘッドが低いデータ変換によって、これらの分布から生成されたノイズサンプルがデータに適用され、これが難読化されてから推論モデルに渡されます。</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">DGX A100システムとネットアップのクラウド対応ストレージシステムを基盤とするNetApp ONTAP AIリファレンスアーキテクチャは、ネットアップとNVIDIAによって開発、検証されました。IT 組織には、次のようなメリットをもたらすアーキテクチャが提供されます。</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AIは、DGX A100システムとNetApp AFF A800ストレージシステムを最先端のネットワークと緊密に統合します。ONTAP AIは、設計の複雑さと推測に頼らず、AI導入を簡易化します。小規模構成から始めて、システムを停止することなく拡張でき、エッジからコア、クラウドまで、データをインテリジェントに管理できます。</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">次の図は、DGX A100システムを使用したONTAP AIソリューションファミリーのいくつかのバリエーションを示しています。AFF A800システムのパフォーマンスは、最大8台のDGX A100システムで検証されます。ONTAP クラスタにストレージコントローラペアを追加することで、アーキテクチャを複数のラックに拡張して、パフォーマンスがリニアに向上したDGX A100システムとペタバイト規模のストレージ容量をサポートできます。このアプローチにより、使用されるDLモデルのサイズと必要なパフォーマンス指標に基づいて、コンピューティングとストレージの比率を個別に変更できる柔軟性が得られます。</block>
  <block id="316a5094893ef1b058844a75c53aaf04" category="paragraph"><block ref="316a5094893ef1b058844a75c53aaf04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153：NVIDIA DGX A100システムとMellanox Spectrumイーサネットスイッチを搭載したNetApp ONTAP AI</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">追加情報 About ONTAP AIについては、を参照してください<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ネットアップが提供する最新世代のストレージ管理ソフトウェアONTAP 9.11を使用すれば、インフラを刷新し、クラウド対応データセンターに移行できます。ONTAP は、業界をリードするデータ管理機能を活用して、データの格納場所に関係なく、単一のツールセットでデータの管理と保護を実現します。エッジ、コア、クラウドなど、必要な場所に自由にデータを移動することもできます。ONTAP 9.11には、データ管理を簡易化し、重要なデータを高速化、保護し、ハイブリッドクラウドアーキテクチャ全体で次世代インフラ機能を実現するためのさまざまな機能が搭載されています。</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOpsツールキットはPythonライブラリで、開発者、データサイエンティスト、DevOpsエンジニア、データエンジニアは、新しいデータボリュームやJupyterLabワークスペースのほぼ瞬時のプロビジョニング、データボリュームやJupyterLabワークスペースのほぼ瞬時のクローニングなど、さまざまなデータ管理タスクを簡単に実行できます。 トレーサビリティやベースライン化のために、データボリュームまたはJupyterLabワークスペースのスナップショットをほぼ瞬時に作成できます。このPythonライブラリは、任意のPythonプログラムまたはJupyterノートブックに読み込むことができるコマンドラインユーティリティまたは関数のライブラリとして機能します。</block>
  <block id="dea84e2e635ce73ddc479a38d5616c98" category="paragraph">NVIDIA Triton Inference Serverは、オープンソースの推論サービスソフトウェアです。モデルの導入と実行を標準化し、高速で拡張性に優れたAIを本番環境に提供できます。Triton Inference Serverは、GPUベースまたはCPUベースのインフラ上のあらゆるフレームワークからトレーニング済みAIモデルを導入、実行、拡張できるため、AI推論が合理化されます。Triton Inference Serverは、TensorFlow、NVIDIA TensorRT、PyTorch、MXNetなどの主要なフレームワークをすべてサポートします。 OpenVNOなど。TritonはKubernetesと統合し、オーケストレーションと拡張を実現します。主要なパブリッククラウドのAIプラットフォームとKubernetesプラットフォームで使用できます。また、多くのMLOpsソフトウェアソリューションと統合されています。</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="section-title">PyTorch</block>
  <block id="04f7f16178ab3e9bddfd0837b64d21a2" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block> はオープンソースのMLフレームワークです。GPUとCPUを使用するディープラーニング用に最適化されたテンソルライブラリです。PyTorchパッケージには多次元テンソル用のデータ構造が含まれており、他の有用なユーティリティ間でテンソルを効率的にシリアル化するための多くのユーティリティを提供します。また、コンピューティング機能を備えたNVIDIA GPUでテンソル計算を実行できるCUDA対応製品もあります。この検証では、OpenCV-Python (CV2)ライブラリを使用してモデルを検証しながら、Pythonで最も直感的なコンピュータビジョンの概念を活用しています。</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">データ管理は、AIアプリケーションの運用やAI / MLデータセットのトレーニングに適切なリソースを使用できるように、エンタープライズIT運用とデータサイエンティストにとって非常に重要です。以下に記載するネットアップテクノロジに関する追加情報 は、この検証の対象外ですが、導入環境によっては関連性がある場合もあります。</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">ONTAP データ管理ソフトウェアには、運用を合理化および簡易化し、総運用コストを削減するための次の機能が含まれています。</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">インラインデータコンパクション、強化された重複排除：データコンパクションはストレージブロック内の無駄なスペースを削減し、重複排除は実効容量を大幅に増やします。この環境データはローカルに格納され、データはクラウドに階層化されます。</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">最小、最大、アダプティブのQuality of Service（AQoS）。きめ細かいサービス品質（QoS）管理機能により、高度に共有された環境で重要なアプリケーションのパフォーマンスレベルを維持できます。</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598：『FabricPool best bests』</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetApp FabricPool の略。Amazon Web Services（AWS）、Azure、NetApp StorageGRID ストレージ解決策 など、パブリッククラウドとプライベートクラウドのストレージオプションへコールドデータを自動的に階層化します。FabricPool の詳細については、を参照してください<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block>。</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP は、卓越したパフォーマンスとデータ保護を実現し、以下の方法でこれらの機能を拡張します。</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">パフォーマンスとレイテンシの低下：ONTAP は、可能なかぎり最小のレイテンシで最高のスループットを提供します。</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">データ保護ONTAP には、組み込みのデータ保護機能が用意されており、すべてのプラットフォームを共通の管理機能で管理できます。</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">NetApp Volume Encryption（NVE）：ONTAP は、オンボードと外部キー管理の両方をサポートし、ボリュームレベルでのネイティブな暗号化を実現します。</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">マルチテナンシーおよび多要素認証ONTAP を使用すると、最高レベルのセキュリティでインフラリソースを共有できます。</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP は、次の機能を備えており、要件が厳しく、絶えず変化するビジネスニーズに対応できます。</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">シームレスな拡張とノンストップオペレーションONTAP を使用すると、既存のコントローラとスケールアウトクラスタに無停止で容量を追加できます。NVMe や 32Gb FC などの最新テクノロジへのアップグレードも、コストのかかるデータ移行やシステム停止を行わずに実行できます。</block>
  <block id="74c384c0caae9c39b0e414cecc8c66ea" category="list-text">クラウドへの接続：ONTAP は、すべてのパブリッククラウドでSoftware-Defined Storage（ONTAP Select ）とクラウドネイティブインスタンス（NetApp Cloud Volumes Service ）のオプションを選択できる、マルチクラウドに対応した最もクラウド対応のストレージ管理ソフトウェアです。</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">新しいアプリケーションとの統合：ONTAP は、既存のエンタープライズアプリケーションをサポートするインフラを使用して、自律走行車、スマートシティ、インダストリー4.0などの次世代プラットフォームやアプリケーション向けにエンタープライズクラスのデータサービスを提供します。</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">ネットアップアストラコントロール</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Astra 制御サービス</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">ネットアップの Astra 製品ファミリーは、オンプレミスとパブリッククラウドの Kubernetes アプリケーション向けに、ネットアップのストレージテクノロジとデータ管理テクノロジを基盤とするストレージサービスとアプリケーション対応データ管理サービスを提供します。Kubernetesアプリケーションのバックアップ、データの別のクラスタへの移行、作業用アプリケーションのクローンの瞬時作成を簡単に実行できます。パブリッククラウドで実行されているKubernetesアプリケーションを管理する必要がある場合は、のドキュメントを参照してください<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block>。Astra Control Service は、 Google Kubernetes Engine （ GKE ）および Azure Kubernetes Service （ AKS ）で Kubernetes クラスタのアプリケーション対応データ管理を提供する、ネットアップが管理するサービスです。</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">アストラ<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> ネットアップは、 Docker と Kubernetes 向けのオープンソースの動的ストレージオーケストレーションツールであり、永続的ストレージの作成、管理、使用を簡易化します。KubernetesネイティブアプリケーションであるTridentは、Kubernetesクラスタ内で直接実行されます。Trident を使用すると、 DL コンテナイメージをネットアップストレージにシームレスに導入し、エンタープライズクラスの AI コンテナ環境を実現できます。Kubernetesユーザ（ML開発者、データサイエンティストなど）は、オーケストレーションとクローニングを作成、管理、自動化し、ネットアップテクノロジを基盤とする高度なデータ管理機能を活用できます。</block>
  <block id="434636f83b39076d7f319707cddbd844" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> 迅速かつセキュアなデータ同期を実現するネットアップのサービスです。オンプレミスの NFS または SMB ファイル共有、 NetApp StorageGRID 、 NetApp ONTAP S3 、 NetApp Cloud Volumes Service 、 Azure NetApp Files 、 Amazon Simple Storage Service （ Amazon S3 ）、 Amazon Elastic File System （ Amazon EFS ）、 Azure Blob 、 Google Cloud Storage 間でファイルを転送する必要があるかどうか または、 IBM Cloud Object Storage を使用すると、 Cloud Sync で必要な場所に迅速かつ安全にファイルを移動できます。転送されたデータは、ソースとターゲットの両方で完全に使用できます。Cloud Sync は、事前に定義されたスケジュールに基づいてデータを継続的に同期し、差分のみを移動するため、データレプリケーションにかかる時間とコストを最小限に抑えることができます。Cloud Sync は、セットアップや使用がきわめて簡単なソフトウェアサービス（SaaS）ツールです。Cloud Sync によって実行されるデータ転送は、データブローカーによって実行されます。Cloud Sync データブローカーは、 AWS 、 Azure 、 Google Cloud Platform 、オンプレミスに導入できます。</block>
  <block id="66b5cd4a3c9ce410ceb216447176b92c" category="section-title">ネットアップのクラウドデータの意味</block>
  <block id="37b37a18c5e4fe4e0985503adba1ee06" category="paragraph">強力なAIアルゴリズム、 <block ref="41205542004b3a03df744ae454bd65c9" category="inline-link-rx"></block> データ資産全体の管理とデータガバナンスを自動化します。コスト削減を容易に特定し、コンプライアンスやプライバシーに関する懸念を特定し、最適化の機会を見つけることができます。クラウドデータセンスダッシュボードを使用すると、重複データを特定して冗長性を排除し、個人データ、個人データ、機密データをマッピングし、機密データや異常に関するアラートを有効にすることができます。</block>
  <block id="b391770315ecce50e9dae3b6506d3513" category="inline-link-macro">次のステップ：テストと検証の計画</block>
  <block id="d063081c0d1c6aff0b7c690b473d4045" category="paragraph"><block ref="d063081c0d1c6aff0b7c690b473d4045" category="inline-link-macro-rx"></block></block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">この検証では、Protopia難読化を1920 x 1080ピクセル画像に5回適用し、難読化手順が完了するまでに毎回かかった時間を測定しました。</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">難読化の速度</block>
  <block id="237d31dab91fe077925e5102e132072f" category="inline-link-macro">前の例：推論の精度の比較。</block>
  <block id="6e3fd8b18c15e04e41fb57acfcafc5aa" category="paragraph"><block ref="6e3fd8b18c15e04e41fb57acfcafc5aa" category="inline-link-macro-rx"></block></block>
  <block id="d6edf1cfcac22abc6c577706f85eb816" category="paragraph">この検証では、Protopia難読化を1920 x 1080ピクセル画像に5回適用し、難読化手順が完了するまでに毎回かかった時間を測定しました。単一のNVIDIA V100 GPUで動作するPyTorchを使用して難読化を適用し、実行間のGPUキャッシュをクリアしました。難読化手順では、5回の実行でそれぞれ5.47ミリ秒、5.27ミリ秒、4.54ミリ秒、5.24ミリ秒、および4.84ミリ秒が実行されました。平均速度は5.072msでした。</block>
  <block id="eee25724989c730f34a19e19a1db23b2" category="paragraph"><block ref="eee25724989c730f34a19e19a1db23b2" category="inline-link-macro-rx"></block></block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">本ドキュメントでは、プライバシーの保護と責任あるAI解決策 の導入に関連する画像難読化機能を使用した、または使用しない、3つの異なるシナリオにおける検証済み設計解決策 について説明します。</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan氏、Michael Oglesby氏、NetApp Byung Hoon Ahn氏、Jennifer Cwagenberg氏、Protopia氏</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">画像の撮影や画像処理の出現とのコミュニケーションには、視覚的な解釈が不可欠です。デジタル画像処理における人工知能（AI）は、がんやその他の疾患識別のための医療分野などの新たなビジネスチャンスをもたらします。また、地球空間での視覚分析による環境ハザード調査、パターン認識、犯罪と闘うためのビデオ処理などにも活用できます。しかし、この機会には特別な責任も伴います。</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">AIを導入する意思決定が増えるほど、データのプライバシー、セキュリティ、法律、倫理、規制に関する問題に関連するリスクを受け入れることができます。責任あるAIは、大企業のAIに欠かせない信頼とガバナンスを企業や政府機関が構築できるようにするための実践を可能にします。本ドキュメントでは、ネットアップが3つの異なるシナリオで検証したAI推論解決策 について説明します。この検証では、Protopiaデータ難読化ソフトウェアとネットアップのデータ管理テクノロジを併用して、機密データをプライベート化し、リスクと倫理的な懸念を軽減します。</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">毎日何百万もの画像が生成され、消費者とビジネスエンティティの両方がさまざまなデジタルデバイスを使用します。その結果、データとコンピューティングのワークロードが急増し、企業はクラウドコンピューティングプラットフォームを利用して、拡張性と効率性を高めることになります。一方、画像データに含まれる機密情報に関するプライバシーの懸念は、パブリッククラウドへの転送によって生じます。画像処理AIシステムの導入における主な障壁は、セキュリティとプライバシーの欠如です。</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">イレイジャーコーディングの権利</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">プライバシー法</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">また、もあります<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> GDPRでは、組織がすべての個人データを消去するように要求する権利が個人に与えられます。また、もあります<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block>は、公正な情報慣行のコードを確立します。写真などのデジタル画像は、GDPRに基づく個人データを構成し、データの収集、処理、消去の方法を規定します。これを怠るとGDPRに準拠できず、組織に深刻な損害を与える可能性があるコンプライアンス違反に対する多額の罰金が科せられる可能性があります。プライバシーに関する原則は、機械学習（ML）モデルとディープラーニング（DL）モデルの予測において公平性を確保し、プライバシーや規制へのコンプライアンス違反に伴うリスクを軽減する、責任あるAIを実装するためのバックボーンとなっています。</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">このドキュメントでは、プライバシーの保護と責任あるAI解決策 の導入に関連する画像難読化機能を使用した、または使用しない、3つの異なるシナリオにおける検証済み設計解決策 について説明します。</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*シナリオ1.* Jupyterノートブック内でのオンデマンド推論。</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*シナリオ2.* Kubernetesでのバッチ推論。</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*シナリオ3.* NVIDIA * Triton推論サーバ。</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">この解決策 では、フェース検出データセットとベンチマーク（FDDB）を使用します。これは、フェース検出の問題を調査するために設計されたフェース領域のデータセットで、PyTorch機械学習フレームと組み合わせて、フェースボックスを実装するためのフレームワークです。このデータセットには、さまざまな解像度の2845枚の画像セットに5171個の面の注釈が含まれています。さらに、このテクニカルレポートでは、この解決策 を適用できる状況において、ネットアップのお客様やフィールドエンジニアから収集した解決策 の領域と関連するユースケースを紹介します。</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">このテクニカルレポートは、次のような方を対象としています。</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">公共スペースでの顔画像処理に関するデータ保護やプライバシーの問題に対処するために、責任あるAIの設計と導入を希望するビジネスリーダーおよびエンタープライズアーキテクト。</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">データサイエンティスト、データエンジニア、AI /機械学習（ML）研究者、AI / MLシステム開発者は、プライバシーの保護と維持を目指します。</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">GDPR、CCPA、国防総省（DoD）や政府機関のプライバシー法などの規制基準に準拠するAI / MLモデルおよびアプリケーション向けのデータ難読化ソリューションを設計するエンタープライズアーキテクト。</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">データサイエンティストとAIエンジニアは、機密情報を保護するディープラーニング（DL）モデルとAI / ML / DL推論モデルを効率的に導入する方法を探しています。</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">この解決策 は、GPUの処理能力と従来のCPUを併用することで、大規模なデータセットにおけるAIワークロードのリアルタイムおよびバッチ推論を処理するように設計されています。この検証では、MLのプライバシー保護推論と、責任のあるAI導入を求めている組織に必要な最適なデータ管理が実証されています。この解決策 は、エッジコンピューティングとクラウドコンピューティングを連携させる単一ノードまたはマルチノードのKubernetesプラットフォームに適したアーキテクチャを提供します。このプラットフォームは、オンプレミスのコアソフトウェアであるNetApp ONTAP AI、NetApp DataOpsツールキット、およびJupyter LabとCLIインターフェイスを使用したProtopia難読化ソフトウェアと連携します。次の図は、ネットアップのDataOpsツールキットとProtopiaを使用したデータファブリックの論理アーキテクチャの概要を示しています。</block>
  <block id="950724ad73ee22fd3b76ae9570281f64" category="paragraph"><block ref="950724ad73ee22fd3b76ae9570281f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Protopia難読化ソフトウェアは、NetApp DataOpsツールキットの上でシームレスに実行され、ストレージサーバから離れる前にデータを変換します。</block>
  <block id="3d68457cd44385c7acbd55eeda70e8f8" category="inline-link-macro">次の例：解決策 Areas</block>
  <block id="55da59d3fe9630935dbd4fc25d52b939" category="paragraph"><block ref="55da59d3fe9630935dbd4fc25d52b939" category="inline-link-macro-rx"></block></block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">AIと機密性の高い推論を担当-ネットアップのAIとProtopia Image Transformation</block>
  <block id="2ffe7358ce461fb4d630742ed966cf0b" category="example-title">NetApp ONTAP Tools for VMware vSphere の略</block>
  <block id="e78afc9f7bd61b3284539108287c91ca" category="example-title">AWS FSX for NetApp ONTAP を使用したVMware Cloud on AWS</block>
  <block id="f83bc0ebbeff6798c7394f8638db2695" category="example-title">ONTAP Tools for VMware -概要</block>
  <block id="f1d501df2ff1e67b18b06eedd1bad6e8" category="example-title">ONTAP によるVMware iSCSIデータストアのプロビジョニング</block>
  <block id="a5e8a94cc8a28008eb4e2e719f658780" category="example-title">ONTAP によるVMware NFSデータストアのプロビジョニング</block>
  <block id="d69c8ea377286ab60d47066fa2946919" category="example-title">iSCSIを使用したFSX ONTAP を使用したWindowsゲスト接続ストレージ</block>
  <block id="113249c2329945af0bbbc9830088e9ea" category="example-title">NFSを使用したFSX ONTAP を使用したLinuxゲスト接続ストレージ</block>
  <block id="05799bad32c5bd80547efe4144fb57af" category="example-title">VMware vSphere 解決策 用の SnapCenter プラグインの前提条件</block>
  <block id="47d7646bd1c6577d907ac316431ae609" category="example-title">SnapCenter Plug-in for VMware vSphere - 導入</block>
  <block id="11d13047d237d5bccdd941bafda45d9d" category="example-title">SnapCenter Plug-in for VMware vSphere - バックアップワークフロー</block>
  <block id="16bbc152851c33a02fcac2fbf943ffee" category="example-title">SnapCenter Plug-in for VMware vSphere - リストアワークフロー</block>
  <block id="305f1daa74a8ec01eaf0ce2c9a8ce355" category="example-title">SnapCenter - SQL リストアワークフロー</block>
  <block id="891220762a1a15ebfba11cf98afb3729" category="cell">06/07/2022</block>
  <block id="e19e98a669ae21f94ffd1659998fd072" category="cell">データ分析</block>
  <block id="c32698794f1279b1f46bacea38a72264" category="cell">Splunk Enterprise解決策 を使用したNetApp EF600へのリンクを追加しました</block>
  <block id="32e9989956756ffe28b84c0dab24eb03" category="cell">02/02/2022</block>
  <block id="9ceed07936bb73f756027dc20e7869e5" category="open-title">南北アメリカ</block>
  <block id="a58c228b4723aee54800749a595ee3d1" category="cell">* AWSリージョン*</block>
  <block id="0ea8853bd99df0275ce197d81b4acdf3" category="cell">* VMCの可用性*</block>
  <block id="da5de74c1914c54c36141e9bbc0bfb2c" category="cell">* FSX ONTAP 可用性*</block>
  <block id="db1904255fd919e193388d9dfc4066ae" category="cell">* NFSデータストアの可用性*</block>
  <block id="34f9a39dcbb737fbdd35cfb9214308b5" category="cell">米国東部（北バージニア州）</block>
  <block id="227b0fc1350a24236051cdda52db89ae" category="cell">米国東部（オハイオ州）</block>
  <block id="578ab1f7b2f00d70184a6fd055855a32" category="cell">米国西部（北カリフォルニア）</block>
  <block id="2826ad747baf050dc2cfb69d5171f78f" category="cell">US West （オレゴン州）</block>
  <block id="1978cc170637ba3fa169853b7c5b2791" category="cell">GovCloud（米国西部）</block>
  <block id="86378e5a26945a10df6434e3cebc709b" category="cell">カナダ（中央）</block>
  <block id="1289483fccf49359b30e09d42f550943" category="cell">南米（サンパウロ）</block>
  <block id="dbb56fbaa43a12cf5dc69fde5096e785" category="paragraph">最終更新日：2022年6月2日</block>
  <block id="0f1c6d45b761226679e0927cc47d24d3" category="open-title">EMEAの場合</block>
  <block id="8c0594d8d8e156a108f31e22903e4349" category="cell">ヨーロッパ（アイルランド）</block>
  <block id="05f6cd9d18df6f52665dab10eda2ebe1" category="cell">ヨーロッパ（ロンドン）</block>
  <block id="5efd079b952b87c886a8a02de8dd5d83" category="cell">ヨーロッパ（フランクフルト）</block>
  <block id="5be61c2e880e77ca057a65a4ff532d45" category="cell">ヨーロッパ（パリ）</block>
  <block id="ecb3d21f3ca319a515169d4aafe9ed99" category="cell">ヨーロッパ（ミラノ）</block>
  <block id="529f3fee69162e06098d8924e8084ca6" category="cell">ヨーロッパ（ストックホルム）</block>
  <block id="2ebc1f6a39f03ec89f2b4bfdaf802f4c" category="open-title">アジア太平洋地域</block>
  <block id="4c2aaaa08c4d6f6e7e5af0e5fecf29df" category="cell">アジア太平洋地域（シドニー）</block>
  <block id="60b549aa334760e9f2bd47c8296afb7b" category="cell">アジア太平洋地域（東京）</block>
  <block id="dfbd3a51c0e9a689817234013c0d51ee" category="cell">アジア太平洋地域（大阪）</block>
  <block id="c8d7db357b2344e3ebeab70a1e63c6c9" category="cell">アジア太平洋地域（シンガポール）</block>
  <block id="5294ca76dd36c8368fcafd7e951115ef" category="cell">アジア太平洋地域（ソウル）</block>
  <block id="78c8c0f60d4851b109cbd33284f812ca" category="cell">アジア太平洋地域（ムンバイ）</block>
  <block id="82f98bf67698e189fc9d846325345bbd" category="cell">アジア太平洋地域（ジャカルタ）</block>
  <block id="1b15cf1d695d130132edd42a701b41a1" category="cell">アジア太平洋地域（香港）</block>
  <block id="3b041c1182ede15a52a683344c9512e0" category="section-title">AWSリージョンの可用性</block>
  <block id="c5fde59b3560ee1ea5aeeebaf94bdf39" category="section-title">Azureリージョンの可用性</block>
  <block id="7ddf4642a2bfdc9a45847e5d375a1ddb" category="inline-link-macro">詳細^2</block>
  <block id="844f1178f4ff7b95030ee50d8917da61" category="sidebar">リージョンによるNFSデータストアのサポート</block>
  <block id="15b1cf33f2d910f9ab5e6fdaeb331bcc" category="sidebar">リージョンがAWSでNFSデータストアをサポート</block>
  <block id="81a6037600add9bb79d72eb49534ff94" category="sidebar">リージョンのAzureでのNFSデータストアのサポート</block>
  <block id="1da3fb2408fde551ca108534afed1987" category="sidebar">Splunk Enterpriseを使用したNetApp EF600</block>
  <block id="419f5ca56c881443509bda0a14523c9c" category="cell">AVSリージョンのサポートを更新し、公開プレビューのお知らせ/サポートに対応</block>
  <block id="40640c0c34d4427f5d18b9ca476e3158" category="summary">このページでは、 NetApp ONTAP ストレージ上の Oracle19c の自動データ保護について説明します。</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">ヘルスケアおよび生物医学研究</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">画像処理は、CT（Computed Tomography）またはMRI（Magnetic Resonance Imaging）から取得した3D画像から外科的な計画を立てる際の病理を診断するために使用されます。HIPAAのプライバシールールは、すべての個人情報および写真などのデジタル画像に関して、組織がデータを収集、処理、消去する方法を規定しています。HIPAA Safe Harbor規制の下でデータが共有可能となるようにするには、フルフェイスの写真画像と、それに相当する画像を削除する必要があります。構造CT/MR画像から個人の顔の特徴を隠すために使用される匿名化アルゴリズムや頭蓋骨除去アルゴリズムなどの自動化技術は、生物医学研究機関のデータ共有プロセスの重要な要素となっています。</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">エンタープライズのお客様は従来、AI / MLモデルのトレーニングを受け、オンプレミスで導入してきました。スケールメリットと効率性の理由から、AI / ML機能をパブリッククラウド、ハイブリッドクラウド、マルチクラウド環境に移行するお客様が増えています。ただし、他のインフラにどのようなデータを公開できるかによって制限されます。ネットアップのソリューションは、に求められるあらゆるサイバーセキュリティの脅威に対処します<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> また、セキュリティ評価を行い、Protopiaのデータ変換と組み合わせることで、画像処理AI / MLワークロードをクラウドに移行する際のリスクを最小限に抑えることができます。</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928：『Responsible AI and Confidential Inferencing - NetApp AI with Protopia Image and Data Transformation』</block>
  <block id="5b8a88d59edea26637f628caefd05974" category="list-text">Kubernetes クラスタはすでに稼働しており、 Trident でサポートされるバージョンの Kubernetes を実行している。サポートされているバージョンの一覧については、を参照してください<block ref="77881c904b113f84b0f08c355b95174f" category="inline-link-rx"></block>。</block>
  <block id="b81146e6af95bf6e22cf57459890216f" category="inline-link">バックエンド</block>
  <block id="f652904c3bfb48fb25a0a75f485f0ff6" category="inline-link">ストレージクラス</block>
  <block id="05543563edfd7ed0348edd3b47280705" category="list-text">NVIDIA DeepOps を使用して Kubernetes クラスタを導入していない場合や Trident を手動で導入する場合は、次の手順で Trident を導入できます<block ref="e119dd171387190517d77417752a581c" category="inline-link-rx"></block> Trident のドキュメントの設定方法の詳細については、Tridentバックエンドと少なくとも1つのKubernetes StorageClassを作成してください<block ref="9e44c6ae604c64be7a70b0384fa1cccd" category="inline-link-rx"></block> および<block ref="336146b6899186b663ba5a7b38e8c39b" category="inline-link-rx"></block> ネットアップドキュメントのリンクされたサブセクションを参照してください。</block>
  <block id="36522cc6d4eb67d30ef19d321901fa6e" category="cell">2022年6月16日</block>
  <block id="e1ea84e227dd99913363ade155774bcf" category="cell">NVIDIA DGX SuperPODとネットアップの設計ガイドを追加しました</block>
  <block id="1edbb6849585c57ecbf402c0706ecf2d" category="sidebar">NVIDIA DGX SuperPOD with NetApp（設計ガイド）</block>
  <block id="e340bc103d02ce2b8e016eb60705029c" category="sidebar">SAP と SAP HANA に対応しています</block>
  <block id="f1fc5bef6accc6d1fab4ab73142df7f3" category="list-text">Ansibleプレイブックを使用してAstra Control Centerを導入するには、AnsibleがインストールされたUbuntu / RHELマシンが必要です。手順 に従います<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Ubuntuおよび手順 の場合<block ref="94346839427703f278bfb2bc5962a814" category="inline-link-rx"></block> RHEL の場合：</block>
  <block id="703fd9e283392bf196948a4c2ed72680" category="list-text">ネットアップサポートサイトにログインし、最新バージョンのNetApp Astra Control Centerをダウンロードします。そのためには、ネットアップアカウントにライセンスを関連付ける必要があります。tar ファイルをダウンロードしたら、ワークステーションに転送します。</block>
  <block id="42042ccfc3ffee97e94beca237148ed4" category="list-text">Astra Control CenterをインストールするOpenShiftクラスタにadminとしてアクセスし、kubeconfigファイルを作成または取得します。</block>
  <block id="aff7b433e7f33e585c67f69803192117" category="list-text">「vars/vars.yml」ファイルを編集し、必要な情報を変数に入力します。</block>
  <block id="b4ca5df207a7b1e22a2f19cac43dd6ad" category="paragraph">ユーザにパスワードベースのsudoアクセスが設定されている場合は、次のコマンドを実行してこのPlaybookを実行し、sudoパスワードを入力します。</block>
  <block id="f04c9d184475a1c831571242df5998ca" category="paragraph">支払い済みのAstra Control Centerに加えて、90日間の評価ライセンスも利用できます。評価版は、EメールとSlackコミュニティチャネルを通じてサポートされます。お客様は、これらのリソース、その他のナレッジベース記事、および製品サポートダッシュボードから入手できるドキュメントにアクセスできます。</block>
  <block id="9c38b2d834f16a22a033cc493828d911" category="paragraph">NetApp Cloud Volumes ONTAP は、クラウドで導入されるNetApp ONTAP のバージョンで、Amazon AWS、Microsoft Azure、Google Cloudなどのさまざまなパブリッククラウドに導入できます。</block>
  <block id="c48c25afacd7dddac49ab104ad056df0" category="paragraph">Astra Tridentは、コンテナやKubernetesディストリビューション向けの、完全にサポートされているオープンソースのストレージオーケストレーションツールです。｛k8s_distribution_name｝などが挙げられます。Trident は、 NetApp ONTAP や Element ストレージシステムを含むネットアップストレージポートフォリオ全体と連携し、 NFS 接続と iSCSI 接続もサポートします。Trident を使用すると、ストレージ管理者の手を煩わせることなく、エンドユーザがネットアップストレージシステムからストレージをプロビジョニングして管理できるため、 DevOps ワークフローが高速化されます。</block>
  <block id="7654a00ca744e9bf01021439190e3119" category="doc">VMware Tanzu Kubernetes Grid Integrated Edition（TKGI）の概要</block>
  <block id="644bd75ee9c13f7d8778e4638d9eb2b2" category="paragraph">VMware Tanzu Kubernetes Grid Integrated（TKGI）Editionは、従来のVMware Enterprise PKSと呼ばれていた、スタンドアロンのコンテナオーケストレーションプラットフォームであり、ライフサイクル管理、クラスタの健常性監視、高度なネットワーク、コンテナレジストリなどの機能を備えています。TKGIは、BOSHとOps Managerで構成されるTKGIコントロールプレーンを使用してKubernetesクラスタをプロビジョニングおよび管理します。</block>
  <block id="a84b33dfae5a2fdc1618084442bc3df0" category="paragraph">TKGIは、オンプレミスのvSphere環境またはOpenStack環境、あるいは各IaaSサービス上の主要なパブリッククラウドのいずれかにインストールして操作できます。さらに、TKGIとNSXおよびNSXとNSXとの統合により、エンタープライズワークロードの幅広いユースケースが可能になります。TKGIとその機能の詳細については、のマニュアルを参照してください <block ref="0b1e387b87be5caa8371b58b8e02b1f8" category="inline-link-macro-rx"></block>。</block>
  <block id="26f1f37ed65557967fe3a789aa75c364" category="paragraph">TKGIは、さまざまなユースケースとデザインに基づいて、さまざまなプラットフォームにさまざまな構成でインストールされています。ガイドに従ってください <block ref="54093918574a441541c9219fc9d087f1" category="inline-link-macro-rx"></block> TKGIとその前提条件をインストールおよび構成するには、次の手順に従います。TKGIは、改ざん不可の構成イメージを実行するTanzu Kubernetesクラスタのノードとして、Bosh VMを使用します。また、Bosh VMに対する手動変更は、リブート後も維持されません。</block>
  <block id="58959a34911d9e88e191f3453ddc81f0" category="paragraph">重要事項：</block>
  <block id="d7fc6fcd5f3c3c3fca9edded9bf380e1" category="list-text">NetApp Tridentでは、特権コンテナへのアクセスが必要です。そのため、TKGIのインストール中に、Tanzu Kubernetesクラスタノードプランを構成する手順でEnable Privileged Containers（特権コンテナを有効にする）チェックボックスを選択してください。</block>
  <block id="651650f759262b05cb38b56003e55784" category="image-alt">TKGIの特権コンテナ</block>
  <block id="956d281862a0ec3c4bb386cd28bf959c" category="list-text">ワークロードの要件を満たすようにワーカーノードの構成を選択し、すべての本番環境を複数のマスター環境に導入してフォールトトレランスを実現することを推奨します。したがって、推奨されるTKGIクラスタ計画は、少なくとも3つのマスターと、少なくとも4つのvCPUと12GBのRAMを持つ3人のワーカーで構成され、負荷の高いワークロードを実現します。</block>
  <block id="74d32c3e98de18a4adf66bd3f05e6088" category="inline-link-macro">次：ネットアップストレージシステムの概要</block>
  <block id="86de08c652cda2ec18cd6f36a36cfcfa" category="paragraph"><block ref="86de08c652cda2ec18cd6f36a36cfcfa" category="inline-link-macro-rx"></block></block>
  <block id="71417a3dd01aa388d35bf54aa4c401fa" category="summary">このページには、本ドキュメントで説明している機能の一部を紹介するビデオへのリンクが記載されています。</block>
  <block id="952be0b8dee874c73cd76a4d6a526b27" category="doc">ビデオとデモ：VMware Tanzu with NetApp</block>
  <block id="811263b3dba6ff02a02f70eb9730ca2e" category="inline-link-macro">Astra Tridentを使用して、VMware Tanzuに永続的ストレージをプロビジョニング</block>
  <block id="6aa25c5e03abeab0ced9fac672bb2330" category="list-text"><block ref="6aa25c5e03abeab0ced9fac672bb2330" category="inline-link-macro-rx"></block></block>
  <block id="03a87e35f2de41c34385d72c2c717acf" category="inline-link-macro">Astra Control Centerを使用して、VMware Tanzuのアプリケーションをクローニングできます</block>
  <block id="591774815c932f725e0adbded50b634b" category="list-text"><block ref="591774815c932f725e0adbded50b634b" category="inline-link-macro-rx"></block></block>
  <block id="bf6a387fea3d3444126eab19bcb4bbcd" category="inline-link-macro">次のレポート：追加情報 ：ネットアップを使用したVMwareのTanzuの紹介</block>
  <block id="df2a7ac55fe19fad5a5006603cfd8662" category="paragraph"><block ref="df2a7ac55fe19fad5a5006603cfd8662" category="inline-link-macro-rx"></block></block>
  <block id="84053bd81ac19b225e107ad3b65ca58d" category="paragraph"><block ref="84053bd81ac19b225e107ad3b65ca58d" category="inline-link-macro-rx"></block></block>
  <block id="de15ad9e760a3587b2effb60a58133b1" category="summary">Astra Tridentは、VMware TanzuなどのコンテナやKubernetesディストリビューション向けの、オープンソースで完全にサポートされているストレージオーケストレーションツールです。</block>
  <block id="143c9ea21ac76ba425aa94411fbba07b" category="doc">Astra Tridentの概要</block>
  <block id="ebe5598ec22d01fe25c02071b488309b" category="section-title">Helmを使用してTridentオペレータを導入</block>
  <block id="a082551b03c5e35829be23792317ac16" category="list-text">NetApp Astra Trident Helmリポジトリを追加</block>
  <block id="836237f5ff429cb9283688cdfaa56c76" category="list-text">Helmリポジトリを更新します。</block>
  <block id="875c7439b686e253522033c63d909efe" category="list-text">Tridentをインストールするための新しいネームスペースを作成します。</block>
  <block id="82b1cf842f022e618212caef5d3c942d" category="list-text">DockerHubのクレデンシャルを使用してシークレットを作成し、Astra Tridentイメージをダウンロードします。</block>
  <block id="e5073fdda88ef7d6b18ac4f938abbece" category="list-text">TKGS（vSphere with Tanzu）またはTKG（管理クラスタを含む）で管理されるユーザまたはワークロードクラスタの場合、次の手順 を実行してAstra Tridentをインストールします。</block>
  <block id="d409e9c69dd2082fd0ed8a86d87258e8" category="list-text">ログインしているユーザに、tridentネームスペースにサービスアカウントを作成する権限があり、tridentネームスペースのサービスアカウントにポッドを作成する権限があることを確認します。</block>
  <block id="397ae57f2a6cbd8444c419c896f19886" category="list-text">以下のHelmコマンドを実行し、作成したネームスペースにTridentオペレータをインストールします。</block>
  <block id="eef6352658410e2218bd7027ae8ff351" category="list-text">TKGI導入によって管理されるユーザまたはワークロードクラスタの場合は、次のHelmコマンドを実行して、作成されたネームスペースにTridentオペレータをインストールします。</block>
  <block id="12d34565a0d56eff4f8d3f99b138e11a" category="list-text">Tridentポッドが稼働中であることを確認します。</block>
  <block id="f48fa73c7f509e20ce14901e4639f13d" category="paragraph">Astra Trident Operator のインストールが完了したら、使用するネットアップストレージプラットフォームに合わせてバックエンドを設定する必要があります。次のリンクに従って、Astra Tridentのセットアップと設定を続けてください。</block>
  <block id="c060cacb4d77409e1402a5dcab49bf8b" category="list-text"><block ref="c060cacb4d77409e1402a5dcab49bf8b" category="inline-link-macro-rx"></block></block>
  <block id="2280e7f4e3cc9a8caee65d058e1db860" category="list-text"><block ref="2280e7f4e3cc9a8caee65d058e1db860" category="inline-link-macro-rx"></block></block>
  <block id="fca47dd46473e4571bb1904fe2d5f3f5" category="inline-link-macro">次：ビデオとデモ：ネットアップが提供するVMware Tanzu</block>
  <block id="61a5a682a4430d961b9bc43c2f902e94" category="paragraph"><block ref="61a5a682a4430d961b9bc43c2f902e94" category="inline-link-macro-rx"></block></block>
  <block id="fa6f7af807ffa3ac6e2efb5c31463a4f" category="paragraph">TridentをNFS経由でNetApp ONTAP ストレージシステムと統合するには、ストレージシステムとの通信を可能にするバックエンドを作成する必要があります。この解決策 では基本的なバックエンドを設定しますが、よりカスタマイズされたオプションを探している場合は、のマニュアルを参照してください <block ref="f72d871ae286e7b7cf7d9ea12426661a" category="inline-link-macro-rx"></block>。</block>
  <block id="aaa6c6e969e6e978f9a8bce54e31b5f7" category="section-title">ONTAP でSVMを作成します</block>
  <block id="b1c04b7e96694453a1307ecc81208ae5" category="list-text">ONTAP System Managerにログインし、Storage &gt; Storage VMの順に選択し、Addをクリックします。</block>
  <block id="f53bd08113ff367a9bcd470b70a036d8" category="list-text">SVMの名前を入力し、NFSプロトコルを有効にし、NFSクライアントアクセスを許可チェックボックスをオンにして、ワークロードクラスタ内でボリュームをPVSとしてマウントできるように、ワーカーノードがオンになっているサブネットをエクスポートポリシールールに追加します。</block>
  <block id="0cdb2a8f015b7a7d81ab5c3d73de88a5" category="image-alt">SVM - NFSを使用して作成</block>
  <block id="e570ad3092406b5118fcd78a9374e048" category="admonition">NSX -Tを使用したユーザクラスタまたはワークロードクラスタのNAT配置を使用する場合は、出力サブネット（TKGS0の場合はフローティングIPサブネット（TKGIの場合））をエクスポートポリシールールに追加する必要があります。</block>
  <block id="8f254daa71e82320e11e55258b095b00" category="list-text">データLIFの詳細とSVM管理アカウントの詳細を指定し、保存をクリックします。</block>
  <block id="02ffb816541fbf18a204c877564fb92e" category="image-alt">SVMのデータLIFとSVMの管理</block>
  <block id="491df82049a4ac2d8b8b2fe6b773d65d" category="list-text">アグリゲートをSVMに割り当てます。Storage &gt; Storage VMsと進み、新しく作成したSVMの横にある省略記号をクリックして、Editをクリックします。ボリュームの作成を優先ローカル階層に制限するチェックボックスをオンにして、必要なアグリゲートを関連付けます。</block>
  <block id="85c5adc69f6da0ebb2ebf365c4211508" category="image-alt">SVMアグリゲートの割り当て</block>
  <block id="95fdf7e31ffa1073f8c42359589c334e" category="list-text">Tridentをインストールするユーザまたはワークロードクラスタに対してNATを使用して配置した場合、ストレージマウント要求はSNATのために非標準ポートから到達する可能性があります。デフォルトでは、ONTAP は、ルートポートから作成されたボリュームマウント要求のみを許可します。したがって、ONTAP CLIにログインし、非標準ポートからのマウント要求を許可する設定を変更してください。</block>
  <block id="03c8ff4111bb9cfc032f786c9bd7c6e8" category="section-title">バックエンドとStorageClassesを作成します</block>
  <block id="e15177ebae9bfb9adab94a9ccf5f2e96" category="list-text">NFSを提供しているNetApp ONTAP システムの場合は、backendName、managementLIF、dataLIF、SVM、ユーザ名を指定してjumphostでバックエンド構成ファイルを作成します。 パスワードなどの詳細情報。</block>
  <block id="c75cfbdcbbe9d48dc121fc816d4a2ccf" category="list-text">次のコマンドを実行してTridentバックエンドを作成します。</block>
  <block id="ad2008cda12d454189828df19b2f9742" category="list-text">バックエンドを作成したら、次にストレージクラスを作成する必要があります。次のストレージクラス定義の例では、必須フィールドと基本フィールドが強調表示されています。パラメータbackendTypeは'新しく作成されたTridentバックエンドのストレージ・ドライバを反映する必要があります</block>
  <block id="0286d73690ed0ef54af06bd9175945cd" category="list-text">kubectlコマンドを実行して、ストレージクラスを作成します。</block>
  <block id="8d8b689e86dbd34b31294b3f829db499" category="list-text">ストレージクラスを作成したら、最初の永続的ボリューム要求（ PVC ）を作成する必要があります。PVC定義の例を次に示します。[storageClassName](ストレージクラス名)フィールドが'作成したストレージクラスの名前と一致していることを確認しますプロビジョニングするワークロードに応じて、PVC定義を必要に応じてさらにカスタマイズできます。</block>
  <block id="c764ff1d25a2f9241afec7161127f74d" category="list-text">kubectlコマンドを発行して、PVCを作成します。作成中の元のボリュームのサイズによっては作成にしばらく時間がかかることがあるため、作成が完了した時点でこのプロセスを監視できます。</block>
  <block id="5f87e8fbf603b28eb84592d8e64980c6" category="doc">追加情報 ：ネットアップを使用したVMwareのTanzuの紹介</block>
  <block id="a6f4f5f0d313fa8894e4ad13a09339c0" category="list-text">VMware Tanzuのドキュメント</block>
  <block id="57a35ee57ca4eb666386f668ebc74599" category="inline-link"><block ref="57a35ee57ca4eb666386f668ebc74599" category="inline-link-rx"></block></block>
  <block id="35d5768f9d0ee829a3e2cae0cba15216" category="paragraph"><block ref="35d5768f9d0ee829a3e2cae0cba15216" category="inline-link-rx"></block></block>
  <block id="2839dd9e9e31ca41ba6399c0a64d3333" category="list-text">VMware Tanzu Kubernetes Gridのドキュメント</block>
  <block id="94ecd750f91f6d1908b92ec42eb37398" category="inline-link"><block ref="94ecd750f91f6d1908b92ec42eb37398" category="inline-link-rx"></block></block>
  <block id="f0a59887fc9e8ee88512ff6312c13efa" category="paragraph"><block ref="f0a59887fc9e8ee88512ff6312c13efa" category="inline-link-rx"></block></block>
  <block id="9cf21c31f745a435ac892addf1fd1a3f" category="list-text">VMware Tanzu Kubernetes Grid Serviceに関するドキュメント</block>
  <block id="98978b88e05533d45b79613d9ee6f26d" category="inline-link"><block ref="98978b88e05533d45b79613d9ee6f26d" category="inline-link-rx"></block></block>
  <block id="56c4cea9b33fd23cf082d00ca92d5a46" category="paragraph"><block ref="56c4cea9b33fd23cf082d00ca92d5a46" category="inline-link-rx"></block></block>
  <block id="c23715ed7437fed1084a24cebb89e63c" category="list-text">VMware Tanzu Kubernetes Grid Integrated Editionのドキュメント</block>
  <block id="fd2560680b89b39b1b988587bf383fb4" category="inline-link"><block ref="fd2560680b89b39b1b988587bf383fb4" category="inline-link-rx"></block></block>
  <block id="f4b2873e621660e86074a62e5a6c5eac" category="paragraph"><block ref="f4b2873e621660e86074a62e5a6c5eac" category="inline-link-rx"></block></block>
  <block id="3ff1ba174bc4d7824738ba1a0c0b4035" category="summary">NetApp Astra Control Centerは、ネットアップの信頼できるデータ保護テクノロジを基盤とするオンプレミス環境に導入された、ステートフルKubernetesワークロード向けの豊富なストレージサービスとアプリケーション対応データ管理サービスを提供します。</block>
  <block id="678f429fd30f5d3718b72e260e17f5f0" category="paragraph">すぐに利用できる、Astra Control REST APIと連携するためのソフトウェア開発ツールキットを探している場合、ネットアップはAstra Control Python SDKのツールキットを提供しています。このツールキットはダウンロードが可能です <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>。</block>
  <block id="6b24baf9bd0e230b887612f836d0fbd5" category="paragraph">プログラミングが適していない状況で構成管理ツールを使用する場合は、ネットアップが公開しているAnsibleプレイブックをクローニングして実行できます <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>。</block>
  <block id="c90524de7ee251d8a5128ac3f59847c6" category="paragraph">Astra Control Centerのインストールには、次の前提条件が必要です。</block>
  <block id="9f2559e9a5f31fdb3d5489aa3367ae35" category="list-text">1つ以上のTanzu Kubernetesクラスタは、管理クラスタまたはTKGSまたはTKGIによって管理されます。TKGワークロードクラスタ1.4 +およびTKGIユーザークラスタ1.12.2+がサポートされています。</block>
  <block id="c94e1287a80d82c490967572d336083d" category="list-text">各Tanzu KubernetesクラスタにAstra Tridentがインストールおよび設定されている必要があります。</block>
  <block id="ba1c516a3e7a998469a5ac73695127ce" category="admonition">サイトにある各Tanzu Kubernetesインストールでは、永続的ストレージ用の専用SVMを使用することを推奨します。マルチサイト環境では、追加のストレージシステムが必要です。</block>
  <block id="c756010e6a027d7d6ae199c033f4b1db" category="list-text">Tridentストレージバックエンドは、ONTAP クラスタから作成されたSVMを含む各Tanzu Kubernetesクラスタで設定する必要があります。</block>
  <block id="dd7ed1e31baf27a40282a08242cf6efc" category="list-text">各Tanzu Kubernetesクラスタに設定されたデフォルトのStorageClassには、Astra Tridentをストレージプロビジョニングツールとして使用します。</block>
  <block id="e8ed7f9c94a716f73364706e6db9c1c6" category="list-text">ingressType「AccTraefik」を使用している場合は、ロードバランシングとアストラコントロールセンターの公開のために、各Tanzu Kubernetesクラスタにロードバランサをインストールし、設定する必要があります。</block>
  <block id="6b769b6cd8bf0a312e04e05973e13018" category="list-text">ingressType「Generic」を使用している場合は、Astra Control Centerを公開するために、各Tanzu Kubernetesクラスタに入力コントローラをインストールし、設定する必要があります。</block>
  <block id="0e6886020b4adf5871ebc7346b63c3a0" category="list-text">Astra Control CenterをインストールしているTanzu Kubernetesクラスタにクラスタ管理者としてアクセスできる必要があります。</block>
  <block id="8bd3433e327d75f3a3c33d9998840fce" category="list-text">RHELまたはUbuntuの管理ワークステーション。</block>
  <block id="ed060d0439d2eda03baa2005199d9bc1" category="paragraph">この解決策 では、Ansibleプレイブックを使用してAstra Control Centerをインストールするための自動手順 について説明します。手順 を手動でインストールしてAstra Control Centerをインストールする場合は、詳細なインストールと操作のガイドに従ってください <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>。</block>
  <block id="662609908ab8e0f372d83dea3511370b" category="inline-link">手順</block>
  <block id="8575c02ec176b0f64904bcbd79e81cba" category="list-text">Astra Control Centerを導入するAnsibleプレイブックを使用するには、AnsibleがインストールされたUbuntu / RHELマシンが必要です。これを実行します<block ref="c1972c5d94c51919767b49f6cefbf6ba" category="inline-link-rx"></block> Ubuntuおよびこれの場合<block ref="c4dab530b5bf152ded398881b8308451" category="inline-link-rx"></block> RHEL の場合：</block>
  <block id="df57d245f4173d8ac23df756917bb6ae" category="list-text">Astra Control CenterをインストールするユーザまたはワークロードのTanzu Kubernetesクラスタに管理者アクセスでkubeconfigファイルを作成または取得します。</block>
  <block id="b2d9440273952d4b05aed1b36c66494d" category="list-text">ディレクトリを'na_Astra_control_siteに変更します</block>
  <block id="7489123185b81a6e11b42218fabb4c3b" category="list-text">「vars/vars.yml」ファイルを編集し、必要な情報を変数に入力します。</block>
  <block id="2b6b49be82749b9e141c2f0a23c8d11f" category="paragraph">プレイブックを実行しているユーザがrootである場合、またはパスワードなしのsudoが設定されている場合は、次のコマンドを実行してプレイブックを実行します。</block>
  <block id="111dd0947a16442f317af649a2aac536" category="list-text">ingressTypeがAccTraefikの場合は、traefikサービスロードバランサIPを取得します。</block>
  <block id="25ce05402248633e67c7cbc234573b60" category="list-text">Astra Control Centerのすべての機能が動作するには、ライセンスが必要です。ライセンスを追加するには、 ［ アカウント ］ &gt; ［ ライセンス ］ の順に選択し、 ［ ライセンスの追加 ］ をクリックして、ライセンスファイルをアップロードします。</block>
  <block id="bf3293f2603ff733102e45d1152bc0a1" category="admonition">NetApp Astra Control Center のインストールまたは設定で問題が発生した場合は、既知の問題のナレッジベースを利用できます<block ref="695f48b1d8b7348c0e2828947d24161e" category="inline-link-rx"></block>。</block>
  <block id="1e89038a8ae648db9dd4b203267abd3a" category="inline-link-macro">次は、Tanzu Kubernetesクラスタを登録します。</block>
  <block id="c7f57c40ce02379584ec7748d9444ee0" category="paragraph"><block ref="c7f57c40ce02379584ec7748d9444ee0" category="inline-link-macro-rx"></block></block>
  <block id="318a4bce7f9fca07a60ed82408fbcd29" category="doc">VMware Tanzu Kubernetes Grid（TKG）の概要</block>
  <block id="11e5f8209ef45e9884518caf7b5bc68d" category="paragraph">TKGとも呼ばれるVMware Tanzu Kubernetes Gridを使用すると、ハイブリッドクラウド環境やパブリッククラウド環境にTanzu Kubernetesクラスタを導入できます。TKGはKubernetesクラスタそのものである管理クラスタとしてインストールされ、Tanzu Kubernetesクラスタを導入および運用します。これらのTanzu Kubernetesクラスタは、実際のワークロードが導入されているワークロードのKubernetesクラスタです。</block>
  <block id="9a67a32e17609515d2fc11383d1a7b59" category="paragraph">Tanzu Kubernetes Gridは、いくつかの有望なアップストリームコミュニティプロジェクトに基づいて構築され、VMwareが開発、販売、サポートするKubernetesプラットフォームを提供します。Kubernetesディストリビューションに加え、Tanzu Kubernetes Gridには、レジストリ、ロードバランシング、認証などの重要な本番環境クラスのサービスであるアドオンが追加されています。管理クラスタを備えたVMware TKGはvSphere 6.7環境で広く使用されていますが、それがサポートされていても、TKGSにはvSphere 7とのネイティブ統合機能があるため、vSphere 7環境への導入は推奨されません。</block>
  <block id="4e6c29e9760f3e53993a64a5f6c63aaa" category="image-alt">管理クラスタを使用したVMware Tanzu Kubernetes Gridのソリューション</block>
  <block id="ec30336a82729146050b0931adab64f2" category="paragraph">Tanzu Kubernetes Gridの詳細については、のドキュメントを参照してください <block ref="f4dbc56b610d9f5cd603e1a13bb6dedf" category="inline-link-macro-rx"></block>。</block>
  <block id="86fcbed2a7f5b8edced11b10bd1e4266" category="paragraph">Tanzu Kubernetes GridがvSphereクラスタまたはクラウド環境にインストールされているかどうかに応じて、インストールガイドに従ってTanzu Kubernetes Gridを準備して導入します <block ref="492c3fae38681e036fd18bedc1bf8ae5" category="inline-link-macro-rx"></block>。</block>
  <block id="c1f07986544fbf96897f8099577b0e72" category="paragraph">Tanzu Kubernetes Gridの管理クラスタをインストールしたら、のドキュメントに従って、必要に応じてユーザクラスタまたはワークロードクラスタを導入します <block ref="7d3f6d9f879d392af501006eacd0d221" category="inline-link-macro-rx"></block>。VMware TKG管理クラスタでは、Tanzu Kubernetesクラスタのインストールと運用にSSHキーが必要です。このキーは'capv'ユーザを使用してクラスタ・ノードにログインするために使用できます</block>
  <block id="07f15dfb0f84a062c67184adcee67a8b" category="summary">このリファレンスガイドでは、Tanzu Kubernetes Grid（TKG）、Tanzu Kubernetes Grid Service（TKGS）、またはTanzu Kubernetes Grid Integrated（TKGI）のいずれかとして、ネットアップによって検証済みの複数のデータセンター環境に導入された、さまざまなVMware Tanzu Kubernetesソリューションの導入方法を検証します。</block>
  <block id="bec8bc9f783c7d01005b7e64d1ad1785" category="doc">NVA-1166：ネットアップを使用したVMware Tanzuの評価</block>
  <block id="c837e955d75d674feb57af7e68b3d74c" category="paragraph">このリファレンスガイドでは、Tanzu Kubernetes Grid（TKG）、Tanzu Kubernetes Grid Service（TKGS）、またはTanzu Kubernetes Grid Integrated（TKGI）のいずれかとして、ネットアップによって検証済みの複数のデータセンター環境に導入された、さまざまなVMware Tanzu Kubernetesソリューションの導入方法を検証します。また、ネットアップストレージシステムとAstra Tridentストレージオーケストレーションツールとのストレージ統合についても説明します。Tridentストレージオーケストレーションツールを使用して永続的ストレージを管理し、Astra Control Centerで、永続的ストレージを使用してステートフルアプリケーションのバックアップとクローニングを実行できます。最後に、解決策 の統合と検証のビデオデモを紹介します。</block>
  <block id="c0a14f456cfcfac669f2cf374f60561b" category="paragraph">NetApp解決策 を搭載したVMware Tanzuは、次のユースケースにおいて、お客様に卓越した価値を提供するように設計されています。</block>
  <block id="8cc1d80dbdd5d6d142f0173d8c8f2261" category="list-text">VMware vSphereに導入され、ネットアップストレージシステムと統合されたVMware Tanzu Kubernetes Gridサービスの導入と管理が簡単です。</block>
  <block id="8796988ff3c4f065733c3b887d886609" category="list-text">VMware Tanzu Kubernetes Gridソリューションは、エンタープライズコンテナと仮想化ワークロードの機能を統合したものです。</block>
  <block id="d7071bc518e2fa9a30b1debdd8e721f1" category="list-text">VMware Tanzuの機能にネットアップのストレージやネットアップのAstra製品スイートを使用した実際の構成とユースケース</block>
  <block id="3d4565b89cb9591acc32839ce0d48627" category="list-text">VMware Tanzu Kubernetes Gridクラスタに導入されたコンテナ化ワークロードを、Astra Control Centerを使用してネットアップストレージシステムにアプリケーションと整合性のある方法で保護または移行</block>
  <block id="29375f7cc2c5eece7fdd9c99f40eb3f8" category="list-text">オンプレミスのデータセンターとクラウドの両方でコンテナを実行するハイブリッドクラウドモデルに導入できます。</block>
  <block id="ddea0381617b5a4b43a0a98a440c6658" category="paragraph">ネットアップのVMware Tanzuにはこのような課題があることを認め、お客様が選択したハイブリッドクラウド環境にVMware Tanzu Kubernetesソリューションを導入することで、それぞれの問題に対処できる解決策 が示されています。</block>
  <block id="c57f369df48137f738543c0e5012006c" category="paragraph">NetApp解決策 を搭載したVMware Tanzuは、次の主要コンポーネントで構成されています。</block>
  <block id="67d7b0b61202e57bcae8cda82f02e2b3" category="section-title">VMware Tanzu Kubernetesプラットフォーム</block>
  <block id="55ad4cb8f0feecb71e184ef92cff1f70" category="paragraph">VMware Tanzuには、ネットアップのソリューションエンジニアリングチームがラボで検証したさまざまなフレーバーがあります。各Tanzuリリースはネットアップのストレージポートフォリオと正常に統合されており、各リリースが特定のインフラ要件を満たすのに役立ちます。次の各バージョンのTanzuの特徴と機能については、このドキュメントで説明します。</block>
  <block id="5849f8d5cb1d66cb095da163e533dea7" category="paragraph">VMware Tanzu Kubernetes Grid（TKG）</block>
  <block id="45915535ce313f81567f3b3c41571fe9" category="list-text">VMware vSphere環境に展開される標準のアップストリームKubernetes環境。</block>
  <block id="32fcd5c42dc47b5cc021d74a489dee4f" category="list-text">以前はEssential PKSと呼ばれていました（Heptio買収により、2019年2月に取得）。</block>
  <block id="16196833d09cc8d52a1ef3790b4e15d3" category="list-text">TKGは、vSphere 6.7U3以降でサポートされる独立した管理クラスタインスタンスとともに導入されています。</block>
  <block id="08f2ff1c0826ffc53a185010cce7dac7" category="list-text">TKGの導入は、AWSやAzureと同様にクラウドにも導入できます。</block>
  <block id="15aa7eec2d32a1ba74b5cea8af5241ec" category="list-text">WindowsまたはLinuxのワーカーノード（Ubuntu / Photon）を使用できます。</block>
  <block id="89a8813ef0f3f2c1a9b0f20dab87e2a2" category="list-text">NSXとT、HA Proxy、AVIネットワーク、またはロードバランサをコントロールプレーンに使用できます。</block>
  <block id="2ad16c86af27df82ae725dfd15176212" category="list-text">TKGはアプリケーション/データプレーンでMetalLBをサポートしています。</block>
  <block id="7bf259c507ef53db8da3607757164b2e" category="list-text">vSphere CSIおよびNetApp Astra TridentなどのサードパーティCSISを使用可能</block>
  <block id="c840af216b38aff44cc5ba246da60e17" category="paragraph">VMware Tanzu Kubernetes Grid Service（TKGS）</block>
  <block id="27077307fac1683851c72a97ba11c62e" category="list-text">TKGSは、vSphere 7.0U1以降でのみスーパーバイザクラスタおよびワークロードクラスタとともに配置されます。</block>
  <block id="3ee27cde76894c76ad60736ecbca78da" category="list-text">TKGSはアプリケーション/データプレーンでMetalLBをサポートしています。</block>
  <block id="443c9bd7eeb4bc3d39f67cc555b4aab2" category="list-text">は、Tanzuを使用したvSphereポッドのサポートを提供し、環境内の有効なESXiホストでポッドを直接実行できるようにします。</block>
  <block id="f4ef19f9ee886fa602632ef3f35019ad" category="list-text">以前の名称はEnterprise PKS（Heptio取得、2019年2月）です。</block>
  <block id="28789df26df63aa440b3aded601e67a6" category="list-text">NSXとT、HAプロキシ、AVIのいずれかを使用できます。独自のロードバランサを指定することもできます。</block>
  <block id="2b681f710a75cd56332534e50fe625ff" category="list-text">vSphere 6.7U3以降、およびAWS、Azure、GCPでサポートされます。</block>
  <block id="f09eefe449cf027cce033ceb064c2fae" category="list-text">ウィザードを使用してセットアップすると、導入が簡単になります。</block>
  <block id="78c9a89b579a1005676bf4b1a4b3aad7" category="list-text">BOSHが管理する変更不可の制御VMでTanzuを実行します。</block>
  <block id="46c96f35ab6c6f57dd96776e1f115737" category="list-text">NetApp Astra Tridentのように、vSphere CSIやサードパーティのCSISを利用できる（一部の条件が適用される）</block>
  <block id="b63d5ee355078976e86c94b5c978788e" category="paragraph">NetApp Astra Control Centerは、ステートフルKubernetesワークロード向けの充実したストレージおよびアプリケーション対応のデータ管理サービスを提供します。オンプレミス環境に導入され、信頼できるネットアップのデータ保護テクノロジを基盤としています。</block>
  <block id="e764fe6b8f8825a307a87cedbef45678" category="cell">22.04</block>
  <block id="63355c54bd7e8ff73915da41610ec6f7" category="cell">22.04.0</block>
  <block id="22053fd2d26d3a313aea03b09e9a776c" category="cell">VMware Tanzu Kubernetes Gridサービス</block>
  <block id="c99c6e88d4de8db879b1b5ec64d1f7ed" category="cell">0.0.15 [vSphere名前空間]</block>
  <block id="8eb1302ead60c09b6d757b2b7ab84040" category="cell">1.22.6 [スーパーバイザクラスタのKubernetes ]</block>
  <block id="caf617dd6edf29fd289caff7469ea66b" category="cell">VMware Tanzu Kubernetes Grid統合</block>
  <block id="1d5bc9367c9565bbe31cc00aa1f870a4" category="cell">1.13.3</block>
  <block id="5d9dd4ee62c5446f01e895cd118d98dd" category="cell">VMware NSX -Tデータセンター</block>
  <block id="7bc09c21b8fa1161768459982f0ec89e" category="cell">ネットワークとセキュリティ</block>
  <block id="b1179856b0372cb8777975cb658548ac" category="cell">3.1.3</block>
  <block id="cc540661734771d2e0272e8b4ef5c228" category="cell">VMware NSX Advanced Load Balancerの略</block>
  <block id="50382c1137e78c7c038faabadb85d9fd" category="cell">ロードバランサ</block>
  <block id="d08680d7e9b745c4d4b81a2d6df7a012" category="cell">20.1.3</block>
  <block id="743cb170909d5e6e5936fc4783a59de5" category="inline-link-macro">次のステップ：VMware Tanzuの概要</block>
  <block id="4b362af24230ce2d990680198c520d44" category="paragraph"><block ref="4b362af24230ce2d990680198c520d44" category="inline-link-macro-rx"></block></block>
  <block id="30a7219728f2665214ac7ae0458c27a8" category="list-text"><block ref="30a7219728f2665214ac7ae0458c27a8" category="inline-link-macro-rx"></block></block>
  <block id="40ef898131b1ea0532620ff9cb12840c" category="summary">このページには、Astra Tridentを使用してVMware Tanzuに永続的ストレージをプロビジョニングする方法に関するビデオデモのリンクが掲載されています。</block>
  <block id="e0d2648924bbf778345db6153fddf464" category="doc">VMware Tanzuで永続的ストレージをプロビジョニングするには、Astra Tridentを使用してください</block>
  <block id="db70f2aaf062f269f45b2fe61ad31160" category="admonition">このデモは、TKGのバージョン1.3.1とAstra Control Centerのバージョン21.12を使用して、テクニカルプレビューとして記録されました。サポートされている公式バージョンについては、サポートマトリックスを参照してください。</block>
  <block id="945f7593bacdce2a986b2ea8ab58220b" category="summary">このページは、Astra Control Centerを使用してVMware Tanzuのアプリケーションをクローニングする方法を説明するビデオデモへのリンクです。</block>
  <block id="ff56b2be4aa6be0d45adf0bbeb76166d" category="doc">Astra Control Centerを使用して、VMware Tanzuのアプリケーションをクローニングできます</block>
  <block id="15693c045ae1b118bd5c3f8e9cee5c08" category="summary">Astra Control Centerでワークロードを管理できるようにするには、まずTanzu Kubernetesクラスタを登録する必要があります。</block>
  <block id="3a16c17a7d5ce69951add72b2e46c340" category="doc">VMware Tanzu KubernetesクラスタをAstra Control Centerに登録します</block>
  <block id="a723b0aede16ae3d3bdd6761d359595b" category="section-title">VMware Tanzu Kubernetesクラスタを登録します</block>
  <block id="779e6578abb36499d7c5399b33269c9c" category="list-text">最初の手順は、Tanzu KubernetesクラスタをAstra Control Centerに追加して管理することです。[クラスタ]に移動して[クラスタの追加]をクリックし、Tanzu Kubernetesクラスタのkubeconfigファイルをアップロードして、[ストレージの選択]をクリックします。</block>
  <block id="d9687c204aa759a004b29f4f41e01908" category="list-text">クラスタが追加されると、Astra Control Centerがクラスタを検査し、必要なエージェントをインストールしながら、クラスタはDiscoveringステータスに移行します。正常に登録されると、クラスタ・ステータスは「Healthy」に変わります。</block>
  <block id="1e7084bafe0fe7d10e28e10eea2641aa" category="admonition">Astra Control Centerで管理するすべてのTanzu Kubernetesクラスタは、管理対象クラスタにインストールされたエージェントとしてそのインストールに使用されたイメージレジストリにアクセスできる必要があります。このレジストリからイメージがプルされます。</block>
  <block id="f3eca6ba1067d4a61b1229f18ab1a463" category="list-text">ONTAP クラスタをストレージリソースとして Astra Control Center でバックエンドとして管理するようにインポートします。Tanzu KubernetesクラスタがAstraに追加され、ストレージクラスが設定されている場合、ストレージクラスをサポートするONTAP クラスタは自動的に検出されて検査されますが、管理対象のAstraコントロールセンターにはインポートされません。</block>
  <block id="3c786ecd99f0ebd5edd64d81ad32375c" category="list-text">ONTAP クラスタをインポートするには、バックエンドに移動し、ドロップダウンをクリックして、管理対象のONTAP クラスタの横にあるManageを選択します。ONTAP クラスタの資格情報を入力し、 [ 情報の確認 ] をクリックして、 [ ストレージバックエンドのインポート ] をクリックします。</block>
  <block id="af64f63e0642401224fc8f9c2ec7d1c5" category="list-text">バックエンドを追加すると、ステータスが Available に変わります。これらのバックエンドには、Tanzu Kubernetesクラスタ内の永続ボリュームおよびONTAP システム上の対応するボリュームに関する情報が含まれるようになりました。</block>
  <block id="688cdc8b62507f4c74f7452e7889821d" category="list-text">Astra Control Centerを使用してTanzu Kubernetesクラスタ間でバックアップおよびリストアを実行するには、S3プロトコルをサポートするオブジェクトストレージバケットをプロビジョニングする必要があります。現在サポートされているオプションは、ONTAP S3、StorageGRID 、AWS S3、およびMicrosoft Azure Blob Storageです。このインストールのために、 AWS S3 バケットを設定します。バケットに移動し、バケットの追加をクリックして、汎用 S3 を選択します。S3バケットとクレデンシャルの詳細を入力してアクセスし、Make this Bucket the Default Bucket for the Cloud（このバケットをクラウドのデフォルトバケットにする）チェックボックスをオンにして、Add（追加）をクリックします。</block>
  <block id="f1b8312f03a9ec379a8e0fc00f20be33" category="paragraph"><block ref="f1b8312f03a9ec379a8e0fc00f20be33" category="inline-link-macro-rx"></block></block>
  <block id="9c5a4b54facfb25c9699e51ca3728574" category="summary">VMware Tanzu Kubernetesクラスタを登録したら、Astra Control Centerを使用して導入および管理されているアプリケーションを検出できます。</block>
  <block id="ada6daf9261af1429947be91dd72757b" category="paragraph">Tanzu Kubernetesクラスタを登録したら、Astra Control Centerを使用して導入および管理されているアプリケーションを検出できます。</block>
  <block id="48652ad0d003928f33825c84d5c8d950" category="list-text">Tanzu KubernetesクラスタとONTAP バックエンドがAstraコントロールセンターに登録されると、コントロールセンターは指定されたONTAP バックエンドで構成されたストレージクラスを使用しているすべてのネームスペース内のアプリケーションを自動的に検出します。</block>
  <block id="a013472d7ab7df6d0e423dbb7e238f7a" category="paragraph"><block ref="a013472d7ab7df6d0e423dbb7e238f7a" category="inline-link-macro-rx"></block></block>
  <block id="96b5419ab713b49685af4d923930ce22" category="summary">NetApp ONTAP ストレージシステムをiSCSI経由で永続ボリューム用のVMware Tanzu Kubernetesクラスタと統合するためには、まず各ノードにログインし、iSCSIボリュームをマウントするためのiSCSIユーティリティまたはパッケージを設定してノードを準備します。</block>
  <block id="da883967924519350a1c423bd85906dd" category="paragraph">NetApp ONTAP ストレージシステムをiSCSI経由で永続ボリューム用のVMware Tanzu Kubernetesクラスタと統合するには、まず各ノードにログインし、iSCSIボリュームをマウントするためのiSCSIユーティリティまたはパッケージを設定してノードを準備します。そのためには、この『手順 』に記載されている手順に従ってください <block ref="fb2092145032d18c9376d95ca453f9a7" category="inline-link-macro-rx"></block>。</block>
  <block id="50c35de69200a8b9e4be302372e74851" category="admonition">NATによるVMware Tanzu Kubernetesクラスタの導入には、この手順 は推奨されません。</block>
  <block id="bfc5022105ee1678e96b6f9991116647" category="admonition">TKGIは、変更不可の構成イメージを実行するTanzu Kubernetesクラスタのノードとして、Bosh VMを使用します。また、Bosh VMでiSCSIパッケージを手動で変更しても、リブート後も維持されません。そのため、TKGIによって導入、運用されているTanzu Kubernetesクラスタの永続ストレージにはNFSボリュームを使用することを推奨します。</block>
  <block id="16e4431f428a4ec8abdfbee6ec2c2889" category="paragraph">iSCSIボリュームのクラスタノードの準備が完了したら、ストレージシステムとの通信を可能にするバックエンドを作成する必要があります。この解決策 では基本的なバックエンドを設定しましたが、よりカスタマイズ可能なオプションを探している場合は、のドキュメントを参照してください <block ref="f151238ff3a8d488c82b6303d676eaa3" category="inline-link-macro-rx"></block>。</block>
  <block id="31cd969d7cf1970993d449ccccaeddfe" category="paragraph">ONTAP でSVMを作成するには、次の手順を実行します。</block>
  <block id="70d94c82da2765251783d499556773b7" category="list-text">SVMの名前を入力し、iSCSIプロトコルを有効にして、データLIFの詳細を指定します。</block>
  <block id="9305b9f7555d613129963713b0c214e6" category="image-alt">iSCSI SVMデータLIF</block>
  <block id="f9edece6d4cf48c209a5fe7da61f0ecb" category="list-text">SVM管理アカウントの詳細を入力し、保存をクリックします。</block>
  <block id="2b44a7a64e9a3efc0b4e423d6339aaa7" category="image-alt">iSCSI SVMの管理</block>
  <block id="f61c0f70e825557a7be7fe0ac432bdf7" category="list-text">アグリゲートをSVMに割り当てるには、Storage &gt; Storage VMに移動し、新しく作成したSVMの横にある省略記号をクリックしてEditをクリックします。ボリュームの作成を優先ローカル階層に制限するチェックボックスをオンにし、必要なアグリゲートを関連付けます。</block>
  <block id="74ede5d2e56e369e9eda54f4095292f5" category="list-text">バックエンドを作成したら、次にストレージクラスを作成する必要があります。次のストレージクラス定義の例では、必須フィールドと基本フィールドが強調表示されています。パラメータbackendTypeは'新しく作成されたTridentバックエンドのストレージ・ドライバを反映する必要がありますまた、名前フィールドの値もメモしておきます。この値は、以降の手順で参照する必要があります。</block>
  <block id="cf2c5963ca8332d4f43e6c3a955da4da" category="admonition">このファイルに定義されているオプションのフィールド「 fsType 」があります。iSCSIバックエンドでは、この値を特定のLinuxファイルシステムタイプ（XFS、ext4など）に設定するか、またはTanzu Kubernetesクラスタが使用するファイルシステムを決定できるようにするために削除できます。</block>
  <block id="af4fcf3aff174981414dc5c9fce2f4ec" category="section-title">アプリケーションスナップショットを作成します</block>
  <block id="29335406e75e8b137ee91c9f44068bc6" category="paragraph">アプリケーションのSnapshotコピーを作成すると、ONTAP Snapshotコピーとアプリケーションメタデータのコピーが作成されます。このコピーを使用して、アプリケーションを特定の時点の状態にリストアまたはクローニングできます。</block>
  <block id="9bb92323cd91f66cadcdc492341cddd5" category="section-title">アプリケーションのバックアップを作成します</block>
  <block id="c4c29bc3f7db6d04fde98415386e1e7f" category="list-text">アプリケーションを復元するには、[アプリ]&gt;[管理]タブに移動し、該当するアプリをクリックします。アプリケーション名の横にあるドロップダウンメニューをクリックし、[復元]をクリックします。</block>
  <block id="2c0d64177d5c89bc452e9f1eb0fd4f65" category="list-text">新しいネームスペースの詳細を入力し、クローニング先のクラスタを選択します。クローンを既存のSnapshotから作成するか、バックアップから作成するか、アプリケーションの現在の状態から作成するかを選択します。詳細を確認したら、[次へ]をクリックし、確認ペインの[複製]をクリックします。</block>
  <block id="ef0b684dddd1cea4885513d892f39cfa" category="paragraph"><block ref="ef0b684dddd1cea4885513d892f39cfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3901d4e16e17c29d42ccb430b94cc402" category="paragraph"><block ref="3901d4e16e17c29d42ccb430b94cc402" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62772f599e4130a9b43b483c82338681" category="summary">VMware Tanzuは、企業がアプリケーションおよび実行するインフラストラクチャを最新化できるようにする製品ポートフォリオです。VMware Tanzuの機能の完全なスタックにより、開発チームとIT運用チームが1つのプラットフォーム上に統合され、オンプレミスとハイブリッドクラウド環境全体でアプリケーションとインフラストラクチャの両方の最新化を一貫して活用し、継続的に優れたソフトウェアを本番環境に提供します。</block>
  <block id="969f4a20d38cf3096e1659b96da1b729" category="doc">VMware Tanzuの概要</block>
  <block id="c395793804bd9dfa82ff727781faf3c5" category="image-alt">VMware Tanzuポートフォリオ</block>
  <block id="3614585a8ed284306a5eadc9e31585b8" category="paragraph">Tanzuポートフォリオのさまざまなサービスとその機能の詳細については、ドキュメントを参照してください <block ref="e9fed892b98a6bbccfc15bfe67c5aa96" category="inline-link-macro-rx"></block>。</block>
  <block id="3ff60e0bc78c13ace612734741c1e1da" category="paragraph">TanzuのKubernetes Operationsカタログについて、VMwareはTanzu Kubernetes Gridのためのさまざまな実装を提供しています。これらはすべて、さまざまなプラットフォームでTanzu Kubernetesクラスタのライフサイクルをプロビジョニングおよび管理します。Tanzu Kubernetesクラスタは、VMwareによって構築およびサポートされる本格的なKubernetesディストリビューションです。</block>
  <block id="caaf1eb22b79381e3d4a2b2b9a7d1698" category="paragraph">ネットアップでは、VMware Tanzuポートフォリオに含まれる次の製品の導入と相互運用性について、ラボでテストを実施して検証しています。</block>
  <block id="0fe3792ebba34a6c12f05656d54ecb49" category="list-text"><block ref="0fe3792ebba34a6c12f05656d54ecb49" category="inline-link-macro-rx"></block></block>
  <block id="eac001284f9380ccf17ee4490dbe13e1" category="list-text"><block ref="eac001284f9380ccf17ee4490dbe13e1" category="inline-link-macro-rx"></block></block>
  <block id="d6a1da4b26eb2ae838f5db5e80c44aee" category="inline-link-macro">VMware Tanzu Kubernetes Grid Integrated（TKGI）</block>
  <block id="57729a0bf5ad457403cd6505bdfeb143" category="list-text"><block ref="57729a0bf5ad457403cd6505bdfeb143" category="inline-link-macro-rx"></block></block>
  <block id="aa7b3dace1453f21689852e3b066f673" category="summary">VMware Tanzu Kubernetes Grid Service（別名「Tanzu」）を使用すると、Tanzu KubernetesクラスタをvSphereでネイティブに作成および運用できます。また、一部の小規模なワークロードをESXiホストで直接実行することもできます。</block>
  <block id="b71ad38bc3fd2c1a10efc2b09270e430" category="doc">VMware Tanzu Kubernetes Grid Service（TKGS）の概要</block>
  <block id="9f0bacdd758242392df6d215d34d9b8e" category="paragraph">VMware Tanzu Kubernetes Grid Service（別名「Tanzu」）を使用すると、Tanzu KubernetesクラスタをvSphereでネイティブに作成および運用できます。また、一部の小規模なワークロードをESXiホストで直接実行することもできます。vSphereをプラットフォームに変換して、コンテナ化されたワークロードをハイパーバイザーレイヤでネイティブに実行できます。Tanzu Kubernetes Grid Serviceは、ワークロードに必要なクラスタを導入および運用することを有効にすると、vSphereにスーパーバイザクラスタを導入します。vSphere 7とネイティブに統合されており、vCenter SSO、コンテンツライブラリ、vSphereネットワーク、vSphereストレージ、vSphere HAおよびDRS、vSphereセキュリティなど、信頼性の高いvSphereの機能を活用して、Kubernetesのシームレスなエクスペリエンスを実現します。</block>
  <block id="6b25ac3e69375bd4a52dbffeb5c9cb14" category="paragraph">Tanzuを搭載したvSphereは、ハイブリッドアプリケーション環境向けの単一プラットフォームを提供します。このプラットフォームでは、コンテナ内またはVM内でアプリケーションコンポーネントを実行できるため、開発者、DevOpsエンジニア、およびvSphere管理者はより可視性が高く、運用が容易になります。VMware TKGSはvSphere 7環境でのみサポートされており、Tanzu Kubernetes運用ポートフォリオの中で、ESXiホストでポッドを直接実行できる唯一の製品です。</block>
  <block id="0e1d3327747a52bdd78d80247d5b6500" category="image-alt">VMware Tanzu Kubernetes Serviceの略</block>
  <block id="6e1adc41159b779c5ef1a0c9c934a673" category="paragraph">Tanzu Kubernetes Grid Serviceの詳細については、のドキュメントを参照してください <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>。</block>
  <block id="767b04965a47baa63782400d36a0c62e" category="paragraph">機能セットやネットワークなどに関するアーキテクチャ上の考慮事項は多数あります。選択したアーキテクチャによっては、Tanzu Kubernetes Grid Serviceの前提条件と導入プロセスが異なります。このガイドに従って、環境にTanzu Kubernetes Grid Serviceを導入および設定してください <block ref="5e5ad4985bdb8ab17883db4008c7c4a2" category="inline-link-macro-rx"></block>。さらに、TKGS経由で導入されたTanzu Kubernetesクラスタノードにログインするには、このに記載されている手順 に従ってください<block ref="7db41b551ba1165c4dfa4cf2d8a36e55" category="inline-link-rx"></block>。</block>
  <block id="46d890e88b951c5a84a444aad08079ae" category="paragraph">必要なワークロードの要件を満たすためには、ワーカーノードの構成を選択して、複数のマスター環境にすべての本番環境を導入してフォールトトレランスを実現することを推奨します。したがって、負荷の高いワークロードに推奨されるVMクラスには、少なくとも4つのvCPUと12GBのRAMがあります。</block>
  <block id="e8a4d3a2e07c429150e133b7fedebd64" category="paragraph">Tanzu Kubernetesクラスタがネームスペース内に作成されると、「owner」または「edit」権限を持つユーザは、ユーザアカウントを使用してポッドを任意のネームスペース内に直接作成できます。これは'所有者または編集権限を持つユーザーには'クラスタ管理者の役割が割り当てられているためですただし、展開、デーモンセット、ステートフルセット、またはその他の名前空間を作成する場合は、対応するサービスアカウントに必要な権限を持つロールを割り当てる必要があります。これは、展開またはデーモンセットがサービスアカウントを使用してポッドを展開するために必要です。</block>
  <block id="dc4ab077311e2aad5b5af968844fc5fe" category="paragraph">ClusterRoleBindingの次の例を参照して、クラスタ内のすべてのサービスアカウントにクラスタ管理者ロールを割り当てます。</block>
  <block id="5851271128193658704cec246f4fd21c" category="doc">ネットアップストレージ統合の概要</block>
  <block id="c21c42ee74a060038cdb9ea059b7702a" category="list-text"><block ref="c21c42ee74a060038cdb9ea059b7702a" category="inline-link-macro-rx"></block></block>
  <block id="bbf3919625853b65280d28c2d26004fd" category="list-text"><block ref="bbf3919625853b65280d28c2d26004fd" category="inline-link-macro-rx"></block></block>
  <block id="7c83f61ffb36cd4e6fa256ea9573bcff" category="inline-link-macro">次のステップ：ネットアップAstra Controlの概要</block>
  <block id="9fefc82351a3a2abfcae01d825253856" category="paragraph"><block ref="9fefc82351a3a2abfcae01d825253856" category="inline-link-macro-rx"></block></block>
  <block id="22a3cd730895fa6285f7ee2b7838bc34" category="list-text">Astra Control Centerをインストールする｛k8s_usercluster_name｝クラスタへの管理者アクセスがあるkubeconfigファイルを作成または取得します。</block>
  <block id="c67346d734cf1873532bdc9f9a1421da" category="list-text">仮想ワークロードとコンテナ化されたワークロードを同時に実行できます</block>
  <block id="71d00a17a6d603b0b4ebb168354950db" category="list-text">ワークロードのニーズに応じてインフラを個別に拡張できること</block>
  <block id="1722f248c3b6574ad844b53f30ac236c" category="sidebar">ネットアップを活用したVMware Tanzuの評価</block>
  <block id="c9fc26b21b932419e6f167a5ef97a61a" category="sidebar">VMware TanzuのWebサイト</block>
  <block id="8a22a6c667b205ca4e784c0364ccc5ea" category="sidebar">VMware TKG（Tanzu Kubernetes Grid）の概要</block>
  <block id="e5103defcbafcf380570238b4848f4a1" category="sidebar">VMware TKGS（Tanzu Kubernetes Grid Service）の概要</block>
  <block id="a2ec151aed88d77a34df663b329daf31" category="sidebar">VMware TKGI（Tanzu Kubernetes Grid Integrated Edition）の概要</block>
  <block id="e47703dd1fad3279269dda3b343b2272" category="sidebar">Tanzu Kubernetesクラスタを登録します</block>
  <block id="84f09994e75c5ede8e07c6ab4070faae" category="summary">このセクションでは、SwingbenchでシミュレーションしたOLTPワークロードのパフォーマンス検証とベンチマーク結果について詳しく説明します。</block>
  <block id="d9a4da5bae7f5f09fa9c3850a052c626" category="doc">パフォーマンス検証とベンチマーク結果</block>
  <block id="b944009da5cbc8c34fbaa084f3b1d385" category="inline-link-macro">Previous：Oracleデータベース管理。</block>
  <block id="2a07c9ef23ed37175e1063bb7d752c54" category="paragraph"><block ref="2a07c9ef23ed37175e1063bb7d752c54" category="inline-link-macro-rx"></block></block>
  <block id="4e71b9ce7d16c817e38c3c0b45825062" category="paragraph">このパフォーマンス検証の目的は、マークを設定しないことです。このドキュメントに記載されている導入手順とベストプラクティスに従っている場合は、パブリッククラウドに導入したOracleデータベースと同様のパフォーマンス指標を期待できます。</block>
  <block id="0215fc4537f81bbc2d6ff19ba75efeb5" category="paragraph">Swingbench Sales Order Entry（SOE）モジュールを使用してOLTPタイプのワークロードをシミュレートし、NFSプロトコル上のFSXストレージボリュームを備えたM5インスタンスに導入されたOracleデータベースにワークロードを適用しました。デフォルトのSwingbench SOE I/Oプロファイルは、80対20の読み取り/書き込みスプリットに近いため、実際のOLTP Oracleワークロード・プロファイルに近い環境に配置されています。</block>
  <block id="611831b4b814ffa8e208ff6b01e797d9" category="paragraph">このワークロードの値は、受注側で受注エントリ、参照、インベントリクエリなどを実行している同時ユーザ数を増やすことで増加します。テストした値は、同時ユーザ数が8、16、32、64、128であることが確認されています。Swingbenchアルゴリズムは、サーバ側での負荷が高く、適切なトランザクション・ボリュームのプッシュとOracleサーバの制限のテストに使用されています。同時に128人のユーザが作業する場合、EC2インスタンスのCPU利用率は約80~90%に達していることが確認されました。</block>
  <block id="a5cbb12f8f9f28c970230ab16d36e184" category="paragraph">以降のセクションでは、セットアップとテスト結果の詳細について説明します。</block>
  <block id="e018eaf806fedc0fa46d2acde6f60425" category="section-title">テスト環境のセットアップ</block>
  <block id="ff4adf700c0c4ba7e493af033a81ac29" category="paragraph">vCPU×8、32G RAM、ネットワーク帯域幅×10GのEC2 M5インスタンスを導入し、</block>
  <block id="2940f21a2cd7581a414576699c946a28" category="paragraph"><block ref="2940f21a2cd7581a414576699c946a28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5e18ca4731d9d72ae0bd4438c7e84b5" category="section-title">FSXストレージ</block>
  <block id="dc29ebaf5cc1f622aabb0ae70efeced6" category="paragraph">3つのデータベースボリュームを作成し、NFSを使用するボリュームをEC2インスタンスにマウントしました。その手順は次のとおりです。</block>
  <block id="829e4dfdaee315e0cfdba47e5047adf7" category="list-text">/u01 - Oracleバイナリ</block>
  <block id="5853f5304485ce536b44cd0dfb18bdbc" category="list-text">/u02 - Oracleデータ・ファイル、制御ファイル</block>
  <block id="ee6ac3c6792e507ea8c5717f79c8ab46" category="list-text">/u03 - Oracleログファイル、制御ファイル</block>
  <block id="363dd83f018d937efa507464961997c5" category="paragraph">冗長性を確保するために、重要な制御ファイルのコピーを2つ保持しました。</block>
  <block id="009187ce6b03d07047e46c6ed738f305" category="paragraph"><block ref="009187ce6b03d07047e46c6ed738f305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9c8184a7a7a9ecb63af93d93759b393" category="paragraph">FSXファイルシステムは、80、000 IOPS容量と2GiBpsのI/Oスループットで構成されています。</block>
  <block id="3570146db42993029d30dbd022107030" category="section-title">Oracle設定</block>
  <block id="9daecb8faf1751109e100894205a6aef" category="paragraph">Oracleバージョン19CとRUパッチ19.8をインストールしました。DNFSはサーバで有効になっています。</block>
  <block id="9041eebdfc5395440a43baff789c663b" category="paragraph">データベースは、3つのPDBを含むコンテナ化されたデータベースとして導入されました。パフォーマンステストには1つのPDBインスタンスを使用し、次の図に、NFSマウントポイントにおけるOracleストレージのサイジングを示します。</block>
  <block id="9ae30014c647d5fd5e38a292d1061810" category="paragraph"><block ref="9ae30014c647d5fd5e38a292d1061810" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8da929e8cdb57e8ea66260e3f7090d35" category="section-title">Swingbench構成</block>
  <block id="6af00d716d36ee74995307e004b66d3f" category="paragraph">vCPU 8基、RAM 32GのWindowsホストにSwingbench 2.6（最新バージョン）を導入しました。SOE psqlテストモジュールバージョン2をベンチマークに使用しました。デフォルトの負荷プロファイルは、80対20の読み取り/書き込み比率で、実際のOLTPトランザクションワークロードをシミュレートします。</block>
  <block id="5850fdbd1ed0c58b02c8d3797381e7c6" category="paragraph">使用したスキーマスケール係数は50で、最初のデータロードサイズは160G、一時的なスペース割り当ては30Gでした。この規模の要因では、SOEスキーマは、オンライン注文処理のシミュレーション用に1000の倉庫と50百万の顧客を提供しました。</block>
  <block id="9bc139569eaa30f1804b313d21ab69fa" category="paragraph">次のスクリーンショットは、Swingbench Windows UIでのワークロードのプロファイルと一般的なトランザクション実行に関する指標を示しています。</block>
  <block id="4da81979345d8adfb02c96de8993662a" category="paragraph"><block ref="4da81979345d8adfb02c96de8993662a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5531d1590836e811c3ace97db7e230eb" category="paragraph">このグラフが示すように、トランザクションレベルは、テスト実行中も同じレベルに維持されました。</block>
  <block id="6c805c8ead51e13766957cbda36fd2c0" category="section-title">テスト結果の分析</block>
  <block id="54f9f904b574caddc93a83f3057be251" category="paragraph">テストの実行ごとにSwingbenchの結果を取得し、パフォーマンス分析用に対応するOracle AWRレポートを取得しました。</block>
  <block id="9126019861ad7339333760b7b3bd5174" category="paragraph">エンドユーザ側から、トランザクションの量やユーザの応答時間など、主要な指標を確認しました。どちらの指標にも、システムにログインしている同時ユーザー数、およびユーザーが注文を入力した後にトランザクションを完了して応答を受信できる速度が示され、セールスオーダーエントリシステムから実行できるトランザクション数が示されています。</block>
  <block id="809217313025f03af0a774770ed7688d" category="paragraph">Oracleサーバの側から、Oracle AWRレポートを解析して、ユーザトランザクションの速度が低下した可能性のある上位の待機イベントを特定しました。トップ10のOracle待機イベントは、Swingbenchでトランザクション・テストをシミュレートした実行中、Oracleサーバはデータベース・ファイルのシーケンシャル・リードに費やされたデータベース時間の50%～60%を使用して、I/Oがほぼ制限されていることを示しています。ログ・ファイル同期は'データベースの時刻パーセンテージ・レベルの値が小さいにもかかわらず'トランザクションが原因 をバッファ・キャッシュからディスク上のログ・ファイルにログI/OをフラッシュするためのOracleログ処理をコミットするため'貢献要因でもあります</block>
  <block id="4da3501ef8d9ebc196009ef0bf4e4360" category="paragraph">トランザクションの実行中は、ユーザのトランザクションボリューム、ユーザの応答時間、Oracleの上位の待機状態のイベントを同時ユーザの数でグラフ化しました。結果は次のとおりです。</block>
  <block id="911fadede55cdf4e5db896695fd4f9c3" category="paragraph"><block ref="911fadede55cdf4e5db896695fd4f9c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b225219fb0a32b17f3f7f3964edfa599" category="paragraph">この結果から、同時ユーザ数を増加させてユーザトランザクションボリュームを安定的に拡張する一方で、I/Oレイテンシとユーザ応答時間は一定して低く抑えることができ、これはOracleアプリケーションのパフォーマンスとして適切です。</block>
  <block id="ccc7b98ab0c81e5b7e4033e88910e92e" category="paragraph">同時ユーザ数が128に達した時点で、I/Oレイテンシとユーザ応答時間は幾分増加し始めました。次の図に示すように、EC2インスタンスがサーバの最大容量に近づいているため、この状況が想定されます。</block>
  <block id="0cc8a57e10ae7e4e152d74423527f2f0" category="paragraph"><block ref="0cc8a57e10ae7e4e152d74423527f2f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faf8392c1e8a1c488f303b45f48fd31d" category="paragraph">同様に、次の図は、この時点でユーザトランザクションボリュームを処理している場合の、対応するFSXのIOPSとスループットを示しています。</block>
  <block id="a18559304ff06a743412352fbfb82b00" category="paragraph"><block ref="37451e9b66358e4a66c6a1b882f378a1" category="inline-image-macro-rx" type="image"></block>
<block ref="b0d8c670dcd70932cfb6876c97b62036" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d8430502705720b257f565ec9140e72" category="inline-link-macro">Oracleデータベースの導入で考慮すべき要素。</block>
  <block id="b25a4c32c9b6cc39890fa799e15301dc" category="paragraph">OracleサーバEC2インスタンスが制限要因となった場合、プロビジョニングされたFSXストレージ容量にIOPSまたはスループットが到達しませんでした。したがって、で説明するように、ユーザアプリケーションレベルのトランザクションボリュームに基づいて、コンピューティングとストレージのサイズを適切に設定する必要があります <block ref="fa519ff010063f0b425f11c556e4445d" category="inline-link-macro-rx"></block></block>
  <block id="fefc87f11b675de356ca673f3a346ac7" category="inline-link-macro">次：データベースの移行：</block>
  <block id="8996ba3a1cc79692db90ae4be7ef8dd3" category="paragraph"><block ref="8996ba3a1cc79692db90ae4be7ef8dd3" category="inline-link-macro-rx"></block></block>
  <block id="20da1f90c59ba57d043ded8994bb7619" category="summary">このセクションでは、RDSとFSX ONTAP ストレージをカスタマイズした解決策 のカスタム導入アーキテクチャを説明します。</block>
  <block id="c739a7ae4891c6665d1f2f715d2efa3f" category="paragraph"><block ref="c739a7ae4891c6665d1f2f715d2efa3f" category="inline-link-macro-rx"></block></block>
  <block id="ca449b8ca808c6d325abf6b1a047318c" category="paragraph">次のアーキテクチャ図は、FSXストレージサービスを使用したAWS EC2インスタンスへの可用性の高いOracleデータベースの導入を示しています。同様の導入方式ですが、別のリージョンにスタンバイがある場合は、ディザスタリカバリ用に設定できます。</block>
  <block id="a0cdfa3b119f53b827ebc38a9519b32d" category="paragraph">環境内では、OracleコンピューティングインスタンスはAWS EC2インスタンスコンソールを介して導入されます。コンソールから複数のEC2インスタンスタイプを使用できます。ネットアップでは、データベース指向のEC2インスタンスタイプ（RedHat Enterprise Linux 8を使用したm5 Amiイメージや最大10Gpsのネットワーク帯域幅など）を導入することを推奨しています。</block>
  <block id="228488653f80c4dfe7bd79d5f9634ea4" category="paragraph">一方、FSXボリューム上のOracleデータベースストレージは、AWS FSXコンソールまたはCLIとともに導入されます。その後、Oracleバイナリ、データ、またはログのボリュームが提供され、EC2インスタンスのLinuxホストにマウントされます。各データボリュームまたはログボリュームには、採用するストレージプロトコルに応じて複数のLUNを割り当てることができます。</block>
  <block id="736415956026dd8a803e8e2f7c5f0f42" category="paragraph"><block ref="736415956026dd8a803e8e2f7c5f0f42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0537fe1ac97a9f2e83612f0789e84585" category="paragraph">FSXストレージ・クラスタは'二重の冗長性を備えて設計されているため'プライマリ・ストレージ・クラスタとスタンバイ・ストレージ・クラスタの両方が2つの異なるアベイラビリティ・ゾーンに配置されますデータベース・ボリュームは'すべてのOracleバイナリ'データ'およびログ・ボリュームに対して'ユーザーが構成可能な間隔で'プライマリFSXクラスタからスタンバイFSXクラスタに複製されます</block>
  <block id="7a9829ab1a28b0d6ca9ddaee5874655a" category="paragraph">この高可用性Oracle環境は、AnsibleコントローラノードとSnapCenter バックアップサーバおよびUIツールで管理されます。Oracleのインストール、設定、レプリケーションは、Ansibleプレイブックベースのツールキットを使用して自動化されています。Oracle EC2インスタンスカーネルのオペレーティングシステムまたはOracleパッチ適用に対するすべての更新を並行して実行することで、プライマリとスタンバイを同期させることができます。実際、初期の自動化セットアップを簡単に拡張して、必要に応じて日々のOracleタスクを何度も実行することができます。</block>
  <block id="be571c48040d6c3bf764ba40188888d2" category="paragraph">SnapCenter では、Oracleデータベースのポイントインタイムリカバリや、必要に応じてプライマリゾーンまたはスタンバイゾーンでのデータベースクローニングのワークフローを提供しています。SnapCenter UIを使用して'OracleデータベースのバックアップとスタンバイFSXストレージへのレプリケーションを構成し'RTO（目標復旧時間）またはRPO（目標復旧時間）に基づいて高可用性または災害復旧を実現できます</block>
  <block id="be22c0b35f58a932be14c9e55b163ac4" category="paragraph">解決策 は、Oracle RACおよびData Guardの導入と同様の機能を提供する代替プロセスを提供します。</block>
  <block id="72db8e2a11aee3fd6b5ea401c9adcbd6" category="inline-link-macro">次の手順：導入手順</block>
  <block id="6487ec60d16ab8bf4ce0aa7ebaf86b4f" category="paragraph"><block ref="6487ec60d16ab8bf4ce0aa7ebaf86b4f" category="inline-link-macro-rx"></block></block>
  <block id="f3b25b37995dab3a1b6c753dd74ca21e" category="summary">このセクションでは、AWS RDSコンソールUIに加え、SnapCenter UIを使用してOracleデータベース用のAWS RDSカスタムを管理する方法を詳しく説明します。</block>
  <block id="021f869e266a6eaa7e446e54dfc71149" category="doc">EC2/FSX Oracleデータベース管理</block>
  <block id="39ebdf3133bce223758100b117a98e70" category="inline-link-macro">前の手順：導入手順</block>
  <block id="cac2d984db56d4f9cd9b1f85b3cf0c5c" category="paragraph"><block ref="cac2d984db56d4f9cd9b1f85b3cf0c5c" category="inline-link-macro-rx"></block></block>
  <block id="cf8b301cbf8aa698c578ff1f8e64ccc2" category="paragraph">このOracle環境では、AWS EC2とFSXの管理コンソールに加え、Ansible制御ノードとSnapCenter UIツールを使用してデータベースを管理できます。</block>
  <block id="ab1b9a020f08729c00ecee14e5a3be69" category="paragraph">Ansibleコントロールノードを使用してOracle環境構成を管理できます。また、カーネルやパッチの更新のためにプライマリインスタンスとスタンバイインスタンスを同期させる並行アップデートを使用できます。NetApp Automation Toolkitを使用すると、フェイルオーバー、再同期、フェイルバックを自動化して、Ansibleでアプリケーションの高速リカバリと可用性をアーカイブできます。繰り返し可能なデータベース管理タスクには、プレイブックを使用して人為的ミスを減らすことができます。</block>
  <block id="53bd53a68bce8fe697a7455feae3861b" category="inline-link-macro">SnapCenter Plug-in for Oracle Databaseの概要</block>
  <block id="8dad283458f149f04a674f7c674818ed" category="paragraph">SnapCenter UIツールでは、Oracleデータベース用のSnapCenter プラグインを使用して、データベースSnapshotのバックアップ、ポイントインタイムリカバリ、データベースクローニングなどを実行できます。Oracleプラグイン機能の詳細については、を参照してください <block ref="053f091ffb001fc31a47d30bc3d11350" category="inline-link-macro-rx"></block>。</block>
  <block id="c165a519b858dc997da23262308d6463" category="paragraph">以下のセクションでは、SnapCenter UIを使用して、Oracleデータベース管理の主な機能を実行する方法について詳しく説明します。</block>
  <block id="95154aa7c50b812d3683b6995bed8771" category="list-text">データベースSnapshotバックアップ</block>
  <block id="b055b8a9cd44d5f8e1fa330c20aa1dc3" category="list-text">データベースのポイントインタイムリストア</block>
  <block id="20f913ca57379280e5f37dce9cd0de61" category="list-text">データベースクローンの作成</block>
  <block id="e724243c3ef9e2c58168b76f3f537412" category="paragraph">データベースクローニングでは、論理データのエラーや破損が発生した場合にデータをリカバリするために、別のEC2ホストにプライマリデータベースのレプリカが作成されます。また、クローンを使用して、アプリケーションのテスト、デバッグ、パッチ検証を行うこともできます。</block>
  <block id="418768c00fe9ab38a23d8417250d676b" category="section-title">Snapshotを取得しています</block>
  <block id="c018c634b9245f8522eaf32d3fffaa7a" category="paragraph">EC2/FSX Oracleデータベースは、ユーザが設定した間隔で定期的にバックアップされます。ユーザは、Snapshotバックアップを一度に作成することもできます。この環境 では、フルデータベースのSnapshotバックアップとアーカイブログのみのSnapshotバックアップの両方が作成されます。</block>
  <block id="0a1758b0d7a64bf446ccd6c9ea2a559d" category="section-title">フルデータベーススナップショットを取得しています</block>
  <block id="6aa82df330acc0ad1c1859bf7d19d8c6" category="paragraph">フルデータベーススナップショットには、データファイル、制御ファイル、アーカイブログファイルなど、すべてのOracleファイルが含まれます。</block>
  <block id="71a81fc61b4bde806ab23dbb0dff87ab" category="list-text">SnapCenter UIにログインし、左側のメニューでResources（リソース）をクリックします。Viewドロップダウンから、Resource Groupビューに移動します。</block>
  <block id="097f9e0f1d7d03a8b8db3110da618df1" category="paragraph"><block ref="097f9e0f1d7d03a8b8db3110da618df1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a16fe4e102f4f80c9a0ebe875e00921" category="list-text">フル・バックアップ・リソース名をクリックし、[今すぐバックアップ]アイコンをクリックして、追加バックアップを開始します。</block>
  <block id="b157c6d0dbf1f6fc8e66e048cdf587dc" category="paragraph"><block ref="b157c6d0dbf1f6fc8e66e048cdf587dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c41836f211ec5f0aee4024039682c6d3" category="list-text">[バックアップ]をクリックし、バックアップを確定して、フル・データベース・バックアップを開始します。</block>
  <block id="de38ecf82e29f57be2cb258095500ffc" category="paragraph"><block ref="de38ecf82e29f57be2cb258095500ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5114009902f821226811cd39b519e8ae" category="paragraph">データベースの[リソース]ビューで、[データベース管理バックアップコピー]ページを開いて、一度限りのバックアップが正常に完了したことを確認します。フルデータベースバックアップでは、データボリューム用とログボリューム用の2つのSnapshotが作成されます。</block>
  <block id="23c2c3d9fc4ea06c4f1744caa77dd75f" category="paragraph"><block ref="23c2c3d9fc4ea06c4f1744caa77dd75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc2bc8e691b80fc2b94cd487cd59a41e" category="section-title">アーカイブログのSnapshotを取得しています</block>
  <block id="c2a2cc866aaa30cb6344e65c853429a7" category="paragraph">アーカイブログのSnapshotは、Oracleアーカイブログボリュームに対してのみ作成されます。</block>
  <block id="973f07a93ca1636baa391407a84cb38b" category="list-text">SnapCenter UIにログインし、左側のメニューバーにある[Resources]タブをクリックします。Viewドロップダウンから、Resource Groupビューに移動します。</block>
  <block id="47f0395291ce13022063147f4981f69f" category="list-text">ログバックアップリソース名をクリックし、[今すぐバックアップ]アイコンをクリックして、アーカイブログの追加バックアップを開始します。</block>
  <block id="1417f1fbdcb104994815efb345497300" category="paragraph"><block ref="1417f1fbdcb104994815efb345497300" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8ee5a2ad5f43fcd955b6b30854d2f98" category="list-text">Backupをクリックしてバックアップを確定し、アーカイブログのバックアップを開始します。</block>
  <block id="03cb3b3b0da0531d726d5e6b4af1920c" category="paragraph"><block ref="03cb3b3b0da0531d726d5e6b4af1920c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40cffcacb55d81916f38114aac845d4b" category="paragraph">データベースの[リソース]ビューで、[データベース管理バックアップコピー]ページを開き、1回限りのアーカイブログバックアップが正常に完了したことを確認します。アーカイブログバックアップでは、ログボリューム用のSnapshotが1つ作成されます。</block>
  <block id="01422619a982004bea1ad1e237269525" category="paragraph"><block ref="01422619a982004bea1ad1e237269525" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e16045e122b02913b74ef1e8bd29d75c" category="section-title">特定の時点へのリストア</block>
  <block id="7d2260465121189e3f5aef56d1734e86" category="paragraph">SnapCenterベースのリストアを同じEC2インスタンスホストで実行すると、ある時点までのリストアが実行されます。リストアを実行するには、次の手順を実行します。</block>
  <block id="52443d446e6aa795d8e3a08e581684cb" category="list-text">SnapCenter リソースタブのデータベースビューで、データベース名をクリックしてデータベースバックアップを開きます。</block>
  <block id="51d148134901f85184886bb72062b2a0" category="paragraph"><block ref="51d148134901f85184886bb72062b2a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bc3aa5bd0c870df97abdd69ef227826" category="list-text">データベースのバックアップコピーおよびリストアするポイントインタイムを選択します。また、ポイントインタイムに対応するSCN番号もマークダウンします。ポイントインタイムリストアは、時間またはSCNを使用して実行できます。</block>
  <block id="f4a16324772958025bfa77d2ed8af61e" category="paragraph"><block ref="f4a16324772958025bfa77d2ed8af61e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acee7bbe553399023f78a7ac814d7a94" category="list-text">ログボリュームのSnapshotを選択し、マウントボタンをクリックしてボリュームをマウントします。</block>
  <block id="b068acd736c964d27b5833d30c220f7c" category="paragraph"><block ref="b068acd736c964d27b5833d30c220f7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d06beb2a91e58c7e57367e901abc09fd" category="list-text">ログボリュームをマウントするプライマリEC2インスタンスを選択します。</block>
  <block id="94bf51064baf8263a5c7e0d6dba0f38a" category="paragraph"><block ref="94bf51064baf8263a5c7e0d6dba0f38a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f83a9f884d94d22d3c52d510a051ac90" category="list-text">マウントジョブが正常に完了したことを確認します。また、EC2インスタンスホストで、そのログボリュームがマウントされていること、およびマウントポイントパスを確認します。</block>
  <block id="53044f6472847053eea58f6f40258b7c" category="paragraph"><block ref="01717ad5eefdb68ab0f128386310e509" category="inline-image-macro-rx" type="image"></block>
<block ref="684c418b818adf3876d8fd9877edd90f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12a7a64116d859fb64b3f841a43e6fac" category="list-text">マウントされたログボリュームから現在のアーカイブログディレクトリにアーカイブログをコピーします。</block>
  <block id="f57c6961965ccab84762e9b4bbdd72f0" category="list-text">SnapCenter リソースタブ&gt;データベースバックアップページに戻り、データSnapshotコピーを強調表示し、復元ボタンをクリックしてデータベースリストアワークフローを開始します。</block>
  <block id="eb283dcbcce9c21f038d1985c87645da" category="paragraph"><block ref="eb283dcbcce9c21f038d1985c87645da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a08ce545f0f81946ee65326ff4608df" category="list-text">[すべてのデータファイル]および[リストアとリカバリに必要な場合はデータベースの状態を変更する]をオンにして、[次へ]をクリックします。</block>
  <block id="c53b030895e9cee782d7dfcea4a679ad" category="paragraph"><block ref="c53b030895e9cee782d7dfcea4a679ad" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e589c1295b0849053e2d8cc2bbf96a1e" category="list-text">SCNまたは時刻を使用して、目的のリカバリ範囲を選択します。手順6で説明したように、マウントされたアーカイブログを現在のログディレクトリにコピーする代わりに、マウントされたアーカイブログのパスを「リカバリのための外部アーカイブログファイルの場所の指定」に記載できます。</block>
  <block id="12bfd26a9c7f1551fe3664e25975f022" category="paragraph"><block ref="12bfd26a9c7f1551fe3664e25975f022" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f3b533a6c9cd757a311b56318115bbe" category="list-text">必要に応じて実行するプリスクリプトをオプションで指定します。</block>
  <block id="0c61f73092ad29b6a823f67f23872ffb" category="paragraph"><block ref="0c61f73092ad29b6a823f67f23872ffb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16a70e704c6e5104eff1adca9f951c36" category="list-text">必要に応じて、オプションのアフタースクリプトを指定して実行します。リカバリ後に開いているデータベースを確認します。</block>
  <block id="5e5add6f904fa1973ca9f5564c87bdab" category="paragraph"><block ref="5e5add6f904fa1973ca9f5564c87bdab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="975952869f93fd5cb45acf8a19b97834" category="list-text">ジョブ通知が必要な場合は、SMTPサーバとEメールアドレスを指定します。</block>
  <block id="125beea11cb628a2850a9c3b01628d3b" category="paragraph"><block ref="125beea11cb628a2850a9c3b01628d3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f92d4c842e7343ab2f69eac4e3561bc" category="list-text">ジョブの概要をリストア[終了]をクリックして、リストア・ジョブを起動します。</block>
  <block id="0dac703b5b68b8ce38eae7f7224a3de3" category="paragraph"><block ref="0dac703b5b68b8ce38eae7f7224a3de3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e783d4afe611873ddc32a5a59ff2078" category="list-text">SnapCenter からのリストアを検証します。</block>
  <block id="7cc0ed8d8b03fe709b0d004e75183201" category="paragraph"><block ref="7cc0ed8d8b03fe709b0d004e75183201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6e8e06b3f3e03bdb3391888df78e46" category="list-text">EC2インスタンスホストからリストアを検証します。</block>
  <block id="06adcc9a574fcfaa717309c54d0fc7e9" category="paragraph"><block ref="06adcc9a574fcfaa717309c54d0fc7e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="983d6ea8d6962c3e0f9abef0c4c948f4" category="list-text">リストア・ログ・ボリュームをアンマウントするには、手順4と逆の手順を実行します。</block>
  <block id="ca0c306ba98701576c42d241b48d4038" category="section-title">データベースクローンを作成しています</block>
  <block id="a8bd304fe0995bcddba8dd93a8d447a6" category="paragraph">次のセクションでは、SnapCenter クローンワークフローを使用して、プライマリデータベースからスタンバイEC2インスタンスへのデータベースクローンを作成する方法について説明します。</block>
  <block id="91956afde8e3bc7ac47e37b9821ca6f9" category="list-text">フルバックアップリソースグループを使用して、SnapCenter からプライマリデータベースのフルSnapshotバックアップを作成します。</block>
  <block id="023d426483e83bc3abf204154e323eba" category="paragraph"><block ref="023d426483e83bc3abf204154e323eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b08a0a4966d6a40934f84e0367df5124" category="list-text">SnapCenter リソースタブのデータベースビューで、レプリカの作成元のプライマリデータベースのデータベースバックアップ管理ページを開きます。</block>
  <block id="f14aaf01a42159b842a496f880063869" category="paragraph"><block ref="f14aaf01a42159b842a496f880063869" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b265d526ea8d86f13a3ee5b3df11ce5" category="list-text">手順4で作成したログボリュームSnapshotを、スタンバイEC2インスタンスホストにマウントします。</block>
  <block id="160b6f6b07db1490de7e1252e8f6ec84" category="paragraph"><block ref="074cfbf53cae79233eac44ac8a4aa5f8" category="inline-image-macro-rx" type="image"></block>
<block ref="a75c3f795382693108f8d772396f248b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15c2865196d70f81dd791b3329d2604e" category="list-text">レプリカ用にクローンを作成するスナップショットコピーをハイライト表示し、[クローン]ボタンをクリックしてクローン手順 を起動します。</block>
  <block id="568f30b58394b2e0d4e795beb731c0eb" category="paragraph"><block ref="568f30b58394b2e0d4e795beb731c0eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ebc0e83f8e5d02518da0756a18aaab4" category="list-text">レプリカコピー名を変更して、プライマリデータベース名とは異なる名前にします。次へをクリックします。</block>
  <block id="b77619cc2b53d1b603e6051036b122b6" category="paragraph"><block ref="b77619cc2b53d1b603e6051036b122b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ba0975a31e144349d50f09393a5ca21" category="list-text">クローンホストをスタンバイEC2ホストに変更し、デフォルトの名前を受け入れて、Nextをクリックします。</block>
  <block id="d39fd3bd4059fb775d174eef3e53919b" category="paragraph"><block ref="d39fd3bd4059fb775d174eef3e53919b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eeda8df21c3391dcc7a327cfec8f8704" category="list-text">Oracleホームの設定をターゲットOracleサーバーホスト用に構成された設定に合わせて変更し、次へをクリックします。</block>
  <block id="8cb5c7c55cf01620e1eaae0dd817ad2c" category="paragraph"><block ref="8cb5c7c55cf01620e1eaae0dd817ad2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f10b26890bad0f92387ad2c8efb9b532" category="list-text">時刻またはSCNとマウントされたアーカイブログのパスを使用して、リカバリポイントを指定します。</block>
  <block id="9d2a5645a731a8a3af7ee677133ba312" category="paragraph"><block ref="9d2a5645a731a8a3af7ee677133ba312" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684abeacd08eb59922d70d928ce47f45" category="list-text">必要に応じてSMTP Eメール設定を送信します。</block>
  <block id="84bb684b488190f680f548303196f5b9" category="paragraph"><block ref="84bb684b488190f680f548303196f5b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2cc0c6ba26bdf7b30e39313a0ad4098" category="list-text">ジョブの概要を複製し、[完了]をクリックしてクローンジョブを起動します。</block>
  <block id="3461ca6663823ff26ef7d3121d8592c7" category="paragraph"><block ref="3461ca6663823ff26ef7d3121d8592c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5cd909b2ce2e22f0bb8734426ea9e9a" category="list-text">クローンジョブログを確認して、レプリカクローンを検証します。</block>
  <block id="c6c9a361716f3695e5f582cbbaf857f6" category="paragraph"><block ref="c6c9a361716f3695e5f582cbbaf857f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66a858d0c53f7ecef6ff665372a428c5" category="paragraph">クローニングされたデータベースは、ただちにSnapCenter に登録されます。</block>
  <block id="8fc5846614431a858445f7c55fe6f8bf" category="paragraph"><block ref="8fc5846614431a858445f7c55fe6f8bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9b70fde27d9d03d393dc2fd619546988" category="list-text">Oracleアーカイブログモードをオフにします。OracleユーザとしてEC2インスタンスにログインし、次のコマンドを実行します。</block>
  <block id="ca1a9785bb111fcadc4527aae18f822d" category="admonition">プライマリOracleバックアップコピーの代わりに、複製されたセカンダリバックアップコピーから同じ手順でクローンをターゲットFSXクラスタに作成することもできます。</block>
  <block id="2a75f5115dab8b39875560a4d7252d2f" category="section-title">スタンバイおよび再同期へのHAフェイルオーバー</block>
  <block id="f5bc6d05191457096f9da00e0fa56d40" category="paragraph">スタンバイのOracle HAクラスタは、コンピューティングレイヤまたはストレージレイヤのいずれかで、プライマリサイトで障害が発生した場合に高可用性を提供します。解決策 の大きな利点の1つは、ユーザがいつでも、または頻度を問わずにインフラをテストおよび検証できることです。フェイルオーバーは、ユーザがシミュレートすることも、実際の障害によってトリガーすることもできます。フェイルオーバープロセスは同一であり、アプリケーションのリカバリを高速化するために自動化できます。</block>
  <block id="6775249aa36196ee3d9c71774992f2c4" category="paragraph">次のフェイルオーバー手順を参照してください。</block>
  <block id="eb171dc2d1f739dfee2e358326abd0e9" category="list-text">フェイルオーバーをシミュレートするには、ログスナップショットバックアップを実行して、最新のトランザクションをスタンバイサイトにフラッシュします。詳細については、を参照してください <block ref="58f2fe5f16b910e6ad4f8b3f8679e256" category="inline-xref-macro-rx"></block>。実際の障害によってトリガーされたフェイルオーバーでは、最後にリカバリ可能なデータが、スケジュールされたログボリュームのバックアップが最後に成功した時点でスタンバイサイトにレプリケートされます。</block>
  <block id="abdc57f5efdfeac30fe822d9eda2fc9f" category="list-text">プライマリとスタンバイのFSXクラスタ間のSnapMirrorを解除します。</block>
  <block id="bd54ae4d51454c6a89990f066be03d35" category="list-text">複製されたスタンバイデータベースボリュームをスタンバイEC2インスタンスホストにマウントします。</block>
  <block id="588698147b1d63f4f9f6d78dd8d83595" category="list-text">複製されたOracleバイナリをOracleリカバリに使用する場合は、Oracleバイナリを再リンクします。</block>
  <block id="0f1ac3f743fcb2d14875c7a731c3d251" category="list-text">スタンバイOracleデータベースを、最後に使用可能なアーカイブログにリカバリします。</block>
  <block id="ab933bdc7c043f4a3c977049791f0640" category="list-text">アプリケーションおよびユーザアクセス用のスタンバイOracleデータベースを開きます。</block>
  <block id="6928cb13e9136438c86e16b724b3b64f" category="list-text">実際のプライマリサイト障害では、スタンバイOracleデータベースが新しいプライマリサイトの役割を担い、データベースボリュームを使用して、リバースSnapMirror方式で障害が発生したプライマリサイトを新しいスタンバイサイトとして再構築できます。</block>
  <block id="13e25eed8fa423975f854101e3be1e89" category="list-text">プライマリサイトのテストまたは検証の失敗をシミュレートするには、テストの完了後にスタンバイOracleデータベースをシャットダウンします。次に、スタンバイEC2インスタンスホストからスタンバイデータベースボリュームをアンマウントし、プライマリサイトからスタンバイサイトにレプリケーションを再同期します。</block>
  <block id="c3fd0f78855e219b0fd44077ce74e7b5" category="paragraph">これらの手順は、NetApp Automation Toolkitを使用して実行できます。このツールキットは、パブリックのNetApp GitHubサイトからダウンロードできます。</block>
  <block id="ba4d6e5d6eeea04cdc5a4f243b1e5dd8" category="paragraph">セットアップとフェイルオーバーのテストを行う前に、READMEの手順をよくお読みください。</block>
  <block id="7d34df46082e5771e092eb8736597ee0" category="summary">このセクションでは、FSXストレージを使用してOracle RDSカスタムデータベースを導入する手順について説明します。</block>
  <block id="b8a2bfa78779af1958bed97119657167" category="doc">AWS EC2/FSXでのOracleの導入手順をステップバイステップで説明します</block>
  <block id="072a1cb4963593f78b428b4c9a0dcc4f" category="inline-link-macro">以前のバージョン：解決策 アーキテクチャ。</block>
  <block id="ef081c8f35bca2da08c6dbdd6f48a6cd" category="paragraph"><block ref="ef081c8f35bca2da08c6dbdd6f48a6cd" category="inline-link-macro-rx"></block></block>
  <block id="f70ec60e40ece5900605229a28081b13" category="section-title">EC2コンソールを使用して、OracleのEC2 Linuxインスタンスを導入します</block>
  <block id="03d6d2463e27b63c2d7f7ad0e62697af" category="paragraph">AWSを初めて使用する場合は、最初にAWS環境をセットアップする必要があります。AWS Webサイトのランディングページのドキュメントタブには、AWS EC2コンソールでOracleデータベースをホストするために使用できるLinux EC2インスタンスの導入方法に関するEC2指示のリンクが用意されています。次のセクションでは、これらの手順を簡単に説明します。詳細については、リンクされたAWS EC2固有のドキュメントを参照してください。</block>
  <block id="e1fc23220db46fe659667702f62b75e4" category="section-title">AWS EC2環境をセットアップします</block>
  <block id="6d0669826a2bd6e9eb35ea7e89cbe3f4" category="paragraph">EC2およびFSXサービスでOracle環境を実行するために必要なリソースをプロビジョニングするには、AWSアカウントを作成する必要があります。必要な詳細については、次のAWSのマニュアルを参照してください。</block>
  <block id="2966cbe914210fb4f4a3e5fe6adf4762" category="inline-link-macro">Amazon EC2を使用するように設定します</block>
  <block id="1e4a01fe43fb3542c08649e20440f5f1" category="list-text"><block ref="1e4a01fe43fb3542c08649e20440f5f1" category="inline-link-macro-rx"></block></block>
  <block id="df6ca3590d3bec198846463f0ef1c6a8" category="paragraph">主なトピック：</block>
  <block id="74122bb32fc969b565a8b132d4178581" category="list-text">AWSに登録する</block>
  <block id="fe536eddec5cc1d661347011844ba132" category="list-text">キーペアを作成します。</block>
  <block id="6582688edf89986f408a52095794f65b" category="list-text">セキュリティグループを作成します。</block>
  <block id="c78747962ae12e635749aa6b08a4da09" category="section-title">AWSアカウント属性で複数のアベイラビリティゾーンを有効にする</block>
  <block id="2d5ade6857f59cf6d198344d5049da40" category="paragraph">アーキテクチャ図に示されているOracleのハイアベイラビリティ構成については、リージョン内の少なくとも4つのアベイラビリティゾーンを有効にする必要があります。また、ディザスタリカバリに必要な距離を満たすために、複数のアベイラビリティゾーンを異なるリージョンに配置することもできます。</block>
  <block id="b6067af8a0645a7009ccfb45c5271f1e" category="paragraph"><block ref="b6067af8a0645a7009ccfb45c5271f1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8faa9e48d0380a023114890a62861d0f" category="section-title">OracleデータベースをホストするEC2インスタンスを作成して接続します</block>
  <block id="82499151e189f9313aa1450e912f4ffd" category="inline-link-macro">Amazon EC2 Linuxインスタンスを使用する</block>
  <block id="822fd31d54c32c4886e9010d12a8dce7" category="paragraph">チュートリアルを参照してください <block ref="6d0a9d65d170226042c573685041d5e9" category="inline-link-macro-rx"></block> 詳細な導入手順とベストプラクティスについては、を参照してください。</block>
  <block id="a15c0d1773407cc677a49f4cc169a63c" category="list-text">概要（Overview）：</block>
  <block id="4d99c712f714ff14ae3b251667dda4b2" category="list-text">前提条件</block>
  <block id="67b035efef4b92412bb7a8a903121da6" category="list-text">手順1：インスタンスを起動します。</block>
  <block id="6640566c783363c8a66fe226c2a7227b" category="list-text">手順2：インスタンスに接続します。</block>
  <block id="c271b00c470f8a1fb17c05dc6092d9af" category="list-text">手順3:インスタンスをクリーンアップします。</block>
  <block id="9e0cd4f11314aeaa31fce7e3f5960c4c" category="paragraph">次のスクリーンショットは、Oracleを実行するEC2コンソールを使用したm5タイプのLinuxインスタンスの導入を示しています。</block>
  <block id="993b6250c7c69b01670a8165c0cf949d" category="list-text">EC2ダッシュボードで、黄色のLaunch Instanceボタンをクリックして、EC2インスタンス導入ワークフローを開始します。</block>
  <block id="37266a1d594801e15c8f2a455a3ea854" category="paragraph"><block ref="37266a1d594801e15c8f2a455a3ea854" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71a4046454ceb8a1793ee0cfa14dc581" category="list-text">手順1で、「Red Hat Enterprise Linux 8（HVM）」、「SSD Volume Type-AMI-0b0af3577fe5e3532（64ビットx86）/AM-01fc429821bf1f4b4（64ビットARM ）」を選択します。</block>
  <block id="755d0918a7bfcbc1b7541acd1235598e" category="paragraph"><block ref="755d0918a7bfcbc1b7541acd1235598e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5956dcc5f6331fe980094b6ddba4650c" category="list-text">手順2で、Oracleデータベースのワークロードに基づいて適切なCPUとメモリの割り当てを持つm5インスタンスタイプを選択します。[次へ：インスタンスの詳細を構成]をクリックします。</block>
  <block id="55898408b090c35ed97aede8b9893299" category="paragraph"><block ref="55898408b090c35ed97aede8b9893299" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302a3b9b8b1d7dfc842dbfcaa5468b1a" category="list-text">手順3で、インスタンスを配置するVPCとサブネットを選択し、パブリックIPの割り当てを有効にします。[次へ：ストレージの追加]をクリックします。</block>
  <block id="86ec5cd603e5f7341f3f213d5b660cbb" category="paragraph"><block ref="86ec5cd603e5f7341f3f213d5b660cbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e421be5ecc966b1d156d7f0a6f81716a" category="list-text">手順4で、ルートディスクに十分なスペースを割り当てます。スワップを追加するには、スペースが必要な場合があります。デフォルトでは、EC2インスタンスはゼロスワップスペースを割り当てますが、これはOracleの実行には最適ではありません。</block>
  <block id="5246bec51cd11bdee5a098fd3d3d5909" category="paragraph"><block ref="5246bec51cd11bdee5a098fd3d3d5909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="843f8ce7ab50f800b312d3d109724de6" category="list-text">手順5で、必要に応じて、インスタンス識別用のタグを追加します。</block>
  <block id="30a97756451355fd7db0bfd07cc6f667" category="paragraph"><block ref="30a97756451355fd7db0bfd07cc6f667" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3ab3dbfdf3bf87e86423bcf042be111" category="list-text">手順6で、既存のセキュリティグループを選択するか、インスタンスに対して適切なインバウンドポリシーとアウトバウンドポリシーを使用して新しいセキュリティグループを作成します。</block>
  <block id="bdeb5b41f7c9bee78d1e7264990c0a27" category="paragraph"><block ref="bdeb5b41f7c9bee78d1e7264990c0a27" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6232d41ab5791353e400740b1c677c4b" category="list-text">手順7で、インスタンス構成の概要を確認し、[起動]をクリックしてインスタンスの展開を開始します。インスタンスにアクセスするためのキーペアの作成またはキーペアの選択を求められます。</block>
  <block id="fdd8bffe3363802212b12c3b1a7626da" category="paragraph"><block ref="8dc5efc0ebc99dc3e7017ef07cffd6c3" category="inline-image-macro-rx" type="image"></block>
<block ref="ea979786416bbc8ec09d933e3d57cfc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="640d800543e4acd4be5582f719fe45e6" category="list-text">SSHキーペアを使用してEC2インスタンスにログインします。必要に応じて、キーの名前とインスタンスのIPアドレスを変更します。</block>
  <block id="69321a8301f0cb7557529f92163852a6" category="paragraph">アーキテクチャ図に示されているように、プライマリおよびスタンバイのOracleサーバとして、2つのEC2インスタンスをそれぞれ指定のアベイラビリティゾーンに作成する必要があります。</block>
  <block id="de55d86dd430c134cc875c8122ebfd71" category="section-title">Oracleデータベースストレージ用のONTAP ファイルシステム用のFSXをプロビジョニングします</block>
  <block id="2a0b48da85066bd283380f9313f9cd2f" category="paragraph">EC2インスタンス環境では、OSにEBSルートボリュームが割り当てられます。FSX for ONTAP ファイル・システムは'Oracleバイナリ'データ'ログ・ボリュームなど'Oracleデータベース・ストレージ・ボリュームを提供しますFSXストレージNFSボリュームは、AWS FSXコンソールから、またはOracleインストールからプロビジョニングできます。また、自動化パラメータファイルでユーザーが設定したボリュームを割り当てる、構成の自動化も可能です。</block>
  <block id="3560913f6885261f7b64e7cfeea69eab" category="section-title">ONTAP ファイルシステム用のFSXを作成しています</block>
  <block id="db188150cd7e1fbc9cfd2bc034c7b4bb" category="inline-link">ONTAP ファイルシステムのFSXの管理</block>
  <block id="3b46f3b2334f11bf806517b04969429a" category="paragraph">このドキュメントを参照<block ref="eea1efb396f41a443a43d43b53db120b" category="inline-link-rx"></block> ONTAP ファイルシステム用のFSXを作成する場合。</block>
  <block id="f992b6bed702bc01496187fcaec0b8c6" category="paragraph">主な考慮事項：</block>
  <block id="c6d0abeaa6d014ec6632e6b8493487d2" category="list-text">SSDストレージ容量。1024 GiB以上、最大192 TiB。</block>
  <block id="2b410cef067f8cb6a53d05ad2271439b" category="list-text">プロビジョニングされたSSDのIOPS。ワークロードの要件に基づいて、ファイルシステムあたり最大80、000 SSD IOPS。</block>
  <block id="3ab61d0f90da3f61b5741ceb5eb191cc" category="list-text">スループット容量</block>
  <block id="94412c99e275ca9b650dc655a6e69119" category="list-text">管理者のfsxadmin/vsadminパスワードを設定します。FSX設定の自動化に必要です。</block>
  <block id="c9de3d23d86cd04ff4ebf9b1458d70c4" category="list-text">バックアップとメンテナンス：自動日次バックアップを無効にします。データベースストレージのバックアップは、SnapCenter のスケジュール設定によって実行されます。</block>
  <block id="b2ad37d85471ba4bcaf2c2141b1a576d" category="list-text">SVMの詳細ページから、SVM管理IPアドレスとプロトコル固有のアクセスアドレスを取得します。FSX設定の自動化に必要です。</block>
  <block id="da6dd59d1114c8c42782cf7be16609b7" category="paragraph"><block ref="da6dd59d1114c8c42782cf7be16609b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15d09dd6ced339d4022eb28264e99543" category="paragraph">プライマリまたはスタンバイのHA FSXクラスタをセットアップするには、次の手順を実行します。</block>
  <block id="b2232ae7fcc8b0c89d7c5f62a079a0f9" category="list-text">FSXコンソールで、Create File Systemをクリックして、FSXプロビジョニングワークフローを開始します。</block>
  <block id="97a3753a6b826d3f7027a60fbc138cac" category="paragraph"><block ref="97a3753a6b826d3f7027a60fbc138cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8863368642c82b76b987f6f94659021d" category="list-text">NetApp ONTAP のAmazon FSXを選択します。[ 次へ ] をクリックします。</block>
  <block id="064467bccc8ccdcdddef0abbcb9694e0" category="paragraph"><block ref="064467bccc8ccdcdddef0abbcb9694e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4912f49d35e15fbe2d9881db397feb" category="list-text">[標準作成]を選択し、[ファイルシステムの詳細]でファイルシステムに「Multi-AZ HA」という名前を付けます。データベースのワークロードに基づいて、最大80、000 SSDのIOPSを自動またはユーザプロビジョニングのどちらかを選択します。FSXストレージには、バックエンドで最大2TiBのNVMeキャッシングが搭載されており、これにより測定IOPSをさらに向上させることができます。</block>
  <block id="989e0e2825ffa339331f1712bf630fb4" category="paragraph"><block ref="989e0e2825ffa339331f1712bf630fb4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="463daf4dcf56c33aa1c738fb16d15a27" category="list-text">[ネットワークとセキュリティ]セクションで、VPC、セキュリティグループ、およびサブネットを選択します。これらは、FSX展開の前に作成する必要があります。FSXクラスタ（プライマリまたはスタンバイ）の役割に基づいて、FSXストレージノードを適切なゾーンに配置します。</block>
  <block id="3e99b854fb0db94f93ca0ee83bec339a" category="paragraph"><block ref="3e99b854fb0db94f93ca0ee83bec339a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="461a86bccdfc4b32cbc62af43ea97bb3" category="list-text">[セキュリティと暗号化]セクションで、デフォルトを受け入れ、fsxadminパスワードを入力します。</block>
  <block id="82d80f8b6e156fcc9a64215b60433630" category="paragraph"><block ref="82d80f8b6e156fcc9a64215b60433630" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e500f789aeb2255be7988000eaff0e8" category="list-text">SVM名とvsadminパスワードを入力します。</block>
  <block id="84f414cec0c77118741eb2dde6127c3b" category="paragraph"><block ref="84f414cec0c77118741eb2dde6127c3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979fcc33806fd9594ae032fb4fe33c03" category="list-text">ボリューム構成は空白のままにします。この時点でボリュームを作成する必要はありません。</block>
  <block id="9cc80fc34e28347ad7a346e723ff34ac" category="paragraph"><block ref="9cc80fc34e28347ad7a346e723ff34ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18c8eecfeb7f2ef5acbe5fe3fc1eb398" category="list-text">Summaryページを確認し、Create File Systemをクリックして、FSXファイルシステムのプロビジョニングを完了します。</block>
  <block id="992da039cb86b69379ac2a507ea018b2" category="paragraph"><block ref="992da039cb86b69379ac2a507ea018b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edbcb61873336784ce88a841052fa45e" category="section-title">Oracleデータベース用のデータベースボリュームのプロビジョニング</block>
  <block id="2dd5d229a6d07b62ae8943394f3a9a05" category="inline-link-macro">ONTAP ボリュームのFSXの管理-ボリュームの作成</block>
  <block id="846568a6ddb0b9c5539e3bffbecefada" category="paragraph">を参照してください <block ref="031a801f4fdac5974fa88d05f1809883" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="ca3a40f13fd000ce8baf0adbf73ee561" category="list-text">データベース・ボリュームのサイズを適切に設定します。</block>
  <block id="383e4b0acf358da05802b9571408fa27" category="list-text">パフォーマンス構成の容量プール階層化ポリシーを無効にしています。</block>
  <block id="086994099a77453bffc426910b6c783b" category="list-text">NFSストレージボリュームでのOracle dNFSの有効化。</block>
  <block id="814d7476ebeabfd3208ed0432cb5ea38" category="list-text">iSCSIストレージボリュームのマルチパスのセットアップ。</block>
  <block id="398cf8d5f0d4c7da2b945809849b5105" category="section-title">FSXコンソールからデータベースボリュームを作成します</block>
  <block id="6afbf36a53c717018bd3d99a6d735c98" category="paragraph">AWS FSXコンソールから、Oracleデータベースファイルストレージ用に、Oracleバイナリ用、Oracleデータ用、Oracleログ用の3つのボリュームを作成できます。ボリュームの名前が、適切に識別されるようにOracleホスト名（自動化ツールキットのhostsファイルに定義されている）と一致していることを確認してください。この例では、EC2インスタンスの一般的なIPアドレスベースのホスト名ではなく、db1をEC2 Oracleホスト名として使用します。</block>
  <block id="a732ebfc126f02de82d9e2cb4cba3b30" category="paragraph"><block ref="680b0ab2cf542daf748f396bdb970bee" category="inline-image-macro-rx" type="image"></block>
<block ref="7cf576b202936b23771e87094082b21e" category="inline-image-macro-rx" type="image"></block>
<block ref="9a3c4da48152c48ddee14308524b2023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05980643a3cf9b987fd426669d474257" category="admonition">iSCSI LUNの作成は、現在FSXコンソールではサポートされていません。OracleのiSCSI LUNを導入する場合は、NetApp Automation ToolkitによるONTAP の自動化を使用してボリュームとLUNを作成できます。</block>
  <block id="09ee5fa03999e48e0789df07dd602d40" category="section-title">FSXデータベース・ボリュームを持つEC2インスタンスにOracleをインストールして構成します</block>
  <block id="9f92271be71e4bc6eb96033a9ca6d798" category="paragraph">ベストプラクティスに基づいて、Oracleのインストールと設定をEC2インスタンスで実行する自動化キットがネットアップの自動化チームから提供されます。現在のバージョンの自動化キットは、デフォルトのRUパッチ19.8でNFS上のOracle 19Cをサポートしています。自動化キットは、必要に応じて他のRUパッチにも簡単に適用できます。</block>
  <block id="61790d4e19b846282d97e8ceb58e84e0" category="section-title">Ansibleコントローラを準備して自動化を実行します</block>
  <block id="20f3b4bca246eb128d1c7a63ca954276" category="paragraph">セクションの指示に従ってください"<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>「Ansibleコントローラを実行するための小規模なEC2 Linuxインスタンスをプロビジョニングします。RedHatを使用するのではなく、2vCPUと8G RAMのAmazon Linux T2.largeで十分です。</block>
  <block id="6d42906c67a4432124b27f032f56e4dc" category="section-title">NetApp Oracle導入自動化ツールキットを入手できます</block>
  <block id="7beb3cf1c62df8d836bddc0d2b6a3e57" category="paragraph">ステップ1からEC2ユーザとしてプロビジョニングされたEC2 Ansibleコントローラインスタンスと、EC2ユーザホームディレクトリから「git clone」コマンドを実行して、自動化コードのコピーをクローニングします。</block>
  <block id="49130c144c12238cfeca4888e29fbef6" category="section-title">自動化ツールキットを使用してOracle 19Cの自動導入を実行</block>
  <block id="ad5d9ee07a5238092f01b66ae1b4ecca" category="paragraph">詳細な手順を参照してください <block ref="1d838bac5e7032e3241598fe6496fbd6" category="inline-link-macro-rx"></block> Oracle 19CをCLI自動化機能で導入するには、次の手順を実行ホストアクセスの認証にパスワードではなくSSHキーペアを使用しているため、コマンド構文には少し変更があり、プレイブックを実行することができます。概要を次に示します。</block>
  <block id="dc8e3956f25fc431225feacc016616b5" category="list-text">デフォルトでは、EC2インスタンスはアクセス認証にSSHキーペアを使用します。Ansibleコントローラの自動化ルートディレクトリ'/home/ec2-user/na_oracle19c_deploy`と'/home/ec2-user/na_rds_fsx_oranfs_config'から'ステップで導入したOracleホストのSSHキー'accesstkey.pem'のコピーを作成します<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>. 」</block>
  <block id="9391c5feaa671121befe114951f00442" category="list-text">EC2インスタンスDBホストにEC2-USERとしてログインし、python3ライブラリをインストールします。</block>
  <block id="03c10a897f1e18c6adaea250b9f30f19" category="inline-link-macro">スワップファイルを使用して、Amazon EC2インスタンスのスワップスペースとして機能するようにメモリを割り当てるにはどうすればよいですか。</block>
  <block id="85e9698f3736149506cd49ab88086364" category="list-text">ルートディスクドライブから16Gスワップスペースを作成します。デフォルトでは、EC2インスタンスはスワップスペースをゼロにします。AWSのドキュメントには次のものがあります <block ref="53c9867a131506eab4afe1a1678bb974" category="inline-link-macro-rx"></block>。</block>
  <block id="be82130abf6bfa8956a5648b39ad4aa8" category="list-text">Ansibleコントローラ(`cd /home/ec2-user/na_rds_fsx_oranfs_config')に戻り'適切な要件と'linux_config'タグを含むPrecloneプレイブックを実行します</block>
  <block id="83e233b8fca25fb162266daf344246e4" category="list-text">「/home/ec2-user/na_oracle19c_deploy-master」ディレクトリに切り替え、READMEファイルを読み、グローバル変数.ymlファイルに関連するグローバルパラメータを入力します。</block>
  <block id="aed4b8eabfef5056093412d8609b5b9a" category="list-text">host_name.ymlファイルに'host_vars'ディレクトリの関連パラメータを入力します</block>
  <block id="4b8d8efa08e1060a3db2c7693c4de645" category="list-text">Linux用のプレイブックを実行し、vsadminパスワードの入力を求められたらEnterキーを押します。</block>
  <block id="4d552f393608513441eb151998098b4a" category="list-text">Oracle用のプレイブックを実行し、vsadminパスワードの入力を求められたらEnterキーを押します。</block>
  <block id="af392a54b9a2464fdd334372589f1a39" category="paragraph">必要に応じて、SSHキーファイルの権限ビットを400に変更します。「host_vars」ファイルのOracleホスト（「Ansibleホスト」）のIPアドレスを、EC2インスタンスのパブリックアドレスに変更します。</block>
  <block id="ac52b3f8d77eb6814ddf5c761b019c22" category="section-title">プライマリとスタンバイのFSX HAクラスタ間でSnapMirrorをセットアップする</block>
  <block id="3798adb983c6ffabbcf459359d5ddd4c" category="paragraph">高可用性とディザスタリカバリを実現するために、プライマリとスタンバイのFSXストレージクラスタ間にSnapMirrorレプリケーションを設定できます。他のクラウドストレージサービスとは異なり、FSXを使用すると、必要な頻度とレプリケーションスループットでストレージレプリケーションを制御および管理できます。また、ユーザはHAやDRのテストを可用性に影響を与えることなく実施できます。</block>
  <block id="5414f0571ab88c4269ee945ce4291f65" category="paragraph">次の手順は、プライマリおよびスタンバイFSXストレージクラスタ間のレプリケーションをセットアップする方法を示しています。</block>
  <block id="006c42f009ead3331b1f69ac1979609d" category="list-text">プライマリクラスタとスタンバイクラスタのピアリングを設定します。fsxadminユーザーとしてプライマリクラスタにログインし'次のコマンドを実行しますプライマリクラスタとスタンバイクラスタの両方でcreateコマンドが実行されます。「standby_cluster_name」を、ご使用の環境に適した名前に置き換えてください。</block>
  <block id="c725d46c724a573eb994f08a1f309eec" category="list-text">プライマリクラスタとスタンバイクラスタの間にvServerピアリングを設定します。vsadminユーザとしてプライマリクラスタにログインし、次のコマンドを実行します。「primary_vserver_name」、「standby_vserver_name」、「standby_cluster_name」を、ご使用の環境に適した名前に置き換えます。</block>
  <block id="91ba2ff3a22b9830c626441ad69c84ce" category="list-text">クラスタとSVMのピアが正しく設定されていることを確認します。</block>
  <block id="7b39dc0f7648c038ec8ac59504316d0e" category="paragraph"><block ref="7b39dc0f7648c038ec8ac59504316d0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4cb6743e20f6b87b419d9386d784acc" category="list-text">プライマリFSXクラスタのソースボリュームごとに、スタンバイFSXクラスタにターゲットNFSボリュームを作成します。環境に応じてボリューム名を置き換えます。</block>
  <block id="8f65518a43c3a1ba084510438fa2d7d3" category="list-text">データアクセスにiSCSIプロトコルが使用されている場合は、Oracleバイナリ、Oracleデータ、およびOracleログ用のiSCSIボリュームとLUNを作成することもできます。Snapshot用のボリュームには約10%の空きスペースを残します。</block>
  <block id="43aea99cd4b66a7a2f8efdc090e3a5ad" category="paragraph">vol create -volume dr_db1_log -aggregate aggr1 -size 250G -state online -policy default -unix-permissions ---rwxr -xr-type rw</block>
  <block id="18274474e00c13f064a0b4df0b516185" category="list-text">iSCSI LUNの場合は、例としてバイナリLUNを使用して、各LUNのOracleホストイニシエータのマッピングを作成します。igroupを環境に適した名前に置き換え、LUNの追加ごとにlun-idを増やします。</block>
  <block id="0c2c0f6ddcbbbf39434893162abce545" category="list-text">プライマリデータベースボリュームとスタンバイデータベースボリュームの間にSnapMirror関係を作成します。環境に適したSVM名を置き換えます。s</block>
  <block id="a25539ee33148e6d4880b87e1378cafe" category="paragraph">このSnapMirrorのセットアップは、NetApp Automation Toolkit for NFSのデータベースボリュームで自動化できます。このツールキットは、NetApp公開のGitHubサイトからダウンロードできます。</block>
  <block id="f9f129d1122f9209f8f27fa07a5ee4b2" category="paragraph">セットアップとフェイルオーバーのテストを行う前に、READMEの手順をよくお読みください。</block>
  <block id="03b2167f2383aa796f361c5c1c689a49" category="admonition">Oracleバイナリをプライマリクラスタからスタンバイクラスタにレプリケートすると、Oracleのライセンスに影響する可能性があります。詳細については、Oracleのライセンス担当者にお問い合わせください。または、リカバリおよびフェイルオーバー時にOracleをインストールして設定します。</block>
  <block id="fa697481d9c5655bd57d6ee69f0e9f07" category="section-title">SnapCenter の導入</block>
  <block id="3f4b23cd1391b97e8a33f3973471103b" category="section-title">SnapCenter のインストール</block>
  <block id="4c88778182d61374292e3c4ad43ae50e" category="inline-link-macro">SnapCenter サーバをインストールしています</block>
  <block id="282e73196d7c89bb5ec3820592ecee7c" category="paragraph">をクリックします <block ref="9cac1dd5d049b670d2cd847d9e42d30c" category="inline-link-macro-rx"></block> SnapCenter サーバをインストールします。このドキュメントでは、スタンドアロンのSnapCenter サーバをインストールする方法について説明します。SnapCenter のSaaSバージョンはベータ版であり、近日中に提供予定です。必要に応じて、ネットアップの担当者にお問い合わせください。</block>
  <block id="a4c2182f79a7834db47fccf9c264332d" category="section-title">EC2 Oracleホスト用のSnapCenter プラグインを設定します</block>
  <block id="8d0edf4e55e8bc1a96862466762dcdd6" category="list-text">SnapCenter の自動インストールが完了したら、SnapCenter サーバがインストールされているWindowsホストの管理ユーザとしてSnapCenter にログインします。</block>
  <block id="27ee26e15e1da051ff520bf3f87f2a03" category="paragraph"><block ref="27ee26e15e1da051ff520bf3f87f2a03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4af2386526da94f1d101d825c0a623e0" category="list-text">左側のメニューから、[設定]、[クレデンシャル]、[新規]の順にクリックして、SnapCenter プラグインのインストールに使用するEC2ユーザクレデンシャルを追加します。</block>
  <block id="252932f5140410e8d8795c4236e41b47" category="paragraph"><block ref="252932f5140410e8d8795c4236e41b47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37fc637fcb7f9b2e4336350dd7d4775e" category="list-text">EC2インスタンス・ホスト上の/etc/ssh/sshd_configファイルを編集して'ec2-userパスワードをリセットし'パスワードSSH認証を有効にします</block>
  <block id="c1e0ecc2d0f187a040af9ef1e783314d" category="list-text">[ sudo権限を使用する]チェックボックスがオンになっていることを確認します。前の手順でEC2-USERパスワードをリセットしただけです。</block>
  <block id="cc57c2c5394de6466406382d198ba244" category="paragraph"><block ref="cc57c2c5394de6466406382d198ba244" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3326cea52418b74168243fb56340785" category="list-text">名前解決のために、SnapCenter サーバ名とIPアドレスをEC2インスタンスホストファイルに追加します。</block>
  <block id="59c8e627359bc3d4ce92126cbb1356cc" category="list-text">SnapCenter サーバのWindowsホストで'Windowsホスト・ファイルC:\Windows\System32\drivers\etc\hostsにEC2インスタンスのホストIPアドレスを追加します</block>
  <block id="4f91fe76ef9595ef98ee3b0c06a43160" category="list-text">左側のメニューで、[Hosts]&gt;[Managed Hosts]の順に選択し、[Add]をクリックしてEC2インスタンスホストをSnapCenter に追加します。</block>
  <block id="a5714b50c71edc910f423bfdc433d799" category="paragraph"><block ref="a5714b50c71edc910f423bfdc433d799" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb20727c22e9cab381fd0cd7e817ab85" category="paragraph">[Oracleデータベース]をオンにし、送信する前に[その他のオプション]をクリックします。</block>
  <block id="7fab569defa89099ea4c5d28723e2031" category="paragraph"><block ref="7fab569defa89099ea4c5d28723e2031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e249b54031e8a30915659857356cab" category="paragraph">インストール前チェックをスキップするをオンにします。インストール前のチェックをスキップしていることを確認し、保存後に送信をクリックします。</block>
  <block id="3d82631a68b3ec0960761342005b2eca" category="paragraph"><block ref="3d82631a68b3ec0960761342005b2eca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d66b31e61ce12ed5022484588882f5f" category="paragraph">[Confirm Fingerprint (指紋の確認)]というプロンプトが表示されたら、[Confirm and Submit (確認して送信)]をクリック</block>
  <block id="795d864d6ec7d5ca3d8c36c9a83bba6e" category="paragraph"><block ref="795d864d6ec7d5ca3d8c36c9a83bba6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99177ab734274d9f5f703761e4b2deef" category="paragraph">プラグインの設定が正常に完了すると、管理対象ホストの全体的なステータスはrunningと表示されます。</block>
  <block id="1fa50503e60bc51f7dea31d9e91c9c20" category="paragraph"><block ref="1fa50503e60bc51f7dea31d9e91c9c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="112fdeb0eaa93f627cf0effc06f49c76" category="section-title">Oracleデータベースのバックアップポリシーを設定する</block>
  <block id="30baaa9bedea395f88f6183eda043198" category="paragraph">このセクションを参照してください <block ref="5b001af64dcc5050a16c7369f5f2fae2" category="inline-link-macro-rx"></block> Oracleデータベースバックアップポリシーの設定の詳細については、を参照してください。</block>
  <block id="6bfb2a8edb5f9cfb06059a588dda9cc0" category="paragraph">通常は、Oracleデータベースのフルスナップショットバックアップ用のポリシーと、Oracleアーカイブログのみのスナップショットバックアップ用のポリシーを作成する必要があります。</block>
  <block id="708ae75a87a6997af6838bc2e5149a28" category="admonition">バックアップポリシーでOracleアーカイブログの削除を有効にして、ログとアーカイブのスペースを制御できます。HAまたはDRのスタンバイ場所にレプリケートする必要があるため、「セカンダリレプリケーションの選択」オプションで「ローカルSnapshotコピー作成後にSnapMirrorを更新」をオンにします。</block>
  <block id="acea2698961ae21a708203b9a9b86b94" category="section-title">Oracleデータベースのバックアップとスケジュールを設定</block>
  <block id="56f3e355b3a4359c9a0808d978ca484c" category="paragraph">SnapCenter のデータベースバックアップはユーザが設定でき、個別に設定することも、リソースグループ内でグループとして設定することもできます。バックアップ間隔は、RTOとRPOの目標によって異なります。フルデータベースバックアップを数時間おきに実行し、ログバックアップのアーカイブを10～15分などの頻度でアーカイブして、迅速なリカバリを実現することを推奨します。</block>
  <block id="cd6290f31cba79c826366f0927d0dc94" category="paragraph">のOracleのセクションを参照してください <block ref="6d8b99fb2ff81ed91f5551e33542f4f8" category="inline-link-macro-rx"></block> セクションで作成したバックアップポリシーを実装するための詳細な手順については、を参照してください <block ref="f2afcb5a9b8ad2d8fe33e91cb4edb80f" category="inline-xref-macro-rx"></block> およびを使用してスケジュールを設定します。</block>
  <block id="b47b1d2e2c373fd6c07f22a130e90a41" category="paragraph">次の図は、Oracleデータベースをバックアップするように設定されたリソースグループの例を示しています。</block>
  <block id="9736ab13cec4c0e5ba0c09476a101fb2" category="paragraph"><block ref="9736ab13cec4c0e5ba0c09476a101fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2d9cc2beb2b12bdad529e6d42551092" category="inline-link-macro">次の例は、データベース管理です。</block>
  <block id="454fb11269c81c93532752028abffbcd" category="paragraph"><block ref="454fb11269c81c93532752028abffbcd" category="inline-link-macro-rx"></block></block>
  <block id="8a1d7e9120e3db2795bd53b504018b4e" category="summary">このホワイトペーパーでは、AWS向けにカスタマイズされたOracle RDSデータベースHAおよびDR用の解決策 の概要と検証について説明し、複数のアベイラビリティゾーン環境でAWS FSXストレージサービスを利用しています。</block>
  <block id="9ae9d82ee587bffe09c5b3c745d93c1c" category="doc">WP-7357：『Oracle Database Deployment on EC2/FSX Best Practices Introduction』</block>
  <block id="b4c8c277e19db14e178b1060214b896e" category="paragraph">ネットアップ、Niyaz Mohamed、Jeffrey Steiner、Allen Cao氏</block>
  <block id="6848412b0f30d614f7e0bcd903cac052" category="paragraph">ミッションクリティカルなエンタープライズOracleデータベースの多くはオンプレミスでホストされており、多くの企業はこれらのOracleデータベースをパブリッククラウドに移行しようとしています。このようなOracleデータベースはアプリケーション中心のものであるため、ユーザ固有の設定が必要になることがよくあります。これは、多くのパブリッククラウドサービスが提供するデータベースサービスに欠けている機能です。そのため、現在のデータベース環境では、パフォーマンスと拡張性に優れたコンピューティングおよびストレージサービスを基盤に構築されたパブリッククラウドベースのOracleデータベース解決策 が、独自の要件に対応できるようになっている必要があります。AWS EC2コンピューティングインスタンスとAWS FSXストレージサービスは、ミッションクリティカルなOracleデータベースワークロードを構築してパブリッククラウドに移行するためのパズルのピースとして欠けているかもしれません。</block>
  <block id="37b7c86d51875922e0a9f122a670aa62" category="paragraph">Amazon Elastic Compute Cloud（Amazon EC2）は、サイズ変更が可能なセキュアなコンピューティング容量をクラウドで提供するWebサービスです。Webスケールのクラウドコンピューティングを企業にとって容易にするように設計されています。シンプルなAmazon EC2 Webサービスインターフェイスを使用すると、摩擦を最小限に抑えて容量を取得し、設定できます。コンピューティングリソースを完全に管理し、Amazonの実績あるコンピューティング環境で実行できます。</block>
  <block id="c9550c9d9c1b379ad427d739b5c69f00" category="paragraph">Amazon FSX for ONTAP は、業界をリードするNetApp ONTAP のブロックストレージとファイルストレージを使用するAWSストレージサービスで、NFS、SMB、iSCSIを公開します。このような強力なストレージエンジンを使用することで、ミッションクリティカルなOracleデータベースアプリケーションを、1ミリ秒未満の応答時間、数Gbpsのスループット、データベースインスタンスあたり10万以上のIOPSでAWSに簡単に再配置できます。さらに、FSXストレージサービスにはネイティブレプリケーション機能が備わっているため、オンプレミスのOracleデータベースをAWSに簡単に移行したり、ミッションクリティカルなOracleデータベースをHAまたはDR用のセカンダリAWSアベイラビリティゾーンにレプリケートしたりできます。</block>
  <block id="b3f95d0186b2e4989ad81f07a21d72c5" category="paragraph">このドキュメントの目的は、FSXストレージを使用してOracleデータベースを導入し、構成する方法に関するステップバイステップのプロセス、手順、ベストプラクティスのガイダンスを提供することと、オンプレミスシステムと同様のパフォーマンスを提供するEC2インスタンスを提供することです。ネットアップは、AWSパブリッククラウドでOracleデータベースワークロードを導入、設定、管理するために必要なほとんどのタスクを自動化するための自動化ツールキットも提供しています。</block>
  <block id="15d62938aed0de1248a55c07bc0c547c" category="paragraph"><block ref="15d62938aed0de1248a55c07bc0c547c" category="inline-link-macro-rx"></block></block>
  <block id="32800a2387c1d841d80eab97ff7205c2" category="summary">このセクションでは、AWS EC2インスタンスとFSXストレージにOracleデータベースを導入する場合に考慮すべき要素について詳しく説明します。</block>
  <block id="c53749244d982efb6aa5653328227c2a" category="doc">Oracleデータベースの導入で考慮すべき要素</block>
  <block id="0dd9b4b69c30ae87b4322df28758dc18" category="paragraph"><block ref="0dd9b4b69c30ae87b4322df28758dc18" category="inline-link-macro-rx"></block></block>
  <block id="96f819dcc02d1203a3923ddad366ff4b" category="paragraph">パブリッククラウドには、コンピューティングとストレージに多数の選択肢があり、適切なタイプのコンピューティングインスタンスとストレージエンジンを使用することで、データベースの導入を開始できます。また、Oracleデータベース用に最適化されたコンピューティングとストレージの構成も選択する必要があります。</block>
  <block id="e958329ac331abb8419551328745ce28" category="paragraph">以降のセクションでは、OracleデータベースをFSXストレージを搭載したEC2インスタンス上のAWSパブリッククラウドに導入する場合の主な考慮事項について説明します。</block>
  <block id="af9adf45d47438d70bedeea4353827c3" category="paragraph">パブリッククラウドのリレーショナルデータベースのパフォーマンスを最適化するには、適切な VM サイズを選択することが重要です。パフォーマンスを高めるために、Oracle環境にはEC2 M5シリーズインスタンスを使用することを推奨します。このインスタンスはデータベースワークロードに最適化されています。AWSでOracleのRDSインスタンスを提供する際にも、同じインスタンスタイプが使用される。</block>
  <block id="1dbc89cff7796dd99cbe9338453d04d7" category="list-text">ワークロードの特性に基づいて、正しいvCPUとRAMの組み合わせを選択してください。</block>
  <block id="ff1a938ecebc5237c31b8f5d9a9b87ce" category="list-text">VMにスワップスペースを追加する。デフォルトのEC2インスタンス配置ではスワップスペースは作成されませんが、これはデータベースには最適な方法ではありません。</block>
  <block id="d4d5d0e2fb33dadfad4435489bd718a4" category="section-title">ストレージのレイアウトと設定</block>
  <block id="0fe994abd6c200feb672e77242fe9fcb" category="paragraph">次のストレージレイアウトを推奨します。</block>
  <block id="c1b542506bceb69c76148851e217c49f" category="list-text">NFSストレージの場合、推奨されるボリュームレイアウトは3つのボリュームです。1つはOracleバイナリ用、1つはOracleデータ用、もう1つは重複する制御ファイル用、もう1つはOracleアクティブログ、アーカイブログ、および制御ファイル用です。</block>
  <block id="02833700de6eac537733ce81ef6352a3" category="paragraph"><block ref="02833700de6eac537733ce81ef6352a3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc828f321000aae204feb1f0f945893" category="list-text">iSCSIストレージの場合、推奨されるボリュームレイアウトは、Oracleバイナリ用のボリューム、Oracleデータ用のボリューム、重複する制御ファイル用のボリューム、Oracleアクティブログ、アーカイブログ、および制御ファイル用のボリュームの3つです。ただし、データボリュームとログボリュームにはそれぞれ4つのLUNを含めるのが理想的です。LUNの負荷はHAクラスタノード上に分散して配置するのが理想的です。</block>
  <block id="cddd034875839504dacaa29e5dca803f" category="paragraph"><block ref="cddd034875839504dacaa29e5dca803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7810ed5b0bbb3acf153d353ac803a51" category="list-text">ストレージIOPSとスループットについては、FSXストレージクラスタのプロビジョニングされたIOPSとスループットのしきい値を選択できます。これらのパラメータは、ワークロードが変更されるたびにオンザフライで調整できます。</block>
  <block id="c5493cd0fe001da987655ad852808dc7" category="list-text">自動IOPS設定は、割り当てられているストレージ容量のGiBあたり3 IOPS、またはユーザ定義のストレージあたり最大80、000 IOPSです。</block>
  <block id="6524d7ff1096fc6a10590b6d1f7163b6" category="list-text">スループットレベルは、128、256、512、1024、2045 Mbpsのように増分されます。</block>
  <block id="bc4bb24d5e702fb79be623b84e7cf47e" category="inline-link-macro">Amazon FSX for NetApp ONTAP のパフォーマンス</block>
  <block id="b59267e60b3253fa9c2edeed17c1340f" category="paragraph">を確認します <block ref="a572b0e55a3a15b7b3460602e8714ba1" category="inline-link-macro-rx"></block> スループットおよびIOPSのサイジングに関するドキュメント</block>
  <block id="10edbbba4e4c39fc161aeac9fbb88aef" category="section-title">NFS の設定</block>
  <block id="b6e1b7fd7aad364a8ad758d8ae8ba50d" category="paragraph">最も一般的なオペレーティングシステムであるLinuxには、ネイティブのNFS機能が含まれています。Oracleは、Oracleにネイティブに統合されたDirect NFS（dNFS）クライアントを提供しています。Oracleでは20年以上NFSv3がサポートされており、NFSv4はOracle 12.1.0.2以降でサポートされています。NetApp Automation Toolkitを使用したOracleの自動導入で、NFSv3ではdNFSが自動的に設定されます。</block>
  <block id="2b7570eaa12a3e472e9d0cbac6631d57" category="paragraph">その他の考慮事項：</block>
  <block id="6841f6ce9d9a2af93222223df564ca34" category="list-text">TCPスロットテーブルは、ホストバスアダプタ（HBA）キュー深度に相当するNFS環境の機能で、一度に未処理となることのできるNFS処理の数を制御します。デフォルト値は通常16ですが、最適なパフォーマンスを得るには小さすぎます。逆に、新しいLinuxカーネルでTCPスロットテーブルの上限をNFSサーバが要求でいっぱいになるレベルに自動的に引き上げることができるため、問題が発生します。</block>
  <block id="5a749fcdd97cee211c5fea00babe8691" category="paragraph">パフォーマンスを最適化し、パフォーマンスの問題を回避するには、TCPスロットテーブルを制御するカーネルパラメータを128に調整します。</block>
  <block id="dcd7ebfa96f217f8d20c58a185a48531" category="list-text">次の表に、Linux NFSv3 -シングルインスタンスに対する推奨されるNFSマウントオプションを示します。</block>
  <block id="4780ee7b64d0ec83e06977206e8a35b5" category="paragraph"><block ref="4780ee7b64d0ec83e06977206e8a35b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492ef7005cdef278b0b767179a1ecb9" category="admonition">dNFSを使用する前に、Oracleドキュメント1495104.1に記載されているパッチがインストールされていることを確認してください。Oracle 12c以降のDNFSは、NFSv3、NFSv4、NFSv4.1をサポートしています。ネットアップのサポートポリシーはすべてのクライアントについてv3とv4をカバーしていますが、現時点ではOracle dNFSでのNFSv4.1の使用はサポートされていません。</block>
  <block id="2fe1fc26875d6d38f4b15a3a03d498fb" category="paragraph">解決策 アーキテクチャに示されているように、HAはストレージレベルのレプリケーションを基盤としています。そのためOracleのスタートアップと可用性は、コンピューティングとストレージをどれだけ迅速に起動してリカバリできるかにかかっています。主な要因は次のとおりです。</block>
  <block id="137bc4c57a9561d086601728a3db1a90" category="list-text">スタンバイコンピューティングインスタンスを準備し、両方のホストにAnsibleパラレル更新を使用してプライマリと同期します。</block>
  <block id="d653e9032c9904901af96f496db98a3e" category="list-text">スタンバイ目的でプライマリからバイナリボリュームをレプリケートするため、最後の1分間にOracleをインストールする必要がなく、インストールしてパッチを適用する必要があることを特定できます。</block>
  <block id="77991416cd2e0bfc66a77d32e3fbb45a" category="list-text">レプリケーションの頻度は、Oracleデータベースをリカバリしてサービスを利用できるようにするまでの時間を示します。レプリケーションの頻度とストレージ消費量のバランスが考慮されます。</block>
  <block id="0797ee9bca14d1064492a93ac7cc7fa1" category="list-text">自動化を活用してリカバリを行い、スタンバイ状態にすばやく、人的ミスがないように切り替えます。ネットアップは、この目的のための自動化ツールキットを提供しています</block>
  <block id="0a076fda3d30e9959f9332ce7c42445c" category="paragraph"><block ref="0a076fda3d30e9959f9332ce7c42445c" category="inline-link-macro-rx"></block></block>
  <block id="90a0d380974aa73acb8330f1ff9a7930" category="summary">このセクションでは、オンプレミスからAWS EC2インスタンスおよびFSXストレージにOracleデータベースを移行する場合に考慮すべき要素について詳しく説明します。</block>
  <block id="895a8d39dd9ae7fe795349bdbc3f05dc" category="doc">オンプレミスからパブリッククラウドへのデータベースの移行</block>
  <block id="64d625665f42751b8036cb9a6403a0fe" category="inline-link-macro">Previous：データベース管理。</block>
  <block id="69dd1b6ab585f33a36445376492ea8de" category="paragraph"><block ref="69dd1b6ab585f33a36445376492ea8de" category="inline-link-macro-rx"></block></block>
  <block id="373ae4e24c2daa280a4a5aca82dd3818" category="paragraph">データベースの移行は、どのような方法でも難しい課題です。オンプレミスからクラウドへのOracleデータベースの移行も例外ではありません。</block>
  <block id="d1e968e04e34c971d41e644820094cef" category="paragraph">以降のセクションでは、AWS EC2コンピューティングとFSXストレージプラットフォームを使用してOracleデータベースをAWSパブリッククラウドに移行する場合に考慮すべき主な要素について説明します。</block>
  <block id="84639b5fb3b348e6a053dde95414e039" category="section-title">ONTAP ストレージはオンプレミスで利用できます</block>
  <block id="93336cb92f211f9ff347245c8559dd5e" category="paragraph">オンプレミスのOracleデータベースがONTAP ストレージアレイに配置されている場合は、NetApp SnapCenter UIツールを使用してデータベースを移行するためのレプリケーションを簡単に設定できます。</block>
  <block id="df2111c23e70fa013a85041e1415639e" category="list-text">オンプレミスのインスタンスと一致するターゲットコンピューティングEC2インスタンスを構築します。</block>
  <block id="1931f75e563d3dc9ee112e9b4ebd66b7" category="list-text">FSXコンソールから、同じサイズの一致するデータベースボリュームをプロビジョニングします。</block>
  <block id="98201e355445ae8a2eff3b7c33132cc6" category="list-text">FSXデータベースボリュームをEC2インスタンスにマウントします。</block>
  <block id="53fad15133e494dc37bbd0494b8f3a6c" category="list-text">オンプレミスのデータベースボリュームとターゲットのFSXデータベースボリュームとの間にSnapMirrorレプリケーションを設定します。初期同期ではプライマリソースデータの移動に時間がかかる場合がありますが、次の差分更新の方がはるかに高速です。</block>
  <block id="fda597a9ad18b763048653fa5e87e38c" category="list-text">スイッチオーバー時に、プライマリアプリケーションをシャットダウンしてすべてのトランザクションを停止します。SnapCenter で、ログバックアップを実行して残りのトランザクションをターゲットにフラッシュします。</block>
  <block id="8da4f0ed2ee5c7e68c3fe9ec3dde280e" category="list-text">ミラーボリュームを切断し、ターゲットでOracleリカバリを実行し、データベースを稼働状態にしてサービスを開始します。</block>
  <block id="6efd103fd0a488a3d023523ab6377e4e" category="list-text">アプリケーションをクラウド内のOracleデータベースに指定します。</block>
  <block id="86afa353cad293784396216eab80ee52" category="section-title">ONTAP ストレージはオンプレミスでは利用できません</block>
  <block id="c11080183211191097c120f87656c802" category="paragraph">オンプレミスのOracleデータベースがONTAP 以外のサードパーティストレージでホストされている場合、データベースの移行はOracleデータベースのバックアップコピーのリストアに基づいて行われます。スイッチオーバーする前に、アーカイブログを再生して最新の状態にする必要があります。</block>
  <block id="722283478873a13974c4b1b6ea967a40" category="paragraph">AWS S3は、データベースの移動と移行のステージングストレージ領域として使用できます。この方法の手順の概要は、次のとおりです。</block>
  <block id="9312555163563ac6b35994e42f15d009" category="list-text">オンプレミスのインスタンスと同等の、一致する新しいEC2インスタンスをプロビジョニングします。</block>
  <block id="8705a6dedde3ea188c113bda4fe97c14" category="list-text">FSXストレージから同一のデータベースボリュームをプロビジョニングし、そのボリュームをEC2インスタンスにマウントします。</block>
  <block id="6aeff6e3d9f2f107fa5584191966f816" category="list-text">ディスクレベルのOracleバックアップコピーを作成する。</block>
  <block id="0f90c0c06dae8f50c3f93d33a7547df2" category="list-text">バックアップコピーをAWS S3ストレージに移動します。</block>
  <block id="d8fd670e7724b3db99919ea02cd762cc" category="list-text">Oracleの制御ファイルを再作成し、S3ストレージからデータとアーカイブログを取得してデータベースをリカバリします。</block>
  <block id="c4a99d505e8ebe4d5f04ae86d2a724b7" category="list-text">ターゲットのOracleデータベースをオンプレミスのソースデータベースと同期します。</block>
  <block id="3bac7326688b384ce82c7c9807cae4b7" category="list-text">スイッチオーバー時に、アプリケーションとソースのOracleデータベースをシャットダウンします。最新の状態にするために、最後のいくつかのアーカイブ・ログをコピーし、ターゲットOracleデータベースに適用します。</block>
  <block id="98cf6a7f87338026b5b95afee91d5676" category="list-text">ユーザアクセス用にターゲットデータベースを起動します。</block>
  <block id="021e473c3a779caff7d794ce36c8ef68" category="list-text">アプリケーションをターゲットデータベースにリダイレクトして、スイッチオーバーを完了します。</block>
  <block id="46c977a489a77ea3a7d6ff4a7fa6d556" category="section-title">OracleマルチテナンシーCDB/PDBアーキテクチャを使用して、OracleデータベースをAWSに統合します</block>
  <block id="ea274b58537d36559ff3046cd5423083" category="list-text">AWSパブリッククラウドにCDBを作成します。</block>
  <block id="12c774c8ec030e1d104719cf317b5ca2" category="list-text">CDB / PDBのマルチテナンシーにオンプレミスデータベースも導入されている場合は、移行するPDBを取り外します。</block>
  <block id="6ee0eb9b1d29207b2ae6feda6428e2cc" category="list-text">メタデータと下線付きのOracleデータファイルをターゲットCDBインスタンスに転送します。</block>
  <block id="4bb12c493b32940ff849ac100d727582" category="list-text">Oracleの検証手順との互換性を検証</block>
  <block id="e7343c5c0db191b9c4841a6556ebc806" category="list-text">互換性検証に合格した場合は、未接続のPDBをターゲットCDBコンテナに接続します。</block>
  <block id="5bb0b3fe813867de21d25f37b58dc0fc" category="list-text">必要に応じてデータディクショナリを更新します。</block>
  <block id="97b4c444678bacf256568fc4f7071634" category="list-text">アクセスできるように、移行されたPDBをバックアップして開きます。</block>
  <block id="375116b8a4235f7fa12ebc4e2bddb3dc" category="admonition">PDBのプラグインとプラグインを取り外すには、移行計画の際に考慮すべきアプリケーションのダウンタイムが必要です。</block>
  <block id="0978a2ea1e5676c9e8f017f05e988475" category="paragraph">繰り返しになりますが、ネットアップの自動化チームが提供する移行ツールキットを使用すれば、オンプレミスからAWSクラウドへのOracleデータベースの移行をスムーズに進めることができます。ネットアップのパブリックGitHubサイトで、最新のデータベース移行ツールを確認してください。</block>
  <block id="a8fba1abc3fbaa027d18daed3f6e170d" category="doc">MetalLBロードバランサをインストールしています</block>
  <block id="48501496ee9b06b63701de94b6ffc3a5" category="paragraph">このページでは、MetalLB管理対象ロードバランサのインストールおよび設定手順を示します。</block>
  <block id="ccd779a5e754b22c1589256334866c0a" category="paragraph">MetalLBロードバランサは、VMware上のAnthosクラスタと完全に統合されており、1.11リリース以降のAdminおよびUserクラスタセットアップの一部として自動展開を実行しています。ロード・バランサ情報を提供するために変更する必要がある'対応する'cluster.yamlの構成ファイル内にテキストのブロックがありますサポートされている他のロードバランサソリューションのような外部リソースの導入を必要とするのではなく、Anthosクラスタで自己ホストされます。また、IPプールを作成し、クラウドプロバイダで実行されていないクラスタでロードバランサタイプのKubernetesサービスの作成時にアドレスを自動的に割り当てることもできます。</block>
  <block id="b938ac6243408826bd53c58d2a6a6f1f" category="paragraph">Anthos管理用のMetalLBロードバランサをイネーブルにする場合、「admin-cluster .yaml」ファイルにある「Loadbalancer:」セクションの一部の行を変更する必要があります。変更する必要がある値は、「controlPlaneVip:」アドレスを設定し、「kind：」をMetalLBとして設定することだけです。例については、次のコードスニペットを参照してください。</block>
  <block id="79fdf71abab382ca3fbab93d863f835c" category="paragraph">AnthosユーザクラスタでMetalLBロードバランサをイネーブルにする場合、更新が必要な「user-cluster.yaml」ファイルごとに2つの領域があります。まず'admin-cluster.yaml'ファイルと同様に'controlPlaneVip:`'ingressVip:`'と'kind :'の値をLoadbalancerの:`セクションで変更する必要があります例については、次のコードスニペットを参照してください。</block>
  <block id="c173f58ae6718fb7dc80d6ddb9b392e5" category="admonition">設定の後半で、MetalLBロードバランサに割り当てられたIPアドレスのプール内に、ingressVIP IPアドレスが存在している必要があります。</block>
  <block id="77960f17a334c28c4bacd9515ac55817" category="paragraph">次に'metalLB:'サブセクションに移動し'addressPools:'セクションを修正して'-name:'変数にプールの名前を付けますまた、MetalLBが「address:」変数に範囲を提供することで、LoadBalancer型のサービスに割り当てることができるIPアドレスのプールを作成する必要があります。</block>
  <block id="8dfd015968f24ba6c3e2d8386cd40cbe" category="admonition">この例のような範囲を指定すると、特定のサブネット内のアドレス数に制限することも、サブネット全体が使用可能になった場合にCIDR表記として指定することもできます。</block>
  <block id="ea4a20324a094d5f515252d5669a60ca" category="list-text">LoadBalancerタイプのKubernetesサービスが作成されると、MetalLBは自動的にそのサービスに外部IPを割り当て、ARP要求に応答してIPアドレスをアドバタイズします。</block>
  <block id="c09bdf0c852b6f771b10fb71482778db" category="paragraph">アプリケーションのバックアップには、アプリケーションのアクティブな状態とそのリソースの設定がキャプチャされ、ファイルに変換されて、リモートのオブジェクトストレージバケットに格納されます。</block>
  <block id="3805fe09ab2fab11e5a88285db1ba4f1" category="paragraph">アプリケーションのバックアップを作成するには、次の手順を実行します。</block>
  <block id="17937980068cd45516e074151c756bab" category="list-text">Astra Control Centerで管理対象アプリケーションのバックアップを作成するには、[アプリ]&gt;[管理対象]の順に選択し、バックアップを作成するアプリケーションをクリックします。アプリケーション名の横にあるドロップダウンメニューをクリックし、 [ バックアップ ] をクリックします。</block>
  <block id="d587342349a123dddff71bef9eb7b6e6" category="paragraph">アプリケーションをリストアするには、次の手順を実行します。</block>
  <block id="804e8c9205cc0caea9e5cb6645febba7" category="list-text">[アプリ]&gt;[管理]タブに移動し、該当するアプリをクリックします。アプリケーション名の横にあるドロップダウンメニューをクリックし、[復元]をクリックします。</block>
  <block id="b0ff29eefb84e5d7a2cdae616ae42213" category="list-text">新しいネームスペースの詳細を入力し、クローニング先のクラスタを選択して、既存のSnapshot、バックアップ、またはアプリケーションの現在の状態からクローニングするかどうかを選択します。詳細を確認したら、[次へ]をクリックし、[レビュー]ペインの[複製]をクリックします。</block>
  <block id="4c0e19abe22935505e774d4d3b2e8449" category="list-text">新しいアプリケーションはDiscovering状態になり、Astra Control Centerは選択したクラスタにアプリケーションを作成します。アプリケーションのすべてのリソースがAstraによってインストールおよび検出されると、アプリケーションはAvailable状態になります。</block>
  <block id="858674153e1f55409f3ea08cdc502f53" category="inline-link-macro">次の手順：詳細設定オプション。</block>
  <block id="9bb9f32bf0692d68fe53042de73b0c6a" category="paragraph"><block ref="9bb9f32bf0692d68fe53042de73b0c6a" category="inline-link-macro-rx"></block></block>
  <block id="abb33c60fb7710d77680621bb6bb0433" category="doc">F5 BIG-IPロードバランサのインストール</block>
  <block id="4f3422718812b2a40b70340da35b565c" category="paragraph">F5 BIG-IPは、L4-L7ロードバランシング、SSL/TLSオフロード、DNS、ファイアウォールなど、高度な本番環境レベルのトラフィック管理およびセキュリティサービスを幅広く提供するApplication Delivery Controller（ADC）です。これらのサービスにより、アプリケーションの可用性、セキュリティ、パフォーマンスが大幅に向上します。</block>
  <block id="81d91349803cba0e1b0d0f84948ff37c" category="paragraph">F5 BIG-IPは、専用ハードウェア、クラウド、オンプレミスの仮想アプライアンスなど、さまざまな方法で導入、使用できます。F5 BIG-IPの詳細と導入方法については、ここで説明しているドキュメントを参照してください。</block>
  <block id="cb9f661ea2c5b0b25cb936398de81286" category="admonition">F5 BIG-IPは、スタンドアロンモードまたはクラスタモードで導入できます。この検証のために、F5 BIG-IPはスタンドアロンモードで導入されました。ただし本番環境では、単一点障害を避けるために、ビッグIPインスタンスで構成されるクラスタを作成することを推奨します。</block>
  <block id="9c62eb7c12e4e6a75fc74fffecb2db09" category="paragraph">ネットアップのソリューションエンジニアリングチームでは、今回のラボの以下の表に示すリリースを、オンプレミスのAnthos環境で機能することを検証しました。</block>
  <block id="930835cee46ee894bb92b5627c286380" category="paragraph"><block ref="930835cee46ee894bb92b5627c286380" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5869793ca55f5fc50960cbd965138c70" category="inline-image-macro">Big _IP Appliance 、パート 2 を展開します</block>
  <block id="b395903460348cc88bfae6fcad255f21" category="paragraph"><block ref="b395903460348cc88bfae6fcad255f21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca9eda681850d46169f2940362b1548f" category="inline-image-macro">ビッグ IP アプライアンスの導入（第 3 部</block>
  <block id="9c7b1162de6217dfe316b9d57d67b16f" category="paragraph"><block ref="9c7b1162de6217dfe316b9d57d67b16f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="372bcca75330a5dc5675a722489ff49b" category="paragraph"><block ref="372bcca75330a5dc5675a722489ff49b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e7de45031877e6ff00d3069664fbcaf" category="inline-image-macro">BIG-IP Configuration 、パート 2</block>
  <block id="cee8fbb1e19d03d10bbd1e01e76cf77b" category="paragraph"><block ref="cee8fbb1e19d03d10bbd1e01e76cf77b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b648434aacde9879c494bb807f510d0a" category="inline-image-macro">BIG-IP Configuration 、パート 3</block>
  <block id="abc7fe3f8ac78f7eef2f5ca730be051c" category="paragraph"><block ref="abc7fe3f8ac78f7eef2f5ca730be051c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48f2578529c2f8c811567604f610cb5f" category="inline-image-macro">BIG-IP Configuration 、パート 4</block>
  <block id="7032ef2cca6e17b4d3590ecbbce7ff16" category="paragraph"><block ref="7032ef2cca6e17b4d3590ecbbce7ff16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9fd499e062b35d18ef68efd381c6c09" category="inline-image-macro">BIG-IP Configuration 、パート 6</block>
  <block id="78df99aca47bd680a19574eebccf4249" category="paragraph"><block ref="78df99aca47bd680a19574eebccf4249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4e4f5e5f31a0b8312fb2338d9015dd0" category="inline-image-macro">BIG-IP Configuration 、パート 7</block>
  <block id="72cb9d54a4958e24c358ee0871b24454" category="paragraph"><block ref="72cb9d54a4958e24c358ee0871b24454" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c574654bbbf1cf9927e54a1cf4152c71" category="list-text">ウィザードの最初のページでは冗長性が設定されます。デフォルトのままで Next （次へ）をクリックします。次のページでは、ロードバランサに内部インターフェイスを設定できます。インターフェイス1.1は、OVF DeploymentウィザードでInternalというラベルの付いたVMNICにマッピングされます。</block>
  <block id="19ee7bbff17fca60aeffed9079a87c6b" category="inline-image-macro">BIG-IP Configuration 、パート 8</block>
  <block id="93e0638cb95146eb8773223a90aa6d86" category="list-text">次のページでは、 Kubernetes で導入されたポッドにサービスをマッピングするために使用する外部ネットワークを設定できます。VM_Network の範囲内の静的 IP 、適切なサブネットマスク、および同じ範囲のフローティング IP を選択します。インターフェイス1.2は、OVF導入ウィザードでExternalというラベルのVMNICにマッピングされます。</block>
  <block id="803c8b846cb5b5c6c8d5a2b0b07f4dba" category="inline-image-macro">BIG-IP Configuration 、パート 9</block>
  <block id="9cd42351da162e75b1a0178bdd0ded20" category="inline-image-macro">BIG-IP Configuration 、パート 10</block>
  <block id="ad99125325ea694a08a4db92eabb18a1" category="inline-image-macro">BIG-IP Configuration 、パート 11</block>
  <block id="d71ac8787685cb0f3b8f800520d684b1" category="paragraph"><block ref="d71ac8787685cb0f3b8f800520d684b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0344c261b0475e6caf01bb585530f" category="list-text">表示される画面には、現在の共通パーティションのみが表示されます。右側の[作成]をクリックして最初の追加パーティションを作成し、「GKE-ADMIN」という名前を付けます。[繰り返し]をクリックし'パーティションにUser-Cluster-1という名前を付けます[繰り返し]ボタンをもう一度クリックして'次のパーティションにUser-Cluster-2'という名前を付けます最後に、 [ 終了 ] をクリックしてウィザードを完了します。パーティションリスト画面が表示され、すべてのパーティションが表示されます。</block>
  <block id="938c47fe40c045ae4bc242bf2339ab01" category="inline-image-macro">BIG-IP Configuration 、パート 12</block>
  <block id="598f9d349e1cb4c318e78a0d182dd743" category="paragraph"><block ref="598f9d349e1cb4c318e78a0d182dd743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc19630e1d9c7f2a85a541796c5ec51" category="paragraph">管理クラスタ用の各構成ファイルにはセクションがあり、導入するユーザクラスタごとにロードバランサを設定し、オンプレミスのAnthosで管理されるようにします。</block>
  <block id="38779167fbee63015f17c4c1b453dd32" category="paragraph">次のスクリプトは、GKE-Adminクラスタ用パーティションの設定例です。コメントを解除して変更する必要がある値は、次の太字で表示されます。</block>
  <block id="288c554e356764c1144e77f0d78f97bf" category="doc">ロードバランサのオプションを確認する</block>
  <block id="807a04fd6be3315608f66b00ab708987" category="paragraph">Anthosに導入されたアプリケーションは、オンプレミス環境のAnthosに導入されたロードバランサによって提供されるサービスによって世界に公開されます。</block>
  <block id="4f8cee548fdf2c886e16bf694eb06522" category="paragraph"><block ref="4f8cee548fdf2c886e16bf694eb06522" category="inline-link-macro-rx"></block></block>
  <block id="dc89b61e16e84216193885f3a7c62fb9" category="inline-link-macro">次のページ：Red Hat OpenShift Clusterを登録します。</block>
  <block id="13d5bf8d97a187ca5d13b7429c268342" category="paragraph"><block ref="13d5bf8d97a187ca5d13b7429c268342" category="inline-link-macro-rx"></block></block>
  <block id="7cdcf7845d98f304186a5184cd2161ac" category="inline-link-macro">次のステップ：NetApp ONTAP</block>
  <block id="1a4c8966068ddb4b2fda6d5bc54054c3" category="paragraph"><block ref="1a4c8966068ddb4b2fda6d5bc54054c3" category="inline-link-macro-rx"></block></block>
  <block id="a5fcf88905522eca0a7500198fc13ea9" category="paragraph">たとえば、次のようなものです。</block>
  <block id="231a9d200c75839cf9b4ffeecde45821" category="list-text">*独自のLinux OSをお持ちください。* Anthosオンベアメタル環境を導入するLinux OSを選択することで、Anthos環境を既存のインフラストラクチャと管理スキームに適切に適合させることができます。</block>
  <block id="8f3c025cf8c4fb1a7841163ea4213611" category="list-text">*パフォーマンスの向上とコストの削減*ハイパーバイザを必要としないAnthosオンベアメタルクラスタは、GPUなどのパフォーマンスに最適化されたハードウェアデバイスを含むサーバハードウェアリソースへの直接アクセスを求めています。</block>
  <block id="5c96e444541cebd597916a4a84177f6b" category="list-text">*ネットワークパフォーマンスの向上とレイテンシの低減* Anthos-ベア メタルサーバノードは仮想抽象化レイヤーを使用せずに直接ネットワークに接続されているため、低レイテンシと低パフォーマンスを実現するように最適化できます。</block>
  <block id="08c2b93847522285403aa57a50c67356" category="paragraph">Anthosオンベアメタルノードには、現在のデータセンターインフラに合わせて、お客様が選択した複数のLinuxディストリビューションを構成できます。</block>
  <block id="cb9cc8981898224a2fe45ac6ff7d4244" category="cell">1.11</block>
  <block id="969f1705e87aebac2415f45faaf8ef89" category="cell">A250、A220</block>
  <block id="6ff97c39e8de9255f8ab9ffb6a483dce" category="cell">9.9.1.1、9.10.1</block>
  <block id="9401797270b98418222b9be6674161bc" category="admonition">このマルチOS環境では、Anthos-On-by-Metal解決策 でサポートされているOSバージョンとの相互運用性が示されています。導入のために、お客様が1つまたは一部のオペレーティングシステムを標準化することを期待しています。</block>
  <block id="3a6810b280d17ed872c226f7c95dac46" category="list-text">管理ネットワークからアクセス可能な完全なホスト名解決を提供するDNSサーバが少なくとも1つ必要です。</block>
  <block id="14de5275438fed7bf294f7d1ef6ebfce" category="list-text">管理ネットワークからアクセスできるNTPサーバが少なくとも1台必要です。</block>
  <block id="ab851d2f29c7c89b9bc55851dd1002d2" category="list-text">（任意）インバンド管理ネットワークの両方のアウトバウンドインターネット接続。</block>
  <block id="82d4df3a9be244e5548f2913b75e403c" category="admonition">本ドキュメントの「ビデオとデモ」セクションには、ベアメタル環境に導入されたAnthosのデモビデオがあります。</block>
  <block id="8a31087c2de67e51ba9270956af09594" category="paragraph"><block ref="8a31087c2de67e51ba9270956af09594" category="inline-link-macro-rx"></block></block>
  <block id="e66e12138810859d8abf5fa2081fb491" category="summary">Google Cloud Consoleを使用して、オンプレミスのAnthos GKEクラスタにアプリケーションを導入する方法</block>
  <block id="0fedf382c8cab1bb4bd4137b2edd4ddf" category="doc">Google Cloud Console Marketplaceからアプリケーションを導入する</block>
  <block id="db974f321885ec32e283b3ba19624bf5" category="list-text">オンプレミスに導入され、Google Cloud Consoleに登録されたAnthosクラスタ</block>
  <block id="86baa7935f2da05d24c2736b997d56af" category="list-text">Anthosクラスタに設定されているMetalLBロードバランサ</block>
  <block id="0e4a5cc43eded7fb6f9688b4db42749c" category="list-text">アプリケーションをクラスタに導入する権限を持つアカウント</block>
  <block id="0abcad93e8aa42fe77227a82e7bfac88" category="list-text">コストが関連するアプリケーションを選択した場合のGoogle Cloudの請求アカウント（オプション）</block>
  <block id="241b7771ea8f8a56aa7c79c94ea05b45" category="section-title">アプリケーションのデプロイ</block>
  <block id="7519665b833135b7a83098238355d197" category="paragraph">このユースケースでは、Google Cloud Consoleを使用して、シンプルなWordPressアプリケーションをAnthosクラスタの1つに導入します。導入環境では、事前定義されたストレージクラスでNetApp ONTAP が提供する永続的ストレージを使用します。次に、MetalLBロードバランサがIPアドレスを提供して世界に公開するように、アプリケーションのデフォルトサービスを変更する2つの方法を示します。</block>
  <block id="0f46ecb3b1113d47388dd5a45b007f77" category="paragraph">この方法でアプリケーションを展開するには、次の手順を実行します。</block>
  <block id="284e9ebcc65faa3412015e1aef0b212f" category="list-text">導入先のクラスタにGoogle Cloud Consoleでアクセスできることを確認します。</block>
  <block id="c5ae9e1da0751273beff7dba35e9f3a0" category="inline-image-macro">登録済みクラスタ</block>
  <block id="113157b1187558580348ca8d41e0e09d" category="paragraph"><block ref="113157b1187558580348ca8d41e0e09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ffca2e9c9a134c6025fcd79da7b2c759" category="list-text">左側のメニューから「アプリケーション」を選択し、上部にある3ドットのオプションメニューを選択して、「Marketplaceから展開」を選択します。これにより、Google Cloud Marketplaceからアプリケーションを選択できる新しいウィンドウが表示されます。</block>
  <block id="0684d335d9a7c1f72f6bfcd5a3f89e00" category="inline-image-macro">アプリケーションマーケットプレイス</block>
  <block id="c2c2bcc598caddf4725c028c7db228b2" category="paragraph"><block ref="c2c2bcc598caddf4725c028c7db228b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1116a3fdba8715414e3ef4e4f99912" category="list-text">インストールするアプリケーションを検索します。この場合は、WordPressです。</block>
  <block id="822f5bce2ee65cbb4bdffaba2710ba34" category="inline-image-macro">WordPressを検索します</block>
  <block id="660eb3f5a04738d18f35a59427836264" category="paragraph"><block ref="660eb3f5a04738d18f35a59427836264" category="inline-image-macro-rx" type="image"></block></block>
  <block id="510d39751378d8f38e07c02ea0fc6be6" category="list-text">WordPressアプリケーションを選択すると、概要画面が表示されます。[設定]ボタンをクリックします。</block>
  <block id="10caa5e50634911a226bf4aadc5a0c7a" category="inline-image-macro">WordPressの概要画面</block>
  <block id="096a5432cb51a4b959599922c18c06c1" category="paragraph"><block ref="096a5432cb51a4b959599922c18c06c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6ef5c869d6fe64bd1b351a45360b963" category="list-text">次のページで、導入先のクラスタを選択する必要があります。このケースではDemo -Cluster新しいネームスペースとアプリケーションインスタンス名を選択または作成し、WordPressアプリケーションとその元のMariaDBデータベースの両方に必要なストレージクラスと永続的ボリュームサイズを選択します。どちらの場合も、ONTAP NASとCSIのストレージクラスを選択します。</block>
  <block id="355246a53a979cfb1041a2b1940f6879" category="inline-image-macro">WordPressの構成</block>
  <block id="d888949dd50bbca6d60ecc23eaef49f9" category="paragraph"><block ref="d888949dd50bbca6d60ecc23eaef49f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d655c70f06a3434e67cbfc80248a9a" category="admonition">[パブリックIPアクセスを有効にする]は選択しないでください。オンプレミスのAnthos環境からアクセスできないタイプのNodePortのサービスが作成されます。</block>
  <block id="afab588b2fdc93623ccf8cb877caf4da" category="list-text">Deployボタンをクリックすると、アプリケーションの詳細を示すページが表示されます。このページを更新するか、CLIを使用してクラスタにログインし、導入のステータスを確認できます。</block>
  <block id="31e41095bfaa14799239e8d9ba7ad438" category="inline-image-macro">アプリケーションの詳細</block>
  <block id="d0354e2068a16698befdae7925d598c8" category="paragraph"><block ref="d0354e2068a16698befdae7925d598c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="182bdd798d19f66a7142e53dc7ba7d03" category="list-text">CLIを使用すると、アプリケーションが展開されているときの状態を確認できます。このコマンドを実行すると、アプリケーションの名前空間にあるポッド情報を取得できます。「kubectl get pos-n Anthos-wp」</block>
  <block id="4fdb8b8bf983b608be34dc4a03f63bae" category="inline-image-macro">Kubectlポッドを購入する</block>
  <block id="5d15d1dcdf1862334a130d3d7fe69ccc" category="paragraph"><block ref="5d15d1dcdf1862334a130d3d7fe69ccc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e9914dac3fe74f2b341b37fde931ccc8" category="admonition">このスクリーンショットでは、エラー状態のDeployerポッドがあることに注意してください。これは正常な状態です。このポッドは、他のポッドが初期化プロセスを開始した後に自動的に終了するアプリケーションを展開するためにGoogle Cloud Consoleによって使用されるヘルパーポッドです。</block>
  <block id="9d8881c161170e208f09b8b2a142a66f" category="list-text">しばらくしてから、アプリケーションが実行されていることを確認します。</block>
  <block id="ce0590d3b5f26b188a077af82f7344a2" category="inline-image-macro">アプリケーションが実行中です</block>
  <block id="011a851bc4637452cc423fc951144521" category="paragraph"><block ref="011a851bc4637452cc423fc951144521" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3acabe74bca98e10c24bed74bda730" category="section-title">アプリケーションを公開しています</block>
  <block id="76ce15c259c30934261379d5c782fb7a" category="paragraph">アプリケーションを展開した後、そのアプリケーションに世界に到達可能なIPを割り当てるには、2つの方法があります。</block>
  <block id="636274e5bcac1260da12a33d8dae0b1e" category="section-title">Google Cloud Consoleを使用します</block>
  <block id="affe13ca759d7abbd8dd52510dcccb9d" category="paragraph">Google Cloud Consoleを使用してアプリケーションを公開し、ブラウザでサービスのYAML出力を編集して、一般に到達可能なIPを設定できます。そのためには、次の手順を実行します。</block>
  <block id="e14de37e4860e0a27178cce381f79223" category="list-text">Google Cloud Consoleの左側のメニューで、[サービスと入力]をクリックします。</block>
  <block id="7888520f99ee2ce14da11b431d5ae318" category="inline-image-macro">サービスおよび入力</block>
  <block id="a30c95bc1250f0f260b3859484a79e52" category="paragraph"><block ref="a30c95bc1250f0f260b3859484a79e52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6187f833f4cb9c4f7b8ee4db49498f1b" category="list-text">[wordpress -wordpress -svc]サービスをクリックします[Service Details]画面が開きます。上部の[編集]ボタンをクリックします。</block>
  <block id="d203ca99d4a0afdab1bcfe540a547944" category="inline-image-macro">サービスの詳細を編集します</block>
  <block id="572acf06c07873db504c906b27cd9089" category="paragraph"><block ref="572acf06c07873db504c906b27cd9089" category="inline-image-macro-rx" type="image"></block></block>
  <block id="668b0ecfd7e72dc665e312c2993930b3" category="list-text">サービスのYAML情報を含む[サービスの詳細の編集]ページが開きます。「spec:」セクションと「type:」値が表示されるまで下にスクロールします。「clusterIP」に設定されています。この値を「LoadBalancer」に変更し、「Save」ボタンをクリックします。</block>
  <block id="d6b6ff61b6af359d37d3635e95073c9d" category="inline-image-macro">ClusterIP値と入力します</block>
  <block id="198f2e2e4e51b005096e30bd1dc74de8" category="paragraph"><block ref="198f2e2e4e51b005096e30bd1dc74de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5f9f0194a478fbc7f5f93f46c2953de" category="inline-image-macro">LoadBalancer valueと入力します</block>
  <block id="51301646eb8394e4ac0765ad84f0d777" category="paragraph"><block ref="51301646eb8394e4ac0765ad84f0d777" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7331da14461f4638eebbff81857db51" category="list-text">[サービスの詳細]ページに戻ると、[種類:]には「ロードバランサ」が、[外部エンドポイント:]フィールドには、MetalLBプールから割り当てられたIPアドレス、およびアプリケーションがアクセス可能なポートが一覧表示されます。</block>
  <block id="3ec7f6e26f5dfb369960a71540f97a1f" category="inline-image-macro">サービスの詳細は最後です</block>
  <block id="e5b2b641e4db64d79ddda6476267c442" category="paragraph"><block ref="e5b2b641e4db64d79ddda6476267c442" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74e17d078471c59b2bf53ed27db0fb1f" category="section-title">Kubectlを使ってサービスにパッチを適用する</block>
  <block id="f022ee3e39dabcf83208cc99a6eb4a8b" category="paragraph">アプリケーションを公開するには、CLIおよび「kubectl patch」コマンドを使用して展開を変更し、公開到達可能なIPを設定します。これには、次の手順を実行します。</block>
  <block id="7d217d270c695202071f85ac46866514" category="list-text">名前空間内のポッドに関連付けられているサービスを'kubectl get services -n Anthos-wp'コマンドで一覧表示します</block>
  <block id="fe7c7c8f844859020a7db7a331ade810" category="inline-image-macro">サービスを表示します</block>
  <block id="45c0563dbcc7191f2f4360b2e8740e4a" category="paragraph"><block ref="45c0563dbcc7191f2f4360b2e8740e4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6969be1fd50af4592e0d142a1d8d70cd" category="list-text">次のコマンドを使用して、サービスタイプを「ClusterIP」から「Loadbalancer」タイプに変更します。</block>
  <block id="ee64374fc07de409e3af533d716265a7" category="paragraph">この新しいサービスタイプには、MetalLBプールから使用可能なIPアドレスが自動的に割り当てられます。</block>
  <block id="c2a179dcfc744c6d0e1f8e669f780a31" category="inline-image-macro">サービスをロードバランサタイプにパッチします</block>
  <block id="ee6e2870bddeced39fa0bbc481e1cd21" category="paragraph"><block ref="ee6e2870bddeced39fa0bbc481e1cd21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="515ddbc3d2b92a28024949cdc11effe0" category="section-title">公開されている外部IPでアプリケーションにアクセスします</block>
  <block id="9f32f710fb943684fe7ac71944e06000" category="paragraph">公開されたアプリケーションに公開されたIPアドレスが公開されたので、ブラウザを使用してWordPressインスタンスにアクセスできます。</block>
  <block id="3922853243ef47d8d33c4ed74259c64a" category="inline-image-macro">WordPressがブラウザにあります</block>
  <block id="d989de00c947c6c543a0711c796da0b3" category="paragraph"><block ref="d989de00c947c6c543a0711c796da0b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f498970d77b95b37672534275d7e8b40" category="paragraph"><block ref="f498970d77b95b37672534275d7e8b40" category="inline-link-macro-rx"></block></block>
  <block id="21e8ffc6f822b183559b39b43061c1d2" category="summary">ネットアップは、Anthosなどのコンテナベース環境における永続的データのオーケストレーションや管理を支援する製品を多数提供しています。</block>
  <block id="7a8b9d74335d44fbaaf7f5d5aebf0cfd" category="paragraph">Google Cloudは、Anthos Readyストレージパートナープログラムを通じて、パートナー様のストレージ統合とAnthosの新しいリリースの統合に関する最新検証を定期的にリクエストしています。現在検証済みのストレージソリューション、CSIドライバ、使用可能な機能、サポートされているAnthosのバージョンのリストが見つかります<block ref="0ccc93736ba595a77f031ff105798de0" category="inline-link-rx"></block>。</block>
  <block id="ea3b8c601657928fee815e0d16908cf1" category="paragraph">ネットアップは、ネットアップのAstra Trident CSI準拠ストレージオーケストレーションツール、およびONTAP とElementストレージシステムとAnthosのバージョンの検証を求める要望を、四半期ごとに定期的に満たしています。</block>
  <block id="d9c9cc94777c7797db966b663b32ce4d" category="paragraph">次の表に、ネットアップおよびネットアップパートナーのエンジニアが、Anthos Readyストレージパートナープログラムの一環としてNetApp Astra CSIドライバおよび機能セットの検証にテストしたAnthosのバージョンを示します。</block>
  <block id="84aafd4e962655f32c5bdea750278fba" category="paragraph">ネットアップは、Anthosなどのコンテナベース環境における永続的データのオーケストレーションと管理に役立つ製品を多数提供しています。</block>
  <block id="55713395841bbe573d35c776279d08cc" category="paragraph">NetApp Astra Tridentは、オープンソースで、Anthosを含むコンテナやKubernetesディストリビューション向けの完全にサポートされているストレージオーケストレーションツールです。詳細については、 Astra Trident の Web サイトをご覧ください<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>。</block>
  <block id="7b83f653c093c1509ca751b06a9ba82f" category="inline-link-macro">次のセクションでは、NetApp Astra Tridentの概要について説明します。</block>
  <block id="ee33055a07370e6d1e33ad7480a57a7b" category="paragraph"><block ref="ee33055a07370e6d1e33ad7480a57a7b" category="inline-link-macro-rx"></block></block>
  <block id="305e92355c5c05eac28d2fbad20eaa5c" category="list-text">*Anthos管理ワークステーション*gkectl'および'kubectl'コマンドを実行してAnthos展開を展開および操作できる配置ホスト</block>
  <block id="3cd74a54f5924b896bf9cb97397e8b35" category="list-text">*管理クラスタ。* VMware上でAnthosクラスタをセットアップする際に最初に導入されたクラスタ。このクラスタは、導入、拡張、アップグレードなど、下位のユーザクラスタ操作をすべて管理します。</block>
  <block id="11b774f9c0d1531100a341b6da7d98fa" category="list-text">*ユーザクラスタ。*各ユーザクラスタには独自のロードバランサインスタンスまたはパーティションが導入されているため、ユーザまたはグループごとにスタンドアロンのKubernetesクラスタとして機能し、マルチテナンシーを完全に実現できます。</block>
  <block id="b4dfd3f706cb0162d524cf7c36093e7c" category="paragraph">次の図は、VMware環境のAnthos-clusters-onの概要 を示しています。</block>
  <block id="f34111b15d3f3387462dd512dde1392f" category="list-text">*コスト削減。*エンドユーザーは、複数のユーザークラスタを同じ物理環境に導入し、Google Cloud環境や大規模なベアメタルクラスターにリソースをプロビジョニングする代わりに、アプリケーション導入に独自の物理リソースを使用することで、大幅なコスト削減を実現できます。</block>
  <block id="f89d1a459fed3d81a3b4a7360d0e85fc" category="list-text">* VMware vSphere vMotion。* VMware vCenterでは、要求に応じて、無停止でクラスタ内のノード間でVMをホット移行できます。</block>
  <block id="e7a811d106a4076d6c6992a7b97734a0" category="paragraph">次の表に、ネットアップとパートナーが解決策 の検証に使用したvSphereのバージョンを示します。</block>
  <block id="0dc619d5fd0af9a7a1c5ddea5b3e05a4" category="paragraph">Anthosは、デモや評価用に3ノード未満のvSphereクラスタにインストールすることは可能ですが、本番環境のワークロードには推奨されません。2つのノードでは基本的なHAとフォールトトレランスを実現できますが、デフォルトのホストアフィニティを無効にするようにAnthosクラスタ構成を変更する必要があります。この導入方法はGoogle Cloudではサポートされていません。</block>
  <block id="67243afe565a819d977d538c55049340" category="admonition">Anthosには'cluster.yamlファイルごとに構成オプションがあり'環境内のESXiホストの数に基づいて有効または無効にできるノードアフィニティルールが自動的に作成されます</block>
  <block id="748635e1daf718400c0f3bdeb448cf73" category="inline-link-macro">次の例は、ベアメタルのAnthosです。</block>
  <block id="3f3ed1875910e0d28d2c97b78338cc3d" category="paragraph"><block ref="3f3ed1875910e0d28d2c97b78338cc3d" category="inline-link-macro-rx"></block></block>
  <block id="941b2b9e397e77b597402b51e7ef131d" category="paragraph"><block ref="941b2b9e397e77b597402b51e7ef131d" category="inline-link-macro-rx"></block></block>
  <block id="2f0792348007b672e999da06f311bd6f" category="summary">Astra Tridentは、コンテナやKubernetesディストリビューション向けの、Anthosを含む、完全にサポートされているオープンソースストレージオーケストレーションツールです。</block>
  <block id="c91efa18f13fad38864e99107352d0c5" category="paragraph">Astra Tridentは、コンテナやKubernetesディストリビューション向けの、Anthosを含む、完全にサポートされているオープンソースストレージオーケストレーションツールです。Tridentは、NetApp ONTAP やElementストレージシステムなど、ネットアップのストレージポートフォリオ全体と連携し、NFS接続とiSCSI接続もサポートします。Trident を使用すると、ストレージ管理者の手を煩わせることなく、エンドユーザがネットアップストレージシステムからストレージをプロビジョニングして管理できるため、 DevOps ワークフローが高速化されます。</block>
  <block id="e16f8b7c3b79f3d80b3d5b5862b4481a" category="paragraph">管理者は、プロジェクトのニーズとストレージシステムモデルに基づいて複数のストレージバックエンドを構成し、圧縮、特定のディスクタイプ、QoSレベルなどの高度なストレージ機能を有効にして一定のレベルのパフォーマンスを保証できます。定義されたバックエンドは、プロジェクトの開発者が永続的ボリューム要求（ PVC ）を作成し、永続的ストレージをオンデマンドでコンテナに接続するために使用できます。</block>
  <block id="239c66c0132fd8324d609e4f1ce89f79" category="paragraph">2022年4月にAstra Tridentの最新バージョン22.04がリリースされました。Trident のどのバージョンがサポートされているかを確認できます Kubernetes ディストリビューションのテストに使用<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>。</block>
  <block id="1efa4d2f8950cdd5154a6c130953c9f2" category="paragraph">22.04リリースでは、Trident Operatorのインストールを容易にするためにHelmチャートを使用できるようになりました。</block>
  <block id="27bed77b9cf648bc4592d40c2806fb43" category="paragraph">Helmを使用して、導入したユーザクラスタでTridentのインストールを自動化し、永続ボリュームをプロビジョニングするには、次の手順を実行します。</block>
  <block id="c9c8f06cd5f25063dedfc6eea2b08fa7" category="inline-link">Helmインストールページ</block>
  <block id="43eba64dcd06763432addbcf8db2d367" category="list-text">Trident Helmリポジトリを追加します。</block>
  <block id="6a05a869c72ac896a6f7473fba5c9b1e" category="paragraph">導入したユーザクラスタにTridentを手動でインストールし、永続ボリュームをプロビジョニングするには、次の手順を実行します。</block>
  <block id="79273cfc4ab66c2763755b11b14fedb9" category="list-text">インストールアーカイブを管理ワークステーションにダウンロードし、内容を展開します。Tridentの最新バージョンは22.04で、ダウンロード可能です<block ref="c7e04c62da3fb5014b467863172d941c" category="inline-link-rx"></block>。</block>
  <block id="f0d8974fd014601f60573d339d525772" category="list-text">Tridentにはこのファイルを渡すオプションがないため、ユーザクラスタの「kubeconfig」ファイルの場所を環境変数として設定します。</block>
  <block id="1b8283857d1e7c1a4e80a12b3ba66ad9" category="paragraph"><block ref="1b8283857d1e7c1a4e80a12b3ba66ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2540200d51d81caebf749b3eb92aa66f" category="paragraph"><block ref="2540200d51d81caebf749b3eb92aa66f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="695cc7df9129054b4e4bd425d0094832" category="paragraph"><block ref="695cc7df9129054b4e4bd425d0094832" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79cdad7595deba66ecab4005ebe50206" category="paragraph"><block ref="79cdad7595deba66ecab4005ebe50206" category="inline-image-macro-rx" type="image"></block></block>
  <block id="235db056b84e051c45e51c19dc088d7a" category="paragraph"><block ref="235db056b84e051c45e51c19dc088d7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54132be89475e52a0550d90f4b162e74" category="paragraph"><block ref="54132be89475e52a0550d90f4b162e74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7f329dfec2100f6b17e76aecd655cac" category="paragraph"><block ref="a7f329dfec2100f6b17e76aecd655cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ad0944f93fe082ef02313cd33db47" category="paragraph"><block ref="ec1ad0944f93fe082ef02313cd33db47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28eb5fe5f641c3ffa32f2488fa166a36" category="paragraph">このリファレンスガイドで解決策 は、ネットアップとエンジニアリングパートナーの協力のもと、Anthosを複数のデータセンター環境に導入する際の検証について説明します。また、ネットアップストレージシステムとのストレージ統合の詳細についても、Astra Tridentストレージオーケストレーションツールを使用して永続的ストレージを管理する方法を紹介しています。最後に、解決策 検証と実際のユースケースをいくつか確認して文書化します。</block>
  <block id="0d3aabd1c9ad032e07b543d0aff99cb1" category="list-text">ベアメタル上の「bmctl」ツールまたはVMware vSphere上の「gkectl」ツールを使用して展開されたAnthos環境の導入と管理が容易になります。</block>
  <block id="ee1ef628edbfb6bb102163064fbd3d8e" category="paragraph">NetApp解決策 を搭載したAnthosは、このような課題に対応し、お客様のデータセンター環境にオンプレミス環境に完全に自動化された導入を実装することで、それぞれの問題に対処できる解決策 を提供します。</block>
  <block id="ff870d33a6cd8a05e92781267ae2d76c" category="inline-link-macro">次の例は、Anthosの概要です。</block>
  <block id="c3d162eb5f173883de1167105528ba0b" category="paragraph"><block ref="c3d162eb5f173883de1167105528ba0b" category="inline-link-macro-rx"></block></block>
  <block id="ffedc012b4decbb02d6a5ca1791f3d60" category="admonition">「kubeadmin」ユーザを使用してプライベートレジストリにログインする場合は、パスワードの代わりにトークンを使用します。</block>
  <block id="b0215348c4b61c9ef3af7e95c45db79b" category="doc">Seesawロードバランサをインストールしています</block>
  <block id="2498fd03c323b46a1d209aa07977fa55" category="paragraph">Seesawは、VMware環境のAnthosクラスタにインストールされているデフォルトのマネージドネットワークロードバランサで、バージョン1.6～1.10です。</block>
  <block id="1de0bfc08643a28f36a8fcd5662e17f0" category="section-title">シーソーロードバランサの取り付け</block>
  <block id="7e83a37698e612c5150b6c3a383cf59b" category="paragraph">Seesawロードバランサは、VMware上のAnthosクラスタと完全に統合されており、AdminクラスタとUserクラスタセットアップの一部として自動で導入されています。'cluster.yaml'コンフィギュレーションファイルには'ロード・バランサ情報を提供するために変更する必要があるテキストのブロックがあります次に'組み込みのgkectl'ツールを使用してロード・バランサを導入するためのクラスタ配備の前に'追加のステップがあります</block>
  <block id="3d4d180e7186ad7195269636446a1c4c" category="admonition">シーソーロードバランサは、HAモードまたは非HAモードで展開できます。この検証の目的で、シーソーロードバランサはデフォルト設定である非HAモードで展開されました。本番環境では、フォールトトレランスと信頼性を確保するために、HA構成でシーソーを導入することを推奨します。</block>
  <block id="613f73d2545e2e4434e09e47400d96a6" category="paragraph">管理クラスタ用の各構成ファイルと、オンプレミスのAnthosで管理されるようにロードバランサを構成するために導入するユーザクラスタごとにセクションがあります。</block>
  <block id="71f92aabf82706f3d2a00af1b3a34f95" category="paragraph">Seesawロードバランサには、クラスタの展開ごとに提供する必要のある個別の静的な「seesaw-block.yaml」ファイルもあります。このファイルは'cluster.yaml配備ファイルと同じディレクトリに配置する必要がありますまたは'上記のセクションでフルパスを指定する必要があります</block>
  <block id="cda0b5b1eab2f931076d0edc39a6920a" category="paragraph">「admin-seesa-block.yaml」ファイルのサンプルは、次のスクリプトのようになります。</block>
  <block id="967a8ba34c500bbb53dbf69cee7587d9" category="doc">Red Hat OpenShiftクラスタをAstra Control Centerに登録します</block>
  <block id="d2b3fd1f3d8ac38be89cec192a9d1558" category="list-text">最初のステップでは、 OpenShift クラスタを Astra Control Center に追加して管理します。[クラスタ]に移動し、[クラスタの追加]をクリックして、OpenShiftクラスタの「kubeconfig」ファイルをアップロードし、[ストレージの選択]をクリックします。</block>
  <block id="0fafca9f5d93d0accfd1e6ed440a772b" category="list-text">Astra Control Center を使用して OpenShift クラスタ間でバックアップとリストアを行うには、 S3 プロトコルをサポートするオブジェクトストレージバケットをプロビジョニングする必要があります。現在サポートされているオプションは、 ONTAP S3 、 StorageGRID 、および AWS S3 です。このインストールのために、 AWS S3 バケットを設定します。バケットに移動し、バケットの追加をクリックして、汎用 S3 を選択します。S3バケットの詳細とアクセスするためのクレデンシャルを入力し、Make this Bucket the Default Bucket for the Cloud（このバケットをクラウドのデフォルトバケットにする）チェックボックスをクリックして、Add（追加）をクリックします。</block>
  <block id="048fd5f2b27a172a00e3a014fbc0161b" category="inline-link-macro">次に、保護するアプリケーションを選択します。</block>
  <block id="6178a48a7c4c2e616e1caf9190bf41e6" category="paragraph"><block ref="6178a48a7c4c2e616e1caf9190bf41e6" category="inline-link-macro-rx"></block></block>
  <block id="8a7ac28f4ab44e0d4f4da82c8faf774a" category="summary">このページからリンクされたこのビデオでは、ベアメタルクラスタにAnthosを導入する方法について説明します。</block>
  <block id="6ca531ff48fc42e961c1b239f4302fab" category="doc">ベアメタルクラスタへのAnthosの導入</block>
  <block id="cb0b7b75afe3f65d378ff6ab2c93d899" category="paragraph">このビデオでは、ベアメタルクラスタにAnthosを導入する方法を紹介します。</block>
  <block id="97c62d2df3f6258616bde0882c4b890e" category="inline-link-macro">次へ：追加情報</block>
  <block id="5866caac5ce4e920cd3e5d0cd82ea8b7" category="paragraph"><block ref="5866caac5ce4e920cd3e5d0cd82ea8b7" category="inline-link-macro-rx"></block></block>
  <block id="fc31dc82d7754f65126c60eab5625947" category="inline-link-macro">Google Cloud Consoleを使用してアプリケーションをインストールします</block>
  <block id="627662d598c35dc9438ec1747d7766dc" category="paragraph"><block ref="627662d598c35dc9438ec1747d7766dc" category="inline-link-macro-rx"></block></block>
  <block id="ee1514b17e642c9cd1384a20cec220e3" category="summary">このページからにリンクされたビデオでは、このドキュメントに記載されている機能の一部を紹介しています。</block>
  <block id="63e2e4c63022a2ca3a58778bd242195b" category="paragraph">次のビデオでは、このドキュメントに記載されている機能の一部を紹介します。</block>
  <block id="1adda60fb6ef5adf0c35c53442bdd87d" category="inline-link-macro">ビデオ：ベアメタルへのAnthosの導入</block>
  <block id="81082fb0b2db5311a27c6cd75db69481" category="paragraph"><block ref="81082fb0b2db5311a27c6cd75db69481" category="inline-link-macro-rx"></block></block>
  <block id="18d4f7e36efb77494db296ea83bc4753" category="paragraph">ネットアップとともに導入されたベアメタルクラスタ上のAnthosの詳細については、を参照してください <block ref="eb911f2bc48f3132c014132a2870169f" category="inline-link-macro-rx"></block>。</block>
  <block id="d6c97ba6a05169248582981cf5627522" category="inline-link-macro">次の例は、VMware環境のAnthosクラスタです。</block>
  <block id="9954fadf8d7c9568ecdb434ffa0a15c1" category="paragraph"><block ref="9954fadf8d7c9568ecdb434ffa0a15c1" category="inline-link-macro-rx"></block></block>
  <block id="d42437507a421bfdd38119d600ab0014" category="sidebar">AWS EC2/FSXのベストプラクティスにOracleデータベースを導入する</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="sidebar">導入手順</block>
  <block id="71ab9d8f34c9ab92ef83627b823e9825" category="sidebar">データベース管理</block>
  <block id="c3b88d5ff29715f5f8dd3c907b3f1bc3" category="sidebar">データベースの移行</block>
  <block id="f1d1e6ba9a2b7db0fa9da49e0e72d8e2" category="inline-link-macro">次の手順：Seesawロードバランサをインストールしています。</block>
  <block id="bbceb5257bbc998fe84b078ef4d5062b" category="paragraph"><block ref="bbceb5257bbc998fe84b078ef4d5062b" category="inline-link-macro-rx"></block></block>
  <block id="1781760e35ea460b2019eb0440baf384" category="paragraph"><block ref="1781760e35ea460b2019eb0440baf384" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6909280d84c97f4c2d6301b2d570e37a" category="paragraph"><block ref="6909280d84c97f4c2d6301b2d570e37a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="441be298f9b7d68522f3e6df5d9629e2" category="inline-link-macro">次の例：MetalLBロードバランサをインストールします。</block>
  <block id="9c79b190423dda0c207aac371557f50a" category="paragraph"><block ref="9c79b190423dda0c207aac371557f50a" category="inline-link-macro-rx"></block></block>
  <block id="bf19992eca1061913e185b60f91a8344" category="list-text"><block ref="bf19992eca1061913e185b60f91a8344" category="inline-link-macro-rx"></block></block>
  <block id="297afb95cdd3600afb3f67c77b24215f" category="list-text"><block ref="297afb95cdd3600afb3f67c77b24215f" category="inline-link-macro-rx"></block></block>
  <block id="0395f03c04f82443f0fc31b418d2ded6" category="list-text"><block ref="0395f03c04f82443f0fc31b418d2ded6" category="inline-link-macro-rx"></block></block>
  <block id="6f838db94915ec121c6b32b1df99a983" category="inline-link-macro">次に、F5 BIG-IPロードバランサをインストールします。</block>
  <block id="ecdb02c5420667abdb9a61d02af359c2" category="paragraph"><block ref="ecdb02c5420667abdb9a61d02af359c2" category="inline-link-macro-rx"></block></block>
  <block id="ea3f2894c4df21a157c45dcbcf989bda" category="paragraph">以下のページでは、追加情報 解決策 を使用したAnthosでアプリケーションおよび永続的ストレージの管理向けに検証されたネットアップ製品について説明します。</block>
  <block id="c49053fbce1331670d3c2e81d9625fec" category="admonition">Helmは、デフォルトではGKE-Adminワークステーションにインストールされません。からUbuntuと連動するバイナリ形式でダウンロードできます<block ref="3d578643c15f985f07ca6d975ab0e791" category="inline-link-rx"></block>。</block>
  <block id="deae9c61cc109057bffb21d54fd54cdc" category="paragraph">Astra Trident Operator のインストールが完了したら、使用するネットアップストレージプラットフォームに合わせてバックエンドを設定する必要があります。Astra Tridentのセットアップと設定を続行するには、次のリンクを参照してください。</block>
  <block id="6ed9d9e6160cedf6c16c9fa74e9d08aa" category="inline-link-macro">次のステップ：NetApp ONTAP NFS</block>
  <block id="86beb69e1e89df92a89baa0d004b08b8" category="paragraph"><block ref="86beb69e1e89df92a89baa0d004b08b8" category="inline-link-macro-rx"></block></block>
  <block id="06a9f54df07db88477918bd7c3f597de" category="inline-link-macro">次の例は、NetApp Element iSCSIです。</block>
  <block id="dd8532ad7059feaef43031ffa5970de1" category="paragraph"><block ref="dd8532ad7059feaef43031ffa5970de1" category="inline-link-macro-rx"></block></block>
  <block id="0a180196354cfbb6ec70b20db067fa6b" category="inline-link-macro">次へ：NetApp Element</block>
  <block id="73978739caea0775c3c807ecfc27f0c0" category="paragraph"><block ref="73978739caea0775c3c807ecfc27f0c0" category="inline-link-macro-rx"></block></block>
  <block id="5aad41fe64600c5795950512637ebae3" category="inline-link-macro">次の手順：ロードバランサオプションを確認します。</block>
  <block id="0b44acd6b2e7596e640212aa28de05c5" category="paragraph"><block ref="0b44acd6b2e7596e640212aa28de05c5" category="inline-link-macro-rx"></block></block>
  <block id="d0ee5cd6f53ec708670800837b7502b7" category="inline-link-macro">次のステップ：NetApp ONTAP iSCSI</block>
  <block id="884a92818052da7764b1c5b7589bd458" category="paragraph"><block ref="884a92818052da7764b1c5b7589bd458" category="inline-link-macro-rx"></block></block>
  <block id="eec34a14279b64231b91793978a204da" category="paragraph"><block ref="eec34a14279b64231b91793978a204da" category="inline-link-macro-rx"></block></block>
  <block id="f6762efea56447c717fea204b2676851" category="list-text">[ 次へ ] をクリックして各手順を続行し、ストレージ選択画面に達するまで表示される各画面のデフォルト値を受け入れます。仮想マシンを導入するVM_Datastoreを選択し、Nextをクリックします。</block>
  <block id="da0289d58f35e36d18325d6e8038b226" category="admonition">このファイルに定義されているオプションのフィールド「 fsType 」があります。iSCSIバックエンドでは、この値を特定のLinuxファイルシステムタイプ（XFS、ext4など）に設定するか、ワーカーノードのOSが使用するファイルシステムを決定できるようにするためにこの値を削除することができます。</block>
  <block id="ca2835359be5e4e2e79ed5b6fd777515" category="paragraph"><block ref="ca2835359be5e4e2e79ed5b6fd777515" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f154001e329eb4cb13b7745ba16dac" category="doc">VMwareでサポートされるネットアップハイブリッドマルチクラウドの構成</block>
  <block id="9b5e2f812e05038b9b432b2e47e60e83" category="cell">ANF<block ref="982de57bbd4b4909ca13b7582da5a7cb" category="inline-link-macro-rx"></block></block>
  <block id="1d2f8b078a75242901e868e7bd66ab6b" category="inline-link-macro">詳細^3</block>
  <block id="ef1c4ae5f356b44ca460e3aaf7bf2a32" category="cell">CVS<block ref="3317ea58799e6c9da952335ff4000296" category="inline-link-macro-rx"></block></block>
  <block id="6830947ed88b541bd76da4fcd40e36de" category="paragraph">注: 1-現在、初期可用性(IA) 2で、パブリックプレビュー3で現在プライベートプレビュー中です</block>
  <block id="9daaf09aeccc99c61fe453295253eae0" category="doc">まとめ：VMwareを使用したネットアップのハイブリッドマルチクラウドが選ばれる理由とは</block>
  <block id="0c17a5e22f572303947d9e14cd98db39" category="paragraph">ネットアップの Cloud Volume と主要ハイパースケーラ向け VMware ソリューションは、ハイブリッドクラウドの活用を検討している組織に大きな可能性をもたらします。このセクションの残りの部分では、NetApp Cloud Volume の統合によって真のハイブリッドマルチクラウド機能が実現されることを示すユースケースについて説明します。</block>
  <block id="17c56e542773e2aafc2645d0e9f0d8ec" category="summary">VMwareソリューションを使用したネットアップのハイブリッドマルチクラウドは、主要なパブリッククラウドハイパースケーラでのネットアップストレージの機能を実証する、戦略的およびテクノロジ的な機能のセットです。</block>
  <block id="eee9b49313d921d448286765fe05bd22" category="doc">AWS / VMC向けのネットアップハイブリッドマルチクラウドソリューション</block>
  <block id="27dafc6e4e2e3563b0434812fa3fee7c" category="section-title">GCPリージョンのアベイラビリティ</block>
  <block id="68c6fcf9f9393805f0529c36994a9266" category="paragraph">GCPリージョンのアベイラビリティは、GCPがパブリックアベイラビリティに移行するとリリースされます。</block>
  <block id="b632c27ff82cfe142baffd346253a21b" category="doc">VMwareを使用したネットアップハイブリッドマルチクラウドのユースケース</block>
  <block id="0257f1ddf73d49021a7feba150b7ea8b" category="paragraph">このシナリオに最も簡単に使用できる回答は、各ハイパースケーラにおける VMware ソリューションです。ネットアップの Cloud Volume と同様に、 VMware はオンプレミスの VMware 環境を任意のクラウドに移行または拡張できるため、既存のオンプレミスの資産、スキル、ツールを保持しながら、ワークロードをクラウド内でネイティブに実行できます。これにより、サービスの中断や IP 変更の必要性がなくなり、 IT チームは既存のスキルやツールを使用してオンプレミスで行う方法を運用できるようになるため、リスクが軽減されます。これにより、クラウドへの移行が高速化され、ハイブリッドマルチクラウドアーキテクチャへの移行が大幅にスムーズになります。</block>
  <block id="33a1a24f2edf4ad9358baef7fb3c9cdf" category="doc">ANFとJetStreamを使用したディザスタリカバリ</block>
  <block id="14f4fb472fe43e084476c5d8329b15f8" category="paragraph">クラウドへのディザスタリカバリは、耐障害性に優れた対費用効果の高い方法で、サイトの停止やデータ破損からワークロードを保護します（ランサムウェアなど）。VMware VAIOフレームワークを使用すると、オンプレミスのVMwareワークロードをAzure Blobストレージにレプリケートしてリカバリできるため、データ損失を最小限に抑えたり、ほぼゼロのRTOを実現できます。</block>
  <block id="b614fc13a076bceeca03cda9c4b1fdce" category="paragraph">Jetstream DRを使用すると、オンプレミスからAVS、特にAzure NetApp Files に複製されたワークロードをシームレスにリカバリできます。ディザスタリカバリサイトにある最小限のリソースと対費用効果の高いクラウドストレージを使用して、対費用効果の高いディザスタリカバリを実現します。Jetstream DRは、Azure Blob Storageを介したANFデータストアへのリカバリを自動化します。Jetstream DRは、独立したVMまたは関連するVMのグループを、ネットワークマッピングに従ってリカバリサイトインフラストラクチャにリカバリし、ランサムウェアからの保護のためのポイントインタイムリカバリを提供します。</block>
  <block id="29d141d1797b070195b4a3a5af842d35" category="paragraph">このドキュメントでは、JetStream DRの動作原理とその主なコンポーネントについて説明します。</block>
  <block id="0b3b3c3ee7cf95d87f597441efd5f743" category="example-title">解決策 の導入の概要</block>
  <block id="1dff5e9fa7f5c212df3e98d343d6a771" category="list-text">JetStream DRソフトウェアをオンプレミスのデータセンターにインストールします。</block>
  <block id="7b87ce74b3d0f7e81fef7a7994f9c8ed" category="list-text">JetStream DRソフトウェアバンドルをAzure Marketplace（ZIP）からダウンロードし、JetStream DR MSA（OVA）を指定のクラスタに導入します。</block>
  <block id="56c27e9a114a51f4863d0fef4cab3eba" category="list-text">I/Oフィルタパッケージを使用してクラスタを設定します(JetStream VIBをインストールします)。</block>
  <block id="43de8924da88a34109307d6aac84811a" category="list-text">DR AVSクラスタと同じリージョンでAzure Blob（Azureストレージアカウント）をプロビジョニング</block>
  <block id="2cee29b70a6ea4765a6365e4d71775c7" category="list-text">DRVAアプライアンスを導入し、レプリケーションログボリューム（既存のデータストアまたは共有iSCSIストレージからVMDK）を割り当てます。</block>
  <block id="9c6ca12d0f999d69d715e02482665e5d" category="list-text">保護されたドメイン（関連するVMのグループ）を作成し、DRVAとAzure Blob Storage / ANFを割り当てます。</block>
  <block id="04fd46fc4d0422c8562609b47b636797" category="list-text">保護を開始します。</block>
  <block id="8391f9ad7383911e1b8e67d8dfd23ffb" category="list-text">JetStream DRソフトウェアをAzure VMware解決策 プライベートクラウドにインストールします。</block>
  <block id="81aaea44e289ce199fea205f7d0b8cd9" category="list-text">Runコマンドを使用して、JetStream DRをインストールおよび設定します。</block>
  <block id="ef261b549f401ed8d66b72f8310d7376" category="list-text">[Scan Domains]オプションを使用して、同じAzure BLOBコンテナを追加し、ドメインを検出します。</block>
  <block id="3c22f96e96fb514aec06cc03a6d35958" category="list-text">必要なDRVAアプライアンスを導入します。</block>
  <block id="a8930e0df42395d789466e0695d11ce7" category="list-text">使用可能なvSANまたはANFデータストアを使用してレプリケーションログボリュームを作成します。</block>
  <block id="087316b53a71d576c6dfeda2385ef108" category="list-text">保護されたドメインをインポートし、VMの配置にANFデータストアを使用するようにRocVA（リカバリVA）を設定します。</block>
  <block id="f47df812f6139d9d12dc179df9e7da57" category="list-text">適切なフェイルオーバーオプションを選択し、ほぼゼロのRTOドメインまたはVMに対して継続的なリハイドレートを開始します。</block>
  <block id="eb50fc931b0aff72e9034088a04a260b" category="list-text">災害発生時に、指定したAVS DRサイトでAzure NetApp Files データストアへのフェイルオーバーをトリガーします。</block>
  <block id="21e74b3c28d006317f38a2bc8eb1da3b" category="inline-link">Azure Marketplace で入手できます</block>
  <block id="f314a6aa5faf9dfffba2cdac4d4dd420" category="list-text">保護対象サイトのリカバリ後、保護対象サイトへのフェイルバックを起動します。開始する前に、前提条件が満たされていることを確認してください<block ref="600591f3feccd7454d660dd4d2972306" category="inline-link-rx"></block> また、JetStream Softwareが提供するBandwidth Testing Tool（BWT）を実行して、JetStream DRソフトウェアで使用した場合にAzure BLOBストレージとそのレプリケーション帯域幅のパフォーマンスを評価します。接続を含む前提条件が整ったら、からJetStream DR for AVSをセットアップして登録します<block ref="e842a0f9c9000f3898fd5cb9408b8b3e" category="inline-link-rx"></block>。ソフトウェアバンドルをダウンロードしたら、上記のインストールプロセスに進みます。</block>
  <block id="01543f177a0cc07917f4dc3510b8649e" category="paragraph">多数のVM（100+など）の保護を計画して開始する場合は、JetStream DR Automation ToolkitからCapacity Planning Tool（CPT）を使用します。RTOとリカバリ・グループの設定とともに保護対象のVMのリストを指定し、CPTを実行します。</block>
  <block id="ddfb9ed8decef8b3db76f88d682c7f1e" category="paragraph">CPTは次の機能を実行します。</block>
  <block id="ab5991781a05bc72668a8bf941d7a4a5" category="list-text">RTOに応じたVMを保護ドメインに統合する。</block>
  <block id="b3229123cf8dd56b28f1a8e13f79ddde" category="list-text">DRVAとそのリソースの最適な数を定義する。</block>
  <block id="2c3b2c6c87689b15c4cd3ea75cb40ef8" category="list-text">必要なレプリケーション帯域幅の見積もり</block>
  <block id="88d06f884976bb7a1ce66e51624c0196" category="list-text">レプリケーションログボリュームの特性（容量、帯域幅など）を特定します。</block>
  <block id="60a85cb526817dd0f1172dcdacc94700" category="list-text">必要なオブジェクトストレージ容量などを見積もります。</block>
  <block id="ea56b8a01683ebc544ddabe2f0fcf571" category="admonition">ドメインの数と内容は、平均IOPS、合計容量、優先度（フェイルオーバー順序を定義）、RTOなど、VMのさまざまな特性によって異なります。</block>
  <block id="fc321ed0fcff278e628765c7a327d1c0" category="section-title">JetStream DRをオンプレミスのデータセンターにインストールします</block>
  <block id="87674fd676f223da1c84cd30ba47e2d2" category="paragraph">Jetstream DRソフトウェアは、JetStream DR Management Server Virtual Appliance（MSA）、DR Virtual Appliance（DRVA）、およびホストコンポーネント（I/O Filterパッケージ）の3つの主要コンポーネントで構成されています。MSAは、コンピューティングクラスタにホストコンポーネントをインストールして構成し、JetStream DRソフトウェアを管理するために使用されます。次に、インストールプロセスの概要 の概要を示します。</block>
  <block id="44a5c8a42b561b0a83b98c7dffe66dc4" category="list-text">前提条件を確認する。</block>
  <block id="6035c664a9aaf8fa1c40e58c8beaab92" category="list-text">キャパシティプランニングツールを実行して、リソースと構成に関する推奨事項を確認します（オプションですが、コンセプトの実証の試用には推奨されます）。</block>
  <block id="ccc2ab66d8941e0dddf26ed50f55ba4c" category="list-text">JetStream DR MSAを指定されたクラスタ内のvSphereホストに展開します。</block>
  <block id="efdd725636035b733a89826db0da74f4" category="list-text">ブラウザでDNS名を使用してMSAを起動します。</block>
  <block id="39602c8241f165da483e3678f5d62871" category="list-text">vCenterサーバをMSAに登録します。インストールを実行するには、次の手順を実行します。</block>
  <block id="f6a1019b86d486190fed5e4a0c122f59" category="list-text">JetStream DR MSAが導入され、vCenter Serverが登録されたら、vSphere Web Clientを使用してJetStream DRプラグインにアクセスします。これを行うには、[データセンター]&gt;[設定]&gt;[JetStream DR]に移動します。</block>
  <block id="623c8f2c05001c7eeecb0781c049f16b" category="paragraph"><block ref="623c8f2c05001c7eeecb0781c049f16b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5b9a2e255ce372cd80d886148efdd00" category="list-text">JetStream DRインタフェースから、適切なクラスタを選択します。</block>
  <block id="699c846ab66a56017e37da99f6ea7320" category="paragraph"><block ref="699c846ab66a56017e37da99f6ea7320" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d18d2901e95370132a2545c2f511db3" category="list-text">I/Oフィルタパッケージを使用してクラスタを設定します。</block>
  <block id="34896ae2be725a2f3d42bd7b4b7888fd" category="paragraph"><block ref="34896ae2be725a2f3d42bd7b4b7888fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0598abb730b378c25cbbc28507342260" category="list-text">リカバリサイトにAzure Blob Storageを追加します。</block>
  <block id="76ef667a7a95f046d391e54cea1b9142" category="list-text">アプライアンスタブからDR仮想アプライアンス（DRVA）を導入します。</block>
  <block id="ba445d98067e8161fa165b8f25ad294d" category="admonition">DRFAはCPTによって自動的に作成できますが、POCトライアルの場合は、DRサイクルを手動で設定して実行することをお勧めします（Start protection &gt; failover &gt; failback）。</block>
  <block id="60de8eac7ca6ad5f7321abf5b462b65d" category="paragraph">JetStream DRVAは、データ複製プロセスの主要な機能を容易にする仮想アプライアンスです。保護されたクラスタには少なくとも1つのDRVAが含まれている必要があります。通常は、ホストごとに1つのDRVAが構成されます。各DRVAは、複数の保護ドメインを管理できます。</block>
  <block id="f55f11c27893cdacff776d302a9b9d07" category="paragraph"><block ref="f55f11c27893cdacff776d302a9b9d07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ece649567fdf82717852e0f8662d070" category="paragraph">この例では、4台のDRVAが80台の仮想マシン用に作成されています。</block>
  <block id="cf5c65945851f67013f23b2d83d4a346" category="list-text">使用可能なデータストアまたは独立した共有iSCSIストレージプールからVMDKを使用して、各DRVAのレプリケーションログボリュームを作成します。</block>
  <block id="9ad06750519e0664bc1ec852cc5e07b6" category="list-text">Protected Domainsタブで、Azure Blob Storageサイト、DRVAインスタンス、およびレプリケーションログに関する情報を使用して、必要な数の保護ドメインを作成します。保護ドメインは、クラスタ内の特定のVMまたはVMのセットを定義します。これらのVMは一緒に保護され、フェイルオーバー/フェイルバック処理の優先順位が割り当てられます。</block>
  <block id="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="paragraph"><block ref="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e68391e0d2ed07243f438a1d725a243a" category="list-text">保護するVMを選択し、保護ドメインのVM保護を開始します。これにより、指定したBlob Storeへのデータレプリケーションが開始されます。</block>
  <block id="24e5f5b0186cca0606b176380e3ee45c" category="admonition">保護ドメイン内のすべてのVMに同じ保護モードが使用されていることを確認します。</block>
  <block id="9870cb575efa482fab7fa9aa1fdf16ac" category="admonition">ライトバック（VMDK）モードを使用すると、パフォーマンスが向上します。</block>
  <block id="895d59858a04439859a33d3288706702" category="paragraph"><block ref="895d59858a04439859a33d3288706702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6ea2b1c670425ac09f1aadbc26e266" category="paragraph">レプリケーションログボリュームがハイパフォーマンスストレージに配置されていることを確認します。</block>
  <block id="3237de27ecac8fd3a072d337514991eb" category="admonition">フェイルオーバー実行ブックは、VM（回復グループ）のグループ化、起動順序の設定、およびCPU /メモリの設定とIP設定の変更を行うように構成できます。</block>
  <block id="840c65296e1af99a67123dd9459e5548" category="section-title">Runコマンドを使用して、Azure VMware解決策 プライベートクラウドにJetStream DR for AVSをインストールします</block>
  <block id="d2441f955b3d04e99be7845bb7af68a6" category="paragraph">リカバリサイト（AVS）では、3ノードのパイロットライトクラスタを事前に作成することを推奨します。これにより、次の項目を含むリカバリサイトのインフラを事前に設定できます。</block>
  <block id="dab895f226673c73578b4c45dead73c0" category="list-text">宛先ネットワークセグメント、ファイアウォール、DHCPやDNSなどのサービスなど。</block>
  <block id="188d8743a82411348e186c7118e92c9a" category="list-text">AVS対応のJetStream DRのインストール</block>
  <block id="fd3bf57ff38b27ccbf66886b71a34f76" category="list-text">ANFボリュームをデータストアとして構成し、moreJetStream DRではミッションクリティカルなドメインのRTOモードをほぼゼロに設定できます。これらのドメインには、デスティネーションストレージが事前にインストールされている必要があります。この場合、ANFは推奨ストレージタイプです。</block>
  <block id="89aa12cc0cd4846ef86fbe8dfd78d8bc" category="admonition">セグメント作成を含むネットワーク構成は、オンプレミスの要件に合わせてAVSクラスタ上で設定する必要があります。</block>
  <block id="d50efdb8ff06cd2518521c1d4f68a67a" category="paragraph">SLAやRTOの要件に応じて、継続的なフェイルオーバーモードや通常の（標準）フェイルオーバーモードを使用できます。RTOがほぼゼロの場合は、リカバリサイトで継続的なリハイドレートを開始する必要があります。</block>
  <block id="7c1dc76f383d9b6253a273d35f636909" category="paragraph">Azure VMware解決策 プライベートクラウドにJetStream DR for AVSをインストールするには、次の手順を実行します。</block>
  <block id="7f0bec83fc0010707471d9d3b84fd45b" category="list-text">AzureポータルからAzure VMware解決策 に移動し、プライベートクラウドを選択して、実行コマンド&gt;パッケージ&gt; JSDR.Configurationを選択します。</block>
  <block id="6e37d4d4f3c60de2fb2e2e218753f9ea" category="admonition">Azure VMware解決策 のデフォルトCloudAdminユーザには、AVS対応のJetStream DRをインストールするための十分な権限がありません。Azure VMware解決策 では、JetStream DR用のAzure VMware解決策 実行コマンドを呼び出すことで、JetStream DRを簡単かつ自動でインストールできます。</block>
  <block id="832830e8d1c5e28f4e206c65a067fbfc" category="paragraph">次のスクリーンショットは、DHCPベースのIPアドレスを使用したインストール方法を示しています。</block>
  <block id="1ca67a15b29b11c686a17480c2ecde9c" category="paragraph"><block ref="1ca67a15b29b11c686a17480c2ecde9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23fac09aaa7dcea6eb534251f50feae2" category="list-text">JetStream DR for AVSのインストールが完了したら、ブラウザをリフレッシュします。JetStream DR UIにアクセスするには、SDDC Datacenter &gt; Configure &gt; JetStream DRに移動します。</block>
  <block id="58517d8d2fa977f39ca2b76c09c43dc4" category="paragraph"><block ref="58517d8d2fa977f39ca2b76c09c43dc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bf7f298e2ed24c67b98b8d5c4e6dbe" category="list-text">JetStream DRインターフェイスから、オンプレミスクラスタをストレージサイトとして保護するために使用したAzure Blob Storageアカウントを追加し、Scan Domainsオプションを実行します。</block>
  <block id="1e976589dd0f1f098c13f4564f91813c" category="paragraph"><block ref="1e976589dd0f1f098c13f4564f91813c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4e7f9056aa9f52fd1bff1e2837a4e84" category="list-text">保護ドメインをインポートしたら、DRVAアプライアンスを展開します。この例では、JetStream DR UIを使用して、リカバリサイトから継続的なリハイドレートを手動で開始します。</block>
  <block id="7aa502331a6314a8d66df611c4538f75" category="admonition">これらの手順は、CPT作成計画を使用して自動化することもできます。</block>
  <block id="bf4fdf975fae154bdca78e36bd7edbe3" category="list-text">保護ドメインをインポートし、VMの配置にANFデータストアを使用するようにリカバリVAを設定します。</block>
  <block id="0a4fc536683686b518331dd2531934b5" category="paragraph"><block ref="0a4fc536683686b518331dd2531934b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="827098a514e7d7fc1579120ec370bfd9" category="admonition">選択したセグメントでDHCPが有効になっていて、十分なIPが使用可能であることを確認します。ダイナミックIPは、ドメインのリカバリ中に一時的に使用されます。リカバリVM（連続リハイドレートを含む）ごとに、個別のダイナミックIPが必要です。リカバリの完了後、IPは解放され、再利用できます。</block>
  <block id="10e011fef535dced7a4095544de7266d" category="list-text">適切なフェイルオーバーオプション（継続的フェイルオーバーまたはフェイルオーバー）を選択します。この例では、連続リハイドレート（連続フェールオーバー）が選択されています。</block>
  <block id="adac1a1b7a65bae37b6bd9cbd66b248a" category="paragraph"><block ref="adac1a1b7a65bae37b6bd9cbd66b248a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6a68077ca82bffe5f08d96bdcd36e18" category="section-title">フェイルオーバー/フェイルバックを実行しています</block>
  <block id="61a6473493a7f05f03d606cdfeb234d6" category="list-text">オンプレミス環境の保護対象クラスタで障害が発生した場合（部分的または完全な障害）、フェイルオーバーをトリガーします。</block>
  <block id="3a09da9a187f9208fcd685b78b772764" category="admonition">CPTを使用すると、フェイルオーバープランを実行して、Azure Blob StorageからAVSクラスタリカバリサイトにVMをリカバリできます。</block>
  <block id="f66e570f82bdb271d0adb30435ad5b2b" category="admonition">保護対象のVMがAVSで起動されると、フェイルオーバー後（継続的または標準的なリハイドレート）、保護は自動的に再開され、JetStream DRは、Azure Blob Storage内の適切なコンテナまたは元のコンテナにデータをレプリケートし続けます。</block>
  <block id="d27309d11731255db072c47f9675d22f" category="paragraph"><block ref="d27309d11731255db072c47f9675d22f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4a8f8fdcb45687697d39da1e99dc36" category="paragraph"><block ref="ef4a8f8fdcb45687697d39da1e99dc36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf84d29276236d6a8b8e75f1a2c8f115" category="paragraph">タスクバーにフェイルオーバーアクティビティの進行状況が表示されます。</block>
  <block id="8430656d9f62a51ed63ade1e47ad34f7" category="list-text">タスクが完了すると、リカバリされたVMとビジネスに通常どおりアクセスできます。</block>
  <block id="f89c6dfb9ae23126d1e04570e23dcda9" category="paragraph"><block ref="f89c6dfb9ae23126d1e04570e23dcda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c8214eaedd2bb37ba1d1b018bf4aa63" category="paragraph">プライマリサイトが起動して再び実行されるようになったら、フェイルバックを実行できます。VM保護が再開され、データの整合性を確認する必要があります。</block>
  <block id="2743b11e431e1c7f8504d917d4ffc4d6" category="list-text">オンプレミス環境をリストア災害のタイプによっては、保護対象クラスタの構成をリストアまたは検証しなければならない場合があります。必要に応じて、JetStream DRソフトウェアを再インストールする必要があります。</block>
  <block id="232732afcd0f951efbcfaea123f0a632" category="admonition">注：Automation Toolkitで提供されている「recovery_utility_prepare_failback」スクリプトを使用すると、古いVMやドメイン情報などの元の保護サイトをクリーンアップできます。</block>
  <block id="6d52b59b59572c39053e3858b37fcc57" category="list-text">リストアされたオンプレミス環境にアクセスし、Jetstream DR UIに移動して、適切な保護ドメインを選択します。保護サイトがフェイルバックできる状態になったら、UIで[Failback]オプションを選択します。</block>
  <block id="7350f3b9fc85111b45034212957d9d98" category="paragraph"><block ref="7350f3b9fc85111b45034212957d9d98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82bc01d2feed0849423b6b5676888f97" category="admonition">CPTで生成されたフェイルバックプランを使用して、VMとそのデータをオブジェクトストアから元のVMware環境に戻すこともできます。</block>
  <block id="36e8c86c253ad3dad15eaab2f5de961c" category="admonition">リカバリサイトのVMを一時停止して保護対象サイトで再起動したあとの最大遅延時間を指定します。この時間には、フェイルオーバーVMを停止したあとのレプリケーションの完了、リカバリサイトのクリーンアップにかかる時間、保護サイトでVMを再作成する時間などが含まれます。ネットアップの推奨値は10分です。</block>
  <block id="c53daff4bd6065c0627bf739410f7e88" category="paragraph">フェイルバックプロセスを完了し、VM保護およびデータの整合性が再開されたことを確認する。</block>
  <block id="ddd33ab61759ca3d4dcfcd934ab83b04" category="section-title">Ransomware回復</block>
  <block id="459d2a2d25c4ad6db53b9e0b367f3d4c" category="paragraph">ランサムウェアからのリカバリは困難な作業です。具体的には、IT組織にとって、返品の安全ポイントを特定することは困難です。また、復旧したワークロードを、（睡眠中のマルウェアや脆弱なアプリケーションによって）再発する攻撃から確実に保護する方法が決定された場合もあります。</block>
  <block id="414dfaa4bcffbd76b7f5ed891cdf1535" category="paragraph">Jetstream DR for AVSとAzure NetApp Files データストアを併用すると、組織が使用可能なポイントインタイムからリカバリできるため、ワークロードが機能的な分離されたネットワークに必要に応じてリカバリされるため、これらの問題に対処できます。リカバリを使用すると、アプリケーションが相互に機能して通信できるようになり、南北のトラフィックにさらされることがなくなります。その結果、セキュリティチームはフォレンジックなどの必要な修復を安全に実行できます。</block>
  <block id="a20215628470de7f6faa691cc18c4971" category="paragraph"><block ref="a20215628470de7f6faa691cc18c4971" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f95900d5509fa4de2d1c7e9489f4dc6" category="summary">クラウドへのディザスタリカバリは、耐障害性と対費用効果に優れた方法で、サイトの停止やランサムウェアなどのデータ破損からワークロードを保護します。NetApp SnapMirrorを使用すると、ゲスト接続ストレージを使用するオンプレミスのVMwareワークロードを、Azure内で実行されているNetApp Cloud Volumes ONTAP にレプリケートできます。</block>
  <block id="48b47eaa686f297ed741f5cb81de709d" category="paragraph">著者：Ravi BCBとNiyaz Mohamedネットアップ</block>
  <block id="be93173f941fd10be0e9fddb606bd940" category="paragraph">クラウドへのディザスタリカバリは、耐障害性と対費用効果に優れた方法で、サイトの停止やランサムウェアなどのデータ破損からワークロードを保護します。NetApp SnapMirrorを使用すると、ゲスト接続ストレージを使用するオンプレミスのVMwareワークロードを、Azure内で実行されているNetApp Cloud Volumes ONTAP にレプリケートできます。これはアプリケーションデータに適用されますが、実際のVM自体についてはどうでしょうか。ディザスタリカバリは、仮想マシン、VMDK、アプリケーションデータなど、依存するすべてのコンポーネントを対象にする必要があります。これを実現するために、JetstreamとSnapMirrorを併用すると、VM VMDK用のVSANストレージを使用しながら、オンプレミスからCloud Volumes ONTAP にレプリケートされたワークロードをシームレスにリカバリできます。</block>
  <block id="b25b60af8de6f7256f832e93e5651972" category="paragraph">本ドキュメントでは、NetApp SnapMirror、JetStream、およびAzure VMware解決策 （AVS）を使用してディザスタリカバリを設定および実行するためのステップバイステップ形式のアプローチを紹介します。</block>
  <block id="8f0e380cfb4a39395f72ab50e67ea50e" category="paragraph"><block ref="8f0e380cfb4a39395f72ab50e67ea50e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72916c3a8dffc193957f3809a8b4acbf" category="paragraph">本ドキュメントでは、アプリケーションデータ用のゲスト内ストレージ（ゲスト接続とも呼ばれます）を中心に説明します。オンプレミス環境では、アプリケーションと整合性のあるバックアップにSnapCenter を使用していると想定しています。</block>
  <block id="d2e057fdab62f3ae766c18c66acc57fd" category="admonition">本ドキュメントは、環境 サードパーティ製バックアップまたはリカバリ用解決策 に関するものです。環境で使用されている解決策 に応じて、ベストプラクティスに従って、組織のSLAを満たすバックアップポリシーを作成してください。</block>
  <block id="380a8e9be36984cc009caa1b7aaadc5d" category="paragraph">オンプレミス環境とAzure Virtual Network間の接続には、エクスプレスルートグローバルリーチまたはVPNゲートウェイを使用した仮想WANを使用します。オンプレミスVLANの設計に基づいてセグメントを作成する必要があります。</block>
  <block id="057412b2bc7b34ca7066f70b80b69510" category="admonition">オンプレミスのデータセンターをAzureに接続する方法は複数ありますが、これにより、本ドキュメントの特定のワークフローの概要がわかりません。適切なオンプレミスからAzureへの接続方法については、Azureのドキュメントを参照してください。</block>
  <block id="ecc1cadbbbb0ef1d84ddc861f4497661" category="section-title">DR解決策 の導入</block>
  <block id="5497ec7c1fdee07126ed64bf9fed5d87" category="section-title">解決策 の導入の概要</block>
  <block id="8eaa61639db3e085f8c7eb12151b3736" category="list-text">SnapCenter を使用して、必要なRPO要件に従ってアプリケーションデータがバックアップされていることを確認してください。</block>
  <block id="a04938b02e6c8ce6c9dbb34eac7d6a0a" category="list-text">適切なサブスクリプションと仮想ネットワーク内で、Cloud Managerを使用して、適切なインスタンスサイズでCloud Volumes ONTAP をプロビジョニングします。</block>
  <block id="15a6eec061b4c7d026aa504c05f01405" category="list-text">該当するアプリケーションボリュームに対してSnapMirrorを設定します。</block>
  <block id="3d1e7fac653a4e240c35721f0e3902da" category="list-text">スケジュールされたジョブの実行後にSnapMirror更新をトリガーするには、SnapCenter でバックアップポリシーを更新してください。</block>
  <block id="2a690d204d02bcc25768246a5c2082bb" category="list-text">JetStream DRソフトウェアをオンプレミスのデータセンターにインストールし、仮想マシンの保護を開始します。</block>
  <block id="060b718b1c12d4bed763206429b5c467" category="list-text">災害発生時は、Cloud Managerを使用してSnapMirror関係を解除し、指定したAVS DRサイトのAzure NetApp Files またはVSANデータストアへの仮想マシンのフェイルオーバーをトリガーします。</block>
  <block id="16193a2e612115bbf00cb18e7a9ec1aa" category="list-text">アプリケーションVMのiSCSI LUNおよびNFSマウントを再接続します。</block>
  <block id="d274e9c5c862dd28666a25176c344293" category="list-text">プライマリサイトのリカバリ後にSnapMirrorを逆再同期して、保護サイトへのフェイルバックを開始します。</block>
  <block id="c99b24a6817b7fd3c4d8687fc4bb35df" category="section-title">展開の詳細</block>
  <block id="eb5301ce7e383557ea1c2ecc5d8df8a4" category="example-title">AzureでCVOを構成し、ボリュームをCVOにレプリケート</block>
  <block id="97e7c9a7d06eac006a28bf05467fcc8b" category="inline-link">リンク</block>
  <block id="ebcd981f8224ab4325994da29465cf8c" category="paragraph">まず、AzureでCloud Volumes ONTAP を設定します <block ref="4e2a8d8afd7d7aca598f792d5d04f9c7" category="inline-link-rx"></block>）をクリックし、必要なボリュームを、必要な頻度とSnapshotの保持を使用してCloud Volumes ONTAP にレプリケートします。</block>
  <block id="30200baf346b021de0310f8f8307fd8e" category="paragraph"><block ref="30200baf346b021de0310f8f8307fd8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b453212f1c9ff723da2989dbb439d57e" category="example-title">AVSホストとCVOデータアクセスを設定</block>
  <block id="46fdc14ede3dd0a84faa31cf1cde9624" category="paragraph">SDDCを導入する際に考慮すべき2つの重要な要素は、Azure VMware解決策 内のSDDCクラスタのサイズと、SDDCの稼働期間です。ディザスタリカバリ解決策 に関する以下の2つの重要な考慮事項は、全体的な運用コストの削減に役立ちます。SDDCは、3台のホストの規模に対応し、フルスケールの導入ではマルチホストクラスタにまで対応できます。</block>
  <block id="938f299f0522c6e7bea183a8ea437225" category="paragraph">AVSクラスタを導入するかどうかは、主にRPOとRTOの要件に基づきます。Azure VMware解決策 では、テストや実際の災害に備えて、SDDCを随時プロビジョニングできます。SDDCを時間内に導入することで、災害に対処しない場合のESXiホストのコストを削減できます。ただし、このような導入形態では、SDDCのプロビジョニングに数時間かかるRTOが影響を受けます。</block>
  <block id="595875340c961d4ff4461ee8fe8a3ce3" category="paragraph">最も一般的な導入オプションは、SDDCを常時稼働のパイロットライトモードで実行することです。このオプションを使用すると、常に使用可能なホストを3台分のスペースに縮小できます。また、シミュレーションアクティビティとコンプライアンスチェックのベースラインを実行できるため、本番サイトとDRサイト間の運用のずれを回避できるため、リカバリ処理の時間を短縮できます。パイロットライトクラスタは、実際のDRイベントを処理する必要がある場合に、必要なレベルまで迅速に拡張できます。</block>
  <block id="2f5ab77fee006682ed15a6dbfb54c2a0" category="paragraph">AVS SDDCを設定するには（オンデマンドモードまたはパイロットライトモード）、を参照してください<block ref="86c283cfb3c0f32634050918a847eb2d" category="inline-link-rx"></block>。事前に、接続の確立後、AVSホストに常駐するゲストVMがCloud Volumes ONTAP からデータを消費できることを確認してください。</block>
  <block id="f63f01c08cfc3f386ad47993e097e207" category="paragraph">Cloud Volumes ONTAP とAVSを適切に設定したら、VAIOメカニズムを使用し、Cloud Volumes ONTAP へのアプリケーションボリュームのコピーにSnapMirrorを利用することにより、オンプレミスワークロードからAVSへのリカバリ（アプリケーションVMDKとゲストストレージを搭載したVM）を自動化するようにJetstreamを設定します。</block>
  <block id="9f9a4d5afd3892f2b17ecc3ed2ad2630" category="example-title">JetStream DRをオンプレミスデータセンターにインストールします</block>
  <block id="68027d729e644485691d1aa185f22dad" category="paragraph">Jetstream DRソフトウェアは、JetStream DR Management Server Virtual Appliance（MSA）、DR Virtual Appliance（DRVA）、およびホストコンポーネント（I/Oフィルタパッケージ）の3つの主要コンポーネントで構成されています。MSAは、コンピューティングクラスタにホストコンポーネントをインストールおよび構成し、JetStream DRソフトウェアを管理するために使用されます。インストールプロセスは次のとおりです。</block>
  <block id="2e5f490166b4cbb95848c72a3f3296cd" category="list-text">前提条件を確認します。</block>
  <block id="01eb617ea64b2e2237c95fa866dc6c99" category="list-text">リソースと構成に関する推奨事項については、Capacity Planning Toolを実行してください。</block>
  <block id="91d290eafae733f57fe1874a21a706be" category="list-text">JetStream DR MSAを、指定されたクラスタ内の各vSphereホストに導入します。</block>
  <block id="130231ab3f0401b0c0e0f66fadd45d5d" category="list-text">vCenterサーバをMSAに登録します。</block>
  <block id="6f621d6c94ab64b27eea06de601902d1" category="list-text">JetStream DR MSAが導入され、vCenter Serverが登録されたら、vSphere Web ClientでJetStream DRプラグインに移動します。これを行うには、[データセンター]&gt;[設定]&gt;[JetStream DR]に移動します。</block>
  <block id="874efc870db36a204a974a32ac47c11e" category="paragraph"><block ref="874efc870db36a204a974a32ac47c11e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9aad471e9824a9ef2c43fae648b07613" category="list-text">JetStream DRインターフェイスから、次の作業を行います。</block>
  <block id="7ab4f3b382b4ad9e82615cacd27d739c" category="paragraph"><block ref="7ab4f3b382b4ad9e82615cacd27d739c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc59cbc4a86e6676ff3d70ba71ba6c0c" category="list-text">リカバリサイトにあるAzure BLOBストレージを追加します。</block>
  <block id="c86146f54b5d798bebf8802ac8b9fcde" category="paragraph"><block ref="c86146f54b5d798bebf8802ac8b9fcde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47d0f0f8f33fcbb5e022f9d64bbbed63" category="list-text">アプライアンスタブから必要な数のDR仮想アプライアンス（DRVA）を導入します。</block>
  <block id="f609ba6f20a39912fd585d05df8bc4de" category="admonition">キャパシティプランニングツールを使用して、必要なDRVAの数を見積もります。</block>
  <block id="4c16a641767d4c33c410687e7b6613ef" category="paragraph"><block ref="4c16a641767d4c33c410687e7b6613ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6b84958a757d2c38048bdf788c590f" category="paragraph"><block ref="1a6b84958a757d2c38048bdf788c590f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7fbe3ea0d16e8cdd943c71406ee9095" category="list-text">使用可能なデータストアまたは独立した共有iSCSIストレージプールからVMDKを使用して、各DRVAのレプリケーションログボリュームを作成します。</block>
  <block id="376f9301b1fb23692806f601a501bc1d" category="paragraph"><block ref="376f9301b1fb23692806f601a501bc1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3603870d5d8cd5f384cf0b1258a4276a" category="list-text">Protected Domainsタブで、Azure Blob Storageサイト、DRVAインスタンス、およびレプリケーションログに関する情報を使用して、必要な数の保護ドメインを作成します。保護ドメインは、クラスタ内の特定のVMまたはアプリケーションVMのセットを定義します。これらのVMは一緒に保護され、フェイルオーバー/フェイルバック処理の優先順位が割り当てられます。</block>
  <block id="fc72030b6d0a9889fccd2facfedc6b0e" category="paragraph"><block ref="fc72030b6d0a9889fccd2facfedc6b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09795e4b943747b98cfc63dfc54275c3" category="paragraph"><block ref="09795e4b943747b98cfc63dfc54275c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb05314ca50bac72a0b13f171a2b6912" category="list-text">保護するVMを選択し、依存関係に基づいてVMをアプリケーショングループにグループ化します。アプリケーション定義を使用すると、VMのセットを、ブート順序、ブート遅延、およびリカバリ時に実行可能なオプションのアプリケーション検証を含む論理グループにグループ化できます。</block>
  <block id="818cadd78e726fcca2ca69a99c22df63" category="admonition">保護ドメイン内のすべてのVMに同じ保護モードを使用していることを確認します。</block>
  <block id="8cc32e4f2682b9a5731a285459a5d9c5" category="admonition">ライトバック（VMDK）モードを使用すると、パフォーマンスが向上します。</block>
  <block id="639f5dd27b8ff76608b346f78c673b4c" category="paragraph"><block ref="639f5dd27b8ff76608b346f78c673b4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c916465a580d8d569bd369e8e7f6d609" category="list-text">レプリケーションログボリュームがハイパフォーマンスストレージに配置されていることを確認します。</block>
  <block id="1fc3826d710244fdb6c4a09d89f98d5f" category="paragraph"><block ref="1fc3826d710244fdb6c4a09d89f98d5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5038dd04f28442b45e40cc394920ed6" category="list-text">完了したら、保護ドメインの保護の開始をクリックします。選択したVMのデータレプリケーションが開始され、指定したBLOBストアに送信されます。</block>
  <block id="5ed7580bd1e6ae0cef691df5ee3b54a2" category="paragraph"><block ref="5ed7580bd1e6ae0cef691df5ee3b54a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e860406ba63567c5eccf30055287b47" category="list-text">レプリケーションが完了すると、VMの保護ステータスは「回復可能」とマークされます。</block>
  <block id="c873c8c59414399f210af5ec22a764d8" category="paragraph"><block ref="c873c8c59414399f210af5ec22a764d8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a918d27a636eddf2d16b9e8544402c44" category="admonition">フェールオーバーランブックは、VM（回復グループと呼ばれる）をグループ化し、起動順序シーケンスを設定して、CPU /メモリ設定とIP設定を変更するように構成できます。</block>
  <block id="90ee2ee79e46dfb341705824bdba5b5a" category="list-text">「設定」をクリックし、「Runbook設定」リンクをクリックして、Runbookグループを設定します。</block>
  <block id="92471f4927394b88148206ffbdc25dbd" category="paragraph"><block ref="92471f4927394b88148206ffbdc25dbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c352449075dfd7c55f51cc486cc2541" category="list-text">[グループの作成]ボタンをクリックして、新しいランブックグループの作成を開始します。</block>
  <block id="e2fbd552cab46f747bc672bf2e1b0fe9" category="admonition">必要に応じて、画面の下部で、カスタムのプレスクリプトとポストスクリプトを適用して、ランブックグループの操作前および操作後に自動的に実行します。Runbookスクリプトが管理サーバ上に存在することを確認します。</block>
  <block id="27601285770e6db675411c9282459b87" category="paragraph"><block ref="27601285770e6db675411c9282459b87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f26b7048f93345b3726eb88bd506893a" category="list-text">必要に応じてVMの設定を編集します。VMをリカバリするためのパラメータを指定します。これには、ブートシーケンス、ブート遅延（秒単位）、CPUの数、割り当てるメモリの量などが含まれます。上下の矢印をクリックして、VMのブートシーケンスを変更します。MACを保持するためのオプションも用意されています。</block>
  <block id="ff0274a4eb386ebd23581a082f3b5b5b" category="paragraph"><block ref="ff0274a4eb386ebd23581a082f3b5b5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c2cb19a0ef20564c20014e97d134168" category="list-text">静的IPアドレスは、グループの個々のVMに手動で設定できます。VMのNICビューリンクをクリックして、IPアドレスを手動で設定します。</block>
  <block id="f26795dd104c3568722b09bce335c904" category="paragraph"><block ref="f26795dd104c3568722b09bce335c904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85bcb54a31960de00ecac27985d3f3a" category="list-text">Configureボタンをクリックして、それぞれのVMのNIC設定を保存します。</block>
  <block id="d6431b9ceb7168220978cc8a6f804dc2" category="paragraph"><block ref="d6431b9ceb7168220978cc8a6f804dc2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c295c7835a978c48c9f8253edc92e6ab" category="paragraph"><block ref="c295c7835a978c48c9f8253edc92e6ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423aff401e73269c665789c2a91cd2ba" category="paragraph">フェイルオーバーとフェイルバックの両方のランブックのステータスが構成済みとして表示されるようになりました。フェイルオーバーとフェイルバックのRunbookグループは、同じVMと設定の初期グループを使用してペアで作成されます。必要に応じて、それぞれの[詳細]リンクをクリックして変更を行うことで、ランブックグループの設定を個別にカスタマイズできます。</block>
  <block id="8868e7fa41b895d0441f3c000558500e" category="example-title">プライベートクラウドでAVS向けJetStream DRをインストールします</block>
  <block id="ca2d476f98a102308a1ca46e0314f094" category="paragraph">リカバリサイト（AVS）では、3ノードのパイロットライトクラスタを事前に作成することを推奨します。これにより、以下を含むリカバリサイトのインフラを事前に設定できます。</block>
  <block id="03bd3d186e1fc83d47907ac1797d8eaf" category="list-text">宛先ネットワークセグメント、ファイアウォール、DHCPやDNSなどのサービスなど</block>
  <block id="543c0ee14bc42e7f38251e99ace0ea62" category="list-text">ANFボリュームをデータストアなどとして設定</block>
  <block id="1e09668d117c7996e6a76a4aa2e44013" category="paragraph">Jetstream DRは、ミッションクリティカルなドメインでほぼゼロのRTOモードをサポートします。これらのドメインには、デスティネーションストレージが事前にインストールされている必要があります。この場合、ANFは推奨ストレージタイプです。</block>
  <block id="d9a7d19a656972791042b00bc2a308fa" category="admonition">SLAやRTOの要件に応じて、継続的フェイルオーバーモードまたは通常の（標準）フェイルオーバーモードを使用できます。RTOがほぼゼロになるように、リカバリサイトで継続的なリハイドレートを開始する必要があります。</block>
  <block id="4b2287bada3112a86338f8d33bb7f745" category="list-text">Azure VMware解決策 プライベートクラウドにJetStream DR for AVSをインストールするには、実行コマンドを使用します。Azureポータルで、Azure VMware解決策 に移動し、プライベートクラウドを選択して、実行コマンド&gt;パッケージ&gt; JSDR.Configurationを選択します。</block>
  <block id="f36d2f16d7b758d071070007e41f1dc3" category="admonition">Azure VMware解決策 のデフォルトCloudAdminユーザには、AVS対応のJetStream DRをインストールするための十分な権限がありません。Azure VMware解決策 では、JetStream DR用のAzure VMware解決策 実行コマンドを呼び出すことで、JetStream DRのインストールを簡単かつ自動化できます。</block>
  <block id="d5c094ac3602dc70c812b6f203db3080" category="paragraph"><block ref="d5c094ac3602dc70c812b6f203db3080" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1059f69ded45aab3e16676f7655ce33e" category="paragraph"><block ref="1059f69ded45aab3e16676f7655ce33e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f56ba70e80cd5a9d7e833ae9c2a8d00b" category="list-text">オンプレミスクラスタをストレージサイトとして保護するために使用したAzure Blob Storageアカウントを追加し、Scan Domainsオプションを実行します。</block>
  <block id="d46ac425273c7af91c98f03afab4d05d" category="list-text">表示されるポップアップダイアログで、インポートする保護ドメインを選択し、そのインポートリンクをクリックします。</block>
  <block id="8f6ce8893e72ca9a99ea54a38aa9123c" category="paragraph"><block ref="8f6ce8893e72ca9a99ea54a38aa9123c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="258e652acbaceeb040a052eb56f710ff" category="list-text">ドメインがリカバリ用にインポートされます。[保護ドメイン]タブに移動して、目的のドメインが選択されていることを確認するか、[保護ドメインの選択]メニューから目的のドメインを選択します。保護ドメイン内のリカバリ可能なVMのリストが表示されます。</block>
  <block id="44f0914b6b6c354b3ed0d0f5c88f5f40" category="paragraph"><block ref="44f0914b6b6c354b3ed0d0f5c88f5f40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab8894857a9c27d55e00ceb59f0a0a9d" category="list-text">保護ドメインをインポートしたら、DRVAアプライアンスを展開します。</block>
  <block id="a594598fd21c66eb364972e1018fc5b1" category="admonition">これらの手順は、CPT作成プランを使用して自動化することもできます。</block>
  <block id="5dbd13899d13d449aaa288efb68bc4e7" category="list-text">保護ドメインをインポートし、VMの配置にANFデータストアを使用するようにリカバリVAを設定します。</block>
  <block id="30c90d4c81b9e156fa124f63997bd267" category="paragraph"><block ref="30c90d4c81b9e156fa124f63997bd267" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27ece16fa591c8a94d158b6371824318" category="admonition">選択したセグメントでDHCPが有効になっていて、十分なIPが使用可能であることを確認します。ダイナミックIPは、ドメインのリカバリ中に一時的に使用されます。リカバリVM（連続リハイドレートを含む）ごとに、個別のダイナミックIPが必要です。リカバリの完了後、IPは解放され、再利用できます。</block>
  <block id="221af48bbe7986080d7f1ef43b7cc9af" category="admonition">設定の実行時には、継続的フェイルオーバーモードとフェイルオーバーモードが異なりますが、両方のフェイルオーバーモードを同じ手順で設定します。フェイルオーバー手順は、災害発生時の対応として一緒に設定および実行されます。継続的フェイルオーバーはいつでも設定でき、通常のシステム運用中はバックグラウンドで実行できます。災害が発生すると、継続的なフェイルオーバーが完了し、保護対象のVMの所有権がリカバリサイトにただちに移行されます（RTOはほぼゼロ）。</block>
  <block id="12d3f891efb3e0286e3d610d87fa763c" category="paragraph"><block ref="12d3f891efb3e0286e3d610d87fa763c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fad47d76ebfb2068cc150f23d3abc231" category="paragraph">継続的なフェイルオーバープロセスが開始され、UIから進行状況を監視できます。[現在のステップ]セクションの青いアイコンをクリックすると、ポップアップウィンドウが開き、フェイルオーバープロセスの現在のステップの詳細が表示されます。</block>
  <block id="07216bb55061288a2fa29cda954742e3" category="example-title">フェイルオーバーとフェイルバック</block>
  <block id="3dd9279db501526060882c484e7fa2eb" category="list-text">オンプレミス環境の保護対象クラスタで障害が発生した場合（部分的または完全な障害）、該当するアプリケーションボリュームのSnapMirror関係を解除したあと、Jetstreamを使用してVMのフェイルオーバーをトリガーできます。</block>
  <block id="4e26d6c9cc7404940d6c72a71775d261" category="paragraph"><block ref="4e26d6c9cc7404940d6c72a71775d261" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7c749826108cc466667dcaeb67965a7" category="paragraph"><block ref="f7c749826108cc466667dcaeb67965a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="253d2b2bed504833d82e064634bbf83e" category="admonition">この手順は簡単に自動化できるため、リカバリプロセスが容易になります。</block>
  <block id="9824ceea6f74aa9d72ed2bd7473b9362" category="list-text">AVS SDDC（宛先側）上のJetstream UIにアクセスし、フェールオーバーオプションをトリガしてフェールオーバーを完了します。タスクバーにフェイルオーバーアクティビティの進行状況が表示されます。</block>
  <block id="b39966f9c6438e5d60c1de37dfa3ed05" category="paragraph">フェイルオーバーが完了したときに表示されるダイアログウィンドウで、フェイルオーバータスクを計画どおりに指定することも、強制的に実行することもできます。</block>
  <block id="684bb098f20646b3f18e10bc17e2d3c4" category="paragraph"><block ref="684bb098f20646b3f18e10bc17e2d3c4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="562cb54fd49a347cfb889e6021e0be34" category="paragraph"><block ref="562cb54fd49a347cfb889e6021e0be34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979b519fc9d5e27e5d114696ce4b1366" category="paragraph">強制フェイルオーバーでは、プライマリサイトがアクセス不能になり、保護ドメインの所有権がリカバリサイトによって直接引き継がれる必要があります。</block>
  <block id="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="paragraph"><block ref="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9be51d726dd7c6ae76c2545a91f36d11" category="paragraph"><block ref="9be51d726dd7c6ae76c2545a91f36d11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fce15eac6afaa8615d7a00cc4972808" category="list-text">継続的なフェイルオーバーが完了すると、タスクの完了を確認するメッセージが表示されます。タスクが完了したら、リカバリしたVMにアクセスしてiSCSIセッションまたはNFSセッションを設定します。</block>
  <block id="53839296d302ef4a3faf8220562c1ce4" category="admonition">フェイルオーバーモードが「Running in Failover」に変わり、VMのステータスが「Recoverable」になります。保護ドメインのすべてのVMが、フェールオーバーランブック設定で指定された状態でリカバリサイトで実行されるようになりました。</block>
  <block id="50ff3dc4ca6f3eb140f2099f2b480b83" category="admonition">フェールオーバー構成とインフラストラクチャを検証するために、JetStream DRをテストモード（テストフェールオーバーオプション）で実行して、仮想マシンとそのデータをオブジェクトストアからテストリカバリ環境にリカバリすることができます。フェールオーバー手順 がテストモードで実行されると、その動作は実際のフェールオーバープロセスに似ています。</block>
  <block id="a6687fcac4b89ac042d0bf01e0eed2c7" category="paragraph"><block ref="a6687fcac4b89ac042d0bf01e0eed2c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf3e40ce09f6fe770361fe49d398cad9" category="list-text">仮想マシンのリカバリが完了したら、ゲスト内ストレージにストレージディザスタリカバリを使用します。このプロセスを実証するために、この例ではSQL Serverを使用しています。</block>
  <block id="e5007f72fe428769908e4b66a64b1ace" category="list-text">AVS SDDCでリカバリしたSnapCenter VMにログインし、DRモードを有効にします。</block>
  <block id="8bc57e8e0debd3b1f0e1c01431ceb73b" category="list-text">browserNを使用してSnapCenter UIにアクセスします。</block>
  <block id="b29ffa42af1df2e35cdf88be1740bdf8" category="paragraph"><block ref="b29ffa42af1df2e35cdf88be1740bdf8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="392d143fa78a9868b2d56197de458a8d" category="list-text">[設定]ページで、[設定]&gt;[グローバル設定]&gt;[ディザスタリカバリ]の順に選択します。</block>
  <block id="f4060a5dfc75e427eab8fc559b5c3873" category="list-text">Enable Disaster Recoveryを選択します。</block>
  <block id="79bee17b4293b619c241ae80aef8ef62" category="list-text">適用をクリックします。</block>
  <block id="24049296b222c98c12a36098c1928b9f" category="paragraph"><block ref="24049296b222c98c12a36098c1928b9f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f31c54b6a166b6ab176f034d0f52e291" category="list-text">[Monitor]&gt;[Jobs]をクリックして、DRジョブが有効になっているかどうかを確認します。</block>
  <block id="a194386b24136c162d5de560f2c4b3c9" category="admonition">ストレージのディザスタリカバリには、NetApp SnapCenter 4.6以降を使用してください。以前のバージョンでは、アプリケーションと整合性のあるSnapshot（SnapMirrorを使用してレプリケート）を使用し、ディザスタリカバリサイトで以前のバックアップをリカバリする必要がある場合に手動でリカバリする必要があります。</block>
  <block id="a1e59d581c6cda40186a3488aa35c0b5" category="list-text">SnapMirror関係が解除されていることを確認します。</block>
  <block id="ab99ab9f50b0f74bd7b676fbb522f5e8" category="paragraph"><block ref="ab99ab9f50b0f74bd7b676fbb522f5e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5fabb74faf982c31918e4a241092e386" category="list-text">Cloud Volumes ONTAP からリカバリしたSQLゲストVMに、同じドライブレターを使用してLUNを接続します。</block>
  <block id="faedf38240e42a0e3f085f6acdc22aec" category="paragraph"><block ref="faedf38240e42a0e3f085f6acdc22aec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="458585a8fad71bd63549d32afd2c2f69" category="list-text">iSCSIイニシエータを開き、以前切断したセッションを消去して、レプリケートされたCloud Volumes ONTAP ボリュームのマルチパスとともに新しいターゲットを追加します。</block>
  <block id="5d06816a9331ccf1bde11d80e2438672" category="paragraph"><block ref="5d06816a9331ccf1bde11d80e2438672" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2483b40da799327d80d5aa5c4683efee" category="list-text">DR実行前に使用したのと同じドライブレターを使用して、すべてのディスクが接続されていることを確認してください。</block>
  <block id="75c3e1de048df1f08f612bb44462afd4" category="paragraph"><block ref="75c3e1de048df1f08f612bb44462afd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6048d3c947f6b9163f72586701cec853" category="list-text">MSSQLサーバサービスを再起動します。</block>
  <block id="9f8472ea6d004535fc1659d1e6863867" category="paragraph"><block ref="9f8472ea6d004535fc1659d1e6863867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="632dc72bd4eb731f74582d644a0f4b3c" category="list-text">SQLリソースがオンラインに戻っていることを確認します。</block>
  <block id="9d19926e46fa4cd818065a2726bcf42d" category="paragraph"><block ref="9d19926e46fa4cd818065a2726bcf42d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01fb98a09bb6b1d922a6275724f31823" category="admonition">NFSの場合は'mountコマンドを使用してボリュームを接続し'/etc/fstabエントリーを更新します</block>
  <block id="8145668f843709bddb7b6c8b3f3abbfb" category="paragraph">この時点で運用を開始し、通常どおり業務を継続できます。</block>
  <block id="8020518363652d35b23a9585c780e480" category="admonition">NSX Tエンドでは'フェイルオーバー・シナリオをシミュレートするために'個別の専用ティア1ゲートウェイを作成できますこれにより、すべてのワークロードが相互に通信できるようになりますが、環境内や環境外にトラフィックをルーティングできないため、トリアージ、封じ込め、セキュリティ強化のタスクをクロスコンタミネーションのリスクなしに実行できます。この操作はこのドキュメントでは扱いませんが、分離をシミュレートするために簡単に行うことができます。</block>
  <block id="7d7b7ba342280685358aeb9937ce1118" category="paragraph">プライマリサイトが起動し、再び実行されるようになったら、フェイルバックを実行できます。VM保護はJetstreamで再開され、SnapMirror関係を反転する必要があります。</block>
  <block id="5a24d57462c6d674800fbb2a7e0c59ce" category="list-text">オンプレミス環境をリストア災害のタイプによっては、保護対象クラスタの構成をリストアまたは検証しなければならない場合があります。必要に応じて、JetStream DRソフトウェアを再インストールする必要があります。</block>
  <block id="5cf6cc1cdb0715aca121fb45bdc4f42e" category="admonition">CPTによって生成されたフェイルバック計画を使用して、VMとそのデータをオブジェクトストアから元のVMware環境に戻すこともできます。</block>
  <block id="130f86be5d695ec045cce675d14637b8" category="paragraph"><block ref="130f86be5d695ec045cce675d14637b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="504e0be50ebedab76e2a7714a22354d3" category="admonition">リカバリサイトでVMを一時停止して保護対象サイトで再起動したあとの最大遅延時間を指定します。このプロセスには、フェイルオーバーVMを停止したあとのレプリケーションの完了、リカバリサイトのクリーンアップに必要な時間、保護サイトでVMを再作成するのに必要な時間などが含まれます。10分を推奨します。</block>
  <block id="41f8873d7ef0fd0767f8ed6d7798fe87" category="paragraph"><block ref="41f8873d7ef0fd0767f8ed6d7798fe87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5752ed9acb85541568eca0327a24e09f" category="list-text">フェイルバックプロセスを完了し、VM保護およびデータの整合性が再開されたことを確認する。</block>
  <block id="f872505992d08e75adcaa8a9adbc0d18" category="paragraph"><block ref="f872505992d08e75adcaa8a9adbc0d18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684bcaaa7dda535165cb0b8f8e76a5ea" category="list-text">VMのリカバリが完了したら、セカンダリストレージをホストから切断してプライマリストレージに接続します。</block>
  <block id="79f47ff1cd40017f1ef0eb31e7397d75" category="paragraph"><block ref="79f47ff1cd40017f1ef0eb31e7397d75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18f7dd50970b99e8a3cdeab8c42567b0" category="paragraph"><block ref="18f7dd50970b99e8a3cdeab8c42567b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f0269cfb1a6f24731b2bb3a15b436b2" category="list-text">SQLリソースがオンラインに戻っていることを確認します。</block>
  <block id="bb9592df1a1b3d7ea469affe88be679f" category="paragraph"><block ref="bb9592df1a1b3d7ea469affe88be679f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41823ca0d78e787fda8ba7b1c398a29" category="admonition">プライマリストレージにフェイルバックするには、逆再同期処理を実行して、フェイルオーバーの前と同じ関係の方向が維持されていることを確認します。</block>
  <block id="6decfeed5d1c375e40e96552e631df25" category="admonition">逆再同期処理の実行後もプライマリストレージとセカンダリストレージのロールを保持するには、逆再同期処理をもう一度実行します。</block>
  <block id="2087f49e4433786c996468974c61ae4a" category="paragraph">このプロセスは、Oracleなどの他のアプリケーション、類似したデータベースの種類、ゲスト接続ストレージを使用するその他のアプリケーションに適用されます。</block>
  <block id="33b4e9a3c1a928dbdf5273b34d899e61" category="paragraph">常に同様に、重要なワークロードを本番環境に移植する前に、リカバリに必要な手順をテストしてください。</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="section-title">この解決策 の利点</block>
  <block id="3a02a011f551429a5ec8b46a00017abd" category="list-text">効率性と耐障害性に優れたSnapMirrorレプリケーションを使用します。</block>
  <block id="74915666b8d10f77a73b526e91724cc8" category="list-text">ONTAP スナップショットの保持により、利用可能な任意の時点までリカバリします。</block>
  <block id="a3704e4802422c6765dd406472307ba1" category="list-text">ストレージ、コンピューティング、ネットワーク、アプリケーションの検証から、数百~数千のVMのリカバリに必要なすべての手順を完全に自動化できます。</block>
  <block id="c0e8bb909ee76b5f9683012fd9418729" category="list-text">SnapCenter では、レプリケートされたボリュームを変更しないクローニングメカニズムが使用されます。</block>
  <block id="d92ea079cd9d83d3d60c1269804b766c" category="list-text">これにより、ボリュームとSnapshotのデータが破損するリスクを回避できます。</block>
  <block id="843b8877e30b7587ad87b95cd115df4a" category="list-text">DRテストのワークフロー中にレプリケーションが中断されるのを回避します</block>
  <block id="a29a4a29d457d4322f1f22ed58f9b06a" category="list-text">開発とテスト、セキュリティテスト、パッチとアップグレードのテスト、修正テストなど、DR以外のワークフローにDRデータを活用します。</block>
  <block id="e04e963feedf7f0157e360dc2be6d7b3" category="list-text">CPUとRAMの最適化は、小規模なコンピューティングクラスタへのリカバリを可能にすることで、クラウドコストの削減に役立ちます。</block>
  <block id="bd3260deba05f8c5831890f164f83733" category="doc">ANFデータストアソリューションの概要</block>
  <block id="626c4c46c0b0900648e0b954a96c4399" category="paragraph">成功を収めている組織は、変革と刷新の道を歩んでいます。このプロセスの一環として、企業は通常、既存のVMwareへの投資を活用しながら、クラウドのメリットを活用し、移行、バースト、拡張、ディザスタリカバリのプロセスを可能なかぎりシームレスに実行する方法を模索しています。クラウドに移行するお客様は、柔軟性とバースト性、データセンターの終了、データセンターの統合、サポート終了シナリオ、合併や買収などの問題を評価する必要があります。各組織が採用するアプローチは、それぞれのビジネスの優先順位に応じて異なります。クラウドベースの運用を選択する場合、適切なパフォーマンスと最小限の障害を持つ低コストモデルを選択することが重要な目標です。適切なプラットフォームを選択するとともに、クラウドの導入と柔軟性を最大限に活用するために、ストレージとワークフローのオーケストレーションが特に重要になります。</block>
  <block id="bcc2a83e573fb5cbbcd097908c609fa6" category="paragraph">Azure VMware解決策 はお客様に独自のハイブリッド機能を提供しますが、ネイティブストレージのオプションが限られているため、ストレージの負荷が高い組織での有用性が制限されています。ストレージはホストに直接関連付けられているため、ストレージを拡張する唯一の方法は、ホストを追加することです。これにより、ストレージを大量に消費するワークロードのコストを35～40%以上増加させることができます。このようなワークロードに必要なストレージ容量は追加ではなく、追加のホストに料金が発生します。</block>
  <block id="abc79d01b4318a1c67504eb7714e360f" category="paragraph">次のシナリオを考えてみましょう。お客様は6台のホストで馬力（vCPUとvMem）を求めていますが、ストレージの要件も大きくなっています。評価に基づいて、12台のホストがストレージ要件を満たしている必要があります。これにより、必要な容量をすべて追加購入するだけで、より多くのストレージが必要になるため、全体的なTCOが増加します。これは、移行、ディザスタリカバリ、バースト、開発/テストなど、あらゆるユースケースに当てはまります。 など。</block>
  <block id="f6faa113f88d1f8c4795fe189493d34f" category="paragraph">Azure VMware解決策 のもう1つの一般的なユースケースは、ディザスタリカバリ（DR）です。ほとんどの組織には、裏付けのないDR戦略がないため、DR目的だけでゴーストデータセンターを運用する正当性を証明するのに苦労することがあります。管理者は、パイロットライトクラスタやオンデマンドクラスタを使用して、フットプリントゼロのDRオプションを検討できます。ホストを追加せずにストレージを拡張できるため、魅力的な選択肢となる可能性があります。</block>
  <block id="feb87b8a766262f1649eb73f664b5237" category="paragraph">つまり、ユースケースは次の2つの方法で分類できます。</block>
  <block id="113270f68f35ffcbf2a57597bd22e665" category="list-text">ANFデータストアを使用したストレージ容量の拡張</block>
  <block id="a46f3b69652b37f2becc5ad8def389fe" category="list-text">オンプレミスまたはAzureリージョン内のSoftware-Defined Storage（SDDC）間で、ANFデータストアをディザスタリカバリターゲットとして使用することで、コストを最適化したリカバリワークフローを実現できます。このガイドでは、Azure NetApp Files を使用してデータストアに最適化されたストレージを提供する方法を説明します（現時点ではパブリックプレビュー版です）。 Azure VMware解決策 の業界最高のデータ保護機能とDR機能を組み合わせることで、VSANストレージからストレージ容量をオフロードできます。</block>
  <block id="301964836d84fb491fca23f51f902cd0" category="admonition">Azure NetApp Files データストア機能は現在パブリックプレビュー版です。追加情報 の地域のネットアップまたはMicrosoft解決策 アーキテクトにお問い合わせください。</block>
  <block id="9d5486edf9a5ddec98d7f7509d50101c" category="section-title">AzureのVMware Cloudオプション</block>
  <block id="809dd7fcec8077467eab0222ea68e259" category="paragraph">Azure VMware解決策 （AVS）は、Microsoft Azureパブリッククラウド内でVMware SDSを完全に機能させるハイブリッドクラウドサービスです。AVSはMicrosoftが完全に管理およびサポートするファーストパーティの解決策 で、Azureインフラストラクチャを使用するVMwareにより検証されています。そのため、コンピューティング仮想化用のVMware ESXi、ハイパーコンバージドストレージ用のVSAN、ネットワークとセキュリティ用のNSXを、Microsoft Azureのグローバルプレゼンス、クラス最高レベルのデータセンター施設、ネイティブのAzureサービスとソリューションの豊富なエコシステムの近くで利用できます。Azure VMware解決策 SDDCとAzure NetApp Files を組み合わせることで、ネットワークレイテンシを最小限に抑えながら最高のパフォーマンスを実現できます。</block>
  <block id="8718654ef588a85b2a2e46a7727fa16d" category="paragraph">VMware SDDCを導入する際、使用するクラウドに関係なく、最初のクラスタには次のコンポーネントが含まれます。</block>
  <block id="b6955e4f04d87bd186e8f355b710c814" category="list-text">コンピューティング仮想化用のVMware ESXiホストと、管理用のvCenterサーバアプライアンス</block>
  <block id="c865d5c3f7aef0fea827cecdf6da386c" category="list-text">各ESXiホストの物理ストレージ資産を組み込んだVMware vSANハイパーコンバージドストレージ。</block>
  <block id="4d53c4a03b478ccb8f5a4a2cde37db71" category="list-text">管理のためにNSX Managerクラスタを使用した仮想ネットワークとセキュリティのためのVMware NSX</block>
  <block id="94d43b2c8702afe74d26d3a9052e59b4" category="paragraph">Azure NetApp Files は、オールクラウドとハイブリッドクラウドのどちらをターゲットとしている場合でも、アプリケーションワークロードとファイルサービスを導入して管理するための優れたオプションを提供し、データ要件をアプリケーションレイヤとシームレスにすることでTCOを削減します。どのようなユースケースでも、クラウドのメリット、一貫したインフラ、オンプレミスと複数のクラウドにわたる運用、ワークロードの双方向性、エンタープライズクラスの容量とパフォーマンスを迅速に実現するには、Azure VMware解決策 とAzure NetApp Files を選択してください。ストレージの接続に使用される一般的なプロセスと手順は同じです。新しい名前とともに変更されたデータの位置にすぎません。ツールやプロセスはすべて変わらないので、Azure NetApp Files を使用すると導入全体を最適化できます。</block>
  <block id="7017a5961c414dfbe07b539da73560fb" category="list-text">AVS SDDCのデータストアとしてAzure NetApp Files を使用できるようになりました。</block>
  <block id="1997ea39c8d744bf66dd1b36df20eca0" category="list-text">アプリケーションの応答時間を短縮し、可用性を高めて、必要なときに必要な場所でワークロードデータにアクセスできるようにします。</block>
  <block id="d229778544c20c94bc3a4e634983743a" category="list-text">シンプルで瞬時のサイズ変更機能により、VSANストレージの全体的な複雑さを緩和</block>
  <block id="220eb8ba4e87069e79226f808999d319" category="list-text">動的な再構築機能でミッションクリティカルなワークロードのパフォーマンスを保証</block>
  <block id="de55b3d8d98ed7c720c8410fbbce524e" category="list-text">Azure VMware解決策 クラウドが移行先である場合、Azure NetApp Files は最適化された導入に最適なストレージ解決策 です。</block>
  <block id="a13de136306e099dce523fd8db3f037c" category="list-text">Azure VMware解決策 のドキュメント</block>
  <block id="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link"><block ref="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link-rx"></block></block>
  <block id="5e65b51c08430d6fa3dc13275b00da9d" category="paragraph"><block ref="5e65b51c08430d6fa3dc13275b00da9d" category="inline-link-rx"></block></block>
  <block id="6c32a3d0f1a665987b98dde5a0f96d7d" category="list-text">Azure NetApp Files のドキュメント</block>
  <block id="ac236475735595f1237223b0184c5cca" category="inline-link"><block ref="ac236475735595f1237223b0184c5cca" category="inline-link-rx"></block></block>
  <block id="742cb4a55dadc1d5ca8efd2956575138" category="paragraph"><block ref="742cb4a55dadc1d5ca8efd2956575138" category="inline-link-rx"></block></block>
  <block id="8d60f49fa5ec93fd2bea5e083359bdc1" category="paragraph">NFSデータストアのサポートは、オンプレミス環境のESXiバージョン3で導入され、vSphereのストレージ機能が大幅に拡張されました。</block>
  <block id="1aaea72f240547a6a057b9a88a27144b" category="paragraph">vSphere on NFSは、高いパフォーマンスと安定性を提供するため、オンプレミスの仮想化環境に広く採用されているオプションです。オンプレミスのデータセンターに大量のネットワーク接続型ストレージ（NAS）がある場合は、Azure NetApp Fileデータストアを使用してAzureにAzure VMware解決策 SDDCを導入することで、容量とパフォーマンスの課題を克服することを検討してください。</block>
  <block id="19fb9916968211db983d13bffe0cc6af" category="inline-link">99.99%</block>
  <block id="ad25c186e2eeaa2ec5fa0b9d3fa4b8c7" category="paragraph">Azure NetApp Files は、業界をリードする高可用性NetApp ONTAP データ管理ソフトウェアを基盤としています。Microsoft Azureサービスは、基本、メインストリーム、および専門の3つのカテゴリに分類されます。Azure NetApp Files は特殊なカテゴリに分類され、多くの地域にすでに導入されているハードウェアによってサポートされています。Azure NetApp Files には高可用性（HA）機能が組み込まれており、ほとんどのシステム停止からデータを保護し、業界をリードするのSLAを提供します<block ref="404362048587970f5f15a4d9376a71ea" category="inline-link-rx"></block> アップタイム：</block>
  <block id="1b69b6091c2756a0aac2b81e4a880f93" category="paragraph">Azure NetApp Files データストア機能を導入する前に、パフォーマンスやストレージを大量に消費するワークロードをホストする計画のお客様がスケールアウト処理を行うためには、コンピューティングとストレージの両方を拡張する必要がありました。</block>
  <block id="09d432ffd44a3af2e2524362730628cf" category="paragraph">次の点に注意してください。</block>
  <block id="79786892120b18078ded972068ce7cab" category="list-text">SDDCクラスタでは、アンバランスなクラスタ構成は推奨されません。そのため、ストレージを拡張するとホストが追加されるため、TCOが増加します。</block>
  <block id="4d7a269595fa13e9d4bb48449c996a41" category="list-text">1 つの VSAN 環境のみが可能です。そのため、すべてのストレージトラフィックは本番環境のワークロードと直接競合します。</block>
  <block id="99407e1fc016dc5a4f17896a330e66b0" category="list-text">アプリケーションの要件、パフォーマンス、コストに合わせて複数のパフォーマンス階層を提供するオプションはありません。</block>
  <block id="f5188d9f655a6ac9c3d0dccb20d81997" category="list-text">クラスタホスト上に構築されたVSANのストレージ容量の上限に容易に到達できます。Azure NetApp Files のようなAzureネイティブのプラットフォームサービス（PaaS）サービスをデータストアとして統合することで、 お客様は、ストレージを個別に拡張し、必要に応じてコンピューティングノードをSDDCクラスタに追加することだけを選択できます。この機能により、上記の課題を克服できます。</block>
  <block id="cf1c082028930ec1827badc0e64627c6" category="admonition">ストレージの計画とサイジング、および必要なホスト数の確認については、AzureとNetApp解決策 Architectsにお問い合わせください。テスト環境、POC環境、および本番環境では、データストアのレイアウトを最終決定する前に、ストレージのパフォーマンス要件を特定することを推奨します。</block>
  <block id="1622404dda50f5803c9577efc058ec11" category="paragraph"><block ref="1622404dda50f5803c9577efc058ec11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3488e5e13ca2586de3bcc01700bd61b" category="paragraph">移行やディザスタリカバリにおいて最も重要なことは、ターゲット環境に適したサイズを決定することです。オンプレミスからAzure VMware解決策 への切り替えの演習に対応するために必要なノード数を把握することが非常に重要です。</block>
  <block id="b39d58eedf7db669f2a65fd75198d49e" category="paragraph">サイジングには、RVTools（推奨）またはLive OpticsやAzure Migrateなどのその他のツールを使用して、オンプレミス環境の履歴データを使用します。RVToolsは、vCPU、仮想マシン、vDisk、および電源オン/オフVMを含む必要なすべての情報をキャプチャして、ターゲット環境をキャラクタライズするのに最適なツールです。</block>
  <block id="9b45f8f524f59dcb44852dc933d31d60" category="paragraph">RVtoolsを実行するには、次の手順を実行します。</block>
  <block id="b9b14f9a77af6302e167ec8031bac435" category="list-text">RVToolsをダウンロードしてインストールします。</block>
  <block id="a379941a0582174b350ce316b1e64b36" category="list-text">RVToolsを実行し、必要な情報を入力してオンプレミスのvCenter Serverに接続し、Loginを押します。</block>
  <block id="7d0ff8053a5012b379d5e45f7d80bd81" category="list-text">インベントリをExcelスプレッドシートにエクスポートします。</block>
  <block id="ad7235861abcfd585f9793a320142cb9" category="list-text">スプレッドシートを編集し、vInfoタブから理想的でないVMを削除します。このアプローチでは、Azure VMware SDDCクラスタの適切なサイズ設定に必要なホスト数を使用できるストレージ要件に関する明確な出力が得られます。</block>
  <block id="66a03e4bdc70563bcc83f39fd18f2993" category="admonition">ゲスト内ストレージで使用するゲストVMは個別に計算する必要がありますが、Azure NetApp Files では追加のストレージ容量を簡単にカバーできるため、全体的なTCOを抑えることができます。</block>
  <block id="ee7f083efd1984641bff3ff302c447a9" category="section-title">Azure VMware解決策 を導入および設定する</block>
  <block id="95220678e12ace3a65339c08bb6019e5" category="paragraph">オンプレミスと同様に、Azure VMware解決策 を計画することは、仮想マシンの作成と移行を行う本番環境に欠かせません。</block>
  <block id="1b3379256eb1cb0d26126368cc62ab52" category="paragraph">このセクションでは、ゲスト内ストレージを使用するデータストアとして、Azure NetApp Files と組み合わせて使用するAVSを設定および管理する方法についても説明します。</block>
  <block id="449e01682ffd6d9e79c75acf22fa249b" category="list-text">リソースプロバイダを登録し、プライベートクラウドを作成</block>
  <block id="17d7be5e1d44a11ff74be89af34822c9" category="list-text">新しいExpressRoute仮想ネットワークゲートウェイまたは既存のExpressRoute仮想ネットワークゲートウェイに接続します。</block>
  <block id="28325f137394bcd829a01024c035cb5e" category="list-text">ネットワーク接続を検証し、プライベートクラウドにアクセスこれを参照してください <block ref="c494c3efc2923b26ad63800ea1f5c612" category="inline-link-macro-rx"></block> Azure VMware解決策 SDDCプロビジョニングプロセスの詳しい手順については、を参照してください。</block>
  <block id="b2666a13d31389019b43a9085ffd2fe8" category="section-title">Azure VMware解決策 でAzure NetApp Files を設定</block>
  <block id="dbfbac0b1aee2557c747f90a52c200ed" category="paragraph">Azure NetApp Files との新たな統合により、Azure VMware解決策 リソースプロバイダAPI / CLIを使用してAzure NetApp Files ボリュームを使用してNFSデータストアを作成し、選択したクラスタにデータストアをプライベートクラウドにマウントできるようになりました。VMとアプリケーションのVMDKを収容する以外に、Azure NetApp Filesボリュームは、Azure VMware解決策 SDDC環境で作成されたVMからマウントすることもできます。Azure NetApp Files はサーバメッセージブロック（SMB）プロトコルとネットワークファイルシステム（NFS）プロトコルをサポートしているため、ボリュームをLinuxクライアントにマウントしてWindowsクライアントにマッピングできます。</block>
  <block id="3fcf61e60f3486b366489a2db86e92c0" category="admonition">最適なパフォーマンスを実現するには、プライベートクラウドと同じアベイラビリティゾーンにAzure NetApp Files を導入します。エクスプレスルートファストパスを使用するコロケーション施設は、ネットワークレイテンシを最小限に抑えて最高のパフォーマンスを提供します。</block>
  <block id="2a499560ec410b1e1caeb95f6021ac1e" category="admonition">この機能は現在パブリックプレビューにあります。</block>
  <block id="7042805ebe69bccc6ab09f9518f94556" category="paragraph">Azure NetApp FileボリュームをAzure VMware解決策 プライベートクラウドのVMwareデータストアとして接続するには、次の前提条件を満たしていることを確認します。</block>
  <block id="49588f95c73f4a9df95958ba5e856d0c" category="list-text">AZログインを使用し、サブスクリプションがMicrosoft.AVSネームスペースのCloudSanExperience機能に登録されていることを確認します。</block>
  <block id="c0e46e4183896be214bad3fd077b5834" category="list-text">登録されていない場合は、登録します。</block>
  <block id="8fb14eb63139db9a1c626865766368e4" category="admonition">登録が完了するまでに約15分かかることがあります。</block>
  <block id="91bc7290f2d4745c25033c52b73c0662" category="list-text">登録のステータスを確認するには、次のコマンドを実行します。</block>
  <block id="bd00d81bc80103cfbf6f24470f9de4fa" category="list-text">登録が15分以上中間状態で停止した場合は、フラグの登録を解除してから再登録します。</block>
  <block id="30d4986a1e28c78ed243b8fe94ebe5be" category="list-text">Microsoft.AVSネームスペースのAnfDatastoreExperience機能にサブスクリプションが登録されていることを確認します。</block>
  <block id="10b9b69a3124f921ee9a3a8271028b78" category="list-text">VMware拡張機能がインストールされていることを確認します。</block>
  <block id="329e9fb0e53008fcf269d03c5476847d" category="list-text">拡張機能がすでにインストールされている場合は、バージョンが3.0.0であることを確認します。古いバージョンがインストールされている場合は、拡張機能を更新します。</block>
  <block id="f5e4a463688cab0acae8d53e64bd5e36" category="list-text">拡張機能がインストールされていない場合は、インストールします。</block>
  <block id="11d2eb5b9d070e139a779747ce885490" category="list-text">Azureポータルにログインして、Azure NetApp Files にアクセスします。Azure NetApp Files サービスへのアクセスを確認し'AZ provider register `--namespace Microsoft.NetApp–wait`コマンドを使用してAzure NetApp Files リソースプロバイダを登録します登録が完了したら、ネットアップアカウントを作成します。これを参照してください<block ref="2c2f4008511e047aaaf92ad514e98ec9" category="inline-link-rx"></block> を参照してください。</block>
  <block id="09e7af76fc12c4b14e8fbca51314b508" category="paragraph"><block ref="09e7af76fc12c4b14e8fbca51314b508" category="inline-image-macro-rx" type="image"></block></block>
  <block id="187927c7525fb36ec9428b4d84fe0aff" category="list-text">ネットアップアカウントを作成したら、必要なサービスレベルとサイズの容量プールをセットアップします。詳細については、こちらを参照してください<block ref="0a52e91c67ac030fc237a7b13d0404c6" category="inline-link-rx"></block>。</block>
  <block id="c7d6fd5f235d0c8a960facf04a79e4a7" category="paragraph"><block ref="c7d6fd5f235d0c8a960facf04a79e4a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c573a9eace62b9790820458dd59448b0" category="list-text">Azure NetApp Files のデータストアではNFSv3がサポートされています。</block>
  <block id="62dfd4c1cc43e59ef3c56bb615d3b182" category="list-text">最高のパフォーマンスを得るには、PremiumまたはUltra Tierを使用します。</block>
  <block id="0d55d5c3a7459f59fd437a2311322791" category="list-text">Azure NetApp Files の委任されたサブネットを設定し、ボリュームを作成する際にこのサブネットを指定します。委任されたサブネットを作成する詳細な手順については、を参照してください<block ref="e84891bed408b1977d062f4ccc1816aa" category="inline-link-rx"></block>。</block>
  <block id="36fc58c2c3fa32ac586d5628570e9499" category="list-text">容量プールブレード下のボリュームブレードを使用して、データストア用のNFSボリュームを追加します。</block>
  <block id="2832d137c1714a9759f87412fb05253e" category="paragraph"><block ref="2832d137c1714a9759f87412fb05253e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47e7f43ca3ba65dbd1b1edbe26db8cc4" category="paragraph">サイズまたはクォータ別のAzure NetApp Files ボリュームのパフォーマンスについては、を参照してください<block ref="bcd13cd67f856c9e615d78327e957b9c" category="inline-link-rx"></block>。</block>
  <block id="372d7a6604390fe9757888aff0a92970" category="example-title">Azure NetApp Files データストアをプライベートクラウドに追加する</block>
  <block id="0f9e7cabe2f81455810e96baca91c6a7" category="paragraph">Azure NetApp Files データストアをプライベートクラウドに追加するには、次の手順を実行します。</block>
  <block id="b1248573ef968f7d6fc7eaa453fa4d45" category="list-text">必要な機能を登録したら、適切なコマンドを実行して、Azure VMware解決策 プライベートクラウドクラスタにNFSデータストアを接続します。</block>
  <block id="567531ac8390e0378f43db080cbeec2b" category="list-text">Azure VMware解決策 プライベートクラウドクラスタ内の既存のANFボリュームを使用してデータストアを作成します。</block>
  <block id="ed491060b6ac47e89ad70eecda183065" category="paragraph">c：\users\niyaz &gt; az vmware datastore list --resource-key anfavsval2 --cluster Cluster-1 --private-cloud anFDataClus [｛"diskPoolVolume"：null、"id"："/Subscriptions /0efa2dffb4497-bfava-causs "resourcev3fvasa111" Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecods/volumes/ANFRecoDS001"、"priva@datastores "databva,databva,"bvasa,dba,dba,dbava,dbava,dba,dba,"bvasa,"bvasa,")")"bvasa,",",",",","bvasa,","bvasa,"bvasa,"bvasa,"databva,")",",","datastores ",","bva,",",",","data,"bvasa,",",","data,","data,"data,"data,"databva," ｛"diskPoolVolume"：null、"id"："/Subscription/0efa2dfb-f917c-4497-b56a-b3f4eadb8111/resourceGroups/anfavsval2/providers/anavsvase/privateClouds /anvases/clusters/clusters/anfavauss ","resdbavaid",",")"b56b56bocava,","b56b56b56a,",","グループ","b56b56b56b56b95b95b3fvasu2d""リソース",",",",""リソース",","" Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecodsu/volumes/anfrecodsU002"",""リソース",""グループ","",""リソース"b95b95b95b95b95b95b3fb3fb3fb3fb3fb3fb3fb3fb3fb3fb3fb3fb3fb3fb3fb3fb3fb3f</block>
  <block id="d1903b7932291ae49bf265e5af7a75f4" category="list-text">必要な接続が確立されると、ボリュームがデータストアとしてマウントされます。</block>
  <block id="b9eb0553d93e0e4bbee4142fec9403f9" category="paragraph"><block ref="b9eb0553d93e0e4bbee4142fec9403f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="078f601da77f62e8c7e097d5744f9b1b" category="section-title">サイジングとパフォーマンスの最適化</block>
  <block id="2954ff66e26b577154cf218d077ff1a9" category="paragraph">Azure NetApp Files は、 Standard （テラバイトあたり 16mbps ）、 Premium （テラバイトあたり 64MBps ）、 Ultra （テラバイトあたり 128MBps ）の 3 つのサービスレベルをサポートします。データベースワークロードのパフォーマンスを最適化するには、適切なボリュームサイズをプロビジョニングすることが重要です。Azure NetApp Files では、次の要素に基づいてボリュームのパフォーマンスとスループット制限が決定されます。</block>
  <block id="a5d62ae512b963e1f05e839467577f19" category="paragraph"><block ref="a5d62ae512b963e1f05e839467577f19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ce18fddaa7dc898334afc4ab63a163b" category="list-text">パフォーマンスを最適化するには、PremiumまたはUltraティアをデータストアボリュームに使用します。</block>
  <block id="f681df268b9e05fa5155bbf1f38d672f" category="list-text">ゲストVMのファイル共有の要件については、StandardまたはPremiumのいずれかのボリュームを使用してください。</block>
  <block id="1261ba8eeb83d9d138ff9e9a37214a7e" category="section-title">パフォーマンスに関する考慮事項</block>
  <block id="f4479400cc63a0bc54ea3a609d8d89aa" category="paragraph">NFSバージョン3では、ESXiホストと単一のストレージターゲット間の接続に使用できるアクティブなパイプは1つだけであることに注意してください。そのため、フェイルオーバーには別の接続を使用できる場合もありますが、1つのデータストアと基盤となるストレージの帯域幅は、1つの接続で提供可能な量に制限されます。</block>
  <block id="f4c57c87dfa0d5843279b51c6e10d0a6" category="paragraph">Azure NetApp Files ボリュームで使用可能な帯域幅を増やすには、ESXiホストからストレージターゲットへの接続が複数必要です。この問題 に対応するには、各データストアでESXiホストとストレージ間の接続を分けることで、複数のデータストアを設定します。</block>
  <block id="bde357669435115ce8fac67e3a3a5786" category="paragraph">帯域幅を広くするためには、複数のANFボリュームを使用して複数のデータストアを作成し、VMDKを作成して、複数のVMDKに論理ボリュームをストライプするのがベストプラクティスです。</block>
  <block id="c01a936a44f773bc3d0a636cb655c28c" category="list-text">Azure VMware解決策 では、デフォルトで8つのNFSデータストアがサポートされます。これは、サポートリクエストによって増やすことができます。</block>
  <block id="cd58e3b202d882202a16834028640630" category="list-text">ERファストパスとUltra SKUを併用することで、帯域幅の向上とレイテンシの低減を実現できます。詳細情報</block>
  <block id="6ef5173b6cc36d0f4efabbafeeee7443" category="list-text">Azure NetApp Files の「基本」のネットワーク機能を使用すると、Azure VMware解決策 からの接続は、ExpressRoute回線の帯域幅とExpressRouteゲートウェイにバインドされます。</block>
  <block id="0a8e9b67042320d1a2f3f6155fc3e096" category="list-text">「標準」のネットワーク機能（現在はパブリックプレビュー）を使用するAzure NetApp Files ボリュームでは、ExpressRouteファストパスがサポートされます。この機能を有効にすると、FastPathはネットワークトラフィックを直接Azure NetApp Files ボリュームに送信し、ゲートウェイをバイパスして、より高い帯域幅と低レイテンシを実現します。</block>
  <block id="1b75d86136a5cde892b315650fd5ea43" category="section-title">パフォーマンスの最適化</block>
  <block id="213debd5ccd87a89487239a8460a0f0e" category="paragraph">NFSデータストアごとの仮想マシンの推奨数は主観的ですが、各データストアに配置できるVMの最適な数は、さまざまな要因によって決まります。ほとんどの管理者が考慮するのは容量だけですが、VMDKに同時に送信されるI/Oの量は、全体的なパフォーマンスにとって最も重要な要因の1つです。ESXiホストには、データストアリソースに対して競合する仮想マシン間の公平性を確保するための多くのメカニズムがあります。ただし、パフォーマンスを制御する最も簡単な方法は、各データストアに配置する仮想マシンの数を制御することです。仮想マシンの同時I/Oパターンがデータストアに大量のトラフィックを送信している場合は、ディスクのキューがいっぱいになり、レイテンシが高くなります。</block>
  <block id="f9fd5bbf2764cc5b16e9eeeb8b57ee91" category="section-title">ボリュームとデータストアのサイジング</block>
  <block id="01ab7b17836cfa3916b003d7febafe43" category="paragraph">データストア用にAzure NetApp Files 上にボリュームを作成する場合は、必要以上にボリュームを作成することを推奨します。最大ボリュームサイズは100TBまで拡張できますが、最初は小規模なデータストアの容量から始めて、必要に応じて拡張することを推奨します。データストアを適切にサイジングすることで、データストアに多数の仮想マシンを誤って配置してしまうのを防止し、リソースの競合を減らすことができます。仮想マシンに追加の容量が必要な場合にデータストアとVMDKのサイズを簡単に拡張できるため、必要以上に大きいデータストアを作成する必要はありません。最適なパフォーマンスを実現するには、データストアのサイズを大きくするのではなく、データストアの数を増やすことを推奨します。</block>
  <block id="fad725216d945a6443f15949ae73b316" category="cell">覚えておいてください</block>
  <block id="28c7e0cc515aa1271633669cf0e579ad" category="list-text">ANF NFSデータストアのサイズは4TBから8TBに変更できます。</block>
  <block id="90f9dde25089c324af635a76b75a7509" category="list-text">15～20台のVMを1つのデータストアに配置します。VMの要件に応じて、これを35-40 VMに増やすことができます。</block>
  <block id="3236c97f9f8c9cb7fcbc35b9ff162ab3" category="list-text">最大限のパフォーマンスと管理性を実現するためには、データベースなどの高I/Oアプリケーション用にゲストによって管理されるNFS / SMBファイルシステムなどのゲスト所有のファイルシステムを検討してください。</block>
  <block id="0d3f5dc8a647758ee9ad71d0af34e75e" category="section-title">データストアのサイズを拡張する</block>
  <block id="9ae97248366686f76c6f9f6ac9b8d073" category="paragraph">ボリュームの形状変更と動的なサービスレベル変更は、SDDCに対して完全に透過的に行われます。Azure NetApp Files では、これらの機能によって、パフォーマンス、容量、コストの最適化を継続的に実施できます。Azure PortalまたはCLIからボリュームのサイズを変更するか、NFSデータストアのサイズを拡張してください。完了したら、vCenterにアクセスし、データストアタブに移動して適切なデータストアを右クリックし、容量情報の更新を選択します。この手法を使用すると、データストアの容量を増やし、ダウンタイムを生じさせずにデータストアのパフォーマンスを動的に向上させることができます。このプロセスは、アプリケーションに対しても完全に透過的です。</block>
  <block id="264b475cf0374b319edf3b094fe25874" category="list-text">ボリュームの形状変更と動的なサービスレベル機能により、安定状態のワークロードのサイジングを行い、オーバープロビジョニングを回避してコストを最適化できます。</block>
  <block id="c38ea7c6c5e1aef9a1df0cebd81737d9" category="list-text">パブリックプレビューでは、VAAIは有効になりません。</block>
  <block id="35084d885dea7b061e6894c1cf3036d9" category="section-title">ワークロード</block>
  <block id="f7458ac9343d5418ff038f156d9b29fc" category="paragraph">最も一般的なユースケースの1つはマイグレーションです。VMware HCXまたはvMotionを使用して、オンプレミスのVMを移動します。また、Rivermeadowを使用してAzure NetApp Files データストアにVMを移行することもできます。</block>
  <block id="36e402ac6b1a4b9a31bd376a7f89c68e" category="paragraph">VMのバックアップと迅速なリカバリは、ANFデータストアの大きなメリットの1つです。Snapshotコピーを使用すると、パフォーマンスに影響を与えることなくVMやデータストアのコピーをすばやく作成し、Azureストレージに送信して長期的なデータ保護を実現したり、ディザスタリカバリ目的でリージョン間レプリケーションを使用してセカンダリリージョンに送信したりできます。このアプローチでは、変更された情報のみを格納することで、ストレージスペースとネットワーク帯域幅を最小限に抑えます。</block>
  <block id="2bd24edc1157f2ea366bbf67e980b57e" category="paragraph">一般的な保護にはAzure NetApp Files Snapshotコピーを、ゲストVM上にあるSQL ServerやOracleなどのトランザクションデータの保護にはアプリケーションツールを使用します。これらの Snapshot コピーは VMware （整合性） Snapshot とは別のものであり、長期的な保護に適しています。</block>
  <block id="c69157396b1ac0cb910d839c99a0a9e3" category="admonition">ANFデータストアでは、Restore to New Volumeオプションを使用してデータストアボリューム全体をクローニングし、リストアしたボリュームを、AVS SDDC内のホストに別のデータストアとしてマウントできます。マウントされたデータストア内のVMは、個別にクローニングされたVMと同様に登録、再設定、およびカスタマイズできます。</block>
  <block id="92b97805e00b695b9f8aeddf2cc8828d" category="example-title">Cloud Backup for Virtual Machines</block>
  <block id="3b0ec96ab43930bb5b0f274d7a4733bd" category="paragraph">Cloud Backup for Virtual Machinesは、vCenter上のvSphere Web Client GUIを提供し、バックアップポリシーを通じてAzure VMware解決策 仮想マシンとAzure NetApp Files データストアを保護します。スケジュール、保持、その他の機能はポリシーで定義できます。Cloud Backup for Virtual Machine機能は、実行コマンドを使用して導入できます。</block>
  <block id="ad15ef62ee17e83e2a2c4de5cfc0a7e0" category="paragraph">セットアップポリシーと保護ポリシーをインストールするには、次の手順を実行します。</block>
  <block id="68efc774d1525ecfc4ad132a4f363c10" category="list-text">実行コマンドを使用して、Azure VMware解決策 プライベートクラウドにCloud Backup for Virtual Machineをインストールします。</block>
  <block id="3a1d9263efa0039dd46c2e2d0dfc2dec" category="list-text">クラウドサブスクリプションのクレデンシャル（クライアントとシークレットの値）を追加し、保護するリソースを含むクラウドサブスクリプションアカウント（ネットアップアカウントと関連するリソースグループ）を追加します。</block>
  <block id="60d5826756f013d28eadac75aec57698" category="list-text">リソースグループのバックアップの保持、頻度、およびその他の設定を管理するバックアップポリシーを1つ以上作成します。</block>
  <block id="6ad3833cba216d2fe6639be4726ad69e" category="list-text">コンテナを作成し、バックアップポリシーで保護する必要があるリソースを1つ以上追加します。</block>
  <block id="f0c88a652a15d9fedafa82483a1959b4" category="list-text">障害が発生した場合は、VM全体または特定のVMDKを同じ場所にリストアします。</block>
  <block id="52c902402ab9b60471632cf95f1940b6" category="admonition">Azure NetApp Files のSnapshotテクノロジを使用すれば、バックアップとリストアが非常に高速になります。</block>
  <block id="08042ba10c942968c10ed6576a20c1e6" category="paragraph"><block ref="08042ba10c942968c10ed6576a20c1e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3a1d923fd4fc5d2bc1c7e9ac58f59ef" category="example-title">Azure NetApp Files 、JetStream DR、およびAzure VMware解決策 を使用したディザスタリカバリ</block>
  <block id="93460124cbffe590c9cee7667d85d1da" category="paragraph">クラウドへのディザスタリカバリは、耐障害性に優れた対費用効果の高い方法で、サイトの停止やデータ破損からワークロードを保護します（ランサムウェアなど）。VMware VAIOフレームワークを使用すると、オンプレミスのVMwareワークロードをAzure Blobストレージにレプリケートしてリカバリできるため、データ損失を最小限に抑えたり、ほぼゼロのRTOを実現できます。Jetstream DRを使用すると、オンプレミスからAVS、特にAzure NetApp Files に複製されたワークロードをシームレスにリカバリできます。ディザスタリカバリサイトにある最小限のリソースと対費用効果の高いクラウドストレージを使用して、対費用効果の高いディザスタリカバリを実現します。Jetstream DRは、Azure Blob Storageを介したANFデータストアへのリカバリを自動化します。Jetstream DRは、独立したVMまたは関連するVMのグループを、ネットワークマッピングに従ってリカバリサイトインフラストラクチャにリカバリし、ランサムウェアからの保護のためのポイントインタイムリカバリを提供します。</block>
  <block id="8b8adea1567023f8a36745e1e256b41e" category="inline-link-macro">ANF、JetStream、AVSを使用したDR解決策</block>
  <block id="adeb8aee914844a07a855dd7b8fe7ffc" category="paragraph"><block ref="d016a1e57ae2464bcf00474caa126151" category="inline-link-macro-rx"></block>。</block>
  <block id="7a328b7e18172ee10e60d198b9fc26f7" category="doc">Azure / AVS向けのネットアップハイブリッドマルチクラウドソリューション</block>
  <block id="12709db6944c7fef6c2f181c42bd4741" category="doc">GCP / GCVE向けのネットアップハイブリッドマルチクラウドソリューション</block>
  <block id="fcee9cbc5f0c4f0ed62751d0d5f181ef" category="doc">VMwareソリューションを使用したネットアップのハイブリッドマルチクラウド</block>
  <block id="980ba21a8b1f775a9fae0552d8594171" category="doc">VMwareを使用したネットアップのハイブリッドマルチクラウドの概要</block>
  <block id="6e74d566879067f078b210f01e393989" category="paragraph">このアーキテクチャ（下の図を参照）では、NetApp Cloud Volumes ONTAP 、Cloud Volumes Service for Google Cloud、Azure NetApp Files を追加のゲスト内ストレージオプションとして使用して、複数のクラウドプロバイダ間でハイブリッドマルチクラウド接続とアプリケーションのモビリティを実現する方法を大まかに説明します。</block>
  <block id="3fe4ff67f6902f4d03e2aff729e6ca40" category="cell">2022年7月21日</block>
  <block id="c1cb2a6b83f79bd02d9023a9dc25d399" category="cell">CVOとJetStream for AVS（ゲスト接続ストレージ）を搭載したDR解決策 を追加</block>
  <block id="ac0f5de8cc00db2cb13da85ebd7e8780" category="cell">2022/06/10</block>
  <block id="e92ea8797c2bfc161566c53da6321114" category="cell">ANFネイティブデータストア概要を備えたAVSと、JetStreamを使用したDRを追加</block>
  <block id="b481ba8b3ad7fbb6a9786c9907a7c1ba" category="cell">VMwareを使用したネットアップハイブリッドマルチクラウドでのNFSデータストアの利用可能地域のリストが追加されました</block>
  <block id="27f04e57a2bba90c65656f5f47785def" category="open-title">VMwareを使用したハイブリッドマルチクラウド</block>
  <block id="24fef7dbaeab186ae1ddf8a1fa31ef68" category="cell">パブリッククラウドのVMwareと、各ハイパースケーラのネットアップストレージオプションを含むハイブリッドマルチクラウドモデルでネットアップを定義しています。ハイブリッドマルチクラウドのランディングページには、コンテンツごとに人気の高いコンテンツが表示されます。</block>
  <block id="91ef1e01c1592f4e80d47d11c68ddf5c" category="inline-link-macro">VMwareコンテンツを使用したハイブリッドマルチクラウド</block>
  <block id="356bcf8558d9911b876554df23345496" category="cell"><block ref="356bcf8558d9911b876554df23345496" category="inline-link-macro-rx"></block></block>
  <block id="9c155d9143dcac03a6b69afd6ec499b0" category="open-title">ハイブリッドマルチクラウド</block>
  <block id="749354a37dc4552d3c41bbf24ba08598" category="sidebar">VMC向けVMwareを使用したネットアップのハイブリッドマルチクラウド</block>
  <block id="045ec2e9b9dff589c32c257549300273" category="sidebar">CVOをゲスト接続型ストレージとして</block>
  <block id="ff106355f094608231dc8d7116a273e1" category="sidebar">VMC向けハイブリッドマルチクラウドソリューション</block>
  <block id="0ab50f8c17f87a8eecee4603b22f16c8" category="sidebar">VMware AVSを使用したネットアップのハイブリッドマルチクラウド</block>
  <block id="5ab938ef85bdfd3c94e8c4c5f1cfa448" category="sidebar">ゲスト接続ストレージとしてANFを選択します</block>
  <block id="5ab22899d20e83b71d3c1cbbedea208e" category="sidebar">AVS向けハイブリッドマルチクラウドソリューション</block>
  <block id="9fe80f9f1edda788e503795e34b7eb80" category="sidebar">GCVEを対象としたVMwareを使用したネットアップのハイブリッドマルチクラウド</block>
  <block id="f0476be9310e3a4606daded5c91d346f" category="sidebar">CVSをゲスト接続ストレージとして使用する</block>
  <block id="e809dfa83f36389270c46ad868461471" category="sidebar">GCVE向けハイブリッドマルチクラウドソリューション</block>
  <block id="d4cc78732ab0fdcd767ab42a015d34e0" category="sidebar">セキュリティの概要-ネットアップCVS in Google Cloud</block>
  <block id="538d26f438b9f54f2e02fe3eff3093f8" category="sidebar">VMwareを使用したネットアップのハイブリッドマルチクラウド</block>
  <block id="b8aef6e50d3ed85ad8f7568c45050629" category="sidebar">ワークロードの保護</block>
  <block id="a3e69dd4d9f892aab0dcbf0a5dd246e2" category="cell">1.4以降</block>
  <block id="f78d920d9d248820ddf7a3acdd9a34c0" category="doc">Tanzuを使用したVMware vSphereの概要</block>
  <block id="bac31e763c1b2955be0a10de0a4d8012" category="image-alt">VMware vSphereとKubernetes</block>
  <block id="c2e55cf1007600b25e0708bfe26a41f3" category="paragraph">Tanzu環境を備えたVMware vSphereは、ネイティブのTKGSクラスタと同様にWorkload Managementで有効になります。</block>
  <block id="9ff6aa8ffa487db2f0aebe3967972d77" category="image-alt">Supervisorクラスタ</block>
  <block id="b3ba0fe968ce39dcfc6fe8cc0f1b02da" category="image-alt">ネームスペース</block>
  <block id="516a32af5ad38dd3b9ca9c156da39add" category="inline-link-macro">VMware vSphereとTanzu（vSphereポッド）</block>
  <block id="a6726486b20bc2510c7d0b189955e69c" category="list-text"><block ref="a6726486b20bc2510c7d0b189955e69c" category="inline-link-macro-rx"></block></block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">Splunkのデータ分析を最大限に活用し、使いやすさを実感しているお客様には、増え続けるデータの索引付けが当然求められています。データ量の増加に伴い、コンピューティングとストレージのインフラも拡張に対応しなければなりません。</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">インテリジェントな階層化とコスト削減</block>
  <block id="7bcf31269131a9e7ab4d163f239fc4e5" category="inline-link-macro">Previous：この解決策 のメリット</block>
  <block id="b27eab207fc06febce259cb1c08777a3" category="paragraph"><block ref="b27eab207fc06febce259cb1c08777a3" category="inline-link-macro-rx"></block></block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">Splunkのデータ分析を最大限に活用し、使いやすさを実感しているお客様には、増え続けるデータの索引付けが当然求められています。データ量の増加に伴い、コンピューティングとストレージのインフラも拡張に対応しなければなりません。古いデータはあまり参照されないため、同じ量のコンピューティングリソースをコミットし、高価なプライマリストレージを消費する作業は、ますます効率的になりつつあります。大規模な運用では、ウォームデータを対費用効果の高い階層に移動することで、コンピューティングとプライマリストレージをホットデータ用に解放できます。</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">StorageGRID を使用したSplunk SmartStoreは、拡張性とパフォーマンスに優れたコスト効率の高い解決策 を提供します。SmartStoreはデータ認識機能を持つため、データアクセスパターンを自動的に評価して、リアルタイム分析（ホットデータ）用にアクセス可能なデータと、低コストの長期保存（ウォームデータ）に格納するデータを決定します。SmartStoreは業界標準のAWS S3 APIを動的かつインテリジェントに使用し、StorageGRID が提供するS3ストレージにデータを配置します。StorageGRID の柔軟なスケールアウトアーキテクチャにより、ウォームデータ階層は、必要に応じてコスト効率よく拡張できます。StorageGRID のノードベースのアーキテクチャにより、パフォーマンスとコストの要件が最適に満たされます。</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">次の図は、SplunkとStorageGRID の階層化を示しています。</block>
  <block id="821f09f0a5870b1dd3ee40e65f17b546" category="paragraph"><block ref="821f09f0a5870b1dd3ee40e65f17b546" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">業界をリードするSplunk SmartStoreとNetApp StorageGRID の組み合わせにより、フルスタックの解決策 を使用して、分離アーキテクチャのメリットを享受できます。</block>
  <block id="32c614a5724d73faf7f06f754330bbac" category="paragraph"><block ref="32c614a5724d73faf7f06f754330bbac" category="inline-link-macro-rx"></block></block>
  <block id="f362fde28c17f629ded4d965d576f423" category="summary">Splunk Enterpriseは、セキュリティ、IT、DevOpsの各チームの成果を高める、市場をリードするSIEM解決策 です。Splunkの使用率は、お客様の組織全体で大幅に増加しています。そのため、データソースをさらに追加し、そのデータを長期間保持して、Splunkインフラに重点を置く必要があります。</block>
  <block id="3613797d0f4ca076e9cb8ba4c75e87e6" category="inline-link-macro">前のバージョン：単一サイトのSmartStoreのパフォーマンス。</block>
  <block id="5fdd4eaa62513aac277472bf713d1bee" category="paragraph"><block ref="5fdd4eaa62513aac277472bf713d1bee" category="inline-link-macro-rx"></block></block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">Splunk SmartStoreとNetApp StorageGRID を組み合わせることで、SmartStoreとStorageGRID オブジェクトストレージにより取り込みパフォーマンスを向上させ、複数の地域にわたるSplunk環境の拡張性を高める、拡張性に優れたアーキテクチャを実現できます。</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="list-text">NetApp StorageGRID のドキュメントリソース</block>
  <block id="68d4d5362a15088f2ac3fa494c971af5" category="inline-link"><block ref="68d4d5362a15088f2ac3fa494c971af5" category="inline-link-rx"></block></block>
  <block id="580c43c30953ec671dd4a70120e1b513" category="paragraph"><block ref="580c43c30953ec671dd4a70120e1b513" category="inline-link-rx"></block></block>
  <block id="2e85fc867cab94d246e0bf6043b361cd" category="paragraph"><block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="list-text">Splunk Enterpriseに関するドキュメント</block>
  <block id="f710d46c12a05abcfde056d779cb608c" category="inline-link"><block ref="f710d46c12a05abcfde056d779cb608c" category="inline-link-rx"></block></block>
  <block id="2ab8bf37a62983163c96b3c2f9a275d4" category="paragraph"><block ref="2ab8bf37a62983163c96b3c2f9a275d4" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="list-text">SmartStore向けSplunk Enterprise</block>
  <block id="98bda64923adc1da4a0e009dd52832a4" category="inline-link"><block ref="98bda64923adc1da4a0e009dd52832a4" category="inline-link-rx"></block></block>
  <block id="86d261d18a8cb6ce8f95f58af41452e5" category="paragraph"><block ref="86d261d18a8cb6ce8f95f58af41452e5" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="list-text">Splunk Enterprise Distributed Deployment Manual』を参照してください</block>
  <block id="048c67f334d3e1bbcb765e563d076b7d" category="inline-link"><block ref="048c67f334d3e1bbcb765e563d076b7d" category="inline-link-rx"></block></block>
  <block id="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="paragraph"><block ref="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="list-text">Splunk Enterpriseインデクサとインデクサのクラスタを管理しています</block>
  <block id="87fbe590fc8f855078f14ba53325eb46" category="inline-link"><block ref="87fbe590fc8f855078f14ba53325eb46" category="inline-link-rx"></block></block>
  <block id="d0438efbc1a0dbee965023150ccf9334" category="paragraph"><block ref="d0438efbc1a0dbee965023150ccf9334" category="inline-link-rx"></block></block>
  <block id="e4c2e8edac362acab7123654b9e73432" category="cell">1.0</block>
  <block id="d1cdbd3c8324f3afbc5b420ce471feff" category="cell">2022年7月</block>
  <block id="881214767967db331c99550277ceb793" category="summary">このページでは、Splunkのアーキテクチャについて、キーの定義、Splunkの分散環境、Splunk SmartStore、データフロー、 ハードウェアとソフトウェアの要件、単一サイトやマルチサイトなど。</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Splunkのアーキテクチャ</block>
  <block id="aa91789a439fe45bd8d608e61ca9da8c" category="inline-link-macro">以前：Splunk SmartStore向けの柔軟なStorageGRID 機能が搭載されていました。</block>
  <block id="263af6ab01a543147e86a15ed7794682" category="paragraph"><block ref="263af6ab01a543147e86a15ed7794682" category="inline-link-macro-rx"></block></block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">キーの定義</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">次の2つの表に、Splunk環境で使用されているSplunkとネットアップのコンポーネントをまとめます。</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">この表は、Splunk Enterpriseの分散構成向けにSplunkのハードウェアコンポーネントをまとめたものです。</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Splunkコンポーネント</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">インデクサ</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Splunk Enterpriseデータ用のリポジトリ</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">ユニバーサルフォワーダ</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">データを取り込み、インデクサにデータを転送する責任があります</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">ヘッドを検索します</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">インデクサでデータを検索するために使用されるユーザーフロントエンド</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">クラスタマスター</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">インデクサと検索ヘッドのSplunkのインストールを管理します</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">Monitoring Consoleの略</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">導入全体で使用される一元化された監視ツール</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">ライセンスマスター</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">ライセンスマスターがSplunk Enterpriseのライセンスを処理し</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">導入サーバ</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">構成を更新し、アプリケーションを処理コンポーネントに配布します</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">ストレージコンポーネント</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">ホット階層データの管理に使用されるオールフラッシュストレージ。ローカルストレージとも呼ばれます。</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">ウォーム階層データの管理に使用するS3オブジェクトストレージ。SmartStoreがホット階層とウォーム階層の間でデータを移動するために使用します。リモートストレージとも呼ばれます。</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">次の表は、Splunkストレージアーキテクチャのコンポーネントを示しています。</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">責任あるコンポーネント</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">SmartStore</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">インデクサに、ローカルストレージからオブジェクトストレージにデータを階層化する機能を提供します。</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">ホット</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">ユニバーサルフォワーダが新しく書き込まれたデータを配置するランディングスポット。ストレージは書き込み可能で、データは検索可能です。このデータ階層は、通常SSDまたは高速HDDで構成されます。</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">Cache Managerの略</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">インデックス付きデータのローカルキャッシュを管理し、検索が行われたときにリモートストレージからウォームデータを取得し、キャッシュから使用頻度の低いデータを削除します。</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">ウォーム</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">データはバケットに論理的にロールされ、ホット階層から先にウォーム階層に名前が変更されます。この階層内のデータは保護され、ホット階層と同様に大容量のSSDまたはHDDで構成できます。一般的なデータ保護ソリューションを使用すると、増分バックアップとフルバックアップの両方がサポートされます。</block>
  <block id="392d70ca39f31f10bd637936769788df" category="cell">StorageGRID</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Splunkの分散環境</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">多くのマシンでデータが発生する大規模な環境をサポートするには、大量のデータを処理する必要があります。多数のユーザがデータを検索する必要がある場合は、Splunk Enterpriseインスタンスを複数のマシンに分散することで、環境を拡張できます。これを分散配置と呼びます。</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">一般的な分散環境では、Splunk Enterpriseインスタンスごとに特別なタスクを実行し、メインの処理機能に対応する3つの処理階層のいずれかに配置されます。</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">次の表に、Splunk Enterpriseの処理階層を示します。</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">階層</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">データ入力</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">運送会社</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">フォワーダはデータを消費し、インデクサのグループにデータを転送します。</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">インデックス作成</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">インデクサは、通常フォワーダのグループから受信する着信データをインデックス化します。インデクサはデータをイベントに変換し、イベントをインデックスに格納します。インデクサは、検索ヘッドからの検索要求に応答して、インデックス付きデータも検索します。</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">検索管理</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">検索ヘッドは、検索の中心となるリソースとして機能します。クラスタ内の検索ヘッドは交換可能であり、検索ヘッドクラスタの任意のメンバーから同じ検索、ダッシュボード、ナレッジオブジェクトなどにアクセスできます。</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">次の表に、Splunk Enterpriseの分散環境で使用される重要なコンポーネントを示します。</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">責任</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">クラスタマスターのインデックスを作成します</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">インデクサクラスタのアクティビティと更新を調整します</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">インデックス管理</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">インデックスクラスタ</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">相互にデータをレプリケートするように設定されたSplunk Enterpriseインデクサのグループ</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">HEAD Deployerを検索します</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">クラスタマスターへの導入と更新を処理します</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">検索ヘッド管理</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">HEADクラスタを検索してください</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">検索の中心となるリソースとして機能する検索ヘッドのグループ</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">ロードバランサ</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">クラスタ化されたコンポーネントが、検索ヘッド、インデックス化、S3ターゲットによって増大する需要に対応し、クラスタ化されたコンポーネントに負荷を分散するために使用されます。</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">クラスタ構成部品のロード管理</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Splunk Enterpriseの分散環境には、次のようなメリットがあります。</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">多様なデータソースや分散したデータソースにアクセス</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">企業の規模や複雑さに関係なく、データのニーズに対応する機能を提供します</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">データレプリケーションとマルチサイト環境で高可用性を実現し、ディザスタリカバリを確実に実現できます</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Splunk SmartStoreからダウンロードできます</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStoreは、Amazon S3などのリモートオブジェクトストアにインデックス付きデータを格納できるインデクサ機能です。導入のデータボリュームが増えるにつれて、ストレージの需要がコンピューティングリソースを消費するようになることがよくあります。SmartStoreを使用すると、インデクサのストレージリソースとコンピューティングリソースを個別に拡張することで、コスト効率の高い方法で管理できます。</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStoreでは、リモートストレージ階層とキャッシュマネージャが導入されています。これらの機能を使用すると、インデックスサーバー上またはリモートストレージ層上にデータをローカルに配置できます。キャッシュマネージャは、インデクサに設定されているインデクサとリモートストレージ層の間のデータ移動を管理します。</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">SmartStoreを使用すると、インデクサのストレージ設置面積を最小限に抑え、I/O最適化コンピューティングリソースを選択できます。ほとんどのデータはリモートストレージに格納されます。インデクサは、ホットバケット、アクティブまたは最近の検索に参加しているウォームバケットのコピー、バケットメタデータなど、最小限のデータを含むローカルキャッシュを維持します。</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Splunk SmartStoreのデータフロー</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">さまざまなソースからのデータがインデクサに達すると、データはインデックス付けされ、ホットバケットにローカルに保存されます。インデクサは、ホットバケットデータをターゲットインデクサにもレプリケートします。これまでのデータフローは、非SmartStoreインデックスのデータフローと同じです。</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">ホットバケットがウォームにロールすると、データフローは変化します。ソースインデクサは、ウォームバケットをリモートオブジェクトストア（リモートストレージ階層）にコピーしますが、既存のコピーはキャッシュに残しておきます。これは、最近インデックスが作成されたデータを検索する傾向があるためです。ただし、ターゲットインデクサはコピーを削除します。これは、リモートストアが複数のローカルコピーを維持せずに高可用性を提供するためです。これで、バケットのマスターコピーがリモートストアに配置されます。</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">次の図は、Splunk SmartStoreのデータフローを示しています。</block>
  <block id="9fb3b10aa394792f93ac799606bd8ed5" category="paragraph"><block ref="9fb3b10aa394792f93ac799606bd8ed5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">インデクサのキャッシュマネージャは、SmartStoreデータフローの中心になります。検索要求を処理するために必要に応じて、リモートストアからバケットのコピーを取得します。また、時間が経過すると検索に参加する可能性が低下するため、バケットの古いコピーや検索されていないコピーもキャッシュから削除されます。</block>
  <block id="715f39bb7952ceb84a6bd1bb44c1ac4d" category="paragraph">キャッシュマネージャの仕事は、必要なバケットに検索がすぐにアクセスできるようにしながら、使用可能なキャッシュの使用を最適化することです。</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">次の表に、解決策 の実装に必要なソフトウェアコンポーネントを示します。解決策の実装で使用されるソフトウェアコンポーネントは、お客様の要件に応じて異なる場合があります。</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">製品ファミリー</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">製品名</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">製品バージョン</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">StorageGRID オブジェクトストレージ</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11.6</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Enterpriseの</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">SmartStoreを使用したSplunk Enterprise</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">単一のマルチサイト要件</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">Splunkを使用している大規模環境で、多数のマシンからデータを取得し、多数のユーザがデータを検索する必要がある場合は、1つのサイトと複数のサイトにSplunk Enterpriseインスタンスを分散することで、環境を拡張できます。</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">次の表に、Splunk Enterpriseの分散環境で使用されるコンポーネントを示します。</block>
  <block id="1fbd0b2f11fe7779db6380b6d09478df" category="cell">相互のデータをレプリケートするように構成されたSplunk Enterpriseインデクサのグループ</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">ロードバランサ</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">クラスタ化されたコンポーネントの負荷管理</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">次の図は、単一サイトの分散環境の例を示しています。</block>
  <block id="733ecc3327823660187d1d7d76df7079" category="paragraph"><block ref="733ecc3327823660187d1d7d76df7079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">次の図は、マルチサイト分散配置の例を示しています。</block>
  <block id="d10d5e57a05119c14c599013d15d6553" category="paragraph"><block ref="d10d5e57a05119c14c599013d15d6553" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">次の表に、解決策 の実装に必要なハードウェアコンポーネントの最小数を示します。解決策の特定の実装で使用されるハードウェアコンポーネントは、お客様の要件に応じて異なる場合があります。</block>
  <block id="40b955882ffd3093985177c3721cfed2" category="admonition">Splunk SmartStoreとStorageGRID を単一サイトに導入したか複数サイトに導入したかに関係なく、すべてのシステムを単一のコンソールでStorageGRID グリッドマネージャから管理できます。詳細については、「Grid Managerによるシンプルな管理」を参照してください。</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">次の表は、単一サイトで使用されるハードウェアを示しています。</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">ディスク</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">使用可能容量</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">注</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">SG1000 StorageGRID の略</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">管理ノードとロードバランサ</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060の略</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">X48、8TB（NL-SAS HDD）</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1PBを提供</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">リモートストレージ</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">次の表に、マルチサイト構成に使用されるハードウェアをサイトごとに示します。</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">管理ノードとロードバランサ</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">NetApp StorageGRID ロードバランサ：SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">オブジェクトストレージでは、ロードバランサを使用してクラウドストレージネームスペースを提供する必要があります。StorageGRID は、F5やCitrixなどの主要ベンダーのサードパーティ製ロードバランサをサポートしていますが、多くのお客様が、エンタープライズクラスのStorageGRID バランサを選択してシンプルさ、耐障害性、高パフォーマンスを実現しています。StorageGRID ロードバランサは、VM、コンテナ、または専用アプライアンスとして使用できます。</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">StorageGRID SG1000では、S3データパス接続に対してハイアベイラビリティ（HA）グループとインテリジェントなロードバランシングを使用できます。カスタマイズしたロードバランサを提供するオンプレミスのオブジェクトストレージシステムは他にありません。</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">SG1000アプライアンスには次の機能があります。</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">ロードバランサと、必要に応じて管理ノードもStorageGRID システムに対して機能します</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">ノードの導入と設定を簡易化するStorageGRID アプライアンスインストーラ</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">S3エンドポイントとSSLの簡単な設定</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">専用帯域幅（他社製ロードバランサを他のアプリケーションと共有する場合との比較）</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">100Gbpsアグリゲートイーサネット帯域幅×最大4</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">次の図は、SG1000 Gateway Servicesアプライアンスを示しています。</block>
  <block id="3e44556364ce6907a44a9fb5c09eab69" category="paragraph"><block ref="3e44556364ce6907a44a9fb5c09eab69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="section-title">SG6060 の設計</block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">StorageGRID SG6060アプライアンスには、コンピューティングコントローラ（SG6060）と、2台のストレージコントローラと60本のドライブを搭載したストレージコントローラシェルフ（EシリーズE2860）が含まれています。このアプライアンスには次のような特長があります。</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">単一のネームスペースで最大400PBまでスケールアップできます。</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">25Gbpsアグリゲートイーサネット帯域幅×最大4</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">ノードの導入と設定を簡易化するStorageGRID アプライアンスインストーラが搭載されています。</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">各SG6060アプライアンスには、合計180本のドライブを搭載できる拡張シェルフを1台または2台追加できます。</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">EシリーズE2800コントローラ×2（デュプレックス構成）-ストレージコントローラのフェイルオーバーをサポートします。</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">5ドロワードライブシェルフ- 3.5インチドライブを60本（SSD×2、NL-SASドライブ×58）収容します。</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">次の図はSG6060アプライアンスを示しています。</block>
  <block id="8d3bb0a39a1d477f7f0b8789769c96c5" category="paragraph"><block ref="8d3bb0a39a1d477f7f0b8789769c96c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Splunkの設計</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">次の表に、単一サイトのSplunk構成を示します。</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">コア数</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16コア</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32GB RAM</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">ユーザデータを管理します</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">ユーザーフロントエンドはインデクサ内のデータを検索します</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">検索ヘッドクラスタの更新を処理します</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Splunkのインストールやインデックスを管理します</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">Monitoring Consoleとライセンスマスター</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">Splunk環境全体を一元的に監視し、Splunkライセンスを管理します</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">次の表に、マルチサイト構成のSplunkの設定を示します。</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">次の表に、マルチサイト構成（サイトA）のSplunkの設定を示します。</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">データを取り込み、インデクサにデータを転送する責任があります。</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">Splunk環境全体を一元的に監視し、Splunkライセンスを管理します。</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">次の表に、マルチサイト構成（サイトB）のSplunkの設定を示します。</block>
  <block id="b9006101b0f69e04590f5276d5cab52a" category="inline-link-macro">次の例：単一サイトのSmartStoreのパフォーマンス。</block>
  <block id="f7c6952971373a408f0b926fb7202e6f" category="paragraph"><block ref="f7c6952971373a408f0b926fb7202e6f" category="inline-link-macro-rx"></block></block>
  <block id="722462e25c63551f73985fc89f6a2139" category="summary">解決策 を使用すると、コンピューティング、ホットストレージ、またはS3リソースを追加して、ユーザ数や単一のマルチサイト環境全体での取り込み速度の増加に対応することができます。</block>
  <block id="0dd05c4d24d98f033770c01356b3ce26" category="paragraph"><block ref="0dd05c4d24d98f033770c01356b3ce26" category="inline-link-macro-rx"></block></block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*パフォーマンス*。Splunk SmartStoreとNetApp StorageGRID を組み合わせることで、オブジェクトストレージを使用して、ホットバケットとウォームバケット間でデータを迅速に移行できます。StorageGRID は、大規模なオブジェクトワークロードに高速なパフォーマンスを提供することで、移行プロセスを大幅に高速化します。</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*マルチサイト対応。* StorageGRID 分散アーキテクチャにより、Splunk SmartStoreは単一のグローバルネームスペースを介して単一サイトと複数サイトに展開を拡張でき、データの場所に関係なく、あらゆるサイトからデータにアクセスできます。</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*拡張性の向上。* Splunk環境のニーズやニーズの変化に合わせて、コンピューティングリソースから独立してストレージリソースを拡張できるため、TCOが削減されます。</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*容量*。StorageGRID を使用して、1つのネームスペースを560PB以上に拡張することで、Splunk環境の急速に拡大しているボリュームに対応できます。</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*データの可用性。*データの可用性、パフォーマンス、地理的な分散、保持、保護、 また、データのビジネスバリューの変化に応じて動的に調整できるメタデータベースのポリシーに基づくストレージコストも発生します。</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Splunkから提供されるガイドライン</block>
  <block id="29c3e2f956fc4b206ef3c7bbbb3730b0" category="paragraph">SmartStoreキャッシュは、ローカル（ホット）ストレージとリモート（ウォーム）ストレージ間のバケットコピーの転送を処理するインデクサのコンポーネントである。この解決策 のSplunkのサイジングは、に基づいています<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block>。解決策 を使用すると、コンピューティング、ホットストレージ、またはS3リソースを追加して、ユーザ数や単一のマルチサイト環境全体での取り込み速度の増加に対応することができます。</block>
  <block id="a013f15cce9510e1b717f058d9322b0f" category="inline-link-macro">次のステップ：インテリジェントな階層化とコスト削減。</block>
  <block id="1dd4851efea44091fc608ccfa49a8da6" category="paragraph"><block ref="1dd4851efea44091fc608ccfa49a8da6" category="inline-link-macro-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">このテクニカルレポートでは、Splunk SmartStore解決策 にネットアップが提供するメリットを紹介するとともに、環境内のSplunk SmartStoreの設計とサイジングを行うためのフレームワークを紹介します。その結果、シンプルで拡張性と耐障害性に優れた解決策 が実現し、説得力のあるTCOが実現します。</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869：『NetApp StorageGRID with Splunk SmartStore』</block>
  <block id="2dafc6e921d43527cceb2ba642abf973" category="paragraph">カーティケヤンナガリンガム、ボビー・オムメン、ジョセフ・カンダティルバビル</block>
  <block id="648e525fafbee4c7b749ab8740beb0d3" category="paragraph">Splunk Enterpriseは、市場をリードするSecurity Information and Event Management（SIEM）解決策 であり、セキュリティ、IT、DevOpsの各チームの成果を生み出します。データ量は急激に増大し続けており、この膨大なリソースを活用できる大企業にとって大きな販売機会となります。Splunk Enterpriseは、今後もさまざまなユースケースに採用されていきます。ユースケースの増加に伴い、Splunk Enterpriseが取り込んで処理するデータ量も増えています。Splunk Enterpriseの従来型アーキテクチャは、優れたデータアクセスと可用性を提供する分散型スケールアウト設計です。しかし、このアーキテクチャを使用している企業は、急速に拡大するデータ量に対応するための拡張に伴うコストの増大に直面しています。</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">Splunk SmartStoreとNetApp StorageGRID は、コンピューティングとストレージが分離された新しい導入モデルを提供することで、この課題を解決します。また、Splunkエンタープライズ環境に比類のない拡張性と柔軟性をもたらす解決策 を導入して、単一サイトから複数サイトに拡張できます。コンピューティングとストレージを個別に拡張し、コストを削減しながら、コスト効率に優れたクラウドベースのS3オブジェクトストレージにインテリジェントな階層化を追加することで、コストを削減できます。</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">解決策 を使用すると、検索パフォーマンスを維持しながらローカルストレージ内のデータ量を最適化できるため、コンピューティングとストレージをオンデマンドで拡張できます。SmartStoreは、データアクセスパターンを自動的に評価して、リアルタイム分析用にアクセス可能なデータと、低コストのS3オブジェクトストレージに格納するデータを決定します。</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">このテクニカルレポートでは、Splunk SmartStore解決策 にネットアップが提供するメリットを紹介するとともに、環境内のSplunk SmartStoreの設計とサイジングを行うためのフレームワークを紹介します。その結果、シンプルで拡張性と耐障害性に優れた解決策 が実現し、説得力のあるTCOが実現します。StorageGRID は、拡張性と対費用効果に優れたS3プロトコル/ APIベースのオブジェクトストレージであり、リモートストレージとも呼ばれます。そのため、Splunk解決策 を低コストで拡張しながら、耐障害性を高めることができます。</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStoreは、オブジェクトストレージをリモートストアまたはリモートストレージ階層と呼んでいます。</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">NetApp StorageGRID について</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID は、大規模アーカイブ、メディアリポジトリ、Webデータストア向けの、ソフトウェア定義型のオブジェクトストレージ解決策 です。ネットアップは、StorageGRID を導入したことで、業界をリードするイノベーションソリューションとデータ管理ソリューションの提供に関して20年に及ぶ経験を活かし、オンプレミス環境とパブリッククラウド環境、プライベートクラウド環境、ハイブリッドクラウド環境の両方で、情報の価値を最大限に管理、最大限に引き出しています。</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID は、大規模な非構造化データを長期間保管するためのセキュアなストレージを提供します。メタデータベースの統合ライフサイクル管理ポリシーによって、データのライフサイクルを通して最適な保存先が選択されます。コンテンツは適切な場所、適切なタイミングで、適切なストレージ階層に配置されるため、コストを削減できます。単一のネームスペースを使用すると、StorageGRID ストレージの地理的な場所に関係なく、単一の呼び出しでデータにアクセスできます。データセンターとクラウドインフラの間に複数のStorageGRID インスタンスを導入、管理できます。</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">StorageGRID システムは、グローバルに分散された冗長で種類の異なる複数のノードで構成され、既存および次世代のクライアントアプリケーションと統合することができます。</block>
  <block id="5680b078511221b1538af544a52a477e" category="paragraph"><block ref="5680b078511221b1538af544a52a477e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape：Worldwide Object-Based Storage 2019 Vendor Assessmentで、ネットアップを最新レポートのリーダーに位置付けました。StorageGRID は、最も要件の厳しい業界で20年近くの本番環境の導入実績があり、非構造化データのリーダーとして認められています。</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">StorageGRID を使用すると、次のことが可能になります。</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">複数のStorageGRID インスタンスを導入して、データセンターとクラウドの間のあらゆる場所から、数百ペタバイトまで簡単に拡張できる単一のネームスペースを通じてデータにアクセスします。</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">複数のインフラにわたって導入と一元管理を柔軟に行うことができます。</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">階層型イレイジャーコーディング（EC）を活用し、99.999%を超えるデータ保持性で、卓越したデータ保持性を実現します。</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Amazon S3 GlacierとAzure Blobに検証済みの統合により、ハイブリッドマルチクラウド機能をさらに有効化</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">独自のAPIやベンダーロックインを使用せずに、改ざん防止機能を備えたデータ保持によって、法規制義務を満たし、コンプライアンスを促進します。</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">NetApp StorageGRID のホームページ</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">StorageGRID を使用して、最も複雑な非構造化データ管理の問題を解決する方法の詳細については、を参照してください<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block>。</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">Splunk Enterpriseについて</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterpriseは、データを活用するためのプラットフォームです。ログファイル、Webサイト、デバイス、センサー、アプリケーションなど、さまざまなソースで生成されたデータがSplunkのインデクサーに送信されて解析されるため、豊富な分析情報をデータから取得できます。データ漏えいの特定、お客様や製品のトレンドの指摘、インフラの最適化の機会の発見、さまざまなユースケースにわたる実用的な分析情報の提供などが含まれます。</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">Splunk SmartStoreについて</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStoreを使用すると、Splunkアーキテクチャのメリットがさらに広がり、コスト効率の高い方法で拡張できます。コンピューティングリソースとストレージリソースを分離することで、I/O用に最適化されたインデクサノードには、データのサブセットだけをキャッシュとして格納できるため、ストレージの必要性を大幅に削減できます。コンピューティングリソースとストレージリソースのどちらか1つしか必要ない場合は追加しなくても、コストを大幅に削減できます。対費用効果が高く、拡張性に優れたS3ベースのオブジェクトストレージを使用できます。これにより、環境がさらに簡易化され、コストが削減され、より大規模なデータセットを保持できます。</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStoreは、次のような企業に大きな価値をもたらします。</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">コストが最適化されたS3オブジェクトストレージにウォームデータを移動することで、ストレージコストを削減する</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">ストレージとコンピューティングを分離してシームレスに拡張</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">耐障害性に優れたクラウドネイティブストレージを活用して、ビジネス継続性を簡易化</block>
  <block id="8db09dd9a1d2508a1e11189bfe47d246" category="inline-link-macro">次のページ:この解決策 の利点。</block>
  <block id="0032cf08702e09af53bf601b3f83e323" category="paragraph"><block ref="0032cf08702e09af53bf601b3f83e323" category="inline-link-macro-rx"></block></block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">エンドポイントの設定をさらに強化するために、 StorageGRID は管理ノードに組み込まれたトラフィック分類ポリシーを提供し、ワークロードトラフィックを監視し、さまざまな Quality of Service （ QoS ；サービス品質）制限をワークロードに適用できます。トラフィック分類ポリシーは、ゲートウェイノードおよび管理ノードの StorageGRID ロードバランササービス上のエンドポイントに適用されます。これらのポリシーは、トラフィックシェーピングおよびモニタリングに役立ちます。</block>
  <block id="7d68f597b217695f6702ae71ae4eb455" category="summary">StorageGRID には、変化し続ける環境に合わせて、ユーザが利用し、カスタマイズできるさまざまな機能があります。Splunk SmartStoreの導入から拡張に至るまで、環境には変更を迅速に採用することが求められ、Splunkを無停止で使用する必要があります。StorageGRID の柔軟なデータ管理ポリシー（ILM）とトラフィック分類子（QoS）を使用すると、環境を計画して適合させることができます。</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Splunk SmartStore向けの柔軟なStorageGRID 機能</block>
  <block id="0a0da304981bebd25b6bd55cb6151bf0" category="paragraph"><block ref="0a0da304981bebd25b6bd55cb6151bf0" category="inline-link-macro-rx"></block></block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Managerはブラウザベースのグラフィカルインターフェイスで、次の図に示すように、世界中に分散された複数の場所にまたがるStorageGRID システムの設定、管理、および監視を1つの画面で実行できます。</block>
  <block id="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="paragraph"><block ref="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Grid Managerインターフェイスを使用して次のタスクを実行します。</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">Splunk向けNetApp StorageGRID アプリ</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">Splunk Enterprise向けNetApp StorageGRID アプリケーションは、Splunk Enterprise向けのアプリケーションです。このアプリケーションは、Splunk向けNetApp StorageGRID アドオンと連携して動作します。StorageGRID の健全性、アカウントの使用状況、セキュリティ監査の詳細、リソースの使用状況や監視などを確認できます。</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">次の図は、Splunk向けStorageGRID アプリケーションを示しています。</block>
  <block id="7c39625522ddbadc65ea87056e2d32c9" category="paragraph"><block ref="7c39625522ddbadc65ea87056e2d32c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">ILMポリシー</block>
  <block id="fce13f2ee25ffdd1859d6a17a94b0e73" category="paragraph">StorageGRID には、オブジェクトの複数のコピーを保持し、2+1や4+2などのEC（イレイジャーコーディング）スキームを使用して、特定のパフォーマンスやデータ保護の要件に応じてオブジェクトを格納するなど、柔軟なデータ管理ポリシーが用意されています。ワークロードと要件が時間の経過とともに変化する場合、 ILM ポリシーも時間の経過とともに変化する必要があることがよくあります。ILM ポリシーの変更は中核的な機能であり、絶えず変化する環境に StorageGRID のお客様がすばやく簡単に適応できるようにします。</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID は SG5712 、 SG5760 、 SG6060 、 SGF6024 などのベアメタルアプライアンスまたは専用アプライアンスであるノードを追加することで、パフォーマンスを拡張します。テストでは、SG6060アプライアンスを使用した最小サイズの3ノードグリッドを使用して、SmartStoreの主要パフォーマンス要件を超えました。Splunkインフラを拡張し、インデクサを追加すれば、ストレージノードを追加してパフォーマンスと容量を高めることができます。</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">ロードバランサとエンドポイントの設定</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">StorageGRID の管理ノードは、 StorageGRID システムを表示、設定、管理するための Grid Manager UI （ユーザインターフェイス）エンドポイントと REST API エンドポイント、およびシステムアクティビティを追跡するための監査ログを提供します。Splunk SmartStoreリモートストレージに可用性の高いS3エンドポイントを提供するために、管理ノードとゲートウェイノードでサービスとして実行されるStorageGRID ロードバランサを実装しました。また、ロードバランサはローカルトラフィックを管理し、ディザスタリカバリに役立つ GSLB （グローバルサーバロードバランシング）と通信します。</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">エンドポイントの設定をさらに強化するために、管理ノードに組み込まれたトラフィック分類ポリシーをStorageGRID で使用して、ワークロードトラフィックを監視し、さまざまなQuality of Service（QoS；サービス品質）制限をワークロードに適用できます。トラフィック分類ポリシーは、ゲートウェイノードおよび管理ノードの StorageGRID ロードバランササービス上のエンドポイントに適用されます。これらのポリシーは、トラフィックの制限と監視に役立ちます。</block>
  <block id="923a187b8784c27278acc68df21738b8" category="inline-link-macro">次はSplunkのアーキテクチャです。</block>
  <block id="ec27327edf763f5474f1428dfcc067b1" category="paragraph"><block ref="ec27327edf763f5474f1428dfcc067b1" category="inline-link-macro-rx"></block></block>
  <block id="b27064a5ca31ea524411e6ce281c8f0c" category="paragraph">ネットアップはSplunk SmartStore向けのシンプルで拡張性に優れた解決策 を提供し、パフォーマンスと耐障害性を最大限に高めながら、魅力的なTCOを実現します。</block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">このページでは、NetApp StorageGRID 、Splunk Enterprise、Splunk SmartStoreなど、解決策 の設定に使用するコンポーネントについて説明します。</block>
  <block id="0f641483b3a1a8cfcb4b0ad971a2d016" category="inline-link-macro">従来：インテリジェントな階層化とコスト削減を実現</block>
  <block id="b1320bfc03a3d1edb16e0f717149a713" category="paragraph"><block ref="b1320bfc03a3d1edb16e0f717149a713" category="inline-link-macro-rx"></block></block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID は、高性能で対費用効果の高いオブジェクトストレージプラットフォームです。ノードベースの分散グリッドアーキテクチャを使用して、インテリジェントなポリシーベースのグローバルデータ管理を実現します。数ペタバイトの非構造化データと数十億のオブジェクトを、ユビキタスなグローバルオブジェクトネームスペースと高度なデータ管理機能を組み合わせることでシンプルに管理できます。単一コールのオブジェクトアクセスはサイト間を拡張し、高可用性アーキテクチャを簡素化しながら、サイトやインフラストラクチャの停止に関係なく、オブジェクトへの継続的なアクセスを保証します。</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">マルチテナンシーを使用すると、複数のクラウドやエンタープライズ非構造化データアプリケーションを同じグリッド内で安全に処理できるため、StorageGRID のROIとユースケースが向上します。メタデータベースのオブジェクトライフサイクルポリシーを使用して複数のサービスレベルを作成し、複数の地域にわたってデータの保持、保護、パフォーマンス、ローカリティを最適化できます。ユーザは、要件の変化に応じて、ポリシーを調整し、システムを停止せずにデータの再配置を行うことができます。</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStoreはStorageGRID をリモートストレージ階層として活用し、地理的に分散した複数のサイトを展開して、単一のオブジェクトネームスペースとして提供される堅牢な可用性と耐久性を実現します。これにより、Splunk SmartStoreは、StorageGRID の高パフォーマンス、高密度の容量、および単一のURLを使用して複数の物理サイトにまたがる数百のノードに拡張可能な機能を活用し、オブジェクトとやり取りできます。また、 1 つの URL だけで、ストレージの拡張、アップグレード、修復を、 1 つのサイトだけでなく無停止で実行することもできます。StorageGRID 独自のデータ管理ポリシーエンジンにより、最適なレベルのパフォーマンスと耐久性が実現し、データローカリティ要件への準拠が実現します。</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunkは、マシン生成データの収集と分析を行うリーダーであり、運用分析機能を通じてITを簡易化、刷新します。また、ビジネス分析、セキュリティ、IoTのユースケースにも対応します。Splunkソフトウェアを適切に導入するためには、ストレージが欠かせません。</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">マシン生成データは、最も急速に増加しているビッグデータのタイプです。フォーマットは予測不能であり、多くの異なるソースから得られます。多くの場合、高レートで大量に発生します。このようなワークロード特性は、一般にデジタルエキゾーストと呼ばれます。Splunk SmartStoreを使用すると、こうしたデータを把握し、最もコスト効率の高いストレージ階層にホットデータとウォームデータを最適な場所に配置できるように、スマートなデータ階層化を実現できます。</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStoreは、StorageGRID などのオブジェクトストレージ（リモートストレージまたはリモートストレージ階層とも呼ばれます）を使用して、S3プロトコルを使用してウォームデータを格納するインデクサ機能です。</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">導入のデータボリュームが増加すると、ストレージの需要がコンピュータリソースの需要を上回ってしまうことがよくあります。SmartStoreでは、コンピューティングとストレージを個別に拡張することにより、インデックスサーバのストレージリソースとコンピューティングリソースをコスト効率よく管理できます。</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStoreでは、S3プロトコルとキャッシュマネージャを使用して、リモートストレージ層を導入しています。これらの機能を使用すると、インデックスサーバー上またはリモートストレージ上にデータをローカルに配置できます。インデクサに常駐するキャッシュマネージャは'インデクサとリモートストレージ階層の間のデータ移動を管理しますデータはバケットメタデータと一緒にバケットに（ホットおよびウォーム）格納されます。</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">SmartStoreを使用すると、ほとんどのデータがリモートストレージ階層に存在するため、インデクサのストレージ設置面積を最小に抑え、I/O最適化コンピューティングリソースを選択できます。インデクサは、要求され予測された結果を返すために必要な最小限のデータ量を表すローカルキャッシュを維持します。ローカルキャッシュには、ホットバケット、アクティブまたは最新の検索に使用されるウォームバケットのコピー、およびバケットメタデータが格納されます。</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">StorageGRID を搭載したSplunk SmartStoreを使用すると、高パフォーマンスでコスト効率の高いリモートストレージを使用して環境を段階的に拡張でき、解決策 全体にも高い柔軟性を提供できます。これにより、お客様は任意の量のコンポーネント（ホットストレージやウォームS3ストレージ）をいつでも追加でき、インデックスの追加、データの保持の変更、システム停止なしの取り込み速度の向上が可能です。</block>
  <block id="5cb48860c8dadcd442724a4122e031bd" category="inline-link-macro">次に、Splunk SmartStore向けの柔軟なStorageGRID 機能を紹介します。</block>
  <block id="9a206b91ebbd6c75f73fba261d1eed1c" category="paragraph"><block ref="9a206b91ebbd6c75f73fba261d1eed1c" category="inline-link-macro-rx"></block></block>
  <block id="5273463fa2459ed38da1af200de6f150" category="summary">このページでは、NetApp StorageGRID コントローラでのSplunk SmartStoreのパフォーマンスについて説明します。Splunk SmartStoreが、パフォーマンス検証の対象であるStorageGRID オブジェクトストレージであるリモートストレージにウォームデータを移動します。</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">単一サイトのSmartStoreのパフォーマンス</block>
  <block id="47251bcda6f5d3ff81fc5968fa702aad" category="inline-link-macro">それまでの環境：Splunkのアーキテクチャが</block>
  <block id="10da3263ceac590ab423073945a99eac" category="paragraph"><block ref="10da3263ceac590ab423073945a99eac" category="inline-link-macro-rx"></block></block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">このセクションでは、NetApp StorageGRID コントローラでのSplunk SmartStoreのパフォーマンスについて説明します。Splunk SmartStoreがウォームデータをリモートストレージに移動します。この場合は、パフォーマンス検証の対象となるStorageGRID オブジェクトストレージになります。</block>
  <block id="1d01dcffdd1257afb01e4194d766d2f9" category="paragraph"><block ref="1d01dcffdd1257afb01e4194d766d2f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">EF600はホットキャッシュストレージに使用し、StorageGRID 6060はリモートストレージに使用しました。パフォーマンス検証には次のアーキテクチャを使用しました。2つの検索ヘッドと4つの大きなフォワーダを使用してデータをインデクサに転送し、7つのSplunk Event Generator（Eventgens）を使用してリアルタイムデータを生成し、18のインデクサにデータを格納しました。</block>
  <block id="a2fd19ff7e04cf04d5d99320b979cd00" category="paragraph"><block ref="a2fd19ff7e04cf04d5d99320b979cd00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">次の表に、SmartStorageのパフォーマンス検証に使用するハードウェアを示します。</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">大規模なフォワーダ</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16コア</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">SLED 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">ユーザーフロントエンドはインデクサでデータを検索します</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">SmartStoreリモートストアのパフォーマンス検証</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">このパフォーマンス検証では、すべてのインデクサ上のローカルストレージにSmartStoreキャッシュを10日間にわたって設定しました。Splunkクラスタマネージャで「maxDataSize=auto」（750MBのバケットサイズ）を有効にし、すべてのインデクサに変更をプッシュしました。アップロードのパフォーマンスを測定するために、10日間は1日あたり10TBを取り込み、すべてのホットバケットをまとめてウォームアップしました。同時に、インスタンスあたりの最大スループットと平均スループットを取得し、展開全体をSmartStore Monitoring Consoleダッシュボードから取得しました。</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">この図は、1日以内に取り込まれたデータを示しています。</block>
  <block id="c1b0c9568cd6b9bf236fb9566021d8a4" category="paragraph"><block ref="c1b0c9568cd6b9bf236fb9566021d8a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">クラスタマスターから次のコマンドを実行しました（インデックス名は「eventgen-test」）。次に、SmartStore Monitoring Consoleダッシュボードを使用して、インスタンスあたりのアップロードの最大スループットと平均スループット、および展開全体のスループットをキャプチャしました。</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">クラスタマスターは、すべてのインデクサに対してパスワードなしの認証を行います（rtp-idx0001…rtp-idx0018）。</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">ダウンロードパフォーマンスを測定するために、次のコマンドでevict CLIを2回実行して、キャッシュからすべてのデータを削除しました。</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">クラスタマスターから次のコマンドを実行し、StorageGRID のリモートストアにある10日間のデータの上で検索ヘッドから検索を実行しました。次に、SmartStore Monitoring Consoleダッシュボードを使用して、インスタンスあたりのアップロードの最大スループットと平均スループット、および展開全体のスループットをキャプチャしました。</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">インデクサ構成は、SmartStoreクラスタマスターからプッシュされました。クラスタマスターは、インデクサに対して次のような設定を行いました。</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">検索ヘッドで次の検索クエリを実行し、パフォーマンスマトリックスを収集しました。</block>
  <block id="39b8fe84a2982bcbeb6d733343e0678d" category="paragraph"><block ref="39b8fe84a2982bcbeb6d733343e0678d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">パフォーマンス情報はクラスタマスターから収集しました。ピークパフォーマンスは61.34GBpsです。</block>
  <block id="0feb590fe449a8a847517a38f1e0415f" category="paragraph"><block ref="0feb590fe449a8a847517a38f1e0415f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">平均パフォーマンスは約29GBpsです。</block>
  <block id="2a1437158884c9696a6d4cac546972b1" category="paragraph"><block ref="2a1437158884c9696a6d4cac546972b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">StorageGRID のパフォーマンス</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">Eventgenのサポートを提供し</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">SmartStoreのパフォーマンスは、大量のデータから特定のパターンや文字列を検索することに基づいています。この検証では、を使用してイベントが生成されます<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> 検索ヘッドからSplunkの特定のインデックス（eventgen-test）にアクセスし、ほとんどのクエリはStorageGRID に送信されます。次の図は、クエリデータのヒットとミスを示しています。ヒットデータはローカルディスクからで、ミスデータはStorageGRID コントローラから取得されます。</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">緑の色はヒットデータを示し、オレンジ色はミスデータを示します。</block>
  <block id="0bf13ffd9c4e3655384eea9760fdd547" category="paragraph"><block ref="0bf13ffd9c4e3655384eea9760fdd547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">StorageGRID で検索を実行するクエリを次の図に示すように、StorageGRID からのS3読み出し速度の時間が表示されます。</block>
  <block id="5e789be14498e5bac09395d944ced093" category="paragraph"><block ref="5e789be14498e5bac09395d944ced093" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">StorageGRID ハードウェアの使用状況</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">StorageGRID インスタンスには、1つのロードバランサと3つのStorageGRID コントローラがあります。3台のコントローラすべてのCPU利用率は75%～100%です。</block>
  <block id="5c78f5ad926b76e88a749362fb6e3412" category="paragraph"><block ref="5c78f5ad926b76e88a749362fb6e3412" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">SmartStoreとNetAppストレージコントローラ-お客様にとってのメリット</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*コンピューティングとストレージの分離* Splunk SmartStoreは、コンピューティングとストレージを分離し、個別に拡張できます。</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*データはオンデマンドで提供されます。* SmartStoreは、データをオンデマンドのコンピューティングに近く、コンピューティングとストレージの柔軟性とコスト効率を提供し、大規模なデータ保持をより長期化します。</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">* AWS S3 API準拠。* SmartStoreは、AWS S3およびS3 API準拠のStorageGRID などのオブジェクトストアであるリストアストレージと通信するためにAWS S3 APIを使用しています。</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*ストレージ要件とコストを削減* SmartStoreは、古いデータ（ウォーム/コールド）の保存要件を軽減します。データのコピーを1つだけ必要とするのは、ネットアップストレージがデータ保護を提供し、障害や高可用性に対処するためです。</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*ハードウェア障害。* SmartStore展開でのノード障害により、データにアクセスできなくなり、ハードウェア障害やデータの不均衡からのインデクサリカバリが大幅に高速化されています。</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">アプリケーションおよびデータ対応キャッシュ。</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">インデクサの追加とセットアップティアダウンクラスタをオンデマンドで実行。</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">ストレージ階層はハードウェアに固定されなくなりました。</block>
  <block id="a2a5916477583887c69c752ae6366750" category="paragraph"><block ref="a2a5916477583887c69c752ae6366750" category="inline-link-macro-rx"></block></block>
  <block id="f377bdd54f0f567b139a5913567466f1" category="paragraph">* VMware Tanzu Kubernetes Grid (TKG)*</block>
  <block id="7a3368d887604b1812f8f796b668f0e7" category="paragraph">*『VMware Tanzu Kubernetes Grid Service（TKGS）』</block>
  <block id="8da30835717bc9e00a9ea2b89d75d943" category="paragraph">* VMware Tanzu Kubernetes Grid Integrated（TKGI）*</block>
  <block id="22bd1c4adfe1c3f7d3dc00763a7a8d40" category="paragraph">*「vSphereポッド」（Tanzu（vSphereポッド）を使用したvSphere *</block>
  <block id="4f50bac068dbe84c04d257f75bb42142" category="list-text">vSphereネイティブのポッドは、完全な分離のために、処方された仮想ハードウェアを使用して、薄い光子ベースのレイヤで実行されます。</block>
  <block id="c8cefb07aba3cc260670993281c9bef5" category="list-text">NSXは必須ですが'Harborイメージレジストリなどの追加機能をサポートできます</block>
  <block id="b603aa094817eb0510887a841cc71df8" category="list-text">TKGSなどの仮想スーパーバイザークラスタを使用して、vSphere 7.0U1以降に導入および管理されます。ポッドをESXiノードで直接実行します。</block>
  <block id="cf3b96589f75768a855cebe2679e5b8b" category="list-text">vSphere管理により、vSphereと完全に統合され、最高レベルの可視性と制御を実現します。</block>
  <block id="3b050b735b1eb713cc1b3816851e3060" category="list-text">独立したCRXベースのポッドにより、最高レベルのセキュリティを実現。</block>
  <block id="e7004adb0d2f74954305a1023249e642" category="list-text">vSphere CSIの永続的ストレージのみをサポートします。サードパーティ製ストレージオーケストレーションツールはサポートされていません。</block>
  <block id="90534ff553f8895d609b7e0cec5e7977" category="paragraph">Astra Tridentは、コンテナやKubernetesディストリビューション向けの、VMware Tanzuなどのオープンソースの完全サポートされたストレージオーケストレーションツールです。</block>
  <block id="25e19f6e213533d24e711ce5e6738fa9" category="paragraph">VMware vSphereとvSphereポッドとも呼ばれるTanzuを使用すると、VMware vSphere環境のESXiハイパーバイザーノードをベアメタルKubernetes環境のワーカーノードとして使用できます。</block>
  <block id="c2556907e1f90b93c9c43e198113de8b" category="paragraph">仮想化されたSupervisor Clusterは、Kubernetesの高可用性コントロールプレーンを提供するために作成され、ユーザのリソース分離を確実にするために、アプリケーションごとに個別の名前空間が作成されます。</block>
  <block id="9e2885b693a2045e931fda4aeb8bf28f" category="paragraph">Tanzuを含むVMware vSphereを有効にすると、球レットアプリケーションが各ESXiホストにインストールされて設定されます。これにより、各ノードがKubernetes環境でワーカーとして機能し、各ノードに導入されたポッドを管理できます。</block>
  <block id="c44d7c5351501c027261c0480a658d6d" category="paragraph">現在、VMware vSphereでは、TanzuポッドおよびvSphereポッドを使用していますが、ローカルのvSphere CSIドライバのみをサポートしています。これは、vSphere Clientで、vSphereデータストアとして現在使用できるストレージターゲットから選択するストレージポリシーを作成するように管理者を設定することで機能します。これらのポリシーは、コンテナ化されたアプリケーション用の永続ボリュームを作成するために使用されます。</block>
  <block id="fe41e8fdcbc9d8447c9077fbd167fe8d" category="admonition">ネットアップでは、現在、外部のONTAP ストレージアレイやElementストレージアレイに直接接続できるNetApp Astra CSIドライバはサポートしていませんが、多くの場合、これらのネットアップストレージシステムを使用してvSphere環境のプライマリストレージをサポートしています。 また、ネットアップの高度なデータ管理ツールやStorage Efficiencyツールをこれらの方法で使用できます。</block>
  <block id="70aaffec040bcf9e5cf77c0ccabb8f11" category="paragraph">TanzuによるVMware vSphereの詳細については、のドキュメントを参照してください <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>。</block>
  <block id="f0fa38f675f888f14af946299f91a36a" category="summary">VMware vSphereは、データセンターと主要なすべてのクラウドプロバイダで仮想化インフラを提供します。このエコシステムは、場所を問わず仮想コンピューティングの一貫性を維持するディザスタリカバリシナリオに最適です。この解決策 では、データセンターロケーションとAWS上のVMwareクラウドの両方で、VMware仮想化コンピューティングリソースを使用します。</block>
  <block id="c0b7ac0f313be4f2bef55fc6cf3a1947" category="paragraph">この解決策 では、VMware vSphere v7.0U3を実行するHPE ProLiant DL360 Gen 10サーバを使用します。コンピューティングインスタンスを6つ導入し、SQL ServerとOracleサーバに適切なリソースを提供しました。</block>
  <block id="ff1600196b624f9503bddaca0ce10f5d" category="paragraph">ネットアップは、SQL Server 2019で10台のWindows Server 2019 VMを導入しました。それぞれのVMはデータベースサイズが異なるうえ、Oracle 19Cを実行するOracle Linux 8.5 VMを10台導入し、データベースサイズもさまざまです。</block>
  <block id="20f748e1f003c63ad3c63122e1629424" category="paragraph">当社では、プライマリサイトからリストアされた仮想マシンを実行するための十分なリソースを提供するために、2台のホストを持つVMware Cloud on AWSにSDDCを導入しました。</block>
  <block id="a84e981cfea0f9fca307649d4e7bd364" category="paragraph"><block ref="a84e981cfea0f9fca307649d4e7bd364" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f10db05e58b527be630ad143ec566a5" category="summary">このドキュメントで紹介するユースケースでは、ネットアップとVMwareの統合に特化した、実績のあるディザスタリカバリテクノロジに焦点を当てています。ネットアップのONTAP ストレージシステムは、実績あるデータミラーリングテクノロジを提供します。このテクノロジを使用すると、業界をリードするクラウドプロバイダのオンプレミステクノロジとONTAP テクノロジにまたがるディザスタリカバリソリューションを設計できます。</block>
  <block id="86082b0bfc7279f0a1feebe1de23f618" category="paragraph">ONTAP on AWSは、アプリケーションデータをクラウドにレプリケートするためにSnapCenter やSyncMirror とシームレスに統合できる解決策 の1つです。Veeam Backup &amp; Replicationも、ネットアップのONTAP ストレージシステムと緊密に統合され、vSphereネイティブストレージへのフェイルオーバーを可能にする、よく知られたテクノロジです。</block>
  <block id="81127e42ddbedbb1cad03bf70d694aa9" category="paragraph">この解決策 では、SQL ServerとOracleアプリケーションデータをホストしているONTAP システムから、ゲスト接続ストレージを使用してディザスタリカバリ解決策 を提供しています。SnapCenter とSnapMirrorを使用すると、ONTAP システム上のアプリケーションボリュームを保護し、それらをクラウド上のFSXまたはCVOにレプリケートするための管理しやすい解決策 が提供されます。SnapCenter は、DR対応の解決策 で、すべてのアプリケーションデータをAWS上のVMware Cloudにフェイルオーバーします。</block>
  <block id="66e5d5ad5173b295e6b59ee5152216d0" category="list-text">解決策 のドキュメントへのリンク</block>
  <block id="4f6300de9742001d9f7a797da5d53a27" category="paragraph"><block ref="4f6300de9742001d9f7a797da5d53a27" category="inline-link-rx"></block></block>
  <block id="6590e8ec3c5ce0748f55250c70ec048c" category="paragraph"><block ref="6590e8ec3c5ce0748f55250c70ec048c" category="inline-link-rx"></block></block>
  <block id="314695da56c7e601cdf6cfc3227858d9" category="paragraph">この解決策 で概説しているフェイルオーバープロセスが正常に完了すると、SnapCenter とVeeamがAWSで実行されるバックアップ機能を再開します。FSX for ONTAP は、元のオンプレミスデータセンターとの間にSnapMirror関係が確立されていないプライマリストレージとして指定されます。オンプレミスで通常の機能が再開されたら、本ドキュメントに記載されているプロセスと同じ方法で、オンプレミスのONTAP ストレージシステムにデータをミラーリングできます。</block>
  <block id="44ee07074aaf6f8c932889c7158c9906" category="paragraph">また、このドキュメントで説明しているように、アプリケーションデータボリュームをFSX for ONTAP からオンプレミスのONTAP ストレージシステムにミラーリングするようにSnapCenter を設定することもできます。同様に、スケールアウトバックアップリポジトリを使用してAmazon S3にバックアップコピーをレプリケートするようにVeeamを設定し、オンプレミスのデータセンターにあるVeeamバックアップサーバからこれらのバックアップにアクセスできるようにします。</block>
  <block id="fd41e9ec1db4527e12ae403974c6c63c" category="paragraph">フェイルバックについてはこのドキュメントでは説明していませんが、フェイルバックについてはここで説明する詳細なプロセスとはほとんど異なります。</block>
  <block id="cd39f47230bb959e72acb3eb9e5be469" category="paragraph">この解決策 には、ネットアップ、VMware、Amazon Web Services（AWS）、Veeamの革新的なテクノロジが含まれています。</block>
  <block id="ded9cd19cde727f824d72e3ad8ef7662" category="section-title">VMware Cloud Foundationの場合</block>
  <block id="66c9de10f8f96cbfebae805c8a5d0c23" category="paragraph">VMware Cloud Foundationプラットフォームには複数の製品が統合されており、管理者は異機種混在環境全体に論理インフラストラクチャをプロビジョニングできます。これらのインフラ（ドメイン）は、プライベートクラウドとパブリッククラウドの間で一貫した運用を実現します。Cloud Foundationソフトウェアに付属するコンポーネントは、検証済みで条件を満たすコンポーネントを特定するための部品表で、お客様のリスクを軽減し、導入を容易にします。</block>
  <block id="6fa493c0540d656a06e5bc7de182aa5d" category="paragraph">Cloud Foundation BOMには、次のコンポーネントが含まれています。</block>
  <block id="ea712de8051099e742f7b2832804bbe4" category="list-text">Cloud Builder</block>
  <block id="719175eb8771501a012c6d964c29be69" category="list-text">SDDCマネージャ</block>
  <block id="beb9456af324db48fa76084e755d8d0b" category="list-text">VMware vCenter Server Appliance の略</block>
  <block id="f7eea647714641318ee86fedbbed4691" category="list-text">VMware ESXi</block>
  <block id="4ef3d5ade4e00a1767e0cb9da8f6a895" category="list-text">VMware NSX</block>
  <block id="8b1198108d735d15d15ede582012a434" category="list-text">vRealize Automation</block>
  <block id="ea7e7011cc6c20fceefe3f63a6f66b73" category="list-text">vRealize Suite Lifecycle Managerの略</block>
  <block id="7b0dffec85c977f50577ae9e44323ccc" category="list-text">vRealize Log Insightの特長</block>
  <block id="9170490ac213e0fff83de34c7e91bcae" category="inline-link">VMware Cloud Foundationのドキュメント</block>
  <block id="d48b3b75cdd9d69e243c551b712f75e8" category="paragraph">VMware Cloud Foundationの詳細については、を参照してください<block ref="c470e518572535c6a48639b6f7d6e5a7" category="inline-link-rx"></block>。</block>
  <block id="776e392281968fc227c904b7efb2c82d" category="paragraph">VMware vSphereは、物理リソースをコンピューティング、ネットワーク、ストレージのプールに変換する仮想化プラットフォームで、お客様のワークロードおよびアプリケーション要件を満たすために使用できます。VMware vSphereの主なコンポーネントは次のとおりです。</block>
  <block id="ef424b79c70de97da1b97dc4f12fadee" category="list-text">* ESXi。*このVMwareハイパーバイザーは、コンピューティングプロセッサ、メモリ、ネットワーク、その他のリソースを抽象化して、仮想マシンやコンテナワークロードで利用できるようにします。</block>
  <block id="b061e8a5ed8a3a3c319736ff70d51a55" category="list-text">* vCenter。* VMware vCenterは、仮想インフラストラクチャの一部として、コンピューティングリソース、ネットワーク、ストレージとやり取りするための一元的な管理エクスペリエンスを提供します。</block>
  <block id="d42d5a3f8818d925febb1ccce5b5ea10" category="paragraph">ネットアップのONTAP は、製品の緊密な統合、強力なサポート、強力な機能とストレージ効率化機能を備えており、vSphere環境のポテンシャルを最大限に引き出し、堅牢なハイブリッドマルチクラウド環境を構築します。</block>
  <block id="841d75538dc45858ed53ac16358cc7ad" category="paragraph">VMware vSphereの詳細については、を参照してください<block ref="e516b39e5a9a3597e0dc419e086e5395" category="inline-link-rx"></block>。</block>
  <block id="95d57daea7acbc2a7bbae6ded68ee952" category="paragraph">VMwareを使用したネットアップのソリューションの詳細については、以下を参照してください<block ref="3137e9e57f0cd434b880b626db7b2f62" category="inline-link-rx"></block>。</block>
  <block id="3c7164d9420b263a215271d6db617f2b" category="paragraph">一般にネットワークハイパーバイザと呼ばれるVMware NSXは、ソフトウェア定義モデルを使用して仮想化されたワークロードを接続します。VMware NSXは、オンプレミスとAWS上のVMware Cloudに広く導入されており、お客様のアプリケーションやワークロードのネットワーク仮想化とセキュリティを強化します。</block>
  <block id="0b044c7db1e40b4d475fb5b8e225f65e" category="paragraph">VMware NSXの詳細については'を参照してください<block ref="24474a71eda89537e8233714a7d94cc5" category="inline-link-rx"></block>。</block>
  <block id="1299e00bdf464c0bee14fc2f6aab0f37" category="paragraph">NetApp ONTAP ソフトウェアは、 VMware vSphere 環境向けのストレージ解決策を約 20 年にわたって業界をリードしてきました。また、コストを削減しながら管理を簡易化する革新的な機能を継続的に追加しています。vSphere と ONTAP を併用すると、ホストハードウェアと VMware ソフトウェアのコストを削減できます。また、標準搭載のStorage Efficiency機能を活用しながら、一貫した高パフォーマンスで低コストでデータを保護できます。</block>
  <block id="00f8f930135e2662dd01e1e4fc65ec48" category="paragraph">NetApp ONTAP の詳細については、以下を参照してください<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>。</block>
  <block id="cc1cc96c6bd7a597d867c658bca3b7d2" category="section-title">VMware向けのNetApp ONTAP ツール</block>
  <block id="f19b4defe5bd521861bd47f062cab40e" category="paragraph">VMware向けONTAP ツールでは、複数のプラグインを1つの仮想アプライアンスに統合して、ネットアップストレージシステムを使用するVMware環境で仮想マシンのエンドツーエンドのライフサイクル管理を実現しています。VMware用のONTAP ツールには、次のものがあります。</block>
  <block id="dd167aeb5a59f14930ce90d7b32a1310" category="list-text">* Virtual Storage Console（VSC）。*ネットアップストレージを使用して、VMとデータストアの包括的な管理タスクを実行します。</block>
  <block id="caba40f1f4e68f7405c7405bbdf4067a" category="list-text">* VASA Provider for ONTAP 。* Storage Policy-Based Management（SPBM）をVMwareのVirtual Volume（VVol）とネットアップストレージで有効化。</block>
  <block id="52d97a7fde4d2984a3335c87380d5ab4" category="list-text">* Storage Replication Adapter（SRA）*。VMware Site Recovery Manager（SRM）と組み合わせて使用すると、障害が発生した場合にvCenterのデータストアと仮想マシンをリカバリできます。</block>
  <block id="829e52698f21d046badfc12c5846a723" category="paragraph">VMware用のONTAP ツールを使用すると、外付けストレージだけでなく、VVolおよびVMware Site Recovery Managerとの統合も管理できます。これにより、vCenter環境からネットアップストレージを簡単に導入して運用することができます。</block>
  <block id="88d6ca70545898ecc8709b701555225b" category="paragraph">VMware向けNetApp ONTAP ツールの詳細については、以下を参照してください<block ref="c1c4ef8e79ad3b0cab24049eb01885be" category="inline-link-rx"></block>。</block>
  <block id="805c9517e95d3e9efc4b46738ab825fc" category="section-title">NetApp SnapCenter</block>
  <block id="de29da4940709c9f9b03e3d597dcb7cd" category="paragraph">NetApp SnapCenter ソフトウェアは、使いやすいエンタープライズプラットフォームで、アプリケーション、データベース、ファイルシステム全体でデータ保護をセキュアに調整、管理できます。SnapCenter は、ストレージシステムのアクティビティを監視および制御する機能を犠牲にすることなく、これらのタスクをアプリケーション所有者にオフロードすることで、バックアップ、リストア、クローンのライフサイクル管理を簡易化します。SnapCenter は、ストレージベースのデータ管理を活用することで、パフォーマンスと可用性を向上させるとともに、テストや開発の時間を短縮します。</block>
  <block id="a1f54fde77874bbd5be133ca3970d7e8" category="paragraph">SnapCenter Plug-in for VMware vSphereでは、仮想マシン（VM）、データストア、および仮想マシンディスク（VMDK）に対して、crash-consistentおよびVMと整合性のあるバックアップおよびリストア処理がサポートされます。また、SnapCenter アプリケーション固有のプラグインもサポートしているため、仮想化されたデータベースやファイルシステムについて、アプリケーションと整合性のあるバックアップおよびリストア処理を保護できます。</block>
  <block id="f655858b5e82a216de5b6aea071de457" category="paragraph">NetApp SnapCenter の詳細については、以下を参照してください<block ref="aa600981aea381f09908ce10e8269417" category="inline-link-rx"></block>。</block>
  <block id="98c2040e71eaa6795dfe7287a8c6ad93" category="section-title">サードパーティのデータ保護</block>
  <block id="a03670ab805efda6af1029d0cc6ed56e" category="paragraph">Veeam Backup &amp; Replicationは、クラウド、仮想、物理の各ワークロード向けのバックアップ、リカバリ、データ管理解決策 です。Veeam Backup &amp; Replicationには、NetApp Snapshotテクノロジとの統合が特殊化されており、vSphere環境をさらに保護します。</block>
  <block id="a174e33a347bdf86d254ef6b64ebb844" category="paragraph">Veeam Backup &amp; Replicationの詳細については、以下を参照してください<block ref="ff5498b1e93a9fbc10c4f9b6c05db801" category="inline-link-rx"></block>。</block>
  <block id="e1d618f208de1e0652f995ea9ef70c8a" category="section-title">AWS IDおよびアクセス管理</block>
  <block id="72e3b385ab9dce0490acd4320d69b190" category="paragraph">AWS環境には、コンピューティング、ストレージ、データベース、ネットワーク、分析、 さらに、ビジネス上の課題を解決するためのサポートも充実しています。企業は、これらの製品、サービス、およびリソースへのアクセスを許可されたユーザーを定義できる必要があります。ユーザーが構成を操作、変更、または追加できる条件を決定することも同様に重要です。</block>
  <block id="e0371101cd60437f116ae662823d656b" category="paragraph">AWS Identity and Access Management（AIM；アイデンティティアクセス管理）は、AWSのサービスと製品へのアクセスを管理するためのセキュアなコントロールプレーンです。ユーザ、アクセスキー、および権限が適切に設定されていれば、AWSとAmazon FSXにVMware Cloudを導入できます。</block>
  <block id="f97bd254f4560b300dffc1c8320c079a" category="paragraph">AIMの詳細については、以下を参照してください<block ref="51dd129a9a709f0af102f91347214719" category="inline-link-rx"></block>。</block>
  <block id="f93a7ad035f2ab23b92d7f904c204a67" category="paragraph">VMware Cloud on AWS は、 VMware のエンタープライズクラスの SDDC ソフトウェアを AWS クラウドに提供し、ネイティブ AWS サービスへのアクセスを最適化します。VMware Cloud Foundationを基盤とするVMware Cloud on AWSは、VMwareのコンピューティング、ストレージ、ネットワーク仮想化製品（VMware vSphere、VMware vSAN、VMware NSX）と、専用の柔軟なベアメタルAWSインフラストラクチャ上で実行できるように最適化されたVMware vCenter Server管理を統合します。</block>
  <block id="21b9508ecf23f768b8172f58ec935a32" category="paragraph">AWS上のVMware Cloudの詳細については、以下を参照してください<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>。</block>
  <block id="4d82a1ec1af02725042c8c785564ee7a" category="section-title">NetApp ONTAP 対応の Amazon FSX</block>
  <block id="5588d719a2e52cc2437eac404a5afac6" category="paragraph">Amazon FSX for NetApp ONTAP は、フル機能を備えたフルマネージドのONTAP システムで、ネイティブのAWSサービスとして利用できます。NetApp ONTAP を基盤に構築されており、使い慣れた機能に加えて、フルマネージドのクラウドサービスが簡易化されています。</block>
  <block id="4f706209d760c6b9c796b171e747ba84" category="paragraph">Amazon FSX for ONTAP は、パブリッククラウドまたはオンプレミスのVMwareなど、さまざまなコンピューティングタイプにマルチプロトコルサポートを提供します。今日のゲスト接続のユースケースや、テクニカルプレビューのNFSデータストアで利用できるAmazon FSX for ONTAP を使用すると、企業は自社のオンプレミス環境やクラウドで使い慣れた機能を活用できます。</block>
  <block id="97461b19a572ee6589bfdc8bb87cf344" category="paragraph">NetApp ONTAP のAmazon FSXの詳細については、以下を参照してください<block ref="8010f27a5d53263c1742228bc262a2e3" category="inline-link-rx"></block>。</block>
  <block id="b7dd764025f54c4b3bccf4f05424bf77" category="doc">SQL Serverアプリケーションデータをリストアする</block>
  <block id="95f316bb0a092035f960a46cc12705d3" category="paragraph">次のプロセスでは、オンプレミスサイトが動作不能になった場合に、VMwareクラウド サービス でAWS内のSQL Serverをリカバリする方法について説明します。</block>
  <block id="eb7b93b4aadbfaf4b78c0c4bfe125171" category="paragraph">リカバリ手順を続行するには、次の前提条件を満たしている必要があります。</block>
  <block id="aca50891060f7ebe7be1192b4a8b78ad" category="list-text">Windows Server VMがVeeam Full Restoreを使用してVMware Cloud SDDCにリストアされている。</block>
  <block id="9731e8839876f65368eab4ef1eecdc20" category="inline-link-macro">SnapCenter のバックアップとリストアのプロセスの概要</block>
  <block id="fe51b70218e2191f0338d4bcb01eb4a7" category="list-text">セカンダリSnapCenter サーバが確立され、セクションで説明する手順に従ってSnapCenter データベースのリストアと設定が完了している <block ref="f1b6dca3014749c436758b70cc0d8f7f" category="inline-link-macro-rx"></block></block>
  <block id="565a76f57020cb4db728d0a24384a0d9" category="section-title">VM：SQL Server VMのリストア後の設定</block>
  <block id="eface2367b3de31eee3102f62de9295d" category="paragraph">VMのリストアが完了したら、SnapCenter でホストVMを再検出するための準備として、ネットワークやその他の項目を設定する必要があります。</block>
  <block id="0a64ec0b8b14816ed47650a0096fd3b3" category="list-text">管理およびiSCSIまたはNFS用に新しいIPアドレスを割り当てます。</block>
  <block id="8ceacb8e6c12d270f190550e317ed5be" category="list-text">ホストをWindowsドメインに追加します。</block>
  <block id="612dbb7fb61a87afcf471d797448e487" category="list-text">DNSにホスト名を追加するか、SnapCenter サーバのhostsファイルにホスト名を追加します。</block>
  <block id="21b91bc158a5a6579966133ece84f927" category="admonition">SnapCenter プラグインが現在のドメインとは異なるドメインクレデンシャルを使用して導入されている場合は、SQL Server VMでPlug-in for Windowsサービスのログオンアカウントを変更する必要があります。ログオンアカウントを変更したら、SnapCenter SMCore、Plug-in for Windows、およびPlug-in for SQL Serverの各サービスを再起動します。</block>
  <block id="0634c3a099feec2a74ff9c0751719ed6" category="admonition">リストアされたVMをSnapCenter で自動的に再検出するには、FQDNをオンプレミスのSnapCenter に最初に追加されたVMと同じにする必要があります。</block>
  <block id="0d4bede73841f93a92c80d25b0194d1e" category="section-title">SQL Serverリストア用にFSXストレージを構成します</block>
  <block id="1a87030fb5d5a31f7bcfdfa68ade9691" category="paragraph">SQL Server VMのディザスタリカバリリストアプロセスを実行するには、既存のSnapMirror関係をFSXクラスタから解除し、ボリュームへのアクセスを許可する必要があります。これには、次の手順を実行します。</block>
  <block id="4c9e09e4807ffb0a4456b29e6f9a4281" category="list-text">SQL Serverデータベースボリュームとログボリュームの既存のSnapMirror関係を解除するには、FSX CLIから次のコマンドを実行します。</block>
  <block id="3d20282913974593577c784c3192e510" category="list-text">SQL Server Windows VMのiSCSI IQNを含むイニシエータグループを作成して、LUNへのアクセスを許可します。</block>
  <block id="d287a88d877191e5695e6e46cde801a3" category="list-text">最後に、作成したigroupにLUNをマッピングします。</block>
  <block id="e47557c42d0af2df20a15a19f84795ee" category="list-text">パス名を検索するには'lun showコマンドを実行します</block>
  <block id="c38f08ac05515c2b594fc836b22181e0" category="section-title">Windows VMでiSCSIアクセスを設定し、ファイルシステムを検出します</block>
  <block id="39eb9c3b6c8eb2106dcb06edfdbb6f65" category="list-text">SQL Server VMからiSCSIネットワークアダプタをセットアップし、FSXインスタンス上のiSCSIターゲットインターフェイスへの接続が確立されたVMwareポートグループ上で通信します。</block>
  <block id="cf8c6b6b8c54ec784d05b5f092751a4d" category="list-text">iSCSI Initiator Propertiesユーティリティを開き、Discovery、Favorite Targets、およびTargetsタブの古い接続設定を消去します。</block>
  <block id="1a2e1a79fa495e5f511838af9609be4f" category="list-text">FSXインスタンス/クラスタ上のiSCSI論理インターフェイスにアクセスするためのIPアドレスを特定します。これは、AWSコンソールのAmazon FSX &gt; ONTAP &gt; Storage Virtual Machinesの下にあります。</block>
  <block id="d9401c99c6ddc6dbcd6070c357088cf5" category="paragraph"><block ref="d9401c99c6ddc6dbcd6070c357088cf5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba5037ceee608981a7684c3277ceca73" category="list-text">[Discovery]タブで[Discover Portal]をクリックし、FSX iSCSIターゲットのIPアドレスを入力します。</block>
  <block id="49ba75dd04ab3da15488d6e271466575" category="paragraph"><block ref="49ba75dd04ab3da15488d6e271466575" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd6bd08689af39f12a04ce95acbaa7df" category="paragraph"><block ref="cd6bd08689af39f12a04ce95acbaa7df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="193f314b02dfe15e71a9ec5d16f5ce73" category="list-text">[ターゲット]タブで[接続]をクリックし、構成に応じて[マルチパスを有効にする]を選択し、[OK]をクリックしてターゲットに接続します。</block>
  <block id="8625607d58104640aa3cc3a687356560" category="paragraph"><block ref="8625607d58104640aa3cc3a687356560" category="inline-image-macro-rx" type="image"></block></block>
  <block id="907488914aeab882127886e6028b0ea0" category="list-text">コンピュータの管理ユーティリティを開き、ディスクをオンラインにします。以前と同じドライブレターを保持していることを確認します。</block>
  <block id="885afbf2d17d52ec64abfd147535488e" category="paragraph"><block ref="885afbf2d17d52ec64abfd147535488e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc8ec032118740c31355c3345d62bf4" category="section-title">SQL Serverデータベースを接続します</block>
  <block id="7f423619ca14c77f6b9db6f7bda8de76" category="list-text">SQL Server VMで、Microsoft SQL Server Management Studioを開き、接続を選択してデータベースへの接続プロセスを開始します。</block>
  <block id="fd43b9851dc24c4889086cdc9afd2a3a" category="paragraph"><block ref="fd43b9851dc24c4889086cdc9afd2a3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8bff2998bccc1ca5a6d707233af02c9" category="list-text">[追加]をクリックし、SQL Serverプライマリデータベースファイルが格納されているフォルダに移動して選択し、[OK]をクリックします。</block>
  <block id="f700bbcedcee0092e600d8527c84b19f" category="paragraph"><block ref="f700bbcedcee0092e600d8527c84b19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a827dff2feb3c6226fcac7b4b80a3cc8" category="list-text">トランザクションログが別のドライブにある場合は、トランザクションログが格納されているフォルダを選択します。</block>
  <block id="f42947d249de7e97db085085f542e3c4" category="list-text">終了したら、[OK]をクリックしてデータベースに接続します。</block>
  <block id="74242a349c592d71e13c317715f21c6f" category="paragraph"><block ref="74242a349c592d71e13c317715f21c6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f8fd7fd0d8b19f4ee350fa3bfaca1ca" category="section-title">SQL Server Plug-inとのSnapCenter 通信を確認します</block>
  <block id="b6c6326ece2d2042cc822762ac90932a" category="paragraph">SnapCenter データベースを以前の状態にリストアすると、SQL Serverホストが自動的に再検出されます。これを正しく機能させるには、次の前提条件に注意してください。</block>
  <block id="db44d05563a2083dddeaf5a8c08c36b8" category="list-text">SnapCenter はディザスタリカバリモードにする必要があります。これは、Swagger APIまたはディザスタリカバリのグローバル設定で実行できます。</block>
  <block id="f77564f6296c2b86366fa8c55cde3b3d" category="list-text">SQL ServerのFQDNは、オンプレミスのデータセンターで実行されていたインスタンスと同じである必要があります。</block>
  <block id="7effb9a6b0bfb89f35e1496a0b8ee21c" category="list-text">元のSnapMirror関係が解除されている必要があります。</block>
  <block id="25c898cf2666acc247fd6eda6262658f" category="list-text">データベースを含むLUNをSQL Serverインスタンスにマウントし、データベースを接続しておく必要があります。</block>
  <block id="9c7568e40b946736fc8b8e0b79f35603" category="paragraph">SnapCenter がディザスタリカバリモードになっていることを確認するには、SnapCenter Webクライアントで設定に移動します。[グローバル設定]タブに移動し、[災害復旧]をクリックします。ディザスタリカバリを有効にするチェックボックスがオンになっていることを確認します。</block>
  <block id="fa26a16fa4868aed3c0c634a2d7a27a5" category="paragraph"><block ref="fa26a16fa4868aed3c0c634a2d7a27a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba3ddc84b2f59fd2a102309365db81a" category="doc">Veeamフルリストアを使用してアプリケーションVMをリストアする</block>
  <block id="36dc3b29e336105b87846d5917f36466" category="section-title">バックアップリポジトリを作成し、S3からバックアップをインポートする</block>
  <block id="bfa510d8cc1cb8902740f538c9871cd5" category="paragraph">セカンダリVeeamサーバから、S3ストレージからバックアップをインポートし、SQL Server VMとOracle VMをVMware Cloudクラスタにリストアします。</block>
  <block id="e2f3927605d5be5f9e2924c7578d06ab" category="paragraph">オンプレミスのスケールアウトバックアップリポジトリに含まれていたS3オブジェクトからバックアップをインポートするには、次の手順を実行します。</block>
  <block id="04e06ef7f33197a158ddc19d53c0d1a5" category="list-text">[バックアップリポジトリ]に移動し、上部のメニューで[リポジトリの追加]をクリックして、[バックアップリポジトリの追加]ウィザードを起動します。ウィザードの最初のページで、バックアップリポジトリタイプとしてObject Storageを選択します。</block>
  <block id="6206d8a7c31f00a44ec41ebae87e8b6b" category="paragraph"><block ref="6206d8a7c31f00a44ec41ebae87e8b6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4fcfafe3d4baedadc9910b99baf527a" category="list-text">オブジェクトストレージタイプとしてAmazon S3を選択します。</block>
  <block id="293aed632d96ade5bfef832bcdc2cd1e" category="paragraph"><block ref="293aed632d96ade5bfef832bcdc2cd1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="698ebee929c01fad4c318876313789ab" category="list-text">Amazon Cloud Storage ServicesのリストからAmazon S3を選択します。</block>
  <block id="12cfad41ab613d7744d12d07d4a556d4" category="paragraph"><block ref="12cfad41ab613d7744d12d07d4a556d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2639f2cf7409eb24ed59c46794f26c33" category="list-text">ドロップダウンリストから事前に入力したクレデンシャルを選択するか、クラウドストレージリソースにアクセスするための新しいクレデンシャルを追加します。次へをクリックして続行します。</block>
  <block id="ca271cf67d4c973e828e31689285727f" category="paragraph"><block ref="ca271cf67d4c973e828e31689285727f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d158a2a4f2b2c9b52c009bfbd87668a" category="list-text">Bucketページで、データセンター、バケット、フォルダ、および必要なオプションを入力します。適用をクリックします。</block>
  <block id="cf2158b0a3f58d891bcbc6031fde92d4" category="paragraph"><block ref="cf2158b0a3f58d891bcbc6031fde92d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5adae514074dc7c746819968e035e2a0" category="list-text">最後に'完了を選択してプロセスを完了し'リポジトリを追加します</block>
  <block id="076951b7756435f95654310ef960f866" category="section-title">S3オブジェクトストレージからバックアップをインポートする</block>
  <block id="397f99a04387aed7bca366a20084083f" category="paragraph">前のセクションで追加したS3リポジトリからバックアップをインポートするには、次の手順を実行します。</block>
  <block id="6add4097706ff1ee04793b80b99c3980" category="list-text">S3バックアップリポジトリで、バックアップのインポートを選択してバックアップのインポートウィザードを起動します。</block>
  <block id="d2e0dedfd0a67b45116f5c02f41dfad6" category="paragraph"><block ref="d2e0dedfd0a67b45116f5c02f41dfad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f08dd57757030d81cfcdd38f9c443e05" category="list-text">インポート用のデータベースレコードが作成されたら、[次へ]を選択し、サマリー画面で[完了]を選択してインポートプロセスを開始します。</block>
  <block id="dee3665bb9cd000955be1a118818554f" category="paragraph"><block ref="dee3665bb9cd000955be1a118818554f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4afd5477c1ce1473a255dee8ce524184" category="list-text">インポートが完了したら、VMware CloudクラスタにVMをリストアできます。</block>
  <block id="8f2cd7b75623b2421c1eaadd379ca431" category="paragraph"><block ref="8f2cd7b75623b2421c1eaadd379ca431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73fee194f5e4e8ac33d750244fe7ebd5" category="section-title">Veeamを使用して、アプリケーションVMをVMware Cloudにリストアし</block>
  <block id="ec223385ec31537dfd3adc4f3f97735d" category="paragraph">SQLおよびOracle仮想マシンをAWSワークロードドメイン/クラスタ上のVMware Cloudにリストアするには、次の手順を実行します。</block>
  <block id="9085bbecf522e8f0cf0f7d5480dd7cd9" category="list-text">Veeamのホームページで、インポートしたバックアップを含むオブジェクトストレージを選択し、リストアするVMを選択して右クリックし、Restore Entire VM（VM全体のリストア）を選択します。</block>
  <block id="5320e29249c22b00240fc3df301d60a6" category="paragraph"><block ref="5320e29249c22b00240fc3df301d60a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d53e507da99665f0cd76090f0c8b932" category="list-text">[Full VM Restore]ウィザードの最初のページで、必要に応じてVMをバックアップに変更し、[Next]を選択します。</block>
  <block id="118ea730c6c794b12c6da0062216053b" category="paragraph"><block ref="118ea730c6c794b12c6da0062216053b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93e4b62efeb3d091b37047e066e45da4" category="list-text">[復元モード]ページで、[新しい場所に復元]または[別の設定]を選択します。</block>
  <block id="53ddd9505ead460715da91ab5ae479ae" category="paragraph"><block ref="53ddd9505ead460715da91ab5ae479ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faca70e3cfbddf72933acf5dcbedf4ff" category="list-text">ホストページで、VMのリストア先となるターゲットESXiホストまたはクラスタを選択します。</block>
  <block id="5c468616bb48a8d3a72e2b3f20932126" category="paragraph"><block ref="5c468616bb48a8d3a72e2b3f20932126" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ee5d8dddaf8720bc49f23dc8e19f11b" category="list-text">Datastores（データストア）ページで、構成ファイルとハードディスクの両方のターゲットデータストアの場所を選択します。</block>
  <block id="ae5ebb3a87f25b2bf09c963a4029e53a" category="paragraph"><block ref="ae5ebb3a87f25b2bf09c963a4029e53a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48d9c25678124f335015d969c2c7645f" category="list-text">[ネットワーク]ページで、VM上の元のネットワークを新しいターゲットの場所にあるネットワークにマッピングします。</block>
  <block id="b33233fb74ffe76bde21729b21fde02d" category="paragraph"><block ref="b33233fb74ffe76bde21729b21fde02d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3d7fc3c9f85e5663d3361a9e999487c" category="paragraph"><block ref="b3d7fc3c9f85e5663d3361a9e999487c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511bf18240f9f57b5658a22974a640f0" category="list-text">復元されたVMをスキャンしてマルウェアを検出するかどうかを選択し、概要ページを確認してから、完了をクリックして復元を開始します。</block>
  <block id="0e966aefc6e57da3e61d08eb83f8f9b7" category="summary">SnapCenter では、長期のアーカイブと保持を目的として、プライマリストレージシステム（primary &gt; mirror）およびセカンダリストレージシステム（primary &gt; vault）内のSnapMirror関係を更新できます。そのためには、SnapMirrorを使用して、デスティネーションボリュームとソースボリューム間のデータレプリケーション関係を確立して初期化する必要があります。</block>
  <block id="860d1fc24372044f6c88f15cea6b9155" category="doc">SnapMirror関係と保持スケジュールを設定</block>
  <block id="1888797bfba812a31bad2548f183ffe6" category="paragraph">ソースとデスティネーションのONTAP システムが、Amazon VPCピアリング、トランジットゲートウェイ、AWS Direct Connect、またはAWS VPNを使用してピア関係にあるネットワークに配置されている必要があります。</block>
  <block id="aa318628cbf2869d724b704d547dc8f4" category="paragraph">オンプレミスのONTAP システムとFSX ONTAP 間にSnapMirror関係を設定するには、次の手順を実行する必要があります。</block>
  <block id="fbfcc1aa520560c558b69fb448e3e601" category="inline-link">FSX for ONTAP –ONTAP ユーザーガイド</block>
  <block id="7ffc7a254a972aeb4df657be8d41c5a2" category="paragraph">を参照してください<block ref="67cdb2cad717abb12c965d934ae13809" category="inline-link-rx"></block> FSXを使用したSnapMirror関係の作成の詳細については、を参照してください。</block>
  <block id="cc9e567b33c3e82ac1b18f4780ca5f42" category="section-title">ソースとデスティネーションのクラスタ間論理インターフェイスを記録します</block>
  <block id="44c719fef7654c0f1aecbd77f14b9ab7" category="paragraph">オンプレミスにあるソースONTAP システムの場合、クラスタ間LIFの情報をSystem ManagerまたはCLIから取得できます。</block>
  <block id="d3983f090ac28583ca4499e720c4cc25" category="list-text">ONTAP System Managerで、ネットワークの概要ページに移動し、タイプ：クラスタ間のIPアドレスを取得します。このIPアドレスは、FSXがインストールされているAWS VPCと通信するように設定されています。</block>
  <block id="de45ac288e78c12d34318717ae7cacd8" category="paragraph"><block ref="de45ac288e78c12d34318717ae7cacd8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94cf5d813faccf347c0faaab27941922" category="list-text">FSXのクラスタ間IPアドレスを取得するには、CLIにログインして次のコマンドを実行します。</block>
  <block id="244c638485f1bcb26a0e966bd289e4a9" category="paragraph"><block ref="244c638485f1bcb26a0e966bd289e4a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce2dabb10080d128fabb2edc80a417a" category="section-title">ONTAP とFSXの間にクラスタピアリングを確立します</block>
  <block id="84c8209b0c6f3e5e18c66f9f45cf5358" category="paragraph">ONTAP クラスタ間のクラスタピアリングを確立するには、開始側のONTAP クラスタで入力した一意のパスフレーズを、もう一方のピアクラスタで確認する必要があります。</block>
  <block id="085f57325580b1a203343baf39c910d1" category="list-text">デスティネーションFSXクラスタ上で' cluster peer createコマンドを使用してピアリングを設定しますプロンプトが表示されたら、あとでソースクラスタで使用する一意のパスフレーズを入力して作成プロセスを完了します。</block>
  <block id="475947ec353590c018e5b0d813538a84" category="list-text">ソースクラスタでは、ONTAP System ManagerまたはCLIを使用してクラスタピア関係を確立できます。ONTAP System Managerで、Protection &gt; Overviewの順に選択し、Peer Clusterを選択します。</block>
  <block id="692ee36299ec8b049d7462a75dd1463a" category="paragraph"><block ref="692ee36299ec8b049d7462a75dd1463a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa5f33eeccc2dab1c1b6aba564ec238" category="list-text">Peer Cluster（ピアクラスタ）ダイアログボックスで、必要な情報を入力します。</block>
  <block id="28b3f47a49c9a2fb506879e23a7b1723" category="list-text">デスティネーションFSXクラスタでピアクラスタ関係を確立するために使用したパスフレーズを入力します。</block>
  <block id="157bacc8ed48f5dc430560300ef9f5a5" category="list-text">[はい]を選択して'暗号化された関係を確立します</block>
  <block id="70c324b6369e6cb6f4a8df99ac8b4b7e" category="list-text">デスティネーションFSXクラスタのクラスタ間LIFのIPアドレスを入力します。</block>
  <block id="c9af913b694e4e4dcce39b7e3a2eabd2" category="list-text">クラスタピアリングの開始をクリックしてプロセスを完了します。</block>
  <block id="409a2deb1ca3f5fe6ad3f90977529965" category="paragraph"><block ref="409a2deb1ca3f5fe6ad3f90977529965" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b39da3667dd0f4cab32a9027eeadf60" category="list-text">次のコマンドを使用して、FSXクラスタからクラスタピア関係のステータスを確認します。</block>
  <block id="25ca322582650fd7d3732bea77176905" category="paragraph"><block ref="25ca322582650fd7d3732bea77176905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdf4cefe90737a4248cd083c1a1d2e36" category="section-title">SVMピア関係を確立する</block>
  <block id="4f194687804b9dff8219b58d47dc2a69" category="paragraph">次の手順では、SnapMirror関係にあるボリュームを含むデスティネーションとソースのStorage Virtual Machineの間にSVM関係をセットアップします。</block>
  <block id="9bd0b716a7c6f7821d01f58d3576978d" category="list-text">ソースFSXクラスタから、CLIから次のコマンドを使用して、SVMピア関係を作成します。</block>
  <block id="1a82405201cf3be5b0f3f96ffb551406" category="list-text">ソースONTAP クラスタで、ONTAP System ManagerまたはCLIのいずれかを使用してピアリング関係を承認します。</block>
  <block id="dd0f7f7da0626cbd138836fd072f65de" category="list-text">ONTAP System Managerで、保護&gt;概要に移動し、Storage VMピアの下にあるピアStorage VMを選択します。</block>
  <block id="486b508476b1f8dff9a5314ac26e36e9" category="paragraph"><block ref="486b508476b1f8dff9a5314ac26e36e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8b0c3d15e3f1c8ecebfa725f753f98e7" category="list-text">Peer Storage VMダイアログボックスで、次のフィールドに入力します。</block>
  <block id="b980118a5ade1402e409e2354f286c60" category="list-text">ソースStorage VM</block>
  <block id="2cb119a467d09216231bdf2ff83bfb5f" category="list-text">デスティネーションクラスタ</block>
  <block id="1d1fa3ffdce0bd1d4a0faf3d15fb94f6" category="list-text">デスティネーションStorage VM</block>
  <block id="22a926c9631a59bce535d179c6f1f5ae" category="paragraph"><block ref="22a926c9631a59bce535d179c6f1f5ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52fee5b72c266bcf84963c260c8cf2ed" category="list-text">[Peer Storage VMs]をクリックして、SVMピアリングプロセスを完了します。</block>
  <block id="332a29af91768111608bcb6bf43107e7" category="section-title">Snapshot保持ポリシーを作成します</block>
  <block id="b2659ce2591907c1c9269d82e68d8109" category="paragraph">SnapCenter は、プライマリストレージシステムにSnapshotコピーとして存在するバックアップの保持スケジュールを管理します。これは、SnapCenter でポリシーを作成するときに確立されます。SnapCenter では、セカンダリストレージシステムに保持されるバックアップの保持ポリシーは管理されません。これらのポリシーは、セカンダリFSXクラスタで作成されたSnapMirrorポリシーを使用して個別に管理され、ソースボリュームとSnapMirror関係にあるデスティネーションボリュームに関連付けられます。</block>
  <block id="1d64d8f27569c9f8182a6c536add0069" category="paragraph">SnapCenter ポリシーを作成するときに、SnapCenter バックアップの作成時に生成される各SnapshotのSnapMirrorラベルに追加するセカンダリポリシーラベルを指定できます。</block>
  <block id="b3ca63efc1d304947f75061071da604c" category="admonition">セカンダリストレージでは、Snapshotを保持するために、これらのラベルがデスティネーションボリュームに関連付けられたポリシールールと照合されます。</block>
  <block id="422f63101989fe9b50c840c82bb5fe9f" category="paragraph">次の例は、SQL Serverデータベースおよびログボリュームの日次バックアップに使用するポリシーの一部として生成されたすべてのSnapshotに適用されるSnapMirrorラベルを示しています。</block>
  <block id="5f70d8aa597c91ed28f7be347e2fac0a" category="paragraph"><block ref="5f70d8aa597c91ed28f7be347e2fac0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5c9b73d439aa92ef011ebf02237c888" category="inline-link">SnapCenter のドキュメント</block>
  <block id="2d0828fbc32c49aad5149bd71dd05ddf" category="paragraph">SQL ServerデータベースのSnapCenter ポリシーの作成の詳細については、を参照してください<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>。</block>
  <block id="f508c027fda31d58c4677043e1a3eaa8" category="paragraph">まず、保持するSnapshotコピーの数にルールを指定してSnapMirrorポリシーを作成する必要があります。</block>
  <block id="bb66348f31a358d5d6f969b7ab6ee82c" category="list-text">FSXクラスタ上にSnapMirrorポリシーを作成します。</block>
  <block id="e8d5c5ace79f3b8be2db75ba7135e0a8" category="list-text">SnapCenter ポリシーで指定されたセカンダリポリシーラベルと一致するSnapMirrorラベルを持つルールをポリシーに追加します。</block>
  <block id="5a3507b9cf4dd4a569d2ffe314e6b7eb" category="paragraph">次のスクリプトは、ポリシーに追加できるルールの例を示しています。</block>
  <block id="762402f82600698541f18b3a2f4ac8f4" category="admonition">SnapMirrorラベルごとに追加のルールを作成し、保持するSnapshotの数（保持期間）を指定します。</block>
  <block id="2f061612da9689d76bf56673168e2297" category="section-title">デスティネーションボリュームを作成</block>
  <block id="3c09a07bfb806c844317f3b57d93a884" category="paragraph">ソースボリュームからSnapshotコピーの受信者となるデスティネーションボリュームをFSX上に作成するには、FSX ONTAP 上で次のコマンドを実行します。</block>
  <block id="9a9f4d5cf2f4ccad396091e224e45c7e" category="section-title">ソースボリュームとデスティネーションボリューム間にSnapMirror関係を作成します</block>
  <block id="dfceac14afc666c56290006c22ba8a0a" category="paragraph">ソースボリュームとデスティネーションボリューム間のSnapMirror関係を作成するには、FSX ONTAP で次のコマンドを実行します。</block>
  <block id="e3a7ebd416df655cee455d58e86e8477" category="section-title">SnapMirror関係を初期化</block>
  <block id="a457a30bf4ecea53998aa344bee4329a" category="paragraph">SnapMirror関係を初期化このプロセスにより、ソースボリュームから生成された新しいSnapshotが開始され、デスティネーションボリュームにコピーされます。</block>
  <block id="2cd2d537da5641f8e4fc5712872944c4" category="paragraph">ボリュームを作成するには、FSX ONTAP で次のコマンドを実行します。</block>
  <block id="dcbabf28828ef9b03cf9856a74eedf64" category="summary">この解決策 では、SnapCenter は、SQL ServerおよびOracleアプリケーションデータ用に、アプリケーションと整合性のあるSnapshotを提供します。この構成とSnapMirrorテクノロジを組み合わせることで、オンプレミスのAFF とFSX ONTAP クラスタ間で高速なデータレプリケーションを実現できます。また、Veeam Backup &amp; Replicationは、仮想マシンのバックアップとリストア機能も提供します。</block>
  <block id="a7b22ebf343cad0f97e90df47a7d7f0c" category="paragraph">ここでは、バックアップとリストアの両方について、SnapCenter 、SnapMirror、およびVeeamの構成について説明します。</block>
  <block id="66b3c7123c5d46e3d176f20cb0ede484" category="paragraph">次のセクションでは、セカンダリサイトでフェイルオーバーを完了するために必要な設定と手順について説明します。</block>
  <block id="b33c39866fb3627a46e2d343e5fcdb1a" category="list-text">Windows SnapCenter サーバをオンプレミスに導入して設定</block>
  <block id="498fdd311192093265ba745435fc1476" category="doc">Veeam Backup Serverを導入して設定します</block>
  <block id="48e37aaf43e2a1010e9e267340ce923e" category="inline-link">Veeamヘルプセンターのテクニカルドキュメント</block>
  <block id="9e67d6bed8c55a98c2cfe02531c07393" category="paragraph">Veeam Backup &amp; Replicationソフトウェアは、解決策 で、アプリケーション仮想マシンのバックアップと、Veeamスケールアウトバックアップリポジトリ（SOBR）を使用したAmazon S3バケットへのバックアップのコピーのアーカイブを行うために使用します。Veeamは、この解決策 内のWindowsサーバに導入されます。Veeamの導入に関する具体的なガイダンスについては、を参照してください<block ref="43bd82bcfa6fc650951eb1c3021cf923" category="inline-link-rx"></block>。</block>
  <block id="a2af8a9311b9c3a74f6418a81bb700d2" category="section-title">Veeamスケールアウトバックアップリポジトリを設定</block>
  <block id="b61099b9ef1858547775741cc632226a" category="paragraph">ソフトウェアを導入してライセンスを設定したら、バックアップジョブのターゲットストレージとしてスケールアウトバックアップリポジトリ（SOBR）を作成できます。また、ディザスタリカバリ用にVMデータのバックアップ用にS3バケットをオフサイトに配置することも必要です。</block>
  <block id="b2fe763ad14c7947f74a8693fa06bf2b" category="paragraph">作業を開始する前に、次の前提条件を確認してください。</block>
  <block id="e787194bd6ef5154135951b4ab7f0317" category="list-text">バックアップのターゲットストレージとして、オンプレミスのONTAP システム上にSMBファイル共有を作成します。</block>
  <block id="1c2ed63d64d034cdd6fe30f769495f52" category="list-text">SOBRに含めるAmazon S3バケットを作成します。これは、オフサイトバックアップ用のリポジトリです。</block>
  <block id="e349d3884df12b302e0d564f4cf3dec4" category="section-title">VeeamにONTAP ストレージを追加します</block>
  <block id="3f71ccdf6fe8797ee5930ef4b5a0eaf1" category="paragraph">まず、ONTAP ストレージクラスタと関連するSMB / NFSファイルシステムをストレージインフラとしてVeeamに追加します。</block>
  <block id="dc14600d8d3627181cbe1757142b1c03" category="list-text">Veeamコンソールを開き、ログインします。ストレージインフラに移動し、ストレージの追加を選択します。</block>
  <block id="a55b866e82b1226d8874e7d53e6e50a9" category="paragraph"><block ref="a55b866e82b1226d8874e7d53e6e50a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5bb1dc14738b469545970cd32668931f" category="list-text">ストレージの追加ウィザードで、ストレージベンダーとしてネットアップを選択し、Data ONTAP を選択します。</block>
  <block id="391d2bf94e1387196a435da4f4f0af41" category="list-text">管理IPアドレスを入力し、NASファイラーボックスをオンにします。次へをクリックします。</block>
  <block id="a8485af4e188b4009412f68ce18de31a" category="paragraph"><block ref="a8485af4e188b4009412f68ce18de31a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fab62b3f01af99a63f513f81f07f4c93" category="list-text">ONTAP クラスタにアクセスするためのクレデンシャルを追加してください。</block>
  <block id="5e9ee6438a10072376c31e6014cef8c3" category="paragraph"><block ref="5e9ee6438a10072376c31e6014cef8c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f55d6a23cbf126acc9c5ca42a97be0fc" category="list-text">NASファイラーページで、スキャンするプロトコルを選択し、次へを選択します。</block>
  <block id="596ee09f3551be34368ba19aa36584cd" category="paragraph"><block ref="596ee09f3551be34368ba19aa36584cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="674fb2409a1f0a9e628bebcb470960cf" category="list-text">ウィザードのApplyページとSummaryページを設定し、Finishをクリックしてストレージ検出プロセスを開始します。スキャンが完了すると、ONTAP クラスタがNASファイラーとともに使用可能なリソースとして追加されます。</block>
  <block id="dc2bb995c316bc90c4d3a169bbb877d5" category="paragraph"><block ref="dc2bb995c316bc90c4d3a169bbb877d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f9b12801eaee10c32275f4ee61916aa" category="list-text">新たに検出されたNAS共有を使用して、バックアップリポジトリを作成します。[バックアップインフラストラクチャ]で、[バックアップリポジトリ]を選択し、[リポジトリの追加]メニューアイテムをクリックします。</block>
  <block id="621999df528dc938edd5a395cf0df8f3" category="paragraph"><block ref="621999df528dc938edd5a395cf0df8f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="afc15a9e4c0cbbfa567d40414a9725a1" category="inline-link">Veeamの製品ドキュメント</block>
  <block id="218b99cee35d61ca3e9cb2d068673d9a" category="list-text">リポジトリを作成するには、[新規バックアップリポジトリ]ウィザードのすべての手順に従います。Veeamバックアップリポジトリの作成の詳細については、を参照してください<block ref="3932357efba07e37ed76091ad3c0260c" category="inline-link-rx"></block>。</block>
  <block id="b56272bcb8aa2b6cb2998d01ed46d1f8" category="paragraph"><block ref="b56272bcb8aa2b6cb2998d01ed46d1f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fdf6cc44242ceed0927b180d30e5e75" category="section-title">Amazon S3バケットをバックアップリポジトリとして追加します</block>
  <block id="8c5c80325137d0f76fbe191272748ba6" category="paragraph">次の手順では、Amazon S3ストレージをバックアップリポジトリとして追加します。</block>
  <block id="6a1ed885510bb28a64f66f0870fbaa39" category="list-text">[バックアップインフラストラクチャ]&gt;[バックアップリポジトリ]に移動します。[リポジトリの追加]をクリックします</block>
  <block id="bf510a56b5d84298de7541e645b836b7" category="paragraph"><block ref="bf510a56b5d84298de7541e645b836b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021391ea3955cab71330e7a32f03333f" category="list-text">バックアップリポジトリの追加ウィザードで、オブジェクトストレージ、Amazon S3の順に選択します。これにより、新規オブジェクトストレージリポジトリウィザードが起動します。</block>
  <block id="c1f1ad1062498b5eeb9d31293b71343c" category="paragraph"><block ref="c1f1ad1062498b5eeb9d31293b71343c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3a3eb593a619e4becab9e45b8f46652" category="list-text">オブジェクトストレージリポジトリの名前を入力し、次へをクリックします。</block>
  <block id="97f3c4606f2c2ebb0ffadd0616b76446" category="list-text">次のセクションで、クレデンシャルを入力します。AWSのアクセスキーとシークレットキーが必要です。</block>
  <block id="e561e4c61aaefae45d0344b4ce87f23b" category="paragraph"><block ref="e561e4c61aaefae45d0344b4ce87f23b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157669cd4d5a68c9ab9f3537a9e0ea33" category="list-text">Amazon設定がロードされたら、データセンター、バケット、およびフォルダを選択し、適用をクリックします。最後に、[完了]をクリックしてウィザードを終了します。</block>
  <block id="2e9f45d4556ef13d4724b6f93eea5fd3" category="section-title">スケールアウトバックアップリポジトリの作成</block>
  <block id="7d8f14e05d872984577255cdeb1f14ec" category="paragraph">これでVeeamにストレージリポジトリを追加したので、SOBRを作成して、ディザスタリカバリ用にオフサイトのAmazon S3オブジェクトストレージにバックアップコピーを自動的に階層化できます。</block>
  <block id="328e03460d532c3507b2a6ba6ce53438" category="list-text">[バックアップインフラストラクチャ]で、[スケールアウトリポジトリ]を選択し、[スケールアウトリポジトリの追加]メニューアイテムをクリックします。</block>
  <block id="3ffac3b915968cb75860eac6dcb2255b" category="paragraph"><block ref="3ffac3b915968cb75860eac6dcb2255b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="582671a9090106ace80b09bb160558c6" category="list-text">[新しいスケールアウトバックアップリポジトリ]で'SOBRの名前を指定し'[次へ]をクリックします</block>
  <block id="8f7df3cc6ed6758328582e4972dcb532" category="list-text">階層のパフォーマンスについて、ローカルのONTAP クラスタにあるSMB共有を含むバックアップリポジトリを選択します。</block>
  <block id="2c4b66b86991d603fc9db639a47179f8" category="paragraph"><block ref="2c4b66b86991d603fc9db639a47179f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7362749638566881b7b5f8fe545c64e8" category="list-text">配置ポリシーで、要件に基づいて[データの局所性]または[パフォーマンス]を選択します。[次へ]を選択し</block>
  <block id="2d1b39bdffbca5df6978176960bb0148" category="list-text">大容量階層の場合は、SOBRとAmazon S3オブジェクトストレージを拡張します。ディザスタリカバリのために、セカンダリバックアップをタイムリーに提供できるように、バックアップを作成したらすぐにオブジェクトストレージにコピーするを選択します。</block>
  <block id="3a54badf400b7e061484dbadf3a19b19" category="paragraph"><block ref="3a54badf400b7e061484dbadf3a19b19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="248e4221544eda567f1dd23b587cec68" category="list-text">最後に、[適用（Apply）]と[完了（Finish）]を選択してSOBRの作成を確定する。</block>
  <block id="97f8173a9f8ac774dbbb04ad209a46ee" category="section-title">スケールアウトバックアップリポジトリジョブを作成</block>
  <block id="d7b3c8996a5cc044c6c1221d000a9d9b" category="inline-link">Veeam Help Centerテクニカルドキュメント</block>
  <block id="2b6483678eaaf63094c195aa8a37e401" category="paragraph">Veeamを設定する最後の手順は、新しく作成したバックアップ先のSOBRを使用してバックアップジョブを作成することです。バックアップジョブの作成は、ストレージ管理者の作業内容に含まれる通常の作業であり、ここでは詳細な手順については説明しません。Veeamでのバックアップジョブの作成の詳細については、を参照してください<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>。</block>
  <block id="3bd61e230841633b4a28f6d2f882d50e" category="summary">大規模な障害が発生した場合にビジネスクリティカルなアプリケーションを迅速にリストアできるようにするには、実績のあるディザスタリカバリ（DR）環境と計画が不可欠です。この解決策 では、オンプレミスとVMware Cloud on AWSの両方で、VMwareとネットアップのテクノロジを中心にDRのユースケースを紹介します。</block>
  <block id="1ae55e7a3caf44baf5721cdf304e676d" category="doc">TR-4931：『Disaster Recovery with VMware Cloud on Amazon Web Services and Guest Connect』</block>
  <block id="5f3d0127b9424be374b1c1474deb2684" category="paragraph">ネットアップはVMwareとの長年の統合を実現してきました。これは、仮想環境のストレージパートナーとしてネットアップを選んだ何万ものお客様から証明されています。この統合は、クラウドのゲスト接続オプションのほか、NFSデータストアとの最近の統合とも連動します。この解決策 では、一般にゲスト接続ストレージと呼ばれるユースケースを取り上げます。</block>
  <block id="1134d985d8893464bee3d37e02a36402" category="paragraph">ゲスト接続ストレージでは、ゲストVMDKはVMwareでプロビジョニングされたデータストアに導入され、アプリケーションデータはiSCSIまたはNFSに格納されてVMに直接マッピングされます。次の図に示すように、OracleおよびMS SQLアプリケーションを使用してDRシナリオを検証します。</block>
  <block id="50dd1256f4cf87b2fa70e300ade578e4" category="paragraph"><block ref="50dd1256f4cf87b2fa70e300ade578e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9a05fe4fa63215c3d368883b85e9312" category="summary">この解決策 では、NetApp SnapCenter を使用して、アプリケーションと整合性のあるSQL Serverデータベースのバックアップを作成します。仮想マシンのVMDKをバックアップするVeeam Backup &amp; Replicationと併用することで、オンプレミスのデータセンターとクラウドベースのデータセンター向けに包括的なディザスタリカバリ解決策 を実現できます。</block>
  <block id="d312952f462ee1dc88347d6060c708da" category="section-title">Windows SnapCenter Serverをオンプレミスに導入</block>
  <block id="989d04f01dc04fe21c2b542b83a45a6b" category="inline-link">ネットアップドキュメントセンター</block>
  <block id="5d15da138c85d083e6e6409b418b8411" category="paragraph">SnapCenter ソフトウェアはネットアップサポートサイトから入手でき、ドメインまたはワークグループ内にあるMicrosoft Windowsシステムにインストールできます。詳細な計画ガイドとインストール手順については、を参照してください<block ref="c18608d8aa7f8cbafcf1d09b2fb01df0" category="inline-link-rx"></block>。</block>
  <block id="e6220e7462e6d815945c93dcd734235f" category="paragraph">SnapCenter ソフトウェアは、から入手できます<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>。</block>
  <block id="d2476cc18d417aa498cc7c32f99e980b" category="paragraph">インストール後、\\ https://Virtual_Cluster_IP_or_FQDN:8146_を使用してWebブラウザからSnapCenter コンソールにアクセスできます。</block>
  <block id="63b96bb46045042b50fd68d9b5a0f0ba" category="section-title">SnapCenter にストレージコントローラを追加</block>
  <block id="8956d4de491225a4e6515ba0ad92fb30" category="paragraph">SnapCenter にストレージコントローラを追加するには、次の手順を実行します。</block>
  <block id="2ba7db7e99ccd03f69c81ce1f25330e6" category="list-text">左側のメニューから、ストレージシステムを選択し、新規をクリックして、ストレージコントローラをSnapCenter に追加するプロセスを開始します。</block>
  <block id="f1d609f44050cd3b443f66e474c3b93c" category="paragraph"><block ref="f1d609f44050cd3b443f66e474c3b93c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48806d1941dc50dadf8bcd5d590511ab" category="list-text">Add Storage System（ストレージシステムの追加）ダイアログボックスで、ローカルのオンプレミスONTAP クラスタの管理IPアドレス、およびユーザ名とパスワードを追加します。Submitをクリックして、ストレージ・システムの検出を開始します。</block>
  <block id="7b7a93dac3e0141a111190c64a54a220" category="paragraph"><block ref="7b7a93dac3e0141a111190c64a54a220" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc7b9fe54780f87aa8bdf884b95187c5" category="list-text">FSX ONTAP システムをSnapCenter に追加するには、この手順を繰り返します。この場合、Add Storage Systemウィンドウの下部にあるMore Optionsを選択し、Secondaryチェックボックスをオンにして、SnapMirrorコピーまたはプライマリバックアップスナップショットで更新されたセカンダリストレージシステムとしてFSXシステムを指定します。</block>
  <block id="4a8fedebba8d5bd8e357863942b66b79" category="paragraph"><block ref="4a8fedebba8d5bd8e357863942b66b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62104d735113c9c7e8a23cd031ca2004" category="paragraph">SnapCenter へのストレージシステムの追加に関する詳細については、のドキュメントを参照してください<block ref="05f72e618af68eda439c6d688692dcd6" category="inline-link-rx"></block>。</block>
  <block id="c81dcfed07648c407976127bb0bdbed2" category="section-title">SnapCenter にホストを追加します</block>
  <block id="e796a589329333070ad568f533b21931" category="paragraph">次の手順では、ホストアプリケーションサーバをSnapCenter に追加します。このプロセスは、SQL ServerとOracleのどちらでもほぼ同じです。</block>
  <block id="6718a4b38f7a3df604d1fd6079decaae" category="list-text">左側のメニューから、Hostsを選択し、Addをクリックして、SnapCenter にストレージコントローラを追加する処理を開始します。</block>
  <block id="4106a2178f1f526d51c57cb723e0f3ef" category="list-text">[Add Hosts]ウィンドウで、ホストタイプ、ホスト名、およびホストシステムの認証情報を追加します。プラグインタイプを選択します。SQL Serverの場合は、Microsoft WindowsとMicrosoft SQL Serverプラグインを選択します。</block>
  <block id="3eae7017924ae8e187a046e62f5c334e" category="paragraph"><block ref="3eae7017924ae8e187a046e62f5c334e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdb2b840f37deff5210ef9f13e554fd5" category="list-text">Oracleの場合は、[Add Host]ダイアログボックスの必須フィールドに入力し、Oracle Databaseプラグインのチェックボックスをオンにします。次に、Submitをクリックして検出プロセスを開始し、ホストをSnapCenter に追加します。</block>
  <block id="6430fb639e6454a8e47d23925ec8f583" category="paragraph"><block ref="6430fb639e6454a8e47d23925ec8f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7da39703d1c501afafc02c06d1c31788" category="section-title">SnapCenter ポリシーを作成する</block>
  <block id="fa5cc6d015db1929ddc02765f2003a33" category="paragraph">ポリシーを使用すると、バックアップジョブで使用する特定のルールを設定できます。バックアップスケジュール、レプリケーションタイプ、SnapCenter によるトランザクションログのバックアップと切り捨ての処理方法などが含まれますが、これらに限定されません。</block>
  <block id="817a33901829b57a630a499c24b4daf2" category="paragraph">ポリシーには、SnapCenter Webクライアントの設定セクションからアクセスできます。</block>
  <block id="6ddda0770a816978059cd0702e0223d0" category="paragraph"><block ref="6ddda0770a816978059cd0702e0223d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9d91360f1fd4ad1abf6c445ec8ff103" category="paragraph">SQL Serverバックアップのポリシー作成の詳細については、を参照してください<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>。</block>
  <block id="f079afadb233d404e335685a7b58c70e" category="paragraph">Oracleバックアップのポリシー作成の詳細については、を参照してください<block ref="be1c60aeb8bf91be9c4096428152eedc" category="inline-link-rx"></block>。</block>
  <block id="5847f474084786fc8a16763856c1b0da" category="list-text">ポリシー作成ウィザードの進行中は、Replicationセクションに特別な注意をしてください。このセクションでは、バックアッププロセスで作成するセカンダリSnapMirrorコピーのタイプを指定します。</block>
  <block id="fc3c693a9b60faa4913d47e755b4cf34" category="list-text">「ローカルSnapshotコピー作成後にSnapMirrorを更新」設定とは、同じクラスタ上にある2台のSVM間にSnapMirror関係が存在する場合に、この関係を更新することを指します。</block>
  <block id="77bf66c8cee4cd2482095210be78e13a" category="list-text">「ローカルSnapshotコピーの作成後にSnapVault を更新」設定は、2つの別々のクラスタ間、およびオンプレミスのONTAP システムとCloud Volumes ONTAP またはFSxNとの間に存在するSnapMirror関係を更新する場合に使用します。</block>
  <block id="824aec6074385910e619ac91969c68a3" category="paragraph">次の図は、この手順を示しており、バックアップポリシーウィザードでどのように表示されるかを示しています。</block>
  <block id="89bace67b9ee8f5a253e88d282ceb63d" category="paragraph"><block ref="89bace67b9ee8f5a253e88d282ceb63d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6bd8190e5c79ad5d86289d596dd8c16" category="section-title">SnapCenter リソースグループを作成します</block>
  <block id="2f15c296209e980cccf829b7e5c1bbca" category="paragraph">リソースグループを使用すると、バックアップに含めるデータベースリソースを選択できます。ポリシーは各リソースに適用されます。</block>
  <block id="e96fdebed13bd03c9e88f6cff2b7ed67" category="list-text">左側のメニューの[Resources]セクションに移動します。</block>
  <block id="8b5265ba89102ff3a5fd8b504ba85140" category="list-text">ウィンドウの上部で、使用するリソースタイプ（この場合はMicrosoft SQL Server）を選択し、[新しいリソースグループ]をクリックします。</block>
  <block id="695c07b026f6602eff292288473cdc42" category="paragraph"><block ref="695c07b026f6602eff292288473cdc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bad635c8aa26c147bd68eb7b700cabbe" category="paragraph">SnapCenter のドキュメントでは、SQL ServerデータベースとOracleデータベースの両方について、リソースグループを作成する手順を詳しく説明しています。</block>
  <block id="6f9886092f343d1ecc5b676f4ca381c7" category="paragraph">SQLリソースのバックアップについては、を参照してください<block ref="d0500a8d119256a2ca6775a9357c88fa" category="inline-link-rx"></block>。</block>
  <block id="ffbeca6b667809b446c63465c7ff671f" category="paragraph">Oracleリソースのバックアップについては、を参照してください<block ref="c6b13e1956473c7b22893d8b12c1b8be" category="inline-link-rx"></block>。</block>
  <block id="601c3055944b06a3d06d7da4128af752" category="summary">アプリケーションVMとデータベースボリュームをAWSで実行されているVMware Cloud Volumeサービスにフェイルオーバーするには、SnapCenter サーバとVeeam Backup and Replication Serverの両方の実行中のインスタンスをインストールして設定する必要がありました。フェイルオーバーが完了したら、オンプレミスのデータセンターへのフェイルバックが計画されて実行されるまで、これらのツールで通常のバックアップ処理を再開するようにも設定する必要があります。</block>
  <block id="f93f90f32b570b5fbcc3458fb93a6ab2" category="doc">Cloud Backupツール</block>
  <block id="4f31ced8146865d2c2823db3f623bf36" category="section-title">バックアップツールの導入</block>
  <block id="4dad49c9583060929c06d355e24a683a" category="paragraph">SnapCenter サーバとVeeam Backup &amp; Replicationサーバは、VMware Cloud SDDCにインストールするか、VPC内のEC2インスタンスにインストールしてVMware Cloud環境にネットワーク接続できます。</block>
  <block id="f709ed2f05802131924f53cb483d0216" category="section-title">SnapCenter サーバ</block>
  <block id="257b2c5a413bf4e187ebd89c8a363827" category="inline-link-macro">ネットアップドキュメントセンター</block>
  <block id="2bd8e8f9848a7635d56bcd86b9ad4c8f" category="paragraph">SnapCenter ソフトウェアはネットアップサポートサイトから入手でき、ドメインまたはワークグループ内にあるMicrosoft Windowsシステムにインストールできます。詳細な計画ガイドとインストール手順については、を参照してください <block ref="a00f6e57d5c269a935cd1b0491cebb83" category="inline-link-macro-rx"></block>。</block>
  <block id="d099bc9c6d34500d99c2caac0e6df36c" category="paragraph">SnapCenter ソフトウェアは、から入手できます<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>。</block>
  <block id="5a8e524620f781b94c018014370aad68" category="paragraph">Veeam Backup &amp; Replicationサーバは、AWS上のVMware CloudまたはEC2インスタンス上のWindowsサーバにインストールできます。実装の詳細なガイダンスについては、を参照してください<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>。</block>
  <block id="af7bd34681425c09ae0ef24381972fb5" category="section-title">バックアップツールと設定</block>
  <block id="82634d63ab3a3344fb59974c50487bac" category="paragraph">インストールが完了したら、SnapCenter とVeeam Backup &amp; Replicationを設定し、AWS上のVMware Cloudにデータをリストアするために必要なタスクを実行する必要があります。</block>
  <block id="4b152f4bba0a5ca6345daa47736e4622" category="section-title">SnapCenter 構成</block>
  <block id="411fce4d2b732a8bfda73c4f04da246c" category="paragraph">FSX ONTAP にミラーリングされたアプリケーション・データをリストアするには'まずオンプレミスのSnapCenter データベースのフル・リストアを実行する必要がありますこのプロセスが完了すると、VMとの通信が再確立され、プライマリストレージとしてFSX ONTAP を使用してアプリケーションのバックアップを再開できるようになります。</block>
  <block id="d307f68836099290d00bdc9341ec2be7" category="inline-link-macro">セカンダリWindows SnapCenter サーバを展開します</block>
  <block id="520d23cd5df8582645ee42124b69ccae" category="paragraph">AWSに配置されているSnapCenter サーバで実行する手順の一覧については、セクションを参照してください <block ref="a29fcfa081b59708af69951be417dc25" category="inline-link-macro-rx"></block>。</block>
  <block id="50d8cb6b9ada9f3e6328cb534ed5773f" category="paragraph">Amazon S3ストレージにバックアップされた仮想マシンをリストアするには、WindowsサーバにVeeamサーバをインストールし、元のバックアップリポジトリが格納されたVMware Cloud、FSX ONTAP 、およびS3バケットと通信できるように設定する必要があります。また、リストアされたVMの新しいバックアップを実行するために、FSX ONTAP に新しいバックアップリポジトリが設定されている必要があります。</block>
  <block id="845690e8aecca4f756b60cbd6c80c7f9" category="inline-link-macro">セカンダリVeeam Backup &amp; Replication Serverを導入します</block>
  <block id="82a8a7d9b8f053ce73af1c1b5b8694ff" category="paragraph">アプリケーションVMのフェイルオーバーを完了するために必要な手順については、を参照してください <block ref="83d03cb08c05a76f36dedd6b85344746" category="inline-link-macro-rx"></block>。</block>
  <block id="db4ff15d9c0c503103508af3dd860139" category="summary">NetApp AFF Aシリーズシステムは、柔軟なデータ管理オプションを備えたハイパフォーマンスなストレージインフラを提供します。クラウドに対応しているため、さまざまなエンタープライズシナリオに対応できます。この解決策 では、ONTAP AFF A300をプライマリオンプレミスストレージシステムとして使用しました。</block>
  <block id="6e5148fc476ca76eb8c330524bc1064d" category="paragraph">解決策 では、NetApp ONTAP とONTAP Tools for VMwareおよびSnapCenter を併用して、VMware vSphereと緊密に統合された包括的な管理機能およびアプリケーションバックアップ機能を提供しています。</block>
  <block id="e64f2bbe0643eeea77fa30ad5e4bdbe4" category="paragraph">仮想マシンとそのVMDKファイルをホストしているVMwareデータストアには、ONTAP ストレージを使用しました。VMwareでは、接続されたデータストアに対して複数のストレージプロトコルをサポートしています。この解決策 では、ESXiホスト上のデータストアにNFSボリュームを使用しました。ただし、ONTAP ストレージシステムは、VMwareがサポートするすべてのプロトコルをサポートしています。</block>
  <block id="ba1139b1becb929a6ba79e930297c5b7" category="paragraph">次の図は、VMwareストレージオプションを示しています。</block>
  <block id="6869f0a16b26f7047d40a5a9c5a0ccd4" category="paragraph"><block ref="6869f0a16b26f7047d40a5a9c5a0ccd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aed995b63d54f1d314ad87fc5d16b69d" category="paragraph">アプリケーションVM用に、iSCSIゲスト接続ストレージとNFSゲスト接続ストレージの両方にONTAP ボリュームを使用しました。アプリケーションデータには次のストレージプロトコルを使用しました。</block>
  <block id="c787b4233027288b06ace5dad3c0e461" category="list-text">ゲスト接続のOracleデータベースファイル用のNFSボリューム。</block>
  <block id="6a13696c6a6b506058d391582e402c83" category="list-text">ゲスト接続のMicrosoft SQL Serverデータベースおよびトランザクションログ用のiSCSI LUN。</block>
  <block id="6504ffb2b49026508f8d68a73a0893a1" category="cell">データベースタイプ</block>
  <block id="9b8bdf7379e889d83ab24e782c87d2ac" category="cell">ストレージプロトコル</block>
  <block id="0fc2cb6a177a3a14f31bd4810e09fa97" category="cell">Volume概要 の略</block>
  <block id="31f8757839909e87266f2b53482c86ef" category="cell">Windows Server 2019</block>
  <block id="e40ceeaead715c564e85bdc9b183e491" category="cell">SQL Server 2019</block>
  <block id="458648f675593beefe031e7b7ba9fcdd" category="cell">データベースファイル</block>
  <block id="81fae4ea40cc442afa43dab4cc001004" category="cell">ログファイル</block>
  <block id="ed47cdd7d93d911c4e94fc2801456784" category="cell">Oracle Linux 8.5.</block>
  <block id="e13e1c4f4700229b02ee474e7dda4ea2" category="cell">Oracle 19C</block>
  <block id="4659ac5526bf8dff13f1ec371e79b766" category="cell">Oracleバイナリ</block>
  <block id="f0a16b1024d40f006a15728ebd0e0f12" category="cell">Oracleデータ</block>
  <block id="1d9c31e9be3c01076e13f0f4fa1c15ae" category="cell">Oracleリカバリ・ファイル</block>
  <block id="26f11a15ba5f458b3d86d9ecc01b56f3" category="paragraph">また、ONTAP ストレージは、Veeamのプライマリバックアップリポジトリや、SnapCenter データベースのバックアップターゲットにも使用しました。</block>
  <block id="e8d719041d7958d85248e29684218330" category="list-text">Veeamバックアップリポジトリ用のSMB共有。</block>
  <block id="6005cf3be81f9c1a1908df0afb543b7d" category="list-text">SnapCenter データベースのバックアップ先としてのSMB共有</block>
  <block id="6872c2b6282a1ff41523f7b84a51d4da" category="section-title">クラウドストレージ</block>
  <block id="72cd2806db1eac2f04ef89c81542dd54" category="paragraph">この解決策 には、フェイルオーバープロセスの一環としてリストアされた仮想マシンをホストするためのVMware Cloud on AWSが含まれています。本書の執筆時点では、VMwareはVMおよびVMDKをホストするデータストア用のVSANストレージをサポートしています。</block>
  <block id="501c11094fdd604514f321bced51fe82" category="paragraph">FSX for ONTAP は、SnapCenter およびSyncMirror を使用してミラーリングされるアプリケーションデータのセカンダリストレージとして使用されます。フェイルオーバー・プロセスの一環として'FSX for ONTAP クラスタはプライマリ・ストレージに変換され'データベース・アプリケーションはFSXストレージ・クラスタ上で実行される通常の機能を再開できます</block>
  <block id="2872e9fbf25a6695761c355a5170f21f" category="section-title">NetApp ONTAP セットアップ用のAmazon FSX</block>
  <block id="81d8366c2ec35340f9822e490b614b41" category="paragraph">Cloud Managerを使用してAWS FSX for NetApp ONTAP を導入するには、の手順に従います<block ref="f938a02d8e5f1cc6cb4c026bb367a9b5" category="inline-link-rx"></block>。</block>
  <block id="e48c9f83aba7e50a34062296356c11da" category="paragraph">FSX ONTAP を導入したら、オンプレミスのONTAP インスタンスをFSX ONTAP にドラッグアンドドロップして、ボリュームのレプリケーションセットアップを開始します。</block>
  <block id="bfeecfa1e5aafaba3386ba09221608e3" category="paragraph">次の図は、FSX ONTAP 環境を示しています。</block>
  <block id="f0eabf6ad2404299416504a68c18c70b" category="paragraph"><block ref="f0eabf6ad2404299416504a68c18c70b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46fabc81c23066d3f0ef74556fc23d0d" category="section-title">ネットワークインタフェースが作成されました</block>
  <block id="cf36149275607710e0655ce5a52d4745" category="paragraph">NetApp ONTAP のFSXには、ネットワークインターフェイスが事前に設定されており、iSCSI、NFS、SMB、およびクラスタ間ネットワークに使用できる状態になっています。</block>
  <block id="a23141775a4b1f964c8a4c1335d366c7" category="section-title">VMデータストアストレージ</block>
  <block id="60d2a0c028f1fc1db964ff9d52cfe139" category="paragraph">VMware Cloud SDDCには、「vsandatastore」および「workloaddatastore」という名前の2つのVSANデータストアが付属しています。Cloudadmin認証情報へのアクセスが制限された管理VMをホストするには、「vsandatastore」を使用しました。ワークロードには'workloaddatastore.'を使用しました</block>
  <block id="d4fab32948320ef14f4b14bb30559cd4" category="summary">この解決策 では、ネットアップのSyncMirror 処理を実行するために、オンプレミスのONTAP クラスタからAWS FSXへのネットアップONTAP インターコネクトクラスタのネットワークアドレス間の通信が正常に行われている必要があります。また、VeeamバックアップサーバからAWS S3バケットにアクセスできる必要があります。インターネット転送を使用する代わりに、既存のVPNまたはDirect ConnectリンクをS3バケットへのプライベートリンクとして使用できます。</block>
  <block id="c850af3ffbdd92ab67281dbdfeaf4e52" category="paragraph">ONTAP は、SAN環境向けのiSCSI、Fibre Channel（FC）、Fibre Channel over Ethernet（FCoE）、Non-Volatile Memory Express over Fibre Channel（NVMe/FC）など、仮想化に使用される主要なストレージプロトコルをすべてサポートしています。ONTAP は、ゲスト接続用にNFS（v3およびv4.1）とSMBまたはS3もサポートしています。環境に最も適したものを自由に選択でき、必要に応じてプロトコルを1つのシステムで組み合わせることができます。たとえば、いくつかのiSCSI LUNまたはゲスト共有でNFSデータストアの一般的な使用を補うことができます。</block>
  <block id="dc8286bc14e4eca04d5c8c3d3745e742" category="paragraph">この解決策 は、ゲストVMDK用にオンプレミスのデータストアにNFSデータストアを利用し、ゲストアプリケーションデータ用にiSCSIとNFSの両方を利用します。</block>
  <block id="89cf31d317f3100637041ccf296c3421" category="section-title">クライアントネットワーク</block>
  <block id="d6c8c82593995a45499a762d317c04ec" category="paragraph">VMkernelネットワークポートとSoftware-Definedネットワークは、ESXiホストとの接続を提供し、VMware環境外の要素との通信を可能にします。接続は、使用するVMkernelインターフェイスのタイプによって異なります。</block>
  <block id="774cca28a02c25118dc9668598f65663" category="paragraph">この解決策 に対して、次のVMkernelインターフェイスが設定されました。</block>
  <block id="fe4dbcab9b910577e5035e97ac068dae" category="list-text">管理</block>
  <block id="31ce31cccd4aecd29ff8b40dd37b8305" category="section-title">ストレージネットワークをプロビジョニングしました</block>
  <block id="a09cf1d6ddb872a8c1ee517538a9373d" category="paragraph">LIF （論理インターフェイス）は、クラスタ内のノードへのネットワークアクセスポイントを表します。これにより、クライアントがアクセスするデータを格納するStorage Virtual Machineと通信できるようになります。LIF は、クラスタでネットワーク経由の通信の送受信に使用されるポートに設定できます。</block>
  <block id="b976c5d6eaa4fa1f606cff663f77835f" category="paragraph">この解決策 では、次のストレージプロトコル用にLIFが設定されます。</block>
  <block id="cfba851bf46ae36ca092575bba6c7289" category="section-title">クラウド接続オプション</block>
  <block id="466c519a74055fba20814454ab577c83" category="paragraph">お客様は、VPNトポロジやDirect Connectトポロジの導入など、オンプレミス環境をクラウドリソースに接続する際に多くのオプションを選択できます。</block>
  <block id="ce24b5f233dc29fc3614b2c7d961948b" category="section-title">仮想プライベートネットワーク（VPN）</block>
  <block id="55e6887f1e4e535089db85cbcae36acd" category="paragraph">VPN（バーチャルプライベートネットワーク）は、多くの場合、インターネットベースまたはプライベートMPLSネットワークを使用したセキュアなIPSecトンネルの作成に使用されます。VPNのセットアップは簡単ですが、信頼性（インターネットベースの場合）と速度が不足しています。エンドポイントは、AWS VPCまたはVMware Cloud SDDCで終了できます。このディザスタリカバリ解決策 用に、オンプレミスネットワークからNetApp ONTAP 用のAWS FSXへの接続を作成しました。そのため、NetApp ONTAP 向けFSXが接続されているAWS VPC（Virtual Private GatewayまたはTransit Gateway）で終端できます。</block>
  <block id="365e9311cae767fae52a5cdba7003f9a" category="paragraph">VPN設定は、ルートベースまたはポリシーベースのいずれかです。ルートベースの設定では、エンドポイントは自動的にルートを交換し、セットアップは新しく作成されたサブネットへのルートを学習します。ポリシーベースの設定では、ローカルサブネットとリモートサブネットを定義する必要があります。また、新しいサブネットが追加され、IPSecトンネル内で通信が許可される場合は、ルートを更新する必要があります。</block>
  <block id="fb932a9cb1f7aff6a88af2645c80731e" category="admonition">IPSec VPNトンネルがデフォルトゲートウェイ上に作成されていない場合、リモートネットワークルートはローカルVPNトンネルエンドポイントを介してルートテーブルに定義する必要があります。</block>
  <block id="2dc9d6f2c2810edb190acfe717c84a68" category="paragraph">次の図に、一般的なVPN接続オプションを示します。</block>
  <block id="d90d767da5b6da33c2785b3d3120c23f" category="paragraph"><block ref="d90d767da5b6da33c2785b3d3120c23f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1fc9354c56b77f7143d2b6a7d185ad" category="section-title">Direct Connect（直接接続）</block>
  <block id="4aa5340761d0794e8da7cfa5ead94eb3" category="paragraph">Direct ConnectはAWSネットワークへの専用リンクを提供します。専用接続では、1Gbps、10Gbps、または100Gbpsのイーサネットポートを使用してAWSへのリンクを作成します。AWS Direct Connectパートナーは、自社とAWSの間に確立されたネットワークリンクを使用してホスト接続を提供します。この接続は50MBpsから10Gbpsまで提供されます。デフォルトでは、トラフィックは暗号化されません。ただし、MACsecまたはIPsecを使用してトラフィックを保護するためのオプションが用意されています。MACsecはレイヤ2暗号化を提供し、IPsecはレイヤ3暗号化を提供します。MACsecでは、通信するデバイスを秘匿することで、より優れたセキュリティを実現します。</block>
  <block id="f41e1aa529328c6c391ee2bbb3e7b35f" category="paragraph">お客様のルータ機器がAWS Direct Connectの場所にある。この設定を行うには、AWSパートナーネットワーク（APN）を使用します。このルータとAWSルータの間に物理的な接続が確立されます。VPC上のNetApp ONTAP のFSXへのアクセスを有効にするには、Direct ConnectからVPCへのプライベート仮想インターフェイスまたはトランジット仮想インターフェイスが必要です。プライベート仮想インターフェイスでは、VPCへのDirect Connectの拡張性に制限があります。</block>
  <block id="aac639f893699a86dc44236deb8c2ff8" category="paragraph">次の図は、Direct Connectインターフェイスオプションを示しています。</block>
  <block id="65d0f01c0d2abb5df490f85de1a3c7f5" category="paragraph"><block ref="65d0f01c0d2abb5df490f85de1a3c7f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a547cd01b7307bbc41da8aed4983dc1" category="section-title">トランジットゲートウェイ</block>
  <block id="5789b6855d128c642555ffa55396a65c" category="inline-link">AWS Direct Connectのドキュメント</block>
  <block id="3ae6c7e3aea4c72d9bf07244d7b959e6" category="paragraph">トランジットゲートウェイはリージョンレベルの構造で、リージョン内のDirect Connect-to-VPC接続のスケーラビリティを向上させることができます。クロスリージョン接続が必要な場合は、中継ゲートウェイをピアリングする必要があります。詳細については、を参照してください<block ref="9f2a100b6fab526146ca277977e4ef3a" category="inline-link-rx"></block>。</block>
  <block id="ac8979d211e20b50e94073d31f2e8d44" category="section-title">クラウドネットワークに関する考慮事項</block>
  <block id="02c5109954e68b54548d5ef777afaf76" category="paragraph">クラウドでは、基盤となるネットワークインフラはクラウドサービスプロバイダによって管理されますが、お客様はAWSでVPCネットワーク、サブネット、ルーティングテーブルなどを管理する必要があります。また、コンピューティングエッジでNSXネットワークセグメントを管理する必要があります。SDDCグループは、外部VPCとトランジット接続のルートをグループ化します。</block>
  <block id="ee94a9a0de351e37a54ce1fec2961c62" category="paragraph">VMware Cloudに接続されたVPCにFSX for NetApp ONTAP with Multi-AZ Availabilityが導入されている場合、iSCSIトラフィックは、通信を有効にするために必要なルートテーブルの更新を受信します。デフォルトでは、VMware Cloudから、接続されたVPC上のFSX ONTAP NFS/SMBサブネットへの、複数AZ環境用のルートはありません。そのルートを定義するために、VMware Cloud SDDCグループを使用しました。このグループはVMwareが管理する中継ゲートウェイであり、同じリージョン内のVMware Cloud SDDCと外部VPCおよびその他のトランジットゲートウェイとの間の通信を可能にします。</block>
  <block id="7ee08649d3bd024352f28df7dabbb32f" category="admonition">トランジットゲートウェイの使用に関連するデータ転送コストがあります。地域固有のコストの詳細については、を参照してください<block ref="b6f8eb4f405293cd9bb0c07a2ec1b299" category="inline-link-rx"></block>。</block>
  <block id="68010b6bb26779cadbf96e9d04dad537" category="paragraph">VMware Cloud SDDCは、単一のアベイラビリティゾーンに導入できます。これは、単一のデータセンターのようなものです。ストレッチクラスタオプションも使用できます。これは、可用性を高め、アベイラビリティゾーンに障害が発生した場合のダウンタイムを短縮できるNetApp MetroCluster 解決策 のようなオプションです。</block>
  <block id="0d5aa9b9832dc4c044a656ccdd139dcf" category="paragraph">データ転送コストを最小限に抑えるには、VMware Cloud SDDCとAWSのインスタンスまたはサービスを同じアベイラビリティゾーンに配置します。AWSでは、アカウントに固有のAZオーダーリストを用意して複数のアベイラビリティゾーンに負荷を分散するため、名前ではなくアベイラビリティゾーンIDと照合することを推奨します。たとえば、あるアカウント（US-East-1a）がAZ ID 1を指しているのに対し、別のアカウント（US-East-1c）がAZ ID 1を指している場合があります。アベイラビリティゾーンIDはいくつかの方法で取得できます。次の例は、VPCサブネットからAZ IDを取得します。</block>
  <block id="64c06e81643d1c8b6eba37a5343885ec" category="paragraph"><block ref="64c06e81643d1c8b6eba37a5343885ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70cd8bfb8fd7a4082087201414ab2fe4" category="inline-link">VMware のドキュメント</block>
  <block id="8920393d6c2c8771eef99f947100b883" category="paragraph">VMware Cloud SDDCでは、ネットワークはNSXで管理され、南北トラフィックのアップリンクポートを処理するエッジゲートウェイ（Tier-0ルータ）はAWS VPCに接続されます。コンピュートゲートウェイと管理ゲートウェイ（ティア1ルータ）は、イーストウェストトラフィックを処理します。エッジのアップリンクポートが頻繁に使用されるようになった場合は、トラフィックグループを作成して特定のホストIPまたはサブネットに関連付けることができます。トラフィックグループを作成すると、トラフィックを分離するためのエッジノードが追加で作成されます。を確認します<block ref="616556354bfd279ba90d5c2485799af5" category="inline-link-rx"></block> マルチエッジセットアップを使用するために必要なvSphereホストの最小数。</block>
  <block id="e064913c9382e82051f900b9564779d5" category="paragraph">VMware Cloud SDDCをプロビジョニングすると、VMkernelポートが設定済みで、使用可能な状態になります。これらのポートはVMwareで管理されるため、更新は不要です。</block>
  <block id="edbc8b71394d65a981746a0ed9072b51" category="paragraph">次の図は、ホストVMkernel情報の例を示しています。</block>
  <block id="24d3a9af73ac14dc11a2d9a4745a77b0" category="paragraph"><block ref="24d3a9af73ac14dc11a2d9a4745a77b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1315738b589a4d2de3fd82a05b2d4e19" category="section-title">ストレージネットワークのプロビジョニング（iSCSI、NFS）</block>
  <block id="1a6b4ca0fa5ca04588d2e2eac3bf0444" category="paragraph">VMゲストストレージネットワークについては、通常はポートグループを作成します。NSXを使用すると、vCenter上でポートグループとして使用されるセグメントを作成できます。ストレージネットワークはルーティング可能なサブネットにあるため、別々のネットワークセグメントを作成することなく、デフォルトのNICを使用してLUNにアクセスしたりNFSエクスポートをマウントしたりできます。ストレージトラフィックを分離するには、追加のセグメントを作成し、ルールを定義し、それらのセグメントのMTUサイズを制御します。フォールトトレランスを実現するためには、ストレージネットワーク専用のセグメントを少なくとも2つ用意することを推奨します。前述したように、アップリンク帯域幅が問題 になると、トラフィックグループを作成し、IPプレフィックスとゲートウェイを割り当てて、送信元ベースルーティングを実行できます。</block>
  <block id="87e62e5f6f235efbfc557b0177d0e112" category="paragraph">フェイルオーバー時にネットワークセグメントがマッピングされるのを推測しないように、DR SDDCのセグメントをソース環境と照合することを推奨します。</block>
  <block id="9175bb34d0aede26315b313b9432bcbb" category="section-title">セキュリティグループ</block>
  <block id="7c9ffa8d590736372f008da84037edaa" category="paragraph">多くのセキュリティオプションで、AWS VPCとVMware Cloud SDDCネットワーク上のセキュアな通信が提供されます。VMware Cloud SDDCネットワーク内では、NSXトレースフローを使用してパスを識別できます。これには、使用するルールも含まれます。その後、VPCネットワークのネットワークアナライザを使用して、フロー中に消費されるルーティングテーブル、セキュリティグループ、ネットワークアクセス制御リストなどのパスを特定できます。</block>
  <block id="bd6d688efed13ace07c5656a3de04479" category="doc">概要- AWSゲスト接続ストレージのディザスタリカバリ</block>
  <block id="67b5a180b1adfc09bd2752e51613fea5" category="paragraph">このセクションでは、ネットアップとVMwareで使用するオンプレミス環境とクラウド環境をユーザが検証、設定、検証する際に役立つ手順を説明します。この解決策 は、オンプレミスのONTAP AFF と、クラウド向けのVMware CloudおよびAWS FSX ONTAP を使用した、VMwareゲスト接続のユースケースに焦点を当てています。この解決策 は、ディザスタリカバリのシナリオでOracleとMS SQLの2つのアプリケーションを使用して実証されています。</block>
  <block id="d48ec23d0c00af2c45aa4b1c24b412d8" category="summary">プライマリオンプレミスのデータセンターで災害が発生した場合のシナリオとして、AWSでVMware Cloudを使用して、Amazon Web Servicesインフラにあるセカンダリサイトへのフェイルオーバーがあります。仮想マシンとオンプレミスのONTAP クラスタにはアクセスできなくなると仮定しています。また、SnapCenter とVeeamの仮想マシンはどちらもアクセスできなくなり、2次サイトで再構築する必要があります。</block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="doc">フェイルオーバー</block>
  <block id="03c450647cafbb7294b1d6fef9f2476f" category="section-title">災害はプライマリサイトで発生します</block>
  <block id="ff36edd2e7e49fd0a40827688d2f4d8c" category="paragraph">このセクションでは、インフラからクラウドへのフェイルオーバーについて説明します。ここでは、次のトピックについて説明します。</block>
  <block id="9555d80191893a5b671187e1a859f379" category="list-text">SnapCenter データベースのリストア：新しいSnapCenter サーバが確立されたら、MySQLデータベースと構成ファイルをリストアし、データベースをディザスタリカバリモードに切り替えて、セカンダリFSXストレージをプライマリストレージデバイスにします。</block>
  <block id="2f2ee1d320a4d17fae8f4228f0a0c17a" category="list-text">Veeam Backup &amp; Replicationを使用してアプリケーション仮想マシンをリストアします。VMバックアップを含むS3ストレージを接続し、バックアップをインポートして、AWS上のVMware Cloudにリストアします。</block>
  <block id="8509dc3cb04f91e9c6eb62971df36219" category="list-text">SnapCenter を使用してSQL Serverアプリケーションデータをリストアします。</block>
  <block id="81e920a3cfad3020139d281a7be1093a" category="list-text">SnapCenter を使用してOracleアプリケーションのデータをリストアします。</block>
  <block id="7c3080588178d0f5908a96d9e20be883" category="section-title">SnapCenter データベースのリストアプロセス</block>
  <block id="86c580a0ed766eb38c0ef43f08d425e5" category="paragraph">SnapCenter では、MySQLデータベースおよび構成ファイルのバックアップとリストアが可能なため、ディザスタリカバリのシナリオがサポートされます。これにより、管理者はSnapCenter データベースの定期的なバックアップをオンプレミスのデータセンターで保持し、そのデータベースをセカンダリSnapCenter データベースにリストアすることができます。</block>
  <block id="ee1f8cb839e16951e7004e4047603101" category="paragraph">リモートSnapCenter サーバ上のSnapCenter バックアップファイルにアクセスするには、次の手順を実行します。</block>
  <block id="0b5c65b05530328f42d8b65f68657302" category="list-text">ボリュームを読み取り/書き込み可能にするFSXクラスタからSnapMirror関係を解除します。</block>
  <block id="dbfff075901e62d26ef1f316380d01f7" category="list-text">必要に応じてCIFSサーバを作成し、クローニングされたボリュームのジャンクションパスを参照するCIFS共有を作成します。</block>
  <block id="26b0d9d510f38125c4de3a7b68569b29" category="list-text">xcopyを使用して、セカンダリSnapCenter システムのローカルディレクトリにバックアップファイルをコピーします。</block>
  <block id="fa0138f778767381d2b0af9bdabad76e" category="list-text">SnapCenter v4.6をインストールします。</block>
  <block id="736c8557bca1ad901b82efb5e946a527" category="list-text">SnapCenter サーバのFQDNが元のサーバと同じであることを確認します。これは、データベースのリストアを正常に実行するために必要です。</block>
  <block id="6f77488ce3ed6db6422cddaa1e4cbf8f" category="paragraph">リストア・プロセスを開始するには、次の手順を実行します。</block>
  <block id="7220866a3d1d3ba6c1aef39d02d64b1f" category="list-text">セカンダリSnapCenter サーバのSwagger API Webページに移動し、前述の手順に従って認証トークンを取得します。</block>
  <block id="a5214e49691510795c98aad40874caa1" category="list-text">Swaggerページの[Disaster Recovery]セクションに移動し、[0/4.6/disasterrecovery/sa/restore]を選択して、[Try it out]をクリックします。</block>
  <block id="3c235173c5db1037212eff5e3a152a26" category="paragraph"><block ref="3c235173c5db1037212eff5e3a152a26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d76d7bbb789675126fd1e9a0bf929635" category="list-text">認証トークンに貼り付けて、SmDRRestarterRequestセクションで、バックアップ名とセカンダリSnapCenter サーバのローカルディレクトリに貼り付けます。</block>
  <block id="34938ae261d31ae76af2e4369a2c8b0a" category="paragraph"><block ref="34938ae261d31ae76af2e4369a2c8b0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4579e653c0e46ed15c466f496b60b0f3" category="list-text">Executeボタンを選択して'リストア・プロセスを開始します</block>
  <block id="fcbb767c97ce18f6b82f09bf8ea9c993" category="list-text">SnapCenter で、監視セクションに移動してリストアジョブの進捗状況を確認します。</block>
  <block id="8fa0520efd67da15041467d3126133a7" category="paragraph"><block ref="8fa0520efd67da15041467d3126133a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d67615193bee26cd99be6b7ea889f065" category="paragraph"><block ref="d67615193bee26cd99be6b7ea889f065" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49b4fb23e31b4cd2d12434ce03b24134" category="list-text">セカンダリストレージからのSQL Serverのリストアを有効にするには、SnapCenter データベースをディザスタリカバリモードに切り替える必要があります。この処理は、Swagger API Webページで個別の処理として開始されます。</block>
  <block id="35afa1a915c7752e139ef7b0362596a6" category="list-text">[Disaster Recovery]セクションに移動し'[/4.6/disasterrecovery/storage]をクリックします</block>
  <block id="7633ff4043449878afbd5ca925faa5b1" category="list-text">ユーザー認証トークンに貼り付けます。</block>
  <block id="5fb3d7404a8cc43eb5e120b4e22fe16d" category="list-text">SmSetDisasterRecoverySettingsRequestセクションで'EnableDisasterRecoverを'true'に変更します</block>
  <block id="e7470af265e05d2efa8863c259541c2b" category="list-text">Executeをクリックして'SQL Serverの災害復旧モードを有効にします</block>
  <block id="8579e283f02173e29df7090294128589" category="paragraph"><block ref="8579e283f02173e29df7090294128589" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4a08ff9e7fd1ec468bc55c7ba9df45" category="admonition">追加手順に関するコメントを参照してください。</block>
  <block id="5b13229945c45439c072dc9c270e8177" category="inline-link-macro">AWS上のVMCを使用したディザスタリカバリ（ゲスト接続）</block>
  <block id="866b55fdae1463f1934c300853ecefe2" category="list-text"><block ref="866b55fdae1463f1934c300853ecefe2" category="inline-link-macro-rx"></block></block>
  <block id="38631d978812c49b6f395a78becd9750" category="summary">次のプロセスでは、オンプレミスサイトが動作不能になった場合に、VMwareクラウド サービス でAWSでOracleアプリケーションデータをリカバリする方法について説明します。</block>
  <block id="c8ae03dc8bb68d2ad3e63a9126f795e6" category="doc">Oracleアプリケーションデータをリストアします</block>
  <block id="18ed07dc9f8533a3a2cf047292765486" category="paragraph">リカバリ手順を続行するには、次の前提条件を満たしている必要があります。</block>
  <block id="d55274d1968c306eb025dc5e6eca42b4" category="list-text">Veeam Full Restoreを使用して、Oracle LinuxサーバVMがVMware Cloud SDDCにリストアされている。</block>
  <block id="66d808fa42d45f6883d1a223ee26eb0c" category="list-text">セカンダリSnapCenter サーバが確立され、このセクションで説明する手順でSnapCenter データベースおよび構成ファイルがリストアされている <block ref="f1b6dca3014749c436758b70cc0d8f7f" category="inline-link-macro-rx"></block></block>
  <block id="b723df724fefe9f2021e7bb7bd8a57d0" category="section-title">Oracleリストア用にFSXを設定する–SnapMirror関係を解除します</block>
  <block id="ab26994a6aef07f6a796a6109f921a28" category="paragraph">FSxNインスタンスでホストされているセカンダリストレージボリュームにOracleサーバからアクセスできるようにするには、まず既存のSnapMirror関係を解除する必要があります。</block>
  <block id="d80c0676712ecc3e8d717347b9a0113a" category="list-text">FSX CLIにログインした後、次のコマンドを実行して、正しい名前でフィルタリングされたボリュームを表示します。</block>
  <block id="c534b90634ff37c01e77b058859f2a29" category="paragraph"><block ref="c534b90634ff37c01e77b058859f2a29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="771b4d8e9d4a9f112068c45d013c2940" category="list-text">次のコマンドを実行して、既存のSnapMirror関係を解除します。</block>
  <block id="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="paragraph"><block ref="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a4480a103abe04e17eca64a771420a8" category="list-text">Amazon FSX Web Clientでjunction-pathを更新します。</block>
  <block id="a3848e78db2c915e6ec7913bc0779a86" category="paragraph"><block ref="a3848e78db2c915e6ec7913bc0779a86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="467332d89a649add4b0efb09dd2386c5" category="list-text">ジャンクションパス名を追加し、更新（Update）をクリックする。OracleサーバからNFSボリュームをマウントする際に、このジャンクションパスを指定します。</block>
  <block id="7a522c1cba5b4c9df88cb71a944d5efd" category="paragraph"><block ref="7a522c1cba5b4c9df88cb71a944d5efd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="974ee05a635ebfcae6d6f6aa6f5da0b9" category="section-title">Oracle ServerにNFSボリュームをマウントします</block>
  <block id="f3677efe1cf868a895b6634743ae53cd" category="paragraph">Cloud Managerでは、Oracleデータベースファイルとログを格納するNFSボリュームをマウントするための、正しいNFS LIFのIPアドレスを指定してmountコマンドを取得できます。</block>
  <block id="5ecb7cb864e3f6e77b9ae7264115942e" category="list-text">Cloud Managerで、FSXクラスタのボリュームのリストにアクセスします。</block>
  <block id="dc33973d3bef150b7e3be67c8acbde9a" category="paragraph"><block ref="dc33973d3bef150b7e3be67c8acbde9a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf957a98bd60352ec8312937f87b49dc" category="list-text">アクションメニューからマウントコマンドを選択し、Oracle Linuxサーバで使用するマウントコマンドを表示してコピーします。</block>
  <block id="42ae5bd08cec138b52386d868d92bcfe" category="paragraph"><block ref="42ae5bd08cec138b52386d868d92bcfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8026151c7c8dc5002a8652cdd0ac0610" category="paragraph"><block ref="8026151c7c8dc5002a8652cdd0ac0610" category="inline-image-macro-rx" type="image"></block></block>
  <block id="91d32453a4c3b285d62be2bc5eb3d24c" category="list-text">NFSファイルシステムをOracle Linux Serverにマウントします。NFS共有をマウントするためのディレクトリがOracle Linuxホスト上にすでに存在している。</block>
  <block id="3f7f1270061c2e231f722bfd466cec0d" category="list-text">Oracle Linuxサーバから、mountコマンドを使用してNFSボリュームをマウントします。</block>
  <block id="5cafad6c0970ad9fd32dd43eb98a7d6f" category="paragraph">Oracleデータベースに関連付けられたボリュームごとに、この手順を繰り返します。</block>
  <block id="264225a103d86a5e552aebab3ee7dd3f" category="admonition">再起動時にNFSマウントを維持するには'/etc/fstabファイルを編集してマウント・コマンドを追加します</block>
  <block id="2095b7305d1da91dff871c600b482eb9" category="list-text">Oracleサーバをリブートします。Oracleデータベースは正常に起動し、使用できるようになっている必要があります。</block>
  <block id="997d17d93cccb6709985c79ccc870db0" category="doc">ディザスタリカバリに備えたSnapCenter データベースバックアップ</block>
  <block id="9cb03f5cfb57a7f655c8a28ca64ae0d1" category="paragraph">SnapCenter を使用すると、災害発生時にSnapCenter サーバをリカバリできるように、基盤となるMySQLデータベースおよび設定データのバックアップとリカバリを行うことができます。解決策 では、VPC内のAWS EC2インスタンスでSnapCenter データベースと設定をリカバリしました。この手順の詳細については、を参照してください<block ref="85e9a4a54f289ebdfa6c4169fb097d15" category="inline-link-rx"></block>。</block>
  <block id="46137d274838eaef40c110eac160dabc" category="section-title">SnapCenter バックアップの前提条件</block>
  <block id="2fe071c4476effcd542a95a182832104" category="paragraph">SnapCenter バックアップを実行するには、次の前提条件が必要です。</block>
  <block id="be2b68df1cb3db2a8f1393a8c89a5c30" category="list-text">オンプレミスのONTAP システムに作成されたボリュームとSMB共有。バックアップされたデータベースと構成ファイルを検索します。</block>
  <block id="1a9ee88991730f920252a1445a467c77" category="list-text">オンプレミスのONTAP システムと、AWSアカウントのFSXまたはCVOとの間のSnapMirror関係。この関係は、バックアップされたSnapCenter データベースおよび構成ファイルを含むSnapshotの転送に使用されます。</block>
  <block id="3c0e70fa217603c0388de21f978923f3" category="list-text">EC2インスタンスまたはVMware Cloud SDDC内のVMに、クラウドアカウントにWindows Serverをインストールします。</block>
  <block id="328228524f87469e005c8944ad925402" category="list-text">SnapCenter は、VMware CloudのWindows EC2インスタンスまたはVMにインストールします。</block>
  <block id="0038f6b75b40b9c37893544119ad7ca4" category="section-title">SnapCenter のバックアップとリストアのプロセスの概要</block>
  <block id="f4644dc8d01e527218cd1fc0daa6af40" category="list-text">バックアップのdbファイルと構成ファイルをホストするボリュームをオンプレミスのONTAP システムに作成します。</block>
  <block id="c4232930a0fc8d0f9a5e1a16db36a816" category="list-text">オンプレミスとFSX/CVOの間にSnapMirror関係を設定</block>
  <block id="3e1461fe483fb58c7a6642074cb71d8d" category="list-text">SMB共有をマウント</block>
  <block id="dd5b017c2cafc1394e2d7ab7081652e3" category="list-text">APIタスクを実行するためのSwagger承認トークンを取得します。</block>
  <block id="51263d7f64b29b2b3bd6730068e64a27" category="list-text">dbのリストア・プロセスを開始します。</block>
  <block id="23011a36184705e18919c3e5560fd514" category="list-text">xcopyユーティリティを使用して、dbおよびconfigファイルのローカルディレクトリをSMB共有にコピーします。</block>
  <block id="b84dd176bda6a6d30c5cb8901a8bf5b1" category="list-text">FSXで、ONTAP ボリュームのクローンを作成する（オンプレミスからSnapMirror経由でコピーする）。</block>
  <block id="1a3f92b9c5623f19d294ef2907d98cc8" category="list-text">FSXからEC2/VMware CloudにSMB共有をマウントします。</block>
  <block id="87d37b3dfd2b98df04243247ebff4325" category="list-text">SMB共有からローカルディレクトリにリストアディレクトリをコピーします。</block>
  <block id="fd516b8b37d528453c538c9022d6d9db" category="list-text">SwaggerからSQL Serverのリストアプロセスを実行します。</block>
  <block id="63c6890e4065bde44f84394d274e05db" category="section-title">SnapCenter データベースと設定をバックアップします</block>
  <block id="493aa18049179f21c66cc95e36c19670" category="paragraph">SnapCenter は、REST APIコマンドを実行するためのWebクライアントインターフェイスを提供します。Swagger経由でのREST APIへのアクセスについては、SnapCenter のドキュメントを参照してください<block ref="2a9068db8cebf7672f374b2eb0a0c5ec" category="inline-link-rx"></block>。</block>
  <block id="911dd02ad9a62d89e83d996753811c7b" category="section-title">Swaggerにログインし、認証トークンを取得します</block>
  <block id="820336a66e164f408946dd8235833c07" category="paragraph">Swaggerページに移動したら、認証トークンを取得してデータベースリストアプロセスを開始する必要があります。</block>
  <block id="99899958b071bcb677dc5a5b24f1b2a3" category="list-text">SnapCenter Swagger API Webページ（\\ https://&lt;SnapCenterサーバIP &gt;：8146 /スワッガ/_）にアクセスします。</block>
  <block id="20f069ff72fb03614b867af722c7c40b" category="paragraph"><block ref="20f069ff72fb03614b867af722c7c40b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ad3b9c1075f899242a74f969cbb12fa" category="list-text">[Auth]セクションを展開し、[Try it Out]をクリックします。</block>
  <block id="5ffa75198edfa553c162f3b9945a23a0" category="paragraph"><block ref="5ffa75198edfa553c162f3b9945a23a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="41402cfc6490d3bf582b8a14ff8bfcbe" category="list-text">UserOperationContext領域で、SnapCenter の資格情報と役割を入力し、Executeをクリックします。</block>
  <block id="2e1aa1ca38ffa5e45db5da3276238eac" category="paragraph"><block ref="2e1aa1ca38ffa5e45db5da3276238eac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18e649ac855810eb5b8a774b3fab5f5c" category="list-text">以下の応答本文では、トークンを確認できます。バックアッププロセス実行時に、認証用のトークンテキストをコピーします。</block>
  <block id="32d5d8e51cafb2b4d387df356fe41955" category="paragraph"><block ref="32d5d8e51cafb2b4d387df356fe41955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a1a34831e3e917e934e09eb9402b4d6" category="section-title">SnapCenter データベースのバックアップを実行する</block>
  <block id="3d8b8b9e239f00e8fbddb0437a5c5659" category="paragraph">次に、Swaggerページのディザスタリカバリ領域に移動して、SnapCenter バックアッププロセスを開始します。</block>
  <block id="5fd8196e8aa6d444acf7a65f639a6085" category="list-text">[Disaster Recovery]領域をクリックして展開します。</block>
  <block id="7ec34046162f53040f7ca7c8a78c4b17" category="paragraph"><block ref="7ec34046162f53040f7ca7c8a78c4b17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14245d6803dae3fc2cab0fe1fd18565e" category="list-text">「/4.6/disasterrecovery/sa/backup」セクションを展開し、「試してみてください」をクリックします。</block>
  <block id="b5f8e4e588ebd761591d02cb02f2a5dd" category="paragraph"><block ref="b5f8e4e588ebd761591d02cb02f2a5dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aad454707845382aef2a040acc30177a" category="list-text">SmDRBackupRequestセクションで、正しいローカルターゲットパスを追加し、Executeを選択してSnapCenter データベースと設定のバックアップを開始します。</block>
  <block id="949b4a3f3887b0d48d721acc506fb82e" category="admonition">バックアッププロセスでは、NFSまたはCIFSのファイル共有に直接バックアップすることはできません。</block>
  <block id="ef97a1ec7f6c4c7d84f053938ce48398" category="paragraph"><block ref="ef97a1ec7f6c4c7d84f053938ce48398" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f638b2ae24161dbfa69705afbf177bd" category="section-title">SnapCenter からバックアップジョブを監視</block>
  <block id="03322e4ba2c5a628edfa27eb5a52741b" category="paragraph">データベースリストアプロセスを開始するときに、SnapCenter にログインしてログファイルを確認します。Monitorセクションでは、SnapCenter サーバのディザスタリカバリバックアップの詳細を表示できます。</block>
  <block id="82c39eed34769992987a93ed6b12a97f" category="paragraph"><block ref="82c39eed34769992987a93ed6b12a97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac753614a3d47f00caddc06fd2dc281f" category="section-title">XCOPYユーティリティを使用してデータベースバックアップファイルをSMB共有にコピーします</block>
  <block id="d2a0be1c4b7f47c09b612fb78a28adee" category="paragraph">次に、SnapCenter サーバ上のローカルドライブから、SnapMirrorによってデータがAWSのFSXインスタンス上のセカンダリサイトにコピーされるCIFS共有にバックアップを移動する必要があります。ファイルのアクセス権を保持する特定のオプションを指定してxcopyを使用します</block>
  <block id="fa13c8e8caa807a78a4301f1cfa0ec2f" category="paragraph">管理者としてコマンドプロンプトを開きます。コマンドプロンプトで、次のコマンドを入力します。</block>
  <block id="0b55c8177ba39a322f35975c0c3bd3ba" category="section-title">スキルと知識</block>
  <block id="b1adf7ef88c9564fb1f6c97bf42dca5c" category="paragraph">Cloud Volumes Service for AWSにアクセスするには、次のスキルと情報が必要です。</block>
  <block id="7b83d82f99126fdb6efaa234f31683f5" category="list-text">VMwareとONTAP のオンプレミス環境へのアクセスと知識を提供します。</block>
  <block id="39a8abb00c1f9d982e3a29b4baec67f2" category="list-text">VMware CloudおよびAWSへのアクセスとその知識。</block>
  <block id="eaad72d3a50e4be3e11d36792eb96d62" category="list-text">AWSおよびAmazon FSX ONTAP へのアクセスとその知識。</block>
  <block id="25e65b652ca97821fa49aa9571b2b54a" category="list-text">SDDCとAWSのリソースに関する知識</block>
  <block id="18334368a9f4fce73ca297bdd4be123a" category="list-text">オンプレミスリソースとクラウドリソース間のネットワーク接続に関する知識。</block>
  <block id="f917b7afd251e67bbdf50fa466a9918e" category="list-text">ディザスタリカバリシナリオの実用的な知識。</block>
  <block id="77d0638c77df28bd77c058b3da580702" category="list-text">VMware上に導入されたアプリケーションに関する実務的な知識。</block>
  <block id="9ef15415f400d1d1a7b2c4d3e8879124" category="section-title">管理</block>
  <block id="99be46c7a7d783d36552f0f11df8cd5e" category="paragraph">オンプレミスでもクラウドでも、ユーザや管理者は、必要なときに利用資格に応じてリソースをプロビジョニングでき、利用資格が付与されている必要があります。ONTAP やVMwareなどのオンプレミスシステムと、VMwareクラウドやAWSなどのクラウドリソースに対する役割と権限の相互作用は、ハイブリッドクラウドの導入を成功させるために最も重要です。</block>
  <block id="e5d4baff0167d033367d67396f5608f6" category="paragraph">VMwareとONTAP を使用してオンプレミスでDR解決策 を構築し、AWSとFSX ONTAP 上でVMwareクラウドを構築するには、次の管理タスクを実行する必要があります。</block>
  <block id="e6833d473d476a99c7ec8095a5bfe8df" category="list-text">次のプロビジョニングを可能にするロールとアカウント：</block>
  <block id="297c8005623a7f22aad3d141e82fabb5" category="list-text">ONTAP ストレージリソース</block>
  <block id="864d5ea26def3831e53731dc58671672" category="list-text">VMwareのVMやデータストアなど</block>
  <block id="61b883742c54e0000affbbf61cecb00a" category="list-text">AWS VPCとセキュリティグループ</block>
  <block id="cae667335742a0f5e8a41bb0caa73e4c" category="list-text">オンプレミスのVMware環境とONTAP をプロビジョニング</block>
  <block id="7098bf260c6533f1ebf70f5b9bb041b0" category="list-text">VMwareクラウド環境</block>
  <block id="eca5f84e846df7323fccde83f4ff44d5" category="list-text">ONTAP ファイルシステム用のAmazon</block>
  <block id="29b34be64d30233d5ed6d4f314db7483" category="list-text">オンプレミス環境とAWS間の接続</block>
  <block id="c89c49a63ff46b95a3a1930093133477" category="list-text">AWS VPCへの接続</block>
  <block id="9301a9f205ba883a750d8c90b33c2bbc" category="paragraph">VMware仮想環境には、次の図に示すように、ESXiホスト、VMware vCenter Server、NSXネットワーク、およびその他のコンポーネントのライセンスが含まれます。いずれのライセンス方法も異なるため、基盤となるコンポーネントが使用可能なライセンス容量をどのように消費するかを理解しておくことが重要です。</block>
  <block id="42094e9e4a0f05012b8d6753300a1657" category="section-title">ESXiホスト</block>
  <block id="1d50ac197ef032b2bc2e46d8e2e64598" category="paragraph">VMware環境のコンピューティングホストはESXiとともに導入されます。さまざまな容量階層でvSphereのライセンスを取得することで、仮想マシンは各ホストの物理CPUおよび該当する使用権のある機能を利用できます。</block>
  <block id="43e02e05b2879c1406a010bf6a28f8f7" category="section-title">VMware vCenter</block>
  <block id="05f79f8867c02153173be8abc21ae61a" category="paragraph">ESXiホストとストレージの管理は、vCenter Serverを使用してVMware管理者が利用できるさまざまな機能の1つです。VMware vCenter 7.0以降では、ライセンスに応じて、次の3つのエディションのVMware vCenterを使用できます。</block>
  <block id="f958b6a3f3407168711a82d395fb4ac7" category="list-text">vCenter Server Essentials</block>
  <block id="a0301fdeb61b558341af142a9f2dd3aa" category="list-text">vCenter Server Foundation</block>
  <block id="62a846eee92143dee42cae576208c443" category="list-text">vCenter Server Standardの略</block>
  <block id="e44df2b6e256fb033bf0234d942a29f3" category="paragraph">VMware NSXは、管理者が高度な機能を有効にするために必要な柔軟性を提供します。機能は、ライセンスが付与されているNSX Editionのバージョンに応じて有効になります。</block>
  <block id="9e8b160226c9fe22a910c782ce5076e2" category="list-text">プロフェッショナル</block>
  <block id="9b6545e4cea9b4ad4979d41bb9170e2b" category="list-text">詳細設定</block>
  <block id="1330271d87fae19afa4e7be5cd94b9f8" category="list-text">リモートオフィス/ブランチオフィス</block>
  <block id="88793829da8796f676eaebd57e42009d" category="paragraph">NetApp ONTAP のライセンスとは、管理者がネットアップストレージのさまざまな機能を利用する方法を指します。ライセンスには、ソフトウェアの使用権が 1 つ以上記録されています。ライセンスキーをインストールすることはライセンスコードとも呼ばれ、ストレージシステムで特定の機能やサービスを使用できるようになります。たとえば、ONTAP は業界標準の主要なクライアントプロトコル（NFS、SMB、FC、FCoE、iSCSI、 およびNVMe/FC）のサポートも提供します。</block>
  <block id="90a29bf269cfe6c256d42b29776d14dd" category="paragraph">Data ONTAP の機能ライセンスはパッケージとして発行されます。各パッケージには複数または単一の機能が含まれます。パッケージにはライセンスキーが必要であり、キーをインストールすることで、パッケージのすべての機能にアクセスできるようになります。</block>
  <block id="e4b843c32b9db50414c1dfbad0c4d1c0" category="paragraph">ライセンスタイプは次のとおりです。</block>
  <block id="0f00a6a817b378adf16de8d25fbf24fa" category="list-text">*ノードロックライセンス。*ノードロックライセンスをインストールすると、ライセンスされた機能をノードに対して使用できるようになります。ライセンスされた機能をクラスタで使用するには、少なくとも 1 つのノードで、その機能のライセンスが有効になっている必要があります。</block>
  <block id="52db1a3edfedfc7015c35209e22f04c2" category="list-text">*マスター/サイトライセンス。*マスターライセンスまたはサイトライセンスは、特定のシステムシリアル番号に関連付けられません。サイトライセンスをインストールすると、クラスタ内のすべてのノードで、ライセンスされた機能を使用できるようになります。</block>
  <block id="b2aa6f86c442a3ce1bedb4a83498fcc6" category="list-text">*デモ/一時ライセンス。*デモライセンスまたは一時ライセンスは、一定時間が経過すると失効します。このライセンスを使用すると、ライセンスを購入せずに特定のソフトウェア機能を試すことができます。</block>
  <block id="c6009ee65fbe56a5eed91a0a06f3a1b5" category="list-text">*容量ライセンス（ONTAP Select およびFabricPool のみ）。* ONTAP Select インスタンスのライセンスは、ユーザーが管理するデータの量に応じて付与されます。ONTAP 9.4以降では、FabricPool でサードパーティのストレージ階層（AWSなど）を使用する場合に容量ライセンスが必要になります。</block>
  <block id="13b92bafad23a87622890420ed0b860b" category="paragraph">SnapCenter でデータ保護処理を有効にするには、複数のライセンスが必要です。インストールする SnapCenter ライセンスのタイプは、ストレージ環境および使用する機能によって異なります。SnapCenter Standardライセンスでは、アプリケーション、データベース、ファイルシステム、および仮想マシンが保護されます。SnapCenter にストレージシステムを追加する前に、 1 つ以上の SnapCenter ライセンスをインストールする必要があります。</block>
  <block id="c2aa46e5e57aae7e4f4c969c417f1238" category="paragraph">アプリケーション、データベース、ファイルシステム、および仮想マシンを保護するには、FAS またはAFF ストレージシステムにStandardコントローラベースのライセンスをインストールするか、ONTAP Select およびCloud Volumes ONTAP プラットフォームにStandard容量ベースのライセンスをインストールする必要があります。</block>
  <block id="14c2700881a435ad41069af9e8ee6f85" category="paragraph">この解決策 の次のSnapCenter バックアップの前提条件を参照してください。</block>
  <block id="96b3493b2e1844322d28e845c314e10b" category="list-text">オンプレミスのONTAP システムに作成されたボリュームとSMB共有。バックアップされたデータベースと構成ファイルを検索します。</block>
  <block id="f39931d0fa94c8e0cb577222f77fb09d" category="list-text">オンプレミスのONTAP システムと、AWSアカウントのFSXまたはCVOとの間のSnapMirror関係。バックアップされたSnapCenter データベースおよび構成ファイルを含むSnapshotの転送に使用されます。</block>
  <block id="d2727816fa1087ddac7dff69e35c5536" category="section-title">MS SQLの場合</block>
  <block id="f9e005542c2e103eede9db2dfe82bdc7" category="paragraph">この解決策 検証の一環として、ディザスタリカバリのデモにはMS SQLを使用します。</block>
  <block id="ed94f710e6ae715e2f17c5670d6bf092" category="paragraph">MS SQLとNetApp ONTAP のベストプラクティスの詳細については、以下を参照してください<block ref="1ed6e40008e985821d1338a60f7ccab3" category="inline-link-rx"></block>。</block>
  <block id="877ee5bcf7f0335c93ce9f231f44f195" category="paragraph">この解決策 検証の一環として、Oracleを使用してディザスタリカバリを実施します。OracleとNetApp ONTAP のベストプラクティスの詳細については、以下を参照してください<block ref="3b13b5361a3a7b7e48b79b29a907e9fc" category="inline-link-rx"></block>。</block>
  <block id="05241239c2e205951eabc51d0b39de96" category="section-title">Veeamの統合によって</block>
  <block id="cf575d98d37c3423857f91c318d883e7" category="paragraph">この解決策 検証の一環として、Veeamを使用してディザスタリカバリを実証します。VeeamとNetApp ONTAP のベストプラクティスの詳細については、以下を参照してください<block ref="69659c9961c1e42b0f8742562f24fdfa" category="inline-link-rx"></block>。</block>
  <block id="59288c543af9b26fa84b24054d3be8dc" category="paragraph">次のタスクを実行できる必要があります。</block>
  <block id="f35a1ddfb2f9b2cac114bd32ce5bbbab" category="list-text">ドメインサービスを導入して設定します。</block>
  <block id="71877c1e84cfa72072c46494d86a8ee7" category="list-text">所定のVPCに、アプリケーション要件ごとにFSX ONTAP を導入します。</block>
  <block id="9135a2c6ac5c27bd10c50337c5a89f26" category="list-text">AWS Compute GatewayにVMware Cloudを設定して、FSX ONTAP からのトラフィックを許可します。</block>
  <block id="8a401f5d4b33a44bd1812ff7ead2248d" category="list-text">AWSサブネット上のVMware Cloudと、FSX ONTAP サービスが導入されているAWS VPCサブネットとの間の通信を許可するようにAWSセキュリティグループを設定します。</block>
  <block id="2e31cdf7daad1ca06d6642765fa13252" category="section-title">VMwareクラウド</block>
  <block id="f7f38aee276941a8501ab3a4788fb838" category="list-text">AWS SDDCでVMware Cloudを構成</block>
  <block id="08aa379cc2bcb108397d323bd5732f6c" category="section-title">Cloud Managerアカウントの検証</block>
  <block id="17d24c2f3d504e509ec34ba87bfea6a5" category="paragraph">NetApp Cloud Managerを使用してリソースを導入できる必要があります。次のタスクを実行して、を実行できることを確認します。</block>
  <block id="2ee5d6132c6433861745857e6af68778" category="inline-link">Cloud Centralに登録</block>
  <block id="604e59aa26a0b211909e4b9590685eb1" category="list-text"><block ref="35c2f2ba3f068c3df62b94b779d38cce" category="inline-link-rx"></block> まだお持ちでない場合は、</block>
  <block id="e7ef0ccc08f963a97d6ab9c3aabc5081" category="inline-link">Cloud Managerにログイン</block>
  <block id="5ec677c5c014e60203e82de8cbed20e4" category="list-text"><block ref="77549d8461eff5ea7726f72f7e171b7c" category="inline-link-rx"></block>。</block>
  <block id="78e80a35b7d01f404398eea432dd9654" category="inline-link">ワークスペースとユーザーをセットアップする</block>
  <block id="6693afd5aef7c87168fb40b34d61e795" category="list-text"><block ref="491866e862424f2a10f9441373484bc0" category="inline-link-rx"></block>。</block>
  <block id="e7a9cd1dc4bf0c230d0684e18369d70d" category="inline-link">コネクタを作成します</block>
  <block id="821d88deb5e031a9587e5a8e00abe556" category="list-text"><block ref="b3797d3b448c35004d47db91b5cf65cf" category="inline-link-rx"></block>。</block>
  <block id="4c0f2b07e3034da6a2b901197cec7210" category="paragraph">AWSアカウントを作成したら、次のタスクを実行できます。</block>
  <block id="7d8207e3bfa061fd6c5b1389d79e23e4" category="list-text">NetApp ONTAP ファイルシステム用にAmazon FSXをプロビジョニングできるIAM管理ユーザを作成します。</block>
  <block id="7984cdcb84b94f3ec5af3c2aa0bc9f9c" category="section-title">設定の前提条件</block>
  <block id="799b279302dc2106f49a0c61994a42a1" category="paragraph">お客様のトポロジはさまざまであるため、このセクションでは、オンプレミスからクラウドリソースへの通信に必要なポートについて説明します。</block>
  <block id="dee55c33a91e43d371aa8eab0ee8968e" category="section-title">必要なポートとファイアウォールに関する考慮事項</block>
  <block id="34e0f9db6d0a94f20e464420fb481570" category="paragraph">次の表に、インフラ全体で有効にする必要があるポートを示します。</block>
  <block id="28c5fdd36289c2258f08118f41c54729" category="paragraph">Veeam Backup &amp; Replicationソフトウェアに必要なポートの一覧については、を参照してください<block ref="2a9b4a1873abbc6819ad7073e9ebc1a5" category="inline-link-rx"></block>。</block>
  <block id="2a975bb27423e33e6c65cb2e2b14db28" category="paragraph">SnapCenter のより包括的なポート要件については、を参照してください<block ref="4939c26301b3a22bfb3c0a6725311b88" category="inline-link-rx"></block>。</block>
  <block id="8a042a39d5b3b0e7e0554c5af7abd76b" category="paragraph">次の表に、Microsoft Windows Serverに関するVeeamのポート要件を示します。</block>
  <block id="5da618e8e4b89c66fe86e32cdafde142" category="cell">移動元</block>
  <block id="e12167aa0a7698e6ebc92b4ce3909b53" category="cell">終了：</block>
  <block id="60aaf44d4b562252c04db7f98497e9aa" category="cell">ポート</block>
  <block id="f4c6f851b00d5518bf888815de279aba" category="cell">注：</block>
  <block id="52045ab804b1b913874ef04c2c3a2f69" category="cell">バックアップサーバ</block>
  <block id="de6900dd0f213be9d369252ce490a1df" category="cell">Microsoft Windowsサーバ</block>
  <block id="b136ef5f6a01d816991fe3cf7a6ac763" category="cell">TCP</block>
  <block id="67f7fb873eaf29526a11a9b7ac33bfac" category="cell">445</block>
  <block id="3f8c4ba1591441de01c30814d6be96cb" category="cell">Veeam Backup &amp; Replicationコンポーネントの導入に必要なポート。</block>
  <block id="a34fcb59deecb10582ae58c505df58ba" category="cell">バックアッププロキシ</block>
  <block id="fa3060edb66e6ff4507886f9912e1ab9" category="cell">6160</block>
  <block id="a615435ab6eb1aac4a4b4c4ebe2a89e9" category="cell">Veeamインストーラサービスで使用されるデフォルトのポート。</block>
  <block id="480ddf908a09bb49e2eb46b2293d83e0" category="cell">バックアップリポジトリ</block>
  <block id="84c456c47f1859be98a88fa53ffca994" category="cell">2500～3500</block>
  <block id="1622c3ddec12802a4bc6cbb96c7b1b49" category="cell">データ転送チャネルおよびログファイルの収集に使用されるデフォルトのポート範囲。</block>
  <block id="a31f402016255891ea5a6010567d0c28" category="cell">サーバをマウントします</block>
  <block id="6aaba9a124857622930ca4e50f5afed2" category="cell">6162</block>
  <block id="f36e2d75f4071e4e994fdbc77c14ddb0" category="cell">Veeam Data Moverで使用されるデフォルトのポート。</block>
  <block id="510f315f3436af1e5ec4cb22dd263070" category="admonition">ジョブが使用するTCP接続ごとに、この範囲のポートが1つ割り当てられます。</block>
  <block id="655a5fe10451fb66645cbcdec5034698" category="paragraph">次の表に、VeeamによるLinux Serverのポート要件を示します。</block>
  <block id="b5d9f1a9fbf0fb75f6765f140eb5774f" category="cell">Linuxサーバ</block>
  <block id="28c991d1c426febedd1596fd29a3f864" category="cell">コンソールからターゲットLinuxホストへの制御チャネルとして使用されるポート。</block>
  <block id="a4fda10bbaa8015596c2c1c1dd6f1a36" category="paragraph">次の表に、Veeam Backup Serverのポート要件を示します。</block>
  <block id="4197adf45342f775880cf0b40b2bebe4" category="cell">HTTPS、TCP</block>
  <block id="ff48f6174c8c54c3faa04ebcf25b720d" category="cell">vCenter Serverへの接続に使用されるデフォルトのポート。コンソールからターゲットLinuxホストへの制御チャネルとして使用されるポート。</block>
  <block id="dad95acf5318650271f0853ca3c36a1a" category="cell">Veeam Backup &amp; Replication構成データベースをホストしているMicrosoft SQL Server</block>
  <block id="8fb5f8be2aa9d6c64a04e3ab9f63feee" category="cell">1443</block>
  <block id="dc0848552680aa2839c317b54853b6c8" category="cell">Veeam Backup &amp; Replication構成データベースが導入されているMicrosoft SQL Serverとの通信に使用するポート（Microsoft SQL Serverのデフォルトインスタンスを使用している場合）。</block>
  <block id="1cdaa0286d1e5b2da16bb4a4d56030e5" category="cell">すべてのバックアップサーバの名前解決を伴うDNSサーバ</block>
  <block id="8643c8e2107ba86c47371e037059c4b7" category="cell">3389</block>
  <block id="2914ea759530f85f84d8d97088f4c0fb" category="cell">DNSサーバとの通信に使用するポート</block>
  <block id="462cb0982d9c6d8b64cd1a92197cad0e" category="admonition">vCloud Directorを使用する場合は、基盤となるvCenter Serverでポート443を開きます。</block>
  <block id="5fd55c0224ae845943b259eaa37fa9de" category="paragraph">次の表に、Veeam Backup Proxyのポート要件を示します。</block>
  <block id="e564618b1a0f9a0e5b043f63d43fc065" category="cell">6210</block>
  <block id="06c6eec6c18e0d75ea5c6853a2397d90" category="cell">SMBファイル共有のバックアップ時にVSS Snapshotを作成するためにVeeam Backup VSS Integration Serviceで使用されるデフォルトのポート。</block>
  <block id="dd46e35ec3bd7632e2b6924b4ace5592" category="cell">vCenterの設定でカスタマイズ可能なデフォルトのVMware Webサービスポート。</block>
  <block id="67f0bc6c760260e8ecb1e44fc5337bd6" category="paragraph">次の表に、SnapCenter ポートの要件を示します。</block>
  <block id="bd9f125b279a19f0d5b7f09c7d793d35" category="cell">ポートタイプ（ Port Type ）</block>
  <block id="d7ca8612b857419959ee2c089e5be08c" category="cell">SnapCenter 管理ポート</block>
  <block id="0e8433f9a404f1f3ba601c14b026d321" category="cell">HTTPS</block>
  <block id="202ed3792e2cfa7318b12ead83763c37" category="cell">8146</block>
  <block id="a1a3a7ab0e2e0b654e17bb8a2e57e9e5" category="cell">このポートは、SnapCenter クライアント（SnapCenter ユーザ）とSnapCenter サーバ間の通信に使用されます。プラグインホストから SnapCenter サーバへの通信にも使用されます。</block>
  <block id="18622e175ff22b2375f9cbc2314b3285" category="cell">SnapCenter SMCore の通信ポート</block>
  <block id="bb68b5529560433e58ff13eb45622724" category="cell">このポートは、SnapCenter サーバとSnapCenter プラグインがインストールされているホストの間の通信に使用されます。</block>
  <block id="f79093a340ccf8139d6e585381acc44c" category="cell">Windowsプラグインホスト、インストール</block>
  <block id="a1639b6147c7f85402852464ce33b9ae" category="cell">135、445</block>
  <block id="4b790f3dbcd2d867091d8fbf3b63026f" category="cell">これらのポートは、SnapCenter サーバとプラグインがインストールされているホストとの間の通信に使用されます。ポートはインストール後に閉じることができます。さらに、Windows Instrumentation Servicesは、ポート49152~65535を検索します。これらのポートは必ず開いておく必要があります。</block>
  <block id="da8fa0760683502b8b15e2d8f992b780" category="cell">Linuxプラグインホスト、インストール</block>
  <block id="765553e6c7ac8592c389acb9878a050a" category="cell">SSH</block>
  <block id="e541d805fe886aded7cfb18984fba335" category="cell">これらのポートは、SnapCenter サーバとプラグインがインストールされているホストとの間の通信に使用されます。ポートは、プラグインパッケージのバイナリをLinuxプラグインホストにコピーするためにSnapCenter で使用されます。</block>
  <block id="8ffa3ad47599004a1c67f905da7456c0" category="cell">Windows / Linux用のSnapCenter Plug-insパッケージ</block>
  <block id="0c0cfd9478c6551fbfe74a7acb6fc037" category="cell">8145</block>
  <block id="9b52abdc2eaa620c3f1c7588679b8764" category="cell">SMCoreとSnapCenter プラグインがインストールされているホストの間の通信に使用されます。</block>
  <block id="7c1239972879fe0b69b4bb6d5c9a743e" category="cell">VMware vSphere vCenter Server のポート</block>
  <block id="4047860556fa008e56adfadd36f5b7af" category="cell">このポートは、SnapCenter Plug-in for VMware vSphereとvCenter Serverの間の通信に使用されます。</block>
  <block id="87db2cdf992c6481194f67a3c24f2d31" category="cell">SnapCenter Plug-in for VMware vSphereのポート</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="397d2ce87a0d127486b8fa20c5f3cdb9" category="cell">このポートは、vCenter vSphere Web ClientおよびSnapCenter Serverからの通信に使用されます。</block>
  <block id="f201deaeba7cc565253f52d974008543" category="summary">アプリケーションVMおよびデータベースボリュームをAWSで実行されているVMware Cloud Volumeサービスにフェイルオーバーするには、SnapCenter サーバとVeeam Backup and Replication Serverの両方の実行中のインスタンスをインストールして設定する必要があります。フェイルオーバーが完了したら、オンプレミスのデータセンターへのフェイルバックが計画されて実行されるまで、通常のバックアップ処理を再開するようにこれらのツールも設定する必要があります。</block>
  <block id="ee51a40e9d2538b4e33b441d66869c24" category="doc">クラウドバックアップツールと設定</block>
  <block id="a514f4da2fec40b52d89613d7b3854fa" category="section-title">セカンダリWindows SnapCenter サーバを導入します</block>
  <block id="dba3e8475ef38dcd147447c5730c2f7c" category="paragraph">SnapCenter サーバは、VMware Cloud SDDCに導入するか、VPC内のEC2インスタンスにインストールし、VMware Cloud環境にネットワーク接続します。</block>
  <block id="1a297f32b70010f208d00a4f58855fec" category="paragraph">SnapCenter ソフトウェアはネットアップサポートサイトから入手でき、ドメインまたはワークグループ内にあるMicrosoft Windowsシステムにインストールできます。詳細な計画ガイドとインストール手順については、を参照してください<block ref="92e6fa322f689d7da93690560d0b41bd" category="inline-link-rx"></block>。</block>
  <block id="4adffd967d9bbc0f71287e67a568e0ae" category="paragraph">SnapCenter ソフトウェアは、から入手できます<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>。</block>
  <block id="224efa116a105cfd586d82f09e7cd1fe" category="section-title">セカンダリWindows SnapCenter サーバを設定します</block>
  <block id="9ec64430f94c7b2f3824857182b8ff9d" category="paragraph">FSX ONTAP にミラーリングされたアプリケーション・データのリストアを実行するには'まずオンプレミスのSnapCenter データベースのフル・リストアを実行する必要がありますこのプロセスが完了すると、VMとの通信が再確立され、プライマリストレージとしてFSX ONTAP を使用してアプリケーションのバックアップを再開できるようになります。</block>
  <block id="b502974234450ceabf2344f2a3e45f7a" category="paragraph">これを行うには、SnapCenter サーバで次の項目を完了する必要があります。</block>
  <block id="13d56fa22f861d817f01e34bd0dff18d" category="list-text">コンピュータ名を、元のオンプレミスSnapCenter サーバと同じ名前に設定します。</block>
  <block id="87da734902f9a20ba518a732df6228fc" category="list-text">VMware CloudおよびFSX ONTAP インスタンスと通信するためのネットワークを設定します。</block>
  <block id="7f2fdcaa4d368c36731db2bdf5eb79a9" category="list-text">手順 を完了してSnapCenter データベースをリストアします。</block>
  <block id="b9f6e6c037c51c372d51f5f4254d76cc" category="list-text">SnapCenter がディザスタリカバリモードになっていることを確認し、FSXがバックアップ用のプライマリストレージになったことを確認します。</block>
  <block id="b8864a7697abc4d58d337a7803f7ca8e" category="list-text">リストアした仮想マシンとの通信が再確立されたことを確認します。</block>
  <block id="6b9d280aee667ad2407fdb311dc034cb" category="inline-link-macro">SnapCenter データベースのリストアプロセス</block>
  <block id="4757e8da6d3b5465a3ae91d8390db6d9" category="paragraph">これらの手順の実行方法の詳細については、「～」の項を参照してください <block ref="fe5a34b461345b6f910f9d5fd86fde40" category="inline-link-macro-rx"></block>。</block>
  <block id="b827704a3bb22b3992173e0581a1c28b" category="paragraph">Veeam Backup &amp; Replicationサーバは、AWS上のVMware CloudまたはEC2インスタンス上のWindowsサーバにインストールできます。実装の詳細なガイダンスについては、を参照してください<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>。</block>
  <block id="e271ecc9b2a2050b58d0914d62a2325b" category="paragraph">Amazon S3ストレージにバックアップされた仮想マシンをリストアするには、WindowsサーバにVeeamサーバをインストールし、VMware Cloud、FSX ONTAP 、および元のバックアップリポジトリが格納されたS3バケットと通信するように設定する必要があります。また、リストア後にVMの新しいバックアップを実行するために、FSX ONTAP に新しいバックアップリポジトリが設定されている必要があります。</block>
  <block id="d569da58bc917eb906ada72f76bf1030" category="paragraph">このプロセスを実行するには、次の項目を完了する必要があります。</block>
  <block id="6443544e723bdb5a8e0b2e300ce4e821" category="list-text">VMware Cloud、FSX ONTAP 、および元のバックアップリポジトリを含むS3バケットと通信するためのネットワークを設定します。</block>
  <block id="d19ea991ccb7ded9582c07fa062fb3b4" category="list-text">FSX ONTAP 上のSMB共有を新しいバックアップリポジトリとして設定します。</block>
  <block id="adf79b820407599132e907adb994746d" category="list-text">スケールアウトバックアップリポジトリの一部として使用されていた元のS3バケットをオンプレミスにマウントします。</block>
  <block id="a706ef66660617fcf4a5aeb2e6f6d76b" category="list-text">VMをリストアしたら、SQL VMとOracle VMを保護するための新しいバックアップジョブを確立します。</block>
  <block id="28850f35c95cf12d5e28a35c2fdd8e5d" category="inline-link-macro">アプリケーションVMをVeeam Full Restoreでリストアします</block>
  <block id="5ad23c05d5054f7daf749b3a328903be" category="paragraph">Veeamを使用したVMのリストアの詳細については、を参照してください <block ref="145e19bb138e7c87e2d24d78a1c11e93" category="inline-link-macro-rx"></block>。</block>
  <block id="5e86473217a757f4702d326176983651" category="cell">2022年7月28日</block>
  <block id="e325d40f0256e06aa0a0f1c795ea68ee" category="cell">DR解決策 とSnapCenter およびVeeam for AWS / VMC（ゲスト接続ストレージ）を追加</block>
  <block id="af2a34190d0729a3b5a2ed9d50d9e399" category="cell">VMwareソリューションを使用してハイブリッドマルチクラウドのコンテンツを整理：各ハイパースケーラのランディングページと、利用可能な解決策 （ユースケース）コンテンツを含める</block>
  <block id="9c00744e128712d7626e5c00edcfeaa1" category="cell">VMwareを使用して、仮想化とハイブリッドマルチクラウドのコンテンツを整理するためのランディングページを作成</block>
  <block id="5424d7e641fa7962888e16022445e1ae" category="cell">仮想化環境用のVMwareコンテンツとゲスト接続型ストレージオプションを使用したハイブリッドマルチクラウドの作成</block>
  <block id="e307db07b3975fef922a80d07455ee5e" category="cell">データベース</block>
  <block id="6c6fb0f7e5fe3a7242028f22d2792fca" category="cell">ネットアップのソリューションタイルに、エンタープライズアプリケーションとデータベースに関するブログセクションを追加しました。データベースブログに2つのブログを追加。</block>
  <block id="c99ec32d06b1f19699d82b1b34a80ca0" category="paragraph"><block ref="c99ec32d06b1f19699d82b1b34a80ca0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="119d7589ae9a38050e960d08d321b275" category="list-text">Azure NetApp Files （ANF）をNFSデータストア^1の補足情報として使用しています</block>
  <block id="0f9904cf8a560b1c4309e4cf7750b7b9" category="admonition">1 - AVSの補足的なNFSデータストアであるANFは、現在パブリックプレビュー版です。詳細はこちら<block ref="5b3a31b4442bd8ea3aebfc18fe8411e5" category="inline-link-rx"></block>。</block>
  <block id="efe20646a1138596f4f7b7f387cae230" category="list-text">Cloud Volumes Service （CVS）をNFSデータストア^1^として追加で作成します</block>
  <block id="e7e05ca1857ad4b0e930d0672e7657c4" category="inline-link-macro">Cloud Volumes Service （CVS）をNFSデータストア^1の補足情報として追加しました</block>
  <block id="8bde1a7decedb03d4e5ae4c5b6c9f5d3" category="paragraph">詳細については、をご覧ください <block ref="d54e964e36cd6cf7ab87b4b420d12109" category="inline-link-macro-rx"></block>。</block>
  <block id="58098d451cf2728b0542acd542f9000b" category="cell">* NFSデータストアの追加*</block>
  <block id="51b0e38e5ec7edbe37b6672987ce5f2e" category="paragraph">ネットアップが提供する3つの主要ハイパースケーラ（ゲスト接続ストレージデバイスまたはNFSデータストアとしてのネットアップ提供）の機能について、詳しくはこちらをご覧ください。また、ワークフローの移行、クラウドへの拡張/バースト対応、バックアップ/リストア、ディザスタリカバリも行っています。</block>
  <block id="ccb4d111a650d51ca9a8feb2542610be" category="paragraph">ネットアップのストレージは、3つの主要なハイパースケーラそれぞれで、接続されている推測データストアまたはNFSデータストア補助として、複数の方法で利用できます。</block>
  <block id="d22e98327d29984cdf19ebfeeb53bd99" category="paragraph">ネットアップがAWS VMware Cloud（VMC）にもたらす機能の詳細をご確認ください。ネットアップのゲスト接続ストレージデバイスやNFSデータストアを追加で提供し、ワークフローの移行、クラウドへの拡張/バースト対応、バックアップ/リストア、ディザスタリカバリを実現します。</block>
  <block id="e3dea11e8144be98f637687e2a2cf316" category="paragraph">ネットアップストレージは、AWS VMC内で、接続されている推測データストアまたはNFSデータストア補助的なデータストアとして、いくつかの方法で利用できます。</block>
  <block id="206616b83a19162051802c3823da0f7c" category="paragraph">ネットアップは、ゲストに接続されたストレージとして、または各ハイパースケーラにNFSデータストアとしてプロビジョニングされたストレージ向けのソリューションも提供しています。すべてのソリューションは、VMwareのクラウドワークロード分類と同時に分類されます。これらの分類には、次のもの</block>
  <block id="04e248dee456b1f3910d53450d745125" category="list-text">クラウドの補助的なテクノロジーを活用したアプリケーションの最新化。</block>
  <block id="77d50dd2ce4e2531e14f13434a560e7d" category="section-title">NFS追加ストレージオプションの重要性を理解する</block>
  <block id="de8529127f85189767876e4d9a97427c" category="paragraph">あらゆるクラウドでVMwareが提供する独自のハイブリッド機能に加えて、NFSストレージオプションの追加によってストレージ負荷の高い組織での有用性が制限されています。ストレージはホストに直接関連付けられているため、ストレージを拡張する唯一の方法は、ホストを追加することです。これにより、ストレージを大量に消費するワークロードの場合、 35 ～ 40% 以上のコストがかかる可能性があります。このようなワークロードに必要なストレージ容量は増えても容量は増えません。つまり、追加のホストに料金を支払うことになります。</block>
  <block id="af68f7a1e7ca322318bf949baba2129e" category="inline-link-macro">ANFおよびJetStreamを使用したディザスタリカバリ（補足的なNFSデータストア）</block>
  <block id="73c807da78ef06fdb99e2307b5d8cb57" category="list-text"><block ref="73c807da78ef06fdb99e2307b5d8cb57" category="inline-link-macro-rx"></block></block>
  <block id="f93c390413608eaad8cc43b29f8073d0" category="inline-link-macro">ANFおよびCVOを使用したディザスタリカバリ（ゲスト接続ストレージ）</block>
  <block id="233b8f979ad627e56656fbdd647fdc2b" category="list-text"><block ref="233b8f979ad627e56656fbdd647fdc2b" category="inline-link-macro-rx"></block></block>
  <block id="5f2df3110b7088a1c8d1659ffb728f46" category="doc">CVOとAVS（ゲスト接続ストレージ）によるディザスタリカバリ</block>
  <block id="9a130cd816dc8be85c4f198310f16e4c" category="paragraph">ネットアップがAzure VMware解決策 （AVS）に提供する機能の詳細をご確認ください。ゲスト接続ストレージデバイスとしてネットアップが提供する機能と、NFSデータストアの追加機能を利用して、ワークフローを移行し、クラウドへの拡張/バースト対応、バックアップ/リストア、ディザスタリカバリを実施できます。</block>
  <block id="465fe02ad52f12cc5844200de029e385" category="paragraph">ネットアップのストレージは、Azure AVS内で接続されたか、NFSデータストアとして追加で利用するかのいずれかの方法で利用できます。</block>
  <block id="827f15aa97cbfccd71eb2ba3ac7d4eac" category="doc">AzureのNFSデータストアの追加オプション</block>
  <block id="d6e093aa5c1e7500fe79b8732c410c91" category="paragraph">Azure NetApp Files では、複数のデータストアを導入することもできます。これにより、仮想マシンを適切なデータストアに配置し、ワークロードのパフォーマンス要件を満たすために必要なサービスレベルを割り当てることで、オンプレミスの導入モデルを模倣できます。マルチプロトコルをサポートする独自の機能により、SQLやOracleなどのデータベースワークロードにゲストストレージを追加することもできます。また、残りのVMDKを格納するためのNFSデータストアの追加機能も使用できます。この機能とは別に、標準のスナップショット機能を使用すると、迅速なバックアップおよびきめ細かなリストアを実行できます。</block>
  <block id="402936a0724fed1eeed39a4791eae422" category="paragraph">このアーキテクチャでは、ハイブリッドクラウド接続を実現し、オンプレミス環境とAzure間でアプリケーションをモビリティできるようにする方法について、全体的な視点で説明します。また、Azure NetApp Files を追加のNFSデータストアとして使用する方法、およびAzure VMware解決策 でホストされているゲスト仮想マシンのゲスト内ストレージオプションとして使用する方法についても説明します。</block>
  <block id="66433e0e715221ebed495642af8005b7" category="doc">GCP向けNetApp Supplemental NFS Datastoreオプション</block>
  <block id="ce2d3ab910808452912b4cae1adc8bd7" category="paragraph">ネットアップがGoogle Cloud Platform（GCP）Google Cloud Virtualization Engine（GCVE）に提供する機能の詳細については、ネットアップのゲスト接続ストレージデバイスまたはNFSデータストアから、ワークフローの移行、クラウドへの拡張/バースト対応、バックアップ/リストア、ディザスタリカバリに至るまで解説しています。</block>
  <block id="275ed895f3f409270670131f7369b1ac" category="paragraph">ネットアップストレージは、接続されている推測データストアまたはNFSデータストア補助的なGCP GCVE内のいくつかの方法で利用できます。</block>
  <block id="55b61b011b735ba396a8dbd7e3f95f20" category="cell">08/05/02022</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">*ホスト設定*</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">*ネットアップが推奨する値*</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">*再起動が必要です*</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">* ESXi Advanced Configuration *</block>
  <block id="5fffea5cb752d304de420a5efa158e13" category="cell">そのまま使用（VMwareのデフォルトは1）</block>
  <block id="5d1b81f1885499e392018ebd7124ad37" category="inline-link-macro">VMware KB 2007427</block>
  <block id="36478566e3585eb8ea863e941dcb967a" category="cell">そのままにします（ VMware のデフォルトは 0 ですが、 VMFS6 では必要ありません）。詳細については、を参照してください <block ref="68c2cf0ecb6a1c6abaf6e56c035d5866" category="inline-link-macro-rx"></block></block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">vSphere 6.0 以降： 32 に設定他のすべてのNFS設定の場合は、30に設定されます</block>
  <block id="a8af33a99dd728969fd947da27a2f69f" category="cell">vSphere 6.Xのほとんどのリリースでは512 MBに設定されています。6.5U3、6.7U3、7.0以降の場合は、1024MBに設定します。</block>
  <block id="e787d5b0d643685421632a1af3914963" category="cell">vSphere 6.0以降では、ほかのすべてのNFS構成で256を64に設定。</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth^1 ^</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">vSphere 6.0以降では、128に設定されます</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">すべてのNFS設定について、10に設定されます</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">すべてのNFS設定について、12に設定されます</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">FC パスの ALUA を使用する場合は、 RR （ラウンドロビン）に設定されます。それ以外の構成では、すべて FIXED に設定されます。この値を RR に設定すると、最適化されたすべてのアクティブなパスで負荷を分散できます。FIXED は、 ALUA に対応していない従来の構成用の値で、プロキシ I/O を防止できますつまり、Data ONTAP 7-Modeを実行する環境でハイアベイラビリティ（HA）ペアの他方のノードにI/Oが送られないようにすることができます</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">すべての構成で 32 に設定されます。この値を設定すると、 I/O エラーの防止に役立ちます。</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">すべての構成で 8 に設定します。この値を設定すると、 I/O エラーの防止に役立ちます。</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">すべての iSCSI パスで RR （ラウンドロビン）に設定されます。この値を RR に設定すると、最適化されたすべてのアクティブなパスで負荷を分散できます。</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">すべての構成で 32 に設定されます。この値を設定すると、I/Oエラーの防止に役立ちます</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">VMware KB 86331</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">VMware vSphere ESXi 7.0.1およびVMware vSphere ESXi 7.0.2を使用する場合、1-NFSの高度な設定オプションMaxQueueDepthが想定どおりに機能しないことがあります。参照してください <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">* ONTAP ツール*</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">*デフォルト設定*</block>
  <block id="f639f9fbf0a0ec97e697dc20f2dec14f" category="sidebar">追加のNFSデータストアオプション</block>
  <block id="015a03470e91621621a76f7a4e3dc56e" category="sidebar">NFSデータストアとしてのANF：概要</block>
  <block id="8be166a6a918ed4074f79487db89b538" category="sidebar">補足的なNFSデータストア-プライベートプレビュー</block>
  <block id="5a9500ea180d9aa487f8a027550c1888" category="sidebar">追加のNFSデータストアの概要</block>
  <block id="5cc354638211ca59bc561a960afa71f9" category="sidebar">NFSデータストアの補足-パブリックプレビュー（Microsoft）</block>
  <block id="95fd29d87d2c7d3100a5198bc7067e95" category="sidebar">AVS用の補足的なNFSデータストア</block>
  <block id="e7e97f343a76aab098fd05b8953ee1a5" category="list-text">Azure VMware解決策 ホストへのAzure NetApp Files データストアの接続（プレビュー）</block>
  <block id="1838681ebe885a1a1e886cdf7e263065" category="inline-link"><block ref="1838681ebe885a1a1e886cdf7e263065" category="inline-link-rx"></block></block>
  <block id="2361f6fabb02c6060c638b5f1780cda2" category="paragraph"><block ref="2361f6fabb02c6060c638b5f1780cda2" category="inline-link-rx"></block></block>
  <block id="bcd4c93e63ff96ec357bc67c62874e0c" category="cell">2022年8月23日</block>
  <block id="10daf0bb04814721080056526de2b200" category="cell">NFSデータストアの追加オプションのすべてについて、使用可能な最新のリージョンを更新しました</block>
  <block id="9e779086e93810f8495caf5b07f578cd" category="paragraph">Microsoftは、AzureとAVS上でNFSデータストアの補足情報を提供します。まず、AVSとANFの両方が特定の地域で利用可能かどうかを確認する必要があります。次に、ANF補助NFSデータストアがそのリージョンでサポートされているかどうかを確認する必要があります。</block>
  <block id="8ff7e1fad21e60bbdef17593aae83ff6" category="list-text">AVSとANFの対応状況を確認します <block ref="757f75bead0b939967621d226ba54faa" category="inline-link-macro-rx"></block>。</block>
  <block id="2f53a51554f6e0b66622228f3db68361" category="list-text">ANF補助NFSデータストアが使用可能かどうかを確認します <block ref="02ba6bc5fe71be0f7426aedd427de443" category="inline-link-macro-rx"></block>。</block>
  <block id="926f20c82f92e797825f3ddf31c8d15b" category="paragraph">GCP/GCVE上でNFSデータストアを追加できるかどうかは、Googleによって定義されています。まず、特定の地域でGCVEとCVSの両方が利用可能かどうかを確認する必要があります。次に、そのリージョンでCVS補助NFSデータストアがサポートされているかどうかを確認する必要があります。</block>
  <block id="0970f21d33cd70a68d82d99f1d6abd42" category="list-text">GCVEとCVSの可用性を確認します <block ref="007e08d33d89c24a1316c16966bb4055" category="inline-link-macro-rx"></block>。</block>
  <block id="52d36923e6e7f21dede2a88e87bd5528" category="list-text">CVS補助NFSデータストアの可用性を確認する <block ref="007e08d33d89c24a1316c16966bb4055" category="inline-link-macro-rx"></block>。</block>
  <block id="46c2094fdbb2fbdc301a330fb7419074" category="paragraph">AWS / VMCで追加のNFSデータストアを使用できるかどうかは、Amazonによって定義されています。まず、VMCとFSxNの両方が指定されたリージョンで利用可能かどうかを確認する必要があります。次に、FSxNの補足的なNFSデータストアがそのリージョンでサポートされているかどうかを確認する必要があります。</block>
  <block id="c10e413ea65850b7369ee5ae6f60b460" category="list-text">VMCのFSxN補足的なNFSデータストアがまもなく利用可能になります。</block>
  <block id="a1838a4ac0f386c517d82fae26f2372e" category="paragraph">次の表に、情報がまだリリースされている間に、VMC、FSxN、およびFSxNの現在のサポート状況をNFSデータストアとして示します。</block>
  <block id="97be15a34c6b82b6177132129dd0b293" category="doc">Region Availability - VMCの補助的なNFSデータストア</block>
  <block id="0b6b52ed7135814c4a167640dee306f2" category="doc">リージョンの可用性–Google Cloud Platform（GCP）向けのNFSデータストア補足機能</block>
  <block id="e78040a1599894c3db7423e479a1f7d1" category="summary">クラウドへのディザスタリカバリは、耐障害性と対費用効果に優れた方法で、サイトの停止やランサムウェアなどのデータ破損からワークロードを保護します。NetApp SnapMirrorを使用すると、ゲスト接続ストレージを使用するオンプレミスのVMwareワークロードを、Google Cloudで実行されているNetApp Cloud Volumes ONTAP にレプリケートできます。</block>
  <block id="58997b61f0fc8812c9977a9dd3d181c5" category="doc">SnapCenter 、Cloud Volumes ONTAP 、Veeamレプリケーションを使用したアプリケーションディザスタリカバリ</block>
  <block id="0fa916b50826c2fab3e504331d6b8ad1" category="paragraph">執筆者：ネットアップSuresh Thoppay</block>
  <block id="366fe59477118cc36e7ef7936cc04771" category="paragraph">クラウドへのディザスタリカバリは、耐障害性と対費用効果に優れた方法で、サイトの停止やランサムウェアなどのデータ破損からワークロードを保護します。NetApp SnapMirrorを使用すると、ゲスト接続ストレージを使用するオンプレミスのVMwareワークロードを、Google Cloudで実行されているNetApp Cloud Volumes ONTAP にレプリケートできます。これはアプリケーションデータに適用されますが、実際のVM自体についてはどうでしょうか。ディザスタリカバリは、仮想マシン、VMDK、アプリケーションデータなど、依存するすべてのコンポーネントを対象にする必要があります。これを実現するために、SnapMirrorとVeeamを併用すれば、オンプレミスからCloud Volumes ONTAP にレプリケートしたワークロードをシームレスにリカバリしながら、VM VMDKにvSANストレージを使用することができます。</block>
  <block id="93fb0db9f34ab708d4c3e5d233e4d97f" category="paragraph">このドキュメントでは、NetApp SnapMirror、Veeam、Google Cloud VMware Engine（GCVE）を使用してディザスタリカバリを設定および実行するためのステップバイステップ形式のアプローチについて説明します。</block>
  <block id="669129cbcdc854bf23fe7e672be9c44c" category="paragraph"><block ref="669129cbcdc854bf23fe7e672be9c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c611c3f34a5f506ad20f441b78810981" category="paragraph">オンプレミス環境とGoogle Cloudネットワーク間の接続には、専用のインターコネクトやCloud VPNなどの接続オプションを使用します。オンプレミスVLANの設計に基づいてセグメントを作成する必要があります。</block>
  <block id="b62c675a3e45635be4cc5a65dde4c55c" category="admonition">オンプレミスのデータセンターをGoogle Cloudに接続する方法は複数ありますが、この方法では、このドキュメントの特定のワークフローの概要を説明することはできません。オンプレミスからGoogleへの適切な接続方法については、Google Cloudのドキュメントを参照してください。</block>
  <block id="5e345ef39956138694764fce9921e498" category="list-text">Veeamソフトウェアをインストールし、Google Cloud VMware Engineインスタンスへの仮想マシンのレプリケーションを開始します。</block>
  <block id="7c6d17fe855de9f3821d0cead78f4d26" category="list-text">災害発生時は、Cloud Managerを使用してSnapMirror関係を解除し、仮想マシンとVeeamのフェイルオーバーをトリガーします。</block>
  <block id="e36e9213012a15c95ec5048a09f751b0" category="list-text">アプリケーションをオンラインにします。</block>
  <block id="820f3ffde5403dbc2ca3d17b511f569e" category="example-title">Google CloudでCVOを構成し、ボリュームをCVOにレプリケート</block>
  <block id="6765d7341fa9566a047031c62d2040b8" category="inline-link">CVOを確認して</block>
  <block id="14cdb7188d3a5edcc69cb9fe2ebf708b" category="paragraph">最初の手順は、Google CloudでCloud Volumes ONTAP を設定することです <block ref="21dbe7906aa79142ad8a44237d3d84a5" category="inline-link-rx"></block>）をクリックし、必要なボリュームを、必要な頻度とSnapshotの保持を使用してCloud Volumes ONTAP にレプリケートします。</block>
  <block id="1b6eb09708583df3feb79dd7e7b9ed2a" category="paragraph"><block ref="1b6eb09708583df3feb79dd7e7b9ed2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b67ee8de7f0f6f1b68e41ce4be6b4a0b" category="inline-link">SnapCenter を使用してレプリケーションを設定する</block>
  <block id="8064e6b40ef12da2c44763dcfe735ae8" category="paragraph">SnapCenter の設定およびデータのレプリケートの手順の例については、を参照してください<block ref="68793c30d3c5e8a024de6c79bc478fe1" category="inline-link-rx"></block></block>
  <block id="5a101eac27a34cdc3b06c105760d0cee" category="example-title">GCVEホストとCVOデータアクセスを設定する</block>
  <block id="1fe9f40218e52161bc5e31e2cd383a0b" category="paragraph">SDDCを導入する際に考慮すべき2つの重要な要素は、GCVE解決策 のSDDCクラスタのサイズと、SDDCの稼働時間です。ディザスタリカバリ解決策 に関する以下の2つの重要な考慮事項は、全体的な運用コストの削減に役立ちます。SDDCは、3台のホストの規模に対応し、フルスケールの導入ではマルチホストクラスタにまで対応できます。</block>
  <block id="4f7b492a9eedf950f4dbd01357b22979" category="paragraph">Cloud Volumes ONTAP は任意のVPCに導入でき、GCVEはそのVPCへのプライベート接続でiSCSI LUNに接続する必要があります。</block>
  <block id="727eadb1fcad984cfa778a04f2181408" category="paragraph">GCVE SDDCを設定するには、を参照してください<block ref="06e1fa19855b73b0e800850663f265a2" category="inline-link-rx"></block>。前提条件として、接続が確立された後で、GCVEホストに存在するゲストVMがCloud Volumes ONTAP からデータを使用できることを確認します。</block>
  <block id="fb75a211e033fa96e7f692258221c1da" category="paragraph">Cloud Volumes ONTAP とGCVEを適切に設定したら、Veeamのレプリケーション機能を使用して、Cloud Volumes ONTAP へのアプリケーションボリュームコピーにSnapMirrorを利用することで、オンプレミスのワークロードのGCVE（アプリケーションVMDKおよびゲストストレージを搭載したVM）へのリカバリを自動化するようにVeeamを設定します。</block>
  <block id="87e3cc18e14b0d78c8c46e3ed343fca7" category="example-title">Veeamコンポーネントをインストールします</block>
  <block id="60fec867397af265e1e757d06135859e" category="example-title">VMレプリケーションをVeeamとセットアップする</block>
  <block id="d81c3dfdfda7fb8581660b5d218c6a3a" category="inline-link">vSphere VMレプリケーションジョブをセットアップします</block>
  <block id="6a67b79523a52a3a2b4e485485456565" category="paragraph">オンプレミスのvCenterとGCVEのvCenterをVeeamに登録する必要があります。<block ref="9af60ccd7c779b77ba6ce43ae96a95f6" category="inline-link-rx"></block> ウィザードの[ゲスト処理]ステップで、[アプリケーション対応のバックアップとリカバリにSnapCenter を使用するので、アプリケーション処理を無効にする]を選択します。</block>
  <block id="34510608302d692ff6f3936359703d26" category="example-title">Microsoft SQL Server VMのフェイルオーバー</block>
  <block id="ce137de4140fd114a7fb3fcb057328fa" category="list-text">Veeam Replicationでは、DRサイトのVMのIPアドレスを変更できます。</block>
  <block id="dee7570423fb41bfa5f00fd539ed91da" category="doc">Region Availability - ANFの補助的なNFSデータストア</block>
  <block id="9e289e2a1ce460725108e7241e19b575" category="doc">Region Availability：AWS、Azure、GCPのNFS補足データストア</block>
  <block id="3ce209dcd58ed0c7d8cf39f37f2b1557" category="paragraph">AWS、Azure、Google Cloud Platform（GCP）でのNFSデータストアの補足サポートについては、Global Regionを参照してください。</block>
  <block id="f22705ef66107a528d4982aa8fdd463d" category="list-text"><block ref="f22705ef66107a528d4982aa8fdd463d" category="inline-link-macro-rx"></block></block>
  <block id="e9063f3c3631446cbaeef19e7965f491" category="sidebar">SnapCenter 、CVO、Veeamレプリケーションを活用したアプリケーションディザスタリカバリ</block>
  <block id="d15aa19396a83c3c15a1fb8ba83efda1" category="cell">2022年8月25日</block>
  <block id="f37741764b2517136f3747b14ec803a0" category="cell">新しい解決策 ：ネットアップとVMwareによるNVIDIA AIエンタープライズ</block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterpriseは、AIとデータ分析ソフトウェアを提供するエンドツーエンドのクラウドネイティブスイートです。すべての組織がAIで成功できるように最適化されています。</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">ネットアップとVMwareによるNVIDIA AI Enterprise</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">ITアーキテクトや管理者にとって、AIツールの構築は複雑で、馴染みのない作業です。さらに、多くのAIプラットフォームはエンタープライズ対応ではありません。ネットアップとVMwareを基盤とするNVIDIA AI Enterpriseは、合理化されたエンタープライズクラスのAIアーキテクチャを提供するために開発されました。</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterpriseは、NVIDIA認定システムを搭載したVMware vSphere上で動作するようにNVIDIAによって最適化、認定、サポートされている、AIとデータ分析のためのエンドツーエンドのクラウドネイティブスイートです。AIワークロードの導入、管理、拡張を簡易化し、最新のハイブリッドクラウド環境で容易に実行できます。ネットアップとVMwareを基盤とするNVIDIA AI Enterpriseは、シンプルで使いやすいパッケージで、エンタープライズクラスのAIワークロードとデータ管理を実現します。</block>
  <block id="24c4078c95e6e2df55bd1d251c11f4aa" category="paragraph"><block ref="24c4078c95e6e2df55bd1d251c11f4aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d92209f7d0eac282a9a26e642c20a91" category="inline-link-macro">次のステップ：テクノロジの概要</block>
  <block id="51624dfcafe192d37d40a363ccfa4260" category="paragraph"><block ref="51624dfcafe192d37d40a363ccfa4260" category="inline-link-macro-rx"></block></block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA AI Enterprise with NetApp and VMware -テクノロジの概要</block>
  <block id="bdab293b91374abd32d30076de9d29b9" category="paragraph"><block ref="bdab293b91374abd32d30076de9d29b9" category="inline-link-macro-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="section-title">NVIDIA AIエンタープライズ</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterpriseは、NVIDIA認定システムを搭載したVMware vSphere上で動作するようにNVIDIAによって最適化、認定、サポートされている、AIとデータ分析のためのエンドツーエンドのクラウドネイティブスイートです。AIワークロードの導入、管理、拡張を簡易化し、最新のハイブリッドクラウド環境で容易に実行できます。</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGCは、AIソリューションの開発に従事するAI担当者向けに最適化されたGPUソフトウェアのカタログをホスティングします。また、モデルトレーニング用のNVIDIA Baseコマンド、モデルを導入および監視するためのNVIDIA Fleetコマンド、独自のAIソフトウェアに安全にアクセスして管理するためのNGC Private Registryなど、さまざまなAIサービスにアクセスできます。また、NVIDIA AI Enterpriseをご利用のお客様は、NGCポータルからサポートをリクエストできます。</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphereは、CPU、ストレージ、およびネットワークリソースを含む集約されたコンピューティングインフラにデータセンターを変革する、VMwareの仮想化プラットフォームです。vSphereは、これらのインフラを統合運用環境として管理し、管理者がその環境に含まれるデータセンターを管理するためのツールを提供します。</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">vSphereの中核となるコンポーネントは、ESXiとvCenter Serverの2つです。ESXiは、管理者が仮想マシンと仮想アプライアンスを作成して実行する仮想化プラットフォームです。vCenter Serverは、管理者がネットワークに接続された複数のホストを管理し、ホストリソースをプールするためのサービスです。</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ネットアップが提供する最新世代のストレージ管理ソフトウェアONTAP 9を使用すれば、インフラを最新化し、クラウド対応のデータセンターに移行できます。ONTAP は、業界をリードするデータ管理機能を活用して、データの格納場所に関係なく、単一のツールセットでデータの管理と保護を実現します。エッジ、コア、クラウドなど、必要な場所に自由にデータを移動することもできます。ONTAP 9には、データ管理の簡易化、重要なデータの高速化と保護、ハイブリッドクラウドアーキテクチャ全体で次世代インフラ機能を実現する多数の機能が搭載されています。</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">NetApp DataOpsツールキットは、高性能なスケールアウトネットアップストレージを基盤とする開発/トレーニング用ワークスペースと推論サーバの管理を簡易化するPythonベースのツールです。主な機能は次のとおりです。</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">ハイパフォーマンスでスケールアウト可能なネットアップストレージを基盤とする、大容量のJupyterLabワークスペースを迅速にプロビジョニングできます。</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">エンタープライズクラスのネットアップストレージを基盤とする新しいNVIDIA Triton Inference Serverインスタンスを迅速にプロビジョニング</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">実験的または迅速な反復を可能にするために、大容量のJupyterLabワークスペースをほぼインスタンス化してクローニングします。</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">大容量JupyterLabワークスペースのスナップショットをほぼインスタンスで保存し、バックアップやトレーサビリティ/ベースライン設定を実現します。</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">ほぼインスタンス化することなく、大容量でハイパフォーマンスなデータボリュームをプロビジョニング、クローニング、およびSnapshot作成する。</block>
  <block id="263db194560bc66bd5de27c72f9b7923" category="paragraph"><block ref="263db194560bc66bd5de27c72f9b7923" category="inline-link-macro-rx"></block></block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">ネットアップとVMwareアーキテクチャを基盤とするNVIDIA AI Enterprise</block>
  <block id="9ca68ac69c80fa519c5ead343d865ce4" category="inline-link-macro">前のページ：テクノロジの概要</block>
  <block id="ab7d7704700b22bf8dd4ce26b09e2562" category="paragraph"><block ref="ab7d7704700b22bf8dd4ce26b09e2562" category="inline-link-macro-rx"></block></block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">この解決策 は、ネットアップ、VMware、NVIDIA認定システムを使用した、実績のある馴染みのあるアーキテクチャを基盤としています。詳細については、次の表を参照してください。</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">AIとデータ分析ソフトウェア</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">NVIDIA AI Enterprise for VMware</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">仮想化プラットフォーム</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">コンピューティングプラットフォーム</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">NVIDIA認定システム</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">Data Management Platformの略</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="121c96ce43abda774fe95c1ccde1603e" category="paragraph"><block ref="121c96ce43abda774fe95c1ccde1603e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23a5db9f9241f7132df83ceacee13eb5" category="inline-link-macro">次の手順：初期セットアップ。</block>
  <block id="65ee66895a5d90d6bde80ce787a7e3b7" category="paragraph"><block ref="65ee66895a5d90d6bde80ce787a7e3b7" category="inline-link-macro-rx"></block></block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">ネットアップとVMwareによるNVIDIA AI Enterprise -追加情報 の詳細</block>
  <block id="77b8a01d0d63ff78898858cf688363c3" category="inline-link-macro">前の例：「Case - TensorFlow Training Job」</block>
  <block id="14b2e29c23cc5c2fbf0ecfe2c97d9919" category="paragraph"><block ref="14b2e29c23cc5c2fbf0ecfe2c97d9919" category="inline-link-macro-rx"></block></block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA AI Enterprise with VMware</block>
  <block id="5fad8e8f46a27398d761d66b0cb3f138" category="paragraph"><block ref="b79ccae54733d96b388303db61e85c7c" category="inline-link-rx"></block>]</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen、Sr.ネットアップ、マネージャー</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">ネットアップ、システム管理者、Ramesh Isaac氏</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">ネットアップ、テクニカルマーケティングエンジニア、Roney Daniel氏</block>
  <block id="ffdaf4e44bdc58181aaa1fb09d821794" category="summary">NVIDIA AI Enterpriseとネットアップ、VMwareを併用- NVIDIA NGCソフトウェアを利用</block>
  <block id="a99b0f81ba7eb4c3316c034815d10d6f" category="doc">NVIDIA NGCソフトウェアを利用</block>
  <block id="c9af43d59068b9518707160eb6b96225" category="inline-link-macro">前へ：初期セットアップ。</block>
  <block id="594eb3d3a076d44ee9951aa997704c5a" category="paragraph"><block ref="594eb3d3a076d44ee9951aa997704c5a" category="inline-link-macro-rx"></block></block>
  <block id="4161955dbf0998e264bc502f3cedc932" category="paragraph">このセクションでは、NVIDIA AI Enterprise環境でNVIDIA NGCエンタープライズソフトウェアを利用するために実行する必要があるタスクについて説明します。</block>
  <block id="cdc25880ca2e070e7e8937596a923a72" category="inline-link-macro">次の手順：セットアップ。</block>
  <block id="990700dce54370c3a1bca7246dfa67a2" category="paragraph"><block ref="990700dce54370c3a1bca7246dfa67a2" category="inline-link-macro-rx"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">ネットアップとVMwareを利用するNVIDIA AI Enterprise - NVIDIA NGCソフトウェアを利用-セットアップ</block>
  <block id="d0dad2e446397223579c27c4071bd112" category="inline-link-macro">以前：NVIDIA NGCソフトウェアを利用</block>
  <block id="149dec50621ec3639bea5fc28effa6cf" category="paragraph"><block ref="149dec50621ec3639bea5fc28effa6cf" category="inline-link-macro-rx"></block></block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">このセクションでは、NVIDIA AI Enterprise環境でNVIDIA NGCエンタープライズソフトウェアを利用するために実行する必要がある初期セットアップタスクについて説明します。</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="inline-link-macro">初期セットアップ</block>
  <block id="512338e48541699ec73dae999f67080a" category="paragraph">このセクションで説明する手順を実行する前に、に記載されている手順に従ってNVIDIA AI Entrpriseホストソフトウェアがすでに導入されていることを前提としています <block ref="a8e4d2617194ed990c0124f2cc8aee91" category="inline-link-macro-rx"></block> ページ</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">vGPUを使用してUbuntuゲストVMを作成します</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">NVIDIA AI Enterprise導入ガイド</block>
  <block id="1d7d5c692ef1d70e3217e93bb16af99e" category="paragraph">まず、vGPUを使用してUbuntu 20.04ゲストVMを作成する必要があります。vGPUを使用してUbuntu 20.04ゲストVMを作成する場合は、の手順に従います <block ref="f5168fb76d8813fb2707289c4637d2ea" category="inline-link-macro-rx"></block>。</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">NVIDIA Guest Softwareをダウンロードしてインストールします</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">NVIDIA AI Enterpriseクイックスタートガイド</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">次に、前の手順で作成したゲストVMに必要なNVIDIAゲストソフトウェアをインストールします。必要なNVIDIAゲストソフトウェアをゲストVMにダウンロードしてインストールするには、のセクション5.1-5.4に記載されている手順に従います <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>。</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">セクション5.4で説明した検証タスクを実行するときは、ガイドの作成後にCUDAコンテナイメージが更新されているため、別のCUDAコンテナイメージバージョンタグを使用する必要がある場合があります。今回の検証では「nvidia / CUDA：11.0.3-base-ubuntu20.04」を使用しました。</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">AI /分析フレームワークコンテナをダウンロード</block>
  <block id="12a93794571377dc80b4be8c2f22349c" category="paragraph">次に、NVIDIA NGCからAIまたは分析フレームワークのコンテナイメージをダウンロードして、ゲストVM内で利用できるようにする必要があります。ゲストVM内でフレームワークコンテナをダウンロードするには、の手順に従います <block ref="26bd3715eff2817a0154bee58d883e27" category="inline-link-macro-rx"></block>。</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">NetApp DataOpsツールキットをインストールして設定します</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">次に、ゲストVM内で従来の環境にNetApp DataOpsツールキットをインストールする必要があります。NetApp DataOpsツールキットを使用すると、ONTAP システム上のスケールアウトデータボリュームをゲストVM内の端末から直接管理できます。ゲストVMにNetApp DataOpsツールキットをインストールするには、次のタスクを実行します。</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">pipをインストールします。</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">ゲストVM端末からログアウトし、再度ログインします。</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">NetApp DataOpsツールキットを設定する。この手順を完了するには、ONTAP システムのAPIアクセスの詳細が必要です。これらはストレージ管理者から入手する必要があります。</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">ゲストVMテンプレートを作成します</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">最後に、ゲストVMに基づいてVMテンプレートを作成する必要があります。このテンプレートを使用すると、NVIDIA NGCソフトウェアを使用するゲストVMをすばやく作成できます。</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">ゲストVMに基づいてVMテンプレートを作成するには、VMware vSphereにログインし、ゲストVM名をクリックして「Clone」を選択し、「Clone to Template...」を選択して、ウィザードに従います。</block>
  <block id="05e042a4870614727b5012704b95e5ec" category="paragraph"><block ref="05e042a4870614727b5012704b95e5ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ad90a409faffb6ba8eef6ec1658543c" category="inline-link-macro">次の例：「ユースケース- TensorFlowトレーニングジョブ」</block>
  <block id="2dbc93dcf9e19b9e4c3cdac9786d0d7d" category="paragraph"><block ref="2dbc93dcf9e19b9e4c3cdac9786d0d7d" category="inline-link-macro-rx"></block></block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NVIDIA AI Enterpriseとネットアップ、VMwareを利用- NVIDIA NGCソフトウェアを活用-ユースケース- TensorFlowトレーニングジョブの例</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">使用例- TensorFlowトレーニングジョブ</block>
  <block id="9e4efb6787f44fcab6b00e2afd36fcee" category="inline-link-macro">前へ：セットアップ。</block>
  <block id="fd157334647c1bdd933147dbf284f59e" category="paragraph"><block ref="fd157334647c1bdd933147dbf284f59e" category="inline-link-macro-rx"></block></block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">このセクションでは、NVIDIA AI Enterprise環境内でTensorFlowトレーニングジョブを実行するために実行する必要があるタスクについて説明します。</block>
  <block id="cd33d31cec93ae54705bbc90e8ffbc09" category="paragraph">ここで説明する手順を実行する前に、に記載されている手順に従ってゲストVMテンプレートを作成済みであることを前提としています <block ref="8c165f1fe6ca595dd726d3af3dcdf541" category="inline-link-macro-rx"></block> ページ</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">テンプレートからゲストVMを作成します</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">最初に、前のセクションで作成したテンプレートから新しいゲストVMを作成する必要があります。テンプレートから新しいゲストVMを作成するには、VMware vSphereにログインし、テンプレート名を右クリックして「このテンプレートからVMを新規作成...」を選択し、ウィザードに従います。</block>
  <block id="9739d298a43441a49ece0169468d720e" category="paragraph"><block ref="9739d298a43441a49ece0169468d720e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">データボリュームを作成してマウント</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">次に、トレーニングデータセットを格納する新しいデータボリュームを作成する必要があります。NetApp DataOpsツールキットを使用して、新しいデータボリュームを簡単に作成できます。次のコマンド例は、「ImageNet」という名前のボリュームを作成し、容量を2TBにしています。</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">データボリュームにデータを入力する前に、ゲストVM内でデータボリュームをマウントする必要があります。NetApp DataOpsツールキットを使用して、データボリュームを簡単にマウントできます。次のコマンド例は、前の手順で作成したボリュームをアンマウントしています。</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">データボリュームの取り込み</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">新しいボリュームのプロビジョニングとマウントが完了したら、トレーニングデータセットをソースの場所から取得して、新しいボリュームに配置できます。通常はS3またはHadoopのデータレイクからデータを取得する必要があり、場合によってはデータエンジニアの支援も必要になります。</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">TensorFlowトレーニングジョブを実行する</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">これで、TensorFlowトレーニングジョブを実行する準備が整いました。TensorFlowトレーニングジョブを実行するには、次のタスクを実行します。</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">NVIDIA NGC Enterprise TensorFlowコンテナイメージを取得します。</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">NVIDIA NGCエンタープライズTensorFlowコンテナのインスタンスを起動します。「-v」オプションを使用して、データボリュームをコンテナに接続します。</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">コンテナ内でTensorFlowトレーニングプログラムを実行します。次のコマンド例は、コンテナイメージに含まれるResNet-50トレーニングプログラムの実行例を示しています。</block>
  <block id="5a71d5119829b5c78d377ad1aa8a90a8" category="inline-link-macro">次へ：追加情報 の検索場所。</block>
  <block id="d5ca60148a0675b3abb83565cbf886d7" category="paragraph"><block ref="d5ca60148a0675b3abb83565cbf886d7" category="inline-link-macro-rx"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA AI Enterprise with NetApp and VMware -初期セットアップ</block>
  <block id="232b44c6dbb39fe55ed3d2ae7953c0ce" category="paragraph"><block ref="232b44c6dbb39fe55ed3d2ae7953c0ce" category="inline-link-macro-rx"></block></block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">このセクションでは、ネットアップとVMwareでNVIDIA AI Enterpriseを活用するために必要な初期セットアップタスクについて説明します。</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">NVIDIA AI Enterprise製品サポートマトリックス</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">ネットアップとVMware解決策 のドキュメント</block>
  <block id="bf44a799ea99e6a60d34e10561a03e4e" category="paragraph">ここで説明する手順を実行する前に、VMware vSphereとNetApp ONTAP が導入済みであることを前提としています。を参照してください <block ref="7fc42871bfcfe7310a97a725dca473d8" category="inline-link-macro-rx"></block> サポートされているvSphereのバージョンの詳細については、を参照を参照してください <block ref="627bf2e2dbf74de3f0be812563fb3ec4" category="inline-link-macro-rx"></block> NetApp ONTAP を使用したVMware vSphereの導入の詳細については、を参照してください。</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">NVIDIA AI Enterprise Host Softwareをインストールします</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">NVIDIA AI Entrpriseホストソフトウェアをインストールするには、のセクション1~4に記載されている手順に従います <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>。</block>
  <block id="cd110cdaa9b8e3838ddcbc34234a5317" category="inline-link-macro">次はNVIDIA NGCソフトウェアを活用</block>
  <block id="4a2f52c7b89633749f7644b851cb7bc6" category="paragraph"><block ref="4a2f52c7b89633749f7644b851cb7bc6" category="inline-link-macro-rx"></block></block>
  <block id="56991209ac6bc77f76e9e1828103cdfc" category="cell">ブログを追加- Amazon FSXストレージを使用して、ハイブリッドクラウドでOracleデータベースの運用を刷新しましょう</block>
  <block id="9f65880e605551f01ff1d2c03d3fa4c6" category="cell">2022年6月29日</block>
  <block id="304bc05c6debf3075c4f25dcffcf50bd" category="cell">WP-7357：『Oracle Database Deployment on EC2/FSX Best Practices』を追加</block>
  <block id="befb671d4726ae8f3ef8dab781033dcc" category="inline-link-macro">ストレージSnapshotを使用したOracleマルチテナントプラグイン可能なデータベースクローン</block>
  <block id="aeb79a141f3c3f603cee05dfa64277aa" category="inline-link-macro">Amazon FSXストレージでハイブリッドクラウドのOracleデータベース運用を刷新</block>
  <block id="a35641294527bf47526671d78d910a7e" category="list-text"><block ref="a35641294527bf47526671d78d910a7e" category="inline-link-macro-rx"></block></block>
  <block id="958dc0e3d1fcb4de4e8d506927ac81d3" category="sidebar">EC2/FSXのベストプラクティスに基づいたOracleデータベースの導入</block>
  <block id="9e2a9bc8a2f8e27bba893554318c300a" category="paragraph">リポジトリに対するすべての主要な変更（新しいソリューション、メジャーアップデート、新しいビデオ / デモなど）は、で追跡されます <block ref="62716531525ec9f2f5022745ce51b3a4" category="inline-link-macro-rx"></block>。</block>
  <block id="4d6f369fd362693ff1e7c02749ce60d9" category="example-title">JetStream DRをオンプレミスにインストールする方法</block>
  <block id="91a827791bf5a23c98b3d5c7a69fe4ac" category="example-title">プライベートクラウドにJetStream DR for AVSをインストールする方法</block>
  <block id="60e3a8b4e353d775c34a7d4d16b3d797" category="example-title">フェールオーバー/フェールバックの実行方法</block>
  <block id="a401c5c75859d12743686229123750bc" category="cell">2022/09/14</block>
  <block id="1063ab954566d1fe67239a1e96653a34" category="cell">AWS / VMCにNFSデータストアの追加オプションを追加しました</block>
  <block id="b7331610ced5770e91945f51e7656fcf" category="cell">ESXiおよびONTAP の推奨設定に「Reboot Required」情報を追加しました</block>
  <block id="b6f0b1a9bd2c9c15cf02f97ead58d81f" category="list-text">補足的なNFSデータストアとしてのFSX ONTAP</block>
  <block id="aa98d71f784cc09bb41639407a3263d5" category="inline-link-macro">VMCの追加のNFSデータストアオプション</block>
  <block id="d1a83ba46ad33cdd3fc8bd7a4e73176d" category="paragraph">詳細を表示します <block ref="faae832115390401ac20af18b263017a" category="inline-link-macro-rx"></block>。詳細を表示します <block ref="5f92906354f0392b0588cf1731a5faf9" category="inline-link-macro-rx"></block>。</block>
  <block id="7bf09ad035c9bf793d2fa043537aefb5" category="paragraph">詳細を表示します <block ref="cfba6c34c6cd33cf1694f8b48900db44" category="inline-link-macro-rx"></block>。詳細を表示します <block ref="a17693751f1eec7b9dedb49cf6a85cf2" category="inline-link-macro-rx"></block>。</block>
  <block id="483a9a3bc528f4d194f9f8f3d2a8411a" category="inline-link-macro">AVSの補足的なNFSデータストアオプション</block>
  <block id="7772cfe9c74977a26d43cfda8576ff1a" category="paragraph">詳細を表示します <block ref="b477b575563628f6202758f8f4d6ef57" category="inline-link-macro-rx"></block>。詳細を表示します <block ref="e443f734d29f2f5bbba9449696a3f3f6" category="inline-link-macro-rx"></block>。</block>
  <block id="026198900efc3d72ea20d8258c67523f" category="paragraph">詳細を表示します <block ref="c21bcdb7b1f85738a3211dff01d327ef" category="inline-link-macro-rx"></block>。詳細を表示します <block ref="266132cd9b913032bfeaea66cd238ea6" category="inline-link-macro-rx"></block>。</block>
  <block id="110493136fe9c9cec7895d42493cf949" category="doc">TR-4938：AWSにVMware CloudでNFSデータストアとしてAmazon FSX for ONTAP をマウント</block>
  <block id="fac58d9bf77947f6384b904919414388" category="paragraph">成功を収めている組織は、変革と刷新の道を歩んでいます。このプロセスの一環として、企業は通常、既存のVMwareへの投資を使用して、クラウドのメリットを活用し、プロセスの移行、バースト、拡張、ディザスタリカバリを可能なかぎりシームレスに実行する方法を模索しています。クラウドに移行するお客様は、柔軟性とバースト性、データセンターの終了、データセンターの統合、ライフサイクルの終了、合併、合併などのユースケースを評価する必要があります。 買収など。</block>
  <block id="040632d7dc15d3ff95c3010b585c825d" category="inline-link">最近の統合</block>
  <block id="d790d297409e3864a7ea5e89c42f2281" category="paragraph">VMware Cloud on AWSはお客様に独自のハイブリッド機能を提供するため、大多数のお客様に適していますが、ネイティブストレージの選択肢が限られているため、ストレージの負荷が高い組織での有用性が制限されています。ストレージはホストに直接関連付けられているため、ストレージを拡張する唯一の方法は、ホストを追加することです。これにより、ストレージを大量に消費するワークロードのコストを35～40%以上増加させることができます。このようなワークロードには、追加の処理能力ではなく、ストレージと分離されたパフォーマンスが必要ですが、追加のホストに料金を支払うことになります。ここでは、を行います<block ref="ce6e0c0e7e2ab2c5f159e9999125a0f1" category="inline-link-rx"></block> ONTAP 向けFSXは、VMware Cloud on AWSを使用して、大量のストレージとパフォーマンスを必要とするワークロードに最適です。</block>
  <block id="419a1659c567e39948d6e6e837c207d8" category="paragraph">次のシナリオを考えてみましょう。お客様は8台のホストで馬力を求めています（vCPU / vMem）が必要ですが、ストレージにも大きな要件があります。評価に基づいて、ストレージ要件を満たすために16台のホストが必要です。これにより、必要な容量をすべて追加購入するだけで、より多くのストレージが必要になるため、全体的なTCOが増加します。これは、移行、ディザスタリカバリ、バースト、開発/テストなど、あらゆるユースケースに当てはまります。 など。</block>
  <block id="477aa009d1d8f0ca50a38092473e92c8" category="paragraph">このドキュメントでは、AWS上のVMware Cloud用のNFSデータストアとしてONTAP 用のFSXをプロビジョニングして接続するために必要な手順を説明します。</block>
  <block id="dfc876546f6dc1183356f103bca8c9bf" category="section-title">接続オプション</block>
  <block id="96ebe87ba2bf6e2436936fad5261faee" category="paragraph">ここでは、ハイレベルな接続アーキテクチャと、ホストを追加することなくSDDCクラスタ内のストレージを拡張するために解決策 を実装するために必要な手順について説明します。</block>
  <block id="373604cc33724c808b5ea035d2c5d911" category="paragraph">Amazon FSX for NetApp ONTAP はフルマネージドサービスで、広く普及しているNetApp ONTAP ファイルシステムを基盤に、信頼性、拡張性、パフォーマンス、機能豊富なファイルストレージを提供します。Amazon FSX for NetApp ONTAP （Multi-AZ）は、フローティングIPアドレスを使用して、アベイラビリティゾーンレベルで障害が発生した場合にNASトラフィックのフェイルオーバー機能を有効にします。このIPアドレスはVPC CIDRアドレススペースの外部にあるため、ENIを介してSDDCにルーティングすることはできません。したがって、VMware Transit Connectを使用して、NASインターフェイスのフローティングIPアドレスに接続してください。</block>
  <block id="f86935ff4bae98bba5454898ea941c13" category="paragraph"><block ref="f86935ff4bae98bba5454898ea941c13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5dfb62423539055e813d9c1ad0de5ec" category="paragraph">導入手順の概要は次のとおりです。</block>
  <block id="a7e048390e1de16427d130135387bbfa" category="list-text">新しい指定VPCでAmazon FSX for ONTAP を作成します。</block>
  <block id="1f950f8c314491fa3429d8c2b47b567d" category="list-text">SDDCグループを作成します。</block>
  <block id="564e0792e18e12a265348716dc476e35" category="list-text">VMware Transit ConnectとTGWの添付ファイルを作成します。</block>
  <block id="6618150a8dc116ed81a57b9c0241d023" category="list-text">ルーティング（AWS VPCとSDDC）とセキュリティグループを設定する。</block>
  <block id="657ef96833b0b326d08849a14b70424f" category="list-text">NFSボリュームをデータストアとしてSDDCクラスタに接続します。</block>
  <block id="4950c77542ffaf6f7c4295f413cd34bf" category="inline-link-macro">AWSでのVMware Cloudの導入</block>
  <block id="38cb82c3cccc048a7afcc98467fce2aa" category="paragraph">ONTAP 用のFSXをNFSデータストアとしてプロビジョニングして接続する前に、まずCloud SDDC環境でVMwareをセットアップするか、またはv1.20以上にアップグレードした既存のSDDCを取得する必要があります。詳細については、を参照してください <block ref="8f2441f58c4fdf4959e58cb9afc7d8c0" category="inline-link-macro-rx"></block>。</block>
  <block id="fcb9956e91549e3dd62d5abdb369413b" category="admonition">ONTAP のFSXは、現在、ストレッチクラスタではサポートされていません。</block>
  <block id="ee377d68ed297e79a44797bf1a95c224" category="paragraph">このドキュメントでは、AWSでVMwareクラウドを使用してAmazon FSX for ONTAP を設定するために必要な手順について説明します。Amazon FSX for ONTAP は、アプリケーションワークロードとファイルサービスを導入および管理する優れたオプションを提供し、データ要件をアプリケーションレイヤとシームレスにすることでTCOを削減します。どのようONTAP なユースケースでも、オンプレミスからAWSにクラウドのメリット、一貫したインフラ、運用を迅速に実現するためには、AWS対応のVMwareクラウドとAmazon FSXを選択し、ワークロードの双方向の移動性、エンタープライズクラスの容量とパフォーマンスを実現できます。ストレージの接続に使用する一般的なプロセスと手順は同じです。新しい名前と同様に変更されたデータの位置にすぎないことを忘れないでください。ツールとプロセスはすべて変わらないので、Amazon FSX for ONTAP を使用すると、全体的な導入を最適化できます。</block>
  <block id="0f7e01a8024cd158b945c34799508470" category="paragraph">このプロセスの詳細については、詳細なウォークスルービデオをご覧ください。</block>
  <block id="e4d49e783d07283d117d34b32c4415cd" category="doc">AWSのNFSデータストアの追加オプション</block>
  <block id="b2e86378d41d58201dddc613a82c81e2" category="paragraph">VMware Cloudの準備が完了してAWS VPCに接続したら、接続元のVPCまたは既存のデフォルトVPCではなく、新しく指定したVPCにAmazon FSX for NetApp ONTAP を導入する必要があります。</block>
  <block id="b96e49fe229de5c473c616c913f822c8" category="inline-link">VMware Cloud内のSDDCグループの構成</block>
  <block id="ff5a4226923e95cf43bd31559660d1c8" category="paragraph">まず、SDDCが配置されている同じリージョンとアベイラビリティゾーンにVPCを追加で導入し、そのVPCにAmazon FSX for NetApp ONTAP を導入します。<block ref="5be76f2b0a93cb7fee056cbead96da1a" category="inline-link-rx"></block> コンソールを使用すると、FSX for ONTAP を導入する、新しく指定したVPCに接続するために必要なネットワーク設定オプションを使用できます。</block>
  <block id="61a4d8e132eda51933073e665a4eac93" category="admonition">FSX for ONTAP は、AWS SDDC上のVMwareクラウドと同じ可用性ゾーンに導入します。</block>
  <block id="55304a7521acfdd7143fb9cdb66a6344" category="paragraph">NetApp ONTAP ファイルシステム用のAmazon FSXを作成してマウントするには、次の手順を実行します。</block>
  <block id="1a8a81e4c4d14a95fc47e07b614950b5" category="list-text">Amazon FSXコンソール（https://console.aws.amazon.com/fsx/`）を開き、* Create file system *を選択して、* File System Creation *ウィザードを開始します。</block>
  <block id="ffd72149dd51740fcd4d150cabc5561f" category="list-text">[ファイルシステムタイプの選択]ページで、[*Amazon FSX for NetApp ONTAP *]を選択し、[次へ]をクリックします。[ファイルシステムの作成*]ページが表示されます。</block>
  <block id="e71747de43d70e18285f2764e5a036a6" category="paragraph"><block ref="e71747de43d70e18285f2764e5a036a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4817656b0e2a8e3ebdf2bd3377b2456" category="list-text">作成方法には、*標準作成*を選択します。</block>
  <block id="35eb19b4c782b6a9c50e35b42f8c1f8c" category="paragraph"><block ref="35eb19b4c782b6a9c50e35b42f8c1f8c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f47a2dd0d360703b1b45075c63cff1b" category="paragraph"><block ref="5f47a2dd0d360703b1b45075c63cff1b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="11dd82404551d7373785e4fcbc9b1005" category="list-text">Virtual Private Cloud（VPC）の「*ネットワーク」セクションで、ルートテーブルに加えて適切なVPCと優先サブネットを選択します。この場合は、ドロップダウンメニューからDemo-FSxforONTAP -VPCが選択されます。</block>
  <block id="a9bc1797cfb722fb8dbfec3b16f44cb9" category="paragraph"><block ref="a9bc1797cfb722fb8dbfec3b16f44cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a560e434862aec182aa626e0de6ca3a" category="list-text">暗号化キーの「* Security &amp; Encryption *」セクションで、ファイルシステムの保存データを保護するAWS Key Management Service（AWS KMS）暗号化キーを選択します。*File System Administrative Password*には'fsxadminユーザーの安全なパスワードを入力します</block>
  <block id="9626f8b41e6908a3873b72869026a9da" category="paragraph"><block ref="9626f8b41e6908a3873b72869026a9da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75f7834ca5cbd9bf6c7a2b2e5073b427" category="list-text">「* Default Storage Virtual Machine Configuration *」セクションで、SVMの名前を指定します。</block>
  <block id="7c32cf52ace07fb1672e72defde4ac61" category="admonition">GAでは4つのNFSデータストアがサポートされます。</block>
  <block id="5c732cc058a6b6d4676b55223bf85f5f" category="paragraph"><block ref="5c732cc058a6b6d4676b55223bf85f5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51ac4bf63a0c6a9cefa7ba69b4154ef1" category="cell">設定</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0%</block>
  <block id="a85c04491cb5bbcb534dc50b65b97530" category="cell">自動削除</block>
  <block id="4ec86a7059e3d1002a06c51cbec9ad47" category="cell">ボリューム/古い順に選択します</block>
  <block id="5987147997d274c5292cab0b0006bef1" category="cell">ボリューム階層化ポリシー</block>
  <block id="902c737cbaa1a86889c41fec210c805f" category="cell">最初に試行してください</block>
  <block id="f4c25546f220bb5d07f94244c9303967" category="cell">自動拡張</block>
  <block id="4c0abf2d4c54820b8d33061abaf30759" category="cell">スナップショットポリシー</block>
  <block id="7c031a8d1af863155f52c6a16c34e0c1" category="paragraph"><block ref="7c031a8d1af863155f52c6a16c34e0c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3216fa1649258260fcc7fb0c291ff2fb" category="paragraph"><block ref="3216fa1649258260fcc7fb0c291ff2fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2d2529841aebb478d3748c5528b4696" category="list-text">[ファイルシステムの作成]ページに表示されているファイルシステム構成を確認します。</block>
  <block id="a7f848b3fa508f3850a768505d8de438" category="list-text">[ファイルシステムの作成*]をクリックします。</block>
  <block id="8c63e014bdbc571ce93e6b93d628d4e2" category="paragraph"><block ref="8c63e014bdbc571ce93e6b93d628d4e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef936ea5a977520b22368e3dbad83818" category="paragraph"><block ref="ef936ea5a977520b22368e3dbad83818" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f36688b56a320d6a48574b6092329e26" category="paragraph">Amazon FSX for ONTAP のパフォーマンスについては、を参照してください<block ref="45a884cbefaf34ae6fd7defa1c6be8c3" category="inline-link-rx"></block>。</block>
  <block id="6d3e0252631c98651b062c2fc85ad936" category="example-title">手順2：SDDCグループを作成します</block>
  <block id="82fd9df68bd32ff1e24a66dc98b1e237" category="paragraph">ファイルシステムとSVMを作成したら、VMwareコンソールを使用してSDDCグループを作成し、VMware Transit Connectを設定します。これを行うには、次の手順を実行します。VMware Cloud ConsoleとAWSコンソールの間を移動する必要があります。</block>
  <block id="cfdf8bfdb817c09bbd04bc1f8aec640d" category="list-text">VMCコンソールにhttps://vmc.vmware.com`からログインします。</block>
  <block id="7959effd33c50a6257362d30f57326de" category="list-text">[*インベントリ*]ページで、[*SDDCグループ*]をクリックします。</block>
  <block id="b8f684e055bd625606633c09969e9540" category="list-text">[*SDDCグループ*]タブで、[*actions*]をクリックし、[*SDDCグループの作成*]を選択します。SDDCグループの名前は「FSxONTAPDatastoreGrp」です。</block>
  <block id="ab3ee4623c465cb9edfbfeccc6ca86ba" category="list-text">[メンバシップ]グリッドで、グループメンバとして含めるSDDCを選択します。</block>
  <block id="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="paragraph"><block ref="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4fa61cc3be19123a586bd1f8e29e6e" category="list-text">「Configuring VMware Transit Connect for your group will iss Charges per attachment and data transfers」（グループごとのVMwareトランジット接続の設定で添付ファイルおよびデータ転送ごとの料金が発生する）が選択されていることを確認し、「*グループの作成このプロセスが完了するまでに数分かかることがあります。</block>
  <block id="a3f9cb9f805a5c5abc39008c09a7f2b1" category="paragraph"><block ref="a3f9cb9f805a5c5abc39008c09a7f2b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b17d6992e86eba9b41dc8a123e6e8fb" category="example-title">手順3：VMware Transit Connectを設定します</block>
  <block id="dde50926302f7ec2015681d9c6a96817" category="inline-link">グループに外部VPCを接続する手順</block>
  <block id="8ebb2eb5630a76b1fe25c564158f80f6" category="list-text">新しく作成した代表VPCをSDDCグループに接続します。[* External VPC *（外部VPC *）]タブを選択し、に従います<block ref="b29559f9008e4efd51a29ebaa2e02912" category="inline-link-rx"></block>。このプロセスは、完了までに10～15分かかる場合があります。</block>
  <block id="ac3defa2f0f4566a77fa8a1608c03c29" category="paragraph"><block ref="ac3defa2f0f4566a77fa8a1608c03c29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633bd88abb0a911cad29e551387946b8" category="list-text">［*アカウントの追加*］をクリックします。</block>
  <block id="cec0191b59ccf1e88591a2c33ced8c4b" category="list-text">ONTAP ファイルシステム用のFSXのプロビジョニングに使用したAWSアカウントを指定します。</block>
  <block id="7dee7e783d13b6d5d415926ce0bfc306" category="list-text">[ 追加（ Add ） ] をクリックします。</block>
  <block id="6a61e881b78352ae03c966d62ea1556d" category="list-text">AWSコンソールに戻り、同じAWSアカウントにログインして、* Resource Access Manager *サービスページに移動します。リソース共有を承認するボタンがあります。</block>
  <block id="8fd6a12de6d9f24e91a89e003fe58ccd" category="paragraph"><block ref="8fd6a12de6d9f24e91a89e003fe58ccd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b5910ab3c7395246baf35589ead376f" category="admonition">外部VPCプロセスの一部として、AWSコンソールからResource Access Manager経由で新しい共有リソースへのアクセスを求められます。共有リソースは、VMware Transit Connectで管理されているAWS Transit Gatewayです。</block>
  <block id="48fb6ee0dcc903c5fcfb9d1b15f2e3ad" category="list-text">[*リソース共有を許可する*]をクリックします。</block>
  <block id="333af8dd6d2cdd37922abf85ebd7179a" category="paragraph"><block ref="333af8dd6d2cdd37922abf85ebd7179a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e8fd48c7d02ab11c26a3e1882fd465a" category="list-text">VMCコンソールに戻り、外部VPCが関連付けられた状態になっています。表示されるまでに数分かかることがあります。</block>
  <block id="49ba8c3245c3d07a0ed6167e466b43e1" category="example-title">手順4：中継ゲートウェイの接続を作成します</block>
  <block id="9db03aae4c3c9b489ffa8fc51242bb7e" category="list-text">AWSコンソールでVPCサービスページに移動し、FSXファイルシステムのプロビジョニングに使用したVPCに移動します。ここでは、右側のナビゲーションペインで*Transit Gateway Attachment*をクリックして、トランジットゲートウェイの添付ファイルを作成します。</block>
  <block id="6d37c5b21f24bcca6d12fc5042185d45" category="list-text">[*VPC Attachment*]で、[DNS Support]がオンになっていることを確認し、FSX for ONTAP が展開されているVPCを選択します。</block>
  <block id="1dcf4f0eabbad36654447dfb34f237b4" category="paragraph"><block ref="1dcf4f0eabbad36654447dfb34f237b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc8975fcad9c69f295fb15e5a13f2e40" category="list-text">[*トランジットゲートウェイの添付ファイルの作成*]をクリックします。</block>
  <block id="89483e202d4e3f304f821390c4a7a7cc" category="paragraph"><block ref="89483e202d4e3f304f821390c4a7a7cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2e46cdc573277625faad22330cf154f" category="list-text">VMware Cloud Consoleに戻り、SDDC Group &gt; External VPCタブに戻ります。FSXに使用するAWSアカウントIDを選択し、VPCをクリックして* Accept *をクリックします。</block>
  <block id="36fdbe9831a4d114b9917bcd89fac4c2" category="paragraph"><block ref="36fdbe9831a4d114b9917bcd89fac4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d94f2f6e446adaf149684973d365ee" category="paragraph"><block ref="c3d94f2f6e446adaf149684973d365ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a81e35637833161072f4311f3cb32ac5" category="admonition">このオプションが表示されるまでに数分かかることがあります。</block>
  <block id="08783cc975c3897f2fbd3671f2f82620" category="list-text">次に、[* Routes *]列の[* External VPC *]タブで、[* Add Routes *]オプションをクリックして、必要なルートを追加します。</block>
  <block id="028ce3dd99b949a311e20d5403f17103" category="list-text">ネットアップONTAP フローティングIPを含むAmazon FSXのフローティングIP範囲のルート。</block>
  <block id="40fd62af6ee711539f271fc7513146a5" category="paragraph"><block ref="40fd62af6ee711539f271fc7513146a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e007562e54d1b070168e2b77a1766fdc" category="paragraph"><block ref="e007562e54d1b070168e2b77a1766fdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="937e96f27b1c5759ad7123b60f3775db" category="example-title">手順5：ルーティング（AWS VPCとSDDC）とセキュリティグループを設定する</block>
  <block id="b484a2377e56c4c768b99fa1ba1b950a" category="list-text">AWSコンソールのVPCサービスページでVPCを検索し、VPCの* main * routeテーブルを選択して、SDDCに戻るルートを作成します。</block>
  <block id="a563a48fad77850ec5058bda722b322a" category="list-text">下部パネルでルートテーブルを参照し、*ルートの編集*をクリックします。</block>
  <block id="85f3b67e1c98b7869b12f779e5f02b51" category="paragraph"><block ref="85f3b67e1c98b7869b12f779e5f02b51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb26d090b870823ae62ed28050e3aa89" category="list-text">ルートの編集*パネルで、*ルートの追加*をクリックし、*トランジットゲートウェイ*と関連付けられたTGW IDを選択してSDDCインフラストラクチャのCIDRを入力します。[ 変更の保存 *] をクリックします。</block>
  <block id="99388849296a3bbf649a9a953c7ce7d5" category="paragraph"><block ref="99388849296a3bbf649a9a953c7ce7d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74b3770eecc791f1748634fe7f30e559" category="paragraph"><block ref="74b3770eecc791f1748634fe7f30e559" category="inline-image-macro-rx" type="image"></block></block>
  <block id="358c085fce4b273ef954f6147feeb2c8" category="admonition">SDDCインフラストラクチャのCIDRブロックを使用してインバウンドルールを更新します。</block>
  <block id="268ce11e03f9defefab0c436b3818aab" category="admonition">接続の問題を回避するために、VPC（FSX for ONTAP が存在する場合）のルートテーブルが更新されていることを確認します。</block>
  <block id="a3debdddc4080cea8851b37aee79d278" category="admonition">NFSトラフィックを受け入れるようにセキュリティグループを更新します。</block>
  <block id="492fa7be92a68b15ae3479a6542a7774" category="example-title">手順6：NFSボリュームをデータストアとしてSDDCクラスタに接続する</block>
  <block id="e91ba866f25c52426b4d551f9fa981ef" category="paragraph">ファイルシステムをプロビジョニングして接続を確立したら、VMware Cloud ConsoleにアクセスしてNFSデータストアをマウントします。</block>
  <block id="3c4c5dd0c54ac8e289c4fb955dfe019e" category="list-text">VMCコンソールで、SDDCの*ストレージ*タブを開きます。</block>
  <block id="b953143972b1f780c4334b7673a4c696" category="paragraph"><block ref="b953143972b1f780c4334b7673a4c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b525bd0f1409ea87d946684edb92331" category="list-text">attach datastore *をクリックし、必要な値を入力します。</block>
  <block id="ad7075e284143c915d4b8c07e499daa4" category="admonition">NFSサーバアドレスは、NFS IPアドレスです。このアドレスは、AWSコンソールのFSX &gt; Storage Virtual Machines（ストレージ仮想マシン）タブ&gt; Endpoints（エンドポイント）にあります。</block>
  <block id="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="paragraph"><block ref="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d13c0b52cc34c4f5571b5ea17a13e01" category="list-text">データストアの接続*をクリックして、データストアをクラスタに接続します。</block>
  <block id="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="paragraph"><block ref="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3387672e6f02f40253d603226e4fd8" category="list-text">次の図のようにvCenterにアクセスしてNFSデータストアを検証します。</block>
  <block id="30880d4531deb5f77cf22e65ed7f3bc8" category="paragraph"><block ref="30880d4531deb5f77cf22e65ed7f3bc8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff56eef7a458cc9250ee84cb0b8b3752" category="cell">FSX ONTAP の略<block ref="b9210f6aa16b7e370d59e02bd5b54f88" category="inline-link-macro-rx"></block></block>
  <block id="b2859c129ed9d2683658aaef48d31759" category="doc">&lt;解決策 名&gt;</block>
  <block id="4845fee41e2c9edce3bd46094fdb57a2" category="paragraph">作成者：&lt;名前&gt;、&lt;役職&gt;、&lt;会社&gt;</block>
  <block id="ef1e6887c579ba81dcedc3f4e3793cd2" category="section-title">対象者</block>
  <block id="46c04e63acdf5955295f68d8a963bfbd" category="paragraph">この解決策 は、&lt;Goal &gt;に関心のある&lt;role&gt;を対象としています。</block>
  <block id="1d00e7dce692e8dc3f6877f035e3a616" category="paragraph">または</block>
  <block id="b98cf6de800fd94a50eaa1fff8bfd974" category="section-title">解決策 テスト/検証環境</block>
  <block id="aca7234abb238eb8646973440eb294d3" category="paragraph">この解決策 のテストと検証は、最終的な導入環境と異なる場合があるラボで実施しました。詳細については、次のセクションを参照してください。</block>
  <block id="bb46e30937334302b789ae4644fdc412" category="image-alt">解決策 アーキテクチャ図</block>
  <block id="39f3ba4cf87d6a47181e787c275344e5" category="section-title">ハードウェア/ソフトウェアコンポーネント</block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">* ハードウェア *</block>
  <block id="619d009ae026df3741648cc5d1d82614" category="cell">&lt;ハードウェア名&gt;</block>
  <block id="295146e011d375f76fc8093d2a5f746a" category="cell">&lt;モデル/バージョン&gt;</block>
  <block id="18206c5add24b8898426959c811b779b" category="cell">詳細情報</block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*ソフトウェア*</block>
  <block id="b8b4ca3eb830ebaf39f536d59b342a79" category="cell">&lt;ソフトウェア名&gt;</block>
  <block id="192dcc5c64e1f37fd6c9e50a1b157443" category="cell">バージョン</block>
  <block id="94f04537971d7a4a561c607ec55952a2" category="section-title">その他の注意事項</block>
  <block id="5f8c710bd804698095dac1f01702f2dc" category="list-text">注1</block>
  <block id="b5be88cc2b21098a0407835f4cf72ead" category="list-text">注n</block>
  <block id="dd1d4adbfe73c3cd87fc248a003b05a0" category="section-title">解決策 の導入</block>
  <block id="335680aa8906e185cbdaebb23568afb0" category="example-title">手順1：&amp;lt;説明ステップ名&amp;gt;</block>
  <block id="8368bea2982e0341bdf3dd2e21ae59ba" category="list-text">タスク1.</block>
  <block id="246b81c0be9905296fd43f043d65acf9" category="list-text">タスクn</block>
  <block id="dc84800e606f171d76211870801056d9" category="example-title">手順2：&amp;lt;説明ステップ名&amp;gt;</block>
  <block id="1361b538eba6bc2813d883fde1eaa379" category="example-title">ステップn:&amp;lt;説明ステップ名&amp;gt;</block>
  <block id="b57b7771f6b9c2ff769c133b18814390" category="section-title">その他の導入オプション</block>
  <block id="43437c4ac7246d8571bf69d647faab0e" category="inline-link-macro">ドキュメントの概要</block>
  <block id="0da1d1196a3aec2a948937502374b5bb" category="list-text"><block ref="0da1d1196a3aec2a948937502374b5bb" category="inline-link-macro-rx"></block></block>
  <block id="71214e9c5af2e86babf8e62565a8dda2" category="inline-link-macro">別のドキュメントの概要</block>
  <block id="2757c805d63f926c06b19e462b16de69" category="list-text"><block ref="2757c805d63f926c06b19e462b16de69" category="inline-link-macro-rx"></block></block>
  <block id="2f9ce81cf9e5f73733bacd731daaedbc" category="sidebar">補足的なNFSデータストア：概要</block>
  <block id="cd9738c68373595541959c8e55ede29e" category="sidebar">補足的なNFSデータストア：オプション</block>
  <block id="00ec4042cd11b865f5a96645c8f6abca" category="sidebar">補足的なNFSデータストアとしてのFSX ONTAP ：概要</block>
  <block id="74fed8860f1d0399cb4c6a16b2510cd1" category="sidebar">VMC用の補足的なNFSデータストア</block>
  <block id="d251fcb24842564580e4c994b283538e" category="cell">FSxN/VMCおよびANF / AVSのTCO計算ツールとシミュレータへのリンクを追加</block>
  <block id="8625e1de7be14c39b1d14dc03d822497" category="sidebar">ツール</block>
  <block id="e5365f39437feb49b24eddfa73253c24" category="sidebar">FSX for ONTAP + VMC TCO計算ツール</block>
  <block id="4856ec39dcc21fb53484ef230701e66b" category="sidebar">FSX for ONTAP + VMC Simulatorの略</block>
  <block id="67c988a2e4a11132f6866cf0aff95568" category="sidebar">ANF + AVS TCO Calculator</block>
  <block id="faeff2a13624e3552e026ffcba1c35dc" category="sidebar">ANF + AVSシミュレータ</block>
  <block id="714163a53d8c9c62964e7d6931c1c9ec" category="admonition">接続されたVPCにFSX for ONTAP を導入することはできません。代わりに、新しい指定されたVPCに導入してから、SDDCグループを介してVPCをVMware Managed Transit Gateway（vTGW）に接続する必要があります。</block>
  <block id="d7641cecb55db2651063f3be07278b31" category="example-title">手順1：新しい指定のVPCにAmazon FSX for ONTAP を作成する</block>
  <block id="4e0c93d8fb3b7cedc4f8d92d8d692e85" category="admonition">データストアのサイズは、お客様によってかなり異なります。NFSデータストアごとの仮想マシンの推奨数は主観的ですが、各データストアに配置できるVMの最適な数は、さまざまな要因によって決まります。ほとんどの管理者が考慮するのは容量だけですが、VMDKに同時に送信されるI/Oの量は、全体的なパフォーマンスにとって最も重要な要因の1つです。オンプレミスのパフォーマンス統計を使用して、それに応じてデータストアボリュームのサイズを設定します。</block>
  <block id="2f0865bd1a50874390d074524829bfc4" category="admonition">接続されたVPCではなく、新しい指定のVPCであることを確認してください。</block>
  <block id="55431364d6f307d0c1adb83c07425d6c" category="admonition">デフォルトでは、ONTAP のFSXは、ファイルシステムのデフォルトのエンドポイントIPアドレス範囲として198.19.0.0/16を使用します。エンドポイントのIPアドレス範囲が、AWS SDDCのVMC、関連付けられたVPCサブネット、およびオンプレミスインフラと競合しないことを確認してください。よくわからない場合は、重複しない範囲を使用してください。</block>
  <block id="505582b625e19e5637e0557ad61b581e" category="list-text">「*デフォルトのボリューム構成*」セクションで、データストアに必要なボリューム名とサイズを指定し、「*次へ*」をクリックします。これはNFSv3ボリュームである必要があります。Storage Efficiency *の場合、「* enabled *」を選択して、ONTAP のStorage Efficiency機能（圧縮、重複排除、コンパクション）を有効にします。作成後、シェルを使用して、*_volume modify _*を使用して次のようにボリュームパラメータを変更します。</block>
  <block id="9fdea1f4f5c62c2485312ab231c865ee" category="cell">ボリュームギャランティ（スペースギャランティ形式）</block>
  <block id="bd03fce695997bf49af026bcb349a578" category="cell">なし（シンプロビジョニング）–デフォルトで設定されます</block>
  <block id="9399f3b9e96901f84ac3bd68deec8850" category="cell">fractional_reserve（フラクショナルリザーブ）</block>
  <block id="6b3edd41659df403c04fb39ee40b0b0a" category="cell">0%–デフォルトで設定されます</block>
  <block id="dfa2ec9e60d8028b01d021f862fb77da" category="cell">snap_reserve（percent-snapshot-space）</block>
  <block id="80c2511d74ccaf27c63f1b6c3aafb2dc" category="cell">オートサイズ（autosize-mode）</block>
  <block id="535a7e7f6a8dd82fa6603e44982e0525" category="cell">enabled–デフォルトで設定されます</block>
  <block id="df370ff95c6787552e774c17a2878b11" category="cell">Snapshotのみ–デフォルトで設定されます</block>
  <block id="f072855ce664b2c9dd19371c8f451e72" category="paragraph">次のSSHコマンドを使用して、ボリュームを作成および変更します。</block>
  <block id="82bf57f964fd07a578454495c4ae3a34" category="paragraph">*新しいデータストアボリュームをシェルから作成するコマンド：*</block>
  <block id="3fe80d288dea7b9265abdfe33f302a9a" category="paragraph">*注：*シェルで作成したボリュームは、AWSコンソールに表示されるまでに数分かかります。</block>
  <block id="34b5a79399461f15942cc2bbb68ddb58" category="paragraph">*デフォルトで設定されていないボリューム・パラメータを変更するコマンド：*</block>
  <block id="8f2384de60fd85d0b57b92b82a7b1835" category="admonition">初期移行シナリオでは、デフォルトのSnapshotポリシーで原因 データストアの容量がフルの問題を解決できます。これを克服するには、必要に応じてSnapshotポリシーを変更します。</block>
  <block id="a19c957e90534613b36e90008ac1736c" category="admonition">容量とパフォーマンスの要件に従って、これまでの手順を繰り返し、SVMまたはファイルシステム、およびデータストアボリュームを作成します。</block>
  <block id="5659fbd7d9a7a1963d1f57717f874bcb" category="list-text">次の手順では、関連付けられたVPC内のセキュリティグループが、SDDCグループCIDRに対する正しいインバウンドルールで更新されていることを確認します。</block>
  <block id="381318b231b70d3c81a3bb05e8912be3" category="paragraph">これは、適切なSDDCへの接続を準備する最後のステップです。ファイルシステムを構成し、ルートを追加し、セキュリティグループを更新したら、次にデータストアをマウントします。</block>
  <block id="e60de72a8067fd05498b03b24d9f93e7" category="paragraph">この解決策 は、次のユースケースに対応します。</block>
  <block id="50f68cc3bee11411ba8ee639a7ed59d7" category="list-text">&lt;ユースケース1&gt;</block>
  <block id="bfbe592724efe7b70f86b50a78741381" category="list-text">&lt;ユースケースn&gt;</block>
  <block id="732f94f3061dc1751b3c7e3ea8566239" category="paragraph">この解決策 は、次のものを対象としています。</block>
  <block id="dab739113e8cfebbcfcfaea1515c0bcf" category="list-text">&lt;役割&gt;様、&lt;目標&gt;に関心のある方、</block>
  <block id="7367185552beb127edfea2f14982e67f" category="list-text">&lt;役割&gt;：&lt;目標&gt;に関心をお持ちの方。</block>
  <block id="71b51633ceea83cdf1136196fce39901" category="admonition">Cloud Volumes ONTAP をAWS VMCに接続する方法としてサポートされているのは、ゲスト内ストレージだけです。</block>
  <block id="9761d5208d76a88ba5a08152c4431c2f" category="admonition">Cloud Volumes ONTAP をAzure VMware解決策 に接続する方法としてサポートされているのは、ゲスト内ストレージだけです。</block>
  <block id="bb19e956b854f8e209f51237a29feb31" category="admonition">現在、Cloud Volumes ONTAP （CVO）をAWS VMCに接続する方法としてサポートされているのは、ゲスト内ストレージだけです。</block>
  <block id="36c48411397a73fcbe7ccac93862641b" category="admonition">本ドキュメントの作成時点で使用可能な唯一のオプションは、ゲスト内ストレージでした。NFSデータストアの補足サポートが提供されるようになりましたが、それ以外のドキュメントも提供されます <block ref="2feee9d08b57f121d415095bba26ae78" category="inline-link-macro-rx"></block>。</block>
  <block id="44db359cccfc9a14e67b800f405a2078" category="sidebar">自動化環境を設定します</block>
  <block id="1c08b76510a159f0dcb62c62d5584a78" category="paragraph"><block ref="1c08b76510a159f0dcb62c62d5584a78" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">このTRでは次の資料を参照しています。</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Apache Sparkのアーキテクチャとコンポーネント</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Apache Sparkのユースケース</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="506326e78695dcca6de9cbc14a77c5b7" category="list-text">Apacheの課題</block>
  <block id="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link"><block ref="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link-rx"></block></block>
  <block id="a4047ab5c68e6bd8f8ad5dfc79e46847" category="paragraph"><block ref="a4047ab5c68e6bd8f8ad5dfc79e46847" category="inline-link-rx"></block></block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="list-text">SparkのNLPです</block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">広告クリック予測のためのディープおよびクロスネットワーク</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link"><block ref="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link-rx"></block></block>
  <block id="c0ce2c750c3848619c847bc001ba66be" category="paragraph"><block ref="c0ce2c750c3848619c847bc001ba66be" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">ストリーミングETL</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">NetApp EシリーズHadoop向けソリューション</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="6e1ead71812900db964474f24a84ff5e" category="list-text">顧客コミュニケーションからネットアップAIとの感情分析</block>
  <block id="270a8289ec3296709282f87be3043182" category="inline-link"><block ref="270a8289ec3296709282f87be3043182" category="inline-link-rx"></block></block>
  <block id="5d6e0d6396516ff7be3c4a58b49ef3a7" category="paragraph"><block ref="5d6e0d6396516ff7be3c4a58b49ef3a7" category="inline-link-rx"></block></block>
  <block id="a435d889d8c30f88d959b581e585cb98" category="inline-link"><block ref="a435d889d8c30f88d959b581e585cb98" category="inline-link-rx"></block></block>
  <block id="2e0db0f40c94a679b5a5692c131d03f4" category="paragraph"><block ref="2e0db0f40c94a679b5a5692c131d03f4" category="inline-link-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">DataOpsツールキット</block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">ネットアップには、FAS / AFF、Eシリーズ、Cloud Volumes ONTAP の3つのストレージポートフォリオがあります。AFF とONTAP を搭載したEシリーズは、Apache Spark搭載のHadoopソリューション向けに検証済みです。ネットアップのデータファブリックは、データ管理のサービスとアプリケーション（ビルディングブロック）を統合して、データのアクセス、制御、保護、セキュリティを実現します。</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">NetApp Sparkソリューションの概要</block>
  <block id="255ce02d0613433bc0a7c76f4afde71e" category="inline-link-macro">以前のバージョン：解決策 テクノロジ。</block>
  <block id="dd12a34c3b567f24a9da980ebdd52821" category="paragraph"><block ref="dd12a34c3b567f24a9da980ebdd52821" category="inline-link-macro-rx"></block></block>
  <block id="5e1c0d548834c9871fb6687dd0f1adab" category="paragraph">ネットアップには、FAS / AFF、Eシリーズ、Cloud Volumes ONTAP の3つのストレージポートフォリオがあります。AFF とONTAP を搭載したEシリーズは、Apache Spark搭載のHadoopソリューション向けに検証済みです。ネットアップのデータファブリックは、以下の図に示すように、データアクセス、制御、保護、セキュリティのためのデータ管理サービスとアプリケーション（ビルディングブロック）を統合しています。</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">データファブリックは、データ管理のサービスとアプリケーションを提供します。</block>
  <block id="84996abc8bbc3c77ef59d8a39c852d30" category="paragraph"><block ref="84996abc8bbc3c77ef59d8a39c852d30" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">* NetApp NFS 直接アクセス。 * 最新の Hadoop クラスタと Spark クラスタを、ソフトウェアやドライバの追加の必要なしに NetApp NFS ボリュームに直接アクセスできます。</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">* NetApp SnapMirrorテクノロジ。*オンプレミスとONTAP クラウドまたはNPSインスタンス間のデータ保護機能を提供します。</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">次の図は、Sparkの解決策 とネットアップストレージを示しています。</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">Sparkの解決策 とネットアップストレージ</block>
  <block id="0847e549ec9fd7e676ad66196c4210a2" category="paragraph"><block ref="0847e549ec9fd7e676ad66196c4210a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4d71ccd96e1b29bc3437c1cb6a245e" category="paragraph">ONTAP Spark解決策 は、既存の本番データへのアクセスを使用して、インプレース分析、AI、ML、DLのワークフローに、ネットアップNFSダイレクトアクセスプロトコルを使用しています。Hadoopノードで使用可能な本番データは、インプレース分析ジョブ、AIジョブ、MLジョブ、DLジョブを実行するためにエクスポートされます。データにアクセスしてHadoopノード内で処理することができ、NetApp NFSに直接アクセスするかどうかは関係ありません。Sparkでは、スタンドアロンのクラスタマネージャまたは「yarn」クラスタマネージャを使用して、「」を使用してNFSボリュームを構成できます<block ref="7667eac59549f5d64cbcc9214ea613f8" category="inline-link-rx"></block>。3つのユースケースに異なるデータセットを使用して検証しました。これらの検証の詳細については、「テスト結果」セクションを参照してください。 （XRef）</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">次の図は、NetApp Apache Spark / Hadoopストレージの位置付けを示しています。</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">NetApp Apache Spark / Hadoopストレージの位置付け。</block>
  <block id="5af92584fa4ab2b78abca73f9bbdcf42" category="paragraph"><block ref="5af92584fa4ab2b78abca73f9bbdcf42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">また、EシリーズSparkの解決策 、AFF / FAS ONTAP Spark解決策 、StorageGRID Spark解決策 の独自の機能を特定し、詳細な検証とテストを実施しました。ネットアップでは、今回の調査結果に基づいStorageGRID て、新規導入時と拡張性に優れた新規導入時にEシリーズ解決策 を使用し、既存のNFSデータを使用したインプレース分析、AI、ML、DL、DLのワークロードにはAFF / FAS解決策 を、オブジェクトストレージが必要な場合には最新のデータ分析に使用することを推奨しています。</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Sparkに対してネットアップのソリューションをお勧めしました。</block>
  <block id="d3deaa8bf3eb6619cb86d00d661a22e9" category="paragraph"><block ref="d3deaa8bf3eb6619cb86d00d661a22e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">データレイクは、分析、AI、ML、DLの各ジョブに使用できる、ネイティブ形式の大規模データセット用のストレージリポジトリです。Eシリーズ、AFF / FAS、StorageGRID SG6060 Sparkソリューション用のデータレイクリポジトリを構築しました。Eシリーズシステムでは、Hadoop SparkクラスタへのHDFSアクセスが提供されますが、既存の本番環境のデータには、NFSの直接アクセスプロトコルを通じてHadoopクラスタへアクセスされます。オブジェクトストレージに配置されるデータセットに対しては、NetApp StorageGRID によってS3とS3aのセキュアなアクセスが提供されます。</block>
  <block id="22ad538f7c0e01603f9410a9bdc10d04" category="inline-link-macro">次：ユースケースの概要</block>
  <block id="5de3601bc15319fca36066c272d6321d" category="paragraph"><block ref="5de3601bc15319fca36066c272d6321d" category="inline-link-macro-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">このページでは、主なAI、ML、DLのユースケースとアーキテクチャについて詳しく説明します。</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">AI、ML、DLの主なユースケースとアーキテクチャ</block>
  <block id="4204e74b027f3052d00f7e876556fd90" category="inline-link-macro">Previous：ユースケースの概要。</block>
  <block id="8fc7ffb01920f82159e7c7fc73617df5" category="paragraph"><block ref="8fc7ffb01920f82159e7c7fc73617df5" category="inline-link-macro-rx"></block></block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">主なAI、ML、DLのユースケースと手法は、以下のセクションに分類できます。</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">SparkのNLPパイプラインとTensorFlow分散推論です</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">次のリストには、データサイエンスコミュニティで採用されている最も一般的なオープンソースのNLPライブラリが、さまざまな開発レベルで含まれています。</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">Natural Language Toolkit（NLTK）</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block>。すべてのNLP手法に対応する完全なツールキットです。2000年代初頭から維持されています。</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">TextBLOB</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block>。NLTKとPatternの上に構築された使いやすいNLPツールPython API。</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">Stanford Core NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block>。Stanford NLP Groupが開発したJavaのNLPサービスとパッケージ。</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">Gensim氏</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block>。人間のトピックモデリングは、チェコデジタル数学ライブラリプロジェクトのPythonスクリプトの集合として開始されました。</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">スパレーシー</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block>。PythonとCythonを使用した、トランスフォーマ用GPUアクセラレーションを備えたエンドツーエンドの産業用NLPワークフロー。</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">Fasttextの場合</block>
  <block id="07ad1b642fbcf4cbc6f67e8f5b7ce593" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block>。FacebookのAI Research（Fair）ラボで作成された単語埋め込みや文分類の学習用の無料の軽量オープンソースNLPライブラリです。</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">Spark ML</block>
  <block id="27e7661d3fd9daf238bb981e30734c3c" category="paragraph">Spark NLPは、あらゆるNLPタスクと要件に対応する単一のユニファイド解決策 です。拡張性が高く、パフォーマンスが高く、精度の高いNLPベースのソフトウェアを、実稼働環境で使用できます。また、転移学習を活用し、研究やさまざまな業界における最新のアルゴリズムとモデルを実装しています。Sparkは上記のライブラリを完全にサポートしていないため、Spark NLPはの上に構築されました<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> Sparkの汎用インメモリ分散データ処理エンジンを、ミッションクリティカルな本番ワークフロー向けのエンタープライズクラスのNLPライブラリとして活用しよう。アノテータは、ルールベースのアルゴリズム、機械学習、TensorFlowを利用してディープラーニングの実装を強化しています。トークン化、レマタイ化、語幹化、部分読み上げタギング、名前付きエンティティー認識など、一般的なNLPタスクを取り上げますが、これらに限定されません。 スペルチェックと感情分析。</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">トランスフォーマー（BERT）の双方向エンコーダリプレゼンテーションは、NLPのトランスベースの機械学習技術です。事前トレーニングと微調整の概念を普及させました。BERTの変圧器アーキテクチャは機械翻訳から生まれたもので、回帰型ニューラルネットワーク（RNN）ベースの言語モデルよりも長期的な依存関係をモデル化します。また、マスク言語モデリング（MLM）タスクも導入されました。このタスクでは、すべてのトークンのランダムな15%がマスクされ、モデルによって予測され、真の双方向性が実現されます。</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">FinBert</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">ロイターTRRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">金融PhraseBankの</block>
  <block id="575e9b077146ddbbac786ed0a40a1a21" category="inline-link">財務ニュースの業況分析</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">ドキュメントDLについて説明する</block>
  <block id="8171f59448f55698ad8ecd07ce1633b6" category="paragraph">金融感情の分析は、専門的な言語と、その分野のラベル付けされたデータが不足しているために困難になっています。<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>事前に訓練されたBERTに基づく言語モデルであるBERTは、ドメインに適合しています<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block>、金融コーパス、およびラベル付けされたデータと微調整された(<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block>）を参照してください。研究者たちは、財務用語を使ってニュース記事から4、500件の文章を抽出した。次に、16人の専門家と修士の学生が、財務上の背景にポジティブ、ニュートラル、ネガティブのラベルを付けています。2016年から2020年までの間に、FinBERTと他の2つの事前トレーニングパイプライン（）を使用してNASDAQ企業収益の売上高記録の感情を分析するために、Sparkのエンドツーエンドのワークフローを構築しました<block ref="6d4ea12c876c5a993aa1b5d0f03f167f" category="inline-link-rx"></block>、<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block>）をSparkのNLPから取得します。</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">Spark NLPの基礎となるディープラーニングエンジンは、機械学習向けのエンドツーエンドのオープンソースプラットフォームであるTensorFlowです。モデル構築が容易で、どこでも堅牢なML生産を実現し、研究のための強力な実験を可能にします。このため、Sparkの「yarn cluster」モードでパイプラインを実行する場合、基本的には分散TensorFlowを実行し、1つのマスターノードと複数のワーカーノード、およびクラスタにマウントされたネットワーク接続型ストレージにわたって、データとモデルの並列化を行いました。</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Horovodの分散トレーニング</block>
  <block id="ba6c44669e2888938a004611469c95dc" category="inline-link">TR-3969：『NetApp Solutions for Hadoop』</block>
  <block id="6f5ab42847eab5c573282c94e51100a9" category="paragraph">MapReduce関連のパフォーマンスの中核となるHadoop検証は、TeraGen、TeraSort、TeraValidate、およびDFSIO（読み取りおよび書き込み）を使用して実行されます。に、TeraGenおよびTeraSortの検証結果を示します<block ref="c56c49d0c7359320f900743306997a3c" category="inline-link-rx"></block> Eシリーズおよび「ストレージ階層化」（xref）for AFF のセクションに記載されています。</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Hovorod on Spark（SparkでのHovorod</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">お客様からの要望に基づいて、Sparkを使用したトレーニングの配布は、さまざまなユースケースで最も重要なトレーニングの1つと考えています。このドキュメントでは、を使用しました<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> ネットアップのオンプレミス、クラウドネイティブ、ハイブリッドクラウドソリューションでSparkのパフォーマンスを検証するには、AFF ストレージコントローラ、Azure NetApp Files 、FAS StorageGRID をご利用ください。</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Horovod on Sparkパッケージは、Horovodの便利なラッパーを提供します。このラッパーはSparkクラスタで分散されたトレーニングワークロードを簡単に実行できるようにするものです。厳密なモデル設計ループでは、トレーニングデータと推論データが存在するSparkで、データ処理、モデルトレーニング、モデル評価がすべて行われます。</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Kagle Rossmann Store Sales</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">SparkでHorovodを実行するためのAPIには、高レベルのエスティメータAPIと低レベルの実行APIの2つがあります。どちらも、Sparkの実行者に対してHorovodを起動するために同じ基盤メカニズムを使用していますが、Estimator APIはデータ処理、モデルトレーニングループ、モデルチェックポイント、メトリック収集、および分散トレーニングを抽象化します。Horovod Spark Estimators、TensorFlow、Kerasを使用して、に基づくエンドツーエンドのデータ準備と分散トレーニングワークフローを実施しました<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> 競合他社</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">主なユースケースごとにPythonスクリプトを使用できます。</block>
  <block id="94f33f4ba60c5f66bf0c60c3e391a81b" category="paragraph">スクリプト「kers_spark_horovod_Rossmann _ estimator.py」は、のセクションにあります <block ref="9843d2ebe8b4d4385946214b6f8e40b8" category="inline-link-macro-rx"></block> 次の3つの部分で構成されます</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">最初の部分では、Kaggleが提供し、コミュニティが収集した最初のCSVファイルのセットを介して、さまざまなデータ前処理ステップを実行します。入力データは'Validation'サブセットとテストデータセットで構成されるトレーニングセットに分かれています</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">2番目の部分では、対数シグスモイド活性化関数とAdamオプティマイザを使用してKeras Deep Neural Network（DNN）モデルを定義し、Sparkに対してHorovodを使用してモデルの分散トレーニングを実行します。</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">3番目の部分では、検証セット全体の平均絶対エラーを最小化する最適なモデルを使用して、テストデータセットの予測を実行します。次に、出力CSVファイルが作成されます。</block>
  <block id="ca1ff924f88675800b52c7c1b223b4a2" category="inline-link-macro">「機械学習」</block>
  <block id="a67083c66285446e108268f795b72b24" category="paragraph">を参照してください <block ref="65cdc2076a502903b78fb8128fc1a214" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">CTR予測にKerasを使用したマルチワーカーディープラーニング</block>
  <block id="4debf96216c552af520b74d3d0d2f2dc" category="paragraph">ML プラットフォームとアプリケーションの最近の進歩により、現在は大規模な学習が注目されています。クリックスルー率（ CTR ）は、オンライン広告インプレッション数 100 件あたりの平均クリックスルー数（パーセンテージ）と定義されています。デジタルマーケティング、小売、 E コマース、サービスプロバイダなど、さまざまな業界やユースケースで重要な指標として広く採用されています。を参照してください<block ref="5e9febd4c244550b32d7bb781b595741" category="inline-link-rx"></block> Kubernetes、分散データETL、DaskおよびCUDA MLを使用したモデルトレーニングなど、CTRのアプリケーションとエンドツーエンドのクラウドAIワークフロー実装の詳細を確認できます。</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Criteo Terabyteのログデータセットをクリックします</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">このテクニカルレポートでは、別のを使用しました<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> （TR-4904を参照）。Kerasを使用した複数のワーカーによる分散型ディープラーニングで、Deep NetworkモデルとCross Network（DCN）モデルを使用したSparkワークフローを構築し、ログ損失エラー機能のパフォーマンスをベースラインSparkのSpark ML Logistic Regression(ログ記録的回帰)モデルと比較します。DCNは、制限された角度の効率的な機能の相互作用を効率的にキャプチャし、高度な非線形相互作用を学習し、手動によるフィーチャーエンジニアリングや完全な検索を必要とせず、計算コストも低くなります。</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">Webスケールのレコメンダシステムのデータはほとんどが個別に分類されるため、フィーチャーの探索には困難な大規模でスパースな機能スペースが必要になります。これは、大規模なシステムのほとんどをロジスティック回帰などの線形モデルに限定しています。しかし、予測可能な機能を頻繁に特定すると同時に、見過ごしていない機能やまれなクロス機能を調べることが、予測を適切に行うための鍵となります。線形モデルは単純で、解析可能で、簡単にスケール変更できますが、表現力は限られています。</block>
  <block id="793743a945a26aaa07de844420d013af" category="paragraph">一方、クロス機能は、モデルの表現力を向上させる上で重要であることが示されています。残念なことに、このような機能を特定するには、手動での機能開発や完全な検索が必要になることがよくあります目に見えない機能の相互作用を一般化することは、しばしば困難です。DCNのような十字型ニューラルネットワークを使用すると、自動で機能交差を明示的に適用することで、タスク固有の機能エンジニアリングを回避できます。クロスネットワークは複数のレイヤで構成されており、レイヤの深さによって高度な相互作用がプロバンスされます。各レイヤは、既存のレイヤに基づいて上位の相互作用を生成し、以前のレイヤからの相互作用を保持します。</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">Deep Neural Network（DNN；ディープニューラルネットワーク）は、さまざまな機能で非常に複雑なインタラクションをキャプチャすることを約束します。ただし、DCNと比較して、必要なパラメータの数は非常に多く、クロス機能を明示的に形成できず、一部のタイプの機能の相互作用を効率的に学習できない場合があります。クロスネットワークはメモリ効率が高く、実装も簡単です。クロスコンポーネントとDNNコンポーネントを共同でトレーニングし、予測機能のインタラクションを効率的に取り込み、Crito CTRデータセットで最先端のパフォーマンスを提供します。</block>
  <block id="9830e1f81f623b33106acc186b93374e" category="inline-link">ml</block>
  <block id="fefc70efb4580c1020c62303f76330f7" category="inline-link">ミリリブ</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">Deepctr</block>
  <block id="75e8e622ae2ef0cb646ef505a0b3f7be" category="paragraph">DCNモデルは、埋め込みレイヤーとスタッキングレイヤーから始まり、クロスネットワークとディープネットワークが並行して使用されます。次に、2つのネットワークからの出力を組み合わせた最終的な組み合わせレイヤを示します。入力データは、スパースフィーチャーとデンスフィーチャーを持つベクトルにすることができます。Sparkでは、その両方です<block ref="e0c7aa0ef7a63ea331cba99be2697841" category="inline-link-rx"></block> および<block ref="495fc8cfd173be827e5c6c8258a34e04" category="inline-link-rx"></block> ライブラリには「SparseVector」タイプが含まれます。したがって、ユーザーがそれぞれの機能やメソッドを呼び出す際には、2つの機能を区別し、注意することが重要です。CTR予測などのWebスケールの推薦システムでは、入力は主に「country = USA」などの分類的な機能です。このような機能は、多くの場合、1つのホットベクトルとしてエンコードされます。たとえば、「[0,1,0,..]」のようになります。「SparseVector」を使用したワン・ホット・エンコーディング（OHE）は、絶えず変化する語彙や拡大する語彙を持つ実世界のデータセットを扱う場合に便利です。で例を変更しました<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> 大きなボキャブラリを処理するために、DCNの埋め込みレイヤーとスタッキングレイヤーに埋め込みベクトルを作成します。</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Critoディスプレイ広告のデータセット</block>
  <block id="d05de658e793ee731e5a3782c453caa6" category="paragraph">。<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> 広告のクリックスルーレートを予測します。13の整数型の機能と、各カテゴリの基数が多い26の分類的な機能があります。このデータセットでは、入力サイズが大きいため、ログロスの0.001が実質的に大きく改善されています。大規模なユーザベースの予測精度がわずかに向上すると、企業の収益が大きく増加する可能性があります。データセットには7日間の11GBのユーザログが格納されており、これは約4100万レコードに相当します。Sparkのdataframe .randomSplit()関数を使用して、トレーニング用のデータ(80%)、クロス検証(10%)、およびテスト用の残りの10%をランダムに分割しました。</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCNは、Kerasを使用したTensorFlowに実装されました。DCNを使用したモデルトレーニングプロセスの実装には、次の4つの主要コンポーネントがあります。</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*データ処理と埋め込み。*ログトランスフォームを適用することで、リアルタイム機能が正規化されます。カテゴリフィーチャーの場合、寸法6×（カテゴリの基数）1/4の密度の高いベクトルにフィーチャーを埋め込みます。すべての埋め込み結果を次元1026のベクトルに連結します。</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*最適化* Adam Optimizerを使用してミニバッチ確率的最適化を適用しました。バッチサイズは512に設定されています。ディープネットワークにバッチ正規化が適用され、グラジエントクリップの基準が100に設定されました。</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*均一化。*私達はL2の均一化かドロップアウトが有効であることが見つけられなかったので早い停止を使用した。</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">* Hyperparameters*。非表示レイヤー数、非表示レイヤーサイズ、初期学習レート、およびクロスレイヤー数に基づくグリッド検索に基づく結果を報告します。非表示レイヤーの数は2～5で、非表示レイヤーのサイズは32～1024です。DCNの場合、クロスレイヤの数は1～6です。初期学習レートは0.0001から0.001に調整され、0.0001単位で増加しました。すべての実験は訓練ステップ150,000で早期停止を適用し、それを超えて過剰なフィッティングが発生し始めました。</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="ca099c15c1ba89f9956f37979064b6ea" category="inline-link">xDeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">自動内部（AutoInt</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="ebca0d5eb18ce917a3f0d2d49746eb3d" category="paragraph">DCNに加えて、CTRの予測に使用される他の一般的なディープラーニングモデルもテストしました<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block>、<block ref="dc65ad48383bc08407486976f4411f66" category="inline-link-rx"></block>、<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block>および<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block>。</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">検証に使用するアーキテクチャ</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">この検証では、4つのワーカーノードと1つのマスターノードにAFF-A800 HAペアを使用しました。すべてのクラスタ・メンバーを、10GbEネットワーク・スイッチを介して接続しました。</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">今回のNetApp Sparkの解決策 検証では、E5760、E5724、AFF-A800の3種類のストレージコントローラを使用しました。Eシリーズストレージコントローラは、12Gbps SAS接続の5つのデータノードに接続されました。AFF のHAペアストレージコントローラは、エクスポートされたNFSボリュームを10GbEでHadoopワーカーノードに接続することで提供します。Hadoopクラスタのメンバーは、Eシリーズ、AFF 、およびStorageGRID のHadoopソリューションで10GbE接続を介して接続されます。</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">検証に使用するアーキテクチャ。</block>
  <block id="2f2f17293788ab5e5b754a35afe8b3b5" category="paragraph"><block ref="2f2f17293788ab5e5b754a35afe8b3b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d69bb7b5d4a03684a8454a168278a99a" category="inline-link-macro">次の手順：テスト結果</block>
  <block id="8e32abf231872a250f5352294ee7f66d" category="paragraph"><block ref="8e32abf231872a250f5352294ee7f66d" category="inline-link-macro-rx"></block></block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">本ドキュメントでは、Apache Sparkのアーキテクチャ、お客様のユースケース、ビッグデータ分析と人工知能に関連するネットアップストレージポートフォリオについて説明します。また、一般的なHadoopシステムに対して業界標準のAI、機械学習、ディープラーニングツールを使用してさまざまなテスト結果を提示することで、適切なSpark解決策 を選択できます。</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570：『NetApp Storage Solutions for Apache Spark：Architecture、Use Cases、Performance Results』</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">ネットアップKarthikeyan Nagalingam、Rick Huang氏</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">本ドキュメントでは、Apache Sparkのアーキテクチャ、お客様のユースケース、ビッグデータ分析と人工知能（AI）に関連するネットアップストレージポートフォリオについて説明します。また、一般的なHadoopシステムに対して業界標準のAI、機械学習（ML）、ディープラーニング（DL）ツールを使用してさまざまなテスト結果を提示することで、適切なSpark解決策 を選択できます。まず、Sparkアーキテクチャ、適切なコンポーネント、2つの配置モード（クラスタとクライアント）が必要です。</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">このドキュメントでは、構成の問題に対処するためのユースケースも紹介しています。また、Sparkでのビッグデータ分析、AI、ML、DLに関連するネットアップのストレージポートフォリオの概要についても説明しています。その後、Spark固有のユースケースとNetApp Sparkの解決策 ポートフォリオから得られたテスト結果をご紹介します。</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">このセクションでは、小売、デジタルマーケティング、銀行業務、ディスクリート製造、プロセス製造などのデータ成長業界におけるビッグデータ分析とAI / ML / DLに関するお客様の課題に焦点を当てます。 政府機関やプロフェッショナルサービスも利用できます。</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">予測不可能なパフォーマンス</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">従来型のHadoop導入では、一般にコモディティハードウェアを使用します。パフォーマンスを向上させるには、ネットワーク、オペレーティングシステム、Hadoopクラスタ、Sparkなどのエコシステムコンポーネント、ハードウェアをチューニングする必要があります。それぞれのレイヤを調整しても、Hadoopは環境内のハイパフォーマンスを想定して設計されていないコモディティハードウェア上で実行されるため、必要なパフォーマンスレベルを達成することは困難です。</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">メディアおよびノードの障害</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">通常の状態でも、コモディティハードウェアは障害が発生しやすくなります。データノードの1つのディスクに障害が発生すると、Hadoopマスターはデフォルトでそのノードを正常な状態ではないとみなします。次に、レプリカから正常なノードに、そのノードからネットワーク経由で特定のデータをコピーします。このプロセスにより、Hadoopジョブのネットワークパケット速度が低下します。正常な状態に戻ったら、クラスタでデータを再度コピーしてレプリケートデータを削除する必要があります。</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Hadoopベンダーロックイン</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Hadoopディストリビュータは独自のバージョン管理機能を備えたHadoopディストリビューションを所有しており、これによってお客様はこれらのディストリビューションにロックされます。ただし、多くのお客様が、特定のHadoopディストリビューションにお客様を結び付けることのないインメモリ分析をサポートしている必要があります。ディストリビューションを自由に変更し、分析機能を活用する必要があります。</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">複数の言語をサポートしていない</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">MapReduce Javaプログラムに加えて、ジョブを実行するために複数の言語のサポートが必要になることがよくあります。SQLやスクリプトなどのオプションを使用すると、回答を取得する柔軟性が高まり、データを整理して取得するためのオプションが増え、データを分析フレームワークにすばやく移動できます。</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">使用の難しさ</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">しばらくの間、Hadoopが使いにくいとユーザからクレームを受けています。Hadoopは新しいバージョンが登場するたびにシンプルかつ強力になりましたが、今もこの批評家は存続しています。Hadoopを使用するには、JavaおよびMapReduceのプログラミングパターンを理解する必要があります。これは、データベース管理者や、従来のスクリプトスキルセットを持つユーザにとっての課題です。</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">複雑なフレームワークとツール</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">企業のAIチームは、さまざまな課題に直面します。導入エコシステムやアプリケーションごとに専門的なデータサイエンスの知識があるとしても、ツールやフレームワークは単に相互に変換されるわけではありません。データサイエンスプラットフォームは、Spark上に構築された対応するビッグデータプラットフォームとシームレスに統合する必要があります。データ移動が容易で、再利用可能なモデル、すぐに使えるコード、プロトタイプ作成、検証、バージョン管理、共有、再利用といったベストプラクティスに対応するツールを備えています。 また、モデルを迅速に本番環境に導入できます。</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">ネットアップを選ぶ理由</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">ネットアップでは、次の方法でSpark体験を向上させています。</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">NetApp NFSから直接アクセスする（次の図を参照）ことで、データを移動したりコピーしたりすることなく、既存または新規のNFSv3 / NFSv4データに対してビッグデータ分析ジョブを実行できます。データの複数のコピーが作成されるため、ソースとデータを同期する必要がありません。</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">ストレージ効率が向上し、サーバのレプリケーションが不要になります。たとえば、NetApp EシリーズHadoop解決策 にはデータのレプリカが3つではなく2つ必要であり、FAS Hadoop解決策 にはデータソースが必要ですが、データのレプリケーションやコピーは必要ありません。ネットアップのストレージソリューションは、サーバ間のトラフィックも削減します。</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">ドライブおよびノードの障害時のHadoopジョブとクラスタの動作が向上します。</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">データ取り込みのパフォーマンスが向上します。</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">別のApache Spark設定。</block>
  <block id="ce1f5d61aacdba15be898e2d6408542f" category="paragraph"><block ref="ce1f5d61aacdba15be898e2d6408542f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">たとえば、金融機関や医療機関では、ある場所から別の場所へデータを移動する際に法的義務を果たす必要がありますが、これは容易な作業ではありません。このシナリオでは、NetApp NFSから直接アクセスして、財務データと医療データを元の場所から分析します。もう1つの主なメリットは、NetApp NFS直接アクセスを使用することで、ネイティブのHadoopコマンドを使用してHadoopデータを簡単に保護できるようになることと、ネットアップの充実したデータ管理ポートフォリオでデータ保護ワークフローを実現できることです。</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">NetApp NFS直接アクセスでは、HadoopクラスタとSparkクラスタに対して次の2種類の導入オプションを提供しています。</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">デフォルトでは、HadoopクラスタまたはSparkクラスタは、データストレージとデフォルトのファイルシステムにHadoop Distributed File System（HDFS；Hadoop分散ファイルシステム）を使用しています。NetApp NFSから直接アクセスできるため、デフォルトのHDFSをデフォルトのファイルシステムとしてNFSストレージに置き換えることができ、NFSデータを直接分析できます。</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">もう1つの導入オプションでは、NetApp NFS直接アクセスを使用して、1つのHadoopクラスタまたはSparkクラスタ内でHDFSを追加のストレージとして構成することもできます。この場合、 NFS エクスポートを介してデータを共有し、 HDFS データと同じクラスタからデータにアクセスできます。</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">NetApp NFS直接アクセスを使用する主な利点は次のとおりです。</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">現在の場所からデータを分析することで、分析データをHDFSなどのHadoopインフラに移動するための時間とパフォーマンスのかかる作業を回避できます。</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">レプリカの数を3分の1から1に削減。</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">ユーザを分離してコンピューティングとストレージを分離し、個別に拡張</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">ONTAP の充実したデータ管理機能を活用して、エンタープライズデータを保護</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Hortonworksデータプラットフォームの認定。</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">ハイブリッドデータ分析の導入を実現</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">動的なマルチスレッド機能を活用してバックアップ時間を短縮</block>
  <block id="009b0bd3acc58fbc1c3db15692583fa9" category="paragraph">を参照してください<block ref="217abb9bc41aa22d30da41b7958b4152" category="inline-link-rx"></block> Hadoopデータのバックアップ、クラウドからオンプレミスへのバックアップ、ディザスタリカバリ、既存のHadoopデータに対するDevTestの有効化、データ保護とマルチクラウド接続の実現、分析ワークロードの高速化を実現します。</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">次のセクションでは、Sparkのお客様にとって重要なストレージ機能について説明します。</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">ストレージ階層化</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">Hadoopストレージ階層化を使用すると、ストレージポリシーに従ってさまざまなタイプのファイルを格納できます。ストレージ・タイプには' hot ''cold ''warm ''all_sssd ''one _sssd 'が含まれます 「lazy_persist`」。</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">次の図に、ネットアップのHadoop SSD向けソリューションのパフォーマンスを示します。</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">1TBのデータをソートする時間です。</block>
  <block id="55fdf8b2dd620bd73dcd37db50e0f0e5" category="paragraph"><block ref="55fdf8b2dd620bd73dcd37db50e0f0e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">TR-3969『NetApp Eシリーズ解決策 for Hadoop』</block>
  <block id="8cdadd1c9614abebd1b476daba691f36" category="list-text">ベースラインNL-SAS構成では、8つのコンピューティングノードと96本のNL-SASドライブを使用しました。この構成では、1TBのデータが4分38秒で生成され、を参照してください<block ref="f08cd7da48b5d74d9eaab10199016f47" category="inline-link-rx"></block> クラスタとストレージ構成の詳細については、を参照してください。</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">TeraGenを使用した場合、SSD構成ではNL-SAS構成よりも1TBのデータが15.66x高速で生成されました。さらに、SSD構成では、コンピューティングノードの半分とディスクドライブの半分（合計24本のSSDドライブ）が使用されていました。ジョブの完了時間に基づき、NL-SAS構成の約2倍の速さで処理されました。</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">パフォーマンスの拡張-スケールアウト</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">AFF 解決策 のHadoopクラスタの処理能力を強化する必要がある場合は、適切な数のストレージコントローラを使用してデータノードを追加できます。ワークロードの特性に応じて、ストレージコントローラアレイごとにデータノードを4つから始めて、ストレージコントローラごとにデータノードを8つに増やすことを推奨します。</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF とFAS はインプレース分析に最適です。コンピューティング要件に基づいて、ノードマネージャを追加できます。また、ノンストップオペレーション機能により、ダウンタイムなしでストレージコントローラをオンデマンドで追加できます。AFF とFAS を備えた豊富な機能を備えており、NVMeメディアのサポート、効率性の保証、データ削減、QoS、予測分析、 クラウドの階層化、レプリケーション、クラウドの導入、セキュリティお客様が要件を満たせるように、ネットアップでは、追加のライセンスコストなしでファイルシステム分析、クォータ、オンボックスロードバランシングなどの機能を提供しています。ネットアップは、同時ジョブ数やレイテンシの低減、処理の簡易化、1秒あたりのスループットの向上といった、競合他社よりも優れたパフォーマンスを提供しています。さらに、ネットアップのCloud Volumes ONTAP は、主要な3つのクラウドプロバイダすべてで動作します。</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">パフォーマンスの拡張-スケールアップ</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">ストレージ容量を追加する必要がある場合は、スケールアップ機能を使用して、AFF 、FAS 、およびEシリーズシステムにディスクドライブを追加できます。Cloud Volumes ONTAP を使用してストレージをPBレベルに拡張するには、使用頻度の低いデータをブロックストレージからオブジェクトストレージに階層化し、追加のコンピューティングなしでCloud Volumes ONTAP ライセンスをスタックするという2つの要素を組み合わせます。</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">複数のプロトコル</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">ネットアップシステムは、SAS、iSCSI、FCP、InfiniBandなど、Hadoop導入のほとんどのプロトコルをサポートしています。 およびNFSが必要です。</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">運用およびサポートされるソリューション</block>
  <block id="dc15faa991f0a6740734b42c6e08c347" category="inline-link">MapR</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">認定資格</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">パートナー</block>
  <block id="b1202a92f536818c64c3005cf78d8e35" category="paragraph">本ドキュメントに記載されているHadoopソリューションは、ネットアップによってサポートされています。これらのソリューションは、主要なHadoopディストリビュータでも認定されています。詳細については、を参照してください<block ref="cc609e66e0173716d91f0397bfa09e1b" category="inline-link-rx"></block> サイト、<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> サイト、Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> および<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> サイト：</block>
  <block id="7a2a776baec23a88727e6039089b8193" category="inline-link-macro">次のステップ：対象となるお客様</block>
  <block id="e8020665ce34622c78e50d808e554235" category="paragraph"><block ref="e8020665ce34622c78e50d808e554235" category="inline-link-macro-rx"></block></block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">TeraGenベンチマークツールでTeraSortおよびTeraValidateスクリプトを使用して、E5760、E5724、およびAFF-A800構成でのSparkのパフォーマンス検証を測定しました。さらに、SparkのNLPパイプラインとTensorFlow分散トレーニング、Horovod分散トレーニング、KerasによるディープFMでのCTR予測を使用した複数ワーカーのディープラーニングの3つの主なユースケースをテストしました。</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">テスト結果</block>
  <block id="0daa7dd4f2822f3e63bdac1bd5870a75" category="inline-link-macro">以前：主要なAI、ML、DLのユースケースとアーキテクチャ</block>
  <block id="26d27784aaeb94a4670d31f46185d57d" category="paragraph"><block ref="26d27784aaeb94a4670d31f46185d57d" category="inline-link-macro-rx"></block></block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">TeraGenベンチマークツールでTeraSortおよびTeraValidateスクリプトを使用して、E5760、E5724、およびAFF-A800構成でのSparkのパフォーマンス検証を測定しました。さらに、SparkのNLPパイプラインとTensorFlow分散トレーニング、Horovod分散トレーニング、Kerasを使用したディープFMでのCTR予測を利用した複数ワーカーのディープラーニングという、3つの主なユースケースをテストしました。</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">EシリーズとStorageGRID の検証には、Hadoopレプリケーションファクタ2を使用しました。AFF の検証に使用したデータソースは1つだけです。</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">次の表に、Sparkのパフォーマンス検証のハードウェア構成を示します。</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Hadoopワーカーノード</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">ドライブタイプ</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">ノードあたりのドライブ数</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">ストレージコントローラ</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">（ SAS ）。</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">単一のハイアベイラビリティ（HA）ペア</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">単一のHAペア</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800が必要です</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">次の表に、ソフトウェア要件を示します。</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7.9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">OpenJDKランタイム環境</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">OpenJDK 64ビットのServer VM</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25.302</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1.</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">火花</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLPです</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlowです</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">クラス</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">財務心理分析</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">NVIDIA Riva SDKを参照してください</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">Taoフレームワーク</block>
  <block id="3f57666cb1b915db482629c0554b2d92" category="paragraph">公開しました<block ref="36713788fc49ad5281ee4a8956df0b3b" category="inline-link-rx"></block>を使用して、エンドツーエンドの会話型AIパイプラインを構築しました<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>、AFF ストレージ、NVIDIA DGXシステムパイプラインは、DataOpsツールキットを活用して、バッチオーディオ信号処理、Automatic Speech Recognition（ASR）、転送学習、感情分析を実行します。<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block>および<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block>。金融サービス業界へのセンチメント分析のユースケースの拡大、SparkNLPワークフローの構築、特定事業体の認識など、さまざまなNLPタスクに対する3つのBERTモデルのロード、NASDAQ Top 10 Companiesの四半期収益コールに関するセンテンスレベルのセンチメントの取得。</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">次のスクリプト「センチメント_アナリシス_スパーク」。PY’はFinBERTモデルを使用してHDFS内のトランスクリプトを処理し、次の表に示すようにポジティブでニュートラルでネガティブな感情カウントを生成します。</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">次の表に、2016年から2020年までのNASDAQトップ10企業の収益/コール、センテンスレベルの感情分析を示します。</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">センチメントの数値と割合</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">10社すべて</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">AMZN</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">GOOGL</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">INTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">マイクロソフト</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">正の数</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567年</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">ニュートラルカウント</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">負の数</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787年になります</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">分類なしのカウント</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">（合計数）</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552.</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205.</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">割合の点では、CEOとCFOが話している文のほとんどは事実上であり、中立的な感情を持っています。決算発表時に、アナリストは肯定的または否定的な感情を伝える可能性のある質問をします。また、マイナスやプラスの心理が株価に与える影響についても、取引日の同日または翌日に定量的に調査することもできます。</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">次の表に、NASDAQトップ10企業の文章レベルの感情分析をパーセントで示します。</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">センチメントの割合</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">肯定的</block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10.13%</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18.06％</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8.69%</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5.24%</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9.07%</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12.08%</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11.44%</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13.25%</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6.23%</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">ニュートラル</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87.17%</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79.02%</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88.82%</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91.87%</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88.42%</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86.50%</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84.65%</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83.77%</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92.44%</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">負</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2.43%</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2.92％</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2.49％</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1.52%</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2.51 %</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1.42 %</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3.91%</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2.96 %</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1.33%</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">分類なし</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0.27%</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1.37 %</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0.01%</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">ワークフローの実行時間に関しては'local'モードからHDFSの分散環境に至るまで4.78倍の大幅な改善が見られましたまた'NFSを活用することで'さらに0.14%の向上が見られました</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">次の図に示すように、データとモデルの並列処理によって、データ処理と分散TensorFlowモデルの推論速度が向上しています。NFSのデータの場所では、トレーニング済みのモデルがワークフローのボトルネックになっているため、ランタイムが若干向上しました。Transcriptデータセットのサイズを増やすと、NFSの方が明らかになります。</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">SparkのNLP感情分析のエンドツーエンドワークフローランタイム。</block>
  <block id="bb9cd55aa92ceddf07506d9a2aaaa151" category="paragraph"><block ref="bb9cd55aa92ceddf07506d9a2aaaa151" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Horovodのパフォーマンスを使用した分散トレーニング</block>
  <block id="319e0ff7f30f4729140562f5e123c5cb" category="inline-link-macro">「主要な各ユースケース用のPythonスクリプト」</block>
  <block id="e37af8307fb97140dbcc0c8e2293d58f" category="paragraph">次のコマンドでは、1つのコアを持つ160個の実行者を持つ単一の「マスター」ノードを使用して、Sparkクラスタ内にランタイム情報とログファイルを生成しました。実行者メモリはメモリ不足エラーを回避するために5GBに制限されていました。を参照してください <block ref="033a864c436cdbcbe38983e75952a07f" category="inline-link-macro-rx"></block> データ処理、モデル・トレーニング、およびモデル精度計算の詳細については、「kers_spark_horovod_Rossmann _dimator.py」を参照してください。</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">トレーニング期間が10回の場合の結果、次のようになりました。</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">入力データの処理、DNNモデルのトレーニング、精度の計算、TensorFlowチェックポイントと予測結果のCSVファイルの作成に43分以上かかりました。トレーニング期間を10に制限しました。実際には100に設定されていることが多く、モデルの精度が十分であることを確認しています。トレーニング時間は通常、エポックの数に比例して拡大します。</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">次に、クラスタで使用可能な4つのワーカーノードを使用して、HDFS内のデータで「yarn」モードで同じスクリプトを実行しました。</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">結果として得られる実行時間は次のように改善されました。</block>
  <block id="206c83ab2ec1ea280656b18c0e2dc4dd" category="paragraph">HorovodのモデルとSparkのデータの並列化により、「yarn」と「local」モードを比較したランタイムが5.29x短縮され、トレーニング期間が10時間に短縮されました。次の図に、凡例に「hdfs」と「Local」を示します。基盤となるTensorFlow DNNモデルのトレーニングを、GPUがあればさらに高速化できます。このテストを実施し、今後のテクニカルレポートに結果を公開する予定です。</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">次のテストでは、NFSとHDFSの入力データをランタイムで比較しました。AFF A800のNFSボリュームは、Sparkクラスタ内の5つのノード（マスター1つ、ワーカー4つ）にまたがって「/sparkdemo/horovod」にマウントされました。前のテストと同様のコマンドを実行しましたが'--data-dir'パラメータは現在NFSマウントを指しています</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">NFSを使用した場合の実行時間は次のようになりました。</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">次の図に示すように、1.43倍の速度がさらに向上しました。このため、ネットアップのオールフラッシュストレージをクラスタに接続することで、Horovod Sparkワークフローの高速データ転送と配信というメリットを享受し、1つのノードで実行する場合と比べて7.55x高速化を達成できます。</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Horovod Sparkのワークフローランタイム。</block>
  <block id="56085b16b09d835f05c89b29473a0e73" category="paragraph"><block ref="56085b16b09d835f05c89b29473a0e73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">CTR予測パフォーマンスのディープラーニングモデル</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">クリック率を最大化するように設計されたレコメンダシステムでは、低い順に数学的に計算される可能性のある、ユーザーの行動の背後にある高度な機能の相互作用を学習する必要があります。低次と高次の両方の機能の相互作用は、どちらか一方をバイアスすることなく、ディープラーニングモデルにとっても同様に重要です。新しいニューラルネットワークアーキテクチャでの機能学習に向けて、界面活性化機械ベースのニューラルネットワークであるDeep Factorization Machine（DeepFM）は、界面活性化装置を組み合わせた推奨製品です。</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">ワイド・モデルとディープ・モデル</block>
  <block id="4028a7777950de6e915d72e379bde75d" category="paragraph">従来の三角分解機械は、機能間の潜伏ベクトルの内側としてのペアワイズ機能の相互作用をモデル化しますが、理論的には高次情報をキャプチャすることができます。実際には、機械学習の実践では、一般的に、計算と保管の複雑さが高いため、二次フィーチャーの相互作用しか使用しませGoogleなどのディープニューラルネットワークのバリエーション<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> 一方、リニアワイドモデルとディープモデルを組み合わせて、ハイブリッドネットワーク構造で高度な機能の相互作用を学習します。</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">このワイド・ディープ・モデルには2つの入力があります。1つは基本的なワイド・モデル用で、もう1つはディープのためです。後者の部分では、エキスパートフィーチャー・エンジニアリングが必要です。このため、この手法は他のドメインには一般的にできません。ワイド・ディープ・モデルとは異なり、DeepFMはフィーチャー・エンジニアリングなしでRAW機能を使用して効率的にトレーニングできます。ワイド・パートとディープ・パートは同じ入力と埋め込みベクトルを共有するためです。</block>
  <block id="03eaefcaa3f1aca8b4ffa8b95a4798b9" category="inline-link-macro">「主なユースケースごとにPythonスクリプトを用意しています。」</block>
  <block id="105a0d9d76e001ecdab02b77ca3a98ae" category="paragraph">私たちはまず'セクションのrun_classification_Crito_spark.pyを使用して'ctr_trine.csv'という名前のCSVファイルにCrito'trine.csv'をNFSマウント'/sparkdemo/tr-4570-data'に格納しました <block ref="43e008bfee5963b21d09b0af490bfdd7" category="inline-link-macro-rx"></block> このスクリプト内で'関数process_input_file'は'タブを削除し'区切り文字として''を'改行として''を挿入するための複数の文字列メソッドを実行しますコードブロックがコメントとして表示されるように、元の「train .txt」を1回だけ処理する必要があることに注意してください。</block>
  <block id="c960954a8d119eab5ff32a80d7fcc8e8" category="paragraph">以下の異なるDLモデルのテストでは、「ctr_train .csv」を入力ファイルとして使用しました。その後のテスト実行では、入力CSVファイルがSpark DataFrameに読み込まれ、スキーマに「label」のフィールド、整数の高密度フィーチャー「I1」、「I2」、「I3」、…、「I13」が含まれています。 また'希薄な機能は''C1'、'C2'、'C3'、…、'C26']`です次の「spark-smSubmit」コマンドは、入力CSVで実行し、クロス検証用に20%のスプリットを備えたDeepFMモデルをトレーニングし、10回のトレーニング期間後に最適なモデルを選択して、テストセットの予測精度を計算します。</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">データファイル「ctr_train .csv」は11 GBを超えるため、エラーを回避するには、データセットサイズよりも十分な「spark.driver.maxResultSize」を設定する必要があります。</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">Apache Arrowの</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">上記のSparkSession.Builder'構成でも有効になっています<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block>は、SparkのDataFrameを「df.toPandas ()」メソッドを使用してPandas DataFrameに変換します。</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">ランダムにスプリットした後、トレーニングデータセットに3、6M行以上、テストセットに9、000サンプル以上が存在します。</block>
  <block id="e6219a2eedbe95f3aa16ed53c4733845" category="paragraph">このテクニカルレポートでは、GPUを使用せずにCPUテストに焦点を当てているため、適切なコンパイラフラグを使用してTensorFlowを構築することが重要です。これにより、GPUアクセラレーションライブラリの呼び出しを回避し、TensorFlowのAdvanced Vector Extensions（AVX）およびAVX2命令を最大限に活用できます。これらの機能は、ベクトル化された加算、フィードフォワード内の行列乗算、またはバック伝播DNNトレーニングなどの線形代数計算用に設計されています。256ビット浮動小数点(FP)レジスタを使用したAVX2で使用可能なFMA (fMultiply Add)命令は、整数コードとデータ型に最適で、最大2倍の速度を実現します。FPコードとデータ型の場合、AVX2はAVXと比較して8%の高速化を実現します。</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">バザー</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">ソースからTensorFlowを構築する場合は、を使用することを推奨します<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block>。今回の環境では、シェルプロンプトで以下のコマンドを実行して、「リタイア」、「リタイヤ」、「バザール」をインストールしました。</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">ビルドプロセス中にC++ 17の機能を使用するには、GCC 5以降を有効にする必要があります。この機能は、RHELがソフトウェアコレクションライブラリ(SCL)とともに提供します。次のコマンドは'devtoolset'とGCC 11.2.1をRHEL 7.9クラスタにインストールします</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">記事</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">最後の2つのコマンドは'devtoolsets-11'を有効にしますこれには'/opt/r/devtoolset11-root//usr/bin/gcc`(GCC 11.2.1)が使用されますまた'gitのバージョンが1.8.3よりも大きいことを確認してください(RHEL 7.9に付属しています)これを参照してください<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> 「git」を2.24.1に更新します。</block>
  <block id="dc06a2e6ab4959266b8e70b6a4ecc45c" category="inline-link-macro">「主なユースケースごとにPythonスクリプトを用意しています。」</block>
  <block id="c55692ca5ecd175c73f55ba5b9319688" category="paragraph">最新のTensorFlowマスターリポジトリもすでにクローニング済みであるとします。次に'workspace'ファイルを使用して'workspace'ディレクトリを作成し'AVX、AVX2、FMAを使用してソースからTensorFlowを構築しますconfigureファイルを実行し、正しいPythonバイナリの場所を指定します。<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> はGPUを使用していないため、テストでは無効になっています。設定に応じて'`. bazelrc'ファイルが生成されますさらに、ファイルを編集し、HDFSのサポートを有効にするために「build--define=no_hdfs_support=false」を設定しました。セクションの「. bazelrc」を参照してください <block ref="2aec9284f17908b1690444cda81e493c" category="inline-link-macro-rx"></block> 設定とフラグの完全なリストについては、を参照してください。</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">適切なフラグを使用してTensorFlowを構築したら、次のスクリプトを実行してCritoディスプレイ広告データセットを処理し、DeepFMモデルをトレーニングし、予測スコアからReceiver Operating Characteristic Curve（ROC AUC）の下の領域を計算します。</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">トレーニング期間が10回終了したら、テストデータセットのAUCスコアを取得しました。</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">以前のユースケースと同様に、Sparkワークフローランタイムを異なる場所にあるデータと比較しました。次の図は、SparkワークフローランタイムのディープラーニングのCTR予測の比較を示しています。</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">SparkワークフローランタイムのディープラーニングのCTR予測の比較。</block>
  <block id="d27b678d975cf1fb0769c3e664f4f2dd" category="paragraph"><block ref="d27b678d975cf1fb0769c3e664f4f2dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7eb641fcfa1ced825edab271ee870e9" category="inline-link-macro">次のステップ：ハイブリッドクラウドの解決策</block>
  <block id="3f5dc233ecdfc868e2a067d1eb7d8811" category="paragraph"><block ref="3f5dc233ecdfc868e2a067d1eb7d8811" category="inline-link-macro-rx"></block></block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">このセクションでは、この解決策 のコンテンツに関心のあるユーザーについて説明します。</block>
  <block id="c1416f7786ac2faa1173c4336b6eb03e" category="paragraph"><block ref="c1416f7786ac2faa1173c4336b6eb03e" category="inline-link-macro-rx"></block></block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">分析とデータサイエンスの世界は、ITとビジネスのさまざまな分野に影響を与えています。</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">DevOpsエンジニアは、新しいAIアプリケーションやMLアプリケーションをCIパイプラインやCDパイプラインに統合するためのツールを必要としています。</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">クラウド管理者とアーキテクトは、ハイブリッドクラウドリソースを設定し、管理できる必要があります。</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">ビジネスユーザは、分析、AI、ML、DLアプリケーションにアクセスしたいと考えています。</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">このテクニカルレポートでは、NetApp AFF 、Eシリーズ、StorageGRID 、NFSへの直接アクセス、Apache Spark HorovodとKerasは、これらの役割のそれぞれがビジネスに価値をもたらすのを支援します。</block>
  <block id="1f3c9b64432ff113f81d3897c98ed74b" category="inline-link-macro">次の例は、解決策 テクノロジです。</block>
  <block id="fdd31e37014fd5b0f491f1d30b29c4c3" category="paragraph"><block ref="fdd31e37014fd5b0f491f1d30b29c4c3" category="inline-link-macro-rx"></block></block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">このセクションでは、Apache Spark向けのネットアップストレージソリューションに関する本ドキュメントの概要を示します。</block>
  <block id="265d8449fb55764666dffa0a87f0c3fc" category="inline-link-macro">以前のバージョン：主なユースケースごとにPythonスクリプトを使用していました。</block>
  <block id="7fc4ed21f18b26424c49779d455d4f51" category="paragraph"><block ref="7fc4ed21f18b26424c49779d455d4f51" category="inline-link-macro-rx"></block></block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">本ドキュメントでは、Apache Sparkのアーキテクチャ、お客様のユースケース、ネットアップストレージポートフォリオについて、ビッグデータ、最新の分析、AI、ML、DLに関連する情報をご紹介します。業界標準のベンチマークツールとお客様からの要望に基づくネットアップのパフォーマンス検証テストでは、NetApp Sparkソリューションは、ネイティブのHadoopシステムと比較して優れたパフォーマンスを実証しました。このレポートで紹介したお客様のユースケースとパフォーマンス結果を組み合わせることで、導入環境に適したSpark解決策 を選択できます。</block>
  <block id="7772bd81086ccf1a440798ec74c6c795" category="paragraph"><block ref="7772bd81086ccf1a440798ec74c6c795" category="inline-link-macro-rx"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">最新のエンタープライズデータセンターとは、複数の分散インフラ環境を、オンプレミスや複数のパブリッククラウドと一貫した運用モデルで継続的なデータ管理プレーンを通じて接続するハイブリッドクラウドです。ハイブリッドクラウドを最大限に活用するには、データの変換やアプリケーションのリファクタリングを行わなくても、オンプレミス環境とマルチクラウド環境間でデータをシームレスに移動できる必要があります。</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">Hybrid Cloud解決策 の略</block>
  <block id="bbbb8f5ce180b59d7cf72bfd9ff78bf6" category="inline-link-macro">前の手順：テスト結果</block>
  <block id="e8be57661ebf09e93d86ee83e74adbc3" category="paragraph"><block ref="e8be57661ebf09e93d86ee83e74adbc3" category="inline-link-macro-rx"></block></block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">データ保護などのユースケースでセカンダリストレージをクラウドに移行するか、アプリケーション開発やDevOpsなどのビジネスクリティカルなワークロードをクラウドに移行することで、ハイブリッドクラウドへの移行を開始するとお客様から指摘を受けています。そして、より重要なワークロードに移行します。Webおよびコンテンツホスティング、DevOpsやアプリケーション開発、データベース、分析、コンテナ化されたアプリケーションは、最も一般的なハイブリッドクラウドワークロードです。エンタープライズAIプロジェクトの複雑さ、コスト、リスクは、これまでAIの導入を試験段階から本番運用に妨げていました。</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">ネットアップのハイブリッドクラウド解決策 なら、セキュリティ、データガバナンス、コンプライアンスの統合ツールを活用できます。また、分散環境全体でデータとワークフローを一元管理できる単一のコントロールパネルを使用して、総所有コストを消費量に応じて最適化できます。次の図は、お客様のビッグデータ分析データにマルチクラウド接続を提供するという課題を抱えるクラウドサービスパートナーの解決策 の例です。</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">クラウドサービスパートナーの解決策 の例。</block>
  <block id="ad71e01672e98de491e72d22ba403059" category="paragraph"><block ref="ad71e01672e98de491e72d22ba403059" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">このシナリオでは、AWSでさまざまなソースから受け取ったIoTデータが、NetApp Private Storage（NPS）内の1箇所に保存されます。NPSストレージは、AWSとAzure上にあるSparkクラスタやHadoopクラスタに接続されているため、複数のクラウドで同じデータにアクセスするビッグデータ分析アプリケーションを実行できます。このユースケースの主な要件と課題は次のとおりです。</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">オンプレミス環境やクラウド環境などのさまざまなソースから、さまざまなセンサーやハブを介してデータを受信する必要があります。</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">解決策 は、効率性とコスト効率に優れている必要があります。</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">主な課題は、コスト効率と効率に優れた解決策 を構築し、オンプレミス環境とクラウド環境の間でハイブリッド分析サービスを提供することです。</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">ネットアップのデータ保護機能とマルチクラウド接続解決策 は、複数のハイパースケーラにわたるクラウド分析アプリケーションの課題を解決します。上の図に示すように、センサーからのデータはストリーミングされ、 Kafka を介して AWS Spark クラスタに取り込まれます。データは NPS 内の NFS 共有に格納されます。 NPS は、 Equinix データセンター内のクラウドプロバイダの外部にあります。</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">NetApp NPSは、それぞれDirect Connect接続とExpress Route接続を通じてAmazon AWSとMicrosoft Azureに接続されているため、インプレース分析モジュールを利用して、AmazonとAWS両方の分析クラスタからデータにアクセスできます。そのため、オンプレミスストレージとNPSストレージの両方でONTAP ソフトウェアが実行され、<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> NPSデータをオンプレミスクラスタにミラーリングし、オンプレミスと複数のクラウドにわたってハイブリッドクラウド分析を実現できます。</block>
  <block id="6e53d162faf0b7bc51e81ca980f05f86" category="paragraph">パフォーマンスを最大限に高めるために、通常は複数のネットワークインターフェイスと直接接続またはエクスプレスルートを使用してクラウドインスタンスからデータにアクセスすることを推奨します。ネットアップには、ほかにも、などのData Moverソリューションがあります<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> および<block ref="4c1cade27212922d2ee7525beab5b4a9" category="inline-link-rx"></block> お客様がアプリケーション対応でセキュア、コスト効率に優れたハイブリッドクラウドSparkクラスタを構築できるよう支援します。</block>
  <block id="1e73bec6e2f584224cb16d4550039696" category="inline-link-macro">次の例：主なユースケースごとにPythonスクリプトを使用します。</block>
  <block id="cf6b62d678290b47b2c7abc2f11eb6d5" category="paragraph"><block ref="cf6b62d678290b47b2c7abc2f11eb6d5" category="inline-link-macro-rx"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">このページでは、この解決策 を使用できるさまざまな領域について説明します。</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">ユースケースの概要</block>
  <block id="2a4bf885433f99fb55281d25340cf2b5" category="inline-link-macro">以前：NetApp Sparkソリューションの概要はこちらでした。</block>
  <block id="105ad1f4294f02452bad1ed7ad67aa5d" category="paragraph"><block ref="105ad1f4294f02452bad1ed7ad67aa5d" category="inline-link-macro-rx"></block></block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">ストリーミングデータ</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Sparkはストリーミングデータを処理できます。ストリーミングデータは、抽出、変換、読み込み（ETL）プロセス、データのエンリッチ化、イベント検出のトリガー、複雑なセッション分析に使用されます。</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*ストリーミングETL。*データは継続的に消去され、データストアにプッシュされる前に集約されます。Netflixでは、KafkaストリーミングとSparkストリーミングを使用して、リアルタイムのオンラインムービーの推奨事項とデータ監視解決策 を構築しています。このソリューションでは、さまざまなデータソースから1日数十億件のイベントを処理できます。ただし、従来のETLではバッチ処理の処理方法が異なります。このデータは最初に読み取られ、次にデータベースに書き込まれる前にデータベース形式に変換されます。</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*データのエンリッチ化。* Sparkストリーミングは、静的データを活用してライブデータを強化し、よりリアルタイムのデータ分析を可能にします。たとえば、オンライン広告主は、顧客行動に関する情報に基づいてパーソナライズされたターゲット広告を配信できます。</block>
  <block id="e3c0d503686e9ab8960903bc80d3f700" category="list-text">*イベント検出のトリガ。* Sparkストリーミングを使用すると、重大な問題を示す可能性のある異常な動作をすばやく検出して対応することができます。たとえば、金融機関はトリガーを使用して不正取引を検出および停止し、病院はトリガーを使用して患者のバイタルサインで検出された危険な健康状態変化を検出します。</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*複雑なセッション分析。* Sparkストリーミングは、Webサイトやアプリケーションにログインした後で、ユーザーのアクティビティなどのイベントを収集し、それらをグループ化して分析します。たとえば、Netflixでは、この機能を使用してリアルタイムの動画推奨を提供しています。</block>
  <block id="61fb23ef88a4d1404b2410cf94238fb5" category="paragraph">より多くのストリーミングデータ構成、ConFluent Kafkaの検証、およびパフォーマンステストについては、を参照してください<block ref="10063fdbf72f58440f18bb49eb2309fe" category="inline-link-rx"></block>。</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">機械学習</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Sparkの統合フレームワークを使用すると、機械学習ライブラリ（MLlib）を使用してデータセットに対して繰り返しクエリを実行できます。MLlibは、予測インテリジェンス、マーケティング目的での顧客セグメンテーション、感情分析など、一般的なビッグデータ機能のためのクラスタリング、分類、次元縮小などの領域で使用されます。MLlibは、ネットワークセキュリティで、悪意のあるアクティビティの兆候を示すデータパケットをリアルタイムで検査するために使用されます。セキュリティプロバイダは、新しい脅威について学び、ハッカーの一歩先を行きながら、クライアントをリアルタイムで保護することができます。</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">ディープラーニング</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlowは、業界全体で使用されている一般的なディープラーニングフレームワークです。TensorFlowは、CPUまたはGPUクラスタでの分散トレーニングをサポートしています。このトレーニングは分散されているため、ユーザはディープレイヤを大量に含む大容量のデータを使用してトレーニングを実行できます。</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">最近まで、Apache SparkとTensorFlowを使用したい場合は、PySparkでTensorFlowに必要なすべてのETLを実行し、中間ストレージにデータを書き込む必要がありました。そのデータは、実際のトレーニングプロセス用にTensorFlowクラスタにロードされます。このワークフローでは、ETL用とTensorFlowの分散トレーニング用の2つの異なるクラスタを管理する必要がありました。複数のクラスタを実行して保守する作業は、一般に煩雑で時間もかかりました。</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">以前のSparkバージョンのデータフレームとRDDは、ランダムアクセスが制限されていたため、ディープラーニングには適していませんでした。Spark 3.0では、プロジェクト水素を使用してディープラーニングフレームワークのネイティブサポートが追加されました。このアプローチにより、Sparkクラスタで非MapReduceベースのスケジューリングが可能になります。</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">対話式解析</block>
  <block id="11bb4412e7e82514a739cb60053e30df" category="paragraph">Apache Sparkは、SQL、R、Pythonを含むSpark以外の開発言語でサンプリングしなくても、探索クエリを実行するのに十分な速さです。Sparkは視覚化ツールを使用して複雑なデータを処理し、対話式に視覚化します。Spark with structured streamingは、Web分析のライブデータに対してインタラクティブなクエリを実行します。これにより、Web訪問者の現在のセッションに対してインタラクティブなクエリを実行できます。</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">推薦システム</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">推薦システムは長年にわたり、オンラインショッピング、オンラインエンターテインメント、その他多くの業界の劇的な変化に企業や消費者が対応してきたため、私たちの生活に大きな変化をもたらしてきました。実際、これらのシステムは、AIの本番運用における成功事例として最も顕著に表れています。多くの実用的なユースケースでは、推薦システムを会話型AIやチャットボットと組み合わせてNLPバックエンドに接続することで、関連情報を取得し、有益な推論を作成しています。</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">現在、多くの小売業者は、オンラインでの購入や店舗での集荷、縁石側での集荷、セルフチェックアウト、スキャンと外出など、新しいビジネスモデルを採用しています。これらのモデルは、COVID-19のパンデミックでショッピングの安全性と消費者の利便性を高めることで、注目を引くようになっています。このようなデジタルトレンドの拡大には、AIが欠かせません。こうしたトレンドは消費者の行動に左右され、その逆も同様です。お客様のニーズの高まりに応え、カスタマーエクスペリエンスの強化、運用効率の向上、収益の拡大を実現するために、ネットアップは、機械学習とディープラーニングのアルゴリズムを使用して、より迅速で正確な推奨システムを設計できるよう、大企業のお客様とビジネスを支援しています。</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">コラボレーションフィルタリング、コンテンツベースのシステム、ディープラーニングレコメンダモデル（DLRM）、ハイブリッド手法など、推奨事項を提供するために使用される一般的な手法がいくつかあります。以前は、PySparkを使って、推奨システムを作成するためのコラボレーションフィルタリングを実装していました。Spark MLlibは、コラボレーションフィルタリングのために交互に最小二乗（ALS）を実装しています。これは、DLRMが増加する前に、企業間で非常に人気のあるアルゴリズムです。</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">自然言語処理</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner社</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">会話型AIは、自然言語処理（NLP）によって実現され、コンピュータが人間と通信するのを支援するAIのブランチです。NLPは、スマートアシスタントやチャットボット、Google検索、予測テキストなど、業界のあらゆる業種や多くのユースケースで広く使用されています。に従って<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> 予測：2022年までに、人の70%が日常的に会話型AIプラットフォームとやり取りしています。人間と機械の間で質の高い会話を行うには、応答が迅速かつインテリジェントで、自然な音声である必要があります。</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">お客様は、NLPモデルとAutomatic Speech Recognition（ASR）モデルを処理してトレーニングするために大量のデータを必要としています。また、エッジ、コア、クラウドにわたってデータを移動する必要もあり、推論を数ミリ秒で実行して人間との自然な通信を確立する機能も必要です。NetApp AIとApache Sparkは、コンピューティング、ストレージ、データ処理、モデルトレーニング、微調整、 そして展開。</block>
  <block id="33984e410ab674dcea1f21af4c5db4ec" category="paragraph">感情分析とは、NLP内で、肯定的、否定的、または中立的な感情がテキストから抽出される研究領域のことです。感情分析には、サポートセンターの従業員のパフォーマンスを発信者との会話から適切な自動チャットボット応答まで、さまざまなユースケースがあります。また、四半期ごとの収益呼において、企業の代表者と対象者の間のやり取りに基づいて会社の株価を予測するためにも使用されています。さらに、感情分析を使用して、ブランドが提供する製品、サービス、サポートに関するお客様の見解を判断できます。</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">ジョンスノーラボ</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">財務ニュースのセンチメント</block>
  <block id="322f98ff217f4c12ea8f1b3ea41f4024" category="paragraph">使用しました<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> ライブラリ元<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> を含むTransformers（BERT）モデルから事前にトレーニングされたパイプラインと双方向エンコーダリプレゼンテーションをロードするため<block ref="25bfdf207733b5ead40d4d36ea328e85" category="inline-link-rx"></block> および<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>トークン化、Named Entity Recognition、モデルトレーニング、フィッティング、センチメント分析を大規模に実施しています。Spark NLPは、BERT、Albert、Electra、XLNet、DistilBERTなどの最先端のトランスを提供する唯一のオープンソースNLPライブラリです。 Roberta、DeberTa、XLM-Roberta、Longform, Elmo ユニバーサルセンテンスエンコーダー、Google T5、MarianMT、およびGPT2。このライブラリはPythonとRだけでなく、Apache Sparkをネイティブに拡張することで、JVMエコシステム（Java、Scala、Kotlin）でも大規模に動作します。</block>
  <block id="e4f0ac4ff07b9b5031299d0b3702fedb" category="inline-link-macro">次のステップ：主要なAI、ML、DLのユースケースとアーキテクチャ</block>
  <block id="84fcdcaf39dee89e28f1b44c28ad46ef" category="paragraph"><block ref="84fcdcaf39dee89e28f1b44c28ad46ef" category="inline-link-macro-rx"></block></block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">このセクションでは、Apache Sparkの性質とコンポーネント、およびそれらがこの解決策 にどのように貢献するかについて説明します。</block>
  <block id="b47e85e30f997f214c7850de9dd795da" category="inline-link-macro">前のページ：対象読者</block>
  <block id="9e972d78946023378ffbea0f999c2d03" category="paragraph"><block ref="9e972d78946023378ffbea0f999c2d03" category="inline-link-macro-rx"></block></block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Sparkは、Hadoop Distributed File System（HDFS）と直接連携するHadoopアプリケーションを作成するための一般的なプログラミングフレームワークです。Sparkは本番環境に対応しており、ストリーミングデータの処理をサポートしています。MapReduceよりも高速です。Sparkには、効率的なイテレーションのためのメモリ内データキャッシングが設定可能であり、Sparkシェルはデータの学習と探索のためにインタラクティブです。Sparkでは、Python、Scala、Javaでアプリケーションを作成できます。Sparkアプリケーションは、1つ以上のタスクを持つ1つ以上のジョブで構成されています。</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">すべてのSparkアプリケーションにはSparkドライバがあります。yarn -クライアントモードでは、ドライバはクライアント上でローカルに実行されます。Yarn -クラスタモードでは、ドライバはアプリケーションマスター上のクラスタで実行されます。クラスタモードでは、クライアントが切断してもアプリケーションは引き続き実行されます。</block>
  <block id="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="paragraph"><block ref="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">クラスタマネージャは3種類あります。</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*スタンドアロン。*このマネージャーはSparkの一部であり、クラスタのセットアップが簡単です。</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">* Apache Mesos.* MapReduceなどのアプリケーションも実行される一般的なクラスタマネージャです。</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">* Hadoop糸。*これはHadoop 3のリソースマネージャーです。</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">レジリエントな分散データセット（RDD）はSparkの主要コンポーネントです。RDDは、クラスタ内のメモリに格納されているデータから、失われたデータや欠落しているデータを再作成し、ファイルから取得した初期データまたはプログラムによって作成された初期データを格納します。RDDは、ファイル、メモリ内のデータ、または別のRDDから作成されます。Sparkプログラミングは、変換とアクションという2つの操作を実行します。既存のRDDに基づいて新しいRDDが作成されます。アクションはRDDから値を返します。</block>
  <block id="06b482c7bd2522ec4a62ccc70b71c37e" category="paragraph">変換とアクションはSparkのデータセットとDataFramesにも適用されます。データセットとは、分散されたデータの集合であり、Spark SQLの最適化された実行エンジンの利点とともに、RDDの利点（強力なタイピング、ラムダ関数の使用）を提供します。データセットはJVMオブジェクトから作成し、機能変換（マップ、フラットマップ、フィルタなど）を使用して操作できます。DataFrameは、名前付き列に編成されたデータセットです。概念的には、リレーショナルデータベースのテーブルまたはR/Pythonのデータフレームに相当します。データフレームは、構造化データファイル、HiveまたはHBaseのテーブル、オンプレミスまたはクラウドの外部データベース、既存のRDDなど、さまざまなソースから構築できます。</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Sparkアプリケーションには1つ以上のSparkジョブが含まれています。ジョブは実行者でタスクを実行し、実行者はYarnコンテナで実行します。各実行者は1つのコンテナで実行され、実行者はアプリケーションのライフサイクルを通して存在します。実行者はアプリケーションの起動後に修正され、yarnは割り当て済みのコンテナのサイズを変更しません。実行者は、メモリ内のデータに対してタスクを同時に実行できます。</block>
  <block id="93b777568c6fc956b8dcbf6cb778cf8e" category="inline-link-macro">次のステップ：NetApp Sparkソリューションの概要</block>
  <block id="2e9d493fc7f04097c722ddfd7bf4cba7" category="paragraph"><block ref="2e9d493fc7f04097c722ddfd7bf4cba7" category="inline-link-macro-rx"></block></block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="doc">主なユースケースごとにPythonスクリプトを使用できます</block>
  <block id="6af3c467ec5223400f1d1e91f69cb12b" category="inline-link-macro">従来のソリューション：ハイブリッドクラウド解決策</block>
  <block id="45d040833437bf9dd9f64d4dfa4981c4" category="paragraph"><block ref="45d040833437bf9dd9f64d4dfa4981c4" category="inline-link-macro-rx"></block></block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">以下の3つのPythonスクリプトは、テストした3つの主なユースケースに対応しています。1つ目は'ecimation_analysis _sparknlp.pyです</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">2番目のスクリプトは'kers_spark_horovod_Rossmann _ estimator.pyです</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">3番目のスクリプトは'run_classification_Crito_spark.pyです</block>
  <block id="be0ba1bf6a99c201834567c4d58fc40e" category="paragraph"><block ref="be0ba1bf6a99c201834567c4d58fc40e" category="inline-link-macro-rx"></block></block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">ユースケースの概要</block>
  <block id="7a28dc06a92c8c13aba4217cc065d556" category="list-text">&lt;ユースケース2&gt;</block>
  <block id="e71faea04999fd95e327c2ae1b14b591" category="list-text">注2：</block>
  <block id="39a42e9bc59c02bbbf3ed4eb16b1cca4" category="paragraph">この解決策 の導入を完了すると、次の作業を実行できます。</block>
  <block id="7300ce5706dee36f69c820d38d478b65" category="list-text">スクリーンショット付きの詳細な手順を実行して、手動で操作します。</block>
  <block id="8412750c53dfad13bb8a2baccb69df63" category="list-text">実行する手順を示すビデオ、またはを使用して、手動で操作します</block>
  <block id="ec325ca23fb4f2a557b0efcf8667bf31" category="list-text">オートメーションセクションに記載されている手順に従って自動的に実行されます。</block>
  <block id="d22702677ec3ab6384e6dae329022796" category="open-title">詳細な手順</block>
  <block id="233777e8b1ab8b0114d7518acdbd2377" category="list-text">タスク2 ...</block>
  <block id="2f43b42fd833d1e77420a8dae7419000" category="paragraph">...</block>
  <block id="a0c7049fba5354f8f1711e379e6f4201" category="open-title">ビデオチュートリアル</block>
  <block id="c6388aefff17f19b12b255766fe6b6fe" category="paragraph">&lt;ビデオの詳細をここに記載&gt;</block>
  <block id="f674169036173cc4a9f01e223c275c8d" category="open-title">導入の自動化</block>
  <block id="b9e9e9354502c35dc60d3744fb1506e6" category="paragraph">&lt;ここに自動化された手順/プロセス/ビデオを記載してください&gt;</block>
  <block id="bbc8a731eb9387bfdc71e5f35721af4c" category="example-title">&amp;lt;オプション1&amp;gt;の説明</block>
  <block id="e83c35e6afea2838c146155292120e3a" category="paragraph">&lt;オプションの詳細をここに入力&gt;</block>
  <block id="a8ec4bf9dc004e6dc4ec8c7c8cb307a3" category="example-title">&amp;lt;オプション2&amp;gt;の説明</block>
  <block id="13e60333560bb11c5611ca7faa0dff3b" category="example-title">&amp;lt;オプションn&amp;gt;の説明</block>
  <block id="955b9fb8bb717f45a2531f62ebef906d" category="doc">NVA-1151-design：NVIDIA DGX A100を搭載したNetApp ONTAP AIシステム設計ガイド</block>
  <block id="329ecbed66c88e6c0c049d051ad6aa9a" category="paragraph">ネットアップDavid ArnetteとSung-Han Lin</block>
  <block id="d940dfad6ae514d8235749f5f5bf92ed" category="paragraph">NVA-1151設計には、NetApp AFF A800ストレージシステム、NVIDIA DGX A100システム、NVIDIA Mellanoxネットワークスイッチを使用した、マシンラーニングと人工知能のワークロードに対応するネットアップの検証済みアーキテクチャが記載されています。また、実装されているアーキテクチャのベンチマークテスト結果も含まれます。</block>
  <block id="20821bbf55dddb9fb677efca1bfcf4d1" category="paragraph"><block ref="20821bbf55dddb9fb677efca1bfcf4d1" category="inline-link-rx"></block></block>
  <block id="16550c71fdf2102ec8face86a5d82746" category="cell">2022年9月30日</block>
  <block id="8485ff07404cda7656a72c1d11b2e278" category="cell">VMware HCXを使用してFSxNデータストアにワークロードを移行するための解決策 を追加</block>
  <block id="bee0d36d9b0ec64a15bf59019a6ec2e2" category="cell">2022/09/29</block>
  <block id="b6942044de91f49e700f684f12314907" category="cell">VMware HCXを使用したANFデータストアへのワークロード移行に関する解決策 を追加</block>
  <block id="fa3811ba5828de9b5ce35701ec38d154" category="list-text">VMCの可用性を確認します <block ref="bd516ef46cad23535fac2e4d7f54defe" category="inline-link-macro-rx"></block>。</block>
  <block id="0ecaf171a89c41ea509c3f45896220b8" category="list-text">Amazonの価格設定ガイドには、FSxN（FSX ONTAP ）が提供されている場所に関する情報が記載されています。この情報は次のページで確認できます <block ref="2d4b4b449ef448fbb3000f58e542f4ee" category="inline-link-macro-rx"></block>。</block>
  <block id="4573434025dab87886cfb0b766c70cb1" category="paragraph">最終更新日：2022年9月28日</block>
  <block id="d8cefe0428d28368238dbbeabef9c83f" category="open-title">ハイブリッドマルチクラウド（HMC）</block>
  <block id="493f775d3c83d2c658056477b1d58f74" category="paragraph">[下線]#* AWS/VMC *#用ビデオ</block>
  <block id="638eb9310db06d086fac0c3c069669af" category="video-title">AWS上のVMware Cloud追加データストア、Amazon FSX for NetApp ONTAP</block>
  <block id="6f605e77e59dfe45ae918965ba0bd336" category="video-title">Amazon FSX for NetApp ONTAP を使用すると、VMware Cloud on AWSのTCOを削減できます</block>
  <block id="d7d56735bb43053ca43b2d9698b2623c" category="video-title">VMCのVMware HCX展開と構成のセットアップ</block>
  <block id="c6434a9743fb403cd78cd2d3a42d9683" category="video-title">VMCおよびFSxN向けVMware HCXでのVMotionのデモ</block>
  <block id="e906083dc0b31806eab68df2c340504f" category="video-title">VMware HCX for VMCおよびFSxNを使用したコールドマイグレーションデモ</block>
  <block id="62184265581f788d642b26b13c273b93" category="paragraph">[underline]#* Azure/AVSのビデオ*#</block>
  <block id="62766d3266d403114a010bc02e7b4004" category="video-title">Azure NetApp Files を使用したAzure VMware解決策 補足データストアの概要</block>
  <block id="4864ff1c07b9b500fd46c4a1c5918fd8" category="video-title">Cloud Volumes ONTAP 、SnapCenter 、JetStreamを使用したAzure VMware解決策 DR</block>
  <block id="8eb2fa7c0d2a676485a155077b770fdd" category="video-title">VMware HCX for AVSとANFを使用したコールドマイグレーションデモ</block>
  <block id="664115ac899ebaf481e2b75540d5c56c" category="video-title">VMware HCX for AVSとANFでのvMotionのデモ</block>
  <block id="914c1d4cdf840b7b030978f1b07915d8" category="video-title">AVSとANF向けVMware HCXの一括移行デモ</block>
  <block id="1709b8b454125c7d55fd44e302c8aee3" category="example-title">VMware Cloud on AWS Migrate with FSxN、VMware HCX</block>
  <block id="9de15a07d3a8b75e451c50d7fa64fae9" category="example-title">Azure VMware Services on AzureとAzure NetApp Files （ANF）</block>
  <block id="875970986c8d6a0d19f47ed744bf33e1" category="example-title">Azure VMware解決策 Migrate with ANF、VMware HCX</block>
  <block id="04a1b40e30ee3bddef53c85ca68c8b36" category="inline-link-macro">VMware HCXを使用して、ワークロードをAzure NetApp Files データストアに移行します</block>
  <block id="edf47ba9dc6467e3104102f10bafe323" category="list-text"><block ref="edf47ba9dc6467e3104102f10bafe323" category="inline-link-macro-rx"></block></block>
  <block id="668f202e4850de68f941501493126dea" category="doc">TR-4640：『VMware HCX-Quickstart guide』を使用してワークロードをAzure NetApp Files データストアに移行する</block>
  <block id="ddfd90f2a10c16cbd6548844b07532c2" category="paragraph">執筆者：NetApp Solutions Engineering</block>
  <block id="e5baae71bfede792aee5ab0c09fbcd23" category="section-title">概要：VMware HCX、Azure NetApp Files データストア、Azure VMware解決策 を使用した仮想マシンの移行</block>
  <block id="45c532c5535fe16cf9a5868bbd9a3fcd" category="paragraph">Azure VMware解決策 およびAzure NetApp Files データストアの最も一般的なユースケースの1つは、VMwareワークロードの移行です。VMware HCXは推奨されるオプションであり、オンプレミスの仮想マシン（VM）とそのデータをAzure NetApp Files データストアに移動するためのさまざまな移行メカニズムを提供します。</block>
  <block id="a2ee24315378af7416f8fef29e0f0efa" category="paragraph">VMware HCXは、主に移行プラットフォームであり、クラウド間でのアプリケーションの移行、ワークロードの再バランシング、ビジネス継続性の簡素化を目的として設計されています。Azure VMware解決策 プライベートクラウドの一部として提供され、ワークロードを移行して、ディザスタリカバリ（DR）処理に使用できるさまざまな方法を提供します。</block>
  <block id="227830ba037f63bb97cffeeb98e3a13e" category="paragraph">このドキュメントでは、Azure NetApp Files データストアのプロビジョニングの手順を追ったガイダンスを示し、その後、さまざまなVM移行メカニズムを有効にするためのインターコネクト、ネットワーク拡張、WAN最適化を含む、オンプレミスおよびAzure VMware解決策 サイドのすべての主要コンポーネントを含む、VMware HCXのダウンロード、導入、設定を行います。</block>
  <block id="a7441e9f968c9ea792320876fd73622a" category="admonition">VMware HCXはVMレベルで移行されるため、どのデータストアタイプでも動作します。このドキュメントAzure NetApp Files は、解決策 コスト効率に優れたVMwareクラウドの導入を計画している、ネットアップの既存のお客様と、ネットアップ以外のお客様を対象としています。</block>
  <block id="0ba40ecb813b20bd8c3277c4afcbd451" category="example-title">手順の概要</block>
  <block id="9a40c0b2781fd2a3a99aa2a6c0c4616e" category="paragraph">次のリストは、Azureクラウド側でHCX Cloud Managerをインストールおよび設定し、オンプレミスでHCX Connectorをインストールするために必要な手順の概要を示しています。</block>
  <block id="d7bfcf4345887ee24f2c3083038c6327" category="list-text">AzureポータルからHCXをインストールします。</block>
  <block id="ea0d203a776b5c56ae3ed2c61269d2a9" category="list-text">HCX Connector Open Virtualization Appliance（OVA）インストーラをオンプレミスのVMware vCenter Serverにダウンロードして導入します。</block>
  <block id="2be88e0d3f6d4e20f4bf2bcca7895d7b" category="list-text">ライセンスキーを使用してHCXをアクティブにします。</block>
  <block id="6a0721ebaaff6c0b1564863ac23c2509" category="list-text">オンプレミスのVMware HCXコネクタをAzure VMware解決策 HCX Cloud Managerとペアリングします。</block>
  <block id="612a4c795715d17bfff4e0ba3a8f66d1" category="list-text">ネットワークプロファイル、コンピューティングプロファイル、およびサービスメッシュを設定します。</block>
  <block id="81feabec43f9f1bcb7230fd62f89fb76" category="list-text">（オプション）移行中に再IPが発生しないように、ネットワーク拡張を実行します。</block>
  <block id="dbed86346a8d7cb3692ba413f7e14f56" category="list-text">アプライアンスのステータスを検証し、移行が可能であることを確認します。</block>
  <block id="2f2c97fb0d914a7fc7bcb2c8fad16868" category="list-text">VMワークロードを移行する。</block>
  <block id="f2f281974ab353b606093268f9d5335e" category="paragraph">作業を開始する前に、次の前提条件が満たされていることを確認してください。詳細については、を参照してください<block ref="88354f8e41d1a2e6cea84b3d932b3286" category="inline-link-rx"></block>。接続などの前提条件が整ったら、Azure VMware解決策 ポータルからライセンスキーを生成して、HCXを設定してアクティブにします。OVAインストーラをダウンロードしたら、次の手順に従ってインストールプロセスを実行します。</block>
  <block id="f52b030029e78590ca66fbf452dfcb14" category="admonition">HCx advancedはデフォルトオプションであり、VMware HCX Enterprise Editionはサポートチケットを通じても利用でき、追加料金なしでサポートされます。</block>
  <block id="67863abb3ec8a28f54adf852298b392b" category="inline-link">ネットアップのリンク</block>
  <block id="d2a5cfbad293008f62b5d4e58457a6d1" category="inline-link">Microsoftのリンク</block>
  <block id="1ed491d88e9198d83430469156bf2665" category="list-text">既存のAzure VMware解決策 Software-Defined Data Center（SDDC）を使用するか、またはこれを使用してプライベートクラウドを作成します<block ref="db330bdc7708ed0196dccd83d189a8ae" category="inline-link-rx"></block> またはこれ<block ref="5633c6477a16a80a8050560dab9783c9" category="inline-link-rx"></block>。</block>
  <block id="e265f4db94070f55784ef698e7f4f29b" category="inline-link">サイト間VPNまたはエクスプレスルートグローバルリーチ接続をセットアップします</block>
  <block id="bb764f1df90a85d77eec079e03bd9764" category="list-text">オンプレミスのVMware vSphere対応データセンターからVMと関連データを移行するには、データセンターからSDDC環境へのネットワーク接続が必要です。ワークロードを移行する前に、<block ref="31180ecf5c9f25ba891b891b395a9305" category="inline-link-rx"></block> オンプレミス環境とそれぞれのプライベートクラウドの間。</block>
  <block id="d08fd3825f77e870dd8e93463aea245d" category="list-text">オンプレミスのVMware vCenter Server環境からAzure VMware解決策 プライベートクラウドへのネットワークパスで、vMotionを使用したVMの移行がサポートされている必要があります。</block>
  <block id="f3b5e5598d4c0c196bd2fd79b000637f" category="inline-link">ファイアウォールルールとポート</block>
  <block id="e1be03b35dc8e9fb114970b06dcd6c18" category="list-text">必要なを確認します<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> オンプレミスのvCenter ServerとSDDC vCenter間のvMotionトラフィックに許可されます。プライベートクラウドでは、vMotionネットワーク上のルーティングはデフォルトで設定されます。</block>
  <block id="444617dcfe0d17ad386105e865d21113" category="list-text">Azure NetApp Files NFSボリュームは、Azure VMware解決策 でデータストアとしてマウントする必要があります。詳細な手順を実行します<block ref="1b959b45bbb3571141089802677ad765" category="inline-link-rx"></block> を使用して、Azure NetApp Files データストアをAzure VMwareソリューションホストに接続します。</block>
  <block id="2f660e9fff52e5ac1b7818a029d3b447" category="example-title">アーキテクチャの概要</block>
  <block id="0048e42e38e4c6f587f210afe26fcb4a" category="inline-image-macro">この図は、この解決策 で使用されているアーキテクチャの概要を示しています。</block>
  <block id="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="paragraph"><block ref="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84f7e9d42c2c0ee4f87ddeaa2e09bb2" category="paragraph">一連の手順に従って、この解決策 の導入を完了します。</block>
  <block id="4c8f77e6ab4a9e453faf4063978f94d5" category="example-title">手順1：アドオンオプションを使用して、Azure PortalからHCXをインストールする</block>
  <block id="f4ca86f94d0e12644ce102e7c48d6030" category="paragraph">インストールを実行するには、次の手順を実行します。</block>
  <block id="7d4c34e9f83446ef58ad083cd2c29580" category="list-text">Azureポータルにログインし、Azure VMware解決策 プライベートクラウドにアクセスします。</block>
  <block id="16671eada5939f5c2129db7e8f9522a0" category="list-text">適切なプライベートクラウドを選択し、アドオンにアクセスします。これを行うには、* Manage &gt; Add-ons *に移動します。</block>
  <block id="de23e32bd14f5f77d4178bb7d56c2eb0" category="list-text">[HCX Workload Mobility]セクションで、[* Get Started*]をクリックします。</block>
  <block id="239ba3d7293041d0d4dcb4c5b538ea74" category="inline-image-macro">[HCX Workload Mobility]セクションのスクリーンショット。</block>
  <block id="91a36107da2b4f5cbc4963027f871289" category="paragraph"><block ref="91a36107da2b4f5cbc4963027f871289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="de66be71be828600d682c9f0bdb03a18" category="list-text">[*契約条件に同意します*]オプションを選択し、[*有効化して展開*]をクリックします。</block>
  <block id="e26184583d86572b90efcca3db66731e" category="admonition">デフォルトの展開はHCX Advancedです。エンタープライズエディションを有効にするには、サポートリクエストを開きます。</block>
  <block id="adafe418547291754cadbfc0d2c5c1dc" category="admonition">導入には約25～30分かかります。</block>
  <block id="e39769185df95d6577314b0c683cf848" category="inline-image-macro">[HCX Workload Mobility]セクションの完了のスクリーンショット。</block>
  <block id="6df468c8490be1137779d8811f53bddb" category="paragraph"><block ref="6df468c8490be1137779d8811f53bddb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae33ed8b7695cc113850f5a13bab6e56" category="example-title">手順2：オンプレミスのvCenter ServerにインストーラOVAを導入する</block>
  <block id="e957ef97a04368fda5e2652e51c19d1d" category="paragraph">オンプレミスコネクタをAzure VMware解決策 のHCX Managerに接続するには、オンプレミス環境で適切なファイアウォールポートが開いていることを確認します。</block>
  <block id="0c216cee9411e03f1127e6ffc2bf025d" category="paragraph">HCX ConnectorをオンプレミスのvCenter Serverにダウンロードしてインストールするには、次の手順を実行します。</block>
  <block id="c28009ba42c1703c33046d99285a0a10" category="list-text">AzureポータルからAzure VMware解決策 にアクセスし、プライベートクラウドを選択して、* Manage &gt; Add-ons &gt; Migration * using HCXを選択し、HCX Cloud ManagerポータルをコピーしてOVAファイルをダウンロードします。</block>
  <block id="3a858d6f55c84c77db797aafa874a8a5" category="admonition">HCXポータルにアクセスするには、デフォルトのCloudAdminユーザー資格情報を使用します。</block>
  <block id="7efdfa090ad75b0c0f02e115ab8e56bd" category="inline-image-macro">HCX OVAファイルをダウンロードするAzureポータルのスクリーンショット。</block>
  <block id="ab9fbdf98484d630980bec96dac55284" category="paragraph"><block ref="ab9fbdf98484d630980bec96dac55284" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d5565b77c91d5d6d289858e4d7ea91" category="list-text">jumphostを使用してmailto：cloudadmin@vsphere.loca l [cloudadmin@vsphere.loca l^]でHCXポータルにアクセスしたら、* Administration &gt; System Updates *に移動し、* Request Download Link *をクリックします。</block>
  <block id="f6b26e036b373b18f11dc0da33ef5268" category="admonition">OVAをダウンロードするか、OVAにコピーしてブラウザに貼り付け、オンプレミスのvCenter Serverに導入するVMware HCX Connector OVAファイルのダウンロードプロセスを開始します。</block>
  <block id="894d2481892f65fcae6dfc0ac7b9ec0d" category="inline-image-macro">エラー：OVAダウンロードリンクのスクリーンショット。</block>
  <block id="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="paragraph"><block ref="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12e1c817f24a0aa94d2ae26ea6535479" category="list-text">OVAをダウンロードしたら、* Deploy OVF Template *オプションを使用して、OVAをオンプレミスのVMware vSphere環境に導入します。</block>
  <block id="fc1a0933af5c68cc43dbb90b50c1b0d3" category="inline-image-macro">エラー：正しいOVAテンプレートを選択するためのスクリーンショット。</block>
  <block id="d36fa73d8072d1ab34f185f12d5fede5" category="paragraph"><block ref="d36fa73d8072d1ab34f185f12d5fede5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ba87ef75729cfcffc74d93e0a0852a1" category="list-text">OVA導入に必要なすべての情報を入力し、「*次へ*」をクリックしてから、「*完了」をクリックしてVMware HCX Connector OVAを導入します。</block>
  <block id="ed1aadd2fcd5906dd58f9a89179a638e" category="admonition">仮想アプライアンスの電源を手動でオンにします。</block>
  <block id="dca749083ce6c763573225ed6a46a64e" category="inline-link">VMware HCXユーザーガイド</block>
  <block id="e10fbd147d2ee50fbbb460ad2f18fa14" category="paragraph">手順については、を参照してください<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>。</block>
  <block id="6897bb7015f874baf69560eef515010c" category="example-title">手順3：ライセンスキーを使用してHCXコネクタをアクティブにします</block>
  <block id="4aa14207b82768ed77473306cc7a65c2" category="paragraph">VMware HCX Connector OVAをオンプレミスに導入してアプライアンスを起動したら、次の手順を実行してHCX Connectorをアクティブにします。Azure VMware解決策 ポータルからライセンスキーを生成し、VMware HCXマネージャでアクティブ化します。</block>
  <block id="3535419e37127ca2de6abd9538414466" category="list-text">AzureポータルからAzure VMware解決策 にアクセスし、プライベートクラウドを選択して、* Manage &gt; Add-ons &gt; Migration Using HCX*を選択します。</block>
  <block id="436402d536d27aaa2091a54751a60036" category="list-text">[* HCXキーを使用してオンプレミスと接続する*]で、[*追加]をクリックしてアクティベーションキーをコピーします。</block>
  <block id="0b053e667d8c9baa8cbb4a5402fe69e1" category="inline-image-macro">HCXキーを追加するためのスクリーンショット。</block>
  <block id="5d9de146e997662a8510bd175e5c593a" category="paragraph"><block ref="5d9de146e997662a8510bd175e5c593a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03fc385dd3b54c80a78341c5aa2189a3" category="admonition">導入されているオンプレミスのHCXコネクタごとに別々のキーが必要です。</block>
  <block id="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link"><block ref="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link-rx"></block></block>
  <block id="b6d4af6a25f46f3687120681e525d833" category="list-text">オンプレミスのVMware HCX Managerにログインします<block ref="f9ac10929d1e2f12c4fea5c57d73b3eb" category="inline-link-rx"></block> 管理者のクレデンシャルを使用</block>
  <block id="b2719f92794cef282f9cd7684baca4c4" category="admonition">OVAの導入時に定義されたパスワードを使用します。</block>
  <block id="a864855f2120d5c8d4793a4866b6a7bb" category="list-text">ライセンスで、手順3からコピーしたキーを入力し、[* Activate*（有効化*）]をクリックします。</block>
  <block id="e5c8d88f2fa7af9f1a719e04c4b17740" category="admonition">オンプレミスのHCXコネクタにはインターネットアクセスが必要です。</block>
  <block id="ee746d79ab481579a8c0202a94e8d378" category="list-text">[*Datacenter Location]には、VMware HCX Managerをオンプレミスにインストールするために最も近い場所を指定します。[* Continue （続行） ] をクリックします</block>
  <block id="c72431b355c96ffdfb7baece307881f0" category="list-text">システム名*で名前を更新し、*続行*をクリックします。</block>
  <block id="030627b8e0e3f6ba69c6a9e524d8e9c0" category="list-text">[はい、続行]をクリックします。</block>
  <block id="05399e57e0b2a25ce8cef32f3628b2e3" category="list-text">[* vCenterの接続*]で、vCenter Serverの完全修飾ドメイン名（FQDN）またはIPアドレスと適切なクレデンシャルを入力し、[*続行]をクリックします。</block>
  <block id="96b1cf77a862dc0408a3e2e9678b2165" category="admonition">あとで接続の問題が発生しないようにFQDNを使用してください。</block>
  <block id="390f6c76fee2d7fb6d09bcedc3622467" category="list-text">Configure SSO/PSC *で、プラットフォームサービスコントローラのFQDNまたはIPアドレスを入力し、* Continue *をクリックします。</block>
  <block id="b070c615098fb975bc2bc3a9f6c67b3e" category="admonition">VMware vCenter ServerのFQDNまたはIPアドレスを入力します。</block>
  <block id="f4bb2b9a4de7e44c942457943977fd34" category="list-text">入力された情報が正しいことを確認し、[* Restart]をクリックします。</block>
  <block id="a565e4f9db7c03385f61c3bdb0f4b806" category="list-text">サービスが再起動すると、表示されるページに緑で表示されます。vCenter ServerとSSOの両方に適切な設定パラメータが必要です。これは前のページと同じである必要があります。</block>
  <block id="457446477fbd3326ba80d1248eaca490" category="admonition">この処理には10~20分かかります。また、プラグインをvCenter Serverに追加する必要があります。</block>
  <block id="1181827ced4ce13f7bd91097d9b10dac" category="inline-image-macro">完了したプロセスを示すスクリーンショット</block>
  <block id="534d4f43f7a513cf2f2152686da775ae" category="paragraph"><block ref="534d4f43f7a513cf2f2152686da775ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0b94fcafcd5f76f4f84be761263d657" category="example-title">手順4：オンプレミスのVMware HCXコネクタをAzure VMware解決策 HCX Cloud Managerとペアリングします</block>
  <block id="ae37843769e741d076e2422772db5395" category="paragraph">オンプレミスとAzure VMware解決策 の両方にHCX Connectorをインストールした後、このペアリングを追加して、オンプレミスのVMware HCX Connector for Azure VMware解決策 プライベートクラウドを構成します。サイトペアリングを設定するには、次の手順を実行します。</block>
  <block id="28b0363954066139335c413f28022037" category="list-text">オンプレミスのvCenter環境とAzure VMware解決策 SDDCの間にサイトペアを作成するには、オンプレミスのvCenter Serverにログインし、新しいHCX vSphere Web Clientプラグインにアクセスします。</block>
  <block id="f4f57342a1f5bfd667f7d19048c4aa85" category="inline-image-macro">HCX vSphere Web Clientプラグインのスクリーンショット。</block>
  <block id="1ecb33e8c47a03470ff03bb6c09a1d87" category="paragraph"><block ref="1ecb33e8c47a03470ff03bb6c09a1d87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302ca8cbe91eb456c9defb6fe514b81e" category="list-text">[インフラストラクチャ]で、[サイトペアリングの追加*]をクリックします。</block>
  <block id="cd6182a85ca09ca99bda2787165407d9" category="admonition">プライベートクラウドにアクセスするための、Azure VMware解決策 HCXのURLまたはIPアドレス、およびCloudAdminロールのクレデンシャルを入力します。</block>
  <block id="407d1d705e5bdedf2e1c5e9257c0c1ef" category="inline-image-macro">CloudAdminロールのURLまたはIPアドレスとクレデンシャルのスクリーンショット。</block>
  <block id="6e861dfeca468a35e2aa6f6a42b2ad5f" category="paragraph"><block ref="6e861dfeca468a35e2aa6f6a42b2ad5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bccd838ddedeb361e65189136ac5c0f" category="list-text">[ 接続 ] をクリックします。</block>
  <block id="7630a70e4d4511de5ac0f8ce18edd594" category="admonition">VMware HCX Connectorは、ポート443経由でHCX Cloud Manager IPにルーティングできる必要があります。</block>
  <block id="ddea1cbf444f5d4e69d68b23eb0b4b59" category="list-text">ペアリングが作成されると、新しく構成されたサイトペアリングがHCXダッシュボードで使用できるようになります。</block>
  <block id="8cdce778f46399f121d65006767f466a" category="inline-image-macro">HCXダッシュボードで完了したプロセスのスクリーンショット</block>
  <block id="a71387f99ef8fc06b56323de8e6a67e6" category="paragraph"><block ref="a71387f99ef8fc06b56323de8e6a67e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38bca9c1088c36da27f6910232836b09" category="example-title">手順5：ネットワークプロファイル、コンピューティングプロファイル、およびサービスメッシュを設定します</block>
  <block id="a030f25f2e21cc0db80d6a88646adb63" category="paragraph">VMware HCX Interconnectサービスアプライアンスは、インターネットを介したレプリケーションおよびvMotionベースの移行機能を提供し、ターゲットサイトへのプライベート接続を提供します。インターコネクトは、暗号化、トラフィックエンジニアリング、VMモビリティを提供します。インターコネクトサービスアプライアンスを作成するには、次の手順を実行します。</block>
  <block id="efb9332572aac00947298fc1ed65c0da" category="list-text">インフラストラクチャー（Infrastructure）で、*インターコネクト（Interconnect）&gt;マルチサイトサービスメッシュ（Multi-Site Service Mesh）&gt;プロファイル計算（Compute Profiles）&gt;コンピュートプロファイル作成（Create Compute Profile）*を選択</block>
  <block id="96e78a381f203820b7fb0d823994f764" category="admonition">コンピューティングプロファイルでは、導入されるアプライアンスや、HCXサービスからアクセスできるVMwareデータセンターの部分などの導入パラメータを定義します。</block>
  <block id="df03fa88f502c44f3476981d50c25ae4" category="inline-image-macro">vSphere Client Interconnectページのスクリーンショット</block>
  <block id="0f7d2c9383c1f40641b39e9f65126dcf" category="paragraph"><block ref="0f7d2c9383c1f40641b39e9f65126dcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba9d884b8a48f110e052a2644f36c6bb" category="list-text">コンピューティングプロファイルを作成したら、*マルチサイトサービスメッシュ&gt;ネットワークプロファイル&gt;ネットワークプロファイルの作成*を選択して、ネットワークプロファイルを作成します。</block>
  <block id="7e461f559c367396eca97f75c2262003" category="paragraph">ネットワークプロファイルは、HCXが仮想アプライアンスに使用するIPアドレスとネットワークの範囲を定義します。</block>
  <block id="12618dff60108a0e440afb082e782c71" category="admonition">この手順には複数のIPアドレスが必要です。これらのIPアドレスは、管理ネットワークからインターコネクトアプライアンスに割り当てられます。</block>
  <block id="9f137734809298c4fa85b07a7ddb6c5f" category="inline-image-macro">vSphere Client InterconnectページにIPアドレスを追加したスクリーンショット</block>
  <block id="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="paragraph"><block ref="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f78591a00b39059d077f422f8695286" category="list-text">現時点では、コンピューティングプロファイルとネットワークプロファイルは正常に作成されています。</block>
  <block id="5e8122825414e5afe12c228e3afb9f77" category="list-text">[Interconnect（相互接続）]オプションの[* Service Mesh（サービスメッシュ*）]タブを選択してサービスメッシュを作成し、オンプレミスサイトとAzure SDDCサイトを選択します。</block>
  <block id="efe6cc3fe15f7c67781cd956f1aa3b8e" category="list-text">サービスメッシュは、ローカルとリモートのコンピューティングプロファイルとネットワークプロファイルのペアを指定します。</block>
  <block id="292b454f1874f04a4b6f9258b5f933e4" category="admonition">このプロセスの一部として、セキュアなトランスポートファブリックを作成するために、ソースサイトとターゲットサイトの両方にHCXアプライアンスが展開され、自動的に設定されます。</block>
  <block id="0433a192b31baf05b1deba1471c492ff" category="inline-image-macro">vSphere Client InterconnectページのService Meshタブのスクリーンショット</block>
  <block id="55551523a891564fc7b09d6dec2fe75f" category="paragraph"><block ref="55551523a891564fc7b09d6dec2fe75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9df03f8fa3fc5e40e9100c8ebbd3a2ad" category="list-text">これが設定の最後の手順です。導入が完了するまでに約30分かかります。サービスメッシュを設定すると、ワークロードVMを移行するためのIPsecトンネルが正常に作成され、環境の準備が整います。</block>
  <block id="532b4e992bd2794e777d1c1320e94f98" category="inline-image-macro">vSphere Client Interconnectのページで完了したプロセスのスクリーンショット</block>
  <block id="9158466ef9c7277d9287f86080b2c362" category="paragraph"><block ref="9158466ef9c7277d9287f86080b2c362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0e8a1058909962c26cdead8b3fab020" category="example-title">手順6：ワークロードを移行する</block>
  <block id="80ea378666ca268305d30933ca376035" category="paragraph">さまざまなVMware HCX移行テクノロジを使用して、オンプレミスとAzure SDDC間でワークロードを双方向に移行できます。VMは、HCXバルク移行、HCX vMotion、HCXコールド移行、HCX Replication Assisted vMotion（HCX Enterprise Editionで利用可能）、HCX OS Assisted Migration（HCX Enterprise Editionで利用可能）などの複数の移行テクノロジーを使用して、VMware HCXでアクティブ化されたエンティティとの間で移動できます。</block>
  <block id="94638809b72d557d4335dfce65f69e35" category="inline-link">VMware HCXの移行タイプ</block>
  <block id="aa52e427086548446f11ad8e43c6e998" category="paragraph">さまざまなHCX移行メカニズムの詳細については、を参照してください<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block>。</block>
  <block id="998d1ed8e82c8145e094c99bf11f8408" category="paragraph">*一括移行*</block>
  <block id="15a3af99dcf6c8651b8f168e13625c61" category="paragraph">このセクションでは、一括移行のメカニズムについて詳しく説明します。HCXの一括移行機能では、移行先のvSphere HCXインスタンスでVMを再作成する際に、vSphere Replicationを使用してディスクファイルを移行します。</block>
  <block id="181b4946601ef2026e3d3ca16145a722" category="paragraph">VMの一括移行を開始するには、次の手順を実行します。</block>
  <block id="76b01c506c1450a5b0ff6dccaeb0e9b7" category="list-text">[*Services]&gt;[Migration*]の下の[*Migrate*]タブにアクセスします。</block>
  <block id="bdfca72da9e5f7e7bfcd81aa9844aa45" category="inline-image-macro">vSphere Clientの移行セクションのスクリーンショット。</block>
  <block id="005bf2b00a4806639f3ea37ea4509f6b" category="paragraph"><block ref="005bf2b00a4806639f3ea37ea4509f6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc18384d5bbc3aa89ffea93d51abc451" category="list-text">[リモートサイト接続*]で、リモートサイト接続を選択し、ソースとデスティネーションを選択します。この例では、デスティネーションはAzure VMware解決策 SDDC HCXエンドポイントです。</block>
  <block id="251b1066293b131079328f5d09e33aca" category="list-text">[移行するVMの選択]をクリックします。これにより、すべてのオンプレミスVMが一覧表示されます。match:value式に基づいてVMを選択し、* Add *をクリックします。</block>
  <block id="70dc92c7c0c3752e5757560b72fa8f04" category="list-text">[*転送と配置*]セクションで、移行プロファイルを含む必須フィールド（*クラスタ*、*ストレージ*、*デスティネーション*、*ネットワーク*）を更新し、[*検証*]をクリックします。</block>
  <block id="009e0b54f8062ebadb85388889541f12" category="inline-image-macro">vSphere Clientの転送と配置のセクションのスクリーンショット</block>
  <block id="e5cde894c26fccdfef420936d570829b" category="paragraph"><block ref="e5cde894c26fccdfef420936d570829b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7599f8a3668b692ca7501152d4682c07" category="list-text">検証チェックが完了したら、*移動*をクリックして移行を開始します。</block>
  <block id="79af22f136dbfe3d3bf950a72f2c5f5b" category="inline-image-macro">移行開始のスクリーンショット。</block>
  <block id="c40f6796f391e80926e1a459f389859b" category="paragraph"><block ref="c40f6796f391e80926e1a459f389859b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c1969ef22141ce348651d2b0f4eb5dd8" category="admonition">この移行では、移行元VMディスクのデータをプレースホルダディスクにレプリケートできるように、移行先vCenter内の指定したAzure NetApp Files データストアにプレースホルダディスクが作成されます。HBRはターゲットへの完全な同期に対してトリガーされ、ベースラインが完了すると、RPO（目標復旧時点）サイクルに基づいて増分同期が実行されます。フル/増分同期が完了すると、特定のスケジュールが設定されていないかぎり、スイッチオーバーが自動的にトリガーされます。</block>
  <block id="c0b39ee3609ffbaf676e9119dd912e9b" category="list-text">移行が完了したら、移行先のSDDC vCenterにアクセスして同じことを検証します。</block>
  <block id="5d882ffc756bfb07c0785abe30634c3c" category="paragraph"><block ref="5d882ffc756bfb07c0785abe30634c3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d785f8302edf28ffd50ba9bd9a1e3e5" category="paragraph">さまざまな移行オプションの詳細と、HCXを使用してオンプレミスからAzure VMware解決策 にワークロードを移行する方法については、を参照してください<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>。</block>
  <block id="73e6478a04a38e6c1af3fd112abd351f" category="paragraph">このプロセスの詳細については、次の詳細なウォークスルービデオをご覧ください。</block>
  <block id="128dd96b5323b02401db618a27f67394" category="paragraph">HCX vMotionオプションのスクリーンショットを次に示します。</block>
  <block id="d77e1c6edbcf98bc28017153ba737ae7" category="paragraph"><block ref="d77e1c6edbcf98bc28017153ba737ae7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="efb5f7e867e5fc98adcdcb1d219cdd4a" category="admonition">移行に十分な帯域幅を使用できることを確認します。</block>
  <block id="6147587d84b933dcb429334a5e2594f9" category="admonition">移行先のANFデータストアには、移行を処理するための十分なスペースが必要です。</block>
  <block id="d7372a0d2d0e1ec31f9e1d607d52e246" category="paragraph">オンプレミスのあらゆるタイプ/ベンダーストレージに存在するオールクラウドやハイブリッドクラウド、データのいずれをターゲットとしている場合でも、Azure NetApp Files とHCXは、アプリケーションワークロードを展開して移行するための優れたオプションを提供し、データ要件をアプリケーションレイヤとシームレスにすることでTCOを削減します。どのようなユースケースでも、クラウドのメリット、一貫したインフラ、オンプレミスと複数のクラウドにわたる運用、ワークロードの双方向の移動、エンタープライズクラスの容量とパフォーマンスを迅速に実現するには、Azure VMware解決策 とAzure NetApp Files を選択してください。VMware vSphere Replication、VMware vMotion、Network File Copy（NFC；ネットワークファイルコピー）を使用してストレージの接続やVMの移行を行う場合と同じ手順を実行します。</block>
  <block id="7a7f4f94771d5c3f94a76599dcacb0cf" category="list-text">Azure NetApp Files をAzure VMware解決策 SDDC上のデータストアとして使用できるようになりました。</block>
  <block id="44b43fa706a816b30490196d187959c4" category="list-text">オンプレミスからAzure NetApp Files データストアへのデータの移行は簡単です。</block>
  <block id="bc6808bfb84f0a05f9640103114929fa" category="list-text">Azure NetApp Files データストアは、移行アクティビティ中に必要な容量やパフォーマンスに合わせて簡単に拡張および縮小することができます。</block>
  <block id="61af664797ae795435faba35dd141335" category="inline-link"><block ref="61af664797ae795435faba35dd141335" category="inline-link-rx"></block></block>
  <block id="ab19b6733f7a9500ff9d392433071ef2" category="paragraph"><block ref="ab19b6733f7a9500ff9d392433071ef2" category="inline-link-rx"></block></block>
  <block id="7c5ba33b986ba469d277c4ca9f906e55" category="inline-link-macro">VMware HCXを使用して、ワークロードをFSxNデータストアに移行します</block>
  <block id="c037991d132128e15cdbfefe3ac8e997" category="list-text"><block ref="c037991d132128e15cdbfefe3ac8e997" category="inline-link-macro-rx"></block></block>
  <block id="086d898e7d4a481c2147d4eb71dff1f6" category="section-title">概要：VMware HCX、FSX ONTAP 補足データストア、およびVMware Cloudを使用した仮想マシンの移行</block>
  <block id="82778188ea3c0ca7871389afec5bfd03" category="paragraph">Amazon Web Services（AWS）上のVMware Cloud（VMC）の一般的なユースケースであり、Amazon FSX for NetApp ONTAP 上の追加のNFSデータストアは、VMwareワークロードの移行です。VMware HCXは、オンプレミスの仮想マシン（VM）とそのデータを、VMwareがサポートする任意のデータストア上で実行して、FSX for ONTAP の補足的なNFSデータストアを含むVMCデータストアに移動するための、さまざまな移行方法を推奨します。</block>
  <block id="2fbfc2601ddccd56b7728df6f0a658e1" category="paragraph">VMware HCXは、主に、クラウド間でのワークロードの移行、ワークロードの再バランシング、ビジネス継続性を簡素化するように設計されたモビリティプラットフォームです。VMware Cloud on AWSに含まれており、ワークロードを移行して、ディザスタリカバリ（DR）処理に使用するためのさまざまな方法が用意されています。</block>
  <block id="aabc04eb6cd0b22670013ea8212b7a4f" category="paragraph">このドキュメントでは、VMware HCXの導入と構成に関するステップバイステップ形式のガイダンスを提供します。これには、VMware HCXのすべての主要コンポーネント、オンプレミス、クラウドデータセンター側などが含まれ、さまざまなVM移行メカニズムが可能になります。</block>
  <block id="d493b7ce0e1cf6434fdce9bd4fa1c847" category="inline-link">HCXの導入の概要</block>
  <block id="274e6762dc6bf155637729306a74154b" category="inline-link">チェックリストB-HCXとVMware CloudをAWS SDDCデスティネーション環境にインストールします</block>
  <block id="1db2f90540d47d2fe14bfc6cad01537a" category="paragraph">詳細については、を参照してください<block ref="871067259283ae637dd3ddcf90a49e5d" category="inline-link-rx"></block> および<block ref="b5449e907f27219538721e57c42a92c0" category="inline-link-rx"></block>。</block>
  <block id="18ad70c16d20c99de2753c4da7fb1291" category="paragraph">VMware HCXのインストールと構成の手順の概要を次に示します。</block>
  <block id="b9b7e6b65417eaac8eeb13d3f809942d" category="list-text">VMwareクラウド サービス コンソールを使用して、VMC Software-Defined Data Center（SDDC）のHCXをアクティブにします。</block>
  <block id="76f775a9fe0b12df87ae0ad6b34efdd9" category="list-text">HCX Connector OVAインストーラをオンプレミスのvCenter Serverにダウンロードして導入します。</block>
  <block id="f970657dc986e56f66a60a02b1210c43" category="list-text">ライセンスキーを使用してHCXをアクティブにします。</block>
  <block id="2d7e8f746bd165e0f342b659b51cff2c" category="list-text">オンプレミスのVMware HCX ConnectorとVMC HCX Cloud Managerをペアリングします。</block>
  <block id="a9f9ba84cb2c76d9b8033c6f9ad14642" category="list-text">（任意）ネットワーク拡張を実行してネットワークを拡張し、再IP化を回避します。</block>
  <block id="f5633594a47ccbe1e89229d43cbce0ec" category="inline-link">HCXインストールの準備中</block>
  <block id="ecdf05ad108113e6a7e36c14f4d8e596" category="paragraph">作業を開始する前に、次の前提条件が満たされていることを確認してください。詳細については、を参照してください<block ref="c59343d9a8c2798bf6815397e3f08bd3" category="inline-link-rx"></block>。接続性を含む前提条件を満たした後、VMCのVMware HCXコンソールからライセンスキーを生成して、HCXを構成してアクティブ化します。HCXがアクティブ化されると、vCenter Plug-inが展開され、管理にvCenterコンソールを使用してアクセスできるようになります。</block>
  <block id="f0983a6fa9c97fbc87ff3ad43495e008" category="paragraph">HCXのアクティベーションと展開を行う前に、次のインストール手順を完了する必要があります。</block>
  <block id="dba413fdbeffb35a4459e9d3f45be3bd" category="inline-link">VMwareへのリンク</block>
  <block id="b390c6b07bec05579868558e66fda8e2" category="list-text">既存のVMC SDDCを使用するか、次の手順で新しいSDDCを作成します<block ref="11000cc7aedbe4805fa20a67d23d81ac" category="inline-link-rx"></block> またはこれ<block ref="5f912d133d878a69c5af374752da199e" category="inline-link-rx"></block>。</block>
  <block id="67cff13cad47354f1f51ce3ef47c6ddc" category="list-text">オンプレミスのvCenter環境からVMC SDDCへのネットワークパスで、vMotionを使用したVMの移行がサポートされている必要があります。</block>
  <block id="c9f9609ee5731fe3777e57937464dc54" category="list-text">必要なを確認します<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> オンプレミスのvCenter ServerとSDDC vCenter間のvMotionトラフィックに許可されます。</block>
  <block id="aa8db0799849f7e0b11c7c3594394423" category="list-text">ONTAP NFSボリュームのFSXは、VMC SDDCに補助的なデータストアとしてマウントする必要があります。NFSデータストアを適切なクラスタに接続するには、以下の手順を実行します<block ref="2d161daeb93489b09b5e8bcd39dbc4b1" category="inline-link-rx"></block> またはこれ<block ref="6eb21d78e613b27f69be6d996a6367b3" category="inline-link-rx"></block>。</block>
  <block id="915747189317f7496ecb2bcdc22e83b5" category="paragraph">テスト目的では、この検証に使用したオンプレミスのラボ環境をサイト間VPNを介してAWS VPCに接続しました。これにより、オンプレミスでAWSに接続し、さらに外部の中継ゲートウェイ経由でVMwareクラウドSDDCに接続できるようになりました。HCx移行およびネットワーク拡張トラフィックは、オンプレミスとVMwareクラウドのデスティネーションSDDC間でインターネットを介して送信されます。このアーキテクチャは、Direct Connectプライベート仮想インターフェイスを使用するように変更できます。</block>
  <block id="20c789c477f416c40ed37a0a96f352d5" category="paragraph">次の図は、アーキテクチャの概要を示しています。</block>
  <block id="9f4db1da9d84fe1111fd9ae7c377f786" category="paragraph"><block ref="9f4db1da9d84fe1111fd9ae7c377f786" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5189f076565998395f00538902b201d3" category="example-title">手順1：アドオンオプションを使用してVMC SDDC経由でHCXをアクティブにします</block>
  <block id="84d84827fbe9c4b33c9c3b806b314d3f" category="inline-link">vmc.vmware.com</block>
  <block id="db44791d0479a0d2c9f5549eac8850ad" category="list-text">でVMCコンソールにログインします<block ref="98f8f917cb7f10ee415fb6ce242d9349" category="inline-link-rx"></block> Inventoryにアクセスします。</block>
  <block id="049aac4163d4ee979d2ebd21434216a2" category="list-text">適切なSDDCを選択し、アドオンにアクセスするには、[SDDCで詳細を表示]をクリックして、[Add ONS]タブを選択します。</block>
  <block id="933c74bf858432dc81f521597cffbfbb" category="list-text">Activate for VMware HCXをクリックします。</block>
  <block id="7335132a517aad5765c48773404c2687" category="admonition">この手順の完了には最大25分かかります。</block>
  <block id="be7b0f3d5e22843c4a2107342b36330b" category="paragraph"><block ref="be7b0f3d5e22843c4a2107342b36330b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcf3d539a908f48f7d82acf7470675f7" category="list-text">導入が完了したら、HCX Managerとそれに関連するプラグインがvCenterコンソールで使用可能であることを確認して、導入を検証します。</block>
  <block id="8c0cff0c106bc3f5a4dd79c01c3de7a9" category="list-text">適切な管理ゲートウェイファイアウォールを作成して、HCX Cloud Managerへのアクセスに必要なポートを開きます。HCX Cloud ManagerはHCX操作に対応しています。</block>
  <block id="6eac4c95d8f88bfb601f7b87770513ab" category="paragraph">オンプレミスコネクタがVMCのHCXマネージャと通信するためには、適切なファイアウォールポートがオンプレミス環境で開いていることを確認します。</block>
  <block id="185b9319145cb225cdb1256b494e0595" category="list-text">VMCコンソールからHCXダッシュボードに移動し、管理に移動して、システム更新タブを選択します。HCX Connector OVAイメージのRequest a Download Linkをクリックします。</block>
  <block id="039b399de18508b9f1029358886fea99" category="list-text">HCXコネクタをダウンロードした状態で、OVAをオンプレミスのvCenter Serverに導入します。vSphere Clusterを右クリックし、Deploy OVF Templateオプションを選択します。</block>
  <block id="bd18e96a29eec74967666d876a146937" category="paragraph"><block ref="bd18e96a29eec74967666d876a146937" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8df6b0257b180b48db7d56e06e4da54" category="list-text">Deploy OVF Templateウィザードで必要な情報を入力し、NextをクリックしてからFinishをクリックして、VMware HCX Connector OVAを導入します。</block>
  <block id="8925cbdefd949dca662858e368d4ccfb" category="list-text">仮想アプライアンスの電源を手動でオンにします。詳しい手順については、を参照してください<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>。</block>
  <block id="fab9859fcf95f41f7bb654e91e6876b4" category="paragraph">VMware HCX Connector OVAをオンプレミスに導入してアプライアンスを起動したら、次の手順を実行してHCX Connectorをアクティブにします。VMCのVMware HCXコンソールからライセンスキーを生成し、VMware HCX Connectorのセットアップ中にライセンスを入力します。</block>
  <block id="fddda62632eb91015346909c9da3cf70" category="list-text">VMware Cloud Consoleで、Inventory（インベントリ）に移動し、SDDCを選択してView Details（詳細の表示）をクリックします。アドオンタブのVMware HCXタイルで、HCXを開くをクリックします。</block>
  <block id="51e51578490c90a69c673d41361b0070" category="list-text">Activation Keysタブで、Create Activation Keyをクリックします。システムタイプをHCXコネクタとして選択し、確認をクリックしてキーを生成します。アクティベーションキーをコピーします。</block>
  <block id="e30847f53a6e375f1da81f871c44e963" category="paragraph"><block ref="e30847f53a6e375f1da81f871c44e963" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c410deb9d7b04917aff523f97f944894" category="admonition">オンプレミスに配置されたHCXコネクタごとに、個別のキーが必要です。</block>
  <block id="1111fa8f5187058abdce3daca03b7e32" category="inline-link"><block ref="1111fa8f5187058abdce3daca03b7e32" category="inline-link-rx"></block></block>
  <block id="d9432955aa7705a1f97c9e94c730fdc9" category="list-text">オンプレミスのVMware HCX Connectorにログインします<block ref="ece20a9f7dc6720cdeb30c7e7733cd22" category="inline-link-rx"></block> 管理者のクレデンシャルを使用</block>
  <block id="f5f8371708aa6ae3ddb84d1f4d9b5d17" category="list-text">[ライセンス交付（Licensing）]セクションで、手順2からコピーしたアクティベーションキーを入力し、[有効化（Activate）]をクリックします。</block>
  <block id="404a7c7a7d73b870628663e76e974d09" category="admonition">有効化を正常に完了するには、オンプレミスHCXコネクタにインターネットアクセスが必要です。</block>
  <block id="564ed09bba79e1d4262e37fc94987fbe" category="list-text">データセンターの場所で、VMware HCX Managerをオンプレミスにインストールする場所を指定します。Continue をクリックします。 .</block>
  <block id="61ce05ace76ff1424841e5e551873a97" category="list-text">[システム名]で名前を更新し、[続行]をクリックします。</block>
  <block id="4bc852451f43c4b3df306f35e67e4178" category="list-text">[はい]を選択してから、[続行]</block>
  <block id="7eefbebbdefe472b13ce5d0bce410737" category="list-text">[vCenterの接続]で、IPアドレスまたは完全修飾ドメイン名（FQDN）とvCenter Serverの資格情報を入力し、[続行]をクリックします。</block>
  <block id="47a7ea3464363cf9baa528c91d3aa4dc" category="admonition">あとで通信の問題が発生しないようにFQDNを使用してください。</block>
  <block id="eb7e70dd1954a71454c2e6a0cb9ed5f8" category="list-text">Configure SSO/PSC（SSO/PSCの設定）で、Platform Services ControllerのFQDNまたはIPアドレスを入力し、Continue（続行）をクリックします。</block>
  <block id="1f2f2ed2ec24b1f1ab37799a6f27fa40" category="admonition">vCenter ServerのIPアドレスまたはFQDNを入力します。</block>
  <block id="24b993e60859697b0875bc838cfe12aa" category="list-text">情報が正しく入力されていることを確認し、[再起動]をクリックします。</block>
  <block id="b0fca3e3f2889bbec562577014fafd9a" category="list-text">完了すると、vCenter Serverは緑で表示されます。vCenter ServerとSSOの両方で、前のページと同じ設定パラメータを指定する必要があります。</block>
  <block id="8463d9f0fc95490bc0c65d3ba9063dea" category="admonition">この処理には10~20分かかります。また、プラグインをvCenter Serverに追加することもできます。</block>
  <block id="a56ac8f65b53b91dba588aafc428f8b2" category="paragraph"><block ref="a56ac8f65b53b91dba588aafc428f8b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65d6e263d26134bb05aeec17adc73a06" category="example-title">手順4：オンプレミスのVMware HCXコネクタをVMC HCX Cloud Managerとペアリングします</block>
  <block id="f68b6001164eba9a9e765e551c59a3c1" category="list-text">オンプレミスのvCenter ServerとVMC SDDCの間にサイトペアを作成するには、オンプレミスのvCenter Serverにログインして、HCX vSphere Web Clientプラグインにアクセスします。</block>
  <block id="10f9af0781b3c0a9d621bac0b8719365" category="paragraph"><block ref="10f9af0781b3c0a9d621bac0b8719365" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1af79e59a8d820cc101f77efa75cb01d" category="list-text">[インフラストラクチャ]で、[サイトペアリングの追加]をクリックします。リモートサイトを認証するには、VMC HCX Cloud ManagerのURLまたはIPアドレス、およびCloudAdminロールのクレデンシャルを入力します。</block>
  <block id="1b49b2932a225dd49cc6f5298ad6cc8f" category="paragraph"><block ref="1b49b2932a225dd49cc6f5298ad6cc8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7c72a1b7e925abd687d2c7a4ac5a2f" category="admonition">HCx情報は、SDDC Settingsページから取得できます。</block>
  <block id="1272226ee970b8e49c49d25af6f4b6b8" category="paragraph"><block ref="1272226ee970b8e49c49d25af6f4b6b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="838d70471e28171464ffd4fed8d9df3a" category="paragraph"><block ref="838d70471e28171464ffd4fed8d9df3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dbcfb2058c277401b0872487463fe313" category="list-text">サイトのペアリングを開始するには、[接続]をクリックします。</block>
  <block id="2147cde45e80d7c6a5db679f7180eab4" category="admonition">VMware HCX Connectorは、ポート443経由でHCX Cloud Manager IPと通信できる必要があります。</block>
  <block id="618a4f677a45dc2b53f7c464b5598c28" category="paragraph">VMware HCX Interconnect（HCX-IX）アプライアンスは、インターネットを介したセキュアなトンネル機能と、レプリケーションおよびvMotionベースの機能を実現するターゲットサイトへのプライベート接続を提供します。インターコネクトは、暗号化、トラフィックエンジニアリング、SD-WANを提供します。HCI IX Interconnect Applianceを作成するには、次の手順を実行します。</block>
  <block id="f32fcca3303979d42a8f0be055fc36dd" category="list-text">インフラストラクチャー（Infrastructure）で、相互接続（Interconnect）&gt;マルチサイトサービスメッシュ（Multi-Site Service Mesh）&gt;プロファイル計算（Compute Profiles）&gt;コンピュートプロファイルの作成（Create Compute Profile</block>
  <block id="46c0e6a1b2dbd6331bcea8e4726de843" category="admonition">コンピューティングプロファイルには、インターコネクト仮想アプライアンスの導入に必要なコンピューティング、ストレージ、およびネットワーク導入のパラメータが含まれています。また、VMwareデータセンターのどの部分にHCXサービスからアクセスできるかを指定します。</block>
  <block id="46a447d35c4917802c9d612dd8ede3b5" category="inline-link">計算プロファイルの作成</block>
  <block id="9fc475734bed02e370e17ea150a74fd3" category="paragraph">手順の詳細については、を参照してください<block ref="3e2a71be9bcd47a34446e38d1b8f4987" category="inline-link-rx"></block>。</block>
  <block id="648388c6923f0b4fc45138b46fb56158" category="paragraph"><block ref="648388c6923f0b4fc45138b46fb56158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3c8534d57516f63a1f263c7e4a4c7a" category="list-text">コンピューティングプロファイルを作成したら、Multi-Site Service Mesh &gt; Network Profiles &gt; Create Network Profileを選択して、ネットワークプロファイルを作成します。</block>
  <block id="52d18a4f9043fce9a1e9d57e92fc77a4" category="list-text">ネットワークプロファイルは、HCXが仮想アプライアンスに使用するIPアドレスとネットワークの範囲を定義します。</block>
  <block id="2565e95c468130be3fbdbb45da6cadeb" category="admonition">これには2つ以上のIPアドレスが必要です。これらのIPアドレスは、管理ネットワークから仮想アプライアンスに割り当てられます。</block>
  <block id="f62f78e1c7b4b764032cbdad0c61a6d0" category="paragraph"><block ref="f62f78e1c7b4b764032cbdad0c61a6d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9fad750cff1511b959d686e3a0829f0" category="inline-link">ネットワークプロファイルの作成</block>
  <block id="51cbf458571723275b781ce4b3fec323" category="paragraph">手順の詳細については、を参照してください<block ref="fb1b37f7979e3209d40171b59e47f33b" category="inline-link-rx"></block>。</block>
  <block id="784e6023ad40986353535651f974e468" category="admonition">インターネット経由でSD-WANに接続する場合は、[ネットワークとセキュリティ]セクションでパブリックIPを予約する必要があります。</block>
  <block id="c1b5864550e5f67407a0efd2cbe55b67" category="list-text">サービスメッシュを作成するには、InterconnectオプションのService Meshタブを選択し、オンプレミスサイトとVMC SDDCサイトを選択します。</block>
  <block id="295ecbce57290e03752d2e06d4575fff" category="paragraph">サービスメッシュによって、ローカルとリモートのコンピューティングプロファイルとネットワークプロファイルのペアが確立されます。</block>
  <block id="1e21db3cc04207cfb46fd912cdfef571" category="paragraph"><block ref="1e21db3cc04207cfb46fd912cdfef571" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba94996b6f6f31ef7ea483dc8f0046c" category="admonition">このプロセスの一部では、ソースサイトとターゲットサイトの両方で自動的に構成されるHCXアプライアンスを展開し、セキュアなトランスポートファブリックを作成します。</block>
  <block id="b7e93bb3e8f576437ca086d1702a7994" category="list-text">ソースとリモートのコンピューティングプロファイルを選択し、Continue（続行）をクリックします。</block>
  <block id="ef7ca07b9da6362e4aa341061333a66c" category="paragraph"><block ref="ef7ca07b9da6362e4aa341061333a66c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e42fcfe670e1a9e7a259fb3c9d3dad87" category="list-text">アクティブにするサービスを選択し、[続行]をクリックします。</block>
  <block id="ff89555f65d5e42967fac9abcecb74c8" category="paragraph"><block ref="ff89555f65d5e42967fac9abcecb74c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8438ec331921e82a31eaa97deb5f8c0" category="admonition">Replication Assisted vMotion Migration、SRM Integration、およびOS Assisted Migrationには、HCX Enterpriseライセンスが必要です。</block>
  <block id="9a44378d7dd14730acf075e18d7d8c29" category="list-text">サービスメッシュの名前を作成し、完了をクリックして作成プロセスを開始します。導入が完了するまでに約30分かかります。サービスメッシュを設定したら、ワークロードVMの移行に必要な仮想インフラとネットワークを作成します。</block>
  <block id="725a12cf06f45e850e7588b816663c20" category="paragraph"><block ref="725a12cf06f45e850e7588b816663c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0de3992884fcc0e48531f19cce447e7" category="example-title">手順6：ワークロードを移行する</block>
  <block id="af65fc6bdee93e32363bfe5c2cf8ee3a" category="paragraph">HCxは、オンプレミスやVMC SDDCなど、2つ以上の異なる環境間で双方向の移行サービスを提供します。HCXバルク移行、HCX vMotion、HCXコールド移行、HCX Replication Assisted vMotion（HCX Enterprise Editionで利用可能）、HCX OS Assisted Migration（HCX Enterprise Editionで利用可能）などのさまざまな移行テクノロジーを使用して、HCXでアクティブ化されたサイトとの間でアプリケーションワークロードを移行できます。</block>
  <block id="0afeac0ffbe358cc58864e34fc54c9b2" category="paragraph">使用可能なHCX移行テクノロジの詳細については、を参照してください<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block></block>
  <block id="97957dd6d4c5d792035241d68a97795e" category="paragraph">HCX-IXアプライアンスは、Mobility Agentサービスを使用して、vMotion、コールド、およびReplication Assisted vMotion（RAV）の移行を実行します。</block>
  <block id="2234ed56b9cbb2a083fd5fe49a89bce1" category="admonition">HCX-IXアプライアンスは、Mobility AgentサービスをvCenter Serverのホストオブジェクトとして追加します。このオブジェクトに表示されるプロセッサ、メモリ、ストレージ、およびネットワークのリソースは、IXアプライアンスをホストする物理ハイパーバイザーでの実際の消費量を表していません。</block>
  <block id="c3735752087d3a11c85329680057de55" category="paragraph"><block ref="c3735752087d3a11c85329680057de55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c14d0d24d8dccac2ac3ca3ddacf8ba8" category="example-title">VMware HCX vMotion</block>
  <block id="8f2dbd716f60bbee8012a3f0e361fc65" category="paragraph">このセクションでは、HCX vMotionメカニズムについて説明します。この移行テクノロジは、VMware vMotionプロトコルを使用してVMをVMC SDDCに移行します。vMotion移行オプションは、一度に1つのVMのVM状態を移行するために使用します。このマイグレーション方式では、サービスは中断されません。</block>
  <block id="0c1394a246edcdcb98e3c5fe3cedabbb" category="admonition">IPアドレスを変更せずにVMを移行するには、ネットワーク拡張を設定する必要があります（VMが接続されているポートグループの場合）。</block>
  <block id="896f227a656a8b0f4a64aa3e12b2506e" category="list-text">オンプレミスのvSphereクライアントから、Inventoryに移動し、移行するVMを右クリックして、HCX Actions &gt; Migrate to HCX Target Siteを選択します。</block>
  <block id="d683c9596c42727fea13c654874f39be" category="paragraph"><block ref="d683c9596c42727fea13c654874f39be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4479366aca979ecb9be874cab7bc543" category="list-text">仮想マシンの移行ウィザードで、リモートサイト接続（ターゲットVMC SDDC）を選択します。</block>
  <block id="09ca4fea7b9ff384e38622ce7cc20a9c" category="paragraph"><block ref="09ca4fea7b9ff384e38622ce7cc20a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67358e55b470861e1e14c63c30156dd4" category="list-text">グループ名を追加し、[転送と配置]の下で必須フィールド(クラスタ、ストレージ、および宛先ネットワーク)を更新し、[検証]をクリックします。</block>
  <block id="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="paragraph"><block ref="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a961199f9300128fcaa431e9245ac13" category="list-text">検証チェックが完了したら、Goをクリックして移行を開始します。</block>
  <block id="f3d5cf5ffd51c9062748a6a292f749f7" category="inline-link">VMware HCX vMotionとコールドマイグレーションについて理解する</block>
  <block id="136739244c82e4bdcdb6a1b1c3712d3b" category="admonition">vMotionによる転送では、VMのアクティブメモリ、実行状態、IPアドレス、およびMACアドレスがキャプチャされます。HCX vMotionの要件と制限の詳細については、を参照してください<block ref="011541f11351d17074bdfa0823ec743b" category="inline-link-rx"></block>。</block>
  <block id="f2ca81fdc3e7326c354dc180a98c7ef2" category="list-text">VMotionの進捗状況と完了は'HCX＞Migrationダッシュボードから監視できます</block>
  <block id="b41362505f00e258d5e04636a0edaf7c" category="paragraph"><block ref="b41362505f00e258d5e04636a0edaf7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e4900648931ee918be9251a268e792c" category="example-title">VMware Replication Assisted vMotionの場合</block>
  <block id="3bb995dd361711179fda278eb498a385" category="paragraph">VMwareのドキュメントに気づいたように、VMware HCX Replication Assisted vMotion（RAV）は、バルク移行とvMotionのメリットを組み合わせています。一括移行では、vSphere Replicationを使用して複数のVMが同時に移行されます。これは、スイッチオーバー中にVMがリブートされるためです。HCx vMotionはダウンタイムなしで移行を行いますが、レプリケーショングループで一度に1つのVMが順次実行されます。RAVは、VMを並行して複製し、スイッチオーバーウィンドウまで同期させます。スイッチオーバープロセスでは、VMを停止することなく一度に1つずつ移行します。</block>
  <block id="93e2f4753a86232a37f8bd57209f626d" category="paragraph">次のスクリーンショットは、マイグレーションプロファイルをReplication Assisted vMotionとして示しています。</block>
  <block id="7c12abc7edfaeb45279b8ee126759269" category="paragraph"><block ref="7c12abc7edfaeb45279b8ee126759269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a740a2796b321475f6bd003fafa67e5b" category="paragraph">レプリケーションの所要時間は、少数のVMのvMotionよりも長くなる可能性があります。RAVでは、差分のみを同期し、メモリの内容を含めます。以下はマイグレーションステータスのスクリーンショットです。マイグレーションの開始時刻がVMごとに異なり、終了時刻も表示されます。</block>
  <block id="27e8bd561ebb9d9ee4d23860c10a3883" category="paragraph"><block ref="27e8bd561ebb9d9ee4d23860c10a3883" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e61c2a41cf1924a0a1e3d5217e16a084" category="paragraph">HCXマイグレーションオプションと、HCXを使用してオンプレミスからAWS上のVMware Cloudにワークロードを移行する方法については、を参照してください追加情報<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>。</block>
  <block id="f261622b527cc27756d5ba83c22662f8" category="admonition">VMware HCX vMotionには、100 Mbps以上のスループット機能が必要です。</block>
  <block id="60bd242580d7de82c0a2e6eee14d2f50" category="admonition">ONTAP データストア用のターゲットVMC FSXには、移行に対応できる十分なスペースが必要です。</block>
  <block id="17e30673228b69814c7132c287c12ecb" category="paragraph">オールクラウドとハイブリッドクラウドのどちらをターゲットとしていても、オンプレミスのあらゆるタイプ/ベンダーストレージに保存されているデータを対象としている場合でも、NetApp ONTAP 対応のAmazon FSXとHCXは、データ要件をアプリケーションレイヤにシームレスにすることで、ワークロードの導入と移行を実現する優れたオプションを提供します。どのようなユースケースでも、VMCとFSX for ONTAP データストアを選択すれば、オンプレミスと複数のクラウドにわたるクラウドのメリット、一貫したインフラ、運用、ワークロードの双方向の移動、エンタープライズクラスの容量とパフォーマンスを迅速に実現できます。VMware vSphereレプリケーション、VMware vMotion、さらにはNFCコピーを使用してストレージを接続し、VMを移行するための一般的なプロセスと手順は同じです。</block>
  <block id="273435500e4b837aea488094a233f579" category="list-text">Amazon FSX ONTAP をVMC SDDCを使用するデータストアとして使用できるようになりました。</block>
  <block id="cbbc4fc2bc12f5fd25f84b44f93fd5f3" category="list-text">ONTAP データストア用のFSXを使用して、任意のオンプレミスデータセンターからVMCに簡単にデータを移行できます</block>
  <block id="9004e09f6485129980daf3188affad35" category="list-text">移行アクティビティ中に容量とパフォーマンスの要件を満たすために、FSX ONTAP データストアを簡単に拡張および縮小できます。</block>
  <block id="34e948a9d10cb991d2da187e3e54caef" category="list-text">VMware Cloudのドキュメント</block>
  <block id="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link"><block ref="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link-rx"></block></block>
  <block id="1427dee608f6801474787ea58df57a2c" category="paragraph"><block ref="1427dee608f6801474787ea58df57a2c" category="inline-link-rx"></block></block>
  <block id="cc788b7e72b2a734dd0985bd1e0e9fe3" category="list-text">Amazon FSX for NetApp ONTAP のドキュメント</block>
  <block id="9c7174d13497f84bdd0b3e21af13794d" category="inline-link"><block ref="9c7174d13497f84bdd0b3e21af13794d" category="inline-link-rx"></block></block>
  <block id="05c89cf5b898c5c58986dac08f22a2a1" category="paragraph"><block ref="05c89cf5b898c5c58986dac08f22a2a1" category="inline-link-rx"></block></block>
  <block id="33efddb311b6c85bba97e5349040815f" category="sidebar">ワークロード移行ソリューション</block>
  <block id="e946411f5b47d53428345ae0e0e5f5fd" category="sidebar">ワークロードのマイグレート</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="6ff1dafebf930a9c5fef12bf43046987" category="example-title">エンタープライズアプリケーションとデータベース</block>
  <block id="98e44b407e40d6f57f90877a1960efae" category="list-text"><block ref="98e44b407e40d6f57f90877a1960efae" category="inline-link-macro-rx"></block></block>
  <block id="e2cd0f8dc5281c13263991c6973df405" category="list-text"><block ref="e2cd0f8dc5281c13263991c6973df405" category="inline-link-macro-rx"></block></block>
  <block id="bf49d74794280c8a3a207a97d6447db7" category="list-text"><block ref="bf49d74794280c8a3a207a97d6447db7" category="inline-link-macro-rx"></block></block>
  <block id="4efd965058c15f138d2c4d43454c3012" category="list-text"><block ref="4efd965058c15f138d2c4d43454c3012" category="inline-link-macro-rx"></block></block>
  <block id="5bfc3700f5feddf9397449627edbbdb9" category="example-title">コンテナ/ Kubernetes</block>
  <block id="665b01682714e51e25b232a31a06b70e" category="inline-link-macro">NetAppとGoogle Anthosのビデオ</block>
  <block id="810afd9a3a1d12fd9dd41977c9ed1781" category="list-text"><block ref="810afd9a3a1d12fd9dd41977c9ed1781" category="inline-link-macro-rx"></block></block>
  <block id="668ed010c67826eb36328daf61db1909" category="inline-link-macro">ネットアップとVMware Tanzuのビデオ</block>
  <block id="f05d310ffaf62c6645cbc528c52f46e1" category="list-text"><block ref="f05d310ffaf62c6645cbc528c52f46e1" category="inline-link-macro-rx"></block></block>
  <block id="19ec96fa965825479da361c5626b34f0" category="inline-link-macro">ネットアップのDevOps向けビデオ</block>
  <block id="f1afd91555fd6fb162a6343cf91fdc05" category="list-text"><block ref="f1afd91555fd6fb162a6343cf91fdc05" category="inline-link-macro-rx"></block></block>
  <block id="70fc473134508f4cbdb235049ab72bc6" category="inline-link-macro">Red Hat OpenShiftを搭載したネットアップのビデオをご覧ください</block>
  <block id="f86f2e66a68f28ad563c787ff0145ba4" category="list-text"><block ref="f86f2e66a68f28ad563c787ff0145ba4" category="inline-link-macro-rx"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">本ドキュメントでは、ティアストレージベンチマークキットを使用した、NetApp ONTAP 上の流暢なプラットフォームのパフォーマンスベンチマークについて説明します。</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941：ネットアップのONTAP ストレージコントローラに精通していること</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam、Joe Scott、NetApp Rankesh Kumar、Conluent</block>
  <block id="f79dab50e0f9664c4b4d604319a8cbbe" category="paragraph">Conluent Platformの拡張性と柔軟性を高めるには、ワークロードを非常に迅速に拡張し、バランスを調整できる必要があります。階層型ストレージを使用すると、このような運用上の負担が軽減されるため、大量のデータを管理しやすくなります。基本的には、データストレージとデータ処理を分離することで、各ストレージを個別に簡単に拡張できるようにすることが重要です。</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">業界をリードする革新的なテクノロジを搭載したNetApp ONTAP データ管理ソフトウェアは、データの保存場所にかかわらず、多様なメリットを提供します。</block>
  <block id="ff221b4a7c17defefb1a32cf9136086d" category="inline-link-macro">次へ：解決策</block>
  <block id="700a1e72f5247529520dfae6b0d991e3" category="paragraph"><block ref="700a1e72f5247529520dfae6b0d991e3" category="inline-link-macro-rx"></block></block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">このページでは、この解決策 で使用されるテクノロジーについて説明します。</block>
  <block id="1ac2a5604ed02bc66c4d6241b534d13b" category="inline-link-macro">前へ：解決策。</block>
  <block id="9ec2e79862a05fa25e8c20aa973e0d4b" category="paragraph"><block ref="9ec2e79862a05fa25e8c20aa973e0d4b" category="inline-link-macro-rx"></block></block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">NetApp ONTAP ストレージコントローラ</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP は、ハイパフォーマンスなエンタープライズクラスのストレージオペレーティングシステムです。</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8では、Amazon Simple Storage Service（S3）APIがサポートされるようになりました。ONTAP は、Amazon Web Services（AWS）S3 APIアクションのサブセットをサポートしており、クラウドプロバイダ（AWS、Azure、GCP）とオンプレミスの両方のONTAPベースシステムでデータをオブジェクトとして表すことができます。</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">ネットアップのStorageGRID ソフトウェアは、オブジェクトストレージ向けの主力製品であるネットアップの解決策 です。ONTAP は、エッジ上での取り込み/前処理ポイントを提供することでStorageGRID を補完します。ネットアップが提供するオブジェクトデータ向けデータファブリックを拡張し、ネットアップ製品ポートフォリオの価値を高めます。</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">S3バケットへのアクセスは、許可されたユーザアプリケーションとクライアントアプリケーションを介して提供されます。次の図は、S3バケットにアクセスするアプリケーションを示しています。</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">次の図は、S3バケットにアクセスするアプリケーションを示しています。</block>
  <block id="6090835a60a6e1de5e0c995ca8c5e5f8" category="paragraph"><block ref="6090835a60a6e1de5e0c995ca8c5e5f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">主なユースケース</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">S3 APIをサポートする主な目的は、ONTAP でオブジェクトへのアクセスを提供することです。ONTAP ユニファイドストレージアーキテクチャで、ファイル（NFSおよびSMB）、ブロック（FCおよびiSCSI）、オブジェクト（S3）がサポートされるようになりました。</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">ネイティブS3アプリケーション</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">S3を使用したオブジェクトアクセスにONTAP のサポートを利用できるアプリケーションが増えています。大容量のアーカイブワークロードには適していますが、ネイティブS3アプリケーションではハイパフォーマンスが急速に拡大しており、次のようなニーズがあります。</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">分析</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">人工知能</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">エッジからコアへの取り込み</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">ONTAP System Managerなど、使い慣れた管理ツールを使用して、ONTAP の開発や運用に使用できる高性能オブジェクトストレージを迅速にプロビジョニングできるようになりました。そのため、ONTAP のStorage Efficiency機能とセキュリティを活用できます。</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">FabricPool エンドポイント</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">ONTAP 9.8以降では、FabricPool でONTAP のバケットへの階層化がサポートされるため、ONTAP間で階層化できます。これは、既存のFAS インフラをオブジェクトストアのエンドポイントとして転用する場合に最適なオプションです。</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool では、次の2つの方法でONTAP への階層化がサポートさ</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*ローカルクラスタ階層化。*非アクティブなデータは、クラスタLIFを使用してローカルクラスタにあるバケットに階層化されます。</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*リモートクラスタの階層化。*非アクティブなデータは、FabricPool クライアントのIC LIFとONTAP オブジェクトストアのデータLIFを使用して、従来のFabricPool クラウド階層と同様に、リモートクラスタにあるバケットに階層化されます。</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">ONTAP S3 は、ハードウェアや管理の追加なしで既存のクラスタの S3 機能を利用する場合に適しています。300TBを超える導入については、NetApp StorageGRID ソフトウェアを引き続き、オブジェクトストレージ向けの主要なネットアップ解決策 としてご利用いただけます。ONTAP またはStorageGRID をクラウド階層として使用する場合は、FabricPool ライセンスは必要ありません。</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">格納域の優れた階層化ストレージを実現するNetApp ONTAP</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">すべてのデータセンターで、ビジネスクリティカルなアプリケーションの稼働を維持し、重要なデータの可用性とセキュリティを確保する必要があります。新しいNetApp AFF A900システムは、ONTAP Enterprise Editionソフトウェアを搭載し、耐障害性に優れた設計を採用しています。ネットアップの新しい高速NVMeストレージシステムは、ミッションクリティカルな運用の中断をなくし、パフォーマンスの調整を最小限に抑え、ランサムウェア攻撃からデータを保護します。</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">初期導入から流暢なクラスタの拡張に至るまで、ビジネスクリティカルなアプリケーションに影響を伴わない変化に迅速に適応する必要があります。ONTAP のエンタープライズデータ管理、Quality of Service（QoS；サービス品質）、およびパフォーマンスにより、お客様の環境を計画して適合させることができます。</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">ネットアップのONTAP とConluent Tiered Storageを併用すると、スケールアウトストレージターゲットとしてONTAP を利用することでApache Kafkaクラスタの管理が簡素化され、流暢なコンピューティングリソースとストレージリソースを個別に拡張できます。</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">ONTAP S3サーバは、成熟したONTAP のスケールアウトストレージ機能を基盤としています。ONTAP クラスタをシームレスONTAP に拡張するには、新しく追加したノードを使用するようにS3バケットを拡張します。</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">ONTAP システムマネージャを使用してシンプルな管理を実現</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">ONTAP System Managerは、ブラウザベースのグラフィカルインターフェイスで、ONTAP ストレージコントローラの設定、管理、監視を、単一のコンソールから世界中に分散して実行できます。</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">この図は、ONTAP System Managerのワークスペースを示しています。</block>
  <block id="45e8e67e3e5407c5dc518dd00eb8249b" category="paragraph"><block ref="45e8e67e3e5407c5dc518dd00eb8249b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">ONTAP S3は、System ManagerおよびONTAP CLIを使用して設定および管理できます。System Managerを使用してS3を有効にしてバケットを作成する場合、ONTAP では、シンプルな設定を実現するためのデフォルトのベストプラクティスが提供されます。CLIからS3サーバとバケットを設定した場合は、必要に応じてSystem Managerでそれらを管理することも、その逆も可能です。</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">System Manager を使用して S3 バケットを作成すると、 ONTAP によって、システムで最も使用可能なパフォーマンスサービスレベルがデフォルトで設定されます。たとえば、AFF システムの場合、デフォルト設定は「最高レベル」です。パフォーマンスサービスレベルは、事前定義されたアダプティブQoSポリシーグループです。カスタムの QoS ポリシーグループを指定する場合は、デフォルトのサービスレベルのいずれかを指定する代わりに、ポリシーグループを指定しなくてもかまいません。</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">事前定義されたアダプティブQoSポリシーグループには次のものがあります。</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*最高レベル*。低レイテンシと最高レベルのパフォーマンスを必要とするアプリケーションに使用されます。</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*パフォーマンス。*適度なパフォーマンスとレイテンシが求められるアプリケーションに使用します。</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*値。スループットと容量がレイテンシよりも重要なアプリケーションに使用。</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*カスタム。*カスタムのQoSポリシーを指定するか、QoSポリシーなしで指定します。</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">[ 階層化に使用する *] を選択した場合、パフォーマンスサービスレベルは選択されず、階層化データに最適なパフォーマンスを備えた低コストのメディアを選択しようとします。</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP は、選択したサービスレベルを満たす最も適切なディスクを含むローカル階層でこのバケットをプロビジョニングしようとします。ただし、バケットに含めるディスクを指定する必要がある場合は、 CLI でローカル階層（アグリゲート）を指定して S3 オブジェクトストレージを設定することを検討してください。CLI から S3 サーバを設定した場合も、必要に応じて System Manager で管理できます。</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">バケットに使用するアグリゲートを指定できるようにするには、 CLI を使用する必要があります。</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Conflicent Platform は、データへのアクセス、保存、管理を継続的なリアルタイムストリームとして簡単に行うことができる、フルスケールのデータストリーミングプラットフォームです。ConFluent では、 Apache Kafka を作成した元のクリエイターが開発したサービスを利用して、 Kafka のメリットをエンタープライズクラスの機能で拡張しながら、 Kafka の管理や監視の負担を軽減することができます。現在、Fortune 100企業の80%以上がデータストリーミングテクノロジを採用しており、大部分が活用されています。</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Conflicent Platform を使用すると、データが異なるシステム間でどのように転送または統合されるかなど、基本的なメカニズムを気にすることなく、データからビジネス価値を引き出す方法に集中できます。具体的には、 Con裕福 なプラットフォームによって、 Kafka へのデータソースの接続やストリーミングアプリケーションの構築、 Kafka インフラの保護、監視、管理が簡易化されます。現在、Conluent Platformは、金融サービス、オムニチャネル小売、自律走行車から不正検出、マイクロサービス、IoTまで、さまざまな業界で幅広く使用されています。</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">次の図は、流暢なプラットフォームのコンポーネントを示しています。</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">この図は、流暢なプラットフォームのコンポーネントを示しています。</block>
  <block id="f64c3e5205853c0df35b5f05dcb208a1" category="paragraph"><block ref="f64c3e5205853c0df35b5f05dcb208a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">流暢なイベントストリーミング技術の概要</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">カフカ</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">流暢なプラットフォームの中核はです<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block>最も人気の高いオープンソース分散ストリーミングプラットフォームです。Kafkaの主な機能は次のとおりです。</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">流暢なプラットフォームのエンタープライズ機能の概要</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">* ConFluent Control Center * Kafkaの管理と監視を行うためのUIベースのシステムです。Kafka Connect の管理や、他のシステムとの接続の作成、編集、管理を簡単に行うことができます。</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">* Kafka Connectコネクタ。*コネクタはKafka Connect APIを使用して、Kafkaと他のシステム（データベース、キーバリューストア、検索インデックス、ファイルシステムなど）との接続に使用します。Confluent Hub には、一般的なデータソースおよびシンク用のダウンロード可能なコネクタがあります。これには、 Conluent Platform でこれらのコネクタの完全なテストとサポートされたバージョンが含まれます。詳細については、を参照してください<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>。</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">* セルフバランシングクラスタ。 * 自動ロードバランシング、障害検出、自己修復機能を提供します。また、必要に応じてブローカーの追加や運用停止も可能で、手動での調整は不要です。</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*流暢な自動データバランサ。*ブローカーの数、パーティションのサイズ、パーティションの数、およびクラスタ内のリーダーの数について、クラスタを監視します。これにより、データを移動してクラスタ全体で均等なワークロードを作成しながら、トラフィックのリバランシングを調整して、リバランシング中の本番ワークロードへの影響を最小限に抑えることができます。</block>
  <block id="0265b0b07689b6439fc600eec3164763" category="inline-link-macro">次の例は、パフォーマンスの検証を流暢に行います。</block>
  <block id="7d58203770f3360011c58049bd5dc048" category="paragraph"><block ref="7d58203770f3360011c58049bd5dc048" category="inline-link-macro-rx"></block></block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">NetAppストレージ・コントローラ1台のAFF A900を使用して'ワークロードの生成中に5ノードまたは8ノードのブローカ・ノードを使用して階層型ストレージのテストを実施しました今回のテストでは、AFF A900のリソース使用率が100%に達するまで、ブローカーノードの数に合わせて完了までの時間とパフォーマンスの結果が拡張されました。ONTAP ストレージコントローラには、少なくとも1つのHAペアが必要です。</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">ワークロードジェネレータを使用したパフォーマンステスト</block>
  <block id="3daa014912cbb3dddcdeae426aea8652" category="inline-link-macro">前の手順：パフォーマンスの検証が流暢になりました。</block>
  <block id="262b5107278b398d0de9b7ef6b52e5d0" category="paragraph"><block ref="262b5107278b398d0de9b7ef6b52e5d0" category="inline-link-macro-rx"></block></block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">S3読み出し処理のパフォーマンスは、ブローカーノードの数に基づいてリニアに向上しました。ONTAP ストレージコントローラを使用すると、1つの環境で最大12個のHAペアをサポートできます。</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">次のグラフは、S3の階層化トラフィックと5ノードまたは8ノードのブローカーを組み合わせたものです。AFF A900の単一HAペアのパフォーマンスを最大化しました。</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">このデータグラフには、S3の階層化トラフィックと5ノードまたは8ノードのブローカーが組み合わされて表示されます。</block>
  <block id="388c51cbcac77b72c2e68dc334f9cf73" category="paragraph"><block ref="388c51cbcac77b72c2e68dc334f9cf73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">次のグラフは、Kafkaのスループットを約31.74GBpsで示しています。</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">このデータグラフは、Kafkaのスループットを約31.74GBpsで示しています。</block>
  <block id="1dc39288e0903ff9947d26bba4d46cef" category="paragraph"><block ref="1dc39288e0903ff9947d26bba4d46cef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">また、ONTAP ストレージコントローラの「perfstat」レポートでも同様のスループットが確認されました。</block>
  <block id="12521f8f565efeb65b076c8966841804" category="inline-link-macro">次：パフォーマンスに関するベストプラクティスのガイドライン</block>
  <block id="4d8306a1e68c76874ac5d8c93a819977" category="paragraph"><block ref="4d8306a1e68c76874ac5d8c93a819977" category="inline-link-macro-rx"></block></block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">この検証テストは、NetApp ONTAP ストレージコントローラを使用した流暢な階層化のスループットが31.74GBpsに達しました。</block>
  <block id="f86bb9f7d3cb6d2f8473494c8bd135ec" category="inline-link-macro">Previous：パフォーマンスのベストプラクティスのガイドライン</block>
  <block id="65b905a56baa366aa274945ca5b7cad4" category="paragraph"><block ref="65b905a56baa366aa274945ca5b7cad4" category="inline-link-macro-rx"></block></block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">この検証テストは、NetApp ONTAP ストレージコントローラを使用した流暢なティアのスループットが31.74GBpsに達しました。</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">流暢とは</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">ONTAP におけるS3のベストプラクティスです</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">S3オブジェクトストレージの管理</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="1b70ac0a972fddf1e1a33e6ed9df49c7" category="cell">2022年9月</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">このページでは、この解決策 のパフォーマンスを向上させるためのベストプラクティスについて説明します。</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">パフォーマンスのベストプラクティスのガイドライン</block>
  <block id="25075404ed18180817b5ff523b98b3ea" category="inline-link-macro">前のテスト：ワークロードジェネレータを使用したパフォーマンステスト。</block>
  <block id="78f6cc0a5eeea34ea4a6b6d750751008" category="paragraph"><block ref="78f6cc0a5eeea34ea4a6b6d750751008" category="inline-link-macro-rx"></block></block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">ONTAP の場合は、可能なかぎりGETサイズ&gt;= 1MBを使用します。</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">ブローカ・ノードでserver.properties`にあるnum.network.threads`と'num.io.threadsを増やすと'階層化アクティビティの増加をS3階層にプッシュできますこれらの結果は'num.network.threads`と'num.io.threads'32に設定されています</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">S3バケットは、メンバーアグリゲートごとに8つのコンスティチュエントをターゲットとする</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">S3トラフィックを伝送するイーサネットリンクでは、ストレージとクライアントの両方で可能な場合、MTU 9、000を使用する必要があります。</block>
  <block id="9a2dcec18734a6b09898eef44edd5f9a" category="paragraph"><block ref="9a2dcec18734a6b09898eef44edd5f9a" category="inline-link-macro-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">このページでは、この解決策 のパラメータに含まれる流出のパフォーマンス検証について説明します。</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">競合する性能検証</block>
  <block id="e0c5d30e7d8ab807973bb9e8800f9f30" category="paragraph"><block ref="e0c5d30e7d8ab807973bb9e8800f9f30" category="inline-link-macro-rx"></block></block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">この検証は、NetApp ONTAP 上の階層型ストレージについて、流暢なプラットフォームで実施しました。ネットアップと流暢なチームがこの検証に協力し、必要なテストケースを実施しました。</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">矛盾する設定です</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">セットアップには、3台の動物園、5台のブローカー、256GBのRAMと16個のCPUを搭載した5台のテストサーバを使用しました。ネットアップストレージには、AFF A900 HAペアでONTAP を使用しました。ストレージとブローカーは、100GbE接続経由で接続されています。</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">次の図に、階層型ストレージの検証に使用する構成のネットワークトポロジを示します。</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">この図は、階層型ストレージの検証に使用する構成のネットワークトポロジを示しています。</block>
  <block id="e1265b0a6795e57b3d1df5094ecde2bb" category="paragraph"><block ref="e1265b0a6795e57b3d1df5094ecde2bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">ツールサーバは、Conluentノードとの間でイベントを送受信するアプリケーションクライアントとして機能します。</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">テストには次のパラメータを使用しました。</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">検証にはHTTPプロトコルにONTAP を使用しましたが、HTTPSも使用しました。アクセスキーとシークレットキーは、「 confliclus.tir.s3.cred.file.path 」パラメータで指定したファイル名に格納されます。</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">ネットアップストレージコントローラ–ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">ONTAP では、検証用に単一のHAペア構成を設定しました。</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">この図は、検証用に単一のHAペアとして構成された環境を示しています。</block>
  <block id="0ccd17060e15591b9c8588dc7d974ecd" category="paragraph"><block ref="0ccd17060e15591b9c8588dc7d974ecd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">検証結果</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">以下の 5 つの検証ケースを完了しました。最初の 2 つは機能テストで、残りの 3 つはパフォーマンステストです。</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">このテストでは、API呼び出しを使用して階層化ストレージに使用されるオブジェクトストアで、GET、PUT、DELETEなどの基本的な処理を実行します。</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">このテストでは、オブジェクトストレージのエンドツーエンド機能をチェックします。トピックを作成し、新たに作成されたトピックにイベントストリームを生成し、ブローカーがオブジェクトストレージにセグメントをアーカイブするのを待機し、イベントストリームを消費して、消費されたストリームが生成されたストリームと一致するかどうかを検証します。このテストは、オブジェクトストアフォールト挿入の有無にかかわらず実施しました。ONTAP のいずれかのノードでサービスマネージャサービスを停止し、エンドツーエンド機能がオブジェクトストレージで機能することを検証することで、ノード障害をシミュレートしました。</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">ワークロードジェネレータを消費</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">このテストでは、セグメントをアーカイブすることにより、オブジェクトストアへの書き込みワークロードを間接的に生成します。コンシューマグループがセグメントを取得すると、読み取りワークロード（セグメント読み取り）がオブジェクトストレージから生成されました。このワークロードはTOCCスクリプトによって生成されました。このテストでは、並列スレッドでのオブジェクトストレージの読み取りと書き込みのパフォーマンスをチェックしました。階層化機能の正確性テストと同様に、オブジェクトストアフォールト挿入を使用したテストと使用しなかったテストを実施しました。</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">保持ワークロードジェネレータ</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">このテストでは、トピックの保持ワークロードが多い場合のオブジェクトストレージの削除パフォーマンスを確認しました。保存ワークロードは、テストトピックと並行して多数のメッセージを生成するTOCCスクリプトを使用して生成されました。テストトピックでは、サイズベースおよび時間ベースの強力な保持設定を使用してイベントストリームをオブジェクトストアから継続的にパージするように設定しました。その後、セグメントがアーカイブされました。その結果、ブローカーによるオブジェクトストレージの削除や、オブジェクトストアの削除処理のパフォーマンス収集が行われ、多くの削除が発生していました。</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">検証の詳細については、を参照してください<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> Webサイト。</block>
  <block id="0e20876ceb73ae36999db9f6c412bdc5" category="inline-link-macro">次は、ワークロードジェネレータを使用したパフォーマンステストです。</block>
  <block id="ab82cfabb720bf1d31365b6ce33825f9" category="paragraph"><block ref="ab82cfabb720bf1d31365b6ce33825f9" category="inline-link-macro-rx"></block></block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">このセクションでは、階層型ストレージ用のNetApp ONTAP を使用した、Conluent Platform環境でのパフォーマンス検証に使用するハードウェアとソフトウェアについて説明します。次の表に、解決策 のアーキテクチャと基本コンポーネントを示します。</block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">ONTAP を搭載したNetApp AFF A900ストレージコントローラは、データストリーム向けに設計された分散システムです。どちらも水平方向に拡張可能で、耐障害性に優れており、負荷時に優れたパフォーマンスを提供します。データ量を最小限に抑えるデータ削減テクノロジにより、分散型データストリーミングとストリーム処理を相互に補完し、ストレージコストを削減します。AFF A900ストレージコントローラは優れたパフォーマンスを提供すると同時に、コンピューティングリソースとデータストレージリソースを分離できます。これにより、システム管理が簡素化され、リソースを個別に拡張できます。</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">解決策 の概要を示す画像。</block>
  <block id="52dff9f6353660d69eddc1e9fdee4a83" category="paragraph"><block ref="52dff9f6353660d69eddc1e9fdee4a83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">プラットフォームコンポーネント</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">環境の構成</block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">矛盾するプラットフォームバージョン6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">ゾーニングキーパー×3</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">ブローカーサーバ×8</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5台のツールサーバ</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">Grafana×1</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 xコントロールセンター</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">すべてのノード上のオペレーティングシステム</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">NetApp ONTAP ：ウォームバケット用</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">AFF A900ハイアベイラビリティ（HA）ペア×1</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">CPU×2、合計16個の物理コア</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">インテルXeon</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256GBの物理メモリ</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">100GbEデュアルポート</block>
  <block id="39bc57d27d632df4261bc60caf39a90c" category="paragraph"><block ref="39bc57d27d632df4261bc60caf39a90c" category="inline-link-macro-rx"></block></block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">NetApp ONTAP ストレージコントローラとKafkaが競合します</block>
  <block id="875353af43abce06e81496931b9482ef" category="paragraph"><block ref="875353af43abce06e81496931b9482ef" category="inline-link-macro-rx"></block></block>
  <block id="93d153de96abb104b1cf0b56dddc7dfc" category="sidebar">VMware HCXを使用してワークロードをANFデータストアに移行する</block>
  <block id="9e925e9341b490bfd3b4c4ca3b0c1ef2" category="inline-link">これ</block>
  <block id="953fa9bc59561d97ed62ce854465ba35" category="paragraph">vSphere 5.5 以降では、 vmkfstools – y コマンドに代わって、空きブロック数を指定する esxcli storage vmfs unmap コマンドが使用されます（ VMware KB を参照）<block ref="1d61bd4e8925f7d5aac61e083b728439" category="inline-link-rx"></block> 詳細については、を参照してください）。vSphere 6.5 以降では、 VMFS 6 を使用している場合、スペースは自動的に非同期で再利用される必要があります（を参照）<block ref="a9ae15a1c91a14939aefb313015202e6" category="inline-link-rx"></block> vSphere のドキュメントを参照）。ただし、必要に応じて手動で実行することもできます。この自動マッピング解除は ONTAP でサポートされ、 VMware vSphere 用の ONTAP ツールでは低優先度に設定されます。VMFSデータストアとして使用するためにLUNをプロビジョニングする場合は、LUNに対してspace-allocationオプションを手動で有効にする必要があります。VMware vSphere用のONTAP ツールを使用している場合、スペースの請求がサポートされるようにLUNが自動的に設定されるため、それ以上の操作は必要ありません。を参照してください<block ref="fca823934ad533ca13947daa01d8e441" category="inline-link-rx"></block> 詳細については、ナレッジベースの記事を参照してください。</block>
  <block id="b95b607ac94c4a8cb830243ecb537f59" category="cell">LDAPで使用されるセッションセキュリティのレベルを定義します（sign、seal、none）。LDAP署名は、Active Directoryから要求された場合にCVSパフォーマンスでサポートされます。CVS-SWではLDAP署名はサポートされません。どちらのタイプのサービスでも、現時点ではシーリングはサポートされていません。</block>
  <block id="ce32836b59e052d959dee4d2358e5a21" category="paragraph">テスト目的で、この検証に使用したオンプレミスのラボ環境はサイト間VPNを介して接続されており、オンプレミスでAzure VMware解決策 に接続できます。</block>
  <block id="0bcfdba2f090838df9da44d825fedc49" category="doc">TR-4942：『Migrate workloads to FSX ONTAP datastore using VMware HCX』</block>
  <block id="dd5244d49dea74bb9effd68426155ca2" category="sidebar">VMware HCXを使用したONTAP データストアのFSXへのワークロードの移行</block>
  <block id="cdf4d8a8fa9326debf96606ee7177f41" category="doc">AsciiDocコーディングおよび出力のサンプル</block>
  <block id="6c1cc46d8764b2147f50c80e336ab770" category="paragraph">このドキュメントには、asciidocソースとその出力の例が含まれています。</block>
  <block id="c252a357a127635943f82514442e62b3" category="section-title">見出しレベル</block>
  <block id="8000c50cdc8b68dd9ea0d326040cbd63" category="paragraph">[青い下線]*ソースAsciiDoc::*</block>
  <block id="3c2f44ba0863f4f0fcb5023aa4ee6ca2" category="paragraph">[青い下線]*生成されたHTML:*</block>
  <block id="efea650a2edf10e173ba726fa4e90c5f" category="section-title">見出しレベル1（セクションタイトル）</block>
  <block id="2b70e22920b3d78a96efdd65b4b37c1f" category="section-title">見出しレベル2（セクションタイトル）</block>
  <block id="3742ded2a390654e38f763a70bd4e35a" category="section-title">見出しレベル3（セクションタイトル）</block>
  <block id="4d1ebef97112908dabe0c9c786eaa7ba" category="section-title">見出しレベル4（セクションタイトル）</block>
  <block id="44e6fd3a1839882d90b6020944c4aeb1" category="section-title">見出しレベル5（セクションタイトル）</block>
  <block id="691d1860ec58dd973e803e209697d065" category="section-title">リスト</block>
  <block id="d3263947659da25e39643e07688fb919" category="paragraph">箇条書き：</block>
  <block id="6e991c331de28266251c487c42df1f10" category="list-text">これは順序付けられていないリストです</block>
  <block id="d1ad2884248be2067d5bc70a584eba6d" category="list-text">これはまだ番号なしのリストです</block>
  <block id="b84268ab94bb6da5f97f344b7f78bf9f" category="list-text">これは、順序付けされていないリストのサブエレメントです</block>
  <block id="434aab8bf1245d04dc3e96af08e1842e" category="paragraph">順序付きリスト：</block>
  <block id="07628350d195b6ebaae83ec46df8e1c3" category="list-text">これは順序付きリストです</block>
  <block id="964f443f29145e9fa43a38671d07d447" category="list-text">これはまだ注文済みリストです</block>
  <block id="239cecc0851db8990cd18461b6243348" category="list-text">これは、順序付きリストのサブエレメントです</block>
  <block id="fff0d600f8a0b5e19e88bfb821dd1157" category="section-title">イメージ</block>
  <block id="340c4d7a25252d5807344db646713010" category="paragraph">リポジトリ内またはWeb上の任意の場所にあるイメージにリンクできます。リポジトリ内のイメージの場合'これらのイメージはメディアフォルダに配置されるため'次のように適切に設定する必要があります</block>
  <block id="13d002c81cf56705c2becc11e5ed9a4f" category="image-alt">リポジトリ内のイメージ</block>
  <block id="43d8eb4fa9bb019f23b6835a3d3c93d7" category="image-alt">リポジトリ外のイメージ</block>
  <block id="bd908db5ccb07777ced8023dffc802f4" category="section-title">リンク</block>
  <block id="69faa60007e518154e5dfa6c7cb9606d" category="paragraph">イメージと同様に'リンクはリポジトリ内またはWeb上の任意の場所にあるドキュメントを参照できます内部参照の場合、リンクソースへのパスが"link:::"ステートメントで指定されていることを確認することが重要です。</block>
  <block id="8cc0407dfab26edc02bac943afa1c50d" category="inline-link-macro">ネットアップソリューション変更ログ（社内用）</block>
  <block id="e5eddd5cb0a7a1048bd37c62e18ae2dd" category="paragraph"><block ref="e5eddd5cb0a7a1048bd37c62e18ae2dd" category="inline-link-macro-rx"></block></block>
  <block id="4d9909e75daa4ee8685674e4136d2046" category="inline-link-macro">ネットアップソリューションの変更ログ（外部）</block>
  <block id="bc630a540bb452bb9f726ed7c7e14715" category="paragraph"><block ref="bc630a540bb452bb9f726ed7c7e14715" category="inline-link-macro-rx"></block></block>
  <block id="3bdabc119341b76ec34be01ada064a84" category="section-title">折りたたみ可能なコンテンツ（ツイスト）</block>
  <block id="b78a3223503896721cca1303f776159b" category="example-title">タイトル</block>
  <block id="b66944886034ca73431f2e338216bd4b" category="paragraph">折りたたまれるテキストはここに表示されます。</block>
  <block id="70f60b4a0e07b27ad4d42c2ede9220f3" category="admonition">[タイトル]をクリックすると、展開されたコンテンツが表示されます</block>
  <block id="1cc54ce67047f47e6e0b998e4757610b" category="section-title">テーブルを作成しています</block>
  <block id="2e0fea6cc0d29edadf544e93bf56013c" category="cell">列A</block>
  <block id="778c1ae51201605a08ca7745c8dd3856" category="cell">列B</block>
  <block id="00862db58047a1191cc2f83e69ff9892" category="cell">列C</block>
  <block id="19273115ac8897b4064a43ccf533c3ba" category="cell">列Aのテキスト</block>
  <block id="9ed785bee043f58e69669715e38bfe2d" category="cell">列Bのテキスト</block>
  <block id="ec7498417999a2d1bc9ab843b061d478" category="cell">列Cのテキスト</block>
  <block id="19ffdf534588898ed43f67fde767f1fd" category="paragraph">次に、1つの行がテーブル全体にまたがっており、他の行が複数の列にまたがってデータを持つ別の例を示します。</block>
  <block id="bf767d30d483b6701f943a456017bf9d" category="cell">ヘッダー列1</block>
  <block id="6e3e0843cfe6ff00d3b74bf168580453" category="cell">ヘッダー列2</block>
  <block id="a2fa10d34df17b106b689ca93f07c770" category="cell">ヘッダー列3</block>
  <block id="61bd6ed3bebad9294ee30668abbeff3c" category="cell">ヘッダー列4</block>
  <block id="1a168c8aca72f77bf84798bb31a4cb8c" category="cell">これは、テーブルの4つの列すべてにまたがって表示される、非常に長い行です。この行の唯一のセルであり、空のセルは残りません。</block>
  <block id="4f14cfb44ee45b336256dd439e135021" category="cell">これは、表内の3つの列にまたがって表示される長い行で、1つの空のセルを残します。</block>
  <block id="43eddd3ae82d79991b5cefa462bed9d7" category="cell">この行は列の2つにまたがっており、2つのセルが空になっています。</block>
  <block id="77631ca4f0e08419b70726a447333ab6" category="cell">これ</block>
  <block id="f1965a857bc285d26fe22023aa5ab50d" category="cell">行</block>
  <block id="a2a551a6458a8de22446cc76d639a9e9" category="cell">はです</block>
  <block id="fea087517c26fadd409bd4b9dc642555" category="cell">正常</block>
  <block id="00a4cb60b0815316a1416dae59b77543" category="inline-link-macro">AsciiDocのドキュメント</block>
  <block id="c784ba850708b73450bc80d79e01313e" category="admonition">テーブルのレイアウトを変更するために指定できるオプションは多数あります。詳細については、作成するリポジトリ（HTMLバージョン）で例を検索し、VScodeにアクセスしてソースを表示するか、を参照してください <block ref="8ce64cdd9ff98df64c05c93fb30bd0b8" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="e2f7e3242523777351b6658f86564416" category="section-title">タブ付きブロック</block>
  <block id="d6d281824a9f2f56cd13926cacd6f6c3" category="open-title">最初のタブ</block>
  <block id="a13c148381823333364efc7a66153681" category="paragraph">最初のタブの内容がここに表示されます</block>
  <block id="99a1d6da572d7987b546c07b1053d7b0" category="open-title">2番目のタブ</block>
  <block id="d93aaa34fa764ccd0a071f1c256e0a6f" category="paragraph">2番目のタブのコンテンツはここに表示されます</block>
  <block id="3b04793c63a616fa65f54f1d98c263e1" category="admonition">「2番目のタブ」をクリックすると、そのセクションの内容が表示されます。</block>
  <block id="c53dba1ad099d932b01eacd82bd500f2" category="doc">NVA-1155：『FlexPod Datacenter with Cisco UCS and NetApp AFF A800 over FC-Design and Deployment Guide』で、Oracle 19C RACデータベースを検証します</block>
  <block id="547673676a9fdbc79f1364e749be4d0a" category="paragraph">ネットアップAllen Cao</block>
  <block id="a42a54d915f9cd474841cab349e2de5e" category="paragraph">この設計および導入ガイドでは、FlexPod Datacenter with Cisco UCS and NetApp AFF A800 over FCを使用したOracle 19C RACデータベースについて説明します。解決策 また、Oracle Linux 8.2を使用した最新のFlexPod データセンターインフラストラクチャでOracle RACデータベースをホストするためのステップバイステップの導入プロセスについても説明しますオペレーティングシステムとRed Hat互換カーネル。</block>
  <block id="26536a9e695c3724c27d8ef7d7297f41" category="inline-link-macro"><block ref="26536a9e695c3724c27d8ef7d7297f41" category="inline-link-rx"></block></block>
  <block id="6e0751d9d8cd023132b0afea3073c96d" category="paragraph"><block ref="6e0751d9d8cd023132b0afea3073c96d" category="inline-link-macro-rx"></block></block>
  <block id="6e170e4c0b9eb50546a09aafc90dc157" category="doc">TR-4794：『Oracle databases on NetApp EF Series』</block>
  <block id="9b6fc59469e9f5ee36cb85b08daacec3" category="paragraph">Mitch Blackburn、Ebin Kadavy、ネットアップ</block>
  <block id="fa8b4902d0c1e464dcf9256a434920ba" category="paragraph">TR-4794は、ストレージ管理者とデータベース管理者がOracleをNetApp EFシリーズのストレージに正常に導入できるようにするためのものです。</block>
  <block id="6ccd62bc352fd170c5fa9538c6fa84b1" category="inline-link-macro"><block ref="6ccd62bc352fd170c5fa9538c6fa84b1" category="inline-link-rx"></block></block>
  <block id="0d3b1c298c590bed5f16adc6a5e10809" category="paragraph"><block ref="0d3b1c298c590bed5f16adc6a5e10809" category="inline-link-macro-rx"></block></block>
  <block id="954dcd3322a22ffd4d24f94c2d40abfc" category="doc">TR-4467：『SAP with Microsoft SQL Server on Windows』-『Best Practices Using NetApp Clustered Data ONTAP and SnapCenter 』</block>
  <block id="611a4a6b98272a717f8e1f6bf5ba787b" category="paragraph">Marco Schoen 、ネットアップ</block>
  <block id="dbd408dfbba42c9529974244acc200aa" category="paragraph">TR-4467では、Windows環境でMicrosoft SQL Serverを実行するSAP Business Suiteソリューションをサポートする、clustered Data ONTAP の導入に関するベストプラクティスをお客様やパートナー様に紹介しています。</block>
  <block id="39929f96a57edd550a6cb67e9fd82f26" category="inline-link-macro"><block ref="39929f96a57edd550a6cb67e9fd82f26" category="inline-link-rx"></block></block>
  <block id="e1373a4ef25d8a3dcebe3b2cff4b90b2" category="paragraph"><block ref="e1373a4ef25d8a3dcebe3b2cff4b90b2" category="inline-link-macro-rx"></block></block>
  <block id="e848c28a0a485bcf645b0791381d9c89" category="doc">Microsoft SQL Server環境の刷新</block>
  <block id="69015d285622bbd074d7bccf4ea12670" category="paragraph">運用を最適化し、オンプレミスでもクラウドでも、データを最大限に活用できます。</block>
  <block id="f867ac1965207b2211a876821d31d617" category="inline-link-macro"><block ref="f867ac1965207b2211a876821d31d617" category="inline-link-rx"></block></block>
  <block id="3f73fe1a14da103e822fb292c28f66df" category="paragraph"><block ref="3f73fe1a14da103e822fb292c28f66df" category="inline-link-macro-rx"></block></block>
  <block id="a23b0f6840eece1bcfc1a2ce047e740e" category="doc">TR-3633：『ONTAP 上のOracleデータベース』</block>
  <block id="3b1f454fff17aa123534722dc8b6870b" category="paragraph">ネットアップ、Jeffrey Steiner</block>
  <block id="bb00932088674136830625fe37741beb" category="paragraph">を参照してください <block ref="d0d24196afeacb93f8904954168bf8db" category="inline-link-macro-rx"></block> TR-3633で説明されている環境、構成、およびバージョンが環境に対応しているかどうかを確認するには</block>
  <block id="76775d774363eb515c3954389bf96eb8" category="inline-link-macro"><block ref="76775d774363eb515c3954389bf96eb8" category="inline-link-rx"></block></block>
  <block id="ee47cd10fbc8d219225b06932059463a" category="paragraph"><block ref="ee47cd10fbc8d219225b06932059463a" category="inline-link-macro-rx"></block></block>
  <block id="d76cffc02762fcf81c8bb85e5fe9e987" category="doc">TR-4764：『Best Practices Guide for Microsoft SQL Server with NetApp EF Series』</block>
  <block id="d9cd8ac988f5ea26e28a2da5f3485ff9" category="paragraph">ネットアップMitch Blackburn、Pat Sinthusan</block>
  <block id="9db08b91ae68a77b71af230b40b31325" category="paragraph">このベストプラクティスガイドは、ストレージ管理者およびデータベース管理者がMicrosoft SQL ServerをNetApp EFシリーズストレージに正常に導入できるようにすることを目的としています。</block>
  <block id="d378412674e2e76ee3c7e245fd0aad9c" category="inline-link-macro"><block ref="d378412674e2e76ee3c7e245fd0aad9c" category="inline-link-rx"></block></block>
  <block id="855280cfa22ac6785edc7f9e23fa2cf7" category="paragraph"><block ref="855280cfa22ac6785edc7f9e23fa2cf7" category="inline-link-macro-rx"></block></block>
  <block id="d5b9082efbf726d2e38c5042668ae4f0" category="doc">TR-4250：『SAP with Oracle on UNIX and NFS with NetApp Clustered Data ONTAP and SnapManager for SAP 3.4』</block>
  <block id="bb8cd3f7aec777de29cee988f4ade068" category="paragraph">ネットアップ Nils Bauer</block>
  <block id="ea455e11718ea0bfb200c540f4e0c038" category="paragraph">TR-4250は、Oracleデータベースを使用してSAP Business Suite製品をサポートするストレージソリューションを設計する際の課題に対応しています。ストレージインフラの設計、導入、運用、管理を中心に、最新世代の SAP ソリューションの利用に際して経営陣や IT 部門責任者が一般に直面する課題について、その対処方法を示します。本書で紹介する推奨事項は、特定の SAP アプリケーションに限定したものではなく、規模や範囲に関係なくさまざまな SAP 環境に応用できます。TR-4250は、ネットアップ製品およびSAP製品のテクノロジと運用に関する基本的な知識があることを前提としています。TR-4250は、ネットアップ、SAP、Oracle、およびお客様の技術スタッフの協力のもとに開発されました。</block>
  <block id="72b1d38d81a57d1482ce5708d98653f1" category="inline-link-macro"><block ref="72b1d38d81a57d1482ce5708d98653f1" category="inline-link-rx"></block></block>
  <block id="9661c205dc29ba33fe04212e23a675a7" category="paragraph"><block ref="9661c205dc29ba33fe04212e23a675a7" category="inline-link-macro-rx"></block></block>
  <block id="be52c99c6345cb49ab79a79b9565c737" category="doc">TR-4785：『NetApp EシリーズおよびBeeGFSを使用したAI導入』</block>
  <block id="36f4667e440709d475f1c5db4ecae97e" category="paragraph">Nagalakshmi Raju、Daniel Landes、Nathan Swartz、ネットアップAmine Bennani</block>
  <block id="c74f37bd5e8951b2feda7d19b03326e9" category="paragraph">人工知能（AI）、機械学習（ML）、ディープラーニング（DL）の各アプリケーションには、大規模なデータセットと計算処理が伴います。これらのワークロードを正常に実行するには、ストレージノードとコンピューティングノードの両方をシームレスにスケールアウトできるアジャイルインフラが必要です。このレポートには、AIトレーニングモデルを分散モードで実行するための手順が含まれており、コンピューティングノードとストレージノードをシームレスにスケールアウトできます。また、このレポートには、解決策 EシリーズストレージとBeeGFS並列ファイルシステムを組み合わせることで、AIワークロード向けに柔軟で対費用効果の高いシンプルな解決策 を実現する方法を示すさまざまなパフォーマンス指標も含まれています。</block>
  <block id="ee8f67cac9ef02f83e05d3b531bbaa8f" category="inline-link-macro"><block ref="ee8f67cac9ef02f83e05d3b531bbaa8f" category="inline-link-rx"></block></block>
  <block id="f23e849942acdc76ad2147cc16d1c207" category="paragraph"><block ref="f23e849942acdc76ad2147cc16d1c207" category="inline-link-macro-rx"></block></block>
  <block id="e889531653bc3baae2aadf3bee46a54f" category="doc">NVA-1156 -導入：NVIDIA DGX A100システムとBeeGFSを搭載したNetApp EFシリーズAI</block>
  <block id="4472645bc6fe350406624df126edf4ac" category="paragraph">Abdel Sadek、Tim Chau、Joe McCormick、ネットアップDavid Arnette</block>
  <block id="7d8f094cc030aec75a343f1baad8c19d" category="paragraph">このドキュメントでは、NetApp EF600 NVMeストレージシステム、ThinkParQ BeeGFS並列ファイルシステム、NVIDIA DGX A100システム、NVIDIA Mellanox Quantum QM8700 200Gbps InfiniBand（IB）スイッチを使用した、機械学習（ML）および人工知能（AI）ワークロード向けのNetApp Verified Architectureについて説明します。このドキュメントには、導入完了後に検証ベンチマークテストを実行する手順も記載されています。</block>
  <block id="58f81dbff2cc92916b8e184779ecf9ad" category="inline-link-macro"><block ref="58f81dbff2cc92916b8e184779ecf9ad" category="inline-link-rx"></block></block>
  <block id="e032117163a7b2e48c80c9a423ff17b8" category="paragraph"><block ref="e032117163a7b2e48c80c9a423ff17b8" category="inline-link-macro-rx"></block></block>
  <block id="7d7e004acd6ddcaf6ddbea36835d3a1e" category="paragraph"><block ref="7d7e004acd6ddcaf6ddbea36835d3a1e" category="inline-link-macro-rx"></block></block>
  <block id="0046f5684030ae3e0fe25061bf411059" category="doc">NVA-1153設計：NVIDIA DGX A100システムとMellanox Spectrumイーサネットスイッチを搭載したNetApp ONTAP AI</block>
  <block id="7bfbd6c5c294b7f81d430bd31f53aea3" category="paragraph">NVA-1153 -設計には、NetApp AFF A800ストレージシステム、NVIDIA DGX A100システム、NVIDIA Mellanox NVIDIA Spectrum SN3700V 200GBのイーサネットスイッチを使用した、機械学習（ML）と人工知能（AI）のワークロードに対応するネットアップの検証済みアーキテクチャが記述されています。この設計では、コンピューティングクラスタインターコネクトファブリック用のRDMA over Converged Ethernet（RoCE）を特徴としており、ハイパフォーマンスワークロード向けに完全なイーサネットベースのアーキテクチャを提供します。また、実装されているアーキテクチャのベンチマークテスト結果も記載します。</block>
  <block id="7b6f81cfdb86a2e75cd90e7b2397b5c5" category="inline-link-macro"><block ref="7b6f81cfdb86a2e75cd90e7b2397b5c5" category="inline-link-rx"></block></block>
  <block id="12e9f3f9d266156ccfbbb4ea8f21eb86" category="paragraph"><block ref="12e9f3f9d266156ccfbbb4ea8f21eb86" category="inline-link-macro-rx"></block></block>
  <block id="455d43e3be683302c81c2b5626db170c" category="doc">TR-4851：『NetApp StorageGRID Data Lake for Autonomous Driving Workloads -解決策 design』</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">ネットアップ、David Arnette</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851は、機械学習（ML）とディープラーニング（DL）のソフトウェア開発のためのデータリポジトリおよび管理システムとして、NetApp StorageGRID オブジェクトストレージを使用する方法を示しています。このホワイトペーパーでは、自律走行車ソフトウェア開発におけるデータフローと要件、およびデータライフサイクルを合理化するStorageGRID 機能について説明します。この 解決策 環境 は、MLおよびDL開発プロセスで一般的なマルチステージのデータパイプラインワークフローです。</block>
  <block id="5d5c58f2793c027dcda637fc95601825" category="inline-link-macro"><block ref="5d5c58f2793c027dcda637fc95601825" category="inline-link-rx"></block></block>
  <block id="17534f242f61128daf02fd0bde2ab66d" category="paragraph"><block ref="17534f242f61128daf02fd0bde2ab66d" category="inline-link-macro-rx"></block></block>
  <block id="a479dadc1f089681ec4db29c16fec163" category="doc">TR-4810：『NetApp ONTAP and Lenovo ThinkSystem SR670 for AI and ML Model Training Workloads』</block>
  <block id="5ebb854a0e7b0964891f587bfc1d231a" category="paragraph">Karthikeyan Nagalingam、NetApp Miroslav Hodak、Lenovo</block>
  <block id="17f161066b709ea249da0f86319938b3" category="paragraph">TR-4810は、コスト効率に優れたエントリレベルのコンピューティングおよびストレージアーキテクチャを説明し、ネットアップのストレージコントローラとLenovo ThinkSystemサーバにGPUベースの人工知能（AI）トレーニングを導入します。このセットアップは、複数のトレーニングジョブを並行して実行する小規模から中規模のチーム向けの共有リソースとして設計されています。</block>
  <block id="44daeb1185bf6a8c6c548cc1df101795" category="paragraph">TR-4810は、V100 GPU上のTensorFlowでのイメージ分類トレーニングを評価する業界標準のMLPerfベンチマークのパフォーマンスデータを提供します。パフォーマンスを測定するために、ResNet50をImageNetデータセット、バッチサイズ512、ハーフ精度、CUDA、cuDNNで使用しました。この分析は、4台のGPU SR670サーバとエントリレベルのネットアップストレージシステムを使用して実施しました。このテストでは、共有、マルチユーザ、マルチジョブの各ケースでテストした複数のユースケースで、パフォーマンスの効率が非常に優れており、個 々 のジョブで最大4台のサーバを拡張できます。大規模なスケールアウトジョブは効率が低下していましたが、まだ実行可能です</block>
  <block id="6f6e299cb7d6645bd11115fbed7ce551" category="inline-link-macro"><block ref="6f6e299cb7d6645bd11115fbed7ce551" category="inline-link-rx"></block></block>
  <block id="8eaaf4ccaaaec94b575ee16254ad49c1" category="paragraph"><block ref="8eaaf4ccaaaec94b575ee16254ad49c1" category="inline-link-macro-rx"></block></block>
  <block id="0ae928f6b14175d27f45a4e5ad647657" category="doc">NVA-1151 -導入：NVIDIA DGX A100システムを搭載したNetApp ONTAP AI</block>
  <block id="290beddb4a567cd98ba4f9116eee11b4" category="paragraph">NVA-1151 - NetApp AFF A800ストレージシステム、NVIDIA DGX A100システム、NVIDIA Mellanoxネットワークスイッチを使用した、機械学習（ML）と人工知能（AI）のワークロード向けのNetApp Verified Architecture（NVA）でのストレージシステムの導入手順を記載します。また、導入完了後に検証ベンチマークテストを実行する手順についても説明します。</block>
  <block id="213372f55b01b1d34de9624d7447ce72" category="inline-link-macro"><block ref="213372f55b01b1d34de9624d7447ce72" category="inline-link-rx"></block></block>
  <block id="f66a35643d6d6ce9bd6be71845a54cf8" category="paragraph"><block ref="f66a35643d6d6ce9bd6be71845a54cf8" category="inline-link-macro-rx"></block></block>
  <block id="1cfaf5b4fb65d4736720e0bc9565006f" category="doc">NVA-1150-deploy：Quantum StorNext with NetApp E-Series Systems Design Guide』</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">ネットアップ、Ryan Rodine氏</block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">このドキュメントでは、NetApp EシリーズストレージシステムにStorNext並列ファイルシステム解決策 を導入する方法について詳しく説明します。この解決策 では、NetApp EF280オールフラッシュアレイ、NetApp EF300オールフラッシュNVMeアレイ、NetApp EF600オールフラッシュNVMeアレイ、およびNetApp E5760ハイブリッドシステムについて説明します。Frametestベンチマークに基づいてパフォーマンス特性を評価します。Frametestベンチマークは、メディアおよびエンターテイメント業界で広く使用されているツールです。</block>
  <block id="60e713e183b7355809395b78af237e3d" category="inline-link-macro"><block ref="60e713e183b7355809395b78af237e3d" category="inline-link-rx"></block></block>
  <block id="3da570d632857f468742bb9e82bb15bc" category="paragraph"><block ref="3da570d632857f468742bb9e82bb15bc" category="inline-link-macro-rx"></block></block>
  <block id="3e22ed7172d7770cfa1457b7e70b2b06" category="doc">TR-4915：『Data movement with E-Series and BeeGFS for AI and analytics workflows』</block>
  <block id="b85127cc663f1e3f1a6a366bb2732406" category="paragraph">ネットアップ、Cody HarrymanとRyan Rodineです</block>
  <block id="f75519c0654938719b5319e8d452e91a" category="paragraph">TR-4915では、任意のデータリポジトリから、NetApp EシリーズSANストレージをサポートするBeeGFSファイルシステムにデータを移動する方法について説明します。人工知能（AI）や機械学習（ML）のアプリケーションの場合、お客様は、数ペタバイトを超える大規模なデータセットを、モデル開発のためにBeeGFSクラスタに移動する必要があることがあります。このドキュメントでは、NetApp XCPとNetApp Cloud Sync ツールを使用してこの処理を実行する方法について説明します。</block>
  <block id="69735c95d12121c6a49bf7078822f1a5" category="inline-link-macro"><block ref="69735c95d12121c6a49bf7078822f1a5" category="inline-link-rx"></block></block>
  <block id="85f5a6a68a78eee054d216895dfe53a9" category="paragraph"><block ref="85f5a6a68a78eee054d216895dfe53a9" category="inline-link-macro-rx"></block></block>
  <block id="32940041bf5093eb48af6ffae914f8cc" category="doc">NVA-1156設計：NVIDIA DGX A100システムとBeeGFSを搭載したNetApp EFシリーズAI</block>
  <block id="ff50db1ba0f8ba4a103a810e1ceb2afc" category="paragraph">Abdel Sadek、Tim Chau、Joe McCormick、David Arnette、ネットアップ</block>
  <block id="1d78c2c26f50714898cd986ca8147756" category="paragraph">NVA-1156 -設計には、NetApp EF600 NVMeストレージシステム、BeeGFS並列ファイルシステム、NVIDIA DGX A100システム、NVIDIA Mellanox Quantum QM8700 200Gbps IBスイッチを使用した、機械学習（ML）と人工知能（AI）のワークロードに対応したネットアップの検証済みアーキテクチャが記述されています。この設計では、ストレージとコンピューティングクラスタのインターコネクトファブリックに12Gbps InfiniBand（IB）を採用して、ハイパフォーマンスワークロード向けの完全なIBベースのアーキテクチャをお客様に提供しています。また、実装されているアーキテクチャのベンチマークテスト結果も記載します。</block>
  <block id="aca17de13a4a5756ad91fcaa1eac2f32" category="inline-link-macro"><block ref="aca17de13a4a5756ad91fcaa1eac2f32" category="inline-link-rx"></block></block>
  <block id="62d0bf89b3e7ccd1a8242fc23544a5a4" category="paragraph"><block ref="62d0bf89b3e7ccd1a8242fc23544a5a4" category="inline-link-macro-rx"></block></block>
  <block id="07bb9ea92d477ff776a5a9f59a55e75c" category="doc">TR-4799 -設計：自動運転ワークロード向けのNetApp ONTAP AIリファレンスアーキテクチャ</block>
  <block id="697dbe2a012e27540eab2481a9572ec4" category="paragraph">NVIDIA DGXファミリーのシステムは、エンタープライズAIに特化して設計された、世界初の統合人工知能（AI）プラットフォームです。NetApp AFF ストレージシステムは、卓越したパフォーマンスと業界をリードするハイブリッドクラウドデータ管理機能を提供します。ネットアップとNVIDIAは提携を通じてNetApp ONTAP AIリファレンスアーキテクチャを構築し、お客様にAIと機械学習（ML）のワークロードをサポートし、エンタープライズクラスのパフォーマンス、信頼性、サポートを提供するターンキー解決策 を提供しています。</block>
  <block id="ae4f0cd83b874dc6ee1f3d15fbcde464" category="inline-link-macro"><block ref="ae4f0cd83b874dc6ee1f3d15fbcde464" category="inline-link-rx"></block></block>
  <block id="db2c2e1615c8876019da15e39f1c3ce4" category="paragraph"><block ref="db2c2e1615c8876019da15e39f1c3ce4" category="inline-link-macro-rx"></block></block>
  <block id="53abcff00f0617502a70da8730cab6c0" category="doc">TR-4211：『NetApp ONTAP AI Reference Architecture for Healthcare：Diagnostic Imaging -解決策 Design』</block>
  <block id="eae34d8ef755492887b6a7aa4362588d" category="paragraph">NVIDIA、NetApp Jacci Cenci、Sathish Thyagarajan、Rick Huang、Sung-Han Lin</block>
  <block id="c92ae00fd88c8477c24628d0f17deceb" category="paragraph">このリファレンスアーキテクチャでは、ヘルスケアユースケース向けにNVIDIA DGX-2システムとNetApp AFF ストレージを使用して人工知能（AI）インフラを構築するお客様のガイドラインを紹介します。また、医療診断画像、検証済みのテストケース、結果のディープラーニング（DL）モデルの開発に使用される高レベルのワークフローに関する情報も含まれています。また、お客様の導入に推奨されるサイジングについても説明します。</block>
  <block id="f6e5955fac81d01e271cb733c3163cba" category="paragraph"><block ref="f6e5955fac81d01e271cb733c3163cba" category="inline-link-macro-rx"></block></block>
  <block id="8ada98332d4bde2905136eacd122ca17" category="doc">NVA-1150設計：NetApp EシリーズシステムでのQuantum StorNextの設計ガイド</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">このドキュメントでは、NetApp Eシリーズストレージシステムを使用したStorNextパラレルファイルシステム解決策 の設計方法について詳しく説明します。この解決策 では、NetApp EF280オールフラッシュアレイ、NetApp EF300オールフラッシュNVMeアレイ、EF600オールフラッシュNVMeアレイ、およびNetApp E5760ハイブリッドシステムについて説明します。Frametestベンチマークに基づいてパフォーマンス特性を評価します。Frametestベンチマークは、メディアおよびエンターテイメント業界で広く使用されているツールです。</block>
  <block id="8d34cd86db3dd46b4c83d32098f9f458" category="inline-link-macro"><block ref="8d34cd86db3dd46b4c83d32098f9f458" category="inline-link-rx"></block></block>
  <block id="580fb8819de48faa426f431251c8b4db" category="paragraph"><block ref="580fb8819de48faa426f431251c8b4db" category="inline-link-macro-rx"></block></block>
  <block id="822b5b3ac9e0f170e124850176f6f5ad" category="doc">TR-4807：『NetApp ONTAP AI Reference Architecture for Financial Services Workloads -解決策 Design』</block>
  <block id="a8b8bcca1cc81c47655f69efaea66280" category="paragraph">Karthikeyan Nagalingam、Sung-Han Lin、NetApp Jacci Cenci、NVIDIA</block>
  <block id="5e01fc0ba3a2133ea5de509bf81e119d" category="paragraph">このリファレンスアーキテクチャでは、金融セクターのユースケース向けにNVIDIA DGX-1システムとNetApp AFF ストレージを使用して人工知能インフラを構築するお客様向けのガイドラインを提供します。また、金融サービスのテストケースや結果のディープラーニングモデルの開発に使用されるワークフローの概要についても説明します。また、お客様の導入に推奨されるサイジングについても説明します。</block>
  <block id="a6f98d09d0c8f042087143764a02630c" category="inline-link-macro"><block ref="a6f98d09d0c8f042087143764a02630c" category="inline-link-rx"></block></block>
  <block id="cc1efb0a1d820f8806a752002b5d9b4c" category="paragraph"><block ref="cc1efb0a1d820f8806a752002b5d9b4c" category="inline-link-macro-rx"></block></block>
  <block id="208683138843b8d3d5e2d587c3c7655b" category="doc">TR-48815：『NetApp AFF A800 and Fujitsu Server PRIMERGY GX2570 M5 for AI and ML Model Training Workloads』</block>
  <block id="5f2ab39ba2f8133927b3b4608a712d5b" category="paragraph">David Arnette、NetApp、大石隆、富士通</block>
  <block id="62c32325e658b728843c4f250b5d1547" category="paragraph">この解決策 は、ネットアップストレージシステムと富士通のサーバを使用して人工知能システムを導入するためのスケールアウトアーキテクチャに焦点を当てています。解決策 は、富士通GX2570サーバとNetApp AFF A800ストレージシステムを使用したMLperf v0.6モデルトレーニングベンチマークで検証されました。</block>
  <block id="b7c37fdfd029affe5cf4c25d73b9084d" category="inline-link-macro"><block ref="b7c37fdfd029affe5cf4c25d73b9084d" category="inline-link-rx"></block></block>
  <block id="dc4386f7ba9f47c00c36d26452de1559" category="paragraph"><block ref="dc4386f7ba9f47c00c36d26452de1559" category="inline-link-macro-rx"></block></block>
  <block id="5c6463fd6d00a2574dfb072c48e8de49" category="doc">TR-4859：『Deploying IBM Spectrum Scale with NetApp E-Series Storage - Installation and validation』</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">ネットアップ、Chris Seirer</block>
  <block id="fdb4fdcbeafc3d334651614437516062" category="paragraph">TR-4859では、IBMのSpectrum Scaleソフトウェアスタックに基づいて、フル並列ファイルシステムの解決策 を導入するプロセスについて説明しています。TR-4859は、Spectrum Scaleのインストール、インフラの検証、構成の管理の方法に関する詳細を提供するように設計されています。</block>
  <block id="c9bcc5e8e66d05c764fccb9ece380847" category="inline-link-macro"><block ref="c9bcc5e8e66d05c764fccb9ece380847" category="inline-link-rx"></block></block>
  <block id="22c1cefecec00093f0b70a70b2680dcf" category="paragraph"><block ref="22c1cefecec00093f0b70a70b2680dcf" category="inline-link-macro-rx"></block></block>
  <block id="03077b9327bcb8fdf3f360d27c4dd2a6" category="doc">NVA-1153 -導入：NVIDIA DGX A100システムとMellanox Spectrumイーサネットスイッチを搭載したNetApp ONTAP AI</block>
  <block id="5f4c1dd940d24299c2c5a80211b1e330" category="paragraph">NVA-1153 - NetApp AFF A800ストレージシステム、NVIDIA DGX A100システム、NVIDIA Mellanox Spectrum SN3700V 200GBイーサネットスイッチを使用した、機械学習（ML）と人工知能（AI）のワークロード向けのNetApp Verified Architectureでのストレージシステムの導入手順を記載します。また、導入完了後に検証ベンチマークテストを実行する手順についても説明します。</block>
  <block id="c24b711a1468d82d0ec120ccf0fe60e8" category="inline-link-macro"><block ref="c24b711a1468d82d0ec120ccf0fe60e8" category="inline-link-rx"></block></block>
  <block id="fa7cdfafd1276f51fd3285f61a6c4aec" category="paragraph"><block ref="fa7cdfafd1276f51fd3285f61a6c4aec" category="inline-link-macro-rx"></block></block>
  <block id="c1ba6d72bba1b6f1d94714d4fcc78480" category="doc">TR-4320：『NetApp E-Series and Commvault Data Platform V11 - Reference Architecture and Storage Best Practices』</block>
  <block id="23b69f42a62554346d10d302e32866df" category="paragraph">Commvault Girish Chanchlani、Akash Gupta氏</block>
  <block id="451f1cdad20049e4046b157a54826db1" category="paragraph">TR-4320は、Commvault Data Platform V11環境でNetApp Eシリーズストレージを使用する場合のリファレンスアーキテクチャとベストプラクティスの概要を示しています。Commvaultとネットアップはこのリファレンスアーキテクチャを共同開発し、Commvault Data Platform V11の導入にNetApp Eシリーズストレージを使用するガイダンスを提供しています。このリファレンスアーキテクチャを使用すると、この解決策 の適用時間を短縮できます。</block>
  <block id="df7cf7c589f9721849875c4944ab1b5f" category="inline-link-macro"><block ref="df7cf7c589f9721849875c4944ab1b5f" category="inline-link-rx"></block></block>
  <block id="d08fcd93c2915044da2cb0000a532b24" category="paragraph"><block ref="d08fcd93c2915044da2cb0000a532b24" category="inline-link-macro-rx"></block></block>
  <block id="fe85f62ed86fedb2f150ec1a40d67f2e" category="doc">TR-4704：『Deploying Veritas NetBackup with NetApp E-Series Storage』</block>
  <block id="d223d0d947999082ea93b57a68b3614b" category="paragraph">Akash GuptaとPrincipled Technologies、ネットアップ</block>
  <block id="9c993f8d3d3aa7be9c86474635154c12" category="paragraph">TR-4704では、NetApp EシリーズストレージへのVeritas NetBackupの導入について説明しています。</block>
  <block id="ddc8bf6244e563f16009d9f3993a3651" category="inline-link-macro"><block ref="ddc8bf6244e563f16009d9f3993a3651" category="inline-link-rx"></block></block>
  <block id="f0320db0293afb1c878e6a4fd3127640" category="paragraph"><block ref="f0320db0293afb1c878e6a4fd3127640" category="inline-link-macro-rx"></block></block>
  <block id="fd031987b2da91ab23764bc7a2eeb897" category="doc">TR-4471：『E-Series and EF Series Reference Architecture and Storage Best Practices with Veeam Backup &amp; Replication 9.5』</block>
  <block id="febdd047851001456a2f0c683cfcfd2b" category="paragraph">Akash Gupta、ネットアップのShawn Lie(北南米)、Stefan Renner (EMEA)、Michael Cade (パフォーマンス)、Veeam</block>
  <block id="a207fab8627637842c817cfbb6e2a3e5" category="paragraph">TR-4471では、Veeam Backup &amp; Replication 9.5環境でNetApp Eシリーズストレージを使用する際のリファレンスアーキテクチャとベストプラクティスを紹介しています</block>
  <block id="609999428a14d32b8afba97bbc6a3bd3" category="inline-link-macro"><block ref="609999428a14d32b8afba97bbc6a3bd3" category="inline-link-rx"></block></block>
  <block id="27f4fbfb25a706ee60055e1e7bc5b112" category="paragraph"><block ref="27f4fbfb25a706ee60055e1e7bc5b112" category="inline-link-macro-rx"></block></block>
  <block id="6a2c7fa6b0a402c3b9034538d8c9771f" category="doc">NVA-1143：マルチテナントインフラ向けHyTrustを備えたFISMA向けのNetApp HCI -NISTセキュリティ制御- NVAの設計と導入</block>
  <block id="2de6bbd06654b0c6d7bd5a6f2bb218f8" category="paragraph">ネットアップ、Abhinav Singh、Arvind Ramakrinan氏</block>
  <block id="6fdf0a62913845390e552b0f7d42cbf7" category="paragraph">NVA-1143では、NetApp HCI がNational Institute of Standards and Technology（NIST；米国標準技術研究所）SP 800-53 Revision 4のセキュリティとプライバシーの制御を満たすように設計および導入される方法について説明しています。この制御は、プライベートクラウドインフラやマルチテナントの導入に不可欠です。</block>
  <block id="7f02c84e9695cb8a35c7deacae1ac60a" category="inline-link-macro"><block ref="7f02c84e9695cb8a35c7deacae1ac60a" category="inline-link-rx"></block></block>
  <block id="d296785b2301f7049b2372228fec21ee" category="paragraph"><block ref="d296785b2301f7049b2372228fec21ee" category="inline-link-macro-rx"></block></block>
  <block id="b1567dc4fc97586a9f0b9a3cc9b7fafa" category="doc">NVA-1157 -導入：NetApp Storage解決策 を使用したApache Sparkワークロード</block>
  <block id="a9828ed348eedd7a35b76de35fda7796" category="paragraph">NVA-1157-deployでは、NetApp NFS AFF ストレージシステムでのApache Spark SQLのパフォーマンスと機能性検証について説明しています。さまざまなシナリオに基づいた構成、アーキテクチャ、パフォーマンステストのほか、SparkとNetApp ONTAP データ管理ソフトウェアの使用に関する推奨事項を確認します。また、NetApp AFF A800ストレージコントローラに比べて、Just a Bunch of Disks（JBOD）に基づくテスト結果についても説明します。</block>
  <block id="b2bbcfd654a3dd74458969dc7e877cd4" category="paragraph"><block ref="b2bbcfd654a3dd74458969dc7e877cd4" category="inline-link-macro-rx"></block></block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623：『NetApp E-Series E5700 and Splunk Enterprise』</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">Mitch Blackburn、ネットアップ</block>
  <block id="821c9e3ae35ae3b188264d2461cec030" category="paragraph">TR-4623に、NetApp EシリーズとSplunkの設計を統合したアーキテクチャを示します。ノードストレージのバランス、信頼性、パフォーマンス、ストレージ容量、密度を最適化この設計では、Splunkクラスタ化インデックスのノードモデルを採用し、拡張性を高めてTCOを削減しています。ストレージをコンピューティングから切り離すことで、それぞれを個別に拡張できるため、オーバープロビジョニングを行うコストを削減できます。また、Splunkのマシンログイベントシミュレーションツールから取得したパフォーマンステスト結果をまとめたものです。</block>
  <block id="7c65bf783488e992fb7c72bab3ddbbf2" category="inline-link-macro"><block ref="7c65bf783488e992fb7c72bab3ddbbf2" category="inline-link-rx"></block></block>
  <block id="145793ae401011691a99a02e5087ba8a" category="paragraph"><block ref="145793ae401011691a99a02e5087ba8a" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">最新のデータ分析-さまざまな分析戦略に対応するさまざまなソリューション</block>
  <block id="8e1e8679efe4694874eb9820dff26af8" category="paragraph">このホワイトペーパーでは、ネットアップの最新のデータ分析解決策 戦略について説明します。ビジネスの成果、お客様の課題、テクノロジのトレンド、競合他社のレガシーアーキテクチャ、最新のワークフローなどの詳細を確認できます。ユースケース、業界、クラウド、テクノロジパートナー、Data Mover、NetApp Active IQ 、NetApp DataOpsツールキット、HadoopからSparkへ、NetApp Astra Control、コンテナ、エンタープライズデータ管理、アーカイブ、階層化を使用したSoftware-Defined Storage。AIと分析の目標を達成し、ネットアップとお客様が同時にデータアーキテクチャを刷新しようとしています。</block>
  <block id="ef159076e3a244c9e0bc48cdde7742a7" category="inline-link-macro"><block ref="ef159076e3a244c9e0bc48cdde7742a7" category="inline-link-rx"></block></block>
  <block id="bff0b3c76158c2ffdc1105de3c094296" category="paragraph"><block ref="bff0b3c76158c2ffdc1105de3c094296" category="inline-link-macro-rx"></block></block>
  <block id="4eb5c705ea54813c084d88a3d5a668f0" category="admonition">ドキュメントごとにドキュメントタイトル（レベル0）を1つだけ指定する必要があり、セクションタイトルはスキップできません（セクションの下位の次の見出しレベルをセクションの下に指定する必要があります）。そのため、処理中のビルドエラーを解消するために、サンプルは出力に表示されません。</block>
  <block id="9b6f25534617a536120885c9ce2bf30b" category="inline-link">インストール手順 については、Veeamの製品ドキュメントを参照してください</block>
  <block id="51c7ff4d9c3185f2df469eed762010d5" category="inline-link-macro">VMware Cloud Tech Zone</block>
  <block id="baab3b6c6024ccda908423e27d1a7d5b" category="admonition">この解決策 は、VMwareからも入手できます。にアクセスしてください <block ref="e4f8fde8ba3579a04642cf870e6e362f" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="dc32da64b7845bbbf4827a1513cd8daa" category="inline-link-macro">VMware HCXを使用して、AWS SDDC上のNetApp ONTAP およびVMware Cloud用のFSXでハイブリッドクラウドを構成します</block>
  <block id="e51f186f2c7dd10d7f4c1196ab269d7c" category="list-text"><block ref="e51f186f2c7dd10d7f4c1196ab269d7c" category="inline-link-macro-rx"></block></block>
  <block id="3cf6cddd26350e6a84e8bef869102647" category="cell">2022年10月25日</block>
  <block id="80d05b7bca341d02b41c7f6cb32ad23b" category="cell">NFSデータストアとしてのFSX ONTAP のVMwareドックへのリンクを追加</block>
  <block id="2937ec3775c4b0354bf359a5892c53f7" category="cell">ブログ「Configuring Hybrid Cloud with FSX ONTAP and VMC on AWS SDDC Using VMware HCX」を追加</block>
  <block id="0676783b7d49061bfb23deb83b2d2f82" category="paragraph">*ジョブテンプレートを設定して起動します。*</block>
  <block id="544348a8f04b16faced725115db5b6f3" category="section-title">環境のインベントリ、グループ、ホスト、クレデンシャルを作成します</block>
  <block id="be86ca474df5e14056bc0f20d2cdb767" category="section-title">プロジェクトを作成します</block>
  <block id="d02a79fb6f05358e16f9d9cf02288ac3" category="section-title">グローバル変数を設定します</block>
  <block id="3506caa5fe966a4676faac2993bc1431" category="section-title">自動化ハンドブック</block>
  <block id="ba985cf3c812e3ba064fedc7353bbb77" category="section-title">Oracleデータベースをリカバリしています</block>
  <block id="fb467c38c5af2ca41ea3f09fe535144d" category="list-text">* RO/RWアクセスルール。*エクスポートへのアクセスレベルを制御するには、読み取り/書き込みまたは読み取り専用を選択します。CVS -パフォーマンスには、次のオプションがあります。</block>
  <block id="b42b7de139bf4398a5d4b048ecf30c9f" category="paragraph">さらに、Cloud Volumes Service では、サポートされる最大グループ数を最大32まで拡張する拡張グループサポートが提供されています。そのためには、有効なUNIXユーザおよびグループのIDを含むLDAPサーバへのLDAP接続が必要です。この設定の詳細については、を参照してください<block ref="744e76592290230cb7381c9b8a5414da" category="inline-link-rx"></block> Googleのドキュメントを参照してください。</block>
  <block id="73867c3747b10f9f7b4b54a4597ff38b" category="paragraph">IAMには、Cloud Volumes Service に対する詳細な権限があらかじめ組み込まれています。を見つけることができる<block ref="fefbe49b0be12af5b957eff3a3dc2826" category="inline-link-rx"></block>。</block>
  <block id="00aa2e143f3d3b00e94456b23d239a8d" category="paragraph">を参照してください<block ref="5d862676de2107050ea35e71368d2326" category="inline-link-rx"></block> 詳細については、Google Cloudのドキュメントを参照してください。</block>
  <block id="4a0d70491e56eae6b1e0743d9c3a3777" category="paragraph">Cloud Volumes Service APIでは、基盤となるネットワーク転送としてHTTPS（TLSv1.2）を使用してRESTベースのAPIを使用します。最新のAPI定義を確認できます<block ref="d30245d84ac801bb5beeb0b65de1621d" category="inline-link-rx"></block> およびでのAPIの使用方法に関する情報<block ref="00c944b7c7739b905457d5d21be6a7ef" category="inline-link-rx"></block>。</block>
  <block id="f84137720cfd9533352746a01677a6b2" category="paragraph">CloudSQL、Google Cloud VMware Engine（GCVE）、ファイルストアなど、他のGoogle Cloudネイティブサービスと同様の方法で、Cloud Volumes Service はを使用します<block ref="0f93a99b9e468a051182b66dabbf3bed" category="inline-link-rx"></block> サービスを提供します。PSAでは、サービスは、を使用するサービスプロデューサプロジェクト内に構築されます<block ref="2d8d4488e7ed7b53a7aafab379ba8587" category="inline-link-rx"></block> サービスコンシューマに接続するには、次の手順に従います。サービスプロデューサーはネットアップが提供して運用します。サービスコンシューマは、Cloud Volumes Service ファイル共有にアクセスするクライアントをホストする、お客様のプロジェクトのVPCです。</block>
  <block id="9448d83a67980a22f2db155347fa277c" category="paragraph">から参照される次の図<block ref="6a8b5039754626811ee5b8fe5289e273" category="inline-link-rx"></block> Cloud Volumes Service のドキュメントの概要をに示します。</block>
  <block id="a436da0007911ed6531e093688e82535" category="paragraph">共有VPCを使用する場合は、NFS Kerberosまたは/またはを使用した転送中の暗号化が可能です <block ref="639817e82862065dd236f0597e0b07ea" category="inline-link-macro-rx"></block> トレースから収集された情報の多くを隠すことができます。ただし、一部のトラフィックは、などのプレーンテキストで送信されます <block ref="c2e2f225386e22bd13a8b4b174f478da" category="inline-link-macro-rx"></block> および <block ref="86c1c13023c15e9d9a6317a0b69e7ce3" category="inline-link-macro-rx"></block>。次の図に、Cloud Volumes Service から発信されたプレーンテキストLDAPクエリからのパケットキャプチャと、公開されている可能性のある識別情報を示します。Cloud Volumes Service のLDAPクエリでは、現在、暗号化またはLDAP over SSLがサポートされていません。CVS - Active Directoryから要求された場合に、パフォーマンスがLDAP署名をサポートします。CVS-SWではLDAP署名はサポートされません。</block>
  <block id="75956b9ee748b806549eeec3c9a81192" category="inline-link"><block ref="75956b9ee748b806549eeec3c9a81192" category="inline-link-rx"></block></block>
  <block id="6c84917a571a2282fd9fb2a6f058a11e" category="paragraph"><block ref="6c84917a571a2282fd9fb2a6f058a11e" category="inline-link-rx"></block></block>
  <block id="5bcf8cb715ebf788ba3e70915f4256c2" category="paragraph">リージョンごとに許可されるActive Directory接続は1つだけです。</block>
  <block id="00d6cadb7a586713782bbffe59d5bc21" category="paragraph">Cloud Volumes Service は、異なるエンドポイント間でサービス管理（コントロールプレーン）とデータアクセス（データプレーン）をセグメント化することで、Google Cloudのセキュアなアーキテクチャを提供します。これにより、どちらも他方に影響を与えることはありません（を参照） <block ref="d861c2ffd2960acc200167f08fd40005" category="inline-link-macro-rx"></block>）。Googleを使用している<block ref="1ac65cff0d913f26dd36736caeefd5b7" category="inline-link-rx"></block> （PSA）サービスを提供するためのフレームワーク。このフレームワークでは、ネットアップが提供、運用するサービスプロデューサーと、Cloud Volumes Service ファイル共有にアクセスするクライアントをホストする顧客プロジェクトのVirtual Private Cloud（VPC；仮想プライベートクラウド）であるサービスコンシューマが区別されます。</block>
  <block id="1e21a0f8a8012a10d3db8d473ba52502" category="paragraph">LDAPおよびKerberosを使用する場合は、これらのサービスで使用されているネットワークポートを確認する必要があります。Cloud Volumes Service で使用されているすべてのポートの一覧については、を参照してください<block ref="0dc8f2243f86f97f7b6af9378a496f93" category="inline-link-rx"></block>。</block>
  <block id="811bec2d7b00d479640fbf3259346fe6" category="paragraph">CVS -パフォーマンス用のKMSの設定については、を参照してください<block ref="a0d8b07d63b271255da3bba6f51651a4" category="inline-link-rx"></block>。</block>
  <block id="c56328227fc3affbe6ed0ef4ba04f494" category="list-text"><block ref="c56328227fc3affbe6ed0ef4ba04f494" category="inline-link-rx"></block></block>
  <block id="c6563340810489dd712f25c2644eaed8" category="list-text"><block ref="c6563340810489dd712f25c2644eaed8" category="inline-link-rx"></block></block>
  <block id="150a343c955aa3114dca2e9c39571ad8" category="paragraph">さらに、Kerberosを含むLDAPを使用するSMB、NFS、およびデュアルプロトコル構成では、Windows Active Directoryドメインへのアクセスが必要になります。Active Directory接続はである必要があります<block ref="10ec0b3d8ec2c3b73be0dd7483e61c9e" category="inline-link-rx"></block> 地域単位で指定します。Active Directoryドメインコントローラ（DC）は、で識別できます<block ref="821541d595f9fee8c67d91aa5da861b4" category="inline-link-rx"></block> 指定したDNSサーバを使用しています。返されるDCはすべて使用されます。対象となるDCのリストは、Active Directoryサイトを指定することによって制限できます。</block>
  <block id="7a9b1188e66f0581af9bc76ec3099a55" category="paragraph">Cloud Volumes Service は、に割り当てられているCIDR範囲のIPアドレスを使用して到達します<block ref="3102e8199e828cb030b6f0ade5fc2cec" prefix=" " category="inline-code"></block> コマンドを実行中です<block ref="e8e0c669039859d9678de67879e03e1d" category="inline-link-rx"></block>。このCIDRをソースアドレスとして使用して、Active Directoryドメインコントローラへのインバウンドファイアウォールを設定できます。</block>
  <block id="60bb23c83a123fdd2c99980eb34c8f80" category="paragraph">Active Directoryドメインコントローラは必須です<block ref="7b35a292c67c7ee0f89d3dd389e188e4" category="inline-link-rx"></block>。</block>
  <block id="fd313eaaaadfe56df9ec88896284165d" category="paragraph">CVS -パフォーマンス用のKMSの設定方法については、<block ref="905a3b34ffbfe930acdbf23dd47d698f" category="inline-link-rx"></block>。</block>
  <block id="9fd9d0ecc58c5d26f4934bc140ac2a41" category="list-text">CVS -パフォーマンスを利用すると、他のCVSパフォーマンスボリュームにリージョン間でボリュームをレプリケーションすることができます。詳細については、を参照してください<block ref="ec408a29560fd662bec08bf50f9ff3d6" category="inline-link-rx"></block> Cloud Volumes Service のドキュメントを参照してください。</block>
  <block id="6a7870f99b17bbb49636a1e7be9d4be1" category="list-text">CVS-SWは、サービスネイティブのボリュームバックアップ/リストア機能を提供します。詳細については、を参照してください<block ref="2377dc7e4548195ed704b70f3ce6250c" category="inline-link-rx"></block> Cloud Volumes Service のドキュメントを参照してください。</block>
  <block id="344c8cea0d31ef9e8c7c56863c714a04" category="paragraph">また、Google Cloudのクロスリージョンレプリケーション（CRR）管理により、ボリュームの削除、Snapshotの削除、Snapshotスケジュールの変更など、悪意のある管理操作を防止できます。そのためには、ボリューム管理者を分離したカスタムロールを作成します。カスタムロールでは、ソースボリュームは削除できますが、ミラーを解除できないため、ボリューム操作を実行できないCRR管理者からデスティネーションボリュームを削除できません。を参照してください<block ref="bf2a9ccb864ad3a1fa1ddc1fec02a961" category="inline-link-rx"></block> 各管理者グループが許可する権限については、Cloud Volumes Service のマニュアルを参照してください。</block>
  <block id="99144970696c7e366271871a0e83b6cd" category="paragraph">これらの理由から、NetApp Cloud Volumes Service は、を使用してバックアップサービスを提供します<block ref="253601e5d476a508040b734cbc7b3164" category="inline-link-rx"></block>。</block>
  <block id="57e8b261ab803839f73416e368f552bc" category="paragraph">Cloud Volumes Service バックアップは、Cloud Volumes Service Asオプションに組み込まれています。ユーザは、Cloud Volumes Service バックアップをボリューム単位でアクティブ化して保護するボリュームを決定できます。を参照してください<block ref="218d9dd384a48541f627c5084c286ade" category="inline-link-rx"></block> バックアップの詳細については、を参照してください<block ref="d724a11e2928bd8489b8ad8fe1eac94b" category="inline-link-rx"></block>、スケジュール、および<block ref="31e05107512c82ef17df4f5c4b3fe0bd" category="inline-link-rx"></block>。</block>
  <block id="de8a90c8653195ed30cc4920de8c7921" category="paragraph">Cloud Volumes Service バックアップの管理（バックアップの作成、削除、リストア）を行うには、が必要です<block ref="595f329bf934dbc7996bb735e9664896" category="inline-link-rx"></block> ロール。</block>
  <block id="6640e7cef3ca860543c49a5125ba4c5a" category="list-text">NFSv4.xに加えてkrb5pを使用した方がパフォーマンスが向上し、ファイル数の多いワークロードに対応できます。</block>
  <block id="11eb332ab75184a78c40c9174e16f520" category="paragraph-title">ネットアップと VMware ：力を合わせて</block>
  <block id="58eaebf972358f1cf03d386a4ade1a0f" category="section-title">次の手順</block>
  <block id="3603e14740d8edd319e72186341cb0af" category="cell">2022年6月12日</block>
  <block id="48461fa824ae344e0934144c7523c3f6" category="cell">Amazon FSXストレージを使用したハイブリッドクラウドでのOracleデータベースの最新化に関する7つのビデオを追加</block>
  <block id="954a2b08ded0ca2c881930f5ebeee24a" category="example-title">人工知能（AI）と最新のデータ分析</block>
  <block id="672d7bebe35b300386767050d4222453" category="paragraph">[underline]#* AWSとFSX *でハイブリッドクラウドを使用したOracleの最新化に関するビデオ</block>
  <block id="deb1d0bb3f3f4ef0121635c0f832a3bf" category="video-title">パート1 -ユースケースと解決策 アーキテクチャ</block>
  <block id="369b9aec1beb25441dc7c7fb46bc0fc6" category="video-title">パート2a -自動PDB再配置機能を使用した、オンプレミスからAWSへのデータベース移行と可用性の最大化</block>
  <block id="2edb94ef9695015c5cd01fec59bcc782" category="video-title">パート2b - SnapMirrorを使用したBlueXPコンソールを使用したオンプレミスからAWSへのデータベースの移行</block>
  <block id="59fa2b2110d3350efd262bd841c10975" category="video-title">第3部-データベースの自動HA / DRレプリケーションのセットアップ、フェイルオーバー、再同期</block>
  <block id="938d46c61cee67ddb1711167aba9f463" category="video-title">パート4a -複製されたスタンバイコピーから、SnapCenter UIを使用した開発とテストのためのデータベースクローン</block>
  <block id="09b285fbf39efff75f085bbadedde45e" category="video-title">パート4b - SnapCenter UIを使用したデータベースのバックアップ、リストア、クローニング</block>
  <block id="45885d9d91879afc9c37a8b3e046aac4" category="video-title">パート4c -データベースのバックアップ、BlueXP SaaS Appsによるリストアのバックアップとリカバリ</block>
  <block id="fe86efdcec6e779b5ef15f62d8f2bc90" category="paragraph-title">NetApp CVO（シングルノードインスタンス）をAWSに導入するための構成ファイルがTerraformにあります</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="paragraph-title">手順</block>
  <block id="4e91e39d32f2399e7c90059f4eea5684" category="paragraph-title">降水量：</block>
  <block id="93726ca0be25ac3bef0f54da1e20751c" category="paragraph-title">NetApp CVO（HAペア）をAWSに導入するための構成ファイルがTerraformにあります</block>
  <block id="99661bfb937ca0c49c78878d8d2b0e77" category="paragraph-title">NetApp ONTAP FSXをAWSに導入するためのTerraform構成ファイル</block>
  <block id="1538b268d8f3b010dea63370c1a65935" category="paragraph-title">レシピ：</block>
  <block id="107933ea485144e916f16cd69884fea6" category="paragraph-title">AzureにANFボリュームを導入するための環境設定ファイルを用意しています</block>
  <block id="c2d6144ea47815bb9e1c4e09c0918486" category="paragraph-title">Azure上にデータ保護機能を備えたANFボリュームを導入するための構成ファイルを用意しています</block>
  <block id="1ed1215fce9948e3bee78c99bf12de8d" category="paragraph-title">Azure上にデュアルプロトコルを使用してANFボリュームを導入するための構成ファイルが用意されています</block>
  <block id="15b915279743f1a43ce2c0f10062e69e" category="paragraph-title">Azure上のSnapshotからANFボリュームを導入するための構成ファイルをテラフォームしてください</block>
  <block id="664b1f8a02a683b16bb76004afb03be2" category="paragraph-title">AzureにシングルノードのCVOを導入するための構成ファイルがTerraformに用意されています</block>
  <block id="f06bfa867f111b72b9e71b8a75d661da" category="paragraph-title">AzureにCVO HAを導入するための構成ファイルがTerraformに用意されています</block>
  <block id="e10db5a03ff1c5409d1b9ef0cf32ae11" category="paragraph-title">GCPにNetApp CVO（シングルノードインスタンス）を導入するためのTerraform構成ファイル</block>
  <block id="1e95e8962dbf55d78e03e8da38f9f408" category="paragraph-title">NetApp CVO（HAペア）をGCPに導入するための構成ファイルをTerraformしています</block>
  <block id="f39b5c8ffff4c5fccbc9ca01bf3bacf8" category="paragraph-title">GCPにNetApp CVSボリュームを導入するためのTerraform構成ファイル</block>
  <block id="934282d2b6cc731f63bcc3cdfbba32a1" category="paragraph">導入シナリオに基づいて、Veeamバックアップサーバ、バックアップリポジトリ、およびバックアッププロキシを導入する必要があります。このユースケースでは、Veeam用のオブジェクトストアとスケールアウトリポジトリも必要ありません。<block ref="3798d8f6f1f14581181abe3a5ef34dc1" category="inline-link-rx"></block></block>
  <block id="a94f1b9cbc89a005a38096b1750f907f" category="cell">2022年12月15日</block>
  <block id="754451201969a73231c286ef8f4b2fd6" category="cell">TR-4923：『SQL Server on AWS EC2 Using Amazon FSX for NetApp ONTAP 』を追加</block>
  <block id="f53cfd73e0994740413d578c9dd6b36e" category="doc">TR-4923：『SQL Server on AWS EC2 Using Amazon FSX for NetApp ONTAP 』</block>
  <block id="9aeea85747c176482897f26600d172d0" category="paragraph">執筆者：Pat Sinthusan and Niyaz Mohamed、NetApp</block>
  <block id="8bd093418d226733e085e856bd9165c8" category="paragraph">オンプレミスのストレージシステムとクラウドストレージサービスの機能の違いによって、アプリケーションをオンプレミスからクラウドに移行したいと考えている企業は少なくありません。このギャップが解消されたことで、Microsoft SQL Serverなどのエンタープライズアプリケーションの移行で問題が生じていました。特に、堅牢なスナップショット、Storage Efficiency機能、高可用性、信頼性、一貫性のあるパフォーマンスなどのエンタープライズアプリケーションを実行するために必要なサービスが不足しているため、設計のトレードオフやアプリケーションの移行が必要になりました。FSX for NetApp ONTAP を使用することで、顧客は妥協する必要がなくなります。NetApp ONTAP のFSXは、AWSが販売、サポート、課金、フルマネージドのネイティブ（ファーストパーティ）AWSサービスです。NetApp ONTAP の機能を活用して、エンタープライズクラスのストレージとデータ管理機能を提供します。ネットアップは、AWSで30年にわたってマネージドサービスとしてオンプレミスで提供してきたのと同じ機能を提供します。</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="inline-link">AWS FSX ONTAP の略</block>
  <block id="a2f7f68476a76b6aa359589e4d201707" category="paragraph">EC2インスタンス上のSQL Serverを使用すると、データベース管理者は、自身のデータベース環境と基盤となるオペレーティングシステムにアクセスしてカスタマイズできます。EC2インスタンス上のSQL Serverをと組み合わせて使用する必要があります<block ref="3f737fd84a60fb425fdcdb5cf9a593da" category="inline-link-rx"></block> データベースファイルを格納するために、ブロックレベルのレプリケーションを使用して、高パフォーマンス、データ管理、およびシンプルで簡単な移行パスを実現できます。そのため、AWS VPC上で複雑なデータベースを簡単に移行して、クリック回数を減らすことができ、スキーマの変換も不要です。</block>
  <block id="cf79d59896c29cc7579cf75220c25c95" category="section-title">NetApp ONTAP でSQL Serverを使用するメリット</block>
  <block id="8908df00453997edbfc759829ecdf0d8" category="paragraph">Amazon FSX for NetApp ONTAP は、AWSにSQL Serverを導入する場合に最適なファイルストレージです。次のようなメリットがあります。</block>
  <block id="7b699f0e1a60e419ed7d9173339aa3f5" category="list-text">一貫した高パフォーマンスとスループットを低レイテンシで実現</block>
  <block id="8a34b0f2109dd0aad0c0c9976717cdd3" category="list-text">NVMeキャッシュによるインテリジェントなキャッシングでパフォーマンスを向上</block>
  <block id="b10e27f9d68e001b8aa9369c8d308a8c" category="list-text">容量、スループット、IOPSをオンザフライで柔軟にサイジングできます</block>
  <block id="169fee7c17564fc51aa8d2e77bcc1ce0" category="list-text">オンプレミスからAWSへの効率的なブロックレプリケーション</block>
  <block id="fd140f04c5bc5f51aff3ea5e1619abaf" category="list-text">データベース環境での一般的なプロトコルであるiSCSIの使用</block>
  <block id="e2c00a563e0219fd93fa6f24606dee33" category="list-text">シンプロビジョニングやゼロフットプリントのクローンなどのStorage Efficiency機能を備えています</block>
  <block id="4ac0316f1ba409d5cd9684222f9f8ada" category="list-text">バックアップにかかる時間が数時間から数分に短縮され、RTOが短縮されます</block>
  <block id="e3168d8a4383357a37460afad2f8878d" category="list-text">わかりやすいNetApp SnapCenter UIで、SQLデータベースのバックアップとリカバリをきめ細かく実行できます</block>
  <block id="935da11069e36e124602b7e23a73ee06" category="list-text">実際の移行前に複数のテスト移行を実行できること</block>
  <block id="15173984ed0ff615a3f0d55c8cd12291" category="list-text">移行中のダウンタイムを短縮し、ファイルレベルまたはI/Oレベルのコピーによって移行の課題を克服できます</block>
  <block id="0de5f8d5cf18757efac074c02f16a0bb" category="list-text">メジャーリリースまたはパッチの更新後にルート原因 を検出することで、MTTRを短縮できます</block>
  <block id="1a8e2e4ef765d6c61c4652659fb151ac" category="paragraph">一般的にオンプレミスで使用されているように、FSX ONTAP にSQL Serverデータベースを導入すると、優れたパフォーマンス、ストレージ効率、データ管理機能を備えた理想的なデータベースストレージ環境が実現します。ワークセットサイズが5%であると仮定して複数のiSCSIセッションを使用した場合、Flash Cacheを配置すると、FSX ONTAP サービスでは10万IOPSを超えることがあります。この構成では、非常に要件の厳しいアプリケーションのパフォーマンスを完全に制御できます。FSX for ONTAP に接続された小規模なEC2インスタンス上で実行されるSQL Serverは、FSX for ONTAP に対して適用されるネットワーク帯域幅の制限のみであるため、はるかに大規模なEC2インスタンス上で実行されるSQL Serverと同じパフォーマンスを実現できます。インスタンスのサイズを縮小することでコンピューティングコストも削減され、TCOを最適化して導入できます。iSCSIを使用するSQLと'FSX for ONTAP 上のマルチチャネルの継続的可用性共有を持つSMB3.0を組み合わせることで'SQLワークロードに大きなメリットがもたらされます</block>
  <block id="135b308ed83c53f1516b7c754566d1c4" category="section-title">作業を開始する前に</block>
  <block id="365a329d23604298414064b1bd2dba2f" category="paragraph">Amazon FSX for NetApp ONTAP とEC2インスタンス上のSQL Serverを組み合わせることで、今日の最も要求の厳しいアプリケーション要件を満たすエンタープライズレベルのデータベースストレージ設計を作成できます。両方のテクノロジを最適化するには、SQL ServerのI/Oパターンと特性を理解することが重要です。SQL Serverデータベース用の適切に設計されたストレージレイアウトは、SQL ServerのパフォーマンスとSQL Serverインフラの管理をサポートします。また、ストレージレイアウトを適切に設定すれば、初期導入を成功させ、ビジネスの成長に合わせて環境をスムーズに拡張できます。</block>
  <block id="800d285a5a8ca10451f7ace50ac40de5" category="paragraph">本ドキュメントの手順を完了する前に、次の前提条件を満たしている必要があります。</block>
  <block id="69a7abd5a400936f0e1a89910dfa0ba1" category="list-text">AWSアカウント</block>
  <block id="bfa061c0e7fe048c571ab15bc8d211a4" category="list-text">EC2およびFSX for ONTAP をプロビジョニングするための適切なIAMロール</block>
  <block id="a76b04166db341ceee35b584673698e9" category="list-text">EC2上のWindows Active Directoryドメイン</block>
  <block id="3084927119ae63d45676d527dfb4a882" category="list-text">すべてのSQL Serverノードが相互に通信できる必要があります</block>
  <block id="b1ada0ca0559fff335d482de393b4c70" category="list-text">DNS解決が機能し、ホスト名を解決できることを確認します。この条件を満たしていない場合は、ホストファイルエントリを使用します</block>
  <block id="8413178222467ef68eb68a0644f11c42" category="list-text">SQL Serverのインストールに関する一般的な知識</block>
  <block id="9c69c1668eca3541f0576cdc7fc730f0" category="paragraph">また、ネットアップのSQL Server環境向けベストプラクティスを参照して、ストレージ構成が最適であることを確認してください。</block>
  <block id="49c805233b94175c188c58ebf681a2b9" category="example-title">EC2上のSQL Server環境向けのベストプラクティス構成</block>
  <block id="d1d9da06ca1cde6106fef737b522df6e" category="paragraph">FSX ONTAP では、ストレージの調達が最も簡単な作業であり、ファイルシステムを更新することで実行できます。このシンプルなプロセスにより、必要に応じてコストとパフォーマンスを動的に最適化し、SQLワークロードのバランスを取ることができます。また、シンプロビジョニングも有効になります。FSX ONTAP シンプロビジョニングは、ファイルシステムでプロビジョニングされているものよりも、SQL Serverを実行しているEC2インスタンスに、より多くの論理ストレージを提供するように設計されています。スペースを事前に割り当てるのではなく、データの書き込み時にストレージスペースが動的に各ボリュームまたはLUNに割り当てられます。ほとんどの構成では、ボリュームまたはLUN内のデータが削除される（Snapshotコピーに保持されていない）と、空きスペースも解放されます。次の表に、ストレージを動的に割り当てるための設定を示します。</block>
  <block id="db1bfba30dab4f1ed4a13cc586837f1b" category="cell">なし（デフォルトで設定）</block>
  <block id="f6445fd89b0b2c67f0304765c4c9a760" category="cell">LUNリザベーション</block>
  <block id="f1e0735081bab920eff76b08a4600c76" category="cell">fractional_reserve</block>
  <block id="856ee920f3261cadbc1c3fc52171d071" category="cell">0%（デフォルトで設定）</block>
  <block id="99c0f62171e34b4ab6a79265f038e3af" category="cell">スナップリザーブ</block>
  <block id="7c68df7d17c446f99304ee1dc1498bfc" category="cell">オートサイズ</block>
  <block id="521c36a31c2762741cf0f8890cbe05e3" category="cell">オン</block>
  <block id="43c4c1dbc452be91829f25ee32c2a956" category="cell">ボリューム階層化ポリシー</block>
  <block id="6d576caa9862f6db0177dfaff7abb095" category="cell">Snapshotのみ</block>
  <block id="e08a486f204620eff1a08fc926316c68" category="paragraph">この構成では、ボリュームの合計サイズは、ファイルシステムで実際に使用可能なストレージよりも大きくなる可能性があります。LUNまたはSnapshotコピーがボリューム内の使用可能なスペースよりも多くのスペースを必要とする場合、ボリュームは、包含ファイルシステムからより多くのスペースを取得して自動的に拡張します。自動拡張では、FSX ONTAP によって、ボリュームのサイズが事前に決めた最大サイズまで自動的に拡張されます。ボリュームの自動拡張をサポートするには、使用可能なスペースを包含ファイルシステムに確保する必要があります。そのため、自動拡張を有効にした状態でファイルシステムの空きスペースを監視し、必要に応じてファイルシステムを更新してください。</block>
  <block id="82373a2016779f9c20fdc0d8b48101a7" category="inline-link">space-allocのようになります</block>
  <block id="0126eb1acda2ac795726d8bc5fe76a98" category="paragraph">これに加えて、を設定します<block ref="9d6ca3a9a42127525354c85d54adc465" category="inline-link-rx"></block> ボリュームのスペースが不足し、ボリューム内のLUNが書き込みを受け付けられなくなったときにFSX ONTAP がEC2ホストに通知するように、LUNのオプションを有効にします。また、このオプションを指定すると、EC2ホスト上のSQL Serverでデータが削除された場合に、ONTAP のFSXでスペースが自動的に再利用されます。space-allocationオプションは、デフォルトでdisabledに設定されています。</block>
  <block id="afa7be61df3527a5c4b5b7369729dfbc" category="admonition">ギャランティがnoneのボリュームにスペースリザーブLUNを作成する場合の動作は、スペースリザーブなしのLUNと同じです。ギャランティがnoneのボリュームは、ボリューム自体、書き込み時に初めてスペースが割り当てられるため、LUNに割り当てられるスペースはありません。</block>
  <block id="cf18df2432b44bda18f67ef6fc93e36f" category="paragraph">この構成では、通常、FSX ONTAP 管理者はボリュームのサイズを設定して、ホスト側とファイルシステム内のLUNの使用済みスペースを管理および監視する必要があります。</block>
  <block id="3e5fc395bc0727ee4a5d50bf7852e11e" category="admonition">SQL Serverのワークロードには別のファイルシステムを使用することを推奨します。ファイルシステムが複数のアプリケーションに使用されている場合は、ファイルシステムとファイルシステム内のボリュームの両方のスペース使用量を監視して、ボリューム間でスペースの競合が発生していないことを確認します。</block>
  <block id="9bc03cfd47c7deb1375b7e700fba9c1a" category="admonition">FlexCloneボリュームの作成に使用されるSnapshotコピーは、自動削除オプションでは削除されません。</block>
  <block id="20292bb9591bce95b16e6ee1415023d3" category="admonition">ストレージのオーバーコミットメントは、最小限のシステム停止でも許容できないSQL Serverなどのミッションクリティカルなアプリケーションに対して慎重に検討し、管理する必要があります。このような場合は、ストレージ消費の傾向を監視して、オーバーコミットメントが許容される量を判断することを推奨します。</block>
  <block id="d846da4dd06c448920cac63b79adc614" category="list-text">ストレージのパフォーマンスを最適化するには、ファイルシステムの容量をデータベースの合計使用量の1.5倍にプロビジョニングします。</block>
  <block id="e2ec94309dce197f199c6e60cd3070eb" category="list-text">シンプロビジョニングを使用してアプリケーションのダウンタイムを回避するには、適切な監視と効果的なアクションプランが必要です。</block>
  <block id="d7fbab8fe0fe681c9e815507bcdf85c8" category="list-text">Cloudwatchやその他の監視ツールのアラートを設定して、ストレージがいっぱいになったときに対応できるように十分な時間をユーザーに連絡するようにしてください。</block>
  <block id="626a89ea253e84625436538e7249e94d" category="section-title">SQL Server用のストレージを設定し、バックアップ、リストア、クローニングの各処理にSnapCenter を導入します</block>
  <block id="0a1c2236044192334a3fb3bbc0ab0dcd" category="paragraph">SnapCenter でSQL Serverの処理を実行するには、まずSQL Server用のボリュームとLUNを作成する必要があります。</block>
  <block id="0cf06bf086c162ff9027bab7f6f36c93" category="example-title">SQL Server用のボリュームとLUNを作成します</block>
  <block id="ff6ef44023084895f5f22aaf568ee0e3" category="paragraph">SQL Server用のボリュームとLUNを作成するには、次の手順を実行します。</block>
  <block id="0165fcfd32879eacf541aadf086338d2" category="list-text">でAmazon FSXコンソールを開きます<block ref="977f5adc4374191d0e48b9c0a8830158" category="inline-link-rx"></block></block>
  <block id="1e33ad7579c798ce6033c144ac99b840" category="list-text">CreationメソッドのStandard Createオプションを使用して、NetApp ONTAP ファイルシステムのAmazon FSXを作成します。これにより、FSxadminとvsadminの資格情報を定義できます。</block>
  <block id="a83755c47ff9159637d0666c65d8c544" category="paragraph"><block ref="a83755c47ff9159637d0666c65d8c544" category="inline-image-macro-rx" type="image"></block></block>
  <block id="269452df07db5e5d5fb10125ef2dfc42" category="list-text">fsxadminのパスワードを指定します。</block>
  <block id="0939c7e9185662b3e54503cb12415c7a" category="paragraph"><block ref="0939c7e9185662b3e54503cb12415c7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dea5db34596930d023317e03284777e1" category="list-text">SVMのパスワードを指定します。</block>
  <block id="d2b251088e201058dd19119478e04523" category="paragraph"><block ref="d2b251088e201058dd19119478e04523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5a504f8d9fd87dc54c0f8a370eed579" category="inline-link">NetApp ONTAP のFSX上にボリュームを作成する</block>
  <block id="d0ff5f8be38ac60d217f9c007a52da0e" category="list-text">に示す手順に従ってボリュームを作成します<block ref="1146addad8000a8f0f70de9ea1e5f637" category="inline-link-rx"></block>。</block>
  <block id="17288ccd1a2a55fccc24e084bec74a89" category="list-text">ストレージの Snapshot コピーのスケジュールと保持ポリシーを無効にします。代わりに、NetApp SnapCenter を使用して、SQL ServerのデータボリュームとログボリュームのSnapshotコピーを調整します。</block>
  <block id="c5023b4b04bc0ddc3d77e81fee7d99bb" category="list-text">高速できめ細かなリストア機能を利用するために、別 々 のボリューム上の個 々 のLUNにデータベースを設定します。</block>
  <block id="6cb174042332f6d15cedab79c1f88bac" category="list-text">ランダムな読み取り/書き込みワークロードであるため、ユーザデータファイル（.mdf）を別 々 のボリュームに配置します。トランザクションログバックアップは、データベースバックアップよりも頻繁に作成するのが一般的です。このため、トランザクションログファイル（.ldf）をデータファイルとは別のボリュームに配置して、それぞれに個別のバックアップスケジュールを作成できるようにします。この分離により、ログファイルのシーケンシャルライトI/Oがデータファイルのランダムリード/ライトI/Oから分離され、SQL Serverのパフォーマンスが大幅に向上します。</block>
  <block id="0588cef8958d83f61aed452f853f5852" category="list-text">tempdbは、Microsoft SQL Serverで一時的なワークスペースとして使用されるシステムデータベースです。特に、I/Oを大量に消費するDBCC CHECKDB操作に使用されます。したがって、このデータベースは専用ボリュームに配置してください。ボリューム数が課題となる大規模な環境では、慎重に計画を立てたあと、tempdbを少数のボリュームに統合し、他のシステムデータベースと同じボリュームに格納できます。tempdbのデータ保護は、Microsoft SQL Serverを再起動するたびに、このデータベースが再作成されるため、優先度が高くありません。</block>
  <block id="0f33b537ada1b2dcb95880741120d7b6" category="list-text">次のSSHコマンドを使用してボリュームを作成します。</block>
  <block id="4272c7e0323a62da36a59d8db2457c11" category="list-text">Windows Serverの管理者権限を使用して、PowerShellでiSCSIサービスを開始します。</block>
  <block id="91d0d079f1c5a2183c1012cd2c2e59ab" category="list-text">Windows Serverの管理者権限を使用して、PowerShellでMultipath IOをインストールします。</block>
  <block id="4dee8d84e86540a5c4c302b3d75c32bc" category="list-text">Windows Serverの管理者権限を使用して、PowerShellでWindowsイニシエータ名を検索します。</block>
  <block id="13aca4cbeddb191f6e28fc3dc5b50aca" category="paragraph"><block ref="13aca4cbeddb191f6e28fc3dc5b50aca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1fcce0650c7bce1532fc57b6af299dba" category="list-text">puttyを使用してStorage Virtual Machine（SVM）に接続し、igroupを作成します。</block>
  <block id="a260444f9f7265e7da0cffa861246e93" category="list-text">LUNを作成するには、次のSSHコマンドを使用します。</block>
  <block id="0bf39861d87235a7c094d3de2e3a8840" category="paragraph"><block ref="0bf39861d87235a7c094d3de2e3a8840" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f5ef787d84b4ec1b5183cffdef5b56" category="list-text">OSのパーティショニングスキームを使用してI/Oアライメントを実行するには、推奨されるLUNタイプとしてwindows_2008を使用してください。を参照してください<block ref="ff5fd3b71f5cd8b1a4e2fe23ad6d92ae" category="inline-link-rx"></block> 追加情報 の場合。</block>
  <block id="4f10474fd5677d7f5caee5944cfd1a79" category="list-text">次のSSHコマンドを使用して、作成したLUNにigroupをマッピングします。</block>
  <block id="e9cb77a7f24ef618789f32ace120d069" category="paragraph"><block ref="e9cb77a7f24ef618789f32ace120d069" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0108f548c7bfba3ca19e227db2ad81d9" category="list-text">Windowsフェイルオーバークラスタを使用する共有ディスクの場合は、SSHコマンドを実行して、Windowsフェイルオーバークラスタに参加しているすべてのサーバに属するigroupに同じLUNをマッピングします。</block>
  <block id="88c4f29ad54bd37fb1b7a1491b7af990" category="list-text">iSCSIターゲットを使用してWindows ServerをSVMに接続する。AWSポータルでターゲットのIPアドレスを検索します。</block>
  <block id="547003177db44afb512e9939c282d6c9" category="paragraph"><block ref="547003177db44afb512e9939c282d6c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df9eaa73034109b21c143e8c209823c2" category="list-text">Server ManagerおよびToolsメニューから、iSCSI Initiatorを選択します。[Discovery]タブを選択し、[Discover Portal]を選択します。前の手順で確認したiSCSI IPアドレスを入力し、Advanced（詳細設定）を選択します。[ローカルアダプタ]から[Microsoft iSCSIイニシエータ]を選択します。イニシエータIPから、サーバのIPを選択します。[OK]を選択して、すべてのウィンドウを閉じます。</block>
  <block id="076e00306637258d0363c74566eb915d" category="paragraph"><block ref="076e00306637258d0363c74566eb915d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd432f2fc3bb1fab0023bf42f7b4108" category="list-text">SVMの2つ目のiSCSI IPについて手順12を繰り返します。</block>
  <block id="5648333e8838336553b385e488639863" category="list-text">[* Targets *（ターゲット*）]タブを選択し、[* Connect *（接続*）]を選択して、[* Enable muti-path *（マルチパスを有効にする*）</block>
  <block id="4bff8ed7bd736139029b8aa4f639ccd9" category="paragraph"><block ref="4bff8ed7bd736139029b8aa4f639ccd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f94de8933712f5d52ca62caf7fef6eb5" category="list-text">パフォーマンスを最大限に高めるには、セッションをさらに追加します。5つのiSCSIセッションを作成することを推奨します。*プロパティ*&gt;*セッションの追加*&gt;*詳細設定*を選択し、ステップ12を繰り返します。</block>
  <block id="5636fa6e8685f1da20bf9489bcadc782" category="paragraph"><block ref="5636fa6e8685f1da20bf9489bcadc782" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c762aaec425b12667f2a575012e48905" category="list-text">パフォーマンスを最適化するために、ターゲットインターフェイスごとに5つのiSCSIセッションを設定します。</block>
  <block id="72a53f90bcbaa031cad1c79575c53094" category="list-text">全体的なiSCSIパフォーマンスが最大になるようにラウンドロビンポリシーを設定します。</block>
  <block id="168b03d713c83578e3c90be8e0a76a8e" category="list-text">LUNをフォーマットするときは、パーティションの割り当て単位のサイズが64Kに設定されていることを確認します</block>
  <block id="a196b0bfd5261a81ff3d40a2043f792c" category="list-text">次のPowerShellコマンドを実行して、iSCSIセッションが保持されていることを確認します。</block>
  <block id="58fbf35d4173787943d2fe31aed43341" category="paragraph"><block ref="58fbf35d4173787943d2fe31aed43341" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22ae84abced8e9e1236160d982616772" category="list-text">次のPowerShellコマンドを使用してディスクを初期化します。</block>
  <block id="ac47df449db0c31d1ba6117a1dd19765" category="paragraph"><block ref="ac47df449db0c31d1ba6117a1dd19765" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b1e9edc2d6e907049df14a10a6fcc404" category="list-text">PowerShellを使用して、Create PartitionコマンドとFormat Diskコマンドを実行します。</block>
  <block id="79484e9f2e5f0589c78f273edd80759f" category="paragraph">付録BのPowerShellスクリプトを使用すると、ボリュームおよびLUNの作成を自動化できますLUNは、SnapCenter を使用して作成することもできます。</block>
  <block id="d05ae24753b4098046ae8369c5618b97" category="paragraph">ボリュームとLUNを定義したら、SnapCenter を設定してデータベース処理を実行できるようにする必要があります。</block>
  <block id="6309043436d4e7e5bad9a81c89ff15e4" category="example-title">SnapCenter の概要</block>
  <block id="419a08c6fdce80a29b8f8aeb7524f0e2" category="paragraph">NetApp SnapCenter は、ティア1エンタープライズアプリケーション向けの次世代データ保護ソフトウェアです。SnapCenter は、一元管理インターフェイスを備えているため、複数のデータベースやその他のアプリケーションワークロードのバックアップ、リカバリ、クローニングに関連する、複雑で時間のかかる手動プロセスを自動化して簡易化できます。SnapCenter は、ネットアップのSnapshot、NetApp SnapMirror、SnapRestore 、NetApp FlexCloneなどのネットアップテクノロジを活用しています。この統合により、IT部門は、ストレージインフラを拡張し、厳しいSLAコミットメントを満たし、企業全体の管理者の生産性を向上させることができます。</block>
  <block id="aa7c84b8a1ac7c27cbd3e14740e96214" category="example-title">SnapCenter サーバの要件</block>
  <block id="4ee08603c9fd8ece4f670310954cdde6" category="paragraph">次の表に、Microsoft Windows ServerにSnapCenter Serverとプラグインをインストールするための最小要件を示します。</block>
  <block id="05bbb43b3d923283e0b6ffafd088f41f" category="cell">コンポーネント</block>
  <block id="9b97b7bd5e0a87be7bf218224ada83cf" category="cell">要件</block>
  <block id="44e5a606cb3fbfaed79ce8eb853ed886" category="paragraph">最小 CPU 数</block>
  <block id="ea54f01387bc5362f6e287ba66d656a8" category="paragraph">4つのコア/ vCPU</block>
  <block id="99880291d6a6b72b928a1847a6135c88" category="paragraph">最小構成：8GB推奨：32GB</block>
  <block id="96e1506a8b72a455b990ffe403eea2cf" category="paragraph">ストレージスペース</block>
  <block id="39b4c2fc16a74430850f1b767f816bdd" category="paragraph">インストール用の最小スペース：リポジトリ用に10GB以上のスペース：10GB</block>
  <block id="2e71b3fb71d89f18906d4807a6011e20" category="cell">サポートされているオペレーティングシステム</block>
  <block id="00aae0645113cb861020a7a42ded48c2" category="list-text">Windows Server 2012</block>
  <block id="96bc7f42979153694e05a6a2b867772e" category="list-text">Windows Server 2012 R2</block>
  <block id="ed590cb2453f0683b64cb528f78610a2" category="list-text">Windows Server 2016</block>
  <block id="7c01fa88a74580e7e4f62ca6bfe7ee83" category="cell">ソフトウェアパッケージ</block>
  <block id="aab81d3c2e898a19cf0f270cdb285a21" category="list-text">.NET 4.5.2以降</block>
  <block id="43de0ba571a51d1adc60e6d05ecf8d70" category="list-text">Windows Management Framework （ WMF ） 4.0 以降</block>
  <block id="fd6133b32592ca288e63c1b1257f656d" category="list-text">PowerShell 4.0 以降</block>
  <block id="427d30c4045ae36c0130a14658100185" category="paragraph">詳細については、「スペースとサイジングの要件」を参照してください <block ref="bcc48263fbca83f546b0bc02edad3f56" category="inline-link-rx"></block></block>
  <block id="a19fb58a9ea7e8409b13e971960fdbf8" category="paragraph">バージョンの互換性については、を参照してください<block ref="b7322bec4509d45107de6de43ca1f517" category="inline-link-rx"></block>。</block>
  <block id="00324c8ea6b2abc68414748e587e15ec" category="example-title">データベースストレージレイアウト</block>
  <block id="a02dce187534c84aa16d8849406a60eb" category="paragraph">次の図に、SnapCenter でバックアップする場合のMicrosoft SQL Serverデータベースストレージレイアウトの作成に関する考慮事項を示します。</block>
  <block id="4c246b141980a6574bc7f111fe7abef7" category="paragraph"><block ref="4c246b141980a6574bc7f111fe7abef7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ebfae4b9e090c4988616a73ffc71415e" category="list-text">I/O負荷の高いクエリやサイズの大きいデータベース（500GBなど）を別のボリュームに配置すると、リカバリ時間が短縮されます。このボリュームは、別のジョブでバックアップすることも必要です。</block>
  <block id="4916b57b0128fd5a0a4300f0a8763292" category="list-text">重要度が低い、またはI/O要件が低い中小規模のデータベースを1つのボリュームに統合します。多数のデータベースを同じボリュームにバックアップすると、保持する必要があるSnapshotコピー数が少なくなります。また、Microsoft SQL Serverインスタンスを統合して、同じボリュームを使用して作成するバックアップSnapshotコピーの数を制御することを推奨します。</block>
  <block id="8db6b23eddd61aa572ca93a39703d4a8" category="list-text">テキスト関連のファイルとファイルストリーミング関連のファイルをすべて格納するために、別 々 のLUNを作成します。</block>
  <block id="cb11fd215e0c541cb65535e582b9b273" category="list-text">Microsoft SQL Serverのログバックアップを保存する場合は、ホストごとに個別のLUNを割り当てます。</block>
  <block id="48b8325fd70d83c2d4e99987e23b07ef" category="list-text">データベースサーバのメタデータ設定とジョブの詳細を格納するシステムデータベースが頻繁に更新されない。システムデータベースやtempdbは、別のドライブまたはLUNに配置してください。システムデータベースをユーザデータベースと同じボリュームに配置しないでください。ユーザデータベースのバックアップポリシーが異なり、システムデータベースのユーザデータベースのバックアップ頻度も同じではありません。</block>
  <block id="1be01a12dc77b3099b16d258c12db3f9" category="list-text">Microsoft SQL Server可用性グループの設定の場合は、レプリカのデータファイルとログファイルをすべてのノードの同一フォルダ構造に配置します。</block>
  <block id="a586cfc38b79b6539a9723b4d2f5af66" category="paragraph">ユーザデータベースレイアウトを別 々 のボリュームに分離することでパフォーマンスが向上するだけでなく、バックアップとリストアに要する時間にも大きく影響します。データファイルとログファイルに別 々 のボリュームを配置すると、複数のユーザデータファイルをホストするボリュームに比べて、リストア時間が大幅に短縮されます。同様に、I/O負荷の高いアプリケーションを使用するユーザデータベースは、バックアップ時間が長くなる傾向があります。バックアップとリストアの方法については、本ドキュメントで後述します。</block>
  <block id="7f3611c256fabe67e4d74a6c70cfe9c5" category="admonition">SQL Server 2012（11.x）以降、システムデータベース（マスター、モデル、MSDB、tempdb）、およびDatabase Engineユーザデータベースは、ストレージオプションとしてSMBファイルサーバとともにインストールできます。この環境 は、スタンドアロンのSQL ServerとSQL Serverフェイルオーバークラスタのどちらのインストールでも使用できます。これにより、ボリュームの容量、パフォーマンスの拡張性、データ保護機能など、ONTAP のパフォーマンスとデータ管理機能をすべて備えたFSXを使用できます。これらの機能は、SQL Serverで利用できます。アプリケーションサーバが使用する共有には、継続的可用性が設定されている必要があります。また、ボリュームはNTFSセキュリティ形式で作成する必要があります。ONTAP 用のFSXからSMB共有に配置されたデータベースでは、NetApp SnapCenter を使用できません。</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="admonition">SnapCenter を使用してバックアップを実行しないSQL Serverデータベースについては、データファイルとログファイルを別 々 のドライブに配置することを推奨します。データを同時に更新して要求するアプリケーションでは、ログファイルに書き込み負荷がかかり、（アプリケーションによっては）データファイルの読み取り/書き込み負荷が高くなります。データを取得する場合、ログファイルは必要ありません。そのため、データの要求は、そのドライブに配置されたデータファイルから満たすことができます。</block>
  <block id="41a264a984b034248073a80093913e60" category="admonition">新しいデータベースを作成するときは、データとログ用に別 々 のドライブを指定することを推奨します。データベース作成後にファイルを移動するには、データベースをオフラインにする必要があります。Microsoftのその他の推奨事項については、「データファイルとログファイルを別 々 のドライブに配置する」をご覧ください。</block>
  <block id="f4ea2029dd0e694cde33838315883930" category="example-title">SnapCenter のインストールとセットアップ</block>
  <block id="d39d360863f3fda3c5d615dc978e14ae" category="inline-link">SnapCenter サーバをインストールします</block>
  <block id="1155d165aa176b6275b67036497cd8e6" category="inline-link">SnapCenter Plug-in for Microsoft SQL Serverをインストールしています</block>
  <block id="067f687182a68fccec4a3840e67fc889" category="paragraph">に従ってください<block ref="4144149cc24a91f915be2d3b14f23c22" category="inline-link-rx"></block> および<block ref="7e24f6ba39e2c63512c07f20cb1a71c0" category="inline-link-rx"></block> SnapCenter をインストールしてセットアップするには、次の手順</block>
  <block id="3ab2ad2898088a813669db2948590562" category="paragraph">SnapCenter をインストールしたら、次の手順を実行してセットアップします。</block>
  <block id="dd0c654d5a8ede80984b9526335bddc9" category="list-text">クレデンシャルを設定するには、* Settings *&gt;* New *を選択し、クレデンシャル情報を入力します。</block>
  <block id="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="paragraph"><block ref="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c790771cb60de4cb4a7212e8db25bf3c" category="list-text">[ストレージ・システム]&gt;[新規]を選択してストレージ・システムを追加し、にONTAP ストレージ情報に適切なFSXを入力します。</block>
  <block id="28e78cc4b0ec3be7790fc763323de0f6" category="paragraph"><block ref="28e78cc4b0ec3be7790fc763323de0f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0e0b904d3c7826b806c48118543142c" category="list-text">[*Hosts*&gt;*Add*]を選択してホストを追加し、ホスト情報を入力します。SnapCenter によって、WindowsおよびSQL Serverプラグインが自動的にインストールされます。この処理には時間がかかることがあります。</block>
  <block id="0f2c351522362209f5160c4794708c97" category="paragraph"><block ref="0f2c351522362209f5160c4794708c97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23dd2805cf2d7b26334d0678ab4e99b4" category="paragraph">すべてのプラグインをインストールしたら、ログディレクトリを設定する必要があります。トランザクションログバックアップが格納された場所を指定します。ホストを選択してログディレクトリを設定し、[ログディレクトリを設定]を選択します。</block>
  <block id="5c5fb88ff793d01c8b1a283f1ee88749" category="admonition">SnapCenter は、ホストログディレクトリを使用してトランザクションログバックアップデータを格納します。これはホストおよびインスタンスレベルです。SnapCenter で使用する各SQL Serverホストには、ログバックアップを実行するように設定されたホストログディレクトリが必要です。SnapCenter にはデータベースリポジトリがあるため、バックアップ、リストア、クローニングの処理に関連するメタデータは中央のデータベースリポジトリに格納されます。</block>
  <block id="0fc057cb39ba1a444dbc365c0161d31f" category="paragraph">ホストログディレクトリのサイズは、次のように計算します。</block>
  <block id="e067558831f8381f0970051292e0a02a" category="paragraph">ホストログディレクトリのサイズ=（システムデータベースサイズ+（最大DB LDFサイズ×日次ログ変更率%））×（Snapshotコピー保持率）÷（1–LUNオーバーヘッドスペース%）</block>
  <block id="1b5bc043867e6da78577571c1070e56a" category="paragraph">ホストログディレクトリのサイジングの計算式では、次のことを前提としています。</block>
  <block id="fa7afec3a90f55ad9aea3b76f336302f" category="list-text">tempdbデータベースを含まないシステムデータベースバックアップ</block>
  <block id="f550013c290c4a21af7974f7440d758a" category="list-text">10%のLUNオーバーヘッド・スペースホスト・ログ・ディレクトリを専用のボリュームまたはLUNに配置しますホストログディレクトリのデータ量は、バックアップのサイズとバックアップを保持する日数によって異なります。</block>
  <block id="83924e370463c681c401f53e2b4b3f2d" category="paragraph"><block ref="83924e370463c681c401f53e2b4b3f2d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd9dfb7fc6f502e70f86a8c1f2d66aa1" category="paragraph">LUNがすでにプロビジョニングされている場合は、ホストログディレクトリを表すマウントポイントを選択できます。</block>
  <block id="db38f16eb9374dba4590f05c202fa4a5" category="paragraph"><block ref="db38f16eb9374dba4590f05c202fa4a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a708f2af7ec6f7c7ae489cca832c811" category="paragraph">これで、SQL Serverのバックアップ、リストア、クローニングの処理を実行する準備ができました。</block>
  <block id="7bfeafaf85908b711b618c069c66e99c" category="example-title">SnapCenter を使用してデータベースをバックアップする</block>
  <block id="fc197cb26aec21d091eb6791c0d7cbff" category="paragraph">データベースとログファイルをFSX ONTAP LUNに配置したら、SnapCenter を使用してデータベースをバックアップできます。フルバックアップを作成するには、次のプロセスを使用します。</block>
  <block id="f52f437d3282493fd1855bba366c482a" category="list-text">SnapCenter では、バックアップをスケジュールする頻度など、RPOをバックアップ頻度として指定し、データ損失を最大数分まで削減できます。SnapCenter では、バックアップを5分ごとの頻度で実行するようにスケジュールを設定できます。ただし、場合によっては、ピークトランザクション時間内や、データ変更率が所定の時間内に高くない時間帯に、バックアップが5分以内に完了しないことがあります。フルバックアップではなくトランザクションログを頻繁にバックアップするようにスケジュールを設定することを推奨します。</block>
  <block id="7b99ea666dfc26516833c088400741e6" category="list-text">RPOとRTOには、数多くのアプローチがあります。このバックアップ方法に代わるもう1つの方法は、間隔の異なるデータとログのバックアップポリシーを用意することです。たとえば、SnapCenter では、ログバックアップを15分間隔で、データバックアップを6時間間隔で実行するようにスケジュールします。</block>
  <block id="14b0febccc904523871b9498c72ab705" category="list-text">Snapshotを最適化するためのバックアップ設定および管理するジョブの数には、リソースグループを使用します。</block>
  <block id="45be64dc5372d4c03684e301633c794c" category="list-text">[*リソース]を選択し、左上のドロップダウン・メニューから[Microsoft SQL Server]を選択します。[*リソースを更新*]を選択します。</block>
  <block id="94cc612f3fcbd977b78ea3b7a422c531" category="paragraph"><block ref="94cc612f3fcbd977b78ea3b7a422c531" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b8d60492f611ef339bf79fdbeb56dda" category="list-text">バックアップするデータベースを選択し、* Next *および（*+*）を選択して、ポリシーが作成されていない場合にポリシーを追加します。新しいポリシーを作成するには、「*新しいSQL Serverバックアップポリシー」に従います。</block>
  <block id="d99e4391045a563d9d1d2d78ddd2417a" category="paragraph"><block ref="d99e4391045a563d9d1d2d78ddd2417a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89f2e11b6c9317605c01622834d4853d" category="list-text">必要に応じて、検証サーバを選択します。このサーバは、フルバックアップの作成後にSnapCenter でDBCC CHECKDBを実行するサーバです。[次へ*]をクリックして通知を確認し、[*概要*]を選択します。確認したら、[完了]をクリックします。</block>
  <block id="fc2d6f88564b6e12fc40b19f28b7420d" category="paragraph"><block ref="fc2d6f88564b6e12fc40b19f28b7420d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="919295932fd1084fb39c4a1be23b37ed" category="list-text">[今すぐバックアップする]をクリックして、バックアップをテストします。ポップアップ・ウィンドウで、*バックアップ*を選択します。</block>
  <block id="93598d1ad688123817fda7d22fa0ac82" category="paragraph"><block ref="93598d1ad688123817fda7d22fa0ac82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c738a74e68034a98f4a38a1b41ef2d4" category="list-text">バックアップが完了したことを確認するには、* Monitor *を選択します。</block>
  <block id="710fa04917c218b834664e1f0d37a48c" category="paragraph"><block ref="710fa04917c218b834664e1f0d37a48c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67459542a38abe56e00d4512bb475f05" category="list-text">リストア・プロセス中にSnapCenter がすべてのバックアップ・ファイルを読み取って自動的に順序どおりにリストアできるように、SnapCenter からトランザクション・ログ・バックアップをバックアップします。</block>
  <block id="54d8d459dfb725a307f3bb54495de3e3" category="list-text">サードパーティ製品をバックアップに使用する場合は、ログシーケンスの問題を回避するためにSnapCenter でバックアップをコピーを選択し、本番環境にロールアップする前にリストア機能をテストします。</block>
  <block id="83b7215bcd7cc73d11f34b95b4026718" category="example-title">SnapCenter を使用してデータベースをリストアします</block>
  <block id="7172cc34c1510c3891870c7c009c94e1" category="paragraph">FSX ONTAP をEC2上のSQL Serverとともに使用する主な利点の1つは'各データベース・レベルで迅速かつ詳細なリストアを実行できることです</block>
  <block id="5afcacb3783eeead2b5317d1c455b3bc" category="paragraph">個 々 のデータベースを特定の時点またはSnapCenter で最新の状態にリストアするには、次の手順を実行します。</block>
  <block id="a028f8b44f91b1338df98ed3237d093a" category="list-text">Resources（リソース）を選択し、リストアするデータベースを選択します。</block>
  <block id="b5f8165159678d41fab115d5a8f013d2" category="paragraph"><block ref="b5f8165159678d41fab115d5a8f013d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb395b310e199ca7ef6b36360302bc50" category="list-text">データベースのリストアに使用するバックアップ名を選択し、リストアを選択します。</block>
  <block id="e99d25ac3998e8701f51a1990c8d8785" category="list-text">「* Restore *」ポップアップ・ウィンドウに従って、データベースを復元します。</block>
  <block id="8bdb6d6fe719d2506b9b5f86bda88b43" category="list-text">「* Monitor *」を選択して、リストア・プロセスが正常に完了したことを確認します。</block>
  <block id="e445e84ca78cd7f21cdd70356d211583" category="paragraph"><block ref="e445e84ca78cd7f21cdd70356d211583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459c0a4ca065bbbedc6304d4c6903cc5" category="example-title">小規模から大規模までのデータベースが多数あるインスタンスの場合の考慮事項</block>
  <block id="0be8a2d7e2996a1641824fa4250d2fd3" category="paragraph">SnapCenter では、リソースグループ内のインスタンスまたはインスタンスのグループに含まれる、サイズの大きなデータベースをバックアップできます。データベースのサイズは、バックアップ時間の主要な要因ではありません。バックアップの所要時間は、ボリュームあたりのLUN数、Microsoft SQL Serverの負荷、インスタンスあたりのデータベースの総数、および具体的にはI/O帯域幅と使用量によって異なります。インスタンスまたはリソースグループからデータベースをバックアップするようにポリシーを設定する際には、Snapshotコピーごとにバックアップするデータベースの最大数をホストあたり100に制限することを推奨します。Snapshotコピーの総数が、1、023個のコピー制限を超えないようにしてください。</block>
  <block id="33f3c567c61942e461392756abce64dc" category="paragraph">また、各データベースまたはインスタンスに対して複数のジョブを作成するのではなく、データベース数をグループ化して、バックアップジョブを並行して実行するように制限することを推奨します。バックアップ期間のパフォーマンスを最適化するには、一度にバックアップできるデータベース数を100個以下にするようにバックアップジョブの数を減らします。</block>
  <block id="ea2e6af969539b040884e9a2ec1fcb49" category="paragraph">前述したように、バックアッププロセスではI/O使用率が重要な要素です。データベースのI/O処理がすべて完了するまで、バックアッププロセスを休止する必要があります。大量のI/O処理が発生しているデータベースは、別のバックアップ時間に保留するか、バックアップ対象の同じリソースグループ内の他のリソースへの影響を避けるために、他のバックアップジョブから分離する必要があります。</block>
  <block id="e5ad8f936997e1328b1b169bf5c6cc8b" category="paragraph">インスタンスあたり200のデータベースをホストするMicrosoft SQL Serverホストが6つある環境では、ホストごとに4つのLUNとボリュームごとに1つのLUNが作成されていると仮定した場合、Snapshotコピーごとにバックアップできるデータベースの最大数を100に設定したフルバックアップポリシーを設定します。各インスタンスに200個のデータベースがあると、200個のデータファイルが2つのLUNに均等に分散され、200個のログファイルがボリュームあたり100個のLUNに均等に分散されます。</block>
  <block id="7804dbf4b7a37ec699db9a31f21bbea7" category="paragraph">3つのリソースグループを作成して3つのバックアップジョブをスケジュールします。各グループには合計400個のデータベースが含まれます。</block>
  <block id="e2ba702320599667af2b18f0fad307e0" category="paragraph">3つのバックアップジョブをすべて同時に実行すると、1、200個のデータベースがバックアップされます。サーバの負荷とI/O使用状況によっては、各インスタンスの開始時間と終了時間が異なる場合があります。この場合、合計24個のSnapshotコピーが作成されます。</block>
  <block id="2d0d5c636161f9ca31c8ffbfa5ee5d7c" category="paragraph">ネットアップでは、フルバックアップに加えて、重要なデータベースに対してトランザクションログバックアップを設定することを推奨しています。データベースプロパティが完全復旧モデルに設定されていることを確認します。</block>
  <block id="aac1148375449745ddbbe1709a2375f5" category="list-text">tempdbデータベースは一時的なデータを含んでいるため、バックアップには含めないでください。tempdbは、Snapshotコピーを作成しないストレージシステムボリュームにあるLUNまたはSMB共有に配置します。</block>
  <block id="16c5de1581b82a1f8657a3a98ac8fd34" category="list-text">I/O負荷の高いアプリケーションを使用するMicrosoft SQL Serverインスタンスは、別のバックアップジョブに分離して、他のリソースの全体的なバックアップ時間を短縮する必要があります。</block>
  <block id="a9a558ac49f24a2b078812205f07179c" category="list-text">同時にバックアップするデータベースセットは、最大で約100個に制限し、残りのデータベースバックアップセットはずらして配置することで、同時にバックアップ処理が行われないようにします。</block>
  <block id="68086c26b8c1644dfe6ea7d6fb859641" category="list-text">Microsoft SQL Serverインスタンスで新規データベースが作成されるたびに、SnapCenter は自動的に新規データベースをバックアップ対象と見なします。そのため、リソースグループでは、複数のデータベースではなくMicrosoft SQL Serverインスタンス名を使用します。</block>
  <block id="5e5d80c17369e70061349fffb43b0aa8" category="list-text">データベースリカバリモデルをフルリカバリモデルに変更するなど、データベース設定を変更した場合は、すぐにバックアップを実行して最新の状態へのリストア処理を実行してください。</block>
  <block id="3dce7613a0d76dcf6fcb8e1daf396bbb" category="list-text">SnapCenter では、SnapCenter の外部で作成されたトランザクションログバックアップをリストアできません。</block>
  <block id="0007de7aba408b88984eb8eb18044303" category="list-text">FlexVol ボリュームをクローニングするときは、クローンメタデータ用の十分なスペースがあることを確認してください。</block>
  <block id="9416a94214ef699335d78087cd9f12c6" category="list-text">データベースをリストアするときは、ボリュームに十分なスペースがあることを確認してください。</block>
  <block id="86e3f69ee9647210c14858984e2649ef" category="list-text">少なくとも週に1回は、システムデータベースの管理とバックアップを行うための個別のポリシーを作成します。</block>
  <block id="330337562cd623f5deb5908d4e8af736" category="example-title">SnapCenter を使用して、データベースをクローニングする</block>
  <block id="0a6bfc2082e52dc96430a6b7c0dfc7e7" category="paragraph">開発/テスト環境の別の場所にデータベースをリストアしたり、ビジネス分析目的でコピーを作成したりする場合、ネットアップのベストプラクティスは、クローニング方法論を利用して同じインスタンスまたは代替インスタンス上にデータベースのコピーを作成することです。</block>
  <block id="0f462cc9e20017ed0597a6a199f57035" category="paragraph">FSX for ONTAP 環境でホストされているiSCSIディスクで500GBのデータベースのクローニングには、通常5分未満で完了します。クローニングが完了したら、クローニングしたデータベースに対して必要なすべての読み取り/書き込み処理を実行できます。ほとんどの時間はディスクスキャン（diskpart）に費やされています。ネットアップのクローニング手順 は、データベースのサイズに関係なく、通常は2分未満で完了します。</block>
  <block id="886ef20e3049a00bc0d9a1c734bb90da" category="paragraph">データベースのクローニングは、デュアル方式で実行できます。最新のバックアップからクローンを作成することも、セカンダリインスタンスで最新のコピーを利用できるクローンライフサイクル管理を使用することもできます。</block>
  <block id="870999fc556eadefd7740857b96209c3" category="paragraph">SnapCenter を使用すると、必要なディスクにクローンコピーをマウントして、セカンダリインスタンスのフォルダ構造の形式を維持し、引き続きバックアップジョブのスケジュールを設定できます。</block>
  <block id="b2face8e1d4561b0ed5b594bfc4c0063" category="example-title">同じインスタンス内の新しいデータベース名でデータベースをクローニングします</block>
  <block id="4a3135e25926365f40a59fd88af69a44" category="paragraph">EC2で実行されている同じSQL Serverインスタンス内の新しいデータベース名にデータベースをクローニングするには、次の手順を実行します。</block>
  <block id="4655b3c9fecfc4d22a59068929be2bec" category="list-text">[リソース]を選択し、次にクローンを作成する必要があるデータベースを選択します。</block>
  <block id="944b75c61851b0ebc427a8aedc83d6f3" category="list-text">クローンを作成するバックアップ名を選択し、Cloneを選択します。</block>
  <block id="83d2194c2b06657769054af057f16b0a" category="list-text">バックアップ・ウィンドウに表示されるクローンの手順に従って、クローン・プロセスを完了します。</block>
  <block id="8fb624c33e03c9d016909a11c669125d" category="list-text">Monitorを選択して、クローニングが完了したことを確認します。</block>
  <block id="0b075fd84c4c4a47346b99d43f9260be" category="example-title">EC2で実行されている新しいSQL Serverインスタンスにデータベースをクローニングします</block>
  <block id="9451e65c3b1fc3fc6cf89a3fc9cf3cfd" category="paragraph">EC2で実行する新しいSQL Serverインスタンスにデータベースをクローニングするには、次の手順を実行します。</block>
  <block id="479cb4cd4ee76801e360aa03ddc20a3a" category="list-text">同じVPC内のEC2に新しいSQL Serverを作成します。</block>
  <block id="163733cab5060ba4621bb642ba3870a0" category="list-text">「SQL Server用のボリュームとLUNの作成」セクションの手順3および4に従って、iSCSIプロトコルとMPIOを有効にし、ONTAP 用FSXへのiSCSI接続をセットアップします。</block>
  <block id="918269b8806c56ca4a0910482994e142" category="list-text">「SnapCenter のインストールとセットアップ」セクションの手順3に従って、EC2上の新しいSQL ServerをSnapCenter に追加します。</block>
  <block id="e7130318e065eddd45ec86565b727731" category="list-text">リソース／インスタンスを表示を選択し、リソースを更新を選択します。</block>
  <block id="8be42b1e845c00bcb04c11269072f895" category="list-text">[リソース]を選択し、次にクローンを作成するデータベースを選択します。</block>
  <block id="459801927d3c0bd5ddec9c1513f213ec" category="list-text">クローンを作成するバックアップ名を選択し、Cloneを選択します。</block>
  <block id="030603235fe06c85ee75276379fe5baa" category="paragraph"><block ref="030603235fe06c85ee75276379fe5baa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d50db35e68c1259b414779e24fdbf5" category="list-text">バックアップからのクローン作成の手順に従い、EC2に新しいSQL Serverインスタンスを指定し、インスタンス名を指定してクローンプロセスを終了します。</block>
  <block id="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="paragraph"><block ref="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20606e28a0d567be1dabd5cf50a2dc3b" category="section-title">付録</block>
  <block id="16dfbb688028526582ec31ab802b9589" category="example-title">付録A：クラウド形成テンプレートで使用するYAMLファイル</block>
  <block id="4c76ae47de51751cc57a4033d14f2f2a" category="paragraph">AWSコンソールのクラウド形成テンプレートでは、次の.yamlファイルを使用できます。</block>
  <block id="76f249edcff2b74fcc17020455372f1b" category="inline-link"><block ref="76f249edcff2b74fcc17020455372f1b" category="inline-link-rx"></block></block>
  <block id="57ea11aec1064892e5db378204f829c4" category="list-text"><block ref="57ea11aec1064892e5db378204f829c4" category="inline-link-rx"></block></block>
  <block id="f6d8279768d195862ae69a3df8dd51ab" category="inline-link">このGitHubリンク</block>
  <block id="4d39c6875a330594fc8521c48cadd7f6" category="paragraph">PowerShellを使用してiSCSI LUNの作成やNetApp SnapCenter のインストールを自動化するには、からリポジトリをクローニングします<block ref="445e758235a70998ddfcd1531f3ae35b" category="inline-link-rx"></block>。</block>
  <block id="00867e5f5ae22280c11a2626b65e657b" category="example-title">付録B：ボリュームおよびLUNをプロビジョニングするためのPowerShellスクリプト</block>
  <block id="0826ee2b94a579e02e80bfcdf26c5648" category="paragraph">次のスクリプトを使用して、ボリュームとLUNをプロビジョニングし、上記の手順に基づいてiSCSIをセットアップします。PowerShellスクリプトには次の2つがあります。</block>
  <block id="81e24f41fbaff249c9819985065173e3" category="list-text"><block ref="2a9a99327bbfb47d37ee76307e959506" prefix="" category="inline-code"></block></block>
  <block id="2ca8201f2a50e4aec0e5ba21f6afed4d" category="list-text"><block ref="d78c8f4fe63dbe3ffd666bbbaf054cd7" prefix="" category="inline-code"></block></block>
  <block id="6385631c0b330c166b540183cec5af78" category="paragraph">ファイルを実行します<block ref="d2dd03515102971189549a37cb42eb14" prefix=" " category="inline-code"></block> 1番目のスクリプトと2番目のスクリプトは'サーバの再起動後に自動的に実行されますこれらのPowerShellスクリプトは、SVMのクレデンシャルアクセスが原因で実行されたあとで削除できます。</block>
  <block id="d82c21a48349085e4fd93fb6712e3789" category="inline-link"><block ref="d82c21a48349085e4fd93fb6712e3789" category="inline-link-rx"></block></block>
  <block id="c745303ee8000be162517c239783af70" category="paragraph"><block ref="c745303ee8000be162517c239783af70" category="inline-link-rx"></block></block>
  <block id="c6e485d51bc9da63bcac29189dac0f3c" category="list-text">FSX for NetApp ONTAP をご利用ください</block>
  <block id="90572737558e59a2ecdd4618af07d6f3" category="inline-link"><block ref="90572737558e59a2ecdd4618af07d6f3" category="inline-link-rx"></block></block>
  <block id="7545caf3d97477d3c569d56c512074fa" category="paragraph"><block ref="7545caf3d97477d3c569d56c512074fa" category="inline-link-rx"></block></block>
  <block id="ad65cae8cf2bbd15ac77769974a440ce" category="list-text">SnapCenter インターフェイスの概要</block>
  <block id="59cbc11e5ccd87939e1b70af73ec1f01" category="inline-link"><block ref="c0a7623803fcfb4ac66342d4ae76ffff" category="inline-link-rx"></block></block>
  <block id="7ab2e91ecb30982855aa0dde8b78a361" category="paragraph"><block ref="89ba280df4e8c5cfd9bcd0f8c80d8ba5" category="inline-link-rx"></block></block>
  <block id="1bdf7559e69b81c007496a063e71bca0" category="list-text">SnapCenter ナビゲーションペインのオプションを確認します</block>
  <block id="6d5097a2c320359a8d212d07ea067dac" category="inline-link"><block ref="6d5097a2c320359a8d212d07ea067dac" category="inline-link-rx"></block></block>
  <block id="e0ae39eeb7c7d78d56a1292229d1277a" category="paragraph"><block ref="e0ae39eeb7c7d78d56a1292229d1277a" category="inline-link-rx"></block></block>
  <block id="d29a9430434c2654cce06036a4a478b2" category="list-text">SnapCenter 4.0 for SQL Serverプラグインをセットアップします</block>
  <block id="520419781af4d13a8b33c054a304985b" category="inline-link"><block ref="520419781af4d13a8b33c054a304985b" category="inline-link-rx"></block></block>
  <block id="c2580a05e81a19c4b782e51932415e30" category="paragraph"><block ref="c2580a05e81a19c4b782e51932415e30" category="inline-link-rx"></block></block>
  <block id="f781a682aea107fb2cdda3a0c1fd3ac5" category="list-text">SnapCenter とSQL Serverプラグインを使用したデータベースのバックアップおよびリストア方法</block>
  <block id="285a27614fdeee7f22969646d33edc95" category="inline-link"><block ref="285a27614fdeee7f22969646d33edc95" category="inline-link-rx"></block></block>
  <block id="e1685ff793f13bbd2956f2156b0d5a67" category="paragraph"><block ref="e1685ff793f13bbd2956f2156b0d5a67" category="inline-link-rx"></block></block>
  <block id="c8e300ff66d94fe7668ff8d5d5e7f1c3" category="list-text">SnapCenter とSQL Serverプラグインを使用してデータベースをクローニングする方法</block>
  <block id="e482c7b116916a3d87aba2ab1365190b" category="inline-link"><block ref="e482c7b116916a3d87aba2ab1365190b" category="inline-link-rx"></block></block>
  <block id="b916fd292760d6ae01e337bf2a132edb" category="paragraph"><block ref="b916fd292760d6ae01e337bf2a132edb" category="inline-link-rx"></block></block>
  <block id="5d0dd45a93153403c2446a809dcb5fc3" category="sidebar">AWS EC2上のSQL ServerでAmazon FSX for NetApp ONTAP を使用</block>
  <block id="dc406f8350f51d99347d8d026c0435a5" category="list-text">つまり、回転式ディスクからオールフラッシュに移行することでパフォーマンスが向上します。コンピューティングノードの数がボトルネックになっていません。ネットアップのオールフラッシュストレージなら、ランタイムのパフォーマンスを大幅に向上できます。</block>
  <block id="67c8804409fa1f91b1b477b7c99d1d71" category="paragraph">執筆者：Chris Reno、Josh Powell、Suresh Thoppay - NetApp Solutions Engineering</block>
  <block id="37242160d8bbd9ad700322c3c2499272" category="section-title">前提条件、前提条件、コンポーネントの概要</block>
  <block id="3ea8c755cca91dd6bbeec88e906263e9" category="paragraph">この解決策 を導入する前に、コンポーネントの概要、解決策 を導入するための前提条件、およびこの解決策 のドキュメント化に記載した前提条件を確認してください。</block>
  <block id="7bcf43f481a8076036689561dce0e62d" category="inline-link-macro">DR解決策 の要件、事前要件、計画</block>
  <block id="684b2b80ca970225e77585d96775fc95" category="section-title">SnapCenter を使用してDRを実行する</block>
  <block id="782f10deb2809cc33e0082dbe9371f9b" category="paragraph">コンソールにログインしたら、バックアップSQL ServerおよびOracleデータベース用にSnapCenter を設定する必要があります。</block>
  <block id="cf5c2d1e726e35ab57a75901cde43919" category="example-title">セカンダリVeeam Backup &amp; Replicationサーバを導入します</block>
  <block id="2b0e654aa884c8c50887b2eff59bc68f" category="example-title">セカンダリVeeam Backup &amp; Replicationサーバを設定します</block>
  <block id="ed8b9b5c064b716d4c1d3f30a595410f" category="example-title">Veeamのバックアップとレプリケーション</block>
  <block id="42c8c901c8d4c00c90f9f66d69df3cdb" category="example-title">Veeam Backup &amp; Replicationサーバが必要です</block>
  <block id="17f0b02d31e76cb9b2878b4a08f19eb5" category="example-title">Veeam Backup &amp; Replicationの構成</block>
  <block id="53f8aa6361303e58854a4451a706df5e" category="doc">WP-7355：『SnapCenter Plug-in VMware vSphere - Product security』</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">NetApp SnapCenter Plug-in for VMware vSphereのソフトウェアエンジニアリングでは、次のような安全な開発作業を行います。</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">*動的アプリケーションセキュリティテスト(DAST)。*実行中のアプリケーションの脆弱な状態を検出するように設計されたテクノロジ。DAST は、 Web 対応アプリケーションの公開 HTTP および HTML インターフェイスをテストします。</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">*サードパーティのコード通貨。*ソフトウェアの開発およびオープンソースソフトウェア（OSS）の使用の一環として、製品に組み込まれているOSSに関連するセキュリティの脆弱性に対処することが重要です。これは、OSSコンポーネントのバージョンに、いつでも新たに検出された脆弱性が報告される可能性があるため、継続的な取り組みです。</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">*ペネトレーションテスト。*ペネトレーションテストは、システム、Webアプリケーション、またはネットワークを評価して、攻撃者によって悪用される可能性のあるセキュリティの脆弱性を検出するプロセスです。ネットアップでのペネトレーションテスト（ペンテスト）は、承認された信頼できる第三者企業のグループが実施します。このテスト範囲には、高度な攻撃方法やツールを使用した悪意のある侵入者やハッカーなどのアプリケーションやソフトウェアに対する攻撃の開始が含まれます。</block>
  <block id="e3a3be4b4b04c5e0b6a5f1b5ea388380" category="list-text">*製品セキュリティインシデント対応活動。*セキュリティの脆弱性は、社内外で発見され、タイムリーに対処しないと、ネットアップの評判に深刻なリスクをもたらす可能性があります。このプロセスを容易にするために、Product Security Incident Response Team（PSIRT）は脆弱性を報告して追跡します。</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">NetApp SnapCenter Plug-in for VMware vSphereの各リリースには、次のセキュリティ機能が含まれています。</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">*制限付きシェルアクセス。* SSHはデフォルトで無効になっており、1回限りのログインはVMコンソールから有効にした場合にのみ許可されます。</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">*ログインバナーのアクセス警告*ログインプロンプトにユーザ名を入力すると、次のログインバナーが表示されます。</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">ユーザがSSHチャネルを介したログインを完了すると、次の出力が表示されます。</block>
  <block id="83e463bb73b12d9ca6e419327073c8a4" category="list-text">*ロールベースアクセス制御（RBAC）。*ネットアップのONTAP ツールには、次の2種類のRBAC制御が関連付けられています。</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">vCenter Server標準の権限。</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">ロールベースアクセス制御（ RBAC ）</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">VMware vCenterプラグインに固有の権限。詳細については、を参照してください<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>。</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">*暗号化された通信チャネル。*すべての外部通信は、TLSを使用してHTTPS経由で行われます。</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">次の表に、オープンポートの詳細を示します。</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">TCP v4 / V6ポート番号</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080 です</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">OVA GUIでのHTTPS接続</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH（デフォルトでは無効）</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">mysql（内部接続のみ。外部接続はデフォルトで無効）</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">nginx（データ保護サービス）</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">SnapCenter Plug-in for VMware vSphere（SCV）にSSL証明書を作成/インポートする方法</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">*認証局（CA）署名証明書のサポート。* SnapCenter Plug-in for VMware vSphereは、CA署名証明書の機能をサポートしています。を参照してください<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>。</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">*パスワードポリシー。*次のパスワードポリシーが有効です。</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">クレデンシャル情報はすべてSHA256ハッシュを使用して保存されます。</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*基本オペレーティングシステムイメージ。*この製品は、アクセス制限とシェルアクセスが無効になったOVA用のDebianベースOSに同梱されています。これにより、攻撃のフットプリントが削減されます。すべてのSnapCenter リリースベースのオペレーティングシステムには、最大限のセキュリティを適用できる最新のセキュリティパッチが適用されています。</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">ネットアップでは、SnapCenter Plug-in for VMware vSphereアプライアンスに関連するソフトウェア機能およびセキュリティパッチを開発し、その後、バンドルソフトウェアプラットフォームとしてお客様にリリースします。ネットアップでは、これらのアプライアンスにはLinuxのサブシステムに固有の依存関係と独自のソフトウェアが含まれているため、サブオペレーティングシステムを変更しないことを推奨します。これは、ネットアップアプライアンスに影響を及ぼす可能性が高いためです。これは、ネットアップがアプライアンスをサポートできるかどうかに影響します。アプライアンスはセキュリティ関連の問題にパッチを適用するためにリリースされているため、最新のコードバージョンをテストして導入することを推奨します。</block>
  <block id="e50e258ecc9eaa88d6c653c3a24cb319" category="cell">2022 年 3 月</block>
  <block id="3107c066ea7eeb48bd5f87594a08fd7a" category="paragraph">&lt;&lt;&lt;&lt;そこで、NetApp AFF ストレージコントローラと、ストレージポリシーが異なるSSDとSASドライブを搭載したEシリーズストレージコントローラでHadoopストレージの階層化を検証しました。AFF-A800のSparkクラスタには4つのコンピュートワーカーノードがあり、Eシリーズのクラスタには8つのノードがあります。主な用途は、ソリッドステートドライブ（SSD）とハードドライブディスク（HDD）のパフォーマンスを比較することです。</block>
  <block id="dba657bcaa661bcf5461e260c00e4f06" category="paragraph">ネットアップのAFF ストレージコントローラと、ストレージポリシーが異なるSSDおよびSASドライブを搭載したEシリーズストレージコントローラでHadoopストレージの階層化を検証しました。AFF-A800のSparkクラスタには4つのコンピュートワーカーノードがあり、Eシリーズのクラスタには8つのノードがあります。これは主に、ソリッドステートドライブとハードドライブディスクのパフォーマンスを比較するために行いました。&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;a51c9ddf73ca69e1120ce05edc7b0b9607b96eae</block>
  <block id="f14f651fb8150de92c527d88344df494" category="list-text">SSD構成は、TeraSortを使用してNL-SAS構成の1TBのデータを1138.36倍高速にソートしました。さらに、SSD構成では、コンピューティングノードの半分とディスクドライブの半分（合計24本のSSDドライブ）が使用されていました。そのため、ドライブあたりの速度は、NL-SAS構成の約3倍です。&lt; &lt; &lt; &lt; &lt; &lt; &lt; &lt; &lt; &lt; &lt; &lt; &lt; &lt; 頭部</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">ここで重要なのは、回転式ディスクからオールフラッシュに移行することでパフォーマンスを向上させることです。コンピューティングノードの数がボトルネックになっていません。ネットアップのオールフラッシュストレージなら、ランタイムのパフォーマンスを大幅に向上できます。</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">NFSでは、データがすべてプールされる機能と同等で、ワークロードに応じてコンピューティングノードの数を減らすことができました。コンピューティングノードの数を変更した場合、Apache Sparkクラスタユーザは手動でデータをリバランシングする必要がありません。</block>
  <block id="6ed171c4fe1ca516676ea457d91105b1" category="list-text">NFSでは、データがすべてプールされる機能と同等で、ワークロードに応じてコンピューティングノードの数を減らすことができました。コンピューティングノードの数を変更した場合、Apache Sparkクラスタユーザは手動でデータをリバランシングする必要がありません。&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;a51c9ddf73ca69e1120ce05edc7b0b9607b96eae</block>
  <block id="2668a3fec665f31a26e9e428b4ee62a7" category="sidebar">SnapCenter Plug-in VMware vSphere -製品のセキュリティ</block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP は、仮想化に使用されるすべての主要なストレージプロトコルをサポートしています。たとえば、 SAN 環境向けの iSCSI 、 Fibre Channel （ FC ）、 Fibre Channel over Ethernet （ FCoE ）、 Non-Volatile Memory Express over Fibre Channel （ NVMe/FC ）、ゲスト接続用の NFS （ v3 および v4.1 ）、 SMB または S3 などです。お客様は、環境に最適なものを自由に選択でき、必要に応じてプロトコルを 1 つのシステムで組み合わせることができます。</block>
  <block id="d7a198a9254afae95101f5ba8a96e769" category="paragraph">ONTAP は、SAN環境向けのiSCSI、Fibre Channel（FC）、Fibre Channel over Ethernet（FCoE）、Non-Volatile Memory Express over Fibre Channel（NVMe/FC）、ゲスト接続用のNFS（v3およびv4.1）、SMBまたはS3など、仮想化に使用されるすべての主要なストレージプロトコルをサポートしています。お客様は、環境に最適なものを自由に選択でき、必要に応じてプロトコルを 1 つのシステムで組み合わせることができます。たとえば、いくつかのiSCSI LUNやゲスト共有でNFSデータストアの一般的な使用を補うことができます。</block>
  <block id="2df283d70436fd2d0a853af9fae00a91" category="list-text">*ネットアップのSnapshotコピー。* ONTAP は、Snapshotコピーの作成時や使用時にパフォーマンスへの影響を伴わない、VMまたはデータストアの瞬時のSnapshotコピーを提供します。パッチの適用前またはシンプルなデータ保護のために、 VM のリストアポイントを作成する際に使用できます。これらは VMware （整合性）スナップショットとは異なります。ONTAP の Snapshot コピーを作成する最も簡単な方法は、 SnapCenter Plug-in for VMware vSphere を使用して VM とデータストアをバックアップすることです。</block>
  <block id="0fed44d392929d099987f70fe23074b4" category="list-text">* NetApp Volume EncryptionとNetApp Aggregate Encryption *。ネットアップの暗号化オプションは、ソフトウェアベースの簡単な暗号化機能で保存データを保護します。</block>
  <block id="1a4c4db8b74f04b9da9ab150ff36e301" category="list-text">* RESTとAnsible *を使用します<block ref="71191ff17e34498b2463e6167736896a" category="inline-link-rx"></block> ストレージとデータの管理を自動化するには、を参照してください<block ref="d4fc0de110866702e0b8608590b39b64" category="inline-link-rx"></block> ONTAP システムの構成管理に使用します。</block>
  <block id="86544be11c52b782f03ad1ff879f872d" category="paragraph">一部のONTAP 機能は、vSphereのワークロードには適していません。たとえば、ONTAP 9.8より前のFlexGroup テクノロジでは完全なクローニングはサポートされておらず、vSphereではテストされていません（vSphereでの使用に関する最新情報については、「FlexGroup 」の項を参照してください）。FlexCache テクノロジは、読み取り主体のワークロード向けに設計されたものであるため、vSphereにも最適ではありません。キャッシュが元のボリュームから切断されていると、両方の側で NFS データストアエラーが発生する場合があります。</block>
  <block id="f364e3337f5237c93d7b5439c82d444b" category="paragraph">VMware vSphere 用の ONTAP ツールは、 vSphere とともに ONTAP ストレージを使用するための一連のツールです。vCenter プラグインは、以前 Virtual Storage Console （ VSC ）と呼ばれていたもので、 SAN と NAS のどちらを使用している場合でも、ストレージ管理と効率化機能の簡易化、可用性の向上、ストレージコストと運用オーバーヘッドの削減を実現します。データストアのプロビジョニングのベストプラクティスを使用して、 NFS 環境およびブロックストレージ環境用の ESXi ホスト設定を最適化します。以上のメリットのために、ネットアップでは、 ONTAP ソフトウェアを実行しているシステムで vSphere を使用する際のベストプラクティスとして、これらの ONTAP ツールを使用することを推奨します。サーバアプライアンス、vCenter、VASA Provider、Storage Replication Adapterのユーザインターフェイス拡張機能が含まれています。ONTAP ツールのほぼすべてを、最新の自動化ツールで利用できるシンプルなREST APIを使用して自動化できます。</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">* vCenter UIの拡張機能* ONTAP ツールのUI拡張機能は、vCenter UIにホストとストレージを管理するための使いやすいコンテキスト依存メニュー、情報ポートレット、およびネイティブアラート機能を直接組み込み、ワークフローを合理化することで、運用チームやvCenter管理者の業務を簡素化します。</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">* VASA Provider for ONTAP 。* VASA Provider for ONTAP は、VMware vStorage APIs for Storage Awareness（VASA）フレームワークをサポートしています。VMware vSphere 用の ONTAP ツールの一部として提供され、導入を容易にする単一の仮想アプライアンスとして提供されます。VASA Provider では、 VM ストレージのプロビジョニングと監視に役立つように vCenter Server と ONTAP を接続します。VMware Virtual Volumes （ VVol ）のサポート、ストレージ機能プロファイルと個々の VM VVol のパフォーマンスの管理、およびプロファイルの容量と準拠状況の監視用アラームが可能になります。</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">* Storage Replication Adapter. SRAは、VMware Site Recovery Manager（SRM）と併用して、本番サイトと災害復旧サイト間のデータ複製を管理し、DRレプリカを無停止でテストします。検出、リカバリ、再保護のタスクを自動化します。Windows SRM サーバおよび SRM アプライアンス用の SRA サーバアプライアンスと SRA アダプタの両方が含まれています。</block>
  <block id="eff6699ec911b615a51eb7e9e0d89970" category="paragraph">NetApp NFS Plug-in for VMware VAAIはESXiホスト向けのプラグインで、ONTAP 上のNFSデータストアでVAAI機能を使用できます。クローン処理、シック仮想ディスクファイル用のスペースリザベーション、 Snapshot コピーオフロードをサポートしています。コピー処理をストレージにオフロードしても、完了までの時間が必ずしも短縮されるとは限りませんが、ネットワーク帯域幅の要件が軽減され、CPUサイクル、バッファ、キューなどのホストリソースがオフロードされます。VMware vSphere用のONTAP ツールを使用して、ESXiホストまたはサポートされている場合はvSphere Lifecycle Manager（VLCM）にプラグインをインストールできます。</block>
  <block id="082e2767897584434269db14d4ceda54" category="sidebar">VMware仮想化の新機能</block>
  <block id="839a1261c70db1f3c149f86d56e21d15" category="cell">01/12/2023</block>
  <block id="70542da4927194cf41c777029ebe56be" category="cell">ブログを追加：「Protect Your SQL Server Workloads Using NetApp SnapCenter with Amazon FSX for NetApp ONTAP 」をご覧ください</block>
  <block id="577322186c067590a18f8891be57e7e4" category="inline-link-macro">NetApp SnapCenter とAmazon FSX for NetApp ONTAP を使用して、SQL Serverのワークロードを保護します</block>
  <block id="c1b7f59fc598d7a811682707bcd4eb40" category="list-text"><block ref="c1b7f59fc598d7a811682707bcd4eb40" category="inline-link-macro-rx"></block></block>
  <block id="af8dcb8c7a1e8b7e614e570806d8dcee" category="paragraph">VMware vSphereとONTAP ソフトウェアを実行しているシステム上のデータストアの接続には、次の7つのプロトコルが使用されます。</block>
  <block id="a7c815fafe60ae637d38216fa6300395" category="list-text">FCP</block>
  <block id="8b7c42123642e2e4ea7dd426aeb2de58" category="list-text">NVMe/FC</block>
  <block id="f7d773fd2896401c143676940bc001fc" category="list-text">NFS v3</block>
  <block id="0b99b245267ef194ca3b9f6e694b0983" category="list-text">NFS v4.1</block>
  <block id="cfa070ed8af17c3125cfd1530fbd387a" category="paragraph">FCP、FCoE、NVMe/FC、NVMe/FC、NVMe/FC、NVMe/FC、およびiSCSIはブロックプロトコルで、vSphere Virtual Machine File System（VMFS）を使用して、ONTAP FlexVol ボリュームに含まれるONTAP LUNまたはNVMeネームスペースにVMを格納します。vSphere 7.0 以降では、 VMware は本番環境でのソフトウェア FCoE をサポートしなくなりました。NFS はファイルプロトコルで、 VM をデータストア（ ONTAP ボリューム）に配置し、 VMFS を必要としません。SMB（CIFS）、iSCSI、NVMe/FC、NFSもゲストOSからONTAP に直接使用できます。</block>
  <block id="7469c178e150e10730dcab1094765f10" category="paragraph">以下の表に、 vSphere でサポートされる従来のデータストア機能と ONTAP を示します。この情報はVVOLデータストアには該当しませんが、通常は、サポートされているONTAP リリースを使用する環境 vSphere 6.x以降のリリースで使用されます。を参照することもできます<block ref="26c5407c98ec413c85131fd8c0d178b4" category="inline-link-rx"></block> 個々の vSphere リリースに固有の制限を確認するため。</block>
  <block id="6151632541dcd80356c6c76b34d69d0c" category="cell">NVMe-oF</block>
  <block id="18263a30df8afc60a733e59c60676ac0" category="cell">VMFS</block>
  <block id="aa23f9914ce1939ea7a4d479edfdc915" category="cell">ホストあたり1、024個のLUN</block>
  <block id="1af3b27207afc48a363629a315d76b59" category="cell">サーバあたり1、024個のLUN</block>
  <block id="0705fd627c25b5fba17cd9a022ed7d72" category="cell">サーバごとに256名を指定します</block>
  <block id="b4fb1d41fedaec79072964cbb4d16e3d" category="cell">データストアの最大ファイルサイズ</block>
  <block id="fe299bb060ce245b8fe190de21d3978e" category="cell">16TBまたは62TB（ONTAP 9.12.1RC1以降で大容量ファイルが有効な場合）</block>
  <block id="ca6e77250a239af7b4aed9a1ac058825" category="cell">自動ネゴシエーション</block>
  <block id="bad19bc2587cd465cab5cec5a13aa306" category="cell">のNFS.MaxQueueDepthを参照してください<block ref="0391a4aaf03ed2bf80fb4efb215797d0" category="inline-link-rx"></block>。</block>
  <block id="d6407966cf588d8d78d4f7e65f1ea6fd" category="cell">v3のみ**</block>
  <block id="50ed43e1a7a22335069a344bc706b600" category="cell">はい、新しい高性能プラグイン（HPP）を使用して</block>
  <block id="5663fa28fe2a703e07072185e3a90a94" category="paragraph">* VMFSデータストア内でマルチライター対応のVMDKを使用するのではなく、Microsoftクラスタにゲスト内iSCSIを使用することを推奨します。このアプローチは Microsoft と VMware によって完全にサポートされており、 ONTAP （オンプレミスまたはクラウドの ONTAP システムへの SnapMirror ）を使用した優れた柔軟性、設定と自動化が容易で、 SnapCenter で保護できます。vSphere 7 で、新しいクラスタ化された VMDK オプションが追加されました。これは、マルチライター対応のVMDKとは異なります。マルチライター対応のVMDKを使用するには、クラスタ化されたVMDKをサポートするFCプロトコルを介して提供されるデータストアが必要です。その他の制限が適用されます。「 VMware 」を参照してください<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> 設定ガイドラインについては、ドキュメントを参照してください</block>
  <block id="e2bd40041a6472b580305ce9017b0b2e" category="paragraph">** NVMe-oFとNFS v4.1を使用するデータストアには、vSphereレプリケーションが必要です。アレイベースのレプリケーションはSRMではサポートされていません。</block>
  <block id="b8c499c7b537f5bd4e51b0a6d6a1e9d0" category="list-text">ONTAP NFS データストアを使用して vSphere を導入することで、高性能でありながら管理が容易な実装を実現でき、ブロックベースのストレージプロトコルでは達成できない VM / データストア比率が提供されます。このアーキテクチャでは、データストア密度を 10 倍に増やすことも可能で、それに伴いデータストアの数は減少します。データストアのサイズを大きくするとストレージ効率が向上し、運用上のメリットが得られますが、ハードウェアリソースのパフォーマンスを最大限に引き出すためには、少なくとも 4 つのデータストア（ FlexVol ボリューム）を使用して 1 つの ONTAP コントローラに VM を格納することを検討してください。また、異なるリカバリポリシーを使用してデータストアを確立することもできます。ビジネスニーズに基づいて、他のバックアップや複製の頻度を高められるものもあります。FlexGroup ボリュームは設計上拡張できるため、複数のデータストアを使用する必要はありません。</block>
  <block id="241f8fed1e3a823fcd4d0c1eb705b1a2" category="list-text">FlexVol ボリューム、および ONTAP 9.8 以降の FlexGroup ボリューム、 NFS データストアの使用を推奨します。VMware vSphere 用の ONTAP ツールでは現在サポートされていないため、 qtree などの他の ONTAP ストレージコンテナの使用は一般に推奨されません。データストアレベルのクォータや VM ファイルクローンの恩恵を受ける高度に自動化された環境では、 1 つのボリューム内の複数の qtree としてデータストアを導入すると便利です。</block>
  <block id="964a81e46088ae1cc6306072464a9d73" category="list-text">または、 VMFS データストアを、 FC 、 iSCSI または FCoE でアクセスする LUN で構成することもできます。VMFS を使用すると、クラスタ内の各 ESX サーバから同時に従来型の LUN にアクセスすることができます。VMFS データストアは、最大 64TB まで拡張でき、最大 32 個の 2TB LUN （ VMFS 3 ）または単一の 64TB LUN （ VMFS 5 ）で構成できます。ONTAP の最大LUNサイズは、ほとんどのシステムで16TBで、オールSANアレイシステムでは128TBです。したがって、ほとんどの ONTAP システムでは、最大サイズの VMFS 5 データストアを、 4 つの 16TB LUN を使用して作成できます。複数のLUN（ハイエンドのFAS またはAFF システムを使用）を使用する高I/Oワークロードではパフォーマンス上のメリットを得られますが、データストアLUNの作成、管理、保護の複雑さが増し、可用性のリスクが増大することで、このメリットを相殺することができます。ネットアップでは、通常、各データストアに 1 つの大きな LUN を使用し、 16TB を超えるデータストアを追加する必要がある場合にのみスパンすることを推奨しています。NFS と同様に、複数のデータストア（ボリューム）を使用することで、 1 台の ONTAP コントローラのパフォーマンスを最大化することを検討してください。</block>
  <block id="040ffbbbbeda558bdae1e07f5371b4f5" category="list-text">CiscoのVirtual PortChannel（vPC）などのマルチシャーシリンクアグリゲーショングループアプローチを使用して、2つの別 々 のスイッチシャーシ上のポートのリンクアグリゲーションをサポートするスイッチを使用します。</block>
  <block id="19d137845c7f6687c99b386dfad0aa97" category="list-text">LACPが設定されたdvSwitches 5.1以降を使用していない場合、ESXiに接続されているスイッチポートのLACPを無効にします。</block>
  <block id="30254a2bb3e4b3b958b06d08c724e7db" category="list-text">LACPを使用して、IPハッシュを持つダイナミックマルチモードインターフェイスグループを持つONTAP ストレージシステムのリンクアグリゲートを作成します。</block>
  <block id="d608421cceb8e4c584a2a32d9127879e" category="list-text">ESXiでIPハッシュチーミングポリシーを使用します。</block>
  <block id="ba78d695573c8d4f1205452c675fa539" category="paragraph">* SVM LIFは、VLANやMTUなどが設定されたポート、インターフェイスグループ、またはVLANインターフェイスに接続します。ただし、設定の管理はSVMレベルではありません。</block>
  <block id="631e164314a103fe3183b00b759057b2" category="paragraph">SLM は、特定の LUN へのパスをアドバタイズするノードを制限します。ネットアップのベストプラクティスでは、各 SVM のノードごとに少なくとも 1 つの LIF を配置し、 SLM を使用して、 LUN とその HA パートナーをホストするノードへのアドバタイズパスを制限することを推奨しています。他のパスは存在しますが、デフォルトではアドバタイズされません。SLM 内で、レポートノードの追加引数および削除引数を使用して通知されたパスを変更することができます。8.3 より前のリリースで作成された LUN ではすべてのパスがアドバタイズされるため、ホストしている HA ペアへのパスのみがアドバタイズされるように変更する必要があることに注意してください。SLM の詳細については、のセクション 5.9 を参照してください<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>。以前のポートセットの方式を使用すると、 LUN の使用可能なパスをさらに削減できます。ポートセットを使用すると、 igroup 内のイニシエータが LUN を認識する際に経由可能なパス数を減らすことができます。</block>
  <block id="7b997b3be9c993d49799dd9d71d8c3f6" category="list-text">VMware は、 VMware Infrastructure 3 以降で NFSv3 をサポートしています。vSphere 6.0 では NFSv4.1 がサポートされるようになり、 Kerberos セキュリティなどの高度な機能が使用できるようになりました。NFSv3 ではクライアント側のロックが使用され、 NFSv4.1 ではサーバ側のロックが使用されます。ONTAP ボリュームは両方のプロトコルでエクスポートできますが、 ESXi は 1 つのプロトコルでしかマウントできません。この単一プロトコルのマウントにより、他の ESXi ホストが同じデータストアを別のバージョンでマウントすることができるわけではありません。すべてのホストが同じバージョン、つまり同じロック形式を使用するように、マウント時に使用するプロトコルバージョンを指定してください。NFS のバージョンをホスト間で混在させないでください。可能であれば、ホストプロファイルを使用して準拠しているかどうかを確認します</block>
  <block id="d8119941da55a672db49a624330ea7f0" category="list-text">NFS エクスポートポリシーは、 vSphere ホストによるアクセスの制御に使用されます。複数のボリューム（データストア）で 1 つのポリシーを使用できます。NFSv3 では、 ESXi で sys （ UNIX ）セキュリティ形式が使用され、 VM を実行するためにルートマウントオプションが必要となります。ONTAP では、このオプションはスーパーユーザと呼ばれます。スーパーユーザオプションを使用する場合は、匿名ユーザ ID を指定する必要はありません。の値が異なるエクスポートポリシールールに注意してください<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> および<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> 原因 SVM検出がONTAP ツールで問題を検出できるかどうか。ポリシーの例を次に示します。</block>
  <block id="0bbc71e6a4ea49af70dd616d3807e524" category="list-text">匿名UIDの形式です</block>
  <block id="49bb4e84b97bfe104e9fe7eb7df07a38" category="list-text">NFS データストアのボリュームは SVM のルートボリュームからジャンクションされるため、 ESXi がデータストアボリュームに移動してマウントするためにはルートボリュームへのアクセス権も必要となります。ルートボリューム、およびデータストアボリュームのジャンクションがネストされているその他のボリュームのエクスポートポリシーには、 ESXi サーバに読み取り専用アクセスを許可するルールが含まれている必要があります。VAAI プラグインを使用したルートボリュームのポリシーの例を次に示します。</block>
  <block id="8c93fb3ff528165613797962f5a0ed9c" category="list-text">Access Protocol：nfs（nfs3とnfs4の両方を含む）</block>
  <block id="80e6a4f964e826c69c1c62bd5ea67590" category="list-text">RW Access Rule：never（ルートボリュームに最適なセキュリティ）</block>
  <block id="f96625174b4a06d13267f9b0a5a96d59" category="list-text">superuser：sys（VAAIを使用するルートボリュームの場合も必要）</block>
  <block id="23aa7b9aeed3fba2a1ec43e630313af7" category="list-text">プラグインを使用してVMwareクラスタ用のデータストアを作成するときは、単一のESXサーバではなくクラスタを選択します。これにより、データストアがクラスタ内のすべてのホストに自動的にマウントされます。</block>
  <block id="313611996c05f7257ad3043572759306" category="cell">ESXi 7.0U3f以降では、ONTAP 9.12.1RC1以降でのセッショントランキングがサポートされます</block>
  <block id="1abaee3673de53b378351ee9dc679daa" category="list-text">VMware とネットアップは、現在、一般的なマルチパスネットワークアプローチをサポートしていません。NFSv4.1 では、ネットアップは pNFS をサポートしていますが、 VMware はセッショントランキングをサポートしています。NFSv3 は、ボリュームへの複数の物理パスをサポートしていません。ONTAP 9.8 を使用した FlexGroup の場合、 VMware vSphere 用の ONTAP ツールを 1 つのマウントにすることを推奨します。これは、間接アクセスによる影響が通常は最小限（マイクロ秒）であるためです。ラウンドロビン DNS を使用して、 FlexGroup 内の異なるノード上の LIF に ESXi ホストを分散することは可能ですが、その場合、 VMware vSphere 用の ONTAP ツールを使用せずに FlexGroup を作成してマウントする必要があります。その場合、パフォーマンス管理機能は使用できません。</block>
  <block id="4ad396cb9b6773b012067ead8cf08611" category="doc">NetApp Disaster Recovery Orchestrator（DRO）の概要</block>
  <block id="88ac8db9784908706c34feb6caee9044" category="paragraph"><block ref="88ac8db9784908706c34feb6caee9044" category="inline-link-macro-rx"></block></block>
</blocks>