<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="e59c383143e849c3183725256fd9a923" category="summary">ハイブリッドクラウド、デスクトップ仮想化、コンテナ解決策の機能に関する一連のビデオとデモ</block>
  <block id="abcf24668eda72956736ac7e0d4363b2" category="doc">ハイブリッドクラウド、デスクトップ仮想化、およびコンテナのビデオとデモ</block>
  <block id="e96910160219339e97abaf85c4323aaa" category="section-title">ネットアップと VMware Tanzu ビデオシリーズ</block>
  <block id="7108e02acdfbc9a7cf66345731d3ec5e" category="summary">AI と最新のデータ分析に関するブログシリーズ。解決策 の機能</block>
  <block id="407c5c4d36c8f404212036765bd911ac" category="doc">AI と最新のデータ分析ブログ</block>
  <block id="2aa8a49ee37d7496cf666062c18c3ad3" category="paragraph">AI ソリューションと最新のデータ分析ソリューションの特定の機能を紹介するブログの概要です。</block>
  <block id="27f80f5fcc8cfd10fa4ffd9f6c3bc57e" category="section-title">人工知能ブログシリーズ</block>
  <block id="750b570f7c6cacf7b9f43c1c7919ad96" category="inline-link">thePub に掲載された AI に関するブログ</block>
  <block id="183754618306c7f8d7df04f981d234f0" category="list-text"><block ref="183754618306c7f8d7df04f981d234f0" category="inline-link-rx"></block></block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="1cf7e301510c711b73d2b182b9dcf084" category="doc">ユースケース</block>
  <block id="ad54e6f7d665098e981d7e41732ce4c2" category="inline-link-macro">次の例は、アーキテクチャです</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">エラー：グラフィックイメージがありません</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">こちらをご覧ください</block>
  <block id="be5acbec67071810913f6782071a73eb" category="section-title">ストレージ設計</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">アーキテクチャ</block>
  <block id="9a50201aa3bf66a7a0337ccf29d20c90" category="section-title">解決策テクノロジ</block>
  <block id="2b0d957e4ad1bdfd446155ff5bb8a9b2" category="section-title">アーキテクチャ図</block>
  <block id="b831e128b8fd177e9c80396ed741b7c1" category="section-title">ハードウェアとソフトウェアの要件</block>
  <block id="a623a8d0366bf079411aa30be45b2d10" category="section-title">コンピューティング</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">ハードウェア</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">モデル</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">数量</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">ソフトウェア</block>
  <block id="261addf78c7b2c961032b3dd08ba0b1f" category="cell">目的</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">バージョン</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="cell">仮想化</block>
  <block id="c73bbd3786350b0a8d3577d82afdf489" category="cell">Red Hat Enterprise Linux の場合</block>
  <block id="80e910f35b12e9c61335fa88de36edd0" category="cell">Red Hat 仮想化</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="section-title">ストレージ</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4.</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2.</block>
  <block id="fcda5b98e8c212807dc088477e802757" category="cell">NetApp Element</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="3a3a5cd068731551120f43f37950768b" category="cell">ONTAP Select の場合</block>
  <block id="f82f50748d06cc9643330a4a8297ba43" category="cell">9.7</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="section-title">ネットワーキング</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3.</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">追加情報の検索場所</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">このドキュメントに記載されている情報の詳細については、以下のドキュメントや Web サイトを参照してください。</block>
  <block id="1b214ce6b630c9ad822fc984e20f3675" category="inline-link"><block ref="1b214ce6b630c9ad822fc984e20f3675" category="inline-link-rx"></block></block>
  <block id="91fe04078e98f81bd39430c985bba713" category="paragraph"><block ref="91fe04078e98f81bd39430c985bba713" category="inline-link-rx"></block></block>
  <block id="8887a9a417a1629326acdb917d224337" category="list-text">VMware vSphere の場合</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="list-text">NetApp Interoperability Matrix Tool で確認できます</block>
  <block id="930dd6e7cbd550494f96b487d9d38ec8" category="section-title">ハードウェア要件</block>
  <block id="9d273bd32c1fceb91b7d6a4d40e98bdd" category="section-title">ソフトウェア要件</block>
  <block id="d9ae1ecd6158beb6acd24c9f59d0498e" category="paragraph">次の表に、解決策の実装に必要なソフトウェアコンポーネントを示します。解決策の実装で使用されるソフトウェアコンポーネントは、お客様の要件に応じて異なる場合があります。</block>
  <block id="5eed1e48d8861a1192e8694a3d24021b" category="inline-link-macro">次：ユースケース</block>
  <block id="0cdff7d38ef496f6b5510c5034fedf15" category="list-text">パフォーマンスを保証するマルチテナンシー</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="section-title">テクノロジの概要</block>
  <block id="16600c3602f9acbaa2286f34135f6bb8" category="paragraph">NetApp Element ソフトウェアクラスタでは、 QoS をボリューム単位で動的に設定できます。ボリュームごとの QoS 設定を使用して、定義した SLA に基づいてストレージパフォーマンスを制御できます。QoS は、次の 3 つの設定可能なパラメータで定義されます。</block>
  <block id="d91a826908d0c27cf5d21d2152292ab0" category="list-text">* 最小 IOPS 。 * NetApp Element ソフトウェアクラスタがボリュームに提供する平常時の最小 IOPS 。ボリュームに設定された最小 IOPS は、そのボリュームに対して最低限保証されるパフォーマンスレベルです。ボリュームごとのパフォーマンスがこのレベルを下回ることはありません。</block>
  <block id="827b5871d6ce8f2203a567ef3024f072" category="list-text">* Burst IOPS 。 * 短時間のバースト時に許容される最大 IOPS 。バースト期間の設定は、デフォルトの 1 分に設定できます。ボリュームが最大 IOPS レベル未満で動作しているときは、バーストクレジットが蓄積されます。パフォーマンスレベルが非常に高くなってプッシュされると、ボリュームで IOPS が最大 IOPS を超えた短時間のバーストが許容されます。</block>
  <block id="e95bb6f1e85d1ffe0eb983fd5e0fbde8" category="section-title">マルチテナンシー</block>
  <block id="086d1eacd91102f734387f0266326344" category="paragraph">セキュアマルチテナンシーには、次の機能があります。</block>
  <block id="78712bd6b2d8e5531e122b5e849fb842" category="paragraph">NetApp Element ソフトウェアクラスタを使用すると、全体的なストレージ効率とパフォーマンスが向上します。次の機能はインラインで実行されます。常時有効であり、ユーザによる手動設定は必要ありません。</block>
  <block id="7adf04762320f012179ffe68fb0aeb9f" category="paragraph">RHV は以下の機能を提供します。</block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">概要</block>
  <block id="87495e311a3944910e3cc0c7bee3d754" category="cell">VLAN</block>
  <block id="b7dff125c9fce628900142990708436f" category="cell">アウトオブバンド管理ネットワーク</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="7b9993fac4b9a60605aa2884eb40f4a3" category="cell">インバンド管理ネットワーク</block>
  <block id="36a1694bce9815b7e38a9dad05ad42e0" category="cell">1172</block>
  <block id="cd3718e8610b820344c9a0284fe84f90" category="cell">ストレージネットワーク</block>
  <block id="21c5bba1dd6aed9ab48c2b34c1a0adde" category="cell">3343</block>
  <block id="3de18ffc25309bd0755d8543a30ded78" category="cell">移行用ネットワーク</block>
  <block id="38a77aa456fc813af07bb428f2363c8d" category="cell">3345</block>
  <block id="9335616a8b7dc0e6f94fd0c6aa720efe" category="list-text">インバンド管理ネットワークと VM ネットワークからアクセス可能な完全なホスト名解決を提供する DNS サーバが少なくとも 1 台必要です。</block>
  <block id="905a394004d9055ec4708e53880cac66" category="list-text">インバンド管理ネットワークおよび VM ネットワークからアクセスできる NTP サーバが少なくとも 1 台必要です。</block>
  <block id="729d72c073b607d370c067152cc53a10" category="doc">検証結果</block>
  <block id="1b21b0d71706897b69f108572c444d40" category="cell">ハイパーバイザー</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">該当なし</block>
  <block id="b872d0389acf826cc7cf1939cd17a05d" category="inline-link-macro">次へ：追加情報の検索場所</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="doc">概要</block>
  <block id="1ddf333c6654f7f89c739dddfb4cc429" category="section-title">アプリケーション</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">前提条件</block>
  <block id="794df3791a8c800841516007427a2aa3" category="section-title">使用許諾</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="section-title">導入</block>
  <block id="1be465260df7c846768e06c988594a6a" category="paragraph">このドキュメントに記載されている情報の詳細については、次の Web サイトを参照してください。</block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="cell">NetApp Trident</block>
  <block id="7cd95c816f8a04ff858a857e3e5a484d" category="cell">20.04</block>
  <block id="b175d08ac03101cd40f077848d436e1f" category="cell">Red Hat OpenShift のサービスです</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">コンテナオーケストレーション</block>
  <block id="93b3852e5c67975dd33b1769b24a4a85" category="paragraph">Jenkins アプリケーションの導入に必要なリソースを作成するには、次の手順に従います。</block>
  <block id="9fd493573e73cb0e5e55e97306249596" category="list-text">Jenkins という名前の新しいプロジェクトを作成します。</block>
  <block id="5690195262fb589b6021733b4a5a4432" category="paragraph"><block ref="5690195262fb589b6021733b4a5a4432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d256abce3dbdfed83e337956e42f60f" category="list-text">この例では、永続的ストレージを使用して Jenkins を導入しています。Jenkins ビルドをサポートするには、 PVC を作成します。[ ストレージ ] &gt; [ 永続的ボリューム要求 ] の順に選択し、 [ 永続的ボリューム要求の作成 ] をクリックします。作成したストレージクラスを選択し、永続ボリューム要求名が Jenkins であることを確認し、適切なサイズとアクセスモードを選択して、作成をクリックします。</block>
  <block id="f9db9f308c8ed7f5d0ed0851d8d605cb" category="paragraph"><block ref="f9db9f308c8ed7f5d0ed0851d8d605cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9272f40a21ca3dad814c4e3886b40776" category="section-title">永続的ストレージを使用して Jenkins を導入する</block>
  <block id="939a7b51bfb262627185af768c3c1024" category="paragraph">永続ストレージを使用して Jenkins を導入するには、次の手順を実行します。</block>
  <block id="bc5512ef7a17a0cfb58cb1ede30a6137" category="paragraph"><block ref="bc5512ef7a17a0cfb58cb1ede30a6137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="949381804bf1e16ca04ba9ac5fabc6a4" category="paragraph"><block ref="949381804bf1e16ca04ba9ac5fabc6a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc9a211dac876290bd6ed039cf1afdcf" category="paragraph"><block ref="cc9a211dac876290bd6ed039cf1afdcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="274c247b7612630006e3d87d5ed5d46f" category="paragraph"><block ref="274c247b7612630006e3d87d5ed5d46f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da33835bff86a0b0c8be6c67dcf677bb" category="list-text">ポッドがインスタンス化されたら、ネットワーキング &gt; ルートと進みます。Jenkins の Web ページを開くには、 Jenkins ルート用の URL をクリックします。</block>
  <block id="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="paragraph"><block ref="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="paragraph"><block ref="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9359288fc248319fa9acef62e4686d1c" category="paragraph"><block ref="9359288fc248319fa9acef62e4686d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00713894c16827219fd5ab50c5fc3794" category="paragraph"><block ref="00713894c16827219fd5ab50c5fc3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24f99be3c7033ab08c3baec1cdf32702" category="paragraph"><block ref="24f99be3c7033ab08c3baec1cdf32702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b6fc174a3fad5c396413febe1d4ba50" category="list-text">[ 項目の作成 ] ページで、任意の名前を入力し、 [ パイプライン ] を選択して、 [OK] をクリックします。</block>
  <block id="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="paragraph"><block ref="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dedbf53849830e8b275b69e9b98159ce" category="paragraph"><block ref="dedbf53849830e8b275b69e9b98159ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0191ad3b841f8db403ec4749d571eb4b" category="list-text">「今すぐビルド」をクリックして、準備、ビルド、テストの各フェーズで開発を開始します。ビルドプロセス全体が完了してビルドの結果が表示されるまでに数分かかることがあります。</block>
  <block id="1d11f84feef51515ab9fdaafb3f02f3a" category="paragraph"><block ref="1d11f84feef51515ab9fdaafb3f02f3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b04b355d9fc6a2e23965649ebdd0aa31" category="list-text">コードが変更された場合は、必ずパイプラインを再構築して新しいバージョンのソフトウェアにパッチを適用することで、継続的な統合と継続的な提供を実現できます。[ 最近の変更 ] をクリックして、前のバージョンからの変更を追跡します。</block>
  <block id="43d9a2fc4d89e82c869a466778811ab3" category="paragraph"><block ref="43d9a2fc4d89e82c869a466778811ab3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="648bdcd0b9a0f83d7b068dbed3c21c07" category="doc">設計上の考慮事項</block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">ネットワーク設計</block>
  <block id="f1744781b12c15ad3b748bea44d9582b" category="section-title">VLAN の要件</block>
  <block id="e8e0dd181e4ee545195120626098bfba" category="cell">3480</block>
  <block id="3fb04953d95a94367bb133f862402bce" category="cell">3481</block>
  <block id="b7fede84c2be02ccb9c77107956560eb" category="cell">3487</block>
  <block id="35b5078b5953437a59ffd4f77c464800" category="section-title">ネットワークインフラストラクチャサポートリソース</block>
  <block id="c2ffe02d76c4f089648f1647b43e4ee5" category="section-title">ベストプラクティス</block>
  <block id="2d52bcd2e896c32a66c9fe10fed38e0f" category="inline-link-macro">次の手順：ハードウェアとソフトウェアの要件</block>
  <block id="6e16409ed6038c106c7fa1dfbfb9da0f" category="admonition">また、適切なフラグを指定して「 OC debug 」コマンドを実行することにより、 MachineConfig が正常に適用され、サービスが正常に開始されたことを確認することもできます。</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">ハードウェア要件</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">ソフトウェア要件</block>
  <block id="9c295b8302ac546bb93a346b68089f50" category="cell">6.7U3</block>
  <block id="bfd15aa26ba0ced782240c4a8b7e517e" category="cell">ストレージ管理</block>
  <block id="59a703e67b19adc4bdb1373c25fbca94" category="inline-link-macro">次：導入手順</block>
  <block id="98f770b0af18ca763421bac22b4b6805" category="section-title">の機能</block>
  <block id="f95d0437e813349fa018b7f0e68e9a7d" category="paragraph">導入したユーザクラスタに Trident をインストールし、永続ボリュームをプロビジョニングするには、次の手順を実行します。</block>
  <block id="422269f9bb560b76869cbd586b8370d5" category="list-text">ダウンロードしたバンドルから Trident のインストールを解凍します。</block>
  <block id="68602d0447fae81afa9d0528ef0c6420" category="list-text">Trident にはこのファイルを渡すオプションがないため、まず、ユーザクラスタの「 kubeconfig 」ファイルの場所を環境変数として設定します。</block>
  <block id="5d710ec7d521df428edd75c1885ee89b" category="list-text">'trident-installer' ディレクトリには ' 必要なすべてのリソースを定義するマニフェストが含まれています適切なマニフェストを使用して、「 TridentOrchestrator 」カスタムリソース定義を作成します。</block>
  <block id="0ac11186fb38b2e9d4acd38d03f61b5c" category="list-text">存在しない場合は、指定されたマニフェストを使用して、クラスタ内に Trident ネームスペースを作成します。</block>
  <block id="004c51fe71b5c654f88a31270ec6c8e9" category="list-text">トライデントオペレータの配備に必要なリソースを作成しますたとえば ' オペレータ用のサービスアカウント 'ClusterRole' および 'ClusterRoleBind' を 'ServiceAccount' 専用の 'PodSecurityPolicy' またはオペレータ自体に割り当てます</block>
  <block id="f7b9c678b684e969a3ee5ac971514f48" category="list-text">次のコマンドを使用すると、展開後にオペレータのステータスを確認できます。</block>
  <block id="b34dd67c198ad4cf0088bd29c7ef4658" category="list-text">オペレータが導入したら、 Trident をインストールできます。これには 'TridentOrchestrator を作成する必要があります</block>
  <block id="64e437a845e5de3c8e50925ebdfce295" category="list-text">Trident が正しくインストールされていることを確認するには、ネームスペースで実行されているポッドを確認するか、 tridentctl バイナリを使用してインストールされているバージョンを確認します。</block>
  <block id="dd7f72325e6f60ea7163b071e4d5e2cc" category="list-text">このバックエンドファイルを設定したら、次のコマンドを実行して最初のバックエンドを作成します。</block>
  <block id="d8f188eff4c16fa87dd87f51db847f73" category="list-text">バックエンドを作成したら、次にストレージクラスを作成する必要があります。バックエンドと同様に、 sample_inputs フォルダにある環境用に編集可能なサンプルのストレージクラスファイルがあります。作業ディレクトリにコピーし、作成したバックエンドを反映するために必要な編集を行います。</block>
  <block id="eb22c0d536e50f388da6dfd91ba4c0b6" category="list-text">このファイルに対して行う必要がある唯一の編集は ' バックエンドタイプの値を ' 新しく作成されたバックエンドのストレージドライバの名前に定義することですまた、名前フィールドの値もメモしておきます。この値は、以降の手順で参照する必要があります。</block>
  <block id="cc66c30273a9be504b88d3239e65516b" category="paragraph"><block ref="cc66c30273a9be504b88d3239e65516b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86b43786316d35748685c4f7abc4145b" category="paragraph"><block ref="86b43786316d35748685c4f7abc4145b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05808f0e86c04c2a062c2e041f9e0827" category="cell">VLAN ID</block>
  <block id="c87f7de78a1912f53050e58df90e1445" category="cell">仮想ゲスト移行用のネットワーク</block>
  <block id="447cb4a01965e3df01476db3576e0399" category="list-text">（オプション）インバンド管理ネットワークと VM ネットワークの両方のアウトバウンドインターネット接続。</block>
  <block id="0f19aa91cffca51fd061e34dee1e5c79" category="paragraph">このセクションでは、この解決策を本番環境に導入する前に考慮する必要があるベストプラクティスをいくつか紹介します。</block>
  <block id="5c00bc5cb1bdae240d18551e77806abd" category="inline-link">Red Hat 6.11アフィニティグループのドキュメント</block>
  <block id="1050f3dc9e3ee559789e3b25f2e4f77e" category="inline-link">Red Hat OpenShift カスタマイズを使用した RHV へのクラスタのインストール</block>
  <block id="3f4b17e041e63192875c654812122484" category="paragraph">ネットアップ、 Alan Cowles 氏と Nikhil M Kulkarni 氏</block>
  <block id="932ba7da1da9b241bfc5ddbb10e49da2" category="paragraph">企業は、新しい製品の作成、リリースサイクルの短縮、新機能の迅速な追加を目的として、 DevOps の手法を採用する傾向に迫られています。即応性に優れた本来の性質から、コンテナやマイクロサービスは、 DevOps の実践を支援するうえで重要な役割を果たします。しかし、エンタープライズ環境で本番環境規模で DevOps を実践する場合、独自の課題が生じ、基盤となるインフラに次のような一定の要件が課せられます。</block>
  <block id="43ee156205e7f74e32a02d556537fe90" category="list-text">スタック内のすべてのレイヤで高可用性を実現します</block>
  <block id="b59807af538b77fee1fb3d1d3c81f9a8" category="list-text">導入手順の簡易化</block>
  <block id="1a4af279491c72d7c36b4c9767ae712f" category="list-text">API ベースのプログラム可能なインフラで、マイクロサービスの即応性を維持します</block>
  <block id="8ca11bfd783c730b04c0c77fc7574406" category="list-text">仮想ワークロードとコンテナ化されたワークロードを同時に実行できます</block>
  <block id="0111977afdb7fa380f806edbe8438163" category="list-text">ワークロードのニーズに応じてインフラを個別に拡張できる</block>
  <block id="ecfb2402c181e98da49a5d763378b116" category="paragraph"><block ref="ecfb2402c181e98da49a5d763378b116" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb8e8e87ec9c630a0a27910fe29abceb" category="paragraph">RHV は、 Red Hat Enterprise Linux （ RHEL ）上で動作し、 KVM ハイパーバイザーを使用するエンタープライズ仮想データセンタープラットフォームです。</block>
  <block id="603bc85f6f6f4d9e5095745d9252f1d3" category="inline-link">Red Hat Virtualization の Web サイト</block>
  <block id="8a961382f0c47dc86706f0aa8bb93fb4" category="paragraph">RHV の詳細については、を参照してください<block ref="ac07861257bcab0c21d310fa00cb324b" category="inline-link-rx"></block>。</block>
  <block id="0178ef6806a57586f6c66dde7e0e86d2" category="list-text">* 仮想マシンとホストの一元管理。 * RHV マネージャは、導入環境内で物理マシンまたは仮想マシン（ VM ）として動作し、中央インターフェイスから解決策を管理するための Web ベースの GUI を提供します。</block>
  <block id="01b0ee840ef208c283c3f4e959aa9427" category="paragraph"><block ref="01b0ee840ef208c283c3f4e959aa9427" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd89bb4228981d3b22187eb451421cd6" category="section-title">Red Hat OpenShift Container Platform</block>
  <block id="16c321ec2744799f0acef92ce84d06ca" category="paragraph"><block ref="16c321ec2744799f0acef92ce84d06ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="doc">解決策コンポーネント</block>
  <block id="bd4ffcaabbe4a4f83fbfaaa2e34dc8a3" category="section-title">iSCSI ログインのリダイレクト機能と自己回復機能</block>
  <block id="5c8e89de2b8e6e2f103d858b59e5aca0" category="section-title">NetApp Element ソフトウェアクラスタの QoS</block>
  <block id="97bee3e8d0db89b2cd19eba861763e7a" category="list-text">* セキュアな認証。 * Challenge Handshake Authentication Protocol （ CHAP ；チャレンジハンドシェイク認証プロトコル）は、ボリュームへのセキュアなアクセスに使用されます。Lightweight Directory Access Protocol （ LDAP ）は、管理とレポートのためのクラスタへのセキュアなアクセスに使用されます。</block>
  <block id="3918507b16aa3cc38274c29da446d90f" category="list-text">* ボリュームアクセスグループ（ VAG ）。 * 必要に応じて、任意の数の iSCSI イニシエータ固有の iSCSI Qualified Name （ IQN ）を 1 つ以上のボリュームにマッピングし、認証の代わりに VAG を使用できます。VAG 内のボリュームにアクセスするには、イニシエータの IQN がボリュームグループの許可された IQN リストに含まれている必要があります。</block>
  <block id="28328e0db9c18c9ada207997f806124f" category="list-text">* テナント仮想 LAN （ VLAN ）。 * ネットワークレベルでは、 iSCSI イニシエータと NetApp Element ソフトウェアクラスタ間のエンドツーエンドのネットワークセキュリティは、 VLAN を使用することで容易になります。ワークロードまたはテナントを分離するために作成された VLAN については、 NetApp Element ソフトウェアが、特定の VLAN 経由でのみアクセス可能な iSCSI ターゲット SVIP アドレスを別途作成します。</block>
  <block id="fca8436836d48525b8d98babbfd68518" category="list-text">* テナント SVIP アドレスへの L3 ルーティング。 * この機能を使用すると、 iSCSI イニシエータを、 NetApp Element ソフトウェアクラスタとは別のネットワークまたは VLAN に配置できます。</block>
  <block id="c08531651ee4977d5020da1b84003631" category="section-title">エンタープライズクラスのストレージ効率化</block>
  <block id="2e5dd3a69ccb3f04d7814fc742318204" category="list-text">* 圧縮。 * 圧縮は、データが NVRAM に書き込まれる前にインラインで実行されます。データは 4K ブロック単位で圧縮され、システム内で圧縮されたままとなります。この圧縮により、クラスタ全体での容量消費、書き込み処理数、および帯域幅消費が大幅に削減されます。</block>
  <block id="95f1b89c8e9c330fcfdc8ec84633bfe6" category="list-text">* Helix 。 * 個々のボリュームのメタデータはメタデータドライブに格納され、セカンダリメタデータドライブにレプリケートされて冗長性が確保されます。</block>
  <block id="ea2625d89edeb5ba9cb41ca58df54e93" category="paragraph">Anthos には次のような機能があります。</block>
  <block id="c10e0a21a04a29dfca9609b3ec4bab76" category="list-text">* Anthos の構成管理。 * ハイブリッド Kubernetes 環境のポリシーとセキュリティを自動化します。</block>
  <block id="e8c4d5cbaf3932ffa3fa7a097bff923e" category="list-text">* Anthos サービスメッシュ * は、 Istio 電源のサービスメッシュにより、アプリケーションのオブザーバビリティ、セキュリティ、および制御を強化します。</block>
  <block id="844236b21d302f8c93eda00636abfff8" category="list-text">* セキュリティー要件。 * セキュリティーの懸念が高まるお客様や、パブリッククラウドに保存できない機密データセットをお持ちのお客様は、自社のデータセンターのセキュリティーからアプリケーションを実行できるため、組織の要件を満たすことができます。</block>
  <block id="ae6f5747bf29f889c1d28208afab2a1a" category="doc">アプリケーションの展開</block>
  <block id="cef52206f11ced919c8d0dd4b2c791a4" category="paragraph">次のセクションでは、アプリケーションのインストールと展開の方法について説明します。</block>
  <block id="d0954433c0b62861850b87d9cba7599f" category="inline-link-macro">次の手順： GitHub からコードを取得します</block>
  <block id="255a6bf7e1d34563f76daaf2b6cd6184" category="paragraph"><block ref="26e27ac56fb4c03c9632ab9bd4fc068b" category="inline-link-macro-rx"></block>。</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">Kubeflow の公式ドキュメント</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="summary">ネットアップストレージシステム / プラットフォーム上に Kubernetes クラスタ内のコンテナにマウントする必要のある既存のボリュームがあり、クラスタ内の PVC に関連付けられていない場合は、それらのボリュームをインポートする必要があります。これらのボリュームは、 Trident のボリュームインポート機能を使用してインポートできます。</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="doc">既存のボリュームをインポートします</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">Kubernetes の公式ドキュメント</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link">Trident のドキュメント</block>
  <block id="3429b7e0331de8d2f8d377b034ca6855" category="inline-link-macro">Trident の導入と設定</block>
  <block id="c701c7fe143bef79cc6eebc32606262e" category="paragraph">このドキュメントに記載されている情報の詳細については、次のリソースを参照してください。</block>
  <block id="c7c082299876892b4274ecfb3c3f7bcd" category="list-text">NVIDIA DGX-1 サーバ：</block>
  <block id="d2647f7d8e79758eea27c6cdcf636638" category="list-text">NVIDIA DGX-1 サーバ</block>
  <block id="45a310b0e4b087b75cb073303044f6f9" category="inline-link"><block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="af828c56c03364ebbde4c582adeb8de3" category="paragraph"><block ref="af828c56c03364ebbde4c582adeb8de3" category="inline-link-rx"></block></block>
  <block id="65d1be94e9f29dc4af77bef169d5be14" category="list-text">NVIDIA Tesla V100 Tensor コア GPU</block>
  <block id="fad8218d69ce01748faed5492aa5d3ef" category="inline-link"><block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="a724832176ce84a9d4be5c34e44891d3" category="paragraph"><block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="list-text">NVIDIA GPU Cloud （ NGC ）</block>
  <block id="5c75bfead88762783d54deaaa3d62735" category="inline-link"><block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="839d9b8469a8d9554891a7515a2b9be7" category="paragraph"><block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="64ba1593b4427fb62b53b007d4a1c26e" category="list-text">NetApp AFF システム：</block>
  <block id="584122d1d5e8c2c4232e029a6896ba40" category="list-text">AFF データシート</block>
  <block id="9a84c14d2692222552174943486e7136" category="inline-link"><block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="0d9d8991a05834f0e52a99b37ce360b8" category="paragraph"><block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="b4199ce9c494dec10c6ee051ddb413e2" category="list-text">AFF 向け NetApp FlashAdvantage プログラム</block>
  <block id="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link"><block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="72cf25e9f1e13167cd0dde6f285552ea" category="paragraph"><block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="30df7f622635480ab538fb3016f9c36a" category="list-text">ONTAP 9.x のドキュメント</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="35d8efcf211e40a836698bff14ed0ff6" category="list-text">NetApp FlexGroup テクニカルレポート</block>
  <block id="1ab29fc7fde3319a82a477ec308cf820" category="inline-link"><block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="7a26d62dac2be507dcc3e5b9da0ed765" category="paragraph"><block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="de1e4a3a0cae539a34678546eb6e91b3" category="list-text">コンテナ向けのネットアップの永続的ストレージ：</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="1cb9a8619999ebc0a2d9c07624d76166" category="list-text">NetApp Interoperability Matrix を参照してください</block>
  <block id="d51c982ce98a1e197c234ea0b9a5e7d9" category="inline-link"><block ref="d51c982ce98a1e197c234ea0b9a5e7d9" category="inline-link-rx"></block></block>
  <block id="7a211d267d46c5b44662098f9234fcd0" category="list-text">ONTAP AI ネットワーク：</block>
  <block id="b8a60c56690ddfc62bd735d0b212c396" category="list-text">Cisco Nexus 3232C スイッチ</block>
  <block id="bb31172f259c591005fd4cbcdbfadd11" category="inline-link"><block ref="bb31172f259c591005fd4cbcdbfadd11" category="inline-link-rx"></block></block>
  <block id="96eb8aa0e86d101fdf87284d7d6f1bc7" category="paragraph"><block ref="96eb8aa0e86d101fdf87284d7d6f1bc7" category="inline-link-rx"></block></block>
  <block id="926dc08a3a3a3946402bb1beab6545cc" category="list-text">Mellanox Spectrum 2000 シリーズスイッチ</block>
  <block id="193721fbb9ea3851cafcea43a4d95f73" category="list-text">ML フレームワークとツール：</block>
  <block id="edb7d6728a9813b505cb306367d453e3" category="list-text">大理</block>
  <block id="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="inline-link"><block ref="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="inline-link-rx"></block></block>
  <block id="1b2766572fa1896116e3c218eb697113" category="list-text">TensorFlow ：あらゆる環境に対応するオープンソースの機械学習フレームワーク</block>
  <block id="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link"><block ref="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link-rx"></block></block>
  <block id="26909d0380bdba02e2fcf7f7157cd78b" category="list-text">Horovod ： Uber が開発したオープンソースの TensorFlow 用分散学習フレームワーク</block>
  <block id="3ffa9619031400d374ed5c0860d434ab" category="inline-link"><block ref="3ffa9619031400d374ed5c0860d434ab" category="inline-link-rx"></block></block>
  <block id="c9cbaff7c173f4b7bc923573ca753577" category="list-text">コンテナランタイムエコシステムでの GPU の有効化</block>
  <block id="b3a776c1e64d267ebe62a7bf45c6c1b7" category="inline-link"><block ref="b3a776c1e64d267ebe62a7bf45c6c1b7" category="inline-link-rx"></block></block>
  <block id="c5fd214cdd0d2b3b4272e73b022ba5c2" category="list-text">Docker です</block>
  <block id="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link"><block ref="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link-rx"></block></block>
  <block id="60ea9e9ecbf839c413c5e977002eabf4" category="paragraph"><block ref="60ea9e9ecbf839c413c5e977002eabf4" category="inline-link-rx"></block></block>
  <block id="30136395f01879792198317c11831ea4" category="list-text">Kubernetes</block>
  <block id="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link"><block ref="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link-rx"></block></block>
  <block id="6bd14be39aedfe96ceacec2caaac0532" category="paragraph"><block ref="6bd14be39aedfe96ceacec2caaac0532" category="inline-link-rx"></block></block>
  <block id="142f782bb2b326679982208fe40cec31" category="list-text">NVIDIA DeepOps のことです</block>
  <block id="ccd09fd9430cf2df88a137dbec97676b" category="inline-link"><block ref="ccd09fd9430cf2df88a137dbec97676b" category="inline-link-rx"></block></block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="list-text">クビフロー</block>
  <block id="a33d91971f7757996ab0eb8eb0362814" category="inline-link"><block ref="a33d91971f7757996ab0eb8eb0362814" category="inline-link-rx"></block></block>
  <block id="6771540ad76dbed724cb9025978b8510" category="paragraph"><block ref="6771540ad76dbed724cb9025978b8510" category="inline-link-rx"></block></block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="list-text">Jupyter Notebook Server の 2 つのツールを使用</block>
  <block id="c90a0598d42425e6ec2dfb3058534b35" category="inline-link"><block ref="c90a0598d42425e6ec2dfb3058534b35" category="inline-link-rx"></block></block>
  <block id="ef9e62eeb81c0987fbe61de48635886a" category="paragraph"><block ref="ef9e62eeb81c0987fbe61de48635886a" category="inline-link-rx"></block></block>
  <block id="22d149e351657eac5bd1db4934498bbe" category="list-text">データセットとベンチマーク：</block>
  <block id="b318879f822314efe94c2f096d06465c" category="list-text">ImageNet</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="doc">謝辞</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">ネットアップテクニカルマーケティングエンジニア、 Mike Oglesby 氏</block>
  <block id="94a8512f59eafd68b470105fc3269fd4" category="list-text">ネットアップシニアテクニカルディレクター Santosh Rao 氏</block>
  <block id="17e1dd6389643aeecf567ba08bf1df2c" category="paragraph"><block ref="17e1dd6389643aeecf567ba08bf1df2c" category="inline-link-macro-rx"></block></block>
  <block id="bd3114e9e2000f42e265a067e98b0d25" category="doc">フルフィルメントエンジンとしてサードパーティ API に接続します</block>
  <block id="1aea646cd3c044dd0758af18e73cfef3" category="paragraph">次のサードパーティ API を欠品補充エンジンとして回答の質問に関連付けました。</block>
  <block id="94c494471216991658782a32f1e3ef37" category="inline-link">WeatherStack API</block>
  <block id="f7eb24e530470f21243c27770bd2c549" category="list-text"><block ref="c8600f69e922164a09610e481537b92d" category="inline-link-rx"></block>: 指定された場所の天候、温度、降雨および雪を返す。</block>
  <block id="1c96228fa1453bf3f691d5081cbd6adb" category="inline-link">Yelp Fusion API</block>
  <block id="55a3b552be8202b066ea237b831186f4" category="list-text"><block ref="8af0de0530d799485b6d6a2d146ab784" category="inline-link-rx"></block>: 指定された場所で最も近いストア情報を返します。</block>
  <block id="114e8180b93cb1b21cd00067e446e5f0" category="inline-link">eBay Python SDK</block>
  <block id="da6816adc86546982065d9aef78845e5" category="list-text"><block ref="3d046b40b6d382ee41dd02d3b6ab007c" category="inline-link-rx"></block>: 指定されたアイテムの価格を返します。</block>
  <block id="3f7ba19f5b656e6cf8db9c69330a6d6e" category="inline-link-macro">次のステップ： NetApp Retail Assistant のデモ</block>
  <block id="23e96dc8693037c8fa1d7c0587a2d5eb" category="paragraph"><block ref="23e96dc8693037c8fa1d7c0587a2d5eb" category="inline-link-macro-rx"></block></block>
  <block id="37e875b843ef9539c02d09d3bbee6668" category="doc">セクション 4.8 のテストの詳細</block>
  <block id="638c2d891d4e85bcfae409499fba817c" category="inline-link-macro">オーバークォータの GPU 割り当てによる高いクラスタ利用率の達成</block>
  <block id="d9ed812c8dd9083f1fb345425b8ce100" category="paragraph">ここでは、のテストの詳細について説明します <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>。</block>
  <block id="f354c9a7a0a52e7a5a3514252ea5f8b7" category="paragraph">次の順序でジョブを送信します。</block>
  <block id="9e727fdd3aec8274f46685441900280d" category="cell">プロジェクト</block>
  <block id="be53a0541a6d36f6ecb879fa2c584b08" category="cell">イメージ（ Image ）</block>
  <block id="b3428404a5be1cf95d4e53b2ddc8288a" category="cell">GPU の数</block>
  <block id="96b0141273eabab320119c467cdcaf17" category="cell">合計</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">コメント（ Comment ）</block>
  <block id="9320270de4ff6824ae7a21f729fb7d44" category="cell">チーム A</block>
  <block id="c6e328a3639bc00374d81e681f89f609" category="cell">Jupyter</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1.</block>
  <block id="ff8bed43ac09b1148fc7648f5845f698" category="cell">1/4</block>
  <block id="37ce74088416f28dc9bb04355c2e5a28" category="cell">–</block>
  <block id="cfaa375bf6c7f9fcc1bc04d4f30c9154" category="cell">ネットアップ</block>
  <block id="6408e079aefee9702aa00f77228dd941" category="cell">2/4</block>
  <block id="00833fac70036c049bd75443869cacb5" category="cell">実行： AI</block>
  <block id="36d2df43ead992a1e3c86acd0cec69f9" category="cell">4 月 4 日</block>
  <block id="d2313e844e73fe4a8f63d93f4df355fc" category="cell">すべてのクォータを使用しています</block>
  <block id="238ff8d9192e9c01e50a8d6d21f1607b" category="cell">チーム - b</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="e4275e3860ed32f489dbb6a5d4a10f5f" category="cell">0.6/2</block>
  <block id="8457d97e0a0f74a5926d1dee27e53541" category="cell">フラクショナル GPU</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="975ca8804565c1a569450d61090b2743" category="cell">1/2</block>
  <block id="867c7d7d65c50ae3679fabce2eab87a3" category="cell">2/2.</block>
  <block id="c3a4885d143dc5b306446fb380c6cfda" category="cell">4 月 2 日</block>
  <block id="411472b1216ec08457e653eac42d7bbd" category="cell">クォータに 2 つ</block>
  <block id="3b40d1328b825dda4b761a8e534669b7" category="cell">チーム -c</block>
  <block id="d310cb367d993fb6fb584b198a2fd72c" category="cell">0.5</block>
  <block id="76169512ef5ca1abe70b32c0993856af" category="cell">0.5/2</block>
  <block id="e85b79abfd76b7c13b1334d8d8c194a5" category="cell">0.3</block>
  <block id="5c2b079fc9750c2995852b8fb354aae3" category="cell">0.8/2.</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="00fd1da21e8b4ef31d987665dc575099" category="cell">3/2</block>
  <block id="0375b76ff57435094e28e94015a5f052" category="cell">クォータに 1 つ</block>
  <block id="ae7ccf7b1a6a1a023f611a294572a900" category="cell">チーム -d</block>
  <block id="ecdb9acc2db02134680a9c49abe3e991" category="cell">4/8</block>
  <block id="30c006c71ada68e2273b128bc2e6831b" category="cell">クォータの半分を使用します</block>
  <block id="36cf0dc9f04c54214fa577ec66ff53fc" category="paragraph">コマンドの構造：</block>
  <block id="7b3a4ccf5e0cc7918cd458f7e46b9c8e" category="paragraph">テストで使用する実際のコマンドシーケンス：</block>
  <block id="3bf38f884fd74f6e6f1ec3d80018edd8" category="paragraph">この時点で、次の状態になります。</block>
  <block id="e55f05703a3e04fbd9e10f76ae925cc9" category="cell">GPU が割り当てられました</block>
  <block id="26cc9c6ccae01f319282379c339cd90b" category="cell">ワークロードキュー</block>
  <block id="478eb1c4e698b325048b6bccfb8974f6" category="cell">4/4 （ソフトクォータ / 実際の割り当て）</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="cell">なし</block>
  <block id="2df6f557cc57e6d4044b9611b1f56439" category="inline-link-macro">「 Achieving High Cluster Utilization With over-uota 」 GPU 割り当て</block>
  <block id="3667ebc7f28f59fc13bfcf314c67de05" category="paragraph">を参照してください <block ref="dee5d16c649661a62d3a765af5b1a963" category="inline-link-macro-rx"></block> 進行中のテストシナリオについてのディスカッションにご参加ください。</block>
  <block id="ac8466404b94a669f51a3d2db2401cf0" category="inline-link-macro">次は、セクション 4.9 のテストの詳細です</block>
  <block id="84b7d04f598931bc149a92c543d3146f" category="paragraph"><block ref="84b7d04f598931bc149a92c543d3146f" category="inline-link-macro-rx"></block></block>
  <block id="1e92efa8f46c28a3c3a1c03ababfa7be" category="doc">NetApp Retail Assistant のデモ</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">リンクをクリックしてください</block>
  <block id="bb07f1ff94c6f99bf48a403706bea4ca" category="paragraph">NetApp Retail Assistant （奈良）のデモビデオを録画しました。をクリックします<block ref="c1305d6e7f2e06345748f63e36abba33" category="inline-link-rx"></block> 次の図を開き、ビデオデモを再生します。</block>
  <block id="088070f65f454d6b38e8e40e332e70a8" category="paragraph"><block ref="088070f65f454d6b38e8e40e332e70a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d81ccbd202a60c621000abca3f6f3de" category="inline-link-macro">次のスライド： NetApp Cloud Sync を使用して会話履歴をアーカイブ</block>
  <block id="a165baa9089720dc90e8baf16267821f" category="paragraph"><block ref="a165baa9089720dc90e8baf16267821f" category="inline-link-macro-rx"></block></block>
  <block id="6f7f6c0b1054487e622896990b1d6d55" category="doc">TR-4841 ：『 Hybrid Cloud AI Operating System with Data Caching 』</block>
  <block id="1b55e21d5b19a6ba57ae9bbd6f3a0630" category="paragraph">ネットアップ Yochay Ettun 、 cnvrg.io 、 David Arnette 、 Rick Huang 氏</block>
  <block id="28d9fd6fa10254fdcc59aa182ae32dc9" category="paragraph">データの急増と ML と AI の急激な成長により、独自の開発と実装の課題を抱えるゼタバイト経済が生まれました。</block>
  <block id="eb35f773ff882afb6d6d67613a4701ee" category="paragraph">ML モデルは大量のデータを必要とし、コンピューティングリソースにはハイパフォーマンスのデータストレージが必要であることは広く知られていますが、実際には、このモデルを実装するのはそれほど簡単ではありません。特にハイブリッドクラウドインスタンスや柔軟なコンピューティングインスタンスを使用する場合はそうです。一般に、大量のデータが低コストのデータレイクに保存されます。このデータレイクでは、 GPU などのハイパフォーマンスな AI コンピューティングリソースは効率的にアクセスできません。この問題は、一部のワークロードがクラウドで動作し、一部のワークロードがオンプレミス環境または別の HPC 環境に完全に配置されているハイブリッドクラウドインフラにさらに悪化しています。</block>
  <block id="2b8ab86ccf473cca225e50ddb8c47e25" category="paragraph">このドキュメントでは、 IT プロフェッショナルやデータエンジニアがトポロジに対応したデータハブで真のハイブリッドクラウド AI プラットフォームを構築できる、新しい解決策を紹介します。これにより、データサイエンティストは、コンピューティングリソースに近接してデータセットのキャッシュを瞬時に自動作成できます。 どこにいても、その結果、高性能なモデルトレーニングを実施できるだけでなく、データセットバージョンハブ内のデータセットキャッシュ、バージョン、リネージにすぐにアクセスできる複数の AI 専門家のコラボレーションなど、さらなるメリットが得られます。</block>
  <block id="3bc3b194b0ef70e2e6ce113f819619c4" category="inline-link-macro">次の手順：ユースケースの概要と問題点</block>
  <block id="3eb8a6b81400ec3a497fb59a7e6f4360" category="paragraph"><block ref="3eb8a6b81400ec3a497fb59a7e6f4360" category="inline-link-macro-rx"></block></block>
  <block id="1d22ea3c852f35081a408a42b1caa719" category="doc">cnvrg.io の展開</block>
  <block id="e1d91df1cfd0e5839c45e06d0504c9d6" category="section-title">Helm を使用して cnvrg コアを導入します</block>
  <block id="7e9e2a4317009b27ebfc0b4cd222ba30" category="paragraph">Helm は、任意のクラスタ、オンプレミス、 Minikube 、または任意のクラウドクラスタ（ AKS 、 EKS 、 GKE など）を使用して、 cnvrg を迅速に導入する最も簡単な方法です。このセクションでは、 Kubernetes がインストールされたオンプレミス（ DGX-1 ）インスタンスに cnvrg がインストールされた方法について説明します。</block>
  <block id="ea6de3fdf29035cd2d521949527c2a44" category="paragraph">インストールを完了する前に、ローカルマシンに次の依存関係をインストールして準備する必要があります。</block>
  <block id="6f49e891fdb1bb11823492f4d315b2fd" category="list-text">Kubectl のように入力する</block>
  <block id="5e6cef7c129d4703b20be420ac32145c" category="list-text">Helm 3.x</block>
  <block id="93fafc2be5db6c259030d6d8dc989752" category="list-text">Kubernetes クラスタ 1.15 以降</block>
  <block id="116efea8faeef9714de76fe9f81d9b82" category="section-title">Helm を使用して展開します</block>
  <block id="237800170a9b824a7de8c08766ea114e" category="list-text">最新の cnvrg Helm チャートをダウンロードするには、次のコマンドを実行します。</block>
  <block id="9b821098b02043dada6b07b924f4ef5f" category="list-text">cnvrg を導入する前に、クラスタの外部 IP アドレス、および cnvrg を導入するノードの名前が必要です。オンプレミスの Kubernetes クラスタに cnvrg を導入するには、次のコマンドを実行します。</block>
  <block id="1d1eb4e0da8bac1b4eaa79c1f0be9e04" category="list-text">「 helm install 」コマンドを実行します。すべてのサービスとシステムがクラスタに自動的にインストールされます。この処理には最大 15 分かかることがあります。</block>
  <block id="e269e5751f8883222b6d2f55da7ed811" category="list-text">「 helm install 」コマンドの所要時間は最大 10 分です。展開が完了したら、新しく展開した cnvrg の URL に移動するか、新しいクラスタを組織内のリソースとして追加します。「 helm' 」コマンドは正しい URL を通知します。</block>
  <block id="ac0cc75e8d4f0df818dd93a00041897a" category="list-text">すべてのコンテナのステータスが「 Running 」または「 Complete 」の場合、 cnvrg は正常に展開されています。次のような出力が表示されます。</block>
  <block id="3e82668da957bceb0d0c7024273ab624" category="section-title">ResNet50 および胸部 X 線を使用したコンピュータビジョンモデルトレーニング データセット</block>
  <block id="c9c734dfca60f137a58e1a5cb9c89b62" category="inline-link">NIH ダウンロードサイト</block>
  <block id="0c7f26c15912f9f5d0e0473bb21cb9a2" category="paragraph">NVIDIA DGX システムを基盤とする NetApp ONTAP AI アーキテクチャ上の Kubernetes セットアップに、 cnvrg.io AI OS が導入されました。検証には、胸部 X 線の匿名画像からなる NIH 胸部 X 線データセットを使用しました。画像は PNG 形式でした。このデータは NIH クリニカルセンタおよびによって提供された は、から使用できます<block ref="4e3f11b94ad47864cbd9c6049036ac93" category="inline-link-rx"></block>。250 GB のサンプルデータを 15 クラスの 627 、 615 イメージで使用しました。</block>
  <block id="de53b795a18176edb91a88632f621868" category="paragraph">データセットは cnvrg プラットフォームにアップロードされ、 NetApp AFF A800 ストレージシステムからの NFS エクスポートにキャッシュされました。</block>
  <block id="ec948f075c372d4beb7d19a5266f22d5" category="section-title">コンピューティングリソースをセットアップする</block>
  <block id="42af2f71dc8561eb9cfe43d45664ecb3" category="paragraph">cnvrg アーキテクチャおよびメタスケジューリング機能により、エンジニアおよび IT プロフェッショナルは、異なるコンピューティングリソースを 1 つのプラットフォームに接続できます。今回のセットアップでは、ディープラーニングワークロードの実行用に導入されたクラスタ cnvrg を使用しました。追加のクラスタを接続する必要がある場合は、次のスクリーンショットに示すように、 GUI を使用してください。</block>
  <block id="df25fca4c07e68ed339b0e1974a9d59f" category="paragraph"><block ref="df25fca4c07e68ed339b0e1974a9d59f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f541774a08fc687f6e2016c77a6ebca5" category="section-title">データをロードします</block>
  <block id="564bfd33ed32c02158989dfcee59ae89" category="paragraph">cnvrg プラットフォームにデータをアップロードするには、 GUI または cnvrg CLI を使用します。大規模なデータセットの場合は、 CLI の使用を推奨します。 CLI は、多数のファイルを処理できる、拡張性と信頼性に優れた強力なツールです。</block>
  <block id="41ad6001e0d3c17bd4a7957e18bd8bab" category="paragraph">データをアップロードするには、次の手順を実行します。</block>
  <block id="192b006166881688d04f398db712aaeb" category="inline-link">cnvrg CLI</block>
  <block id="8e9fbcfb57e26d7a14f0292c11fae122" category="list-text">をダウンロードします<block ref="d3ae4cf97b77cb5805c16205cd459ce4" category="inline-link-rx"></block>。</block>
  <block id="5cea56fcf2481a021f3d93843a22c319" category="list-text">X 線ディレクトリに移動します。</block>
  <block id="1c5a650f398227a4f97ed81accfbbb4b" category="list-text">「 cnvrg data init 」コマンドを使用して、プラットフォーム内のデータセットを初期化します。</block>
  <block id="5c48f13a3d988e0d618145098a829e3a" category="list-text">「 cnvrg data sync 」コマンドを使用して、ディレクトリのすべての内容を中央のデータレイクにアップロードします。データが中央のオブジェクトストア（ StorageGRID 、 S3 、またはその他）にアップロードされたら、 GUI で参照できます。次の図は、ロードされた胸部 X 線線維症画像 PNG ファイルを示しています。さらに、 cnvrg は、ビルドしたすべてのモデルをデータバージョンに複製できるように、データをバージョン化します。</block>
  <block id="935b6e25167b65d839bc1487ebb2fa6e" category="paragraph"><block ref="935b6e25167b65d839bc1487ebb2fa6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="308e9394a715dc64aa4e48e0054775ed" category="section-title">マッハデータ</block>
  <block id="556cde11a66a789acb7e62b934c1a88c" category="paragraph">トレーニングを高速化し、モデルのトレーニングや実験ごとに 600k 以上のファイルをダウンロードしないようにするために、データを最初に中央のデータレイクオブジェクトストアにアップロードしたあとにデータキャッシュ機能を使用しました。</block>
  <block id="3d163413cac9b6cc4726a9c83d37fed3" category="paragraph"><block ref="3d163413cac9b6cc4726a9c83d37fed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d006c100d76e7d21d64055ce3cfe6a24" category="paragraph">ユーザーが Cache をクリックすると、 cnvrg はリモートオブジェクトストアから特定のコミットでデータをダウンロードし、 ONTAP NFS ボリュームにキャッシュします。完了すると、データをすぐにトレーニングに利用できるようになります。さらに、データが数日間使用されていない場合（たとえば、モデルのトレーニングや探索など）、 cnvrg は自動的にキャッシュをクリアします。</block>
  <block id="53ad459d9bb7a65de3d1cc839b75c19f" category="section-title">キャッシュデータで ML パイプラインを構築</block>
  <block id="db226c80bcb6098ce2f47dd3982cca26" category="paragraph">cnvrg フローを使用すると、本番 ML パイプラインを簡単に構築できます。フローは柔軟性が高く、あらゆる種類の ML ユースケースに対応し、 GUI またはコードを使用して作成できます。フロー内の各コンポーネントは、異なる Docker イメージを使用して異なるコンピューティングリソース上で実行できるため、ハイブリッドクラウドを構築し、 ML パイプラインを最適化できます。</block>
  <block id="6b0eae96748d48b032362774a6467411" category="paragraph"><block ref="6b0eae96748d48b032362774a6467411" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1f18dfff2566b35d7d0e528565c43aa" category="section-title">胸部 X 線フローの構築：データの設定</block>
  <block id="adec555cb8cd4de3f288baed510d1163" category="paragraph">新しく作成したフローにデータセットを追加しました。データセットを追加する際には、特定のバージョン（ commit ）を選択し、キャッシュされたバージョンが必要かどうかを指定できます。この例では、キャッシュされたコミットを選択しました。</block>
  <block id="6dd780034ed574b328dbc16a6b485b79" category="paragraph"><block ref="6dd780034ed574b328dbc16a6b485b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13e0789c536fc18ddcdc32b4ca598b58" category="section-title">胸部 X 線フローの構築：トレーニングモデルの設定： ResNet50</block>
  <block id="fa3c48d58d8e9fd17365fd986906dd52" category="paragraph">パイプラインでは、任意の種類のカスタムコードを追加できます。cnvrg には、再利用可能な ML コンポーネントコレクションである AI ライブラリもあります。AI ライブラリには、アルゴリズム、スクリプト、データソースなど、あらゆる ML やディープラーニングフローで使用できるソリューションがあります。この例では、 ResNet50 の事前ビルドモジュールを選択しました。batch_size ： 128 、 epochs ： 10 などのデフォルトパラメータを使用しました。これらのパラメータは AI ライブラリのドキュメントで確認できます。次のスクリーンショットは、 X 線データセットが ResNet50 に接続された新しいフローを示しています。</block>
  <block id="defe5cc08faaa501eeb5fc5500664d29" category="paragraph"><block ref="defe5cc08faaa501eeb5fc5500664d29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf9bb479506589dfd719446fe3e054c7" category="section-title">ResNet50 の計算リソースを定義します</block>
  <block id="943cb3f5c7789c68e811b0accdb6c5d9" category="paragraph">cnvrg フロー内の各アルゴリズムまたはコンポーネントは、異なる Docker イメージを使用して、異なるコンピューティングインスタンス上で実行できます。セットアップでは、 NetApp ONTAP AI アーキテクチャを採用した NVIDIA DGX システムでトレーニングアルゴリズムを実行したいと考えていました。次の図では、「 GPU - REAL 」を選択しました。これは、オンプレミスクラスタのコンピューティングテンプレートであり、仕様です。また、テンプレートのキューを作成し、複数のテンプレートを選択しました。このようにして 'GPU 実数のリソースを割り当てることができない場合 ( たとえば ' 他のデータ・サイエンティストがリソースを使用している場合 ) は ' クラウド・プロバイダ・テンプレートを追加して ' 自動クラウド・バーストを有効にできます次のスクリーンショットは、 ResNet50 のコンピューティングノードとしての GPU 実数の使用を示しています。</block>
  <block id="27c8450e6f62877ec794262ae4c5a713" category="paragraph"><block ref="27c8450e6f62877ec794262ae4c5a713" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bee38713f37ae72239f6bda08384dfbb" category="section-title">結果の追跡と監視</block>
  <block id="546b7da7049f1d7fdf35cdb57fa96c7c" category="paragraph">フローが実行されると、 cnvrg はトラッキングおよびモニタリングエンジンをトリガーします。フローの各実行は自動的に文書化され、リアルタイムで更新されます。ハイパーパラメータ、指標、リソース使用率（ GPU 利用率など）、コードバージョン、アーティファクト、ログ また、次の 2 つのスクリーンショットに示すように、 ［ テスト ］ セクションで自動的に使用できるようになります。</block>
  <block id="8fabeb8b8d143d509bb92087cbbf953c" category="paragraph"><block ref="8fabeb8b8d143d509bb92087cbbf953c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdbd22304f732000189e44de22498da1" category="paragraph"><block ref="fdbd22304f732000189e44de22498da1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="254a4a0ddc892d6a01d7e7ef286fbb71" category="inline-link-macro">次は終わりです</block>
  <block id="debe391efc3dc12a7d87720a4cf068a5" category="paragraph"><block ref="debe391efc3dc12a7d87720a4cf068a5" category="inline-link-macro-rx"></block></block>
  <block id="c83553858a60514501e9751c0747dea0" category="doc">基本的な資源配分フェアネス</block>
  <block id="dc12a1ce34c0a7a264de91bc9b933a62" category="paragraph">このセクションでは 'team -d がより多くの GPU を要求した場合 ( それらは割り当ての下にあります ) ' システムは 'team -b' および 'team -c のワークロードを一時停止し ' 公正な共有方法で保留状態に移行することを示しています</block>
  <block id="ccc33823c0dc5e9ee0838a5eaa86f076" category="inline-link-macro">セクション 4.9 のテストの詳細</block>
  <block id="86bbd55ea7850716c0c192b19c86176a" category="paragraph">ジョブの送信、使用するコンテナイメージ、実行するコマンドシーケンスなどの詳細については、を参照してください <block ref="94d73a1896276f719be59227f0e93a14" category="inline-link-macro-rx"></block>。</block>
  <block id="b6ea2a2f48a443e7d027bd652ac84762" category="paragraph">次の図は、自動ロードバランシングとプリエンプティブスケジューリングにより、クラスタ使用率、チームごとに割り当てられた GPU 、保留中のジョブを示しています。すべてのチームワークロードが要求した GPU の総数が、クラスタ内で使用可能な合計 GPU 数を超えると、実行： AI の内部公正性アルゴリズムによって、「 team -b 」と「 team -c 」のそれぞれに 1 つのジョブが一時停止されます。これは、それらがプロジェクトの割り当て量を満たしているためです。これにより、クラスタ全体の利用率が向上しますが、データサイエンスチームは、管理者が設定したリソースの制約に基づいて引き続き作業できます。</block>
  <block id="d1a54cf8cb2a06c0715d2f042fbf44bd" category="paragraph"><block ref="d1a54cf8cb2a06c0715d2f042fbf44bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d52816ece2166f7a2e0eadf58d617df9" category="paragraph">このテストシナリオの結果は、次のことを示しています。</block>
  <block id="bce83ec0a92a5b10380007a1643b2fd0" category="list-text">* 自動ロードバランシング。 * システムは、各チームが割り当てを使用するように GPU の割り当て量を自動的に調整します。一時停止されていたワークロードは、そのクォータを超えていたチームに属しています。</block>
  <block id="f8be0d1ca354f8cb4aaa4c8aadcea80b" category="list-text">* 公正な共有の一時停止。 * システムは、ノルマを達成したチームのワークロードを停止してから、もう一方のチームのワークロードを停止します。実行： AI には内部的な公正性アルゴリズムがあります。</block>
  <block id="c088b6e407ba7f9c0274382acfa3eae0" category="inline-link-macro">次の例では、過剰割り当て（ over-Quota Fairness ）</block>
  <block id="8e015e1b989b11d70fcb778747b8c614" category="paragraph"><block ref="8e015e1b989b11d70fcb778747b8c614" category="inline-link-macro-rx"></block></block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">まとめ</block>
  <block id="4ac9fa791a6d1c7c97bbae134dd22586" category="paragraph">真の会話型 AI システムは、人間のような対話を行い、文脈を理解し、インテリジェントな応答を提供します。このような AI モデルは、多くの場合、巨大で非常に複雑です。NVIDIA GPU とネットアップストレージを使用することで、最新の大規模な言語モデルをトレーニングし、最適化して推論を迅速に実行できます。これは、大規模で複雑な AI モデルと比べて高速な AI モデルのトレードオフを終えるための大きなストライドです。GPU に最適化された言語理解モデルは、医療、小売、金融サービスなどの業界向け AI アプリケーションに統合でき、高度なデジタル音声アシスタントをスマートスピーカーやカスタマーサービスラインに搭載できます。これらの高品質な会話型 AI システムにより、さまざまな業種の企業が、お客様との取引においてこれまで達成できなかったパーソナライズされたサービスを提供できます。</block>
  <block id="45d5663acc501eba25058f8956035e9a" category="paragraph">Jarvis は、バーチャルアシスタント、デジタルアバター、マルチモーダルセンサー Fusion （ ASR/NLP/TTS とフュージョンされた CV ）、または ASR/NLP/TTS/CV スタンドアロンの使用例（転写など）の導入を可能にします。私たちは、天気、関心のあるポイント、在庫価格に関する回答の質問を行えるバーチャル小売アシスタントを開発しました。また、 Cloud Sync を使用して会話履歴をアーカイブし、 Nemo モデルを新しいデータにトレーニングすることで、会話型 AI システムの自然言語理解能力を向上させる方法についても説明しました。</block>
  <block id="c6a4d485e7c4cefa4c121ce6c59b28dc" category="inline-link-macro">次：謝辞</block>
  <block id="38a609a97a676f2cc28ccec3d3097d4b" category="paragraph"><block ref="38a609a97a676f2cc28ccec3d3097d4b" category="inline-link-macro-rx"></block></block>
  <block id="1d91c2c04b7f73cb59edb799d095c75c" category="paragraph">このホワイトペーパーでは、 NVIDIA Jarvis フレームワークを使用して会話型人工知能（ AI ）ソリューションを構築し、小売業などのユースケース向けに NetApp ONTAP AI および Cloud Sync を使用しているお客様向けのガイドラインを紹介します。このガイドには、バーチャルアシスタント用の自然言語処理（ NLP ）モデルの開発に使用される高レベルのワークフロー、検証済みのテストケース、および結果に関する情報が含まれています。</block>
  <block id="4c2588a1e3dbf6824a4f05095df75f83" category="paragraph">今日のアプリケーションはどれも AI 主導ではありませんが、 AI の大きなメリットにアクセスできるように進化を続けています。AI の導入をサポートするには、アプリケーションに最適なレベルで機能し、継続的な進化をサポートするために必要なリソースを提供するインフラが必要です。</block>
  <block id="31965de7c735983bb41a0b7e70361db2" category="paragraph">AI ベースのアプリケーションの場合、エッジの場所はデータの主要なソースとして機能します。利用可能なデータは、一定期間にわたって複数のエッジから収集したトレーニングに使用して、トレーニングデータセットを形成できます。その後、トレーニング済みモデルを、データが収集されたエッジに導入して戻すことで、本番環境のデータを専用の推論プラットフォームに繰り返し転送することなく高速な推論を実現できます。</block>
  <block id="9e53c147a93fed13d4349cba2a35e36b" category="paragraph">ネットアップと NVIDIA は、 NVIDIA T4 GPU およびネットアップのクラウド対応ストレージシステムを搭載した NetApp H615c コンピューティングノードを基盤とする NetApp HCI AI 推論解決策を開発および検証しました。NetApp HCI は、あいまいさの範囲に対処し、設計の複雑さを排除し、推測に基づく作業を排除することで、エッジデータセンターでの AI 推論ソリューションの導入を簡易化します。この解決策は、 IT 組織に次のような規範的アーキテクチャを提供します。</block>
  <block id="9c4a53996590c74a0de3bba81f878254" category="list-text">エッジデータセンターで AI 推論を実行できます</block>
  <block id="20c3f996d396cc8c92788bb3585a6e86" category="list-text">GPU リソースの消費を最適化します</block>
  <block id="06e81c54cb9157aa59541289f1163daf" category="list-text">Kubernetes ベースの推論プラットフォームを提供し、柔軟性と拡張性を実現します</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">設計の複雑さを解消</block>
  <block id="ba37c372c4a9119e45c7f525f4743cfc" category="paragraph">エッジデータセンターでは、生成ポイントに非常に近い場所でデータを管理および処理します。このように近接することで、効率が向上し、データの処理に関連するレイテンシが低減します。多くの業種では、エッジデータセンターのメリットが認識されており、この分散型アプローチを採用するデータ処理が多用されています。</block>
  <block id="b501a0f0a3e7d559cecfad08c330227e" category="paragraph">次の表に、エッジの垂直市場とアプリケーションを示します。</block>
  <block id="06ce2a25e5d12c166a36f654dbea6012" category="cell">垂直（ Vertical ）</block>
  <block id="077262cc53a1fb1b5f651d31b6bf81ba" category="cell">医療</block>
  <block id="9da98fbc1c3d290fefb743a2df8914b4" category="cell">コンピュータ支援診断は、医療スタッフによる早期疾患検出を支援します</block>
  <block id="fa0a7aa1622ad105e9cdf5a706058333" category="cell">石油およびガス</block>
  <block id="55dae4e2e7f267e43e5768e66c7c3771" category="cell">遠隔地の生産施設、ビデオ、画像分析の自動検査</block>
  <block id="252ddb15657f2c60bddc73633a7bf8c0" category="cell">航空</block>
  <block id="7a84f6faf76fd3533ae6ca65d28c53eb" category="cell">エアトラフィック制御支援とリアルタイムビデオフィード分析</block>
  <block id="81ea9456adf225bcf11b668b427fd4f2" category="cell">メディアとエンターテイメント</block>
  <block id="5015819e58d425b19f8acc93866e76fa" category="cell">音声 / ビデオコンテンツフィルタリングにより、家族向けのコンテンツを提供します</block>
  <block id="616e90f12cb95950bc1c75396902393a" category="cell">ビジネス分析</block>
  <block id="3e4c06851690089d4952320e9df36dc2" category="cell">テレビ番組のライブ配信イベントでブランドの外観を分析するためのブランド認知</block>
  <block id="a9f7ecebb493e129aafb4cbfd73e85df" category="cell">E コマース</block>
  <block id="5df4fc692c9317012855d6935bf10310" category="cell">理想的な商人およびを見つけるための供給のスマートなバンドル 倉庫の組み合わせ</block>
  <block id="053e0bc8b9627b28e2ed8029a34b35bd" category="cell">小売</block>
  <block id="7cf7816e39e6e0c259a79dc29c5a5e7c" category="cell">自動チェックアウトにより、お客様がカートに入れたアイテムを認識します デジタル決済を促進します</block>
  <block id="165f5687ea9050fba239731810d0abe8" category="cell">スマートシティ</block>
  <block id="a47b360ffbe39c5a39c7e12e2ae8fdf5" category="cell">交通の流れを改善し、駐車を最適化し、歩行者と自転車の安全性を高めます</block>
  <block id="e86883c7cfc07afcf1e5ad8dffd7e1cc" category="cell">製造</block>
  <block id="f4d790a35097fa97c2687ac573b25338" category="cell">品質管理、組み立てラインの監視、欠陥の識別</block>
  <block id="2273d1167a6212812d95dc8fadbae78e" category="cell">カスタマーサービス</block>
  <block id="bf4948e47ea0d77a86e639979879262d" category="cell">カスタマーサービスの自動化による問い合わせの分析と優先順位付け（電話、 E メール、ソーシャルメディア）</block>
  <block id="8e54e9aa508ea37f7fe734e86ba9da27" category="cell">農業</block>
  <block id="7fb956270d49b22c3226bc1db2b0269f" category="cell">肥料や除草剤の使用を最適化するための、農場の運用と活動計画のインテリジェント化</block>
  <block id="3190a811a89bc9da4384152bc43d1b94" category="section-title">対象読者</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">解決策の対象となるグループは次のとおりです。</block>
  <block id="134481f7bea652a34fa2ada120d250e5" category="list-text">データサイエンティスト</block>
  <block id="8d26f0555c7ace3d4b297da8c12fb31b" category="list-text">IT アーキテクト</block>
  <block id="c114d2813b0041352b49187ebc28b62b" category="list-text">フィールドコンサルタント</block>
  <block id="2d6d0cc18609f97853f883c1891397d2" category="list-text">プロフェッショナルサービス</block>
  <block id="467f739adb5605167109d76676b44696" category="list-text">IT マネージャ</block>
  <block id="dcfa1c08d3b0126217af0b8690305c08" category="list-text">IT のイノベーションをもたらすインフラを必要としている他のユーザ エッジに配置された堅牢なデータサービスとアプリケーションサービス</block>
  <block id="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="paragraph"><block ref="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="inline-link-macro-rx"></block></block>
  <block id="3bb420314fa4b29837c4b0528524000f" category="doc">NetApp ONTAP AI と AI のコントロールプレーン</block>
  <block id="1b85c0e7f381bd6f8c3150cafe56a9f0" category="paragraph">NVIDIA DGX システムとネットアップのクラウド対応ストレージシステムを基盤とする NetApp ONTAP AI アーキテクチャこのリファレンスアーキテクチャには、 IT 組織に次のようなメリットがあります。</block>
  <block id="5116c5071beb9f4f5b673c988c417c71" category="list-text">コンピューティングとストレージを個別に拡張できます</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">小規模構成から始めて、シームレスに拡張できます</block>
  <block id="bae698d3cdcc290d6a0048c7b786446c" category="list-text">さまざまなパフォーマンスとコストポイントに対応する幅広いストレージオプションを提供 NetApp ONTAP AI は、 DGX システムと NetApp AFF A800 ストレージシステムを最先端のネットワーク機能と緊密に統合します。NetApp ONTAP AI システムと DGX システムでは、設計の複雑さと推測に頼らず、 AI 導入を簡易化できます。お客様は小規模構成から始めて、システムを中断なく拡張できます。同時に、エッジ、コア、クラウドにわたってデータをインテリジェントに管理できます。</block>
  <block id="c729dcbcad9e1c72ae15d4b823e9f311" category="paragraph">ネットアップの AI コントロールプレーンは、データサイエンティストとデータエンジニアを対象とした、フルスタックの AI 、 ML 、ディープラーニング（ DL ）のデータと実験管理解決策です。AI の利用が拡大するにつれて、ワークロードの拡張性やデータの可用性など、さまざまな課題が生じています。NetApp AI コントロールプレーンは、データネームスペースの迅速なクローニングなどの機能を通じて、これらの課題に対処します。たとえば、 Git リポジトリをはじめ、トレーサビリティとバージョン管理のためにデータやモデルのベースラインをほぼ瞬時に作成する AI トレーニングワークフローを定義および実装します。NetApp AI コントロールプレーンを使用すると、サイトやリージョン間でデータをシームレスにレプリケートし、 Jupyter Notebook ワークスペースをすばやくプロビジョニングして、大規模なデータセットにアクセスできます。</block>
  <block id="42cac0fcbbddfc99b31ff898d7902c83" category="inline-link-macro">次のステップ： AI ワークロードのオーケストレーション向けの AI プラットフォームを実行</block>
  <block id="e3683938a3c34e6a7cf5b3896258e91e" category="paragraph"><block ref="a8dcbc617641d20db42fd66f3a42caae" category="inline-link-macro-rx"></block>。</block>
  <block id="6b4330df9a37bcfef1faecd1e8973464" category="inline-link-macro">オーバークォータフェアネス</block>
  <block id="5648f06cc2dff861e557e088190ccbe2" category="paragraph">を参照してください <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>および <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>また、高度なテストシナリオを考案し、複雑なワークロード管理、自動プリエンプティブスケジューリング、オーバークォータ GPU プロビジョニングを実現する Run ： AI オーケストレーション機能をデモしました。これにより、 ONTAP AI 環境でクラスタリソースの利用率を高め、エンタープライズレベルのデータサイエンスチームの生産性を最適化できました。</block>
  <block id="fed09193953a2a2d15bfba4063981f8c" category="paragraph">これらの 3 つのセクションで、次のプロジェクトとクォータを設定します。</block>
  <block id="d2d5c3e087f684e56b5b81d6212d7ccb" category="cell">クォータ</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8.</block>
  <block id="207b738b6cd0e1cf6ac4a405dc72102f" category="paragraph">また、この 3 つのセクションでは、次のコンテナを使用します。</block>
  <block id="cc6f12794ea24a191cb4f699f1b95036" category="list-text">Jupyter Notebook ： "jupyter/base-notebook</block>
  <block id="b8d0bb7e356bfdd7e018a7c62f9343fa" category="list-text">「 GCR.IO/run-ai-demo/QuickStart 」を実行します</block>
  <block id="c9582d103b2fe8050364d3e629c4e80e" category="paragraph">このテストシナリオでは、次の目標を設定します。</block>
  <block id="c2d51205301247cd0aa0eca284d3889b" category="list-text">リソースのプロビジョニングの簡易性と、リソースの使用方法を説明します ユーザから抽象化されます</block>
  <block id="dfd4af458e74e30246827532e692dca7" category="list-text">ユーザが GPU のフラクションを簡単にプロビジョニングする方法を説明します GPU の数を整数で指定します</block>
  <block id="d7bf7c7f0d7884bd8fe07da4f6a8aba3" category="list-text">チームを編成してコンピューティングのボトルネックを解消する方法を説明します リソースクォータがある場合は、ユーザがそのリソースクォータを確認します クラスタ内に GPU が搭載されている</block>
  <block id="f93609e9c7f7c826e6c83bb1f8416207" category="list-text">ネットアップコンテナなどの大量の計算処理を行うジョブを実行する際に、 NetApp 解決策を使用してデータパイプラインのボトルネックを解消する方法を説明する</block>
  <block id="8ac218f5a62c8021756a192ac737a7f2" category="list-text">を使用して複数のタイプのコンテナを実行する方法を説明します システム</block>
  <block id="802125395813e0bec35472d0403ab94e" category="list-text">Jupyter ノートブック</block>
  <block id="91c4a4ef606f959264719f8d084aab0e" category="list-text">実行： AI コンテナ</block>
  <block id="23edbe937c996eb973ab4c69f9648893" category="list-text">クラスタがフルの状態のときに高い利用率を表示します</block>
  <block id="815a27a2c38741e36d920cbea5587384" category="paragraph">テスト中に実行される実際のコマンドシーケンスの詳細については、を参照してください <block ref="3a65193f11bb9f699d19b0e9a996cd93" category="inline-link-macro-rx"></block>。</block>
  <block id="9d020ce52f8e9ff0d2f2defe3942d660" category="paragraph">13 個のワークロードすべてが送信されると、次の図に示すように、コンテナ名と割り当てられている GPU のリストが表示されます。7 つのトレーニングと 6 つの対話型ジョブが用意されており、 4 つのデータサイエンスチームをシミュレーションして、それぞれに独自のモデルを実行しているか開発中であるかを確認していますインタラクティブなジョブの場合、個々の開発者は Jupyter Notebook を使用してコードの書き込みやデバッグを行っています。そのため、クラスタリソースをあまり使用せずに GPU フラクションをプロビジョニングすることをお勧めします。</block>
  <block id="5deafc9e56279ca519f1e3c351856aa8" category="paragraph"><block ref="5deafc9e56279ca519f1e3c351856aa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa04853a58b1b9ab0033c7e24b9d929" category="paragraph">このテストシナリオの結果は次のようになります。</block>
  <block id="dbaf41fcdcf0aa8cd93bfdf0e7f916f2" category="list-text">クラスタがいっぱいである必要があります。 16 基の GPU が使用されています。</block>
  <block id="25421e793bda820f3023762c547a2495" category="list-text">クラスタの利用率が高い。</block>
  <block id="fdf3de6e0502b5404d2e0b379421f759" category="list-text">フラクショナル割り当てにより、 GPU よりも多くの実験が行われています。</block>
  <block id="68cf93a70e0f0fe62bc0428ce8a8b348" category="list-text">「 team -d 」では、すべてのクォータが使用されているわけではありません。したがって、「 team -b 」と「 team -c 」では、実験に追加の GPU を使用することができるため、イノベーションにかかる時間が短縮されます。</block>
  <block id="9083e59932e59a6f85524ab956fcf772" category="inline-link-macro">次は、基本的な資源配分フェアネスです</block>
  <block id="654c44d69d64b0a5a656dd7b1375ac03" category="paragraph"><block ref="654c44d69d64b0a5a656dd7b1375ac03" category="inline-link-macro-rx"></block></block>
  <block id="39cf3ca3e5dbe56d6eade7cbe3cc40e6" category="doc">例： Kubeflow の操作とタスク</block>
  <block id="e40030fd64108859627c7a126638f0e6" category="list-text">NetApp AI コントロールプレーン：</block>
  <block id="63178726ae501745b3914ec3aa50969e" category="list-text">ネットアップの AI コントロールプレーンテクニカルレポートでご確認ください</block>
  <block id="3ce56c027572d1908d65b63056be024f" category="inline-link"><block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="445a4d3400bdde832e8898d8349696c0" category="paragraph"><block ref="445a4d3400bdde832e8898d8349696c0" category="inline-link-rx"></block></block>
  <block id="9a8ec45d909b996af4c042e44b5c5f29" category="list-text">TensorFlow ：あらゆる環境に対応するオープンソースの機械学習フレームワーク<block ref="db3465122fd83ad1dc4cff7e67d794df" category="inline-link-rx"></block></block>
  <block id="3bc4d41311862190a8fd0d6c8f661971" category="list-text">Iguazio データサイエンスプラットフォーム</block>
  <block id="737d4d1e81ff236001338f46d1623aaa" category="list-text">Iguazio Data Science Platform のドキュメント</block>
  <block id="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link"><block ref="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link-rx"></block></block>
  <block id="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="paragraph"><block ref="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="inline-link-rx"></block></block>
  <block id="4f0f362becf6baf6e08f490115d76d98" category="list-text">Nuclio サーバーレス関数</block>
  <block id="89aa84cdf5db1bece2993801c78914de" category="inline-link"><block ref="89aa84cdf5db1bece2993801c78914de" category="inline-link-rx"></block></block>
  <block id="93eac034cc1c1aaedaf6ed41063825ee" category="paragraph"><block ref="93eac034cc1c1aaedaf6ed41063825ee" category="inline-link-rx"></block></block>
  <block id="b5266d58998338015b5e02ee7e84a833" category="list-text">MLRun オープンソースパイプラインオーケストレーションフレームワーク</block>
  <block id="b96a861dccea968edc0b7a9ff96203e9" category="inline-link"><block ref="b96a861dccea968edc0b7a9ff96203e9" category="inline-link-rx"></block></block>
  <block id="70a8a001358e056f435199da7e17e427" category="paragraph"><block ref="70a8a001358e056f435199da7e17e427" category="inline-link-rx"></block></block>
  <block id="b3f90aaddad391963c2090db8f1b727e" category="list-text">NVIDIA DGX-1 システム</block>
  <block id="d6a377b23d0f4dbe3f5bf91d5f6abf74" category="list-text">NVIDIA Tesla V100 Tensor コア GPU</block>
  <block id="0df7621d860637a2e6e462c56322edab" category="list-text">NVIDIA GPU Cloud</block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="list-text">NetApp AFF システム</block>
  <block id="5f662f6dc276dd5a2a83440d0fe63e9b" category="list-text">AFF 向けのネットアップのフラッシュソリューションの利点</block>
  <block id="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link"><block ref="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link-rx"></block></block>
  <block id="a5d59e86f09bafae4247836d5135b6a3" category="paragraph"><block ref="a5d59e86f09bafae4247836d5135b6a3" category="inline-link-rx"></block></block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="list-text">NetApp ONTAP AI</block>
  <block id="47c991332229e0cbfe947beaa428ea61" category="list-text">DGX-1 と Cisco Networking Design Guide による ONTAP AI</block>
  <block id="b141781260425e95eee945147e2f0d99" category="inline-link"><block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="9fbee18519e76388280bc1f8e3fd6c7e" category="paragraph"><block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="0be3b0697a0ffdfe9065df24ec1d3e16" category="list-text">DGX-1 と Cisco Networking Deployment Guide を使用した ONTAP AI</block>
  <block id="921f17c41dea89b0a711f380e9864e09" category="inline-link"><block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="aef3d0752148699921f8a251537d5ff3" category="paragraph"><block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="205a4f16a51f3acd6dbba76dbeb10818" category="list-text">DGX-1 と Mellanox のネットワーキング設計ガイドで構成される ONTAP AI</block>
  <block id="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link"><block ref="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link-rx"></block></block>
  <block id="0a9e1455c4a5a9965867a5efd6b8cc9b" category="paragraph"><block ref="0a9e1455c4a5a9965867a5efd6b8cc9b" category="inline-link-rx"></block></block>
  <block id="913c29df09bcb5715ed7a48c12f3a0da" category="list-text">ONTAP AI ネットワーク</block>
  <block id="ae2703e9b1dff6da048c786142c2e7db" category="list-text">Cisco Nexus 3232C シリーズスイッチ</block>
  <block id="8a27a2062df55e0aa73964ea8ec2ab55" category="list-text">Mellanox Scale-out SN2000 イーサネットスイッチシリーズ</block>
  <block id="87a849c2f3c412a491f97674d5e27ed1" category="inline-link"><block ref="fd77c1cd25d650110f7047fa02f8327d" category="inline-link-rx"></block></block>
  <block id="a6c16c720941d75800533dedd69929cc" category="paragraph"><block ref="ad90d1952f7d0f85370461937e4484b7" category="inline-link-rx"></block></block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="doc">新しいボリュームをプロビジョニングします</block>
  <block id="117bdbda976fe8b3212bc3b6327a0a1b" category="list-text">Cloud Volumes ONTAP</block>
  <block id="7450cfde7058dc5e1f7909d0280fd7ae" category="list-text">Azure NetApp Files の特長</block>
  <block id="337f05fad2de58e4a8b74cb25536b52d" category="doc">セットアップの概要</block>
  <block id="666f45aef7a28ef5ba6e4bfb2f71bcee" category="section-title">Iguazio の取り付け</block>
  <block id="b681b0e4b3576aa1cd854e2b66c16dcd" category="paragraph">Iguazio は、オンプレミスまたはクラウドプロバイダにインストールできます。プロビジョニングはサービスとして実行でき、 Iguazio またはお客様による管理が可能です。どちらの場合も、 Iguazio はクラスタの導入と管理に使用する導入アプリケーション（ Provazio ）を提供します。</block>
  <block id="3b31e2e4387e938056251a113831e6da" category="inline-link">NVA-1121.</block>
  <block id="8334797b9b3383d4f48d98178b8845ea" category="inline-link">このページです</block>
  <block id="ade8a7efee71036d2ca57676a54b31e3" category="paragraph">オンプレミスでのインストールについては、を参照してください<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> コンピューティング、ネットワーク、ストレージのセットアップに使用できます。イグアスのオンプレミス導入は、顧客に追加料金なしで提供されます。を参照してください<block ref="d273dd0a16e6003b56381a70823807f7" category="inline-link-rx"></block> DNS サーバおよび SMTP サーバの設定Provazio のインストールページは次のとおりです。</block>
  <block id="8e72dced5918c4009ff80044ba6f44db" category="paragraph"><block ref="8e72dced5918c4009ff80044ba6f44db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c16d8d5e717cd029389f76abddf769b7" category="inline-link-macro">次： Kubernetes クラスタの設定</block>
  <block id="1d42e0b2a8893ff00a35554162554936" category="paragraph"><block ref="1d42e0b2a8893ff00a35554162554936" category="inline-link-macro-rx"></block></block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">詳細</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="cell">NFS</block>
  <block id="ed4a202c34987f40d5e245e76a65a243" category="paragraph">次の図は、提案された会話型 AI システムアーキテクチャを示しています。システムは、音声信号またはテキスト入力で操作できます。音声入力が検出された場合、 Jarvis As-as-a-Service （ AIaaS ）は ASR を実行して、 Dialog Manager 用のテキストを生成します。Dialog Manager は、会話の状態を記憶し、テキストを対応するサービスにルーティングし、 Fulfillment Engine にコマンドを渡します。Jarvis NLP サービスは、テキストを受け取り、インテントとエンティティを認識し、それらのインテントとエンティティスロットをダイアログマネージャーに出力します。ダイアログマネージャーは、アクションをフルフィルメントエンジンに送信します。フルフィルメントエンジンは、回答ユーザーが照会するサードパーティ API または SQL データベースで構成されています。フルフィルメントエンジンから結果を受け取った後、 Dialog Manager はテキストを Jarvis TTS AIaaS にルーティングして、エンドユーザーの音声応答を生成します。NLP サービスがシステムとの対話をより多くのユーザが行うように改善されるように、会話履歴をアーカイブし、インテントや Nemo トレーニング用のスロットに注釈を付けることができます。</block>
  <block id="308a0722262fbc3adde5d5d900ad0c36" category="paragraph"><block ref="308a0722262fbc3adde5d5d900ad0c36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="863eef2617ffc374c485389aabdd8a24" category="paragraph">この解決策は、 1 台の DGX ステーションと 1 台の AFF A220 ストレージシステムで検証済みです。Jarvis では、ディープニューラルネットワークの計算に T4 GPU または V100 GPU のいずれかが必要です。</block>
  <block id="6c4fbfa85e86ba1acd8a66b367a3b2c4" category="paragraph">次の表に、テストで解決策を実装するために必要なハードウェアコンポーネントを示します。</block>
  <block id="71c9e70899509bff35197ba9da10dafc" category="cell">T4 または V100 GPU</block>
  <block id="8f452959667e7665cddf2484ddca1724" category="cell">NVIDIA DGX ステーション</block>
  <block id="f7a05af899e536cde0a9c8476c2da0a1" category="paragraph">次の表に、テストで解決策を実装するために必要なソフトウェアコンポーネントを示します。</block>
  <block id="5acec1d6c6e07042eb0c19bc926d2633" category="cell">バージョンまたはその他の情報</block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="cell">NetApp ONTAP データ管理ソフトウェア</block>
  <block id="eaf2f97729e8d5e4d205672da8afc9a5" category="cell">9.6</block>
  <block id="efdec37786e687a58664ebd4ef6bdba4" category="cell">Cisco NX-OS スイッチのファームウェア</block>
  <block id="976d6c35e21478ef03ca2cec2a74dc71" category="cell">7.0 （ 3 ） I6 （ 1 ）</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">NVIDIA DGX OS</block>
  <block id="4a5be8fea83a32ad5c7fc31b02ef1028" category="cell">4.0.4 - Ubuntu 18.04 LTS</block>
  <block id="0664d9eb73230b2a0b514b0facae8ade" category="cell">NVIDIA Jarvis フレームワーク</block>
  <block id="cc5f21cb121669006a19c9fde049f048" category="cell">EA v0.2 の 1 つです</block>
  <block id="dfcc0491fc5a6e738ca8b5ef3a258093" category="cell">NVIDIA Nemo</block>
  <block id="317fe32bf712dffb43ddc0ee8dde8c3c" category="cell">nvcr.io/nvidia / Nemo ： v0.10</block>
  <block id="44769dc982b2126503d2d014bcf7c15a" category="cell">Docker コンテナプラットフォーム</block>
  <block id="0cc9a8e76e0a79d0e0072e0a0d675fe5" category="cell">18.06.1-CE [e68fc7a]</block>
  <block id="3032d0de2852f0bb1e13142c2c47cd5b" category="inline-link-macro">次の例： Jarvis 、 Cloud Sync 、 Nemo の概要を使用して仮想アシスタントを構築します</block>
  <block id="5cefb81f0324c44ec13c02fa7700924b" category="paragraph"><block ref="5cefb81f0324c44ec13c02fa7700924b" category="inline-link-macro-rx"></block></block>
  <block id="9783bbad26249ed7f40d89e12ba42020" category="doc">実行： AI ワークロードのオーケストレーション向けの AI プラットフォーム</block>
  <block id="cb39fb629a91fdf37928a15d38e05318" category="list-text">イノベーションにかかる時間を短縮使用方法： AI リソースのプール化、キューイング、優先付けのメカニズムをネットアップストレージシステムと組み合わせることで、インフラ管理の面倒な作業から研究者を排除し、データサイエンスに専念させることができます。実行： AI とネットアップのお客様は、コンピューティングやデータパイプラインのボトルネックを発生させることなく、必要な数のワークロードを実行することで生産性を向上できます。</block>
  <block id="8df86cf2931aab70fd9ad1f919f40449" category="list-text">チームの生産性の向上。実行： AI 公正性アルゴリズムは、すべてのユーザとチームが公平なリソースを獲得できることを保証します。優先度の高いプロジェクトを中心としたポリシーをあらかじめ設定しておくことで、あるユーザチームから別のユーザチームへリソースを動的に割り当てることができ、ユーザが切望された GPU リソースにタイムリーにアクセスできるようになります。</block>
  <block id="c835378d4be1896f62ef5d2760340909" category="list-text">GPU 利用率の向上：Run ： AI スケジューラを使用すると、 Kubernetes での分散トレーニング用に、フラクショナルな GPU 、整数型 GPU 、複数の GPU ノードを簡単に利用できます。このように、 AI ワークロードは容量ではなくニーズに基づいて実行されます。データサイエンスチームは、 1 つのインフラでより多くの AI 実験を実行できるようになりました。</block>
  <block id="5960deb1522a82336a7a31213acea4b0" category="inline-link-macro">次は、解決策テクノロジです</block>
  <block id="dde440f8f7c47863e65c2d82a820b8a5" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block>。</block>
  <block id="fa752e98365b630341b8478c89a6757f" category="doc">Kubernetes クラスタを設定しています</block>
  <block id="f12c340e651d989970371432778f9be2" category="paragraph">このセクションは、クラウドとオンプレミスのそれぞれの導入について、 2 つの部分に分かれています。</block>
  <block id="ee06675a624f2ec74e8b71b5a57f8f9e" category="section-title">Cloud Deployment Kubernetes Configuration を参照してください</block>
  <block id="b513a0297a0d2efdebed8ce18e2f1715" category="paragraph">NetApp Cloud Manager を使用して、イグアス Kubernetes クラスタへの接続を定義できます。Trident では、ボリュームを使用できるようにするために、クラスタ内の複数のリソースにアクセスする必要があります。</block>
  <block id="2d5bc331cc722113dd483838e908804c" category="list-text">アクセスを有効にするには、 1 つの Iguazio ノードから Kubernetes 構成ファイルを取得します。ファイルは、「 /home/Iguazio/.kube/config. 」の下にあります このファイルをデスクトップにダウンロードします。</block>
  <block id="17c6b0de5b91c5c06a0d8173c89110d8" category="list-text">設定するクラスタの検出に進みます。</block>
  <block id="df37cca51036f4c5b59db211df5354bc" category="paragraph"><block ref="df37cca51036f4c5b59db211df5354bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b848e07dc3f62b4307419421d844f123" category="list-text">Kubernetes 構成ファイルをアップロードします。次の図を参照してください。</block>
  <block id="5bcc42d0a2624f1586064488c3484529" category="paragraph"><block ref="5bcc42d0a2624f1586064488c3484529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63de24a45facebf9f65cb6578847f2b4" category="list-text">Trident を導入し、ボリュームをクラスタに関連付けます。Iguazio クラスタへの持続ボリュームの定義と割り当てについては、次の図を参照してください。このプロセスにより、 Iguazio の Kubernetes クラスタに永続ボリューム（ PV ）が作成されます。使用する前に、永続的ボリューム要求（ PVC ）を定義する必要があります。</block>
  <block id="eee185b539f0e52d8b64916066463222" category="paragraph"><block ref="eee185b539f0e52d8b64916066463222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8b69025b2efa1b2ccb917bc911d30ccd" category="section-title">オンプレミス導入の Kubernetes 構成</block>
  <block id="31bbf80f0649d07d3e8340123f1a6963" category="inline-link">TR-4798</block>
  <block id="5be8900878997a404baf02b07ff271c6" category="paragraph">NetApp Trident のオンプレミスインストールについては、を参照してください<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> を参照してください。Kubernetes クラスタを設定して NetApp Trident をインストールしたら、 Trident を Iguazio クラスタに接続して、データやモデルの Snapshot コピーの作成などのネットアップのデータ管理機能を利用できます。</block>
  <block id="50af1dc10d66589053fc82292fe61444" category="inline-link-macro">次のステップ：永続的ボリューム要求を定義します</block>
  <block id="bb0c0300eb362a15d2d6480d832ecfbe" category="paragraph"><block ref="bb0c0300eb362a15d2d6480d832ecfbe" category="inline-link-macro-rx"></block></block>
  <block id="677b450634b1a6a563206526cb4d9075" category="doc">TR-4858 ：『 NetApp Orchestration 解決策 with Run ： AI 』</block>
  <block id="0959ee1db60e15d1e8e42d1206ca6a19" category="paragraph">ネットアップの Yaron Goldberg 、 Run ： AI 、 David Arnette 、 Sung-Han Lin</block>
  <block id="c87cafeb37457343ef978bbf8cad88b5" category="paragraph">NetApp AFF ストレージシステムは、卓越したパフォーマンスと業界をリードするハイブリッドクラウドデータ管理機能を提供します。ネットアップと Run ： AI は、 NetApp ONTAP AI 解決策の独自の機能である人工知能（ AI ）と機械学習（ ML ）のワークロードに対応し、エンタープライズクラスのパフォーマンス、信頼性、サポートを提供していることを実証するために提携しました。実行： AI ワークロードの AI オーケストレーションにより、 Kubernetes ベースのスケジュールとリソース利用プラットフォームが追加され、研究者が GPU 利用率を管理、最適化できるようになります。ネットアップ、 NVIDIA 、 Run ： AI の解決策を組み合わせた NVIDIA DGX システムは、エンタープライズ AI ワークロードに特化したインフラスタックを提供します。このテクニカルレポートでは、さまざまなユースケースや業種に対応した会話型 AI システムを構築するお客様向けのガイダンスを提供します。Run の導入に関する情報、 AI と NetApp AFF A800 ストレージシステムが記載されています。 AI イニシアチブを短期間で成功に導くためのリファレンスアーキテクチャとして機能します。</block>
  <block id="cae36004793b7131e0fc2323f598e7bb" category="list-text">AI 開発のためのソリューションを設計するエンタープライズアーキテクト コンテナ化などの Kubernetes ベースのユースケース向けのモデルとソフトウェア マイクロサービス</block>
  <block id="5d138e1f42e31fb645a3e3f5a8d37929" category="list-text">データサイエンティストは、効率的なモデルを実現するための効率的な方法を探しています 複数のチームとで構成されるクラスタ環境における開発目標 プロジェクト</block>
  <block id="0d43a0c7aeec219a746e836746c0b208" category="list-text">本番モデルの保守と実行を担当するデータエンジニア</block>
  <block id="00d764d2e91381a99d6f2c7b108e7c8e" category="list-text">エグゼクティブや IT の意思決定者、ビジネスリーダー Kubernetes クラスタのリソース利用率を最適化する方法をご確認ください AI 導入の市場投入までの時間を短縮できます</block>
  <block id="7a83f363d45e73d7915a600e1bbc92ba" category="inline-link-macro">次の手順：解決策の概要</block>
  <block id="29d90e44a805022079f5ad8bc748f89f" category="paragraph"><block ref="29d90e44a805022079f5ad8bc748f89f" category="inline-link-macro-rx"></block></block>
  <block id="6631bf64346739a9880a9789a941a8d6" category="inline-link-macro">ONTAP AI 導入向けの Kubernetes StorageClasses の例</block>
  <block id="01360221b637a04fa184dc6b9355fa46" category="summary">この解決策の作成の一環として、パフォーマンスを簡単に比較しました。ネットアップの標準的なベンチマークジョブをいくつか実行しましたが、 Kubernetes を使用して実行した場合と、ベンチマークの結果を単純な Docker run コマンドを使用して実行した場合を比較しました。</block>
  <block id="0e2f0f77407bfd956f621e13b8c1be34" category="doc">パフォーマンステスト</block>
  <block id="74575b23d5305310e904f87eb02ff980" category="cell">ベンチマーク</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">データセット</block>
  <block id="c269688995d2959579fca276425898b8" category="cell">Docker Run （イメージ / 秒）</block>
  <block id="b3acbf223e2bb7a3a796e3b698a7748d" category="cell">Kubernetes （画像 / 秒）</block>
  <block id="6de4dbc350a60fb9d5ea80ac7854681d" category="cell">シングルノード TensorFlow</block>
  <block id="2ec7cdace40d8a092e842288dfe854f7" category="cell">統合データ</block>
  <block id="a5ee9f5535788c17b947b7f2d8354351" category="cell">6,667.2475</block>
  <block id="b573d76a35b8d44de29524f11e873c60" category="cell">6,661.93125</block>
  <block id="f9622443c76d58838af97acd4f0c12ed" category="cell">6,570.2025</block>
  <block id="f93ed9c22230ae6e2ed85323e8d3dff7" category="cell">6,530.59125</block>
  <block id="83817408eae44458daefc1a9516ad170" category="cell">2 ノードの同期分散 TensorFlow</block>
  <block id="d4b63997154f30598f823403bb4df7ba" category="cell">13,213.70625</block>
  <block id="a328a929a422e4b69be5bbe94694282e" category="cell">13,218.288125</block>
  <block id="209f721713f475a9a0f4ba2743b40853" category="cell">12,941.69125</block>
  <block id="1f07dab13107a813c6d35bb76648ec48" category="cell">12,881.33875</block>
  <block id="66bc9494be0116470b223f2e07873f77" category="summary">このページでは、 NetApp AI コントロールプレーン解決策を実装する Kubernetes クラスタを導入するために実行する必要があるタスクについて説明します。Kubernetes クラスタをすでにお持ちの場合は、 Kubeflow と NetApp Trident でサポートされるバージョンの Kubernetes を実行していれば、このセクションをスキップできます。</block>
  <block id="2034cc978abb3057c4cf27e92b16ee74" category="doc">Kubernetes の導入</block>
  <block id="7c1ab988344d6a8d8cd9a30d6240955a" category="paragraph">このセクションでは、 NetApp AI コントロールプレーン解決策を実装する Kubernetes クラスタを導入するために完了しておく必要があるタスクについて説明します。Kubernetes クラスタをすでにお持ちの場合は、 Kubeflow と NetApp Trident でサポートされるバージョンの Kubernetes を実行していれば、このセクションをスキップできます。Kubeflow でサポートされる Kubernetes バージョンの一覧については、を参照してください<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>。Trident でサポートされている Kubernetes のバージョンのリストについては、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="ef8333b35fd982099a6ca0c7799b5618" category="paragraph">NVIDIA GPU を搭載したベアメタルノードを統合したオンプレミスの Kubernetes 環境では、 NVIDIA の DeepOps Kubernetes 導入ツールの使用を推奨します。このセクションでは、 DeepOps を使用した Kubernetes クラスタの導入について説明します。</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">このセクションで説明する導入の演習を行う前に、次の作業をすでに実行していることを前提としています。</block>
  <block id="612cba744b0eac9a7f153d2c4b8975da" category="list-text">標準的な構成手順に従って、ベアメタルの Kubernetes ノード（ ONTAP AI ポッドに含まれる NVIDIA DGX システムなど）を設定済みであること。</block>
  <block id="5a881e8e37e19924ac592136b5e7cfd3" category="inline-link">DeepOps GitHub サイト</block>
  <block id="452f5f6e8da4512f6cce223a76ae3558" category="list-text">すべての Kubernetes マスターノードとワーカーノード、および導入ジャンプホストに、サポートされているオペレーティングシステムをインストールしておきます。DeepOps でサポートされているオペレーティングシステムのリストについては、を参照してください<block ref="253a2cf380d7db7eaadb375aa91e2221" category="inline-link-rx"></block>。</block>
  <block id="a711e4ccced882d1762a8c653be8e921" category="section-title">NVIDIA DeepOps を使用して Kubernetes をインストールおよび設定します</block>
  <block id="47302a7393e0a038a150e679c9b3e80d" category="paragraph">NVIDIA DeepOps で Kubernetes クラスタを導入および設定するには、導入ジャンプホストから次のタスクを実行します。</block>
  <block id="5c51dc3fcfdd9653809e90fa3948c2f4" category="inline-link">「はじめに」ページ</block>
  <block id="21f937997adb0cac073e2458491f2c2f" category="list-text">の手順に従って、 NVIDIA DeepOps をダウンロードします<block ref="a94c3c17b923443c927cfa8fe7a2482a" category="inline-link-rx"></block> NVIDIA DeepOps GitHub サイトで入手できます。</block>
  <block id="2ed5978807d3da780c60a19b3f38a293" category="inline-link">Kubernetes 導入ガイドのページ</block>
  <block id="2dfe8bb84d94f23030d91e315d7899bc" category="paragraph">DeepOps Kubernetes 環境を使用するには、 Kubernetes マスターノードとワーカーノードがすべて同じユーザである必要があります。</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="doc">デフォルトの Kubernetes StorageClass を設定します</block>
  <block id="e1be30d98edccc10974d5d339832197c" category="paragraph">Kubeflow を導入する前に、 Kubernetes クラスタ内でデフォルトの StorageClass を指定する必要があります。Kubeflow の導入プロセスでは、デフォルトの StorageClass を使用して新しい永続ボリュームのプロビジョニングが試行されます。StorageClass がデフォルトの StorageClass として指定されていない場合、導入は失敗します。クラスタ内のデフォルトの StorageClass を指定するには、導入ジャンプホストから次のタスクを実行します。クラスタ内ですでにデフォルトの StorageClass を指定している場合は、この手順を省略できます。</block>
  <block id="e3e4fbe325df2b20670ca04ad0c2a517" category="list-text">既存のストレージクラスの 1 つをデフォルトのストレージクラスとして指定します。以降のコマンド例では、「 ontap/ai-sFLEXs-retain 」という名前の StorageClass がデフォルトの StorageClass として指定されています。</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">解決策の概要</block>
  <block id="4ed0a51bc1c995651eec6f50591eec1a" category="section-title">NetApp ONTAP AI と Cloud Sync</block>
  <block id="bff183f31dd9706bece9767f4388a819" category="paragraph">ネットアップと NVIDIA は、 NVIDIA DGX システムとネットアップのクラウド対応ストレージシステムを基盤とする NetApp ONTAP AI アーキテクチャを開発、検証しました。このリファレンスアーキテクチャには、 IT 組織に次のようなメリットがあります。</block>
  <block id="88acd7d612f76d7928b6b0448806e1ea" category="list-text">さまざまなパフォーマンスとコストの観点から、幅広いストレージオプションを提供 NetApp ONTAP AI は、 DGX システムと NetApp AFF A220 ストレージシステムを最先端のネットワーク機能と緊密に統合します。NetApp ONTAP AI システムと DGX システムでは、設計の複雑さと推測に頼らず、 AI 導入を簡易化できます。お客様は小規模構成から始めて、システムを中断なく拡張できます。同時に、エッジ、コア、クラウドにわたってデータをインテリジェントに管理できます。</block>
  <block id="69be3bc10a1ad78dbe823def1907c730" category="paragraph">NetApp Cloud Sync を使用すると、 2 つの NFS 共有、 2 つの CIFS 共有、 1 つのファイル共有と Amazon S3 、 Amazon Elastic File System （ EFS ）、 Azure BLOB ストレージの間で、さまざまなプロトコルを介してデータを簡単に移動できます。アクティブ / アクティブ処理とは、ソースとターゲットの両方と同時に作業を継続し、必要に応じてデータの変更を段階的に同期することを意味します。オンプレミスでもクラウドベースでも、ソースシステムとデスティネーションシステム間でデータを移動して段階的に同期できるため、 Cloud Sync では、データを使用できる新しい方法がさまざまに提供されます。オンプレミスのシステム間でのデータ移行、クラウドへのオンボーディングやクラウドへの移行、コラボレーションとデータ分析などのすべての作業を容易に実現できます。次の図は、使用可能なソースとデスティネーションを示しています。</block>
  <block id="1e01782ef13699818c9eb9eab796bffc" category="paragraph">会話型 AI システムでは、 Cloud Sync を活用してクラウドからデータセンターまでの会話履歴をアーカイブし、 NLP （ Natural Language Processing ）モデルのオフライントレーニングを可能にできます。より多くのインテントを認識するためのトレーニングモデルによって、会話型 AI システムは、エンドユーザーからのより複雑な質問にも対応できるようになります。</block>
  <block id="45f2cdf50f8bb89b245e814009b4244c" category="section-title">NVIDIA Jarvis マルチモーダルフレームワーク</block>
  <block id="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="paragraph"><block ref="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ad66827309f61fd22dc58cbbb2f8273" category="inline-link">NVIDIA Jarvis</block>
  <block id="241d985aedf9124840f9adfa9496755d" category="paragraph"><block ref="9f89431954623c8e5c580e4350b427e7" category="inline-link-rx"></block> 会話型 AI サービスを構築するためのエンドツーエンドのフレームワークです。GPU 向けに最適化された次のサービスが含まれています。</block>
  <block id="bb3e7af8136880e3a92118c172aed302" category="list-text">自動音声認識（ ASR ）</block>
  <block id="3c07089a439435a2998f14ea97f90825" category="list-text">自然言語理解（ NLU ）</block>
  <block id="8375cc1d63ce172363c4ed9c3cddd508" category="list-text">ドメイン固有のフルフィルメントサービスとの統合</block>
  <block id="84fb561f92aa70d5e118f429e98ee99b" category="list-text">テキスト / スピーチ（ TTS ）</block>
  <block id="9478a4e1be70e1be0fdd56f3929bbdc2" category="list-text">コンピュータビジョン（ CV ）ジャービスベースのサービスは、最先端のディープラーニングモデルを使用して、リアルタイムの会話型 AI の複雑で困難なタスクに対処します。エンドユーザーとのリアルタイムかつ自然な対話を可能にするには、モデルが 300 ミリ秒未満で計算を完了する必要があります。自然な相互作用は困難であり、マルチモーダル感覚を統合する必要があります。モデルパイプラインも複雑で、上記のサービス全体で調整が必要です。</block>
  <block id="c29efa8b1d5c9d6d647a8ce72bef1b74" category="paragraph">Jarvis は、エンドツーエンドのディープラーニングパイプラインを使用する、マルチモーダル会話型 AI サービスを構築するための、完全に高速化されたアプリケーションフレームワークです。Jarvis フレームワークには、音声、ビジョン、および NLU タスク向けに、事前にトレーニングされた会話型 AI モデル、ツール、最適化されたエンドツーエンドサービスが含まれます。AI サービスに加えて、 Jarvis ではビジョン、オーディオ、およびその他のセンサー入力を同時に融合し、仮想アシスタント、マルチユーザーのディアゼーション、コールセンターアシスタントなどのアプリケーションでマルチコンテキスト会話などの機能を提供できます。</block>
  <block id="dc3652fc64a2a6ea2a3cfd5c40443b16" category="paragraph"><block ref="4282ee73b9eecd67e90ed51f4f36b077" category="inline-link-rx"></block> は、使いやすいアプリケーションプログラミングインターフェイス（ API ）を使用して、 GPU によって高速化された最先端の会話型 AI モデルを構築、トレーニング、微調整するためのオープンソース Python ツールキットです。Nemo は、 NVIDIA GPU で Tensor コアを使用して精度の高いコンピューティングを実行し、複数の GPU に簡単にスケールアップして、トレーニングのパフォーマンスを最大限に高めることができます。Nemo は、医療、金融、小売、通信など、さまざまな業界のさまざまな業界で、ビデオ通話の文字変換、インテリジェントビデオアシスタント、自動コールセンターサポートなどのリアルタイム ASR 、 NLP 、 TTS アプリケーションのモデルを構築するために使用されます。</block>
  <block id="4e5ae683e2a399c166a1724b0aa6952e" category="paragraph">Nemo を使用して、アーカイブされた会話履歴のユーザ質問から複雑なインテントを認識するモデルをトレーニングしました。このトレーニングは、 Jarvis が提供したもの以外にも、小売バーチャルアシスタントの機能を拡張します。</block>
  <block id="053bc62e92a61e44afd338bcb27c422f" category="section-title">小売業のユースケースの概要</block>
  <block id="e1196fc000d661461f32bcaab7319c6a" category="inline-link">小売ユースケースの状態とフローをカスタマイズします</block>
  <block id="8b6b761738b93e745ffa4f73dd233c08" category="paragraph">NVIDIA Jarvis を使用して、スピーチやテキスト入力を受け付け、天気、関心のあるポイント、在庫価格に関する質問に回答できる仮想小売アシスタントを構築しました。会話型 AI システムでは、たとえば、天気や関心のある場所を指定していない場合は、フォローアップの質問をして会話の流れを記憶することができます。また、「タイ料理」や「ノートパソコンのメモリ」などの複雑なエンティティも認識します。 「ロサンゼルスで来週雨が降るだろうか？」など、自然言語の質問を理解しています。 小売バーチャルアシスタントのデモンストレーションは、にあります<block ref="0ba395e7fb59bace5ff35ab3c02ad737" category="inline-link-rx"></block>。</block>
  <block id="af8f881c5074e5e10cd7a34ccbaa9e57" category="paragraph"><block ref="af8f881c5074e5e10cd7a34ccbaa9e57" category="inline-link-macro-rx"></block></block>
  <block id="c755c33dca37a8aaffbf190bdf3f5fef" category="paragraph">この解決策は、 1 台の NetApp AFF A800 システム、 2 台の DGX-1 サーバ、 2 台の Cisco Nexus 3232C 100GbE スイッチで実装されました。DGX-1 サーバはそれぞれ 4 本の 100GbE 接続で Nexus スイッチに接続されます。この接続は、 Converged Ethernet （ RoCE ）を介したリモートダイレクトメモリアクセス（ RDMA ）を使用する GPU 間通信に使用されます。NFS ストレージアクセス用の従来の IP 通信も、これらのリンクで行われます。各ストレージコントローラは、 4 つの 100GbE リンクを使用してネットワークスイッチに接続されています。次の図に、このテクニカルレポートですべてのテストシナリオに使用した ONTAP AI 解決策アーキテクチャを示します。</block>
  <block id="782c9fdc3f29358987c2f5b99fe9e6b9" category="paragraph"><block ref="782c9fdc3f29358987c2f5b99fe9e6b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf8b135ff3c775c5b9bbba1b2f7a61ce" category="section-title">この解決策で使用されているハードウェア</block>
  <block id="a4ec49885c617f2b2500789af7e6eebf" category="paragraph">この解決策は、 ONTAP AI リファレンスアーキテクチャ DGX 1 ノードと AFF A800 ストレージシステム 1 台を使用して検証されました。を参照してください<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> を参照してください。</block>
  <block id="fe59cdcdefd7c53625e1e745b9c5be09" category="cell">DGX-1 システム</block>
  <block id="53270fbfda62583949b287e08ae3d063" category="cell">AFF A800</block>
  <block id="6da64488bfb7f3216610e30ced34ff23" category="cell">Nexus 3232C スイッチ</block>
  <block id="8e926487edd9348114ada5fa88a732df" category="paragraph">この解決策は、 Run ： AI オペレータがインストールされた基本的な Kubernetes 環境で検証されました。Kubernetes はを使用して導入されました<block ref="1c894f7463797b81796e78efc8345fb0" category="inline-link-rx"></block> 導入エンジン：本番環境に必要なすべてのコンポーネントを導入します。DeepOps は自動的に導入されます<block ref="ca1c90879f9a0e8dc4ff805fb398f7ff" category="inline-link-rx"></block> Kubernetes 環境との永続的なストレージ統合のために、デフォルトのストレージクラスが作成されました。これにより、コンテナは AFF A800 ストレージシステムのストレージを活用できます。Trident と ONTAP AI の Kubernetes の詳細については、を参照してください<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block>。</block>
  <block id="a2525584dd9d2a9522ddea95841c06b3" category="cell">9.6p4</block>
  <block id="80afba45eb055fc9bdc48c90d1debd06" category="cell">Kubernetes のバージョン</block>
  <block id="4bbe90408850f459864a71c8054732f1" category="cell">1.17</block>
  <block id="f1112223b41fddc71fd6a626582dfb78" category="cell">Trident のバージョン</block>
  <block id="43d66966083b0e0feac8fb9be14ba5b8" category="cell">20.04.0</block>
  <block id="e993176eed424766bc6bd4758eaf2cb6" category="cell">AI CLI を実行</block>
  <block id="5e6305186adf6e7dcf03f5cbfc802c49" category="cell">v2.1.13</block>
  <block id="f3eeed8e4b2791f80e2f123c4720aef5" category="cell">実行： AI Orchestration Kubernetes Operator バージョン</block>
  <block id="bf8c2933a2f54ce25fe986f66d3bffa3" category="cell">1.0.39</block>
  <block id="076ca75e2fc5b6ea85d72b0a9adc8844" category="inline-link">AI GPU クラスタの前提条件を実行します</block>
  <block id="eaec7f01752b17abf6125d8f29a8543c" category="paragraph">実行に必要なその他のソフトウェア要件： AI は、から入手できます<block ref="98bb21d82bcd499a183c82dcfc9b02f3" category="inline-link-rx"></block>。</block>
  <block id="cc352f05f03c970b081b8afa29693b60" category="inline-link-macro">次のステップ： AI を実行することでクラスタと GPU の利用率を最適化</block>
  <block id="b1b09355c9538fe149372d3728c98bb1" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block></block>
  <block id="7fd01fa95033c040ddfe882c5258bda9" category="paragraph">== hardbreaks ::nofooter: icons:font:linkattrs::imagesdir ::./../media/</block>
  <block id="dbb4dd9a11f48db13d63eedaae717fe5" category="doc">データサイエンスチームのプロジェクトを作成し、 GPU を割り当てる</block>
  <block id="22d09d229a06f294b0f45804f8e639d3" category="paragraph">研究者は、 AI CLI や Kubeflow などのプロセスを使ってワークロードを送信できます。リソースの割り当てを合理化して優先順位を設定するために、 Run ： AI では「プロジェクト」という概念が導入されています。プロジェクトは、プロジェクト名を GPU 割り当てと優先設定に関連付けるクォータエンティティです。複数のデータサイエンスチームを管理するシンプルで便利な方法です。</block>
  <block id="c0bd05e9d88cf015eac684873bfd14c7" category="paragraph">ワークロードを送信する研究者は、プロジェクトをワークロード要求に関連付ける必要があります。Run ： AI スケジューラは、リクエストを現在の割り当てとプロジェクトと比較して、ワークロードにリソースを割り当てることができるかどうか、またはワークロードを保留中の状態にするかどうかを判断します。</block>
  <block id="800f40fa67f69116bf6f38cd07456608" category="paragraph">システム管理者は、実行： AI プロジェクトタブで次のパラメータを設定できます。</block>
  <block id="9c429f2284a95aaa299c7d85ccb16734" category="list-text">* モデルプロジェクト。 * ユーザーごとにプロジェクトを設定し、ユーザーのチームごとにプロジェクトを設定し、実際の組織プロジェクトごとにプロジェクトを設定します。</block>
  <block id="b2f1422cf0d082a495bbf865b9a5621d" category="list-text">* プロジェクトの割り当て量。 * 各プロジェクトは、このプロジェクトに同時に割り当てることができる GPU の割り当て量に関連付けられています。これは、このプロジェクトを使用している研究者が、クラスタ内のどの状態であっても、この数の GPU を取得できることが保証されるという意味で、保証されたクォータです。原則として、プロジェクトの割り当ての合計は、クラスタ内の GPU の数と等しくなければなりません。さらに、このプロジェクトのユーザは、過剰割り当てを受け取ることができます。GPU が使用されていない限り、このプロジェクトを使用する研究者は GPU を増やすことができます。に、クォータ超過テストのシナリオと公平性に関する考慮事項を示します<block ref="9563fd9ab6978412dc97d80a70e51786" category="inline-link-rx"></block>、<block ref="a8ad108feafc827856baa28b0b9070ed" category="inline-link-rx"></block>および<block ref="be867f64efefe193012b1dfc6c82f783" category="inline-link-rx"></block>。</block>
  <block id="20a3a45fbbd9502add12fd216350d569" category="list-text">新しいプロジェクトを作成し、既存のプロジェクトを更新して、既存のプロジェクトを削除します。</block>
  <block id="3bf13b237342258b6ddb3f167d679a3b" category="inline-link">「 AI Documentation 」を実行します</block>
  <block id="77332641abf52ec5dc1af8b23b2339f3" category="list-text">* 特定のノードグループで実行するジョブを制限 * 。特定のプロジェクトを割り当てて、特定のノードでのみ実行することができます。これは、プロジェクトチームが十分なメモリを備えた特殊なハードウェアを必要とする場合などに便利です。また、プロジェクトチームは、特別な予算で取得された特定のハードウェアの所有者になる場合もあります。また、パフォーマンスが低いハードウェアで作業したり、長いトレーニングや無人ワークロードを高速ノードに誘導したりするために、ビルドや対話型のワークロードを処理する必要がある場合もあります。ノードをグループ化し、特定のプロジェクトにアフィニティを設定するコマンドについては、を参照してください <block ref="eae60ce89b8727160634b52e7654bf73" category="inline-link-rx"></block>。</block>
  <block id="2bd802cca9bf193b441123437f5d39ca" category="list-text">* 対話型ジョブの期間を制限します * 。研究者たちは、対話型の仕事を閉じることを忘れがちだ。これにより、リソースの無駄が発生する可能性があります。一部の組織では、対話型ジョブの期間を制限し、自動的に終了することを希望しています。</block>
  <block id="10c2495ded559d79de96be22751712dc" category="paragraph">次の図は、 4 つのチームが作成されたプロジェクトビューを示しています。各チームには、異なるワークロードに対応するために異なる数の GPU が割り当てられます。 GPU の総数は、 2 台の DGX-1 で構成されるクラスタ内の使用可能な GPU の総数と同じです。</block>
  <block id="9ba047faa1d241a6153be986be27097f" category="paragraph"><block ref="9ba047faa1d241a6153be986be27097f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4804b15e4766599ceade052b5ca8af9" category="inline-link-macro">次の例は、 Run AI CLI でジョブを送信しています</block>
  <block id="9c6088fad9917e07026030c1d3eaad09" category="paragraph"><block ref="9c6088fad9917e07026030c1d3eaad09" category="inline-link-macro-rx"></block></block>
  <block id="9e40fd8f5f0e113c758dfa63adc1221d" category="summary">Kubeflow は、データサイエンティストのワークスペースとして機能する、新しい Jupyter Notebook サーバの迅速なプロビジョニングを可能にします。Kubeflow を使用して新しい Jupyter Notebook サーバをプロビジョニングするには、このページに記載されているタスクを実行します。</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">データサイエンティストまたは開発者向けに Jupyter Notebook Workspace をプロビジョニングします 使用</block>
  <block id="5e82e4aa94a53b3b50acf347914be197" category="list-text">Kubeflow 中央ダッシュボードのメインメニューで Notebook Servers をクリックして、 Jupyter Notebook サーバ管理ページに移動します。</block>
  <block id="358d18b5a42ec1d80b04e767298ea372" category="paragraph"><block ref="358d18b5a42ec1d80b04e767298ea372" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208feb7a4d57f0afc49e53fe1fe8b978" category="list-text">新しい Jupyter Notebook サーバをプロビジョニングするには、 New Server をクリックします。</block>
  <block id="3541a3b25823fa3b302c686b6fe2a212" category="paragraph"><block ref="3541a3b25823fa3b302c686b6fe2a212" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f95069a2e81949b101427e1fa4afddf" category="list-text">新しいサーバに名前を付け、サーバのベースにする Docker イメージを選択し、サーバで予約する CPU と RAM の容量を指定します。[ 名前空間 ] フィールドが空白の場合は、ページヘッダーの [ 名前空間の選択 ] メニューを使用して名前空間を選択します。選択したネームスペースがネームスペースフィールドに自動的に入力されます。</block>
  <block id="4fbbbc4aaa49d653f486738eed12357a" category="paragraph">次の例では 'kubeflow-anonymous' ネームスペースが選択されていますまた、 Docker イメージ、 CPU 、 RAM のデフォルト値も使用できます。</block>
  <block id="69bc8b3ae7667985c27ce3ef5de0e6ca" category="paragraph"><block ref="69bc8b3ae7667985c27ce3ef5de0e6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c44927b0124469511a724e179c80bfb5" category="paragraph"><block ref="c44927b0124469511a724e179c80bfb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c73069b282d8e99ecbd8feb39164d40" category="paragraph"><block ref="0c73069b282d8e99ecbd8feb39164d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b120f9006af3d27ef70eb256c99c6617" category="list-text">* オプション： * 希望する数の GPU をノートブックサーバーに割り当てるよう要求します。次の例では、 GPU が 1 つ要求されています。</block>
  <block id="c969e6364e4561a959d1ce20f7187723" category="paragraph"><block ref="c969e6364e4561a959d1ce20f7187723" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8da2142543d647576288d71dddabb01" category="list-text">[ 起動 ] をクリックして、新しいノートブックサーバーをプロビジョニングします。</block>
  <block id="417a2eafac6842560d3900cf9d12b5bb" category="paragraph"><block ref="417a2eafac6842560d3900cf9d12b5bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0463a63e8059055e703ecd9ffa72e106" category="list-text">[ 接続 ] をクリックして、新しいサーバー Web インターフェイスに接続します。</block>
  <block id="4fbf21602f4888216386998d62f1defd" category="list-text">手順 6 で指定したデータセットボリュームがサーバにマウントされていることを確認します。デフォルトでは、このボリュームはデフォルトのワークスペース内にマウントされます。ユーザーの観点から見ると、これはワークスペース内の別のフォルダーにすぎません。データサイエンティストで、インフラのエキスパートではないユーザは、このボリュームを使用するためにストレージの専門知識を持っている必要はありません。</block>
  <block id="c4b6acc44505864a5dccae2571b74f6a" category="paragraph"><block ref="c4b6acc44505864a5dccae2571b74f6a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7d375154397ce9358d2234ec578ff7e" category="paragraph"><block ref="a7d375154397ce9358d2234ec578ff7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="479d03862d87da58784e60e5cfcec977" category="list-text">ターミナルを開き、手順 5 で新しいボリュームが要求された場合は、「 d f -h 」を実行して、 Trident でプロビジョニングされた新しい永続ボリュームがデフォルトのワークスペースとしてマウントされていることを確認します。</block>
  <block id="68f39a4f77e618e6617c3830fb47de7c" category="paragraph">デフォルトのワークスペースディレクトリは、サーバーの Web インターフェイスに最初にアクセスしたときに表示されるベースディレクトリです。そのため、 Web インターフェイスを使用して作成したアーティファクトは、 Trident でプロビジョニングされた永続ボリュームに保存されます。</block>
  <block id="d3e91c75db0cb717734224e6eb72e201" category="paragraph"><block ref="d3e91c75db0cb717734224e6eb72e201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d739fe0e421e9cb4d6315f0021cc5eb" category="paragraph"><block ref="1d739fe0e421e9cb4d6315f0021cc5eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8c20de15cf5efa2297f9d40d899450e" category="list-text">ターミナルを使用して「 nvidia-smi 」を実行し、ノートブックサーバーに正しい数の GPU が割り当てられていることを確認します。次の例では、手順 7 で要求されたように、 1 つの GPU がノートブックサーバーに割り当てられています。</block>
  <block id="ed4e7225349e5c6cd33dfd15ad878438" category="paragraph"><block ref="ed4e7225349e5c6cd33dfd15ad878438" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a37acabf89826767b5a5fcb8dacffa3" category="summary">このページでは、 Kubernetes クラスタに Kubeflow を導入するために完了しなければならないタスクについて説明します。</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">このセクションでは、 Kubernetes クラスタに Kubeflow を導入するために実行する必要のあるタスクについて説明します。</block>
  <block id="f48269a81318d4bd2dd9e57a8239fe56" category="list-text">Kubernetes クラスタはすでに稼働しており、 Kubeflow でサポートされるバージョンの Kubernetes を実行しているとします。サポートされているバージョンの一覧については、を参照してください<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>。</block>
  <block id="9fc644d78f21555decceeddf5b691fa4" category="list-text">内に NetApp Trident のインストールと設定が完了している必要があります Kubernetes クラスタ（を参照） <block ref="ec7700e2b8d95edf2f2700b590eab273" category="inline-link-macro-rx"></block>。</block>
  <block id="48c4dc7fbfa1197490124f13eb565bd2" category="doc">ONTAP AI の導入</block>
  <block id="70d5c23ad68d59b2546133efdd1c3267" category="inline-link">NVA-1121-deploy ： NetApp ONTAP AI 、 Powered by NVIDIA</block>
  <block id="b393f072bc6b17085b75486a2abbcf97" category="paragraph">ONTAP AI を導入するには、ネットワーク、コンピューティング、ストレージハードウェアのインストールと設定が必要です。ONTAP AI インフラの導入手順については、本ドキュメントでは説明していません。導入の詳細については、を参照してください<block ref="8c03c9c25bc6aba17e86c510148a3423" category="inline-link-rx"></block>。</block>
  <block id="03e335ae74b1356b294af55e07eb6b70" category="paragraph">この解決策検証では、 1 つのボリュームを作成して DGX-1 システムにマウントしました。その後、そのマウントポイントをコンテナにマウントして、トレーニング用のデータにアクセスできるようにしました。大規模な環境では、 NetApp Trident によってボリュームの作成とマウントが自動化されるため、管理上のオーバーヘッドが発生しないとともに、エンドユーザによるリソースの管理が可能になります。</block>
  <block id="328d9c8854162b6d9dae70c57baa7505" category="inline-link-macro">次： Kubernetes の導入</block>
  <block id="5102c02ef61bdeaa79904c17f58ca7e3" category="paragraph"><block ref="5102c02ef61bdeaa79904c17f58ca7e3" category="inline-link-macro-rx"></block></block>
  <block id="74c071ff3c1d6d6fc39b72d617aefdf8" category="doc">解決策の導入と検証の詳細</block>
  <block id="b122830b8b8edd9e76690ea23b0c4cbd" category="paragraph">以降のセクションでは、解決策の導入と検証の詳細について説明します。</block>
  <block id="ebe48d794d8ada5d4e067cd5993bdd3e" category="inline-link-macro">次のステップ： ONTAP AI の導入</block>
  <block id="3b103491115e62f2388d69086a2eff9d" category="paragraph"><block ref="3b103491115e62f2388d69086a2eff9d" category="inline-link-macro-rx"></block></block>
  <block id="f7235eb2146d800446cbbbac3a57548c" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block>。</block>
  <block id="d052a88935efadcc9eebf94684d52e19" category="doc">高いクラスタ利用率の達成</block>
  <block id="27d597678185c0988ffb2dbb0c1b941d" category="inline-link-macro">ResNet-50 と ImageNet データセットベンチマークの概要</block>
  <block id="8d46742dbd21a217f738a9ca6a31f634" category="paragraph">このセクションでは、 4 つのデータサイエンスチームがそれぞれ独自のワークロードを送信して実行： AI オーケストレーション解決策を実証する現実的なシナリオをエミュレートしています。このシナリオでは、 GPU リソースの優先順位付けとバランシングを維持しながら、クラスタの利用率を高めることができますまず、で説明した ResNet-50 ベンチマークを使用します セクション <block ref="5872a8c23866a6bf186843724ee58ad7" category="inline-link-macro-rx"></block>：</block>
  <block id="14f48338822299bdf82bb4528d3c9e07" category="paragraph">ResNet-50 ベンチマークを実行しました（を参照）<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block>。パブリック Docker リポジトリに存在しないコンテナには、フラグ「 --local-image 」を使用しました。ディレクトリ「 /mnt/' 」と「 /tmp' 」をホスト DGX-1 ノード上の「 /mnt/' 」と「 /tmp' 」にそれぞれコンテナにマウントしました。データセットは、ディレクトリを指す「 dataset_dir 」引数を持つ NetApp AFFA800 にあります。どちらの場合も '--num_devices =1' と '-g 1' は ' このジョブに 1 つの GPU を割り当てていることを意味します前者は「 run.py 」スクリプトの引数で、後者は「 runai submit 」コマンドのフラグです。</block>
  <block id="bccb844975c2eec86eb25c0d8e2a989b" category="paragraph">次の図は、 97% の GPU 利用率を備え、 16 個の使用可能な GPU が割り当てられたシステム概要ダッシュボードを示しています。GPU / プロジェクトの棒グラフでは、各チームに割り当てられている GPU の数を簡単に確認できます。[ 実行中のジョブ ] ウィンドウ枠には、現在実行中のジョブ名、プロジェクト、ユーザー、タイプ、ノード、 GPU の消費、実行時間、進捗状況、利用率の詳細。キューに登録されているワークロードとその待機時間のリストが「保留中のジョブ」に表示されます。さらに、 Nodes ボックスは、クラスタ内の個々の DGX-1 ノードの GPU 番号と利用率を表示します。</block>
  <block id="1acc627e7c9d8002628b2e12c91ac683" category="paragraph"><block ref="1acc627e7c9d8002628b2e12c91ac683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5d3b5670d9303fddfb021e681546c0" category="inline-link-macro">次の例：要件の低いワークロードやインタラクティブなワークロードに適した、フラクショナルな GPU 割り当て</block>
  <block id="3d9997e0f8b3b6a279c8779455e7c760" category="paragraph"><block ref="3d9997e0f8b3b6a279c8779455e7c760" category="inline-link-macro-rx"></block></block>
  <block id="639ce1b23959b4470d67802f0e5e412a" category="doc">ONTAP AI 導入向けハイパフォーマンスジョブの例</block>
  <block id="fbe29309a183681bc26203d4c65853a2" category="paragraph">このセクションでは、従来のデータサイエンスパイプラインとその欠点について説明します。また、提案するデータセットキャッシング解決策のアーキテクチャについても説明します。</block>
  <block id="1f14aecc1193f646e0005e27fbc6e63d" category="section-title">従来のデータサイエンスパイプラインと欠点</block>
  <block id="17fb7d0ba5495199d3e18fe23dff7b59" category="paragraph">ML モデルの開発と導入の一般的な手順には、次のような反復的な手順が含まれます。</block>
  <block id="63e1ded7e3ae73253b5c287bc9bdef02" category="list-text">データの取り込み</block>
  <block id="52e028dc7ac82e9d4b7b1ae588fecc9a" category="list-text">データの前処理（データセットの複数のバージョンを作成）</block>
  <block id="33cd0fcdd9ee7e650043133b12516155" category="list-text">HyperParameter の最適化、さまざまなモデルなどを含む複数の実験を実行する</block>
  <block id="b85c416c94e0c5314a1e6fcc21d4139e" category="list-text">Monitoringcnvrg.io は、研究から導入までのすべてのタスクを自動化する包括的なプラットフォームを開発しました。次の図に、パイプラインに関するダッシュボードのスクリーンショットのごく一部を示します。</block>
  <block id="5a5ade85e7f7478bcba59e8c3891c914" category="paragraph"><block ref="5a5ade85e7f7478bcba59e8c3891c914" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26d6a4638ffd0b7779f1353f5fe54f0d" category="paragraph">パブリックリポジトリやプライベートデータから複数のデータセットを使用するのは非常に一般的です。また、データセットのクリーンアップやフィーチャーエンジニアリングによって、各データセットに複数のバージョンが生成されることもよくあります。次の図に示すように、データセットハブとバージョンハブを提供するダッシュボードは、コラボレーションツールと整合性ツールをチームで確実に使用できるようにするために必要です。</block>
  <block id="e884d73b6a4214bea010ec3bbfdad8b6" category="paragraph"><block ref="e884d73b6a4214bea010ec3bbfdad8b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93661dde7027bf31b3d007740a3d4648" category="paragraph">パイプラインの次のステップではトレーニングを行います。トレーニングモデルには複数の並行インスタンスが必要で、それぞれがデータセットと特定のコンピューティングインスタンスに関連付けられている必要があります。データセットを特定のコンピューティングインスタンスと特定の実験にバインドすることは、一部の実験は Amazon Web Services （ AWS ）の GPU インスタンスによって実行され、それ以外の実験は DGX-1 インスタンスまたは DGX-2 インスタンスによってオンプレミスで実行される可能性があるため、難しい課題です。GCP の CPU サーバーでは他の実験が実行され、データセットの場所がトレーニングを実行するコンピューティングリソースにあまり近接していない場合があります。合理的なプロキシミティには、データセットストレージからコンピューティングインスタンスへの完全な 10GbE 以上の低レイテンシ接続が必要です。</block>
  <block id="ba4f5ee1b0d01d3416723cfc3ec296ec" category="paragraph">データサイエンティストが、トレーニングを実行し、実験を実行するコンピューティングインスタンスにデータセットをダウンロードするのは、一般的に行われます。ただし、この方法にはいくつかの潜在的な問題があります。</block>
  <block id="90b6a1c5b483f6c6b399bc17c5e1af9a" category="list-text">データサイエンティストがデータセットをコンピューティングインスタンスにダウンロードした場合、統合コンピューティングストレージのパフォーマンスが高くても保証はありません（ハイパフォーマンスシステムの例としては ONTAP AFF A800 NVMe 解決策が挙げられます）。</block>
  <block id="5713a88504bb65e3808faac627a6a0fc" category="list-text">ダウンロードしたデータセットが 1 つのコンピューティングノードに存在する場合、複数のノードで分散モデルを実行すると（ NetApp ONTAP のハイパフォーマンス分散ストレージとは異なり）ストレージがボトルネックになることがあります。</block>
  <block id="299b9ae5439d32ed932f51f3b3aa92d6" category="list-text">トレーニング実験の次の反復は、キューの競合や優先順位のために別のコンピューティングインスタンスで実行される場合もあります。これも、データセットから計算場所へのネットワーク距離が大幅に大きくなります。</block>
  <block id="30e37003024e85518a26760a7ab58f4e" category="list-text">同じコンピューティングクラスタ上でトレーニング実験を実行する他のチームメンバーは、このデータセットを共有できません。各チームメンバーは、任意の場所からデータセットの（高価な）ダウンロードを実行します。</block>
  <block id="9e5d53150336efb0446a063309805f01" category="list-text">後続のトレーニングジョブで同じデータセットの他のデータセットまたはバージョンが必要な場合、データサイエンティストは、 training.NetApp および cnvrg.io を実行しているコンピューティングインスタンスにデータセットの（高価な）ダウンロードを再度実行する必要があります。これにより、これらの障害を解消する新しいデータセットキャッシング解決策が作成されます。解決策は、ホットデータセットを ONTAP ハイパフォーマンスストレージシステムにキャッシュすることで、 ML パイプラインの実行を高速化します。ONTAP NFS では、ネットアップが提供するデータファブリック（ AFF A800 など）にデータセットが 1 回だけ（一度だけ）キャッシュされ、コンピューティングと一緒に配置されます。NetApp ONTAP NFS 高速ストレージが複数の ML コンピューティングノードに対応できるようになるため、トレーニングモデルのパフォーマンスが最適化され、コスト削減、生産性、運用効率が向上します。</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">解決策アーキテクチャ</block>
  <block id="a63af1f206939a3c956a2e8b6ab53103" category="paragraph">この解決策は、次の図に示すように、ネットアップおよび cnvrg.io から提供されます。データセットのキャッシングにより、データサイエンティストは必要なデータセットまたはデータセットのバージョンを選択し、 ML コンピューティングクラスタのすぐ近くにある ONTAP NFS キャッシュに移動できます。データサイエンティストは、遅延やダウンロードを発生させることなく、複数の実験を実行できるようになりました。さらに、コラボレーションするすべてのエンジニアは、データレイクから追加のダウンロードを行うことなく、接続されたコンピューティングクラスタ（任意のノードを自由に選択できる）で同じデータセットを使用できます。データサイエンティストは、すべてのデータセットとバージョンを追跡および監視するダッシュボードを提供し、キャッシュされたデータセットを確認します。</block>
  <block id="612eaee91b23ecc385c1b402d44c081f" category="paragraph">cnvrg.io プラットフォームは、一定の期間使用されていない古いデータセットを自動検出し、キャッシュから削除します。これにより、使用頻度の高いデータセット用に NFS キャッシュの空きスペースが維持されます。ONTAP を使用したデータセットのキャッシングは、クラウドとオンプレミスで機能するため、最大限の柔軟性が得られることに注意してください。</block>
  <block id="0cb5e14601fcf39745352a9556939aa3" category="paragraph"><block ref="0cb5e14601fcf39745352a9556939aa3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="810aceabf729ffa8c2dfd61a3aaeafaa" category="inline-link-macro">次の手順：概念とコンポーネント</block>
  <block id="0a01ff9defa9120e928e7e306e3e3234" category="paragraph"><block ref="0a01ff9defa9120e928e7e306e3e3234" category="inline-link-macro-rx"></block></block>
  <block id="fb1290be14b9bc3c64a2c3c9ace6c065" category="doc">ユースケースの概要と問題点</block>
  <block id="aa04a8198c7c60df7adcd6cd49bec6f8" category="paragraph">データセットとデータセットのバージョンは通常、 NetApp StorageGRID オブジェクトベースストレージなどのデータレイクに配置されるため、コストの削減やその他の運用上のメリットが得られます。データサイエンティストは、これらのデータセットを取得して複数の手順でエンジニアを配置し、特定のモデルを使用したトレーニングに備えます。多くの場合、途中で複数のバージョンが作成されます。次のステップとして、データサイエンティストは、モデルを実行するために最適化されたコンピューティングリソース（ GPU 、ハイエンド CPU インスタンス、オンプレミスクラスタなど）を選択する必要があります。次の図は、 ML コンピューティング環境にデータセットの距離がないことを示しています。</block>
  <block id="cc054601488581e80cc1d19c227126f6" category="paragraph"><block ref="cc054601488581e80cc1d19c227126f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88515fca547c502286d6f2a9081fc734" category="paragraph">ただし、複数のトレーニング実験を異なるコンピューティング環境で並行して実行する必要があります。それぞれの環境では、データレイクからデータセットをダウンロードする必要があります。これはコストと時間のかかるプロセスです。データセットがコンピューティング環境（特にハイブリッドクラウド）に近接していることは保証されません。また、同じデータセットで独自の実験を行う他のチームメンバーも、同じ複雑なプロセスを実行する必要があります。データアクセスが遅いことが明らかなだけでなく、データセットのバージョン、データセットの共有、コラボレーション、再現性の追跡にも困難が伴います。</block>
  <block id="30b64502c0cb2f8a9bf951993e0abbac" category="section-title">お客様の要件</block>
  <block id="5243f720d7e440d7746f03df97ef885f" category="paragraph">リソースを効率的に使用しながら、高パフォーマンスの ML を実行するためには、お客様の要件が異なる場合があります。たとえば、次のような場合があります。</block>
  <block id="1735cf11ce0034dbb80c297fb204bc21" category="list-text">を実行する各コンピューティングインスタンスからデータセットに高速アクセス 高額なダウンロードやデータアクセスの複雑さを伴わないトレーニングモデル</block>
  <block id="80085a846f90523080cf086e66561d52" category="list-text">は任意のコンピューティングインスタンス（ GPU または CPU ）を使用する クラウドでもオンプレミスでも、場所を気にする必要はありません 」と入力します</block>
  <block id="de79912b1ab8764406a232888aab85e5" category="list-text">で複数のトレーニング実験を実行することで、効率と生産性が向上します を使用せずに、同一データセット上の異なるコンピューティングリソースと並行して実行できます 不要な遅延とデータ遅延</block>
  <block id="5211203793a223f02322b88b2e698a82" category="list-text">コンピューティングインスタンスのコストを最小限に抑えます</block>
  <block id="6a6fcee71b4e22ac6a4afdfdb5940b67" category="list-text">データセット、そのリネージ、バージョン、およびその他のメタデータの詳細の記録を保持するツールにより、再現性が向上しました</block>
  <block id="930d18875813298018f8364069441eee" category="list-text">共有とコラボレーションを強化して、の権限を持つすべてのメンバーをサポートします チームはデータセットにアクセスして実験を実行できます</block>
  <block id="5f700d00ad72470694a5aa06cd515c8b" category="paragraph">NetApp ONTAP データ管理ソフトウェアにデータセットのキャッシングを実装するには、次のタスクを実行する必要があります。</block>
  <block id="41fac0272180c0141b5cd7ad6ad85a44" category="list-text">コンピューティングリソースに最も近い NFS ストレージを構成して設定します。</block>
  <block id="25a3a7ee3cfbb4afc291cd5b94dec000" category="list-text">キャッシュするデータセットとバージョンを決定します。</block>
  <block id="dbffd2a20c35c06fbb6ba0cd17e54ef6" category="list-text">キャッシュされたデータセットにコミットされた合計メモリと、追加のキャッシュコミットに使用できる NFS ストレージの量（キャッシュ管理など）を監視します。</block>
  <block id="61d5e7050cbe037ad5adeaf246e6be19" category="list-text">特定の時間内に使用されなかったデータセットは、キャッシュ内でエージングアウトします。デフォルトは 1 日で、その他の設定オプションも使用できます。</block>
  <block id="36691dc48fac4774974c970e3bfa1a7d" category="paragraph"><block ref="36691dc48fac4774974c970e3bfa1a7d" category="inline-link-macro-rx"></block></block>
  <block id="0a1bc6b4024485ff9b55c99c1237e175" category="doc">クラスタと GPU の利用率を最適化して実行： AI</block>
  <block id="b8b025dc1895637326d2420e912751e0" category="summary">Trident を使用して Kubernetes クラスタ内のストレージリソースを動的にプロビジョニングするには、 Trident バックエンドを 1 つ以上作成する必要があります。このページの例は、 ONTAP AI ポッドにネットアップ AI コントロールプレーン解決策を導入する場合に作成するバックエンドのタイプを表しています。</block>
  <block id="f363c1a10e150fdee0f4f310a06acb5e" category="doc">ONTAP AI 導入向け Trident バックエンドの例</block>
  <block id="c0fe00dd01499e23426b850b65782c77" category="paragraph">Trident を使用して Kubernetes クラスタ内のストレージリソースを動的にプロビジョニングするには、 Trident バックエンドを 1 つ以上作成する必要があります。以下に示す例は、 ONTAP AI ポッドにネットアップ AI コントロールプレーン解決策を導入する場合に作成するバックエンドのタイプを表しています。バックエンドの詳細については、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="327a3876126e4773cfcc5e30649c9483" category="paragraph">以下のコマンド例は、同じ ONTAP Storage Virtual Machine （ SVM ）に関連付けられている 2 つの異なるデータ LIF を対象に、 FlexGroup 対応の Trident バックエンドを 2 つ作成する方法を示しています。これらのバックエンドは 'ONTAP-NAS-flexgroup ストレージ・ドライバを使用しますONTAP では、 FlexVol と FlexGroup の 2 つの主要なデータボリュームタイプがサポートされます。FlexVol ボリュームのサイズは限られています（現時点では、最大サイズは環境によって異なります）。一方、 FlexGroup ボリュームは最大 20PB 、 4 、 000 億ファイルまでリニアに拡張でき、データ管理を大幅に簡易化する単一のネームスペースを提供します。そのため、 FlexGroup ボリュームは、大量のデータに依存する AI や ML のワークロードに最適です。</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">少量のデータを処理していて、 FlexGroup ボリュームではなく FlexVol ボリュームを使用する場合は、「 ONTAP-NAS-flexgroup 」ストレージドライバの代わりに「 ONTAP-NAS' ストレージドライバ」を使用する Trident バックエンドを作成できます。</block>
  <block id="d04adbc45ec06c05c1826745b8f4ddf2" category="list-text">また、 FlexVol 対応の Trident バックエンドも 1 つ以上作成することを推奨します。FlexGroup ボリュームをデータセットストレージのトレーニングに使用する場合は、結果、出力、デバッグ情報などの格納に FlexVol ボリュームを使用できます。FlexVol ボリュームを使用する場合は、 FlexVol 対応の Trident バックエンドを 1 つ以上作成する必要があります。次に示すコマンド例は、単一のデータ LIF を使用する、 FlexVol 対応の Trident バックエンドの作成例を示しています。</block>
  <block id="e2b5e920360785877a1831ff4b128520" category="summary">ネットアップのセットアップ</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">セットアップ（ Setup ）</block>
  <block id="9af8334f3fca73145524498c2f49ee10" category="inline-link-macro">次の手順：概要</block>
  <block id="02e8a07ffc2e2c5240049e5214d70427" category="paragraph"><block ref="02e8a07ffc2e2c5240049e5214d70427" category="inline-link-macro-rx"></block></block>
  <block id="9dc7cfc5bd8fb85bad9fdab5cdded288" category="doc">「 AI Installation 」を実行します</block>
  <block id="c1b7d088e01f6ec6ec89bf69437e4bb1" category="paragraph">Run ： AI をインストールするには、次の手順を実行します。</block>
  <block id="7ad0483bc07dbde29ffd404af83f8305" category="list-text">DeepOps を使用して Kubernetes クラスタをインストールし、ネットアップのデフォルトストレージクラスを設定します。</block>
  <block id="16d20d34f759cd25fd7486bbc4046a50" category="list-text">GPU ノードの準備：</block>
  <block id="d3eff3861b26ba61222bacaa41bc0fa7" category="list-text">NVIDIA ドライバが GPU ノードにインストールされていることを確認します。</block>
  <block id="3683aa7fe695a205b8e40e9589c94a2e" category="list-text">「 nvidia - Docker 」がインストールされ、デフォルトの Docker ランタイムとして設定されていることを確認します。</block>
  <block id="cef990020518a58fb1e70a90b5df80fe" category="list-text">インストール実行： AI ：</block>
  <block id="e2d6778a342979b567501f951e36118a" category="inline-link">AI 管理 UI を実行</block>
  <block id="6fc7ea9b01c6028f691aac2aeac528f1" category="list-text">にログインします<block ref="668d940d94d02be49a88c4cfd2736fa9" category="inline-link-rx"></block> クラスタを作成できます。</block>
  <block id="fe8f08cfda6726e2dcc5d0b85ed2c67d" category="list-text">作成した「 runai-operator-&lt;clustername&gt; .yaml 」ファイルをダウンロードします。</block>
  <block id="b428155da5c27d208abd6c179c7669d3" category="list-text">オペレータ設定を Kubernetes クラスタに適用します。</block>
  <block id="fac4447e0ea2e4cd1a2d9e2fefeab694" category="list-text">インストールを確認します。</block>
  <block id="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link"><block ref="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link-rx"></block></block>
  <block id="2d14c64dc5dfa79a68cd6965fbf9e4b7" category="list-text">に進みます<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>。</block>
  <block id="feb48a27d95fc7a7e0c6db496c54d2fa" category="list-text">概要ダッシュボードに移動します。</block>
  <block id="09fa3891e2b39bb62217c6d097310577" category="inline-link">Run ： AI をオンプレミスの Kubernetes クラスタにインストール</block>
  <block id="45d7be937e1eddf966adaf68562966d4" category="inline-link">Run ： AI CLI のインストール</block>
  <block id="728f8fd776de1dc47f318473052286db" category="list-text">右上の GPU の数が、想定される GPU の数と GPU ノードの数をすべてサーバのリストに表示していることを確認します。実行： AI 導入の詳細については、を参照してください<block ref="089aa48f8d7b3b135b035765dd1e17ba" category="inline-link-rx"></block> および<block ref="f2f48a2074c9edc0c2dea174863a4f6e" category="inline-link-rx"></block>。</block>
  <block id="db9d1f740f050b1d20ab43a459bb225a" category="inline-link-macro">次の手順： AI ダッシュボードとビューを実行します</block>
  <block id="c56b5d251d18e9b020f95696fef9f0b9" category="paragraph"><block ref="c56b5d251d18e9b020f95696fef9f0b9" category="inline-link-macro-rx"></block></block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">ネットアップの概要</block>
  <block id="d30aa8861afaf98888c2367f107a8bc6" category="paragraph">ネットアップは、ハイブリッドクラウド環境におけるデータ管理のオーソリティです。ネットアップは、クラウド環境とオンプレミス環境全体でアプリケーションとデータの管理を簡易化し、デジタル変革を加速する、幅広いハイブリッドクラウドデータサービスを提供しています。グローバル企業がデータのポテンシャルを最大限に引き出し、お客様とのコンタクトの強化、イノベーションの促進、業務の最適化を図れるよう、パートナー様とともに取り組んでいます。</block>
  <block id="ee86473f0dbd191846077276ce455778" category="paragraph">NVIDIA DGX システムとネットアップのクラウド対応オールフラッシュストレージを基盤とする NetApp ONTAP AI は、データの信頼性を高め、エッジからコア、クラウドにわたるデータファブリックで分析、トレーニング、推論を高速化します。IT 組織には、次のようなメリットをもたらすアーキテクチャが提供されます。</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">コンピューティングとストレージを個別に拡張できます</block>
  <block id="6cb062d50ca0d4a2bfa0caec33fea16f" category="list-text">さまざまなパフォーマンスとコストの観点から、幅広いストレージオプションを提供 NetApp ONTAP AI は、 NVIDIA DGX-1 、ペタフロップス規模の AI システム、 NVIDIA Mellanox ハイパフォーマンスイーサネットスイッチを統合したコンバージドインフラスタックを提供し、 AI ワークロードの統合、導入の簡易化、 ROI の向上を実現します。このテクニカルレポートでは、 ONTAP AI を DGX-1 と NetApp AFF A800 ストレージシステムの 1 つに活用しました。次の図は、この検証で使用した DGX-1 システムを使用した ONTAP AI のトポロジを示しています。</block>
  <block id="3eedc2d7451e7ff0440f17c9e61227dc" category="paragraph"><block ref="3eedc2d7451e7ff0440f17c9e61227dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="section-title">NetApp AI コントロールプレーン</block>
  <block id="e1fc355cf7f97dbf25407695f8852241" category="paragraph">ネットアップの AI コントロールプレーンは、卓越した拡張性、合理的な導入、ノンストップのデータ可用性を備えた解決策で、 AI と ML を最大限に活用できます。AI コントロールプレーン解決策は、 Kubernetes と Kubeflow をネットアップのデータファブリックと統合します。クラウドネイティブ環境向けの業界標準のコンテナオーケストレーションプラットフォームである Kubernetes は、ワークロードの拡張性とモビリティを実現します。Kubeflow はオープンソースの機械学習プラットフォームで、管理と導入を簡易化し、開発者がより多くのデータサイエンスをより短時間で行えるようにします。ネットアップのデータファブリックは、エッジからコア、クラウドまで、パイプライン全体でデータに確実にアクセスできるよう、データの可用性とモビリティを妥協することなく提供します。このテクニカルレポートでは、 MLRun パイプラインで NetApp AI コントロールプレーンを使用しています。次の図は、 Kubernetes クラスタ管理ページを示しています。各クラスタに異なるエンドポイントを割り当てることができます。NFS Persistent Volume を Kubernetes クラスタに接続し、次の図に示すように、クラスタに接続された永続的ボリュームが表示されます<block ref="33155b45dbdad2f412212744fbe6f8dc" category="inline-link-rx"></block> 永続的ストレージのサポートとデータ管理機能を提供します。</block>
  <block id="b058638c35435549e77a90b91abd3305" category="paragraph"><block ref="b058638c35435549e77a90b91abd3305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d371ade9f9702601a7e2f8f57c8b013" category="paragraph"><block ref="7d371ade9f9702601a7e2f8f57c8b013" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1dc271f7d3ae88e2a019314b7e4fd8e" category="section-title">Iguazio の概要</block>
  <block id="0c9fe13fe6a660070e99a54151edd7c3" category="paragraph">Iguazio Data Science Platform は、開発の簡素化、パフォーマンスの向上、コラボレーションの促進、運用上の課題への対処を可能にする、完全に統合された安全なデータサイエンスプラットフォームサービス（ PaaS ）です。このプラットフォームには以下のコンポーネントが組み込まれており、 Iguazio データサイエンスプラットフォームを次の図に示します。</block>
  <block id="2137518d79f0a3dfe335e8c02312cf96" category="list-text">Jupyter Notebook 、統合分析エンジン、 Python パッケージを含むデータサイエンスワークベンチ</block>
  <block id="68ed19bfa85e4c4677e50979864e169b" category="list-text">実験追跡機能と自動化されたパイプライン機能を使用したモデル管理</block>
  <block id="37a28d84cd653345f1f2c036cb732f2d" category="list-text">拡張性に優れた Kubernetes クラスタでデータサービスと ML サービスを管理</block>
  <block id="77fdda1a79199ac02cde44b4249cb509" category="list-text">サーバレス関数のリアルタイムフレームワークである Nuclio</block>
  <block id="96a6f4a99a7526e82a294d44ed005701" category="list-text">SQL 、 NoSQL 、時系列データベース、ファイル（シンプルなオブジェクト）、ストリーミングをサポートする、きわめて高速でセキュアなデータレイヤです</block>
  <block id="00a48f02675717eaf6082c4ba536a366" category="list-text">ネットアップ、 Amazon S3 、 HDFS 、 SQL データベース、ストリーミングプロトコルやメッセージングプロトコルなどのサードパーティ製データソースとの統合</block>
  <block id="901630ad39a688431a68dc119f5378a3" category="list-text">Grafana に基づくリアルタイムダッシュボード</block>
  <block id="887fce38ef8ddd8546748bb746ed7e5a" category="paragraph"><block ref="887fce38ef8ddd8546748bb746ed7e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="961027a0ac9a1d9515fa54a5d5372c79" category="inline-link-macro">次の手順：ソフトウェアとハードウェアの要件</block>
  <block id="a10e3ee0949323f601d4c9624980eb47" category="paragraph"><block ref="a10e3ee0949323f601d4c9624980eb47" category="inline-link-macro-rx"></block></block>
  <block id="7c4090c7fa7a91e8c7fed182401dbf6b" category="doc">NetApp Trident の導入と設定</block>
  <block id="7c0ea3e86521674f72e056d148d4f2ce" category="paragraph">ネットアップと Run ：このテクニカルレポートでは、 AI と、 NetApp ONTAP AI 解決策の独自機能と、 Run ： AI プラットフォームを組み合わせることで、 AI ワークロードのオーケストレーションを簡易化できることを紹介しています。前の手順では、ディープラーニングのためのデータパイプラインとワークロードオーケストレーションのプロセスを合理化するリファレンスアーキテクチャを示します。これらのソリューションの導入を検討しているお客様には、ネットアップと Run ： AI の活用で詳細を確認することをお勧めします。</block>
  <block id="f797637684ff1290d12e5495dac050a6" category="inline-link-macro">次のセクション 4.8 のテストの詳細</block>
  <block id="bbe251d46ac2a6899a2a4d5d0e331a43" category="paragraph"><block ref="bbe251d46ac2a6899a2a4d5d0e331a43" category="inline-link-macro-rx"></block></block>
  <block id="8383a1cf96c028a0986b7371049c8495" category="doc">ネットワークデバイスの障害予測ユースケースの概要</block>
  <block id="dea416ff04e558b0d76cce896b618880" category="paragraph">この使用例は、アジアの通信空間における Iguazio の顧客をベースにしています。100 万社の企業顧客と年間 125 万件のネットワーク停止イベントに対応しているため、ネットワーク障害による顧客への影響を防止するために、事前に対処する必要がありました。この解決策には、次のような利点があります。</block>
  <block id="feb68271e6d14db0b1ff524f3eb47a27" category="list-text">ネットワーク障害の予測分析</block>
  <block id="70e00676492bea584fb8e7d551515eb5" category="list-text">チケット発行システムとの統合</block>
  <block id="6de8d1444549249c0161228a7b7c1d27" category="list-text">このような Iguazio の実装により、ネットワーク障害を予防するための予防的措置を講じ、障害の 60% を予防しました。</block>
  <block id="fd80dbb606385d62c59605ec96147d3f" category="inline-link-macro">次の手順：セットアップの概要</block>
  <block id="d31627f0c8fea1236773b2420ab9cd39" category="paragraph"><block ref="d31627f0c8fea1236773b2420ab9cd39" category="inline-link-macro-rx"></block></block>
  <block id="8fcbbd73e86fa0b56d72d6127c318c85" category="paragraph">データの急増と機械学習（ ML ）と人工知能（ AI ）の急激な成長により、独自の開発と実装の課題を抱える新たな経済が生まれています。一般に、大量のデータが低コストのデータレイクに保存されます。このデータレイクでは、 GPU などのハイパフォーマンスな AI コンピューティングリソースは効率的にアクセスできません。このレポートでは、データサイエンスの実践者がデータハブを導入し、ワンクリックで、コンピューティングリソースに近い場所にデータセットのキャッシュを作成する新しい解決策を紹介します。その結果、 AI の実践者は、新しいデータセットバージョンハブによって強化されたコラボレーションを活用して、パフォーマンスに優れたモデルトレーニングをより簡単に実施できるようになります。</block>
  <block id="0c8a89e4d7937b03d3adc0f1d6530b08" category="paragraph"><block ref="0c8a89e4d7937b03d3adc0f1d6530b08" category="inline-link-macro-rx"></block></block>
  <block id="321cf11d6ad313e01614cfa7817893fb" category="doc">Jarvis の展開</block>
  <block id="24a0684c018bf0ed5e7001773d8df2c5" category="inline-link">Jarvis Early Access プログラム</block>
  <block id="55ce258288b89404cc493de8c839e20a" category="paragraph">にサインアップできます<block ref="de4a7b23900edb1996cbcb27f4a65904" category="inline-link-rx"></block> NVIDIA GPU Cloud （ NGC ）のジャービスコンテナにアクセスするため。NVIDIA から資格情報を受け取った後、以下の手順を使用して Jarvis を展開できます。</block>
  <block id="e5a6dabbbe3f9144d9f6e72b568893cd" category="list-text">NGC へのサインオン</block>
  <block id="a668e3da095eca41ef93e0c494a6ebad" category="list-text">NGC に組織を設定します :'ea -2- ジャービス '.</block>
  <block id="f3b0315f8d213517a6076eb7aff49cb6" category="list-text">Jarvis EA v0.2 資産の検索 : Jarvis コンテナは「プライベートレジストリ」＞「組織コンテナ」にあります。</block>
  <block id="6db8e9899d42bcac6aeb824da5e952ef" category="list-text">「 Jarvis 」を選択します。「 Model Scripts 」に移動し、「 Jarvis Quick Start 」をクリックします</block>
  <block id="737af365257800065a6412e56d652acc" category="list-text">すべてのアセットが正しく動作していることを確認します。</block>
  <block id="8a5fd124171d01a74b1af73e73ab7761" category="list-text">独自のアプリケーションを構築するためのドキュメントを検索します。 PDF は「 M odel Scripts 」 &gt; 「 Jarvis Documentation 」 &gt; 「ファイルブラウザ」にあります。</block>
  <block id="f3e3b1e7550f6cf9fe883b01695163b7" category="inline-link-macro">次のステップ：リテールのユースケースのステートとフローをカスタマイズします</block>
  <block id="3ae7e712d75bd01d43546679548a28a1" category="paragraph"><block ref="3ae7e712d75bd01d43546679548a28a1" category="inline-link-macro-rx"></block></block>
  <block id="f68b67869778246b8f0d8a98ed043512" category="paragraph">このセクションでは、仮想小売アシスタントの実装について詳しく説明します。</block>
  <block id="02216530e0245f79b0b7448e14bffbce" category="inline-link-macro">次の例は、 Jarvis の導入です</block>
  <block id="a9ca2532d8607b5827969961f314249e" category="paragraph"><block ref="a9ca2532d8607b5827969961f314249e" category="inline-link-macro-rx"></block></block>
  <block id="e7446d382d8184be0a342a2fc45d4394" category="doc">WP-7328 ：『 NetApp Conversational AI Using NVIDIA Jarvis 』</block>
  <block id="5dabc617366db74ce2a9fa3915f6af5a" category="paragraph">ネットアップ、 Rick Huang 、 Sung-Han Lin 、 NVIDIA 、 Davide Onofrio</block>
  <block id="018aacc6ea95e20996bf57b319fd037a" category="paragraph">NVIDIA DGX システムファミリーは、エンタープライズ AI に特化した世界初の人工知能（ AI ）ベースシステムで構成されます。NetApp AFF ストレージシステムは、卓越したパフォーマンスと業界をリードするハイブリッドクラウドデータ管理機能を提供します。ネットアップと NVIDIA は提携を通じて、 NetApp ONTAP AI リファレンスアーキテクチャを構築しました。このリファレンスアーキテクチャは、 AI と機械学習（ ML ）のワークロード向けのターンキー解決策であり、エンタープライズクラスのパフォーマンス、信頼性、サポートを提供します。</block>
  <block id="1a76c739ce37834495a22c5db663d24b" category="paragraph">このホワイトペーパーでは、さまざまな業種のさまざまなユースケースに対応した会話型 AI システムを構築するお客様にガイダンスを提供します。これには、 NVIDIA Jarvis を使用したシステムの導入に関する情報が含まれています。テストは NVIDIA DGX ステーションと NetApp AFF A220 ストレージシステムを使用して実施しました。</block>
  <block id="f813bd56d696cb8de386a53a37eed6f6" category="list-text">AI 開発のためのソリューションを設計するエンタープライズアーキテクト などの会話型 AI のユースケースに適したモデルとソフトウェア バーチャル・リテール・アシスタント</block>
  <block id="0497dfe9ff978e87977c978d3443e206" category="list-text">データサイエンティストは、言語モデリングを効率的に実現する方法を探しています 能力開発の目標</block>
  <block id="e84c345e30f668aa19a041e2e12bc9fe" category="list-text">テキストデータの保守と処理を担当するデータエンジニア お客様からの質問や会話の記録など</block>
  <block id="00101e6b2bf526b1ee79d39389f461fa" category="list-text">エグゼクティブや IT の意思決定者、および関心のあるビジネスリーダー 会話型 AI のエクスペリエンスを変革し、最速の時間を実現できます AI への取り組みから市場に投入</block>
  <block id="88851610d9d91a7b78ab814276bebba7" category="paragraph"><block ref="88851610d9d91a7b78ab814276bebba7" category="inline-link-macro-rx"></block></block>
  <block id="b682eee68510f6de72c9f48b832fba3c" category="inline-link"><block ref="b682eee68510f6de72c9f48b832fba3c" category="inline-link-rx"></block></block>
  <block id="3e5d8230d86c09995fcd8e9ccf335813" category="list-text">Cnvrg.io （<block ref="0691e14f48847a7f13eaf800c0f5813a" category="inline-link-rx"></block>）：</block>
  <block id="6536b07bf755c64528073e655a567c32" category="list-text">Cnvrg コア（無償の ML プラットフォーム）</block>
  <block id="0a16af2994c8e10c6c5976d774430a92" category="paragraph"><block ref="0a16af2994c8e10c6c5976d774430a92" category="inline-link-rx"></block></block>
  <block id="1b21ae34f592a7f2ca92d4a44122475d" category="list-text">Cnvrg のドキュメント</block>
  <block id="0730c44e9dc233c7fce5d95816294f52" category="inline-link"><block ref="0730c44e9dc233c7fce5d95816294f52" category="inline-link-rx"></block></block>
  <block id="f3a2f110576ed38849e70a6bb9794ae8" category="paragraph"><block ref="f3a2f110576ed38849e70a6bb9794ae8" category="inline-link-rx"></block></block>
  <block id="092940c9deac7c0f10a0ed36613c28c2" category="paragraph"><block ref="092940c9deac7c0f10a0ed36613c28c2" category="inline-link-rx"></block></block>
  <block id="492f548658890a1d2495b8af5cebef8c" category="paragraph"><block ref="11ff6f8fb3928ea5c0863401e5e79d17" category="inline-link-rx"></block></block>
  <block id="717108fd0999828c4a6d8290d419733b" category="list-text">NIH 胸部 X 線データセット</block>
  <block id="4eb7427d14327fa86230f324870dc6b8" category="paragraph"><block ref="4eb7427d14327fa86230f324870dc6b8" category="inline-link-rx"></block></block>
  <block id="f249b6ce18772b83efb8a6e58ac09d47" category="list-text">Xiaosong Wang 、 Yifan Peng 、 Le Lu 、 Zhiyong Lu 、 Mohammadhadi Bagheri 、 ロナルド・サマーズ、 ChestX-Ray8 ：『 Hospital scale Chest X-ray Database and Benchmarks on weakly Supervised Classification and Localization of Common Thorax Diseases 、 IEEE CVR 、 pp3462-3471 、 2017TR-4841-0620</block>
  <block id="1e3ecab57c1572b4a25412b1e395562a" category="paragraph">特定のユースケースに合わせてダイアログマネージャーの状態とフローをカスタマイズできます。小売業の例では、次の 4 つの YAML ファイルを使用して、異なるインテントに従って会話を誘導します。</block>
  <block id="608f6d7dfd7bc98630446f0c601cc730" category="paragraph">各ファイルについて、次のファイル名と概要のリストを用意します。</block>
  <block id="77d10e2958e3d21f89adae8647e8d0d2" category="list-text">`main_flow.yml`: 主な会話の流れと状態を定義し、必要に応じて他の 3 つの YAML ファイルにフローを指示します。</block>
  <block id="96b445ea5c6b049dfc1250466b6bdf2e" category="list-text">`retail_flow.yml`: 小売業または関心のある点に関する質問に関連する状態を含みます。システムは最も近い店の情報、または与えられた項目の価格を提供する。</block>
  <block id="17a0ea5055e6be908d7e2f6f983aa471" category="list-text">`weater_flow.yml`: 天気に関する質問に関連する州を含みます。場所を特定できない場合は、フォローアップの質問をして明確にします。</block>
  <block id="ade7d8cc2b23f24add45c4096dd41795" category="list-text">`error_flow.yml`: ユーザのインテントが上記の 3 つの YAML ファイルに入っていないケースを処理します。エラーメッセージを表示した後、システムはユーザーの質問を受け入れるように再経路化します。次のセクションでは、これらの YAML ファイルの詳細な定義を示します。</block>
  <block id="ef7c28f5093b59a07761555c8914df26" category="section-title">main_flow.yml</block>
  <block id="dfc9a806326d590aa4ccf49aa6909cda" category="section-title">retail _flow.yml</block>
  <block id="6e08d9d65c68d5f447f4fd239052c12e" category="section-title">weater_flow.yml</block>
  <block id="b7dc1d2ced2caa9352158983c5ffeda1" category="section-title">ERROR_FLOW.yml</block>
  <block id="c6496825f1a87696b60935af9416283a" category="inline-link-macro">次の手順：サードパーティの API に欠品補充エンジンとして接続します</block>
  <block id="3a9d38bca913120b9d3638cb194cd7e6" category="paragraph"><block ref="3a9d38bca913120b9d3638cb194cd7e6" category="inline-link-macro-rx"></block></block>
  <block id="368c8f521d74a015b7a3e1a46c8847b1" category="paragraph">このセクションでは、 Kubeflow を使用して実行したいさまざまな操作とタスクの例を示します。</block>
  <block id="33204bfa9ee287508f03782fd7ad512e" category="summary">Trident を使用して Kubernetes クラスタ内のストレージリソースを動的にプロビジョニングするには、 Kubernetes StorageClasses を 1 つ以上作成する必要があります。このページの例は、 ONTAP AI ポッドにネットアップ AI コントロールプレーン解決策を導入する場合に作成する、さまざまなタイプのストレージクラスを表しています。</block>
  <block id="d9206a5144976221af82df78ad3d7977" category="paragraph">Trident を使用して Kubernetes クラスタ内のストレージリソースを動的にプロビジョニングするには、 Kubernetes StorageClasses を 1 つ以上作成する必要があります。以下に示す例は、 ONTAP AI ポッドにネットアップ AI コントロールプレーン解決策を導入する場合に作成する、さまざまなタイプのストレージクラスを表しています。StorageClasses の詳細については、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Kubernetes のドキュメント</block>
  <block id="a596fcc71d1c43e3ba86b1557ac7af81" category="paragraph">対応する PersistentVolumeClaim （ PVC ）が削除されたときに永続ボリュームが削除されないようにするため、次の例では「 Retain 」の「 ReclaimPolicy 」の値を使用しています。「 ReclaimPolicy 」フィールドの詳細については、公式を参照してください<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block>。</block>
  <block id="99608a01905f0e69895bbb864a0deba3" category="paragraph">次の例では、 FlexVol 対応の Trident バックエンドが 1 つしか作成されていないため、 StorageClass 定義ファイルで特定のバックエンドが指定されていません。Kubernetes を使用してこの StorageClass を使用するボリュームを管理すると、 Trident は「 ONTAP-NAS' 」ドライバを使用するバックエンドで利用可能なものを使用しようとします。</block>
  <block id="ee1d27a4ae3e30ff30ef72e305b029e7" category="list-text">また、 FlexGroup ボリューム用の汎用の StorageClass を作成することを推奨します。次のコマンド例は、 FlexGroup ボリューム用の汎用の StorageClass を 1 つ作成する方法を示しています。</block>
  <block id="d4a43a35c5d5a5ce3aefe77ceaa73a5c" category="paragraph">特定のバックエンドが StorageClass 定義ファイルで指定されていないことに注意してください。したがって、 Kubernetes を使用してこのストレージクラスを使用するボリュームを管理する場合、 Trident は「 ONTAP-NAS-flexgroup 」ドライバを使用する利用可能なバックエンドを使用しようとします。</block>
  <block id="2732cb29fe3befd83c06e7c220b5456d" category="doc">セクション 4.10 のテストの詳細</block>
  <block id="273936fc522fd7dbe4473de8a0b2a985" category="paragraph">ここでは、のテストについて詳しく説明します <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>。</block>
  <block id="cf46f9264bb33ef7576cf671194a0275" category="paragraph">「 team -a 」、「 team -b 」、「 team -c 」の順にジョブを送信します。</block>
  <block id="fac80c1054e849e1ec88244c017978e7" category="cell">1 個のワークロードをキューに登録</block>
  <block id="eefc99cd833e14811fb22b758cbc62e5" category="cell">2 個のワークロードがキューに登録</block>
  <block id="be46ffa9e65cb964fc3236de02c41e4e" category="paragraph">実行される次のコマンドシーケンスを参照してください。</block>
  <block id="001f9003205f670658ffc60b1e4d62d8" category="cell">2 つのワークロードがそれぞれ 2 つの GPU を必要とします</block>
  <block id="f0f10ddbe8f00433aad17626c8d96a73" category="cell">2 つのワークロードがそれぞれ 2 つの GPU を必要とします</block>
  <block id="f82056dbbe3376b10ac622b0bdaae914" category="cell">8 月 8 日</block>
  <block id="61b8291124bff8ee36a1c799e35395e9" category="paragraph">次に 'team -d のすべてのワークロードを削除します</block>
  <block id="ed9cf33d84548b5953f8b042c72faef4" category="paragraph">を参照してください <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>を参照してください。</block>
  <block id="543cdcd352596e4ad69b4597a2188c02" category="paragraph"><block ref="543cdcd352596e4ad69b4597a2188c02" category="inline-link-macro-rx"></block></block>
  <block id="5b7a8a379330d9d43907b47a6d7ee306" category="doc">Nemo トレーニングを使用してインテントモデルを拡張する</block>
  <block id="a7fbadb37067070a61a3da62b548ba3c" category="paragraph">NVIDIA Nemo は、会話型 AI アプリケーションを作成するために NVIDIA が開発したツールキットです。このツールキットには、 ASR 、 NLP 、 TTS 用のトレーニング済みモジュールのコレクションが含まれています。これにより、研究者やデータサイエンティストは複雑なニューラルネットワークアーキテクチャを簡単に構築し、独自のアプリケーションの設計に集中できるようになります。</block>
  <block id="1a56a4858eeec63d31bc890d38325b84" category="paragraph">前の例で示したように、奈良は限られたタイプの質問しか処理できない。これは、トレーニング済みの NLP モデルでは、これらのタイプの質問についてのみトレーニングを受けているためです。奈良がより幅広い質問に対応できるようにするには、独自のデータセットを使って再トレーニングする必要があります。ここでは、 Nemo を使用して NLP モデルを拡張し、要件を満たす方法を示します。まず、奈良から収集したログを Nemo の形式に変換し、 NLP モデルを強化するためのデータセットを使って学習します。</block>
  <block id="4e19d1e300ea3cd63472939c24caf65d" category="paragraph">私たちの目標は、ユーザーの好みに基づいてアイテムを並べ替えることです。たとえば、奈良に最高級の寿司レストランを提案したり、奈良に最も安い価格のジーンズを探してもらうようにしたりすることができます。このためには、 Nemo で提供されているインテント検出とスロット充填モデルをトレーニングモデルとして使用します。このモデルにより、奈良は検索の好みを理解することができる。</block>
  <block id="5cb83e5ef3cd25eb53fa55d635a7758f" category="section-title">データの準備</block>
  <block id="807cace7b07fcded06b9d106c4dd4d2d" category="paragraph">モデルをトレーニングするには、このタイプの質問のデータセットを収集し、 Nemo 形式に変換します。ここでは、モデルのトレーニングに使用するファイルをリストしました。</block>
  <block id="dc1d3747ed1059f234cbe4a104700abd" category="section-title">dict.intents.csv</block>
  <block id="e803005a5c3a99889733e9c8e8bba406" category="paragraph">このファイルには、 Nemo に理解してもらいたいすべてのインテントが一覧表示されます。ここでは、主なインテントが 2 つあり、 1 つのインテントは、主なインテントのどれにも当てはまらない質問を分類するために使用されます。</block>
  <block id="ce2440c5074ba6a1e30fa2ec906dafb4" category="section-title">dict.slots.csv</block>
  <block id="a3fc542c51797c85b30365ba9b2d12c5" category="paragraph">このファイルには、トレーニングの質問にラベルを付けることができるすべてのスロットが記載されています。</block>
  <block id="795cab38744084526a62914e47789fbe" category="section-title">鉄道 .tsv</block>
  <block id="8a5ae45ea3762f79d1a520bcf61275d5" category="paragraph">これが主なトレーニングデータセットです。各行は、 dict.intent.csv ファイルのインテントカテゴリのリストに続く質問から始まります。ラベルはゼロから列挙されます。</block>
  <block id="db487d8daea13e36203f660d46b3cdfc" category="section-title">train slots.tsv</block>
  <block id="73ade6fc5004174d2abe822c85cdfbef" category="section-title">モデルのトレーニング</block>
  <block id="c764142480a5daa39ac98125503352e8" category="paragraph">次に、次のコマンドを使用してコンテナを起動します。このコマンドでは、軽量なトレーニング用の演習であるため、コンテナで使用する GPU は 1 つに制限されます（ GPU ID = 1 ）。また、ローカルワークスペース / ワークスペース /Nemo/ をコンテナ /Nemo 内のフォルダにマッピングします。</block>
  <block id="a712c52af847db1e143ca43fdd44bd39" category="paragraph">コンテナ内では、事前にトレーニングされたオリジナルの BERT モデルから開始する場合、次のコマンドを使用してトレーニング手順を開始できます。data_dir は、トレーニングデータのパスを設定する引数です。work_dir では ' チェックポイント・ファイルを保存する場所を設定できます</block>
  <block id="9e654b2215e90d20951b3ddd67a15bc6" category="paragraph">新しいトレーニングデータセットがあり、以前のモデルを改善したい場合は、次のコマンドを使用して停止した時点から続行できます。checkpoint_dir は ' 前のチェックポイント・フォルダへのパスを取得します</block>
  <block id="87eea49f703666c49da2d7987ba093b2" category="section-title">モデルを推論します</block>
  <block id="484c4e9e4a0a20bf41551f65663fa9d2" category="paragraph">トレーニング済みモデルのパフォーマンスは、一定の期間の経過後に検証する必要があります。次のコマンドを使用すると、 1 つずつクエリをテストできます。たとえば、このコマンドでは、モデルがクエリの意図を正しく識別できるかどうかを確認します。クエリの目的は、「ここで最高のパスタを取得できる」です。</block>
  <block id="de558a28e6333ac9f453a42631f44c12" category="paragraph">次に、推論からの出力を示します。出力では、トレーニング済みモデルが意図を正しく予測し、関心のあるキーワードを返すことができます。これらのキーワードを使うことで、奈良はユーザが欲しいものを検索し、より正確な検索を行うことができるようになります。</block>
  <block id="5b7f09a1d5da38512130330f4d38fd32" category="paragraph"><block ref="5b7f09a1d5da38512130330f4d38fd32" category="inline-link-macro-rx"></block></block>
  <block id="84860cc77161e23e44eccd05430c00ea" category="doc">実行中のジョブの送信： AI CLI</block>
  <block id="68c9d249f35c91dfcc4a11e209ccbdba" category="paragraph">このセクションでは、 Kubernetes ジョブの実行に使用できる基本的な Run ： AI コマンドについて詳しく説明します。ワークロードの種類に応じて 3 つの要素に分割されます。AI / ML / DL のワークロードは、次の 2 つの汎用タイプに分けることができます。</block>
  <block id="754edd5bae16b4a2ed8e6673821d3339" category="list-text">* 無人トレーニングセッション * 。このようなタイプのワークロードを扱うことで、データサイエンティストは自己実行ワークロードを準備し、実行のためにワークロードを送信します。実行中に、お客様は結果を確認できます。このタイプのワークロードは、多くの場合、本番環境で使用されます。また、モデル開発が段階で行われるため、手動操作は必要ありません。</block>
  <block id="fdfda155b7c1021ae5e73d2ab01c0129" category="list-text">* インタラクティブビルドセッション * 。このようなワークロードの場合、データサイエンティストは Bash 、 Jupyter Notebook 、リモート PyCharm などの IDE を使用した対話型セッションを開始し、 GPU リソースに直接アクセスします。次に、対話型のワークロードを実行してポートを接続し、コンテナユーザに内部ポートを表示するシナリオを紹介します。</block>
  <block id="6ec08732676824c58d76b0ecdc2aed24" category="section-title">無人トレーニングのワークロード</block>
  <block id="18cb2734d0533ff093ddcb1b3005e216" category="paragraph">プロジェクトをセットアップして GPU を割り当てたら、コマンドラインで次のコマンドを使用して Kubernetes のワークロードを実行できます。</block>
  <block id="68e667063c4711033bbf6b7f8b312e1f" category="paragraph">このコマンドは、単一の GPU を割り当てたチーム A の無人トレーニングジョブを開始します。このジョブは、サンプルの Docker イメージである「 gcr.io/run-ai-demo/QuickStart 」に基づいています。私たちはジョブ「 hyper1 」と名付けました。その後、次のコマンドを実行して、ジョブの進捗状況を監視します。</block>
  <block id="cbae10285b6d282e740369a59fd25aaf" category="paragraph">次の図に 'runai list' コマンドの結果を示します一般的なステータスは次のとおりです。</block>
  <block id="e749e4e3bf7ed6d5368f336ba6ceeead" category="list-text">「 ContainerCreating 」を参照してください。Docker コンテナをクラウドリポジトリからダウンロードしています。</block>
  <block id="f5231f23820da3ad520bb16a9dfe97a7" category="list-text">「保留中」。ジョブはスケジュールされるのを待っています。</block>
  <block id="411497b40a902afd2813d3c7af137ffb" category="list-text">「ランニング」。ジョブが実行中です。</block>
  <block id="c0801feb8216aa6b36a769e14c3bc138" category="paragraph"><block ref="c0801feb8216aa6b36a769e14c3bc138" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4f5f0c8fb5ec5bccf18cfd167b1d3bc5" category="paragraph">ジョブのステータスをさらに表示するには、次のコマンドを実行します。</block>
  <block id="db0b192c9c9b9885b435e466b9ac861c" category="paragraph">ジョブのログを表示するには、「 runai logs &lt;job-name&gt; 」コマンドを実行します。</block>
  <block id="280782f59c990a941b600c998427a52c" category="paragraph">この例では、現在のトレーニングエポック、 ETA 、損失関数値、精度、および各ステップの経過時間を含む、実行中の DL セッションのログを確認する必要があります。</block>
  <block id="848ad760ae00e3eca33445cd09cfdf34" category="paragraph">クラスタのステータスは、 Run ： AI UI で確認できます から<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>。[ ダッシュボード ]&gt;[ 概要 ] で、 GPU 利用率を監視できます。</block>
  <block id="f899123d07ffe99c3d97952ae96017ed" category="paragraph">このワークロードを停止するには、次のコマンドを実行します。</block>
  <block id="1f979b6140776c287d458036805ad8aa" category="inline-link">無人トレーニングワークロードの開始</block>
  <block id="637552715214e8c0c87022bac459e824" category="paragraph">このコマンドを実行すると、トレーニングワークロードが停止します。このアクションを確認するには 'runai list' をもう一度実行します詳細については、を参照してください<block ref="e5fbbc266c1fd3a9a029581f5747622d" category="inline-link-rx"></block>。</block>
  <block id="7afece97948db40e546138d81dd343e1" category="section-title">ワークロードを対話型に構築</block>
  <block id="30330792601ba24e9ad5f4f5ee0d5151" category="paragraph">プロジェクトをセットアップして GPU を割り当てたら、コマンドラインで次のコマンドを使用して対話型ビルドワークロードを実行できます。</block>
  <block id="ca57038d87e3f48eb98329e6fd449824" category="paragraph">このジョブは、サンプルの Docker イメージ Python に基づいています。ジョブ build1 という名前を付けました。</block>
  <block id="39fd96ce47a2aa757eb5cc98cd910730" category="admonition">「 --interactive 」フラグは、ジョブが開始または終了していないことを意味します研究者の責任で業務を終了してください。管理者は、対話型ジョブがシステムによって終了されるまでの時間制限を定義できます。</block>
  <block id="d39d9c693980c2af510d4a58be6f2620" category="paragraph">--g 1' フラグは ' このジョブに 1 つの GPU を割り当てます与えられたコマンドと引数は、「 --command sleep -- args インフィニティ」です。コマンドを指定するか、コンテナを開始してすぐに終了する必要があります。</block>
  <block id="aedc6bf8e3cb52af4a660584c69353ca" category="paragraph">次のコマンドは、で説明したコマンドと同様に機能します <block ref="a09c3ced87a580a4004dfa2429aba9c7" category="inline-xref-macro-rx"></block>：</block>
  <block id="1d2bac5ee25c12c0ee793df98c1b4d49" category="list-text">runai list` ：名前、ステータス、経過時間、ノード、イメージ、 プロジェクト、ユーザ、 GPU によるジョブの処理</block>
  <block id="6b5b5fdb13c8b8af02a41b296af91a2e" category="list-text">runai get build1`: ジョブ build1 の追加ステータスを表示します。</block>
  <block id="9c1e129aa488b11d05275f016f42dda5" category="list-text">runai delete build1`: 対話型のワークロード build1 を停止しますコンテナに bash シェルを取得するには ' 次のコマンドを実行します</block>
  <block id="ac97b61bdc50cfc22ffd507de190d00c" category="paragraph">これにより、コンピュータにシェルが直接挿入されます。データサイエンティストは、コンテナ内でモデルを開発または微調整できます。</block>
  <block id="5051a9eb1fad38f876a260ba0a4850af" category="inline-link"><block ref="5051a9eb1fad38f876a260ba0a4850af" category="inline-link-rx"></block></block>
  <block id="c7fdd5fcf033fb9395c27ecbf2e54fc9" category="inline-link">対話型ビルドワークロードの開始と使用</block>
  <block id="ff53dc42327d97c7410a6ac241222ffe" category="paragraph">クラスタのステータスは、 Run ： AI UI で確認できます から<block ref="29f2b88109b12c4db8e875d3f5ba7aae" category="inline-link-rx"></block>。詳細については、を参照してください<block ref="f3d6ab8050b43c83f452779c7622ab1d" category="inline-link-rx"></block>。</block>
  <block id="1028c65994f7201e0f43b3bf5d3c6b41" category="section-title">ポートが接続された対話型のワークロード</block>
  <block id="7d05c708b92b4809bfe9bf66edf8f765" category="inline-link">入力</block>
  <block id="34274fcc13408f06acfe43c4065c3f3b" category="paragraph">Run ： AI CLI でコンテナを開始する際に、対話型ビルドワークロードを拡張することで、コンテナユーザに内部ポートを公開できます。これは、クラウド環境、 Jupyter Notebook の操作、その他のマイクロサービスへの接続に役立ちます。<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> Kubernetes クラスタの外部から Kubernetes サービスへのアクセスを許可します。アクセスを設定するには、どのインバウンド接続がどのサービスに到達するかを定義する一連のルールを作成します。</block>
  <block id="e7f72a2c9a0cb7337eb00a3093f846da" category="paragraph">クラスタ内のサービスへの外部アクセスを適切に管理するには、クラスタ管理者がインストールすることを推奨します<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> ロードバランサを設定します。</block>
  <block id="16d79943625573d5b80809fe2a7ddbdd" category="paragraph">入力をサービスタイプとして使用するには、次のコマンドを実行して、ワークロード送信時にメソッドタイプとポートを設定します。</block>
  <block id="79fcc0299f1a85ebab053926e2222bca" category="paragraph">コンテナが正常に起動したら、「 runai list 」を実行して、 Jupyter Notebook にアクセスする「サービス URL (S) 」を確認します。URL は、入力エンドポイント、ジョブ名、およびポートで構成されます。たとえば、を参照してください<block ref="0309fbe8f364c8f6dfe6f383da8c46c2" category="inline-link-rx"></block>。</block>
  <block id="451b08ed1bf6f7f0a8931cff52c4c45e" category="inline-link">ポートが接続されている対話型のビルドワークロードを起動する</block>
  <block id="b524842923f8cb1e38064fadc680893f" category="paragraph">詳細については、を参照してください<block ref="414875add8a18a03ddddfb14fb1c47f4" category="inline-link-rx"></block>。</block>
  <block id="5bb97c2dd089da990a792356c72a6128" category="inline-link-macro">次は、高いクラスタ利用率を達成することです</block>
  <block id="8f87de13e6ff3dd2fc164bdb930759bb" category="paragraph"><block ref="8f87de13e6ff3dd2fc164bdb930759bb" category="inline-link-macro-rx"></block></block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">ネットアップ、 Mike Oglesby</block>
  <block id="9f1cc947f3e0236f8d5bc32d8d33509a" category="inline-link">cloud.netapp.com</block>
  <block id="1f39acb56ba2a8669371819a64348c74" category="paragraph"><block ref="1f39acb56ba2a8669371819a64348c74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed8e4613850a4014b0e6ef830982caf2" category="paragraph">ここでは、のテストについて詳しく説明します <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>。</block>
  <block id="17b3673d5c28fb72e7cc48549f489dd4" category="cell">6 月 8 日</block>
  <block id="ffe090618e54b7916fa47cf8881019b1" category="cell">team -b/c ワークロードが一時停止し、「 pending 」に移動します。</block>
  <block id="bccfe4ac65004fb31c146d17003d00e8" category="cell">他のチーム (b/c) のワークロードは一時停止し、「保留中」に移動します。</block>
  <block id="3b099141b6a7e4e8804c3fda5ed4f440" category="paragraph">を参照してください <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="5d52789e4f8028aca21d5650bed8273b" category="inline-link-macro">次のセクション 4.10 のテストの詳細</block>
  <block id="61a1556247485f1d0fbb34dbe36d1503" category="paragraph"><block ref="61a1556247485f1d0fbb34dbe36d1503" category="inline-link-macro-rx"></block></block>
  <block id="aa364e0963e38930007df2b60bdba067" category="doc">Trident でプロビジョニングされた永続的ボリュームにデータを保存する</block>
  <block id="ef1fb51957f2aa894de5476a9a0112a2" category="paragraph">NetApp Trident は、コンテナ化されたアプリケーションが求める高度な永続性のニーズに対応できるように設計された、完全にサポートされているオープンソースプロジェクトです。Trident でプロビジョニングされた Kubernetes PersistentVolume （ PV ）に対してデータの読み取りと書き込みを行うことができ、データ階層化、暗号化、 NetApp Snapshot テクノロジ、コンプライアンス、 NetApp ONTAP データ管理ソフトウェアが提供する高パフォーマンスといったメリットも活用できます。</block>
  <block id="a821f368daf439d909bfed3c8e95d4b9" category="section-title">既存の名前空間での PVC の再利用</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link">NetApp Trident のドキュメント</block>
  <block id="15040fc521e7fa5e8ef42694ca89e53d" category="paragraph">大規模な AI プロジェクトでは、異なるコンテナで同じ Kubernetes PV に対してデータの読み取りや書き込みを行う方が効率的な場合があります。Kubernetes Persistent Volume Claim （ PVC ；永続ボリューム要求）を再利用するには、ユーザが PVC を作成しておく必要があります。を参照してください<block ref="5b6274adc29653ed1820027957bdb4e2" category="inline-link-rx"></block> PVC 作成の詳細については、を参照してください。次に、既存の PVC を再利用する例を示します。</block>
  <block id="743520c366f0d11ca817811dda85fcf1" category="paragraph">次のコマンドを実行して ' プロジェクト 'team -a' のジョブ pvc-test' のステータスを表示します</block>
  <block id="7d4c508442c775f946e3d9318b75b1a0" category="paragraph">'team -a' ジョブ 'pvctest' にマウントされた PV /tmp/pvc1mount が表示されますこのようにして、複数のコンテナが同じボリュームから読み取ることができるため、開発中または本番環境で競合する複数のモデルが存在する場合に便利です。データサイエンティストは、モデルのアンサンブルを構築し、大多数の投票またはその他の技術によって予測結果を組み合わせることができます。</block>
  <block id="dae81aa45b8ce281aabbd1402afe277b" category="paragraph">次のコマンドを使用してコンテナシェルにアクセスします。</block>
  <block id="bc63da8fa87210da818596598e359427" category="paragraph">その後、マウントされたボリュームを確認し、コンテナ内のデータにアクセスできます。</block>
  <block id="fc180b17e3fccb2beb46854f71d31406" category="paragraph">PVC の再利用というこの機能は、 NetApp FlexVol ボリュームと NetApp ONTAP FlexGroup ボリュームと連携します。そのため、データエンジニアは、より柔軟で堅牢なデータ管理オプションを利用して、ネットアップのデータファブリックを活用できます。</block>
  <block id="2e203cb5454e63a32bcdb87dc9cb77ad" category="paragraph"><block ref="2e203cb5454e63a32bcdb87dc9cb77ad" category="inline-link-macro-rx"></block></block>
  <block id="52c7321ea4e3d5b264fdc8639a65e280" category="doc">Grafana ダッシュボードを導入します</block>
  <block id="c843fc0ceca9c58b409cab519799c125" category="paragraph">すべてのデータを導入したら、新しいデータに対して推論を実行します。このモデルは、ネットワークデバイス機器の障害を予測します。予測の結果は、 Iguazio 時系列テーブルに格納されます。Iguazio のセキュリティおよびデータアクセスポリシーと統合されたプラットフォームで、 Grafana を使用して結果を表示できます。</block>
  <block id="ae93e86067cc1d0e7bb1ec8fdca6fbc3" category="paragraph">ダッシュボードを導入するには、指定した JSON ファイルをクラスタ内の Grafana インターフェイスにインポートします。</block>
  <block id="213977705fe35a4cb0cfc9365088fc87" category="list-text">Grafana サービスが実行されていることを確認するには、 Services の下を参照してください。</block>
  <block id="b426c25dbb35de6b9c6bff0b10b8bef9" category="paragraph"><block ref="b426c25dbb35de6b9c6bff0b10b8bef9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b6e0cc0a098260878a0e8fa4eb7766" category="list-text">インスタンスが存在しない場合は、 [ サービス ] セクションからインスタンスを展開します。</block>
  <block id="cd40a7a2e0a86f4a0283af5999a050db" category="list-text">[ 新しいサービス ] をクリックします。</block>
  <block id="59c4bcb990174489660974167376a50a" category="list-text">リストから Grafana を選択します。</block>
  <block id="7e280ecf88737f34a1972ac94f9ae2a1" category="list-text">デフォルトを受け入れます。</block>
  <block id="9e47b36567e5001dea59ffee81456737" category="list-text">次のステップをクリックします。</block>
  <block id="4fa350b43dd079673b6fca4852841147" category="list-text">ユーザ ID を入力します。</block>
  <block id="af81385be6cef15b54f8c8c126c0eab0" category="list-text">[ サービスの保存 ] をクリックします</block>
  <block id="568c8b6f668936384414e470f9ddd939" category="list-text">上部の [Apply Changes] をクリックします。</block>
  <block id="b5be50b376063d6c3ffaa3be10d4a9d3" category="list-text">ダッシュボードを展開するには、 Jupyter インターフェイスから「 NetopsPredictions - Dashboard.json 」ファイルをダウンロードします。</block>
  <block id="587b311a501585c3a1d9260d4f147990" category="paragraph"><block ref="587b311a501585c3a1d9260d4f147990" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ad16c6527a3abd13b6864b8b078586b" category="list-text">Services セクションで Grafana を開き、ダッシュボードをインポートします。</block>
  <block id="0b78dd574d02d72071845d040fdde57c" category="paragraph"><block ref="0b78dd574d02d72071845d040fdde57c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3ce0bca8ff75db7ff2bbc3e76532b2" category="list-text">Upload `*.json ’ File をクリックして、以前にダウンロードしたファイル (`NetopsPredictions - Dashboard.json ') を選択します。アップロードが完了すると、ダッシュボードが表示されます。</block>
  <block id="7cd4d06091771aa3f16d2759a067e18c" category="paragraph"><block ref="7cd4d06091771aa3f16d2759a067e18c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0258dc4515b0e18ecd4b55651e27671" category="section-title">デプロイクリーンアップ機能</block>
  <block id="ff4bdefb3ddd7532393d08c8df14d786" category="paragraph">大量のデータを生成する場合は、すべてをクリーンで整理することが重要です。これを行うには 'cleanup.ipynb' ノートブックを使用してクリーンアップ機能を配備します</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="section-title">利点</block>
  <block id="6d0f7ccc9b17bcabb743cabdfb56e0da" category="paragraph">ネットアップと Iguazio は、 Kubeflow 、 Apache Spark 、 TensorFlow などの必須フレームワークや、 Docker や Kubernetes などのオーケストレーションツールを構築することで、 AI アプリケーションや ML アプリケーションの導入を迅速化し、簡易化します。ネットアップと Iguazio は、エンドツーエンドのデータパイプラインを統合することで、多くの高度なコンピューティングワークロードに固有のレイテンシと複雑さを軽減し、開発と運用のギャップを効果的に解消します。データサイエンティストは、大規模なデータセットに対してクエリを実行し、トレーニングフェーズ中にデータやアルゴリズムのモデルを権限のあるユーザと安全に共有できます。コンテナ化されたモデルを本番環境で使用できるようになったら、開発環境から運用環境に簡単に移行できます。</block>
  <block id="daee7e425c63dff416cde0a8932a8483" category="paragraph"><block ref="daee7e425c63dff416cde0a8932a8483" category="inline-link-macro-rx"></block></block>
  <block id="612edeb05f6d237e20f3d843d6e7eba4" category="paragraph">以下のセクションでは、この検証で実行した AI のインストール、テストシナリオ、結果について詳しく説明します。</block>
  <block id="2df14da3d7db15550e8eafc892e89d8e" category="paragraph">TensorFlow ベンチマークを含む業界標準のベンチマークツールを使用して、このシステムの動作とパフォーマンスを検証しました。ImageNet データセットを使用して ResNet-50 をトレーニングしました。これは、画像分類のための有名な Convolutional Neural Network （ CNN ；畳み込みニューラルネットワーク） DL モデルです。ResNet-50 は、処理時間を短縮して正確なトレーニング結果を提供します。これにより、ストレージに対する十分な需要を喚起することができました。</block>
  <block id="a89cd2a9c8244dab756ec04aeb8247e9" category="inline-link-macro">次の手順： AI インストールを実行します</block>
  <block id="13bb3aa52565b3e3f517764c0e88c324" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block>。</block>
  <block id="afee48a46dd68b9618cec81a8ee5ba86" category="paragraph">このセクションでは、 ONTAP AI 解決策のテクノロジ要件について説明します。</block>
  <block id="e96b7604f8b75ae786c6c0e1016e46fd" category="inline-link">ONTAP AI Web サイト</block>
  <block id="929f5f13d86d1be55b96dba26e773c6f" category="paragraph">ハードウェア要件はお客様のワークロードによって異なりますが、 ONTAP AI は、大規模な ML/DL 運用向けに、単一の GPU からラックスケール構成まで、あらゆる規模のデータエンジニアリング、モデルトレーニング、本番環境推論に導入できます。ONTAP AI の詳細については、を参照してください<block ref="7ec9b089c41da1b986bad97e1099df1c" category="inline-link-rx"></block>。</block>
  <block id="41e840b508d9e839f95d16dd582af8d6" category="paragraph">この解決策は、コンピューティングには DGX-1 システム、ネットワーク接続には NetApp AFF A800 ストレージシステム、 Cisco Nexus 3232C を使用して検証しました。この検証で使用される AFF A800 は、ほとんどの ML/DL ワークロードで最大 10 台の DGX-1 システムをサポートできます。次の図に、この検証でモデルのトレーニングに使用する ONTAP AI トポロジを示します。</block>
  <block id="bc2eb92d1e1797a759b677c38f619a8f" category="paragraph"><block ref="bc2eb92d1e1797a759b677c38f619a8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d98e5c43e7b3be89fe8a9076f89f1e99" category="paragraph">この解決策をパブリッククラウドに拡張するために、 Cloud Volumes ONTAP をクラウド GPU コンピューティングリソースと一緒に導入し、ハイブリッドクラウドデータファブリックに統合することで、お客様は特定のワークロードに適したリソースを自由に使用できます。</block>
  <block id="4dc70b997a39a64b2def3ef74a96fdb4" category="paragraph">次の表に、この解決策検証で使用されるソフトウェアのバージョンを示します。</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">コンポーネント</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="d173e10eb6a0fc7969fe540c987e0c7d" category="cell">18.04.4 LTS</block>
  <block id="9b4bffa460105781f82b1d463bde8200" category="cell">4.4.0</block>
  <block id="3c1d47ba5c1ada327abd4532ff9f4437" category="cell">20.02.1</block>
  <block id="0083e57a258edd18b949d3afbf6cfc2a" category="cell">1.15</block>
  <block id="152090ff5e9a05ea7e1cf0c248449638" category="cell">Helm</block>
  <block id="232de5556d4148d75b55012e1230616c" category="cell">3.1.0</block>
  <block id="e5e8ab661917b89b4161959c7dc28442" category="cell">cnvrg.io</block>
  <block id="272f0a04b740763e0a29316bc4af89a4" category="cell">3.0.0</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="cell">NetApp ONTAP</block>
  <block id="d8a31094f88724af6834c47a6697dc56" category="cell">9.6P4</block>
  <block id="9909115a4f9fe32731077286c367501c" category="paragraph">この解決策検証では、 Kubernetes を DGX-1 システム上にシングルノードクラスタとして導入しました。大規模な導入の場合は、管理サービスの高可用性を実現し、 ML ワークロードと DL ワークロードに貴重な DGX リソースを確保するために、独立した Kubernetes マスターノードを導入する必要があります。</block>
  <block id="1c428dd76324aae91879799ae73fbc37" category="inline-link-macro">次のステップ：解決策の導入と検証の詳細</block>
  <block id="5e5761a91dc25c881f4ca86678634b1b" category="paragraph"><block ref="5e5761a91dc25c881f4ca86678634b1b" category="inline-link-macro-rx"></block></block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">追加情報</block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">ネットアップの製品マニュアル</block>
  <block id="7661400c51b9fc184bdec46eb5577ff9" category="doc">GitHub からコードを取得します</block>
  <block id="1a3652d661d6b73b6aa57aff1fa5e4d4" category="paragraph">これで、 Iguazio クラスタおよび開発者環境で NetApp Cloud Volume または NetApp Trident ボリュームを使用できるようになりました。アプリケーションの確認を開始できます。</block>
  <block id="ae53ae826cc9a587fbaee0e834dd75ca" category="paragraph">ユーザは独自のワークスペース（ディレクトリ）を持ちます。すべてのノートブックで ' ユーザー・ディレクトリへのパスは '/User' ですIguazio プラットフォームは、ディレクトリを管理します。上記の手順に従った場合、 NetApp Cloud ボリュームは「 /NetApp 」ディレクトリにあります。</block>
  <block id="754e85a9ea7f4fbb718080a73790abdb" category="paragraph">Jupyter 端子を使用して GitHub からコードを取得します。</block>
  <block id="1d706cc291efb1d79274befd6f9dd64c" category="paragraph"><block ref="1d706cc291efb1d79274befd6f9dd64c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12d0e4b8ba8db4e6a7aa1dda942a1ed4" category="paragraph">Jupyter ターミナルのプロンプトで、プロジェクトのクローンを作成します。</block>
  <block id="d4095d9e0ab52b6d683ace00b5cbea55" category="paragraph">Jupyter ワークスペースのファイルツリーには、「 NetOps - NetApp 」フォルダが表示されます。</block>
  <block id="f8161ff446bbd6f76b0d99d6f34a1d7f" category="inline-link-macro">次の手順：作業環境を構成します</block>
  <block id="48dd929a2f5f248856ce2768950aff4e" category="paragraph"><block ref="48dd929a2f5f248856ce2768950aff4e" category="inline-link-macro-rx"></block></block>
  <block id="2e52c56d063752bbfeda9c8f9d2fee41" category="summary">このページでは、 Kubernetes クラスタに NetApp Trident をインストールして設定するために必要な作業について説明します。</block>
  <block id="e539ec743b02403b5ba74b884d117a5a" category="paragraph">このセクションでは、 Kubernetes クラスタに NetApp Trident をインストールして設定するために必要な作業について説明します。</block>
  <block id="d6c3cdbd20fe8752d1f443bdb84038e3" category="list-text">Kubernetes クラスタはすでに稼働しており、 Trident でサポートされるバージョンの Kubernetes を実行している。サポートされているバージョンの一覧については、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="b8b9eab8c1ed7b79387652490f5724ec" category="section-title">Trident をインストール</block>
  <block id="984b69562391cb8032fd50ded03a29a6" category="paragraph">Kubernetes クラスタに NetApp Trident をインストールして設定するには、導入ジャンプホストから次のタスクを実行します。</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">導入手順</block>
  <block id="f12aad36b1ab9194dd8bc67542366bff" category="doc">NVIDIA DeepOps を使用して Kubeflow を導入します</block>
  <block id="3e1922d78dd7bdb1e8d7e7bd8f5aa92c" category="paragraph">NVIDIA DeepOps が提供する Kubeflow 導入ツールを使用することを推奨します。DeepOps 導入ツールを使用して Kubernetes クラスタに Kubeflow を導入するには、導入ジャンプホストから次のタスクを実行します。</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">インストール手順</block>
  <block id="3ede8bc1f55c95b9a16b2429e0b9bbcc" category="admonition">または、を使用して手動で Kubeflow を導入することもできます<block ref="c75d7e23bc80ca81cea11fe427173cb3" category="inline-link-rx"></block> Kubeflow の公式ドキュメントにあります</block>
  <block id="a73d6d865f72179145299c720c53d39c" category="inline-link">Kubeflow の導入手順</block>
  <block id="2efdbab31c5d41a149e5092f4b8d7e48" category="list-text">Kubeflow Dashboard URL をメモしてください。 DeepOps Kubeflow 導入ツールによって出力されます。</block>
  <block id="d6049afd6b1943d1e98ca6347dd907c5" category="list-text">Web ブラウザで、手順 2 でメモした URL に移動して Kubeflow 中央ダッシュボードにアクセスします。</block>
  <block id="2d84920115f9dc91fe2d35c4dc07eaf0" category="paragraph"><block ref="2d84920115f9dc91fe2d35c4dc07eaf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13e8f52d7e19f83d3e64003c58ea220b" category="doc">NDE を使用して NetApp HCI に VMware 仮想インフラストラクチャを導入する （導入の自動化）</block>
  <block id="2635318d9bf1ea76c73bfab7f3eeafb7" category="section-title">NDE 導入の前提条件</block>
  <block id="f6ec2c1aa5118cb19e89af5a10ecb65c" category="inline-link">NetApp HCI 前提条件チェックリスト</block>
  <block id="2187fc20798cda55150d8c067fac10be" category="paragraph">を参照してください<block ref="c760383d1767df51ab118e6ffc289894" category="inline-link-rx"></block> 導入を開始する前に、 NetApp HCI の要件と推奨事項を確認してください。</block>
  <block id="cd02d0868a7414dd1e76924b30b82b52" category="list-text">ネットワークおよびスイッチの要件と構成</block>
  <block id="1d8b6c167080876dff9ad2e74e70fecf" category="list-text">必要な VLAN ID を準備します</block>
  <block id="17cec09f14c225b5f27dc73542e9077a" category="list-text">スイッチの設定</block>
  <block id="4d40082ed807aa2fb7e1d2f03921e4d4" category="list-text">NetApp HCI および VMware の IP アドレス要件</block>
  <block id="2e8e4792043f43cb4b34a84b8dcd909b" category="list-text">DNS と時間管理の要件</block>
  <block id="829710d6ec2a8e59e7a69fb3537ec494" category="list-text">最終準備</block>
  <block id="fb720b4ad7c03710e0e5771c9fb58b44" category="section-title">NDE 実行</block>
  <block id="cf50c81e30d1d64fcb4992a9792abedb" category="paragraph">NDE を実行する前に、すべてのコンポーネントのラックとスタック、ネットワークスイッチの設定、およびすべての前提条件の確認を完了しておく必要があります。NDE ですべてのアドレスを自動的に設定できるようにする場合は、 1 つのストレージノードの管理アドレスに接続して NDE を実行できます。</block>
  <block id="130c61c344b6fbf262b6f63818eab7e4" category="paragraph">NDE は、 HCI システムをオンラインにするために次のタスクを実行します。</block>
  <block id="d89f68a2ec388fe5d72fb6fe024a0176" category="list-text">少なくとも 2 つのストレージノードにストレージノード（ NetApp Element ソフトウェア）をインストールします。</block>
  <block id="f6f86c1086573c7daeb1f48535041576" category="list-text">VMware ハイパーバイザーを少なくとも 2 つのコンピューティングノードにインストールします。</block>
  <block id="0718265bec3e2ee6fc9d5e0773b5ff60" category="list-text">NetApp HCI スタック全体を管理するために VMware vCenter をインストールします。</block>
  <block id="e09575b9713329ebe2480dbf404b2b1b" category="list-text">ネットアップストレージ管理ノード（ mNode ）と NetApp Monitoring Agent をインストールして設定します。</block>
  <block id="dddc28f734d0bcb367638f51ef8b4dfa" category="admonition">この検証では、 NDE を使用してすべてのアドレスが自動的に設定されます。環境で DHCP を設定したり、ストレージノードとコンピューティングノードごとに IP アドレスを手動で割り当てたりすることもできます。これらの手順については、このガイドでは説明していません。</block>
  <block id="dd9cd526f5753b79bda6de19f1a66fe9" category="paragraph">前述したように、この検証ではコンピューティングノードにケーブルを 2 本使用する構成を使用します。</block>
  <block id="32691d86c49e682187776e0262b732d7" category="paragraph">NDE の詳細な手順については、このドキュメントでは説明していません。</block>
  <block id="968a3687be335c74374e73712c63e2e4" category="inline-link">導入ガイド</block>
  <block id="8b6e1a3a9d21ff63520793416432cd56" category="paragraph">基本の NetApp HCI プラットフォームの導入を完了するための詳細な手順については、を参照してください<block ref="7742239770a3accee30f01673a1a43a5" category="inline-link-rx"></block>。</block>
  <block id="61ef02ded53524d506cd714c5821cd86" category="list-text">NDE が終了したら、 vCenter にログインし、 NetApp HCI およびアプリケーションで使用する NFS ネットワーク用の分散ポートグループ「 ONTAP Select VDS 01-NFS_Network 」を作成します。</block>
  <block id="9fb27fdce8d8c70b2c7b741958c8ac6e" category="inline-link-macro">次： NetApp H615c の設定（手動導入）</block>
  <block id="6623698128b1c14d8639f2404306f783" category="paragraph"><block ref="6623698128b1c14d8639f2404306f783" category="inline-link-macro-rx"></block></block>
  <block id="bd9091c7320e4b1069eed28f04839354" category="paragraph">独自の AI / ML パイプラインを構築する場合、アーキテクチャ内のコンポーネントの統合、管理、セキュリティ、およびアクセス性の設定は困難な作業です。開発者に環境へのアクセスと管理を許可することには、もう 1 つの課題があります。</block>
  <block id="820423ca1ad0e872ef04cbb366b6e3de" category="paragraph">ネットアップと Iguazio を組み合わせることで、これらのテクノロジをマネージドサービスとして統合し、テクノロジの採用を促進し、新しい AI / ML アプリケーションの市場投入期間を短縮できます。</block>
  <block id="b0a9c7dc36cb18f93679b833533b9936" category="paragraph"><block ref="b0a9c7dc36cb18f93679b833533b9936" category="inline-link-macro-rx"></block></block>
  <block id="2fb227f90ebf269423fe0cf1a15b8111" category="doc">永続的ボリューム要求を定義</block>
  <block id="8f5da11015f2baf835f0e8b421c1cfe9" category="list-text">次の YAML をファイルに保存して、 Basic タイプの PVC を作成します。</block>
  <block id="04c58cdb1d0c073dd558caf87f2b8ed1" category="list-text">Iguazio Kubernetes クラスタに YAML ファイルを適用します。</block>
  <block id="f685fdfcc5aedb3ccc237a4020b69cd8" category="section-title">NetApp ボリュームを Jupyter Notebook に接続します</block>
  <block id="dc4b8e255a77b2c73f89b702dbb7acc5" category="inline-link">Iguazio アプリケーションサービスおよびツールの概要</block>
  <block id="11eb1e24a14c1d15ee5e287b4338b764" category="paragraph">Iguazio は、データサイエンティストが AI / ML アプリケーションの開発と導入のための完全なエンドツーエンドスタックを提供するための、複数のマネージドサービスを提供します。これらのコンポーネントの詳細については、を参照してください<block ref="2cf4dcc22fda31f66959754df93d6196" category="inline-link-rx"></block>。</block>
  <block id="3591be3d07a4f8a37d218b9e92bea432" category="paragraph">マネージドサービスの 1 つに Jupyter Notebook があります。開発者はそれぞれ、開発に必要なリソースを備えたノートブックコンテナを独自に導入します。NetApp Cloud Volume へのアクセスを許可するには、コンテナにボリュームを割り当て、リソースの割り当て、ユーザの実行、および永続ボリュームに関する環境変数の設定を次の図に示します。</block>
  <block id="e0d870d503aeb797f7626b14c9acb4ae" category="paragraph">オンプレミス構成の場合は、を参照してください<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> Trident のセットアップでは、データの Snapshot コピーの作成やバージョン管理のためのモデルなど、 NetApp ONTAP のデータ管理機能を有効にできます。Trident バックエンド構成ファイルに次の行を追加すると、 Snapshot ディレクトリが表示されます。</block>
  <block id="12ce9751e0e6d2a7d593d46e19211984" category="inline-link">Trident コマンド</block>
  <block id="71f8fa2d01d0c5a2d9af72f90f65e379" category="paragraph">Trident バックエンド構成ファイルを JSON 形式で作成し、次のコマンドを実行する必要があります<block ref="1dce3ee9e9ff2b59caf27104be259d37" category="inline-link-rx"></block> 参照するには：</block>
  <block id="2842c07cfacaf614e63dc1f2afef93b2" category="paragraph"><block ref="2842c07cfacaf614e63dc1f2afef93b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d47cd04a0ddb5c3e6a2d9b9bc5c6a120" category="inline-link-macro">次の手順：アプリケーションの展開</block>
  <block id="fafac2eb9a7c4fcf46778865a22a00d2" category="paragraph"><block ref="fafac2eb9a7c4fcf46778865a22a00d2" category="inline-link-macro-rx"></block></block>
  <block id="34d54070f7d06f04159ffbc3d9a3e082" category="doc">作業環境を構成します</block>
  <block id="8302b607de31151e5500de556070d9b9" category="paragraph">「 Notebook `````````s_env-example.ipynb` を 'et_env.ipynb` としてコピーします。「 et_env.ipynb 」を開き、編集します。このノートブックでは、資格情報、ファイルの場所、および実行ドライバの変数を設定します。</block>
  <block id="3dc3cffc26096b89061a452cc7d16b6a" category="paragraph">上記の手順を実行すると、次の手順だけが変更されます。</block>
  <block id="26448fec50e405fb230427686eeb11f4" category="list-text">この値は、 Iguazio サービスダッシュボード「 dOcker_registry 」から取得します</block>
  <block id="837784ac15c5cac463a4d016bac63db1" category="paragraph">例：「 ocker-registry.default-tenant.app.clusterq.iguaziodev.com:80` 」</block>
  <block id="04dca9f72f7dfc6f87034c574f821a12" category="list-text">「 admin 」を Iguazio のユーザ名に変更します。</block>
  <block id="b2dea33f1195135f6905b7dd0ee58713" category="paragraph">'IGZ_container_path='/users/admin'</block>
  <block id="0ddaf8f981ee966dc3533de490c7ee4e" category="paragraph">ONTAP システムの接続の詳細を次に示します。Trident のインストール時に生成されたボリューム名も指定します。オンプレミスの ONTAP クラスタの場合、次の設定が適用されます。</block>
  <block id="dada97be0cb81e6518d92aa7112fa356" category="paragraph">Cloud Volumes ONTAP の設定は次のとおりです。</block>
  <block id="586d20125924bc57624aaacc07973d5a" category="section-title">ベースとなる Docker イメージを作成</block>
  <block id="0ab24923db4855b821917446711104c9" category="paragraph">ML パイプラインの構築に必要なものはすべて、 Iguazio プラットフォームに含まれています。開発者は、パイプラインの実行に必要な Docker イメージの仕様を定義し、 Jupyter Notebook からイメージの作成を実行できます。ノートブック 'create-images .ipynb' を開き、すべてのセルを実行します。</block>
  <block id="3dc4e8abb0e99c6cf29451a16a891524" category="paragraph">このノートブックでは、パイプラインで使用する 2 つのイメージが作成されます。</block>
  <block id="5446cc82e4c165e2700af830f8428d63" category="list-text">「 iguazio/NetApp. 」を参照してください ML タスクの処理に使用されます。</block>
  <block id="61145f9d17e187b69bc41525b10aafe6" category="paragraph"><block ref="61145f9d17e187b69bc41525b10aafe6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62e9956426227f62abc9692954a5ad39" category="list-text">「 NetApp/pipeline. 」。NetApp Snapshot コピーを処理するユーティリティが含まれています。</block>
  <block id="4050f795a12d7f83a545999c8a0d1905" category="paragraph"><block ref="4050f795a12d7f83a545999c8a0d1905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6677daf583d4c0cf5860927a024f278d" category="section-title">Jupyter ノートブックを個別に確認します</block>
  <block id="6414e1c23e017075a375d3a531eab90c" category="paragraph">次の表に、このタスクの構築に使用したライブラリとフレームワークを示します。これらのコンポーネントはすべて、 Iguazio のロールベースアクセスおよびセキュリティ制御と完全に統合されています。</block>
  <block id="da292beca00e0b352eade7a070855fd3" category="cell">ライブラリ / フレームワーク</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">説明</block>
  <block id="124d604ba0d3fd8e3d31c821b2a332f5" category="cell">MLRun （ MLRun ）</block>
  <block id="1c1491d01d96c08951ae2ac55fadf443" category="cell">Iguazio によって管理され、 ML / AI パイプラインのアセンブリ、実行、および監視を可能にします。</block>
  <block id="a2580bd6e044f86f4e39be2f59ee91da" category="cell">Nuclio</block>
  <block id="2d753cbb7762fe25d15a2cda2ff84790" category="cell">Iguazio と統合されたサーバーレス機能フレームワーク。Iguazio が管理するオープンソースプロジェクトとしても利用できます。</block>
  <block id="0bbee378f2697a1d0c184e76d2b206c6" category="cell">パイプラインを導入するための Kubernetes ベースのフレームワーク。これは、イグアスが寄与するオープンソースのプロジェクトでもあります。Iguazio と統合されているため、他のインフラストラクチャとのセキュリティおよび統合が強化されています。</block>
  <block id="849efb47ec760eb7c3c6b5848e740c3b" category="cell">Iguazio プラットフォームでは、 Docker レジストリがサービスとして実行されます。レジストリに接続するように変更することもできます。</block>
  <block id="a38f73277b7341a709cf0cb57ebc4434" category="cell">NetApp Cloud Volume の略</block>
  <block id="7279bb663993b77e219b4ca813326d77" category="cell">AWS で Cloud Volume を実行すると、大量のデータにアクセスでき、トレーニングに使用するデータセットのバージョンに Snapshot コピーを作成することもできます。</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="cell">Trident</block>
  <block id="9953e13b783f3ad45d99187c955cb9f9" category="cell">Trident は、ネットアップが管理するオープンソースプロジェクトです。Kubernetes でのストレージリソースやコンピューティングリソースとの統合を簡易化します。</block>
  <block id="5fa4506d691373039fd2834939e582b3" category="paragraph">複数のノートブックを使用して ML パイプラインを構築しました。各ノートブックを個別にテストしてから、パイプラインにまとめてテストすることができます。このデモアプリケーションの導入フローに従って、各ノートブックについて個別に説明します。</block>
  <block id="06a86c2506db8ef5fdac675c1352e3cf" category="paragraph">望ましい結果は、データの Snapshot コピーに基づいてモデルをトレーニングし、推論のためにモデルを導入するパイプラインです。完成した MLRun パイプラインのブロック図を次の図に示します。</block>
  <block id="1d79eb753e06f2122a118408a14d6c51" category="paragraph"><block ref="1d79eb753e06f2122a118408a14d6c51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51b666fe429f998144ea4f2ce818cd60" category="section-title">データ生成機能を導入します</block>
  <block id="034015442bf8bf34c0e7e8149d35dae6" category="paragraph">このセクションでは、ネットワークデバイスデータの生成に Nuclio サーバーレス関数を使用する方法について説明します。この使用例は、パイプラインを展開し、イグアスのサービスを使用してネットワークデバイスの障害を監視および予測する Iguazio クライアントに適しています。</block>
  <block id="2d024dd4dc0601ff2e4d0b81fcaec60a" category="inline-link">Nuclio の Web サイト</block>
  <block id="59009d367371847f2042c59338282f4b" category="paragraph">ネットワークデバイスからのデータをシミュレートしました。Jupyter ノートブック「 d ata-generator.ipynb 」を実行すると、 10 分ごとに実行されるサーバーレス関数が作成され、新しいデータが保存された寄木細工のファイルが生成されます。この機能を配備するには、このノートブックのすべてのセルを実行します。を参照してください<block ref="a9d48e85369982160b96d90770d878d1" category="inline-link-rx"></block> このノートブックの構成部品を確認します。</block>
  <block id="fa0c06ebcd647f13ce81472307615ee3" category="paragraph">関数の生成時に、次のコメントを持つセルは無視されます。ノートブック内のすべてのセルは、機能の一部であると見なされます。Nuclio モジュールをインポートして '%nuclio magic を有効にします</block>
  <block id="c2b253a6bc491b37027772dba5f0b4e7" category="paragraph">関数の仕様では、関数が実行される環境、関数がどのようにトリガされるか、および関数が消費するリソースを定義しました。</block>
  <block id="95b0eb5f892f7b0bcb3ec7dbb9058c02" category="paragraph">「 init_context 」関数は、関数の初期化時に Nuclio フレームワークによって呼び出されます。</block>
  <block id="1aab9637db54631d95ec5901bfda0947" category="paragraph">関数内にないコードは、関数が初期化されるときに呼び出されます。この関数を呼び出すと、ハンドラ関数が実行されます。ハンドラの名前を変更し、関数仕様で指定できます。</block>
  <block id="94be7a657ecb54ef7337030d9dd78b70" category="paragraph">この機能は、導入前にノートブックからテストできます。</block>
  <block id="01237c05459839293bfcd5a3beb1364f" category="paragraph">この機能は、ノートブックから導入することも、 CI / CD パイプラインから導入することもできます（このコードを使用）。</block>
  <block id="c697561ec27606d29683f7fc5fb3846d" category="section-title">ノートブックをパイプライン化します</block>
  <block id="83041c5547fb0ad965936febfc41508d" category="paragraph">これらのノートブックは、このセットアップで個別に実行することを意図したものではありません。これは、各ノートブックを確認するためのものです。ネットアップは、このような案件をパイプラインの一部として呼び出しました。個別に実行するには、 MLRun のドキュメントを参照して、これらを Kubernetes ジョブとして実行します。</block>
  <block id="c16b208e4ffb938f4008373dea5fb4ec" category="section-title">snap_CV.ipynb</block>
  <block id="eeb06194a969eee5616e56b449a99306" category="paragraph">このノートブックでは、パイプラインの最初にあるクラウドボリュームの Snapshot コピーを処理します。ボリュームの名前をパイプラインコンテキストに渡します。このノートブックは、スナップショットコピーを処理するシェルスクリプトを呼び出します。パイプラインでの実行中、実行コンテキストには、実行に必要なすべてのファイルを見つけるのに役立つ変数が含まれています。このコードを記述する際、開発者は、このコードを実行するコンテナ内のファイルの場所を気にする必要はありません。後で説明したように、このアプリケーションはすべての依存関係とともに配置され、実行コンテキストを提供するパイプラインパラメータの定義です。</block>
  <block id="dc82b570ec10aa261c20bf4828af24c1" category="paragraph">作成された Snapshot コピーの場所は、 MLRun コンテキストに配置され、パイプラインの各ステップで使用されます。</block>
  <block id="7f609b3599e86a8f1b83bde97709ba37" category="paragraph">次の 3 つのノートブックは並行して実行されます。</block>
  <block id="d1839287f93e09936af234173d03d6b7" category="section-title">データの前処理 ipynb</block>
  <block id="dbe6ca7c47e3dc8cbd3a4956e684b761" category="paragraph">モデルのトレーニングを有効にするには、生の指標を機能に変換する必要があります。このノートでは、 Snapshot ディレクトリから生の指標を読み取り、モデルトレーニングの機能をネットアップボリュームに書き込みます。</block>
  <block id="dab65fbdf0ed5ce626558d99e83c618f" category="paragraph">パイプラインのコンテキストで実行する場合、「 Data ATA_DIR 」という入力には Snapshot コピーの場所が含まれます。</block>
  <block id="4636df8c7ba383c5f135c7ae8f2ef772" category="section-title">.ipynb を説明する</block>
  <block id="43099d46867c7c0cc922fdd3e026d029" category="paragraph">受信メトリックを視覚化するために、 Kubeflow UI と MLRun UI で使用できるプロットとグラフを提供するパイプラインステップを導入します。各実行には、この表示ツールの独自のバージョンがあります。</block>
  <block id="7fd47125b80c0e6241052a47dcb41b98" category="section-title">deploy-feature-function.ipynb</block>
  <block id="684eb641c7a322c328f8ea91cd482b0d" category="paragraph">ネットアップでは、異常を検出している指標を継続的に監視してこのノートブックは、受信メトリックの予測を実行するために必要な機能を生成するサーバーレス機能を作成します。このノートブックは関数の作成を呼び出します。ファンクションコードはノートブック「 ata-prep . ipynb 」にあります。この目的のために、パイプラインのステップとして同じノートブックを使用していることに注意してください。</block>
  <block id="1c475141d16ada0e53ddb14047963024" category="section-title">train.ipynb</block>
  <block id="43b6984a9b2a7863061833c96be2b851" category="paragraph">フィーチャーを作成した後、モデルトレーニングを開始します。このステップの出力は、推論に使用するモデルです。また、統計を収集して各実行を追跡します（実験）。</block>
  <block id="a6858cae929a8eed6e9c9d6cfa9befac" category="paragraph">たとえば、次のコマンドは、その測定条件のコンテキストに精度スコアを入力します。この値は Kubeflow および MLRun で確認できます。</block>
  <block id="9d1126b5d7690c0eb46dd7713822680e" category="section-title">deploy-inion-function.ipynb を展開します</block>
  <block id="827ebf8bb3ee1798b5394ecd2a8bb3ae" category="paragraph">パイプラインの最後のステップは、継続的な推論のためのサーバーレス機能としてモデルを導入することです。このノートブックでは、「 nuclio-increation-function.ipynb 」で定義されたサーバーレス関数の作成を呼び出します。</block>
  <block id="4d2c908b5247626d682903dc9527bd05" category="section-title">パイプラインのレビューと構築</block>
  <block id="6c8673acfb6249793bed69954ca16a9b" category="paragraph">パイプラインですべてのノートブックを実行するという組み合わせにより ' テストを継続的に実行して ' モデルの精度を新しいメトリックと比較して再評価することができますまず 'pipeline.ipynb' ノートブックを開きますネットアップと Iguazio が ML パイプラインの導入をどのように簡易化しているかを詳しく説明します。</block>
  <block id="50d4decae4f0f08e83a1bd8342bd6ef1" category="paragraph">MLRun を使用して、パイプラインの各ステップにコンテキストを提供し、リソースの割り当てを処理します。MLRun API サービスは、 Iguazio プラットフォームで動作し、 Kubernetes リソースとのやり取りのポイントです。各開発者はリソースを直接要求できません。 API は要求を処理し、アクセス制御を有効にします。</block>
  <block id="c7c5ccf69a87e301b134dcfdf46ab307" category="paragraph">パイプラインは、 NetApp Cloud Volume やオンプレミスのボリュームと連携できます。このデモでは Cloud Volume を使用するように設計しましたが、オンプレミスで実行できるオプションをコードに示しています。</block>
  <block id="ce16d064e13fffda0ff2a07c50276f33" category="paragraph">Jupyter ノートブックを Kubeflow ステップにするために必要な最初のアクションは、コードを関数に変換することです。関数には、ノートブックを実行するために必要なすべての仕様が含まれています。ノートブックを下にスクロールすると、パイプラインのすべてのステップに対応する関数が定義されていることがわかります。</block>
  <block id="8bbbd384e919f705f071525a96cdfaec" category="cell">ノートブックの一部</block>
  <block id="5d75cd50687084d681964f5c6ee8a73a" category="cell">&lt;code_to _function&gt; （ MLRun モジュールの一部）</block>
  <block id="eef456f018469b2d403742d05e33a5dd" category="cell">関数の名前：プロジェクト名。すべてのプロジェクトアーティファクトの編成に使用されます。これは MLRun UI に表示されます。種類：この場合は Kubernetes ジョブ。これには、 Dask 、 MPI 、 spark8s などがあります。詳細については、 MLRun のマニュアルを参照してください。ファイル。ノートブックの名前。これは Git （ HTTP ）の場所にすることもできます。</block>
  <block id="78805a221a988e79ef3f42d7c5bfd418" category="cell">イメージ（ Image ）</block>
  <block id="d0161cbbc56081c803c919679b76b846" category="cell">この手順で使用する Docker イメージの名前。先ほど 'create-image.ipynb ノートブックを作成しました</block>
  <block id="28bb8862d962b462f621d9098de311cd" category="cell">volume_mounts と volumes</block>
  <block id="a6841da965bfb59838d367b9fdc30a8c" category="cell">実行時に NetApp Cloud Volume をマウントするための詳細情報。</block>
  <block id="5d9261bc63dfeef8d26c807e36a9daa4" category="paragraph">また、ステップのパラメーターも定義します。</block>
  <block id="fcd242cd0d87d4de3be34f843180bdb0" category="paragraph">すべてのステップの関数定義が完了したら、パイプラインを構築できます。この定義には 'kfp' モジュールを使用しますMLRun を使用することと、独自に構築することの違いは、コーディングの簡素化と短縮です。</block>
  <block id="f02b57d2fbd61d7629e76438ba68f7a1" category="paragraph">定義した関数は、 MLRun の「 As _ step 」関数を使用してステップコンポーネントになります。</block>
  <block id="8859e75c5bfd3a8ea5a783296d71b795" category="section-title">スナップショットステップの定義</block>
  <block id="dabb827ac33da3a8d8a2384874221aab" category="paragraph">Snapshot 機能を開始し、 v3io をソースとしてマウントします。</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">パラメータ</block>
  <block id="422ac26927e8ad3d6b30617226e26c2a" category="cell">新しいタスクです</block>
  <block id="b954691c9a06ef7281bf4c836e7684f1" category="cell">newtask は、実行される関数の定義です。</block>
  <block id="7871261404e7a8d93339696184b243b9" category="cell">（ MLRun モジュール）</block>
  <block id="4522319a8fbbe0a85c82e604047dfe6c" category="cell">ハンドラ。呼び出す Python 関数の名前。ノートブックでは name ハンドラーを使用しましたが、必須ではありません。パラメータ実行に渡されたパラメータ。このコードでは、 context.get_param （「パラメータ」）を使用して値を取得します。</block>
  <block id="6cebb60f71d9de65143ade7a8388e27a" category="cell">ステップとして（ _STEP. ）</block>
  <block id="070faabab806ce863279f5bd38452cc4" category="cell">名前Kubeflow パイプラインステップの名前。出力：これらは、完了時にステップが辞書に追加する値です。SNAP_CV.ipynb ノートブックを参照してください。mount_v3io()これにより、パイプラインを実行しているユーザーの /User をマウントするステップが構成されます。</block>
  <block id="a8aff967e1649a1c82ea607c881e8091" category="cell">入力</block>
  <block id="6f1ba99c8ee685047e0fa3c32349a01f" category="cell">前の手順の出力に渡すことができます。この場合、 snap.outputs['napVolumeDetails'] は、スナップステップで作成した Snapshot コピーの名前です。</block>
  <block id="a399d9e54dd5dc35c6b455d995702175" category="cell">out_path</block>
  <block id="026446ea82508e4c9f41609b3484b4cb" category="cell">MLRun モジュール LOG_Artifacts を使用して生成するアーティファクトを配置する場所。</block>
  <block id="2fe8889e7fb9545ea383ff3c0451cabf" category="paragraph">上から下に 'pipeline.ipynb' を実行できます次に、 Iguazio ダッシュボードの Pipelines タブに移動して、 Iguazio ダッシュボードの Pipelines タブに示すように、進捗状況を監視できます。</block>
  <block id="74dec5a93e3c1ccb06f26ebc6f9401fb" category="paragraph"><block ref="74dec5a93e3c1ccb06f26ebc6f9401fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f47db69a9e60b47a1c8f7800753f6b57" category="paragraph">トレーニングステップの精度はすべての実行で記録されているため、トレーニングの正確性の記録に示されているように、各テストの精度の記録があります。</block>
  <block id="5bb7a1a5b810ce843cd4d41a7137ce26" category="paragraph"><block ref="5bb7a1a5b810ce843cd4d41a7137ce26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9ebd260b4ed60a239b8228fe68b2dbc" category="paragraph">Snapshot ステップを選択すると、この実験を実行するために使用された Snapshot コピーの名前が表示されます。</block>
  <block id="1d231b2e1da6122607105ce52f87a763" category="paragraph"><block ref="1d231b2e1da6122607105ce52f87a763" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc578a2d3b019d646da18c9172282dc" category="paragraph">ここで説明する手順には、使用した指標を確認するための視覚的なアーティファクトがあります。を展開すると、次の図のように全プロットを表示できます。</block>
  <block id="ffb599ed438d33d337e7cca9a1fbaf07" category="paragraph"><block ref="ffb599ed438d33d337e7cca9a1fbaf07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89238f00748675db057567546f67c2c5" category="paragraph">MLRun API データベースは、プロジェクトごとに編成された各ランの入力、出力、およびアーティファクトも追跡します。各ランの入力、出力、およびアーティファクトの例を次の図に示します。</block>
  <block id="a8baa83f88edfb0fceafeda75819cb5f" category="paragraph"><block ref="a8baa83f88edfb0fceafeda75819cb5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c6050fe85d7b5528bc8356c88eab725" category="paragraph">各ジョブについて、追加の詳細情報が保存されます。</block>
  <block id="8683624a37c6626765321b5cc2f60954" category="paragraph"><block ref="8683624a37c6626765321b5cc2f60954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f02f72c9470e67a8b3c5f9054b0a32c" category="inline-link">MLRun GitHub サイト</block>
  <block id="01661b1e0825da7434573266df1672e0" category="paragraph">MLRun の詳細については、このドキュメントで説明している内容を参照してください。ステップと関数の定義を含むアルアーティファクトは、 API データベースに保存したり、バージョン管理したり、個別に呼び出すことも、完全なプロジェクトとして呼び出すこともできます。プロジェクトを保存して Git にプッシュし、後で使用することもできます。詳細については、を参照してください<block ref="92ae596fd8e402850e22f59a73ed3a44" category="inline-link-rx"></block>。</block>
  <block id="43486dfb907f148e40f3719f314caeb4" category="inline-link-macro">次： Grafana ダッシュボードを導入します</block>
  <block id="0670d6ac4e77f5862afcc2fde43bcc72" category="paragraph"><block ref="0670d6ac4e77f5862afcc2fde43bcc72" category="inline-link-macro-rx"></block></block>
  <block id="0b7e964d1176d21b9ba3eceec8ed95ac" category="doc">コンセプトとコンポーネント</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">人工知能</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">AI とは、人間の心の認識機能を模倣するためにコンピュータが訓練されているコンピュータ科学分野です。AI 開発者は、人間に似た方法、または人間に比べて優れた方法で、コンピュータをトレーニングして問題を解決します。ディープラーニングと機械学習は AI のサブフィールドです。組織は、重要なビジネスニーズに対応するために、 AI 、 ML 、 DL を導入する傾向に迫られています。次に例を示します。</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">未知のビジネスに大量のデータを分析しています 分析</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">自然言語処理を使用して顧客と直接やり取りする</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="section-title">コンテナ</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">コンテナは、共有ホストオペレーティングシステムカーネル上で実行される独立したユーザスペースインスタンスです。コンテナの採用が急速に増加しています。コンテナは、仮想マシン（ VM ）が提供するものと同じアプリケーションのサンドボックス化のメリットの多くを提供します。ただし、 VM が依存するハイパーバイザーレイヤとゲストオペレーティングシステムレイヤが排除されているため、コンテナの軽量化が大幅に向上しています。次の図に、仮想マシンとコンテナを視覚的に示します。</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Docker Web サイト</block>
  <block id="da28cd415837c7f3d1d6221ff490b84b" category="paragraph">コンテナを使用すると、アプリケーションの依存関係や実行時間などをアプリケーションで直接効率的にパッケージングできます。最も一般的に使用されるコンテナパッケージ形式は Docker コンテナです。Docker コンテナ形式でコンテナ化されたアプリケーションは、 Docker コンテナを実行できる任意のマシンで実行できます。これは、アプリケーションの依存関係がマシンに存在しない場合でも当てはまります。これは、すべての依存関係がコンテナ自体にパッケージ化されているためです。詳細については、を参照してください<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block>。</block>
  <block id="9c3d617029ed075512781527983e01e4" category="paragraph"><block ref="9c3d617029ed075512781527983e01e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Kubernetes Web サイト</block>
  <block id="7a1446916a360f9c8ae3b94a97ad8c86" category="paragraph">Kubernetes は、 Google が当初設計した、オープンソースの分散型コンテナオーケストレーションプラットフォームであり、 Cloud Native Computing Foundation （ CNCF ）によって管理されています。Kubernetes を使用すると、コンテナ化されたアプリケーションの導入、管理、拡張の機能を自動化できます。近年、 Kubernetes は主要なコンテナオーケストレーションプラットフォームとして登場しています。他のコンテナパッケージ化形式や実行時間もサポートされていますが、 Kubernetes は Docker コンテナ用のオーケストレーションシステムとして最もよく使用されます。詳細については、を参照してください<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block>。</block>
  <block id="6ea70a0ecace7daa9dfbbc8ff3282de1" category="inline-link">Trident の Web サイト</block>
  <block id="f9b736ec48694a34e744a1a0309602bd" category="paragraph">Trident は、ネットアップが開発および管理しているオープンソースのストレージオーケストレーションツールで、 Kubernetes ワークロード向けの永続的ストレージの作成、管理、使用を大幅に簡易化します。Trident は Kubernetes ネイティブのアプリケーションであり、 Kubernetes クラスタ内で直接実行されます。Trident を使用すると、 Kubernetes のユーザ（開発者、データサイエンティスト、 Kubernetes 管理者など）は、使い慣れた標準的な Kubernetes 形式で永続ストレージボリュームを作成、管理、操作できます。同時に、ネットアップの高度なデータ管理機能と、ネットアップテクノロジを基盤とするデータファブリックを活用できます。Trident は、複雑な永続的ストレージを抽象化して、消費を簡易化します。詳細については、を参照してください<block ref="ad5406ed69f3fe0de810f757310402c9" category="inline-link-rx"></block>。</block>
  <block id="47bbe104ad41e6af2ee0dba5dc76d74d" category="inline-link">DeepOps の Web サイト</block>
  <block id="b1c5aef0d1e7ec0339ca5caa48c1b3e3" category="paragraph">DeepOps は NVIDIA が開発したオープンソースプロジェクトです。 Ansible を使用することで、ベストプラクティスに従って GPU サーバクラスタの導入を自動化できます。DeepOps はモジュール方式であり、さまざまな導入タスクに使用できます。このドキュメントとこの検証の演習では、 DeepOps を使用して、 GPU サーバワーカーノードで構成される Kubernetes クラスタを導入します。詳細については、を参照してください<block ref="640792bfd91bad987ba8fd5d776a2824" category="inline-link-rx"></block>。</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Kubeflow の Web サイト</block>
  <block id="ea77b50ef31a778a66411b993d6cb7d1" category="paragraph">Kubeflow は Kubernetes 向けのオープンソースの AI / ML ツールキットで、 Google が開発したものです。Kubeflow プロジェクトでは、 Kubernetes での AI ワークフローと ML ワークフローの導入を、シンプル、ポータブル、拡張性に優れた方法で実施します。Kubeflow は Kubernetes の複雑さを抽象化し、データサイエンティストがデータサイエンスのベストプラクティスに集中できるようにします。表示については、次の図を参照してください。Kubernetes で企業の IT 部門の標準化が進むにつれて、 Kubeflow は大きな牽引力を発揮してきました。詳細については、を参照してください<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block>。</block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Kubeflow パイプライン</block>
  <block id="384873a621d99250018cd7ce1768f8af" category="paragraph">Kubeflow Pipelines は Kubeflow の主要コンポーネントです。Kubeflow Pipelines は、移植性と拡張性に優れた AI および ML ワークフローを定義、導入するためのプラットフォームと標準です。詳細については、を参照してください<block ref="6de5a235a0c43df48d05588e1b69b959" category="inline-link-rx"></block>。</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Jupyter のウェブサイト</block>
  <block id="3cecf3b7bbdb1a67a537c65bfd6fd529" category="paragraph">Jupyter Notebook Server はオープンソースの Web アプリケーションで、データサイエンティストは Jupyter Notebook と呼ばれる Wiki 形式のドキュメントを作成できます。このドキュメントには、ライブコードと説明的なテストが含まれています。Jupyter Notebook は、 AI プロジェクトと ML プロジェクトを文書化、保存、共有する手段として、 AI と ML のコミュニティで広く使用されています。Kubeflow を使用すると、 Kubernetes での Jupyter Notebook Server のプロビジョニングと導入が簡単になります。Jupyter Notebook の詳細については、を参照してください<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block>。Kubeflow のコンテキスト内の Jupyter Notebook の詳細については、を参照してください<block ref="c5d2218884acd101e6deb4d8c7d39370" category="inline-link-rx"></block>。</block>
  <block id="a2b0a43dcae6386929654b652393e691" category="paragraph"><block ref="a2b0a43dcae6386929654b652393e691" category="inline-image-macro-rx" type="image"></block></block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="section-title">Apache の通気</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9.</block>
  <block id="0b83cba78e13ee67f3ada794b1e8edb8" category="paragraph">NetApp ONTAP 9 はネットアップが提供する最新世代のストレージ管理ソフトウェアです。お客様のような企業がインフラを刷新し、クラウド対応のデータセンターに移行できるようにします。業界をリードするデータ管理機能を備えた ONTAP では、データの格納場所に関係なく、単一のツールセットでデータの管理と保護を行うことができます。エッジ、コア、クラウドなど、必要な場所に自由にデータを移動することもできます。ONTAP 9 には、データ管理を簡易化し、重要なデータを高速化、保護し、ハイブリッドクラウドアーキテクチャ全体で将来のニーズに対応できるインフラを実現する、多数の機能が搭載されています。</block>
  <block id="849f9e6e3176f7bb2abaf1dfdda6f4de" category="section-title">データ管理を簡易化</block>
  <block id="5d0a72b50313f5f3615263a7d19ee676" category="paragraph">データ管理は、アプリケーションやデータセットに適切なリソースを使用できるようにするために、企業の IT 運用にとって非常に重要です。ONTAP には、運用を合理化および簡易化し、総運用コストを削減するための次の機能が含まれています。</block>
  <block id="30490e1b1bd18c329c3b28df91914ffe" category="list-text">* インラインデータコンパクションと重複排除の強化。 * データコンパクションはストレージブロック内の無駄なスペースを削減し、重複排除は実効容量を大幅に増やします。</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">* 最小、最大、アダプティブの Quality of Service （ QoS ；サービス品質）。 * きめ細かい QoS 管理機能により、高度に共有された環境で重要なアプリケーションのパフォーマンスレベルを維持できます。</block>
  <block id="d9a5709ce7afa0856dd86539f75c8087" category="list-text">* StorageGRID 。 * この機能は、 Amazon Web Services （ AWS ）、 Azure 、 NetApp ONTAP FabricPool オブジェクトベースストレージなどのパブリックおよびプライベートクラウドストレージオプションへのコールドデータの自動階層化を提供します。</block>
  <block id="ddb2f8d78c57d5743fdee9e17ae053c9" category="section-title">データの高速化と保護</block>
  <block id="4994fe58be1734616de0863809040200" category="paragraph">ONTAP は、卓越したパフォーマンスとデータ保護を実現し、以下の機能を通じてこれらの機能を拡張します。</block>
  <block id="b109ecc7b4570bf3dbb9f8d082595075" category="list-text">* ハイパフォーマンスと低レイテンシ。 * ONTAP は、可能な限り低いレイテンシで最高のスループットを提供します。</block>
  <block id="9e184f7b8847a390232c0163d45ab461" category="list-text">* NetApp ONTAP FlexGroup テクノロジ。 * FlexGroup ボリュームは、最大 20PB と 4 、 000 億ファイルまでリニアに拡張可能な高性能データコンテナで、データ管理を簡易化する単一のネームスペースを提供します。</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">* データ保護。 * ONTAP は、組み込みのデータ保護機能を提供し、すべてのプラットフォームで共通の管理を実現します。</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* NetApp Volume Encryption* ONTAP は、オンボードと外部の両方のキー管理をサポートし、ボリュームレベルのネイティブ暗号化を実現します。</block>
  <block id="0950833529b7822458a242631cce3b3b" category="section-title">将来のニーズにも対応できるインフラ</block>
  <block id="ba5b61620e18b71a8644dbc382c0c4f1" category="paragraph">ONTAP 9 は、要件が厳しく、絶えず変化するビジネスニーズに対応します。</block>
  <block id="d9d73747d25ab5e9c5de8f1f61c9ec7c" category="list-text">* シームレスな拡張とノンストップオペレーション。 * ONTAP は、既存のコントローラとスケールアウトクラスタに無停止で容量を追加できます。NVMe や 32Gb FC などの最新テクノロジへのアップグレードも、コストのかかるデータ移行やシステム停止を行わずに実行できます。</block>
  <block id="512a65c054e8b5d06216e0eae55abedb" category="list-text">* クラウドへの接続。 * ONTAP は、すべてのパブリッククラウドで Software-Defined Storage （ ONTAP Select ）とクラウドネイティブインスタンス（ NetApp Cloud Volumes Service ）を選択できる、最もクラウドに接続されたストレージ管理ソフトウェアの 1 つです。</block>
  <block id="5ca60f373401802dfa44501cfa4f5cc7" category="list-text">* 新しいアプリケーションとの統合。 * 既存のエンタープライズアプリケーションをサポートする同じインフラを使用して、 ONTAP は、 OpenStack 、 Hadoop 、 MongoDB などの次世代プラットフォームやアプリケーションにエンタープライズクラスのデータサービスを提供します。</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">NetApp Snapshot コピー</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">NetApp Snapshot コピーは、ボリュームの読み取り専用のポイントインタイムイメージです。次の図に示すように、イメージには Snapshot コピーが最後に作成されたあとに作成されたファイルへの変更だけが記録されるため、ストレージスペースは最小限しか消費せず、パフォーマンスのオーバーヘッドもわずかです。</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Snapshot コピーの効率性は、 ONTAP の中核的なストレージ仮想化テクノロジである Write Anywhere File Layout （ WAFL ）によって実現します。WAFL は、データベースと同様に、メタデータを使用してディスク上の実際のデータブロックを参照します。ただし、データベースとは異なり、 WAFL は既存のブロックを上書きしません。更新されたデータは新しいブロックに書き込まれ、メタデータが変更されます。ONTAP では、 Snapshot コピーの作成時にデータブロックをコピーするのではなくメタデータを参照するため、非常に効率的です。他のシステムと違ってコピーするブロックを探すシーク時間もなければ、コピー自体を作成するコストもかかりません。</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">Snapshot コピーを使用して、個々のファイルまたは LUN をリカバリしたり、ボリュームの内容全体をリストアしたりできます。ONTAP は、 Snapshot コピーのポインタ情報をディスク上のデータと比較することで、ダウンタイムや多大なパフォーマンスコストなしで損失オブジェクトや破損オブジェクトを再構築します。</block>
  <block id="9787a3a5983c64cfaf3029a721aab4f0" category="paragraph"><block ref="9787a3a5983c64cfaf3029a721aab4f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">NetApp FlexClone テクノロジ</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">NetApp FlexClone テクノロジは、 Snapshot メタデータを参照してボリュームの書き込み可能なポイントインタイムコピーを作成します。コピーと親でデータブロックが共有されるため、次の図に示すように、コピーに変更が書き込まれるまではメタデータに必要な分しかストレージは消費されません。従来の手法でコピーを作成すると数分から数時間かかりますが、 FlexClone ソフトウェアを使用すれば大規模なデータセットのコピーもほぼ瞬時に作成できます。そのため、同じデータセットのコピーが複数必要な状況（開発用ワークスペースなど）や一時的にデータセットのコピーが必要な状況（本番環境のデータセットでアプリケーションをテストする場合など）に適しています。</block>
  <block id="423c2edb645c178257ba9d79bd9ac684" category="paragraph"><block ref="423c2edb645c178257ba9d79bd9ac684" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">NetApp SnapMirror データレプリケーションテクノロジ</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">NetApp SnapMirror ソフトウェアは、データファブリック全体にわたる、コスト効率に優れた使いやすいユニファイドレプリケーション解決策です。LAN または WAN 経由でデータを高速で複製します。仮想環境と従来の環境の両方でビジネスクリティカルなアプリケーションを含む、あらゆるタイプのアプリケーションに対し、高いデータ可用性と高速なデータレプリケーションを提供します。1 つ以上のネットアップストレージシステムにデータをレプリケートし、セカンダリデータを継続的に更新すると、データが最新の状態に保たれ、必要なときにいつでも使用できます。外部レプリケーションサーバは必要ありません。SnapMirror テクノロジを利用したアーキテクチャの例については、次の図を参照してください。</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">SnapMirror ソフトウェアは、変更されたブロックのみをネットワーク経由で送信することで、 NetApp ONTAP の Storage Efficiency 機能を活用します。SnapMirror ソフトウェアには、組み込みのネットワーク圧縮機能も使用して、データ転送を高速化し、ネットワーク帯域幅の使用量を最大 70% 削減します。SnapMirror テクノロジを使用すると、 1 つのシンレプリケーションデータストリームを利用して単一のリポジトリを作成し、アクティブなミラーと以前のポイントインタイムコピーの両方を保持できるため、ネットワークトラフィックを最大 50% 削減できます。</block>
  <block id="423eee692f81241addaf586841d0c66a" category="paragraph"><block ref="423eee692f81241addaf586841d0c66a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroup Volume の略</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">トレーニングデータセットは、数十億に及ぶ可能性のあるファイルの集まりです。ファイルには、テキスト、オーディオ、ビデオなどの形式の非構造化データを含めることができます。これらのデータは、並行して読み込まれるように保存して処理する必要があります。ストレージシステムは、多数の小さなファイルを格納し、シーケンシャル I/O とランダム I/O でそれらのファイルを並行して読み取る必要があります</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">FlexGroup ボリュームは、次の図に示すように、複数のコンスティチュエントメンバーボリュームで構成される単一のネームスペースです。ストレージ管理者の視点で見ると、 FlexGroup ボリュームは管理され、 NetApp FlexVol ボリュームのように機能します。FlexGroup ボリューム内のファイルは、個々のメンバーボリュームに割り当てられ、複数のボリュームやノードにまたがってストライプされることはありません。次の機能が有効になります。</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">FlexGroup ボリュームは、数ペタバイトの容量と、メタデータ比率の高いワークロード向けの予測可能な低レイテンシを提供します。</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">同じネームスペースで最大 4 、 000 億個のファイルをサポートします。</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">CPU 、ノード、アグリゲート、コンスティチュエント FlexVol ボリューム全体で NAS ワークロードの並列処理をサポートします。</block>
  <block id="07e40bce6e02494c0af7b6a5f2aeaad8" category="paragraph"><block ref="07e40bce6e02494c0af7b6a5f2aeaad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="doc">Kubeflow の導入</block>
  <block id="28b9eb1a9ba550cf23239eb33610203e" category="doc">ソフトウェアとハードウェアの要件</block>
  <block id="dce011ea921230b4e3061bb70569c598" category="section-title">ネットワーク構成：</block>
  <block id="5c56d5a342310a4d1ead67adc85adcab" category="paragraph">クラウドにセットアップするためのネットワーク構成の要件は次のとおりです。</block>
  <block id="df97d4ea35e2febbb06b9bd1ba29b50e" category="list-text">Iguazio クラスタと NetApp Cloud Volume は、同じ仮想プライベートクラウドに存在する必要があります。</block>
  <block id="a8f3c1a7fc956bcddef483bc8797e742" category="list-text">クラウドマネージャは、 Iguazio アプリノードのポート 443 にアクセスできる必要があります。</block>
  <block id="0d1562d43d3c0d4c52eef4a841896eba" category="list-text">本テクニカルレポートでは Amazon Web Services を使用しました。ただし、任意のクラウドプロバイダに解決策を導入することもできます。 ONTAP AI で NVIDIA DGX-1 を使用したオンプレミステストの場合は、便宜のために Iguazio ホスト DNS サービスを使用しました。</block>
  <block id="820de5e74a90f4dbc17e37b78258c35b" category="paragraph">クライアントは、動的に作成される DNS ドメインにアクセスできる必要があります。お客様は必要に応じて独自の DNS を使用できます。</block>
  <block id="43ad77bf4f253415b4e90ea4aa41a2d7" category="paragraph">イグアスは、ご使用のクラスタにオンプレミスでインストールできます。ネットアップでは、 NVIDIA DGX-1 システムで NetApp ONTAP AI の解決策を検証しました。次の表に、この解決策のテストに使用したハードウェアを示します。</block>
  <block id="7b6f2acc1b4489fd971965be635ea987" category="cell">NetApp AFF A800 システム</block>
  <block id="55552614d2dd18f2d6c40759f2de9e22" category="cell">ハイアベイラビリティ（ HA ）ペア × 1 、コントローラ × 2 、 NVMe SSD × 48 （ 3.8TB 以上）</block>
  <block id="413400218c4c262991ad8483b3be0a04" category="cell">Cisco Nexus 3232C ネットワークスイッチ</block>
  <block id="72f23e74ab545a9064f74aca4d904bf4" category="paragraph">次の表に、オンプレミステストに必要なソフトウェアコンポーネントを示します。</block>
  <block id="751601035b4077a9c6f7280ab1d3369c" category="cell">4.4 - Ubuntu 18.04 LTS</block>
  <block id="bb3121464976ef0c6b6b2b81fc75f3c5" category="cell">19.03.5</block>
  <block id="2a820a07d05055e147221622557f34b9" category="cell">コンテナバージョン</block>
  <block id="6f3d0f773f6be20d70e6bbbafca93de9" category="cell">20.01-tF1 - py2</block>
  <block id="46b6cc5d90605df4689002387db99128" category="cell">機械学習フレームワーク</block>
  <block id="f060e908e90b13cff9447e18fbb6bb20" category="cell">TensorFlow 1.15.0</block>
  <block id="4ec1f03a0b910370451392d8af8cd05a" category="cell">イグアテオ</block>
  <block id="80b1aaf85493db4117fca57135bec077" category="cell">バージョン 2.8 以降</block>
  <block id="20de768bd6142b858c4e99c64e19f37b" category="cell">ESX サーバ</block>
  <block id="f884cc5c56f9c9a8d4d61568ff64db9c" category="cell">6.5</block>
  <block id="95b4a53c1023a65c982b077b13be4b96" category="paragraph">この解決策は、 Iguazio バージョン 2.5 および NetApp Cloud Volumes ONTAP for AWS で完全にテストされています。Iguazio クラスタとネットアップのソフトウェアは、どちらも AWS で実行されています。</block>
  <block id="efbef76fea5d52b17e66f66b7fbdb1be" category="cell">[ バージョン ] または [ タイプ ]</block>
  <block id="1f2c90c0f9931b94eab6d9d2d3a640c9" category="cell">アプリケーションノード</block>
  <block id="8f33b30dd333b320c87f038f61e17523" category="cell">m5.mc</block>
  <block id="b8f3b98512c841c7f30ce704570ac0b6" category="cell">データノード</block>
  <block id="ea93f0324aaeaa177497ea41b52cb9ff" category="cell">I3.と は、および</block>
  <block id="870032d2d605939c0c8a813ac8534e80" category="inline-link-macro">次の例：ネットワークデバイスの障害予測ユースケースの概要</block>
  <block id="6b90a2e4861b0a6faf4f640ece131282" category="paragraph"><block ref="6b90a2e4861b0a6faf4f640ece131282" category="inline-link-macro-rx"></block></block>
  <block id="232abf87aa3028a990e94f6bb51fe8bd" category="summary">Kubernetes クラスタでシングルノードの AI ジョブと ML ジョブを実行するには、導入ジャンプホストからこのページのタスクを実行します。</block>
  <block id="46300fa439cc237919f854816fc89fc2" category="doc">シングルノードの AI ワークロードを実行</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">このセクションでは、 Kubernetes クラスタで実行しようとしている特定の AI および ML ワークロードを（ Docker コンテナ形式で）コンテナ化済みであることを前提としています。</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">ImageNet の Web サイト</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">次のコマンド例は、 ImageNet データセットを使用する TensorFlow ベンチマークワークロード用の Kubernetes ジョブを作成する方法を示しています。ImageNet データセットの詳細については、を参照してください<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block>。</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">このジョブ例では、 8 個の GPU を要求するため、 8 個以上の GPU を搭載した 1 つの GPU ワーカーノードで実行することができます。このジョブ例は、 8 個以上の GPU を搭載したワーカーノードが存在しない、または現在別のワークロードを使用しているクラスタで送信できます。その場合、そのようなワーカーノードが使用可能になるまで、ジョブは保留状態のままになります。</block>
  <block id="225e66547943a27f429558dce4e639e2" category="paragraph">「 M emory 」の値が「 emory 」である「 emptyDir 」ボリュームは、この例のジョブで作成されるポッド内の「 /dev/shm 」にマウントされます。Docker コンテナランタイムによって自動的に作成される「 /dev/shm 」仮想ボリュームのデフォルトサイズが、 TensorFlow のニーズに十分でない場合があります。次の例のように 'emptyDir' ボリュームをマウントすると '/dev/shm' 仮想ボリュームが十分に大きくなります「 emptyDir 」ボリュームの詳細については、を参照してください<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block>。</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">この例のジョブ定義で指定されている単一のコンテナには 'ecurityContext&gt; 特権値 'true' が与えられますこの値は、コンテナにホスト上のルートアクセス権があることを意味します。このアノテーションは、実行中の特定のワークロードにルートアクセスが必要なために使用されます。具体的には、ワークロードで実行されるクリアキャッシュ処理にはルートアクセスが必要です。これが特権 : true の注釈であるかどうかは ' 実行している特定のワークロードの要件によって異なります</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">手順 1 で作成したジョブが正しく実行されていることを確認します。次のコマンド例では、ジョブ定義で指定したとおりにジョブ用にポッドが 1 つ作成され、このポッドが GPU ワーカーノードの 1 つで現在実行されていることを確認します。</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">手順 1 で作成したジョブが正常に完了したことを確認します。次のコマンド例は、ジョブが正常に完了したことを確認します。</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">* オプション： * ジョブアーティファクトをクリーンアップします。次のコマンド例は、手順 1 で作成したジョブオブジェクトの削除を示しています。</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">ジョブオブジェクトを削除すると、関連付けられているポッドは Kubernetes によって自動的に削除されます。</block>
  <block id="65f63f96295566cd4278775eef1b4c8c" category="doc">パフォーマンスの低いワークロードやインタラクティブなワークロードに適した、フラクショナルな GPU 割り当て</block>
  <block id="1b3d285072ee60a98cde2f66b6e47fde" category="paragraph">開発、ハイパーパラメータチューニング、デバッグのどの段階であっても、研究者や開発者が自分のモデルに取り組んでいる場合、このようなワークロードに必要なコンピューティングリソースは通常少なくなります。したがって、フラクショナル GPU とメモリをプロビジョニングして、同じ GPU を他のワークロードに同時に割り当てることがより効率的です。実行： AI のオーケストレーション解決策は、 Kubernetes 上のコンテナ化されたワークロード向けのフラクショナル GPU 共有システムを提供します。CUDA プログラムを実行するワークロードをサポートするシステムで、推論やモデル構築などの軽量な AI タスクに特に適しています。フラクショナル GPU システムを使用すると、データサイエンスチームや AI エンジニアリングチームは、 1 つの GPU で複数のワークロードを同時に実行できます。これにより、コンピュータビジョン、音声認識、自然言語処理など、より多くのワークロードを同じハードウェア上で実行できるようになり、コストが削減されます。</block>
  <block id="5db1fcd5bb529fa2475aaf893414d2e4" category="paragraph">実行： AI のフラクショナル GPU システムは、仮想化された論理 GPU を独自のメモリとコンピューティングスペースで効率的に作成します。このスペースは、コンテナが自己完結型のプロセッサであるかのように使用およびアクセスできます。これにより、複数のワークロードを同じ GPU 上で並行して実行でき、互いに影響することはありません。解決策は透過的でシンプル、かつ移植可能であり、コンテナ自体に変更を加える必要はありません。</block>
  <block id="71cdf780e37cc9571b5fcd0bf89958b1" category="paragraph">一般的な usecase では、同じ GPU 上で 2 ～ 8 個のジョブが実行されていることがわかります。つまり、同じハードウェアで作業を 8 倍行うことができます。</block>
  <block id="0a1f69603a47f75f701f92ad7d94e3c5" category="paragraph">次の図のプロジェクト「 team -d 」に属するジョブ「分割 05 」については、割り当てられた GPU の数が 0.50 であることがわかります。さらに 'nvidia-smi コマンドによって確認されますこのコマンドは ' コンテナに使用できる GPU メモリが 'DGX-1 ノードの V100 GPU あたりの 32GB の半分である 16,255MB であることを示します</block>
  <block id="e6d9743072cdc6867ea2980c7db7e7fd" category="paragraph"><block ref="e6d9743072cdc6867ea2980c7db7e7fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9afb11deef37d75cf56adc6e1a2f4020" category="inline-link-macro">次の例：クォータ超過の GPU 割り当てによる高いクラスタ利用率の実現</block>
  <block id="15968f671ef08561726e3064358c707b" category="paragraph"><block ref="15968f671ef08561726e3064358c707b" category="inline-link-macro-rx"></block></block>
  <block id="3642f282b12269091ab196a3aabf0858" category="doc">Trident の運用例</block>
  <block id="ff9caff469d56a572a569942ca24c8b4" category="list-text">NVIDIA DGX システム</block>
  <block id="b69073c22b4269568fd577ea090ce638" category="list-text">NVIDIA DGX-1 システム<block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="fe287c518b9b1345defadacdc6a9ecbf" category="list-text">NVIDIA V100 Tensor コア GPU<block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="d6a8716635a5681cde357a465953bc72" category="list-text">NVIDIA NGC<block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="11bdb18e1c5e7d1e4362c9d2f6956fc8" category="list-text">実行： AI コンテナオーケストレーション解決策</block>
  <block id="5afc85c81e76f427a293dd861e0109a3" category="list-text">実行： AI 製品の概要<block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="9acfbb098f0d9b45b5897b44ae347ee9" category="list-text">実行： AI インストールドキュメント<block ref="cb05a776556ca5a25aec417185ef6863" category="inline-link-rx"></block>
<block ref="b2e8533fae57aa9047d7731db51b6dfe" category="inline-link-rx"></block></block>
  <block id="b0d8a6d0eebdc42ac243c16f9137118d" category="list-text">実行時のジョブの送信： AI CLI<block ref="97ec6c214f99d7e6a39194a167aeecc8" category="inline-link-rx"></block>
<block ref="d75350381b5fda5cc9c9a1ce34c24299" category="inline-link-rx"></block></block>
  <block id="9bd35f4f3f6faa9e9330c54fd2086967" category="list-text">実行時の GPU フラクションの割り当て： AI CLI<block ref="e343516de5fb56c6a0d652bcdfceaab7" category="inline-link-rx"></block></block>
  <block id="ddb27cb97146c8f5964eaf368feb4ce0" category="list-text">テクニカルレポートをご参照ください<block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="2273cd603e277bb35f96881a557b0608" category="list-text">簡単なデモ<block ref="61e3673018126d9a106032d9ff691322" category="inline-link-rx"></block></block>
  <block id="45f26b752dfae88ec8c7def446162521" category="list-text">GitHub リポジトリ<block ref="f9a4909739179bedfa8ba1d225598979" category="inline-link-rx"></block></block>
  <block id="c36e36ff8b7edf8dd17781148ed57337" category="list-text">NetApp AFF A シリーズのデータシート<block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="ffc4c8e8bc10afc438d9c590f44e3b51" category="list-text">ネットアップの All Flash FAS 向けフラッシュソリューションの利点<block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="7843ce52c43038d88c2f54d85f3f764d" category="list-text">ONTAP 9 情報ライブラリ<block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="5f1b8a708e16776ca4372c71dc377653" category="list-text">NetApp ONTAP FlexGroup Volume テクニカルレポート<block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="062d7e5979c653f33e03cb0aaeaec6e9" category="list-text">DGX-1 と Cisco Networking Design Guide による ONTAP AI<block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="59086e50189644b7c19947dfa68f8395" category="list-text">DGX-1 と Cisco Networking Deployment Guide を使用した ONTAP AI<block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="062afad089226e62b53e77ba2af24574" category="list-text">DGX-1 と Mellanox のネットワーキング設計ガイドで構成される ONTAP AI<block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="e6b737f0513721f0a8024f538058333e" category="list-text">DGX-2 を使用した ONTAP AI 設計ガイド<block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="1f9a7430deed674d394796eaea14138f" category="paragraph">本テクニカルレポートでは、小規模から大規模のデータサイエンス / エンジニアリングチームのお客様向けに、 Run ： AI CLI と NetApp ONTAP AI のシステムダッシュボードを使用して Kubernetes クラスタと GPU の使用を最適化するためのガイドラインを紹介します。また、実行： AI プラットフォームのインストール情報、テストシナリオ、検証済みのテストケース用の詳細なコマンドも記載されています。Run ： AI オーケストレーション解決策とネットアップの AI コントロールプレーンを組み合わせることで、最適なリソース利用率で開発者の生産性を向上させ、イノベーションを加速できます。</block>
  <block id="892726726d592ee18c9ee8ad25a088ae" category="inline-link-macro">次はエグゼクティブサマリーです</block>
  <block id="e6c479abab08e982bd2f0efd6e3e405a" category="paragraph"><block ref="e6c479abab08e982bd2f0efd6e3e405a" category="inline-link-macro-rx"></block></block>
  <block id="f23c532f744716d23270b963c3eca570" category="summary">Kubernetes の上で Apache の通気を確保することを推奨します。このセクションでは、 Kubernetes クラスタ内に通気を導入するために完了しておく必要のあるタスクについて説明します。</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Apache Airflow の導入</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Kubernetes クラスタをすでに使用している。</block>
  <block id="e59b39fd5c122dde3747561247eb2888" category="list-text">「 NetApp Trident の導入と構成」のセクションに記載されているように、 Kubernetes クラスタに NetApp Trident をインストールし、設定しておきます。</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Helm をインストールします</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">エアフローは、 Kubernetes の一般的なパッケージマネージャである Helm を使用して導入されます。エアーフローを導入する前に、導入ジャンプホストに Helm をインストールする必要があります。Helm を配置ジャンプホストにインストールするには、に従ってください<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> Helm の公式ドキュメントを参照してください。</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Helm を使用してエアフローを展開します</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Helm を使用して Kubernetes クラスタに通気を導入するには、導入ジャンプホストから次のタスクを実行します。</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">手順 1 の Helm を使用してエアーフローを導入したときにコンソールに出力された指示に従って、エアーフロー Web サービスの URL を取得します。</block>
  <block id="1e48409a293254dced52407be3dbb722" category="doc">Jarvis 、 Cloud Sync 、 Nemo を使用して仮想アシスタントを構築します</block>
  <block id="68dc442228015e015ca6272edb5994e4" category="inline-link-macro">次の例： Jarvis 、 Cloud Sync 、 Nemo の概要を使用して仮想アシスタントを構築します</block>
  <block id="f308b9afc8e29196ebb4fe535e29fc51" category="paragraph"><block ref="f308b9afc8e29196ebb4fe535e29fc51" category="inline-link-macro-rx"></block></block>
  <block id="3ad0505876550699ce505845f96683a7" category="doc">会話履歴をアーカイブするには、 NetApp Cloud Sync を使用します</block>
  <block id="a7e4c14a726c28e6cb4b935701ac2899" category="paragraph">会話履歴を 1 日に 1 回 CSV ファイルにダンプすることで、 Cloud Sync を利用してログファイルをローカルストレージにダウンロードできます。次の図は、オンプレミスとパブリッククラウドにジャービスを導入し、 Cloud Sync を使用して Nemo トレーニングの会話履歴を送信するアーキテクチャを示しています。Nemo の訓練の詳細はセクションで見つけることができる <block ref="14a0a4dd1a1c18cba42b2036fe4dfc33" category="inline-link-macro-rx"></block>。</block>
  <block id="e60c4461b2b4dcf3aa8535e3aab780b3" category="paragraph"><block ref="e60c4461b2b4dcf3aa8535e3aab780b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00717575e300ae9f18fa0a24d97bcca5" category="inline-link-macro">次 : Nemo の訓練を使用して設計モデルを展開しなさい</block>
  <block id="7ee8a10f8da0d566f0c5cccb9528b186" category="paragraph"><block ref="7ee8a10f8da0d566f0c5cccb9528b186" category="inline-link-macro-rx"></block></block>
  <block id="c4e7b8572218b2c9421122c7ab76be25" category="paragraph">NetApp と cnvrg.io はパートナーとして提携し、 ML および DL ソフトウェア開発向けの包括的なデータ管理解決策をお客様に提供しています。ONTAP AI は、あらゆる規模の運用に対応できる高性能なコンピューティングとストレージを提供します。 cnvrg.io ソフトウェアは、データサイエンスのワークフローを合理化し、リソース利用率を向上させます。</block>
  <block id="8537de5688b6b855ec8b5465eca4e8f6" category="list-text">NVIDIA DGX Station 、 V100 GPU 、 GPU Cloud</block>
  <block id="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link"><block ref="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link-rx"></block></block>
  <block id="432a0462f3a215c89d6067d01ac9fee8" category="list-text">NVIDIA DGX ステーション<block ref="00e84bc2760804fd15a292583676639b" category="inline-link-rx"></block></block>
  <block id="a8135dcfdfd9c1074b55895b8d51f9be" category="list-text">NVIDIA V100 Tensor コア GPU<block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="f3e44b157fa7ead37042e8a6f3b14071" category="list-text">NVIDIA NGC<block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="944c1fe2317541350506cecb6131b857" category="inline-link"><block ref="944c1fe2317541350506cecb6131b857" category="inline-link-rx"></block></block>
  <block id="d3ceb6166da1ada512f22bc7832ec047" category="list-text">NVIDIA Jarvis<block ref="34ae4389dc7afcada801d63c08e322b9" category="inline-link-rx"></block></block>
  <block id="21ce987b6ba4d344f1427dc72d497669" category="inline-link"><block ref="21ce987b6ba4d344f1427dc72d497669" category="inline-link-rx"></block></block>
  <block id="7bf7a8db8c3809766aa2579c2eadf37d" category="list-text">NVIDIA Jarvis Early Access<block ref="2daee9604c6a07f74e6776847d2ee61e" category="inline-link-rx"></block></block>
  <block id="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link"><block ref="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link-rx"></block></block>
  <block id="852c7bf0a8f3b30a5a001dbf642dbebe" category="list-text">NVIDIA Nemo<block ref="fa9e246f0ef36a285adacc70507ae974" category="inline-link-rx"></block></block>
  <block id="299a4717590cda2cfe1db321802b4995" category="inline-link"><block ref="299a4717590cda2cfe1db321802b4995" category="inline-link-rx"></block></block>
  <block id="dfc2ce4fd02d20052bebaa2e6b8cd029" category="list-text">開発者ガイド<block ref="9940ba67713949ce4f2fc05d3a37bd8c" category="inline-link-rx"></block></block>
  <block id="5467c9d1c07a7d1786936650b3c2d52a" category="list-text">NetApp AFF A シリーズのデータシート<block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="6bb399f406fc5ac4150ad21c6aa05ab2" category="list-text">ネットアップの All Flash FAS 向けフラッシュソリューションの利点<block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="9415aef2732728cc097fbbc9ab96b2fe" category="list-text">ONTAP 9 情報ライブラリ<block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="d106dc348953acc0500f03a25379282e" category="list-text">NetApp ONTAP FlexGroup Volume テクニカルレポート<block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="05dbc5885d3bec70d2317a4b51526d96" category="list-text">DGX-1 と Cisco Networking Design Guide による ONTAP AI<block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="af5797305db370f4f59d77bf7c73160b" category="list-text">DGX-1 と Cisco Networking Deployment Guide を使用した ONTAP AI<block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="f2345b2674d3976c091d4af042c36a8f" category="inline-link"><block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="f63c45f352478237d0d0fe7c5a26d6bf" category="list-text">DGX-1 と Mellanox のネットワーキング設計ガイドで構成される ONTAP AI<block ref="459df3a4bfb1f89f6920196001257745" category="inline-link-rx"></block></block>
  <block id="b38db7c217c396412f601b87dfc58a8c" category="inline-link"><block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="da8009e462fd2ec5eeb41b4cf3721f7a" category="list-text">DGX-2 を使用した ONTAP AI 設計ガイド<block ref="86d70269673ee41c37a2673f7d3655ce" category="inline-link-rx"></block></block>
  <block id="3ff1a758f526c5ceb434059efe27020a" category="doc">Apache の通気ワークフローの例</block>
  <block id="1a7fa7cc4c79d5163f691ff60e6fc34d" category="doc">「 AI Dashboards and Views 」を実行します</block>
  <block id="3473dab452c5446b1a01a923e9879461" category="paragraph">Run ： AI を Kubernetes クラスタにインストールし、コンテナを正しく設定したら、次のダッシュボードとビューが表示されます<block ref="2af90fde6f4d8ae5947b005d1208e742" category="inline-link-rx"></block> 次の図に示すように、ブラウザで設定します。</block>
  <block id="f977554b7762214959db36c20484c697" category="paragraph"><block ref="f977554b7762214959db36c20484c697" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dfd99441ce89d4be896e4fc9757f7d2" category="paragraph">2 つの DGX-1 ノードによってクラスタ内に提供される GPU は合計 16 個です。ノード数、使用可能な GPU の総数、ワークロードに割り当てられている GPU の数、実行中のジョブの総数、保留中のジョブ、およびアイドル状態に割り当てられている GPU の数を確認できます。右側のバー図は、プロジェクトごとの GPU を示しています。これは、各チームがどのようにクラスタリソースを使用しているかをまとめたものです。中央には、ジョブ名、プロジェクト、ユーザー、ジョブタイプなど、現在実行中のジョブとジョブの詳細のリストが表示されます。 各ジョブが実行されているノード、そのジョブに割り当てられている GPU の数、ジョブの現在の実行時間、ジョブの進捗状況、およびそのジョブの GPU 利用率。1 つのチーム（「 TEAM 」）から送信された実行中のジョブは 3 つしかないため、クラスタの使用率が低いことに注意してください（ GPU 使用率は 23% ）。</block>
  <block id="67545e2efac33412706ff883eff2e1c4" category="paragraph">次のセクションでは、「プロジェクト」タブで複数のチームを作成し、各チームに GPU を割り当てることで、クラスタあたりのユーザ数が多いときにクラスタの使用率を最大限に高め、リソースを管理する方法を説明します。テストシナリオは、トレーニング、推論、対話型のワークロードでメモリリソースと GPU リソースが共有されているエンタープライズ環境をシミュレートしたものです。</block>
  <block id="73eea118e4762640a7f60136f3e5c1a0" category="inline-link-macro">次のセクションでは、データサイエンスチームのプロジェクトを作成し、 GPU を割り当てる方法について説明します</block>
  <block id="7c2c470385b4f61a9e9b5b0881d2f061" category="paragraph"><block ref="7c2c470385b4f61a9e9b5b0881d2f061" category="inline-link-macro-rx"></block></block>
  <block id="efbb4ade01a09771413f4c09880e800a" category="paragraph">このセクションでは、複数のチームがワークロードを送信し、クォータを超過するシナリオを拡張します。この方法では、 Run ： AI の公正性アルゴリズムが、事前設定されたクォータの比率に従ってクラスタリソースを割り当てる方法を説明します。</block>
  <block id="3bd5af2e3a75651c4b9c45d26400fbaa" category="paragraph">このテストシナリオの目標：</block>
  <block id="cc9e23eb4fe1626d97a5dfeab7cf0d25" category="list-text">複数のチームがクォータを介して GPU を要求しているときのキューイングメカニズムを示します。</block>
  <block id="050060785f2852b203c9e82254f2946a" category="list-text">システムが、クォータの比率に従って、クォータを超過した複数のチーム間にクラスタの適正な共有を分散し、クォータが大きいチームがスペア容量の大部分を占めるようにする方法を示します。</block>
  <block id="9e06f625a31670e60f0a8a09917c3ba0" category="paragraph">の末尾 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>では、キューに入れられるワークロードは 2 つあります。 1 つは「 team -b 」用、もう 1 つは「 team -c 」用です。このセクションでは、追加のワークロードをキューに登録します。</block>
  <block id="286cda6cf9e9438a2cff2827773cfe7a" category="inline-link-macro">セクション 4.10 のテストの詳細</block>
  <block id="0e7a9992269080ceaf2b90c188cbb861" category="paragraph">ジョブの送信、使用されるコンテナイメージ、実行されるコマンドシーケンスなどの詳細については、を参照してください <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>。</block>
  <block id="b1df8ade330dd8e3c0962d87a58c1ba9" category="paragraph">すべてのジョブがセクションに従って送信される場合 <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>システム・ダッシュボードには 'team a`'team -b'および 'team -c` のすべての GPU の数が ' 事前設定されたクォータよりも多くなっていることが示されています「 team -a 」は、初期設定のソフトクォータ（ 4 ）よりも 4 基の GPU を占有し、「 team -b 」と「 team -c 」はソフトクォータ（ 2 つ）よりも 2 つの GPU を占有します。割り当てられたクォータ超過 GPU の比率は、事前設定されたクォータの比率と同じです。これは、システムが優先順位の基準として事前設定されたクォータを使用し、複数のチームがクォータを超えて GPU を追加するように要求した場合に応じてプロビジョニングされるためです。このような自動ロードバランシングは、企業のデータサイエンスチームが AI モデルの開発と運用に積極的に関与している場合に、公平性と優先順位付けを提供します。</block>
  <block id="6effcb49094093af4699b050b9994a58" category="paragraph"><block ref="6effcb49094093af4699b050b9994a58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3be1869ca88e0b5881bc6d1da583426" category="list-text">他のチームのワークロードのキュー解除が開始されます。</block>
  <block id="d2325970b5cec6b47eb2c10267e3a599" category="list-text">キュー解除の順序は ' 公正性アルゴリズムに従って決定されますたとえば 'team -b と 'team -c は ' 同等のクォータを持つため ' 同じ量のオーバークォータ GPU を取得します また 'team -a は 'team -b と 'team -c のクォータの 2 倍のクォータを備えているため 'GPU の量が 2 倍になります</block>
  <block id="e2cc28c61aaa6ca7e38bd7ed9de398f1" category="list-text">すべての割り当てが自動的に行われます。</block>
  <block id="c21d5f3e7c1336258c406bddcde6e0f8" category="paragraph">したがって、システムは次の状態で安定します。</block>
  <block id="8f2185cd998019e76038f11669cfbfb0" category="cell">GPU が割り当てられました</block>
  <block id="3b55c08436be9e1008bb19488c139c88" category="cell">8/4</block>
  <block id="f532ced5959572a93091758c821d7ff1" category="cell">クォータを介した 4 基の GPU空のキューです。</block>
  <block id="b0713292a73176f9754bd528cecde2d1" category="cell">クォータを介した 2 つの GPU 。1 つのワークロードがキューに登録</block>
  <block id="1f0189591d8d7dc1d3db367398fb49c5" category="cell">0/8</block>
  <block id="7c0de9de98eb6577a96694238e533915" category="cell">GPU をまったく使用しないので、キューに登録されているワークロードはありません</block>
  <block id="948c32bf5f56f7dd6f3b2baab5f6d89d" category="paragraph">次の図は、プロジェクトごとの GPU 割り当てを示しています Run ：セクションの AI Analytics ダッシュボードに表示される時間 <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>、 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>および <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>。図の各行は、特定のデータサイエンスチーム用にプロビジョニングされた GPU の数を常に表しています。システムは、送信されたワークロードに応じて GPU を動的に割り当てることがわかります。これにより、クラスタ内に使用可能な GPU がある場合はクォータを超過し、公平性に従ってジョブをプリエンプトしてから、 4 つのチームすべてが最終的に安定した状態に到達することができます。</block>
  <block id="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="paragraph"><block ref="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e94097f9836d70dc64016728992696a0" category="inline-link-macro">次の例： Trident でプロビジョニングされた永続的ボリュームにデータを保存する</block>
  <block id="14718f3c808034f0e3239dbaf832a478" category="paragraph"><block ref="14718f3c808034f0e3239dbaf832a478" category="inline-link-macro-rx"></block></block>
  <block id="3c97b4929008c9f4091a8070f570ccd4" category="paragraph">業界標準のベンチマークツール TensorFlow ベンチマークを使用して、このシステムの動作とパフォーマンスを検証しました。ResNet-50 のトレーニングに使用される ImageNet データセット。これは、画像分類のための有名な Convolutional Neural Network （ CNN ；畳み込みニューラルネットワーク） DL モデルです。ResNet-50 は、処理時間を短縮して正確なトレーニング結果を提供し、ストレージに対する十分な需要を喚起できます。</block>
  <block id="123704fec3ddad892d7c2ae5c4de301b" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block></block>
  <block id="56dfbb2acffcc994819cbad5ec450617" category="paragraph">このセクションでは、 ML ワークフローのデータキャッシングに関連する概念とコンポーネントについて説明します。</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="section-title">機械学習</block>
  <block id="d3f18dede1775f82df24232095090253" category="paragraph">ML は、世界中の多くの企業や組織にとって急速に不可欠になっています。そのため、 IT チームと DevOps チームは、 ML ワークロードの標準化や、 ML のジョブやパイプラインで求められる動的で負荷の高いワークフローをサポートするクラウド、オンプレミス、ハイブリッドコンピューティングリソースのプロビジョニングという課題に直面しています。</block>
  <block id="f71dfff263d05c18171dcf4b8c538ebf" category="section-title">コンテナベースの機械学習と Kubernetes</block>
  <block id="002f314c3c41ffb741f8c91d2274af9a" category="paragraph">コンテナは、共有ホストオペレーティングシステムカーネル上で実行される独立したユーザスペースインスタンスです。コンテナの採用が急速に増加しています。コンテナは、仮想マシン（ VM ）が提供するものと同じアプリケーションのサンドボックス化のメリットの多くを提供します。ただし、 VM が依存するハイパーバイザーレイヤとゲストオペレーティングシステムレイヤが排除されているため、コンテナの軽量化が大幅に向上しています。</block>
  <block id="ce8bb3a31abf8bfcdcdacb34d96b010a" category="paragraph">コンテナを使用すると、アプリケーションの依存関係や実行時間などをアプリケーションで直接効率的にパッケージングできます。最も一般的に使用されるコンテナパッケージ形式は Docker コンテナです。Docker コンテナ形式でコンテナ化されたアプリケーションは、 Docker コンテナを実行できる任意のマシンで実行できます。これは、アプリケーションの依存関係がマシンに存在しない場合でも当てはまります。これは、すべての依存関係がコンテナ自体にパッケージ化されているためです。詳細については、を参照してください<block ref="5b5112034c22f544bc19c7a568afbfcb" category="inline-link-rx"></block>。</block>
  <block id="cfbe31a3e8ac3348240670510232ed8f" category="paragraph">人気のあるコンテナオーケストレーションツールである Kubernetes を使用すると、データサイエンティストは柔軟なコンテナベースのジョブとパイプラインを開始できます。また、インフラチームは、管理された単一のクラウドネイティブ環境で ML ワークロードを管理および監視できます。詳細については、を参照してください<block ref="45556eaecf73275e38fa694031a104a3" category="inline-link-rx"></block>。</block>
  <block id="371ac536e4099ad82f6080b713ce9647" category="paragraph">cnvrg.io は、企業が AI やデータサイエンスの開発を研究から生産に至るまで管理、拡張、高速化する方法を変革する AI オペレーティングシステムです。コードファーストのプラットフォームは、データサイエンティストがデータサイエンティストのために構築し、オンプレミスとクラウドのどちらでも実行できる柔軟性を提供します。モデル管理、 MLOps 、継続的な ML ソリューションを備えた cnvrg.io は、データサイエンスチームに最先端のテクノロジを提供します。そのため、 DevOps に費やす時間を短縮し、真の魔法のアルゴリズムに集中できます。cnvrg.io を使用して以来、さまざまな業界のチームが生産モデルを増やし、ビジネス価値を高めてきました。</block>
  <block id="ffb1d184fa3790eda48f1fc2d9c2f821" category="section-title">cnvrg.io メタスケジューラ</block>
  <block id="55fdc117823776b1ebb2170b4adfadf6" category="paragraph">cnvrg.IO には独自のアーキテクチャがあり、 IT エンジニアは異なるコンピューティングリソースを同じコントロールプレーンに接続し、すべてのリソースにわたって cnvrg.io で ML ジョブを管理できます。つまり、次の図に示すように、複数のオンプレミス Kubernetes クラスタ、 VM サーバ、クラウドアカウントを接続し、すべてのリソースで ML ワークロードを実行できます。</block>
  <block id="3c7fcf7e73eda18d7277b14914857f38" category="paragraph"><block ref="3c7fcf7e73eda18d7277b14914857f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cfff0196a077e92a8fe9326f97cb7fc5" category="section-title">cnvrg.io データキャッシング</block>
  <block id="ad693e5ee82f0e0486a136821d0a0779" category="paragraph">cnvrg.io を使用すると、データサイエンティストは、データキャッシングテクノロジを使用して、ホットデータセットとコールドデータセットのバージョンを定義できます。デフォルトでは、データセットは一元化されたオブジェクトストレージデータベースに格納されます。データサイエンティストは、選択したコンピューティングリソースに特定のデータバージョンをキャッシュして、ダウンロード時間を節約し、 ML の開発と生産性を向上させることができます。数日間キャッシュされていないデータセットは、選択した NFS から自動的に消去されます。キャッシュのキャッシュとクリアはワンクリックで実行でき、コーディング、 IT 、 DevOps の作業は必要ありません。</block>
  <block id="42cf1b27f88752e1e98918981aa76e41" category="section-title">cnvrg.io フローと ML パイプライン</block>
  <block id="1bc2ab6c98ec5b23a8a384861da1c6ca" category="paragraph">cnvrg.io フローは、本番 ML パイプラインを構築するためのツールです。フロー内の各コンポーネントは、ベースとなる Docker イメージを使用して選択したコンピューティング上で実行されるスクリプト / コードです。この設計により、データサイエンティストとエンジニアは、オンプレミスとクラウドの両方で実行できる単一のパイプラインを構築できます。cnvrg.io は、データ、パラメータ、およびアーティファクトが異なるコンポーネント間で移動していることを確認します。さらに、各フローを監視して追跡することで、再現性の高い 100% のデータサイエンスを実現します。</block>
  <block id="87cd11047488d3aa87eb2829eeb02305" category="section-title">cnvrg.io コア</block>
  <block id="526c8ebff3057ce85f47160f32e15556" category="paragraph">cnvrg.io コアは、データサイエンスコミュニティが DevOps よりもデータサイエンスに集中できるようにするための無償プラットフォームです。コアの柔軟なインフラストラクチャにより、データサイエンティストは、オンプレミスでもクラウドでも、あらゆる言語、 AI フレームワーク、コンピューティング環境を使用することができます。これにより、最適な処理を実行し、アルゴリズムを構築できます。cnvrg.io コアは、任意の Kubernetes クラスタ上で 1 つのコマンドを使用して簡単にインストールできます。</block>
  <block id="f92894a2a2633c488de71d74ace474d7" category="paragraph">ONTAP AI は、 ML ワークロードとディープラーニング（ DL ）ワークロード向けのデータセンターリファレンスアーキテクチャであり、 Tesla V100 GPU を搭載した NetApp AFF ストレージシステムと NVIDIA DGX システムを使用します。ONTAP AI は、業界標準の NFS ファイルプロトコルである 100Gb イーサネットを基盤としており、標準的なデータセンターテクノロジを使用して実装や管理のオーバーヘッドを軽減する、ハイパフォーマンスな ML / DL インフラを提供します。標準化されたネットワークとプロトコルを使用することで、 ONTAP AI をハイブリッドクラウド環境に統合しながら、運用の一貫性と簡易性を維持できます。解決策 AI は、事前検証済みのインフラ ONTAP として、導入にかかる時間とリスクを削減し、管理オーバーヘッドを大幅に削減することで、お客様はより短期間で価値を実現できます。</block>
  <block id="c2148c4c14a795b271b67f662900da4e" category="paragraph">Trident は、ネットアップが開発および管理しているオープンソースのストレージオーケストレーションツールで、 Kubernetes ワークロード向けの永続的ストレージの作成、管理、使用を大幅に簡易化します。Trident 自体は Kubernetes ネイティブのアプリケーションであり、 Kubernetes クラスタ内で直接実行されます。Trident を使用すると、 Kubernetes のユーザ（開発者、データサイエンティスト、 Kubernetes 管理者など）は、使い慣れた標準的な Kubernetes 形式で永続ストレージボリュームを作成、管理、操作できます。同時に、ネットアップの高度なデータ管理機能と、ネットアップテクノロジを基盤とするデータファブリックを活用できます。Trident は、複雑な永続的ストレージを抽象化して、消費を簡易化します。詳細については、を参照してください<block ref="c98bfcab9052a99136f8752a5ac8ed0b" category="inline-link-rx"></block>。</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetApp StorageGRID</block>
  <block id="ecfefbd82f34239e668be7aac3762226" category="paragraph">NetApp StorageGRID は、ユーザが S3 プロトコルを使用してアクセスできるシンプルなクラウド型ストレージを提供することで、これらのニーズを満たすように設計された Software-Defined オブジェクトストレージプラットフォームです。StorageGRID は、距離に関係なく、インターネットに接続されたサイト全体で複数のノードをサポートするように設計されたスケールアウトシステムです。StorageGRID のインテリジェントポリシーエンジンを使用すると、サイト間でイレイジャーコーディングオブジェクトを選択して地理的な耐障害性を確保したり、リモートサイト間でオブジェクトレプリケーションを行ったりすることで、 WAN アクセスのレイテンシを最小限に抑えることができます。StorageGRID は、この解決策にある優れたプライベートクラウドプライマリオブジェクトストレージデータレイクを提供します。</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="section-title">NetApp Cloud Volumes ONTAP の略</block>
  <block id="c060a6548f860aa739b76c0178ac7c5c" category="paragraph">NetApp Cloud Volumes ONTAP データ管理ソフトウェアは、 AWS 、 Google Cloud Platform 、 Microsoft Azure などのパブリッククラウドプロバイダの柔軟性を活かして、ユーザデータの制御、保護、効率化を実現します。Cloud Volumes ONTAP は、 NetApp ONTAP ストレージソフトウェアを基盤としたクラウドネイティブなデータ管理ソフトウェアで、クラウドデータのニーズに対応する、汎用性に優れた優れたストレージプラットフォームをユーザに提供します。クラウドとオンプレミスで同じストレージソフトウェアを使用することで、ユーザはデータファブリックの価値を活用できます。まったく新しいデータ管理方法について IT 担当者をトレーニングする必要はありません。</block>
  <block id="e16f1943a363dfa46a958bd450c2ecf8" category="paragraph">ハイブリッドクラウドの導入モデルに関心があるお客様は、 Cloud Volumes ONTAP を使用することで、ほとんどのパブリッククラウドで同じ機能とクラス最高のパフォーマンスを実現し、一貫したシームレスなユーザエクスペリエンスをあらゆる環境で実現できます。</block>
  <block id="82ac5cdab15b3954389238dddbc12168" category="paragraph"><block ref="82ac5cdab15b3954389238dddbc12168" category="inline-link-macro-rx"></block></block>
  <block id="d993b502abe38cef7c7256291e3ffa8e" category="paragraph">次の表に、解決策の実装に必要なハードウェアコンポーネントを示します。解決策の特定の実装で使用されるハードウェアコンポーネントは、お客様の要件に応じて異なる場合があります。</block>
  <block id="4c2db3e48f4f33a355c8e493453b53c2" category="inline-link-macro">次の手順：ソフトウェア要件</block>
  <block id="54870296c311c566be3a76b4a4df8e8c" category="paragraph"><block ref="43a6574de87222e6a8a22c8138fc4c45" category="inline-link-macro-rx"></block>。</block>
  <block id="48fe531f68f98f9f6afcf79da6d3b1b3" category="doc">TR-4834 ：『 NetApp and Iguazio for MLRun Pipeline 』</block>
  <block id="a0e5bba9c75f65c1d58c6a238316bd2b" category="paragraph">Rick Huang 氏、 David Arnette 氏、 NetApp Marcelo Litovsky 氏、 Iguazio 氏</block>
  <block id="dd9508a891c15cc4bb34f03dc870ab6c" category="paragraph">本ドキュメントでは、 NetApp ONTAP AI 、 NetApp AI コントロールプレーン、 NetApp Cloud Volume ソフトウェア、 Iguazio データサイエンスプラットフォームを使用した MLRun パイプラインの詳細について説明します。サーバレス機能の Nuclio 、 Kubernetes Persistent Volume 、 NetApp Cloud Volume 、 NetApp Snapshot コピー、 Grafana ダッシュボード、 および Iguazio プラットフォーム上のその他のサービスにより、ネットワーク障害検出のシミュレーション用のエンドツーエンドのデータパイプラインを構築できます。イグアスとネットアップのテクノロジを統合し、オンプレミスだけでなくクラウドでも、迅速なモデル導入、データレプリケーション、本番環境の監視を実現しました。</block>
  <block id="d431a0ad3e0e99cf99c08fda529884bd" category="paragraph">データサイエンティストの仕事は、機械学習（ ML ）モデルと人工知能（ AI ）モデルのトレーニングと調整に集中する必要があります。しかし、 Google の調査によると、データサイエンティストは、 AI / ML ワークフローでのモデル開発を示す次の図に示すように、モデルをエンタープライズアプリケーションで使用し、大規模に実行する方法を検討する時間の約 80% を費やしています。</block>
  <block id="f08b641e59dba6d999dc1bc2085bcd2c" category="paragraph"><block ref="f08b641e59dba6d999dc1bc2085bcd2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eec0363d19df86d30ecefc2e44170fa" category="paragraph">エンドツーエンドの AI / ML プロジェクトを管理するには、エンタープライズコンポーネントについてより広範な理解が必要です。DevOps ではこのような種類のコンポーネントの定義、統合、導入が引き継がれていますが、機械学習の運用では、 AI / ML プロジェクトを含む同様のフローがターゲットとなります。エンドツーエンドの AI / ML パイプラインが企業内でどのように影響するかを知るには、次の必要なコンポーネントのリストを参照してください。</block>
  <block id="ea2ef9b0d095bf991f4973633b485340" category="list-text">データベース</block>
  <block id="3b18b13f059019d19211f8a9f36f7e4e" category="list-text">ファイルシステム</block>
  <block id="d6c823008f20bbfce5f39b30ec9fa918" category="list-text">継続的統合 / 継続的導入（ CI / CD ）パイプライン</block>
  <block id="52681719ec1296447ae0e357c4781415" category="list-text">開発統合開発環境（ IDE ）</block>
  <block id="2fae32629d4ef4fc6341f1751b405e45" category="list-text">セキュリティ</block>
  <block id="bd0992d43bb2d0ca676184502e14754e" category="list-text">データアクセスポリシー</block>
  <block id="c8e2277ecfb1427838c488c217f99466" category="list-text">クラウド</block>
  <block id="a9353b1bd1eeedb788a74090b5f8d0bc" category="list-text">データサイエンスのツールセットとライブラリ</block>
  <block id="2f0ff7df4fd6fa99bbf249af2ea4c3a5" category="paragraph">本書では、ネットアップと Iguazio のパートナーシップによってエンドツーエンドの AI / ML パイプラインの開発が大幅に簡易化されたことを紹介します。この簡易化により、 AI / ML アプリケーションの市場投入までの時間が短縮されます。</block>
  <block id="253411380ba9cde08bcfafbd516ad585" category="paragraph">データサイエンスの世界は、情報技術とビジネスのさまざまな分野に影響をもたらしています。</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">データサイエンティストは、選択したツールとライブラリを柔軟に使用できる必要があります。</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">データエンジニアは、データの流れと配置場所を把握する必要があります。</block>
  <block id="c12281f5ea7b17e370414efbf3f26c30" category="list-text">DevOps エンジニアは、新しい AI / ML アプリケーションを CI / CD パイプラインに統合するためのツールを必要としています。</block>
  <block id="f1a4e0eca545ebe9e3c32f1fde407410" category="list-text">ビジネスユーザは、 AI / ML アプリケーションにアクセスしたいと考えています。ネットアップと Iguazio がどのようにしてプラットフォームのビジネスに価値をもたらすかを説明します。</block>
  <block id="00cc9e5c959e62a9132baca479060db3" category="paragraph">この解決策は、 AI / ML アプリケーションのライフサイクルに従います。まず、データサイエンティストの仕事から始めて、データの前処理やモデルのトレーニングと導入に必要なさまざまな手順を定義します。成果物の追跡、実行の実験、 Kubeflow への導入が可能な、完全なパイプラインの構築に必要な作業をフォローしています。このサイクルを完了するには、パイプラインと NetApp Cloud Volume を統合し、次の図に示すようにデータのバージョン管理を可能にします。</block>
  <block id="ddd4a11ec23c52d3f0831809bc4d7c8f" category="paragraph"><block ref="ddd4a11ec23c52d3f0831809bc4d7c8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7c8cd7998e5c4a67923acf8580d94e2" category="inline-link-macro">次のステップ：テクノロジの概要</block>
  <block id="b9023dede6231d8f57593d31db930bf6" category="paragraph"><block ref="b9023dede6231d8f57593d31db930bf6" category="inline-link-macro-rx"></block></block>
  <block id="2e4fd4a404800f52299c132a3403dc72" category="cell">インフラストラクチャコンポーネント</block>
  <block id="64d354dc5879cf570ce7b4ef676e75bd" category="cell">オペレーティングシステム</block>
  <block id="4152ac69f367cb5f64dfbc247dd41db0" category="cell">展開ジャンプホスト</block>
  <block id="583a65df9db4119165f5ea0abaa50281" category="cell">VM</block>
  <block id="f341fd2fe180518e152be2d6fb4ec20b" category="cell">Kubernetes マスターノード</block>
  <block id="a89c263b82f7c7f61c9b6c93080f8425" category="cell">Kubernetes ワーカーノード</block>
  <block id="f89b34b046a8d6e3137c95861fa3cf8a" category="cell">NVIDIA DGX-1 （ベアメタル）</block>
  <block id="eba551f3f972830c55b1c9bef15b5f26" category="cell">NVIDIA DGX OS 4.0.5 （ Ubuntu 18.04.2 LTS に基づく）</block>
  <block id="0911ffdbb76c891f964e39a07eb6b697" category="cell">1 つの HA ペア</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">ソフトウェアコンポーネント</block>
  <block id="9ba69bd971d430b368ce3f0286c8e77c" category="cell">Apache Airflow Helm チャート</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">サポート</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link">ネットアップにお問い合わせください</block>
  <block id="a1773dfa99aa26853e90886d55e0d05a" category="paragraph">ネットアップは、 Apache Airflow 、 Docker 、 Kubeflow 、 Kubernetes 、 NVIDIA DeepOps のエンタープライズサポートを提供していません。ネットアップの AI コントロールプレーン解決策と同様の機能を備えた、完全にサポートされている解決策に関心がある場合： <block ref="103a4ac9affe57bb7edb7796bfdeb684" category="inline-link-rx"></block> ネットアップがパートナー様と共同で提供する、完全にサポートされている AI / ML ソリューションについて説明します。</block>
  <block id="3cfbc3bac23f6bb9e7ebdc6deefeaf1d" category="paragraph">ネットアップと NVIDIA が開発、検証した NetApp ONTAP AI アーキテクチャは、 NVIDIA DGX システムとネットアップのクラウド対応ストレージシステムを基盤としています。このリファレンスアーキテクチャには、 IT 組織に次のようなメリットがあります。</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">は、さまざまなパフォーマンスとに対応するさまざまなストレージオプションを提供します コストポイント</block>
  <block id="6fa0f6cc1d5d12069641e73217a17be2" category="paragraph">NetApp ONTAP AI は、 DGX システムと NetApp AFF A800 ストレージシステムを最先端のネットワークと緊密に統合します。NetApp ONTAP AI システムと DGX システムでは、設計の複雑さと推測に頼らず、 AI 導入を簡易化できます。お客様は小規模構成から始めて、システムを中断なく拡張できます。同時に、エッジ、コア、クラウドにわたってデータをインテリジェントに管理できます。</block>
  <block id="bdc094a519f73076386a8bf2948832a6" category="paragraph">ネットアップの AI コントロールプレーンは、データサイエンティストとデータエンジニアを対象とした、フルスタックの AI 、 ML 、ディープラーニング（ DL ）のデータと実験管理解決策です。AI の利用が拡大するにつれて、ワークロードの拡張性やデータの可用性など、さまざまな課題が生じています。NetApp AI コントロールプレーンは、データネームスペースの迅速なクローニングを Git レポジトリと同様に行う機能や、トレーサビリティとバージョン管理のためにデータやモデルベースラインをほぼ瞬時に作成する AI トレーニングワークフローを定義して実装するなど、これらの課題に対処します。NetApp AI コントロールプレーンを使用すると、サイトやリージョン間でデータをシームレスにレプリケートし、 Jupyter Notebook ワークスペースをすばやくプロビジョニングして、大規模なデータセットにアクセスできます。</block>
  <block id="22101b8498dea1c2e2e35bd4868847a4" category="paragraph">実行： AI は、世界初の AI インフラストラクチャのオーケストレーションおよび仮想化プラットフォームを構築しました。基盤となるハードウェアからワークロードを抽象化することで、 Run ： AI は、 GPU リソースの共有プールを作成します。この共有プールを動的にプロビジョニングし、 AI ワークロードの効率的なオーケストレーションと GPU の使用の最適化を実現します。データサイエンティストは、大量の GPU パワーをシームレスに消費して研究を向上させ、加速させることができます。一方、 IT チームは、リソースのプロビジョニング、キューイング、利用率に関する一元化されたクロスサイト管理とリアルタイムの可視性を維持します。Run ： AI プラットフォームは Kubernetes を基盤として構築されているため、既存の IT ワークフローやデータサイエンスワークフローと簡単に統合できます。</block>
  <block id="ae00256db8d45ecdaf9c364a96821417" category="paragraph">Run ： AI プラットフォームには、次のようなメリットがあります。</block>
  <block id="d472807c15e94ef6053e95521ff7e838" category="list-text">* イノベーションにかかる時間を短縮 * Run ： AI リソースのプール化、キューイング、優先付けのメカニズムをネットアップストレージシステムと組み合わせることで、研究者たちはインフラ管理の苦労から取り取り除かれ、データサイエンスに専念することができます。実行： AI とネットアップのお客様は、コンピューティングやデータパイプラインのボトルネックを発生させることなく、必要な数のワークロードを実行することで生産性を向上できます。</block>
  <block id="2707d068deb9b46967615c70c806e0d8" category="list-text">* チームの生産性向上。 * 実行： AI 公正性アルゴリズムにより、すべてのユーザーとチームが公平なリソースを共有できるようになります。優先度の高いプロジェクトを中心としたポリシーをあらかじめ設定しておくことで、あるユーザやチームから別のユーザやチームにリソースを動的に割り当てることができ、誰もが切望した GPU リソースにタイムリーにアクセスできるようになります。</block>
  <block id="faa5854c7e84507b88cba1c0ec1a9aaf" category="list-text">* GPU 利用率の向上。 * 実行： AI スケジューラを使用すると、 Kubernetes での分散トレーニング用に、フラクショナルな GPU 、整数型 GPU 、複数の GPU ノードを簡単に利用できます。このように、 AI ワークロードは容量ではなくニーズに基づいて実行されます。データサイエンスチームは、 1 つのインフラでより多くの AI 実験を実行できるようになります。</block>
  <block id="d9533ea5c6cb975dff314dace88f2aa4" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block></block>
  <block id="9abac747d764180a5fe55920e00e887d" category="section-title">お客様にもたらされる価値</block>
  <block id="45ce76bfe721ca13d37ca15fdbebd391" category="paragraph">このホワイトペーパーに貢献したことを、 NVIDIA の著名な同僚によって認められたことに感謝の意を表します。 Davide Onfrio 、 Alex Qi 、 Sicong Ji 、 Marty Jain 、 Robert Sohigian 。また、ネットアップの主要チームメンバーである Santosh Rao 、 David Arnette 、 Michael Oglesby 、 Brent Davis 、 Andy Sayare の協力も感謝しています。 Erik Mulder 氏、 Mike McNamara 氏。</block>
  <block id="81fbc4247f2c3a990b090cef6b9ebe03" category="paragraph">本ホワイトペーパーの作成に大きく貢献した洞察と専門知識を提供したすべての方々に心から感謝します。</block>
  <block id="bc2f62a5c14dc9d16f38cc32c304164c" category="paragraph"><block ref="bc2f62a5c14dc9d16f38cc32c304164c" category="inline-link-macro-rx"></block></block>
  <block id="25edd21a28cb2fca00ab6f30e47c6d79" category="paragraph">サンプルの推論要求を実行するには、次の手順を実行します。</block>
  <block id="cb11a85322b32a7615367d2523718b49" category="list-text">クライアントコンテナ / ポッドへのシェルを取得します。</block>
  <block id="b489ec265fd981ff7aa78a7721bd3101" category="list-text">サンプルの推論要求を実行します。</block>
  <block id="15c5e1ffe753f0365f39e7b508ce5ae0" category="paragraph"><block ref="15c5e1ffe753f0365f39e7b508ce5ae0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5bf2ae3a2d0d1dd1e0740744c9ebb1b" category="paragraph">この推論要求は、イメージ認識に使用される「 re snet50_netdef」 モデルを呼び出します。他のクライアントも、同様のアプローチに従って適切なモデルを発信することで、推論要求を同時に送信できます。</block>
  <block id="a301641e2c9595a0c9c39ee7986f7ca8" category="paragraph"><block ref="a301641e2c9595a0c9c39ee7986f7ca8" category="inline-link-macro-rx"></block></block>
  <block id="76ada3ea43b0e44772967793fe69b1bd" category="inline-link">Kubernetes 導入ガイド</block>
  <block id="03628142cdc704dd6ffe5d7d13573999" category="list-text">の手順に従って、クラスタに Kubernetes を導入します 。<block ref="cdf0a6d71dcbe898357c0e37010d30de" category="inline-link-rx"></block> NVIDIA DeepOps GitHub サイトで入手できます。</block>
  <block id="c6fff1434177c1b95244b5300314f730" category="paragraph">配備に失敗した場合は 'kubectl_localhost' の値を 'd eepops/config/group_vars/k8s-cluster.yml' で false に変更し ' 手順 2 を繰り返します'Copy kubectl binary to Ansible host' タスクは 'kubectl_localhost' の値が true の場合にのみ実行され ' メモリ使用に関する既知の問題がある FETCH Ansible モジュールに依存しますこのようなメモリ使用の問題により、原因がタスクを失敗させることがあります。メモリ問題が原因でタスクが失敗した場合は、以降の導入処理は正常に完了しません。</block>
  <block id="24e1fa4c913dcdc975e022f921d4d603" category="paragraph">「 kubectl_localhost 」の値を「 false 」に変更した後で展開が正常に完了した場合、「 kubectl binary 」を Kubernetes マスターノードから配備ジャンプホストに手動でコピーする必要があります。特定のマスター・ノード上で 'kubectl binary' の場所を確認するには 'which kubectl' コマンドをそのノード上で直接実行します</block>
  <block id="a185054da23018c3578742c41141312b" category="inline-link-macro">次の例： Cnvrg.io の導入</block>
  <block id="c18b567a6a5397941715c30a00a97395" category="paragraph"><block ref="c18b567a6a5397941715c30a00a97395" category="inline-link-macro-rx"></block></block>
  <block id="d7cd7846436814deb26b0df06d7a4b2a" category="summary">Kubernetes クラスタでマルチノードの AI と ML の同期ジョブを実行するには、導入ジャンプホストでこのページにリストされているタスクを実行します。このプロセスにより、ネットアップボリュームに格納されているデータを活用し、 1 つのワーカーノードで提供されるものよりも多くの GPU を使用することができます。</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">分散型 AI の同期ワークロードを実行します</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Kubernetes クラスタでマルチノードの AI と ML の同期ジョブを実行するには、導入ジャンプホストで次のタスクを実行します。このプロセスにより、ネットアップボリュームに格納されているデータを活用し、 1 つのワーカーノードで提供されるものよりも多くの GPU を使用することができます。同期分散 AI ジョブの説明については、次の図を参照してください。</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">同期分散ジョブを使用すると、非同期分散ジョブに比べてパフォーマンスとトレーニングの精度が向上します。同期ジョブと非同期ジョブの長所と短所については、本ドキュメントでは説明していません。</block>
  <block id="262523fcbe6eb0ec96ea58299e58f65c" category="paragraph"><block ref="262523fcbe6eb0ec96ea58299e58f65c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a9af10e4883efa64de927027b5b0ffa" category="list-text">次のコマンド例は、 1 つのワーカーの作成を示しています これは、同じの同期分散実行に関与します 1 つのノードで実行された TensorFlow ベンチマークジョブ を参照してください <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>。この例では、 2 つのワーカーノードでジョブが実行されるため、導入されるワーカーは 1 つだけです。</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">この例のワーカー導入では、 8 個の GPU を要求し、 8 個以上の GPU を搭載した 1 つの GPU ワーカーノードで実行できます。GPU ワーカーノードが 8 個以上の GPU を搭載している場合、パフォーマンスを最大化するには、この数をワーカーノードが機能する GPU の数と同じにすると便利です。Kubernetes の導入の詳細については、を参照してください<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block>。</block>
  <block id="bfe89db11adc9a38165e670f3062d398" category="paragraph">この例では、このコンテナ化された特定のワーカーが自分で完了することはないため、 Kubernetes 環境が作成されます。そのため、 Kubernetes のジョブ構造を使用して導入することは理にかなっていません。従業員が自分で設計または作成した場合、作業構成を使用して従業員を配置することが理にかなっている場合があります。</block>
  <block id="05bdf5435b916b7b205f448788324f2b" category="paragraph">この配置例の仕様で指定されているポッドには 'hostNetwork' の値が true に設定されていますこの値は、ポッドが、 Kubernetes が各ポッドに通常作成する仮想ネットワーキングスタックではなく、ホストワーカーノードのネットワークスタックを使用することを意味します。このアノテーションは、特定のワークロードが Open MPI 、 NCCL 、 Horovod を使用して同期分散方法でワークロードを実行するために使用されます。そのため、ホストネットワークスタックにアクセスする必要があります。Open MPI 、 NCCL 、および Horovod についての説明は、本ドキュメントの範囲外です。この hostNetwork:true' 注釈が必要かどうかは ' 実行している特定のワークロードの要件によって決まります「 hostNetwork 」フィールドの詳細については、を参照してください<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block>。</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">手順 1 で作成したワーカー導入が正常に起動したことを確認します。次のコマンド例は、導入定義に示すように、単一のワーカーポッドが導入用に作成されたこと、およびこのポッドが GPU ワーカーノードの 1 つで現在実行されていることを確認します。</block>
  <block id="3ba975f6a7389af18602f0e938bcc37b" category="list-text">マルチノード同期ジョブの実行を開始して参加させ、追跡するマスター用の Kubernetes ジョブを作成します。次のコマンド例では、 1 つのマスターを作成します。このマスターは、セクションの例で 1 つのノード上で実行された、同じ TensorFlow ベンチマークジョブの同期分散実行を追跡し、開始します <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>。</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">この例では、マスタージョブは 8 個の GPU を要求するため、 8 個以上の GPU を搭載した 1 つの GPU ワーカーノードで実行できます。GPU ワーカーノードが 8 個以上の GPU を搭載している場合、パフォーマンスを最大化するには、この数をワーカーノードが機能する GPU の数と同じにすると便利です。</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">この例のジョブ定義で指定されているマスターポッドには、手順 1 でワーカーポッドに「 hostNetwork 」の値「 true 」が与えられたのと同様に、「 hostNetwork 」の値が「 true 」に設定されます。この値が必要な理由については、手順 1 を参照してください。</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">手順 3 で作成したマスタージョブが正しく実行されていることを確認します。次のコマンド例では、ジョブ定義に示されているように、ジョブに対して単一のマスターポッドが作成され、このポッドが GPU ワーカーノードの 1 つで現在実行されていることを確認します。また、手順 1 で最初に確認したワーカーポッドがまだ実行中で、マスターポッドとワーカーポッドが別々のノードで実行されていることも確認する必要があります。</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">手順 3 で作成したマスタージョブが正常に完了したことを確認します。次のコマンド例は、ジョブが正常に完了したことを確認します。</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">不要になったワーカー配置を削除します。次のコマンド例は、手順 1 で作成したワーカー配置オブジェクトの削除を示しています。</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">ワーカー導入オブジェクトを削除すると、関連付けられているワーカーポッドは Kubernetes によって自動的に削除されます。</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">* オプション： * マスタージョブアーティファクトをクリーンアップします。次のコマンド例は、手順 3 で作成したマスタージョブオブジェクトの削除を示しています。</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">マスタージョブオブジェクトを削除すると、関連付けられているマスターポッドは Kubernetes によって自動的に削除されます。</block>
  <block id="cb1501db8fac0fe0b1cc3b53200f0ab9" category="summary">ビジネスアプリケーションとエンタープライズデータベースに最新の追加機能 ソリューション関連資料</block>
  <block id="9de8e04d062d5eb8e2ff199783964174" category="paragraph">最新のビジネスアプリケーション、エンタープライズデータベースソリューション、ソリューション関連資料の概要。</block>
  <block id="c55aef4f96cafe48d6e5cf37af33721b" category="inline-link">SAP HANA B&amp;amp; R with SnapCenter の略</block>
  <block id="ffbfe314fcb0f0531b18b666e3f70bcc" category="inline-link">FC SAN 上の SAP HANA</block>
  <block id="9b849a5e6a46a992279087781315f191" category="inline-link">Microsoft SQL Server 上の SAP アプリケーション</block>
  <block id="77c484629c9e9b5aed6fa32ebb0e7229" category="inline-link">仮想インフラストラクチャ向け SolidFire ESDS 上の SQL Server</block>
  <block id="91be6e42fe122f20831dcd474322dc82" category="inline-link">SQL Server ： NetApp HCI を使用してデータベースのパフォーマンスを保証します</block>
  <block id="89447eb7454239e11376250fa04a88f7" category="inline-link">Windows 環境で clustered Data を使用して SAP と Microsoft SQL Server を運用 ONTAP</block>
  <block id="373f503ebd19225995680383c6e2d54a" category="summary">ビジネスアプリケーションとエンタープライズデータベース解決策に関する一連のブログ の機能</block>
  <block id="e4f724bc105592da045b6dd008770bbf" category="doc">ビジネスアプリケーションとエンタープライズデータベースブログ</block>
  <block id="034233dab82dddd28f950b8d4198499e" category="paragraph">ビジネスアプリケーションとエンタープライズデータベースソリューションの特定の機能を紹介するブログの概要。</block>
  <block id="8e90e89b52f60feebe2c0df72ca0f424" category="section-title">ビジネスアプリケーションブログ</block>
  <block id="9149421bcec7ca7e29560cd7fc83c4d0" category="section-title">エンタープライズデータベースブログ</block>
  <block id="506b02d257f89febd090ded6564e8c4f" category="summary">ネットアップのソリューションに新たに追加された自動化機能</block>
  <block id="3d45b043c5518eca1e47fb4ba8a813da" category="inline-link-macro">RHEL に CLI を導入するための Ansible Control Node をセットアップします /CentOS</block>
  <block id="0d4c9e63678641d4ae0e23bd36684722" category="list-text"><block ref="0d4c9e63678641d4ae0e23bd36684722" category="inline-link-macro-rx"></block></block>
  <block id="2afb5cc3404c6c8162722fd41895c2de" category="inline-link-macro">Ubuntu で CLI 環境に Ansible Control Node をセットアップします /Debian</block>
  <block id="0f752948a660f9bbb5956c86d669a395" category="list-text"><block ref="0f752948a660f9bbb5956c86d669a395" category="inline-link-macro-rx"></block></block>
  <block id="6b8c64be0bad88fb867c6576ac777b25" category="inline-link-macro">タワー / AWX 環境用の Ansible タワーまたは AWX をセットアップします</block>
  <block id="b8c65aa5893cb554f17ec9c5b653c9bc" category="list-text"><block ref="b8c65aa5893cb554f17ec9c5b653c9bc" category="inline-link-macro-rx"></block></block>
  <block id="61133eed21544af8c4988e345e562ce0" category="summary">データ保護とセキュリティに関する一連のビデオとデモ 解決策の機能</block>
  <block id="80a9ba2a1f85a5cf26d01122fd696973" category="doc">データ保護とセキュリティのビデオとデモ</block>
  <block id="ea233cf80b43de3a730e01b8e376a9bd" category="paragraph">データ保護およびセキュリティソリューションの特定の機能を紹介するビデオとデモの概要。</block>
  <block id="b9332d9812fee56d4f22fd8f245323a9" category="section-title">デモ / ビデオ</block>
  <block id="ec9f29e2bd26bf4a641b2964f3e3cf52" category="summary">ネットアップのソリューションの自動化機能に関する一連のブログ</block>
  <block id="6d64ee49cfa68e79b6fc189f1f83eef9" category="doc">解決策自動化ブログ</block>
  <block id="6380d01fb740985eb6892589e7579224" category="paragraph">ネットアップのソリューション固有の自動化機能を紹介するブログの概要を参照できます。</block>
  <block id="8893b40d0413bdee0d28539b7201b89c" category="summary">AI と最新データに関する一連のビデオとデモ Analytics 解決策の機能</block>
  <block id="d14e8dc770c2ede214d6db5eeb5d5167" category="doc">AI と最新のデータ分析のビデオとデモ</block>
  <block id="4696a661acac2c10910848bfebf30d2d" category="paragraph">AI ソリューションと最新のデータ分析ソリューションの特定の機能を紹介するビデオとデモの概要</block>
  <block id="bd86b07883a3c2983a874d3a11359cde" category="section-title">YouTube のデモ / ビデオ</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="inline-link">ネットアップの AI ソリューション</block>
  <block id="f4016f882c8544b575d00a8cb6a17809" category="list-text"><block ref="f4016f882c8544b575d00a8cb6a17809" category="inline-link-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link">MLOps の 1 つです</block>
  <block id="7cd0e3a75573824e7933841074476cbe" category="list-text"><block ref="7cd0e3a75573824e7933841074476cbe" category="inline-link-rx"></block></block>
  <block id="fcf140abed196b8eba71c45f21312bce" category="doc">ネットアップのソリューション</block>
  <block id="c6aaad7e04b9605d83a2a2aa661fc1b4" category="summary">ネットアップの VDS を使用して、管理者はタスクを他のユーザに委譲できます。導入したサーバに接続して、トラブルシューティングを行ったり、ログを表示したり、監査レポートを実行したりできます。お客様をサポートしながら、ヘルプデスクまたはレベル 3 の技術者は、ユーザセッションのシャドウイング、プロセスリストの表示、必要に応じたプロセスの強制終了を行うことができます。</block>
  <block id="3a1e041969ddc2d8e0e399260d9159a7" category="doc">Login VSI を使用した単一サーバの負荷テスト</block>
  <block id="12d80b6f529069c8b2bc8d45947a0379" category="paragraph">NetApp Virtual Desktop Service は、 Microsoft Remote Desktop Protocol を使用して仮想デスクトップのセッションとアプリケーションにアクセスし、 Login VSI ツールは特定のサーバモデルでホストできるユーザの最大数を決定します。Login VSI は、特定の間隔でのユーザログインをシミュレートし、ドキュメントのオープン、メールの読み書き、 Excel および PowerPoint での作業、ドキュメントの印刷、ファイルの圧縮、ランダムな切断などのユーザ操作を実行します。その後、応答時間を測定します。サーバの使用率が低い場合はユーザの応答時間が短く、ユーザセッションが追加されると応答時間が長くなります。Login VSI は、初回のユーザログインセッションに基づいてベースラインを決定し、ベースラインからのユーザ応答が 2 秒を超えると最大ユーザセッション数を報告します。</block>
  <block id="481e9968651d6bd0d36d67a776a0f32a" category="paragraph">次の表に、この検証で使用したハードウェアを示します。</block>
  <block id="e93f994f01c537c4e2f7d8528c3eb5e9" category="cell">カウント</block>
  <block id="8417ade953d75aa6fa3c64813e005e17" category="cell">NetApp HCI H610C</block>
  <block id="ec1d568aa57f1e1231acef5759640fc6" category="cell">ランチャー、 AD 、 DHCP など用のクラスタ内に 3 つ1 台のサーバで負荷テストを実施します。</block>
  <block id="5b68b81817d64cfa84c65e2e185efe97" category="cell">NetApp HCI H615C</block>
  <block id="c36af9ab64be0b8bd4d5097f58b8a5ba" category="cell">2x24C Intel Xeon Gold 6282 @ 2.1GHz 。1.5TB の RAM 。</block>
  <block id="825c03a9f78635bec804883dde1bd6bf" category="paragraph">次の表に、この検証に使用するソフトウェアを示します。</block>
  <block id="f5bf48aa40cad7891eb709fcf1fde128" category="cell">プロダクト</block>
  <block id="f80ee94fe4a9c10f8d85e442e7521687" category="cell">NetApp VDS 5.4</block>
  <block id="d9cc1f843ea62c12a3e59afbbdc2f9ce" category="cell">オーケストレーション</block>
  <block id="bb15f84d3b96a9b33719b8a71bc62207" category="cell">VM テンプレート Windows 2019 1809</block>
  <block id="f6a3c0d463e2ae697b02a9893e2062a3" category="cell">RDSH のためのサーバ OS</block>
  <block id="5a264c4e5b7b75d4ead67bf3ff7988bc" category="cell">Login VSI</block>
  <block id="5227da0541209a94c7dc0a07cf3e0740" category="cell">4.1.32.1</block>
  <block id="123995603a5e237810bf85a8e3c73f2e" category="cell">VMware vSphere 6.7 Update 3</block>
  <block id="2752fcc90cb7cc7439b827d762e89166" category="cell">VMware vCenter 6.7 Update 3F</block>
  <block id="436bc441be68b676a199df5c1ea02263" category="cell">VMware 管理ツール</block>
  <block id="9ad541af6dac1be0c6655522128a386c" category="paragraph">Login VSI のテスト結果は次のとおりです。</block>
  <block id="17126aef3e415713552604218f448967" category="cell">VM の設定</block>
  <block id="084abcce930cefa047af15fc0836639a" category="cell">Login VSI のベースライン</block>
  <block id="8bb9799dff9f679e2305879f7dc1a9f0" category="cell">Login VSI の最大値</block>
  <block id="e49775052ecbe49b489c84d0b09e916e" category="cell">H610C</block>
  <block id="a9cc7da7b66d8162a44a176bb1109440" category="cell">vCPU 8 基、 48GB RAM 、 75GB ディスク、 8Q vGPU プロファイル</block>
  <block id="28267ab848bcf807b2ed53c3a8f8fc8a" category="cell">799</block>
  <block id="8f85517967795eeef66c225f7883bdcb" category="cell">178</block>
  <block id="bd40934d28717a37aa4087f1622d8f0b" category="cell">H615C</block>
  <block id="4052d2c7017812dc33333a4dc7e83dc9" category="cell">vCPU × 12 、 128GB の RAM 、 75GB のディスク</block>
  <block id="eefc9e10ebdc4a2333b42b2dbb8f27b6" category="cell">763.</block>
  <block id="7a614fd06c325499f1680b9896beedeb" category="cell">272</block>
  <block id="71c62dd6d64bb960471819c829a777fd" category="paragraph">NUMA サブ境界およびハイパースレッディングを考慮すると、 VM のテストと構成用に選択される 8 つの VM は、ホストで使用可能なコアによって異なります。</block>
  <block id="0f57e9c52f3aa2d44da0de48ac87443a" category="paragraph">H610C では 10 台のランチャー VM を使用し、 RDP プロトコルを使用してユーザセッションに接続しました。次の図は、 Login VSI の接続情報を示しています。</block>
  <block id="ad1351ac01d5fe0ac5546c8a2fd2d170" category="paragraph"><block ref="ad1351ac01d5fe0ac5546c8a2fd2d170" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dba4e8b5ffc06c0ccce673fd6f48159" category="paragraph">次の図は、 H610C の Login VSI の応答時間とアクティブなセッションを示しています。</block>
  <block id="8d58d21e6be9e4be37d3c42935a380b5" category="paragraph"><block ref="8d58d21e6be9e4be37d3c42935a380b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72cce33d21386089f9a521f893c14d41" category="paragraph"><block ref="72cce33d21386089f9a521f893c14d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d64755ae2a4094876fbaf88a161ddec2" category="paragraph"><block ref="d64755ae2a4094876fbaf88a161ddec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ab628831ed501803e9da2a64f12dd6e" category="inline-link-macro">次のページ：管理ポータル</block>
  <block id="20fcc4e371ed448b0d5ffee3f4aecb43" category="paragraph"><block ref="20fcc4e371ed448b0d5ffee3f4aecb43" category="inline-link-macro-rx"></block></block>
  <block id="0ccea8702c360d2d159b0e8477fe81d6" category="summary">H610C または H615C を使用している場合、 GPU のライセンスはライセンスの再販権を持つ NVIDIA パートナーから購入する必要があります。</block>
  <block id="1f26c520bd4eba393348dedea38da7b7" category="doc">NVIDIA ライセンス</block>
  <block id="b548ee560d6fa4ee980d777df0300d09" category="inline-link">パートナー検索機能</block>
  <block id="72d760f4e8266e660fa7126e42f63bbe" category="paragraph">H610C または H615C を使用している場合、 GPU のライセンスはライセンスの再販権を持つ NVIDIA パートナーから購入する必要があります。NVIDIA パートナーは、で検索できます<block ref="32da44153625c96a28e5bf10161bbc42" category="inline-link-rx"></block>。仮想 GPU （ vGPU ）や Tesla などで検索してください。</block>
  <block id="7709fb92e99b3458d440c5212792a0de" category="paragraph">NVIDIA vGPU ソフトウェアには、次の 4 つのエディションがあります。</block>
  <block id="31473f257c4cfabfcba0c506fefcf4ca" category="list-text">NVIDIA GRID Virtual PC （ GRID vPC ）</block>
  <block id="75cc5be2167cc23ca9d32aa78a164907" category="list-text">NVIDIA GRID 仮想アプリケーション（ GRID vApps ）</block>
  <block id="53b933a69a5adecaa6c8c8817d2d87a5" category="list-text">NVIDIA Quadro Virtual Data Center Workstation （ Quadro vDWS ）</block>
  <block id="2d655109b3aad5a539482617b4aa3b6b" category="list-text">NVIDIA Virtual ComputeServer （ vComputeServer ）</block>
  <block id="38f26d9fb2d58dd577140e84010a059d" category="section-title">GRID Virtual PC の場合</block>
  <block id="e43876de331b666ca7fd1c7bbb8a844d" category="paragraph">この製品は、 Microsoft Windows アプリケーション、ブラウザ、高解像度ビデオ、およびマルチモニタのサポートに優れたユーザエクスペリエンスを提供する仮想デスクトップを必要とするユーザに最適です。NVIDIA GRID Virtual PC は仮想環境でネイティブエクスペリエンスを実現し、すべての PC アプリケーションをフルパフォーマンスで実行できます。</block>
  <block id="06a4851adc711a27ef53d0577d69e210" category="section-title">Grid 仮想アプリケーション</block>
  <block id="2c20bf668630521a8f76995b0c04c398" category="paragraph">GRID vApps は、リモートデスクトップセッションホスト（ RDSH ）またはその他のアプリケーションストリーミングやセッションベースのソリューションを導入する組織向けの製品です。Microsoft Windows アプリケーションをフルパフォーマンスで実行できるように設計された Windows Server ホスト型の RDSH デスクトップも、 GRID vApps でサポートされています。</block>
  <block id="5de115addc6579e1d30075a2a92c9ae7" category="section-title">Quadro Virtual Data Center Workstation の略</block>
  <block id="74fec534073fb87750193748093ada5a" category="paragraph">このエディションは、 Dassault CATIA 、 SOLIDWORKS 、 3Dexite 、 Siemens NX 、 PTC Creo などの強力な 3D コンテンツ作成アプリケーションを使用するメインストリームおよびハイエンドのデザイナーに最適です。 Schlumberger Petrel または Autodesk Maya 。NVIDIA Quadro vDWS を使用すると、すべてのデバイスのすべての機能とパフォーマンスを使用して、プロフェッショナルなグラフィックスアプリケーションにアクセスできます。</block>
  <block id="fb5cc5533386fd1b00e6b986dec8cba1" category="section-title">NVIDIA Virtual ComputeServer のこと</block>
  <block id="087877c8284ea313c79d65cb22d48329" category="paragraph">多くの組織が、人工知能（ AI ）、ディープラーニング（ DL ）、データサイエンスなど、コンピューティング負荷の高いサーバワークロードを実行しています。このようなユースケースでは、 NVIDIA vComputeServer ソフトウェアが NVIDIA GPU を仮想化することで、エラー修正コード、ページのリタイアメント、 NVLink 経由のピアツーピア、マルチ vGPU などの機能を使用して、コンピューティング負荷の高いサーバワークロードを高速化します。</block>
  <block id="e1f54ed77362f191ac08c4db8d9c44cd" category="admonition">Quadro vDWS ライセンスで GRID vPC と NVIDIA vComputeServer を使用できます。</block>
  <block id="d685cba160011e42327272678904bcbc" category="inline-link-macro">次の手順：導入</block>
  <block id="fed95bc65003dcb3d5ee273e3926bb25" category="paragraph"><block ref="fed95bc65003dcb3d5ee273e3926bb25" category="inline-link-macro-rx"></block></block>
  <block id="56b4cb3c337694fdafc2164dddad87fa" category="summary">GPU は通常、反復演算を実行することでグラフィック表示（レンダリング）に使用されます。この反復的なコンピューティング機能は、多くの場合、 AI やディープラーニングのユースケースに使用されます。</block>
  <block id="1b31ca8ddb749644af37aa10b42e6930" category="doc">GPU に関する考慮事項</block>
  <block id="ceeb28ce3b9ce753f02856fffb7ba66c" category="paragraph">グラフィックを多用するアプリケーションの場合、 Microsoft Azure では、 NVIDIA Tesla M60 カードをベースとした NV シリーズを提供しており、 VM ごとに 1 ~ 4 個の GPU を搭載しています。それぞれの NVIDIA Tesla M60 カードには、 Maxwell ベースの GPU が 2 つ搭載されており、それぞれ 8GB の GDDR5 メモリを搭載しているため、合計 16GB になります。</block>
  <block id="cb433c3099845f0ac8f3ba53d162db7b" category="admonition">NVIDIA ライセンスは NV シリーズに含まれています。</block>
  <block id="0f0c98cc175dc7cda319a35afcd199e5" category="paragraph"><block ref="0f0c98cc175dc7cda319a35afcd199e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ead26a90008a32871b53cb37bbe8431a" category="paragraph">NetApp HCI を使用した H615C GPU には、 NVIDIA Tesla T4 カードが 3 枚搭載されています。各 NVIDIA Tesla T4 カードには、 16GB の GDDR6 メモリを搭載した Touring ベースの GPU が搭載されています。VMware vSphere 環境で使用する場合、仮想マシンは GPU を共有でき、各 VM は専用のフレームバッファメモリを使用します。NetApp HCI H615C 上の GPU では、光線トレースを含めたリアルな画像を作成するために、レイトレーシングを使用できます。GPU 機能のライセンスがある NVIDIA ライセンスサーバが必要です。</block>
  <block id="148811d448421f6a42c549400b7201c0" category="paragraph"><block ref="148811d448421f6a42c549400b7201c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc6992cca0b3d14a85c456d0890f3e37" category="paragraph">GPU を使用するには、適切なドライバをインストールする必要があります。ドライバは NVIDIA ライセンスポータルからダウンロードできます。Azure 環境では、 NVIDIA ドライバを GPU ドライバ拡張機能として使用できます。次に、次のスクリーンショットに示すグループポリシーを更新して、リモートデスクトップサービスセッションに GPU ハードウェアを使用する必要があります。H.264 グラフィックスモードの優先順位を設定し、エンコーダ機能を有効にする必要があります。</block>
  <block id="5b0ff68b017720dd46aa6d1923fdfa95" category="paragraph"><block ref="5b0ff68b017720dd46aa6d1923fdfa95" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7d3d3d6dd94c69620cd3edfb005691c" category="paragraph">タスクマネージャを使用するか、 WebGL サンプルを実行する際に NVidia - SMI CLI を使用して、 GPU のパフォーマンス監視を検証します。GPU 、メモリ、エンコーダのリソースが消費されていることを確認します。</block>
  <block id="d13ca37d387c1bb473c0343278d0477d" category="paragraph"><block ref="d13ca37d387c1bb473c0343278d0477d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f2b53ac98ef55a900849ead654ca636" category="paragraph">仮想デスクトップサービスを搭載した NetApp HCI H615C に仮想マシンが導入されていることを確認するために、 H615C ホストを含む vCenter クラスタリソースを含むサイトを定義します。VM テンプレートには必要な vGPU プロファイルが接続されている必要があります。</block>
  <block id="818fad61fba48977b2293819f37e950a" category="paragraph">共有マルチセッション環境の場合は、複数の同種の vGPU プロファイルを割り当てることを検討してください。ただし、ハイエンドのプロフェッショナル向けグラフィックスアプリケーションの場合は、各 VM を特定のユーザ専用にして分離することを推奨します。</block>
  <block id="a2db30df8af33b0e661aaed00ce2c1d3" category="paragraph">GPU プロセッサは QoS ポリシーで制御でき、各 vGPU プロファイルには専用のフレームバッファを設定できます。ただし、エンコーダとデコーダはカードごとに共有されます。GPU カードへの vGPU プロファイルの配置は、 vSphere ホストの GPU 割り当てポリシーで制御されます。このポリシーでは、パフォーマンス（ VM を分散）や統合（ VM をグループ化）を強化できます。</block>
  <block id="53cf9d36e61cc97b118ae4cc9589bac3" category="summary">NetApp VDS Cloud Workspace Management Suite ポータルでは、オンプレミス、管理ユーザ、アプリケーションカタログ、スクリプト化イベント用のサイトを含むさまざまな VDS 環境を一元的に管理できます。このポータルは、必要に応じてアプリケーションを手動でプロビジョニングしたり、トラブルシューティングのためにマシンに接続したりするために、管理者ユーザーも使用します。</block>
  <block id="e68a6dedaba6faaba6e7afd9197edc4f" category="doc">管理ポータル</block>
  <block id="76368893e7696218fc60d77f96235f35" category="paragraph">NetApp VDS Cloud Workspace Management Suite ポータルを使用できます<block ref="1640f4040bca8395064a2ee51cb5f0ae" category="inline-link-rx"></block> また、今後のバージョンも提供される予定です<block ref="b6375c31f2253ef964d998b5762ba440" category="inline-link-rx"></block>。</block>
  <block id="02655da204b103696191f5d52c33427f" category="paragraph">このポータルでは、オンプレミス、管理ユーザ、アプリケーションカタログ、スクリプト化イベント用に定義されたサイトを含むさまざまな VDS 環境を一元管理できます。このポータルは、必要に応じてアプリケーションを手動でプロビジョニングしたり、トラブルシューティングのためにマシンに接続したりするために、管理者ユーザーも使用します。</block>
  <block id="0499b0532cd51452b57a028f3973d9fa" category="paragraph">サービスプロバイダは、このポータルを使用して独自のチャネルパートナーを追加し、自社のクライアントを管理できます。</block>
  <block id="8af19d014b76fa90ffc0c0477bd47be5" category="inline-link-macro">次の例は、ユーザ管理です</block>
  <block id="631d677d75a0b47f9fe24a201cc8cb85" category="paragraph"><block ref="631d677d75a0b47f9fe24a201cc8cb85" category="inline-link-macro-rx"></block></block>
  <block id="b5ed404fa434aeee227f550cddf89892" category="inline-link">NetApp クラウド</block>
  <block id="d823edbaf98641c5959f3a596de3df66" category="list-text"><block ref="d823edbaf98641c5959f3a596de3df66" category="inline-link-rx"></block></block>
  <block id="b1eb0510d1bc6ffab71faa53637ecde2" category="inline-link">NetApp VDS 製品ドキュメント</block>
  <block id="c5b41ed257411dffc1cc80a4c00cf17c" category="list-text"><block ref="c5b41ed257411dffc1cc80a4c00cf17c" category="inline-link-rx"></block></block>
  <block id="272427e7f4e6650df3749f83086acde6" category="inline-link">VPN ゲートウェイを使用してオンプレミスネットワークを Azure に接続できます</block>
  <block id="c460b4e40e6d4709ed15a2e8dba39833" category="list-text"><block ref="c460b4e40e6d4709ed15a2e8dba39833" category="inline-link-rx"></block></block>
  <block id="440e11297e8634c052b1bfd29a90309c" category="inline-link">Azure ポータル</block>
  <block id="8284aff5fcde6ba43a0ca21712739cae" category="list-text"><block ref="8284aff5fcde6ba43a0ca21712739cae" category="inline-link-rx"></block></block>
  <block id="8867b143d669949d3948e3816324ec75" category="inline-link">Microsoft Windows 仮想デスクトップ</block>
  <block id="0db816b3393ed224b26131285b4e3dff" category="list-text"><block ref="0db816b3393ed224b26131285b4e3dff" category="inline-link-rx"></block></block>
  <block id="7c033f9cfba6e06ff2ee6cb852ce10f4" category="inline-link">Azure NetApp Files 登録</block>
  <block id="aff481c4855a001492901fbefcab7d17" category="list-text"><block ref="aff481c4855a001492901fbefcab7d17" category="inline-link-rx"></block></block>
  <block id="4725a4744390b735ea1bb4e3fc99b686" category="section-title">ストレージノード</block>
  <block id="0f66538edca95cf4d42667cfa5d6a362" category="section-title">コンピューティングノード</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="section-title">NetApp AFF</block>
  <block id="568483e9bd85504f3c9dcef24ecd3235" category="doc">データ管理</block>
  <block id="24e6e2f6171b43a847fe194a9a9b5cd0" category="section-title">グローバルファイルキャッシュ</block>
  <block id="ce29b83c61cdf6a56b49dbde9a4d57e0" category="paragraph">グローバルネームスペース内の複数のサイトにユーザが分散している場合、グローバルファイルキャッシュを使用すると、頻繁にアクセスされるデータのレイテンシを低減できます。グローバルファイルキャッシュの導入は、プロビジョニングコレクションとスクリプト化されたイベントを使用して自動化できます。グローバルファイルキャッシュは、読み取りキャッシュと書き込みキャッシュをローカルで処理し、場所を問わずファイルのロックを維持します。グローバルファイルキャッシュは、 Azure NetApp Files を含む任意の SMB ファイルサーバと連携できます。</block>
  <block id="87db7a122a37ab4a28f2223fa123a5be" category="paragraph"><block ref="87db7a122a37ab4a28f2223fa123a5be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d726de6a27bb533c6c8c44ea508dffa8" category="paragraph">グローバルファイルキャッシュには次のものが必要です。</block>
  <block id="2f28046ff208122796d51bafd8d4bc9c" category="list-text">管理サーバ（ライセンス管理サーバ）</block>
  <block id="83168e6cb289d732cc78427b51f93153" category="list-text">コア</block>
  <block id="e7704357fe6a312ecafae725be93b8c2" category="list-text">データをキャッシュするための十分なディスク容量を備えたエッジ</block>
  <block id="d70c88e6a13ca1af40b966d8d7d831c4" category="inline-link">GFC のドキュメント</block>
  <block id="154c48fd725e7207d36baa74bba5fd7a" category="paragraph">ソフトウェアをダウンロードして、 Edge 用のディスクキャッシュ容量を計算するには、を参照してください<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>。</block>
  <block id="a51a182b58a11b12770fbd2bd9643852" category="paragraph"><block ref="a51a182b58a11b12770fbd2bd9643852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d666527802938c89b9f895300aea220b" category="paragraph">グローバルファイルキャッシュに使用するサービスアカウントを指定します。このアカウントに必要な権限については、を参照してください<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>。</block>
  <block id="ab698dd081619e8f6dc264df6c99b73e" category="paragraph"><block ref="ab698dd081619e8f6dc264df6c99b73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b1486d5cfb9e0c5394a50e2515b53c" category="paragraph">新しいバックエンドファイルサーバを追加し、ファイルサーバ名または IP を指定します。</block>
  <block id="ffeac1f6b14ca75f608539cb6c673f37" category="paragraph"><block ref="ffeac1f6b14ca75f608539cb6c673f37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="643c94b6eb5664ed3cca98d31d7dbd39" category="paragraph">エッジでは、キャッシュドライブのドライブ文字は D にする必要があります表示されない場合は、 diskpart.exe を使用してボリュームを選択し、ドライブレターを変更します。エッジとしてライセンスサーバーに登録します。</block>
  <block id="e9b41aa1ac49113064748a9c6e0f48a9" category="paragraph"><block ref="e9b41aa1ac49113064748a9c6e0f48a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="156666d997fd17a94bed67fe95334273" category="paragraph">コアの自動構成が有効になっている場合は、コア情報がライセンス管理サーバから自動的に取得されます。</block>
  <block id="891d862f33aaeafcd8ecc43e102febd3" category="paragraph"><block ref="891d862f33aaeafcd8ecc43e102febd3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a08e5ca253097ac5ad7741e20d9dd090" category="paragraph">管理者は、世界中のユーザーに透過的なアクセスを提供するために、ファイルサーバーの共有とエッジの場所を指すリンクを使用して、 Microsoft Distributed Filesystem (DFS) を設定できます。</block>
  <block id="0c9f570b7b5b34f0fbdab873e122d432" category="paragraph"><block ref="0c9f570b7b5b34f0fbdab873e122d432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9e8ad2bf50c8da3a637a8858d3a1391" category="paragraph">ユーザがサイトに関連付けられたサブネットに基づいて Active Directory クレデンシャルでログインすると、 DFS クライアントがデータにアクセスするために適切なリンクが使用されます。</block>
  <block id="6a6b2107f2b5daadfd13df04f769a587" category="paragraph"><block ref="6a6b2107f2b5daadfd13df04f769a587" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8aabec6a7d3f54b83478824808357c91" category="paragraph">ファイルアイコンは、ファイルがキャッシュされているかどうかに応じて変化します。キャッシュされていないファイルの場合は、アイコンの左下隅にグレーの X が表示されます。エッジの場所にいるユーザーがファイルにアクセスすると、そのファイルがキャッシュされ、アイコンが変化します。</block>
  <block id="1014b6d5d432758e9041c845e4da7830" category="paragraph"><block ref="1014b6d5d432758e9041c845e4da7830" category="inline-image-macro-rx" type="image"></block></block>
  <block id="610eee89db61eda57b4b6da39d799845" category="paragraph">ファイルが開いているときに、別のユーザーがエッジの場所から同じファイルを開こうとすると、次の選択を求めるプロンプトが表示されます。</block>
  <block id="5a31b6c180e91d3c3d3c1053bbab642c" category="paragraph"><block ref="5a31b6c180e91d3c3d3c1053bbab642c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c6f3b21447f91b42ceee404afc53720" category="paragraph">ユーザが元のコピーが使用可能になったときに通知を受け取るオプションを選択した場合、ユーザには次のように通知されます。</block>
  <block id="922c6f30fa0f74f32df2fac11a3bf378" category="paragraph"><block ref="922c6f30fa0f74f32df2fac11a3bf378" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b9bc3a03a8ae9cef2c5a66238e5ab25" category="inline-link">Talon と Azure NetApp Files の導入に関するビデオ</block>
  <block id="e725329a19c23f541a0bdbead9c9b1e7" category="paragraph">詳細については、を参照してください<block ref="92818ea025c5b78ace999366164c2c46" category="inline-link-rx"></block>。</block>
  <block id="fc95bd8bc19564339fe05c7bad1b7662" category="section-title">SaaS バックアップ</block>
  <block id="482cadbeebfa6f9c4f062c1f2724d546" category="paragraph">NetApp VDS は、 Exchange 、 SharePoint 、 Microsoft OneDrive など、 Salesforce と Microsoft Office 365 のデータ保護を提供します。次の図は、これらのデータサービス用に NetApp VDS で SaaS Backup を提供する方法を示しています。</block>
  <block id="0e3aff181138166393e5e5e698c994d2" category="paragraph"><block ref="0e3aff181138166393e5e5e698c994d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="201e09e85ad81db8a19ef9f20c05d1a5" category="inline-link">このビデオでは</block>
  <block id="4cde65566156674196c087d89ded5c3b" category="paragraph">Microsoft Office 365 のデータ保護のデモについては、を参照してください<block ref="158107d7e819a2ef8c2e8f24519fc9a9" category="inline-link-rx"></block>。</block>
  <block id="2cb2b89213bccd89f81cfbb17b2e070b" category="inline-link-macro">次：運用管理</block>
  <block id="1f3d3eae36241941c6f7a1eaf3615eac" category="paragraph"><block ref="1f3d3eae36241941c6f7a1eaf3615eac" category="inline-link-macro-rx"></block></block>
  <block id="7b0f97bc4856c6b0645650d13b53acb5" category="summary">オンプレミスのリソースとクラウドリソース間の接続が確立されていれば、 NetApp Virtual Desktop Service をオンプレミスに拡張できます。企業は、 Express Route またはサイト間 IPSec VPN 接続を使用して、 Microsoft Azure へのリンクを確立できます。専用リンクまたは IPsec VPN トンネルを使用して、他のクラウドへのリンクを同様の方法で作成することもできます。</block>
  <block id="995d0ae58fc48c0007c3a45046221736" category="doc">ハイブリッドクラウド環境</block>
  <block id="610e3513c7222cae8d2a7c450741211a" category="paragraph">解決策の検証では、次の図に示す環境を使用しました。</block>
  <block id="0d9e9a129d4eb3389af12248eb017ef1" category="paragraph"><block ref="0d9e9a129d4eb3389af12248eb017ef1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60ca94382604fd3deb8a198feed31f1b" category="paragraph">オンプレミスでは、管理ホスト、リモートデスクトップセッションホストなど用に複数の VLAN がありました。これらは 172.21.146-150.0/24 サブネット上にあり、 Microsoft Remote Routing Access Service を使用して企業ネットワークにルーティングされています。また、次のタスクも実行しました。</block>
  <block id="b613a58cb27d96b09550b74a616e43d8" category="list-text">Microsoft Routing and Remote Access Server （ RRAS ； IPchicken.com で識別）のパブリック IP に注目しました。</block>
  <block id="b0aa9d967a62cfeb9427c31c3968fb31" category="list-text">Azure サブスクリプション上に Virtual Network Gateway リソース（ルートベースの VPN ）を作成しました。</block>
  <block id="2db3e884a3b1d82162c06df081b8e8f0" category="list-text">Microsoft RRAS サーバーのパブリック IP のローカルネットワークゲートウェイアドレスを提供する接続を作成しました。</block>
  <block id="ac7b5e31749488bdca809cc69e83bcec" category="list-text">RRAS で VPN 設定を完了し、 VPN ゲートウェイの作成時に提供された事前共有認証を使用して仮想インターフェイスを作成しました。正しく設定されている場合、 VPN は Connected 状態になっている必要があります。Microsoft RRAS の代わりに、 pfSense などの関連ツールを使用して、サイト間 IPsec VPN トンネルを作成することもできます。トンネルはルートベースであるため、設定された特定のサブネットに基づいてトラフィックをリダイレクトします。</block>
  <block id="064b2713bd54ad7c04715d629ea8d77e" category="paragraph">Microsoft Azure Active Directory は、 OAuth に基づいて ID 認証を提供します。通常、エンタープライズクライアント認証には、 NTLM または Kerberos ベースの認証が必要です。Microsoft Azure Active Directory ドメインサービスは、 ADConnect を使用して、 Azure Active Directory とオンプレミスのドメインコントローラ間でパスワードハッシュの同期を実行します。</block>
  <block id="c9ced395d02e614104c13dc687b8d960" category="paragraph">今回のハイブリッド VDS 解決策の検証では、最初に Microsoft Azure に導入し、 vSphere で追加のサイトを追加しました。このアプローチの長所は、プラットフォームサービスが Microsoft Azure に導入され、ポータルを使用してすぐにバックアップできることです。サイト間 VPN リンクがダウンしている場合でも、サービスにはどこからでも簡単にアクセスできます。</block>
  <block id="759e5787427ba679d146727a04400c46" category="paragraph">別のサイトを追加するには、 DCConfig というツールを使用しました。このアプリケーションへのショートカットは、 Cloud Workspace Manager （ CWMgr ） VM のデスクトップで使用できます。このアプリケーションを起動したら、 [ データセンターサイト ] タブに移動し、新しいデータセンターサイトを追加して、必要な情報を次のように入力します。URL は vCenter IP を示します。設定を追加する前に、 CWMgr VM が vCenter と通信できることを確認してください。</block>
  <block id="ae5bd963078c278284e2aabaefb99232" category="admonition">VMware vSphere 環境との通信を有効にするために、 CloudWorkspace マネージャーの vSphere PowerCLI 5.1 がインストールされていることを確認します。</block>
  <block id="e0072a2f037098ba3ee9ec9e1113f1ee" category="paragraph">次の図は、オンプレミスのデータセンターサイトの構成を示しています。</block>
  <block id="30efb5f8dd999c0f737bf30327346d6f" category="paragraph"><block ref="30efb5f8dd999c0f737bf30327346d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f823fddfaa31c0b2b910c651849fe1e0" category="paragraph">コンピューティングリソースには、特定のクラスタ、ホスト名、または空き RAM スペースに基づくフィルタリングオプションが用意されています。ストレージリソースのフィルタリングオプションには、データストア上の最小空きスペースまたはデータストアあたりの最大 VM 数が含まれます。データストアは、正規表現を使用して除外できます。[Save] ボタンをクリックして、設定を保存します。</block>
  <block id="40cf95c01dfbdb8adc110507697330bf" category="paragraph">設定を検証するには、 Test ボタンをクリックするか、 Load Hypervisor をクリックし、 vSphere セクションのドロップダウンを確認します。適切な値が入力されている必要があります。プライマリハイパーバイザーは、デフォルトのプロビジョニングサイトで yes に設定しておくことを推奨します。</block>
  <block id="b081b97ab471a870119bb85e196c0d63" category="paragraph">VMware vSphere で作成された VM テンプレートは、 VDS でプロビジョニングコレクションとして使用されます。プロビジョニング収集には、共有と VDI の 2 つの形式があります。共有プロビジョニングコレクションタイプは、すべてのサーバに 1 つのリソースポリシーが適用されるリモートデスクトップサービスに使用されます。VDI タイプは、リソースポリシーが個別に割り当てられている WVD インスタンスに使用されます。Provisioning Collection 内のサーバには、次の 3 つのロールのいずれかを割り当てることができます。</block>
  <block id="9a0b479d2d7eaed435c14e20818841d9" category="list-text">*TSDATA/* ターミナルサービスとデータサーバの役割の組み合わせ。</block>
  <block id="286b69ba39f77189135fbf4c39786e12" category="list-text">*TS.* ターミナルサービス ( セッションホスト )</block>
  <block id="0b39ab3df8d28606b4bb8f5891022692" category="list-text">* data.* ファイルサーバーまたはデータベースサーバー。サーバロールを定義する際には、 VM テンプレートとストレージ（データストア）を選択する必要があります。選択できるデータストアは特定のデータストアに制限することも、データの使用量に基づいてデータストアが選択される最も使用率の低いオプションを使用することもできます。</block>
  <block id="fb89cc64fafb0e1626269bc00c07ae73" category="paragraph">各導入環境では、アクティブユーザ、固定、サーバ負荷、またはユーザ数に基づいて、クラウドリソース割り当ての VM リソースがデフォルトで設定されます。</block>
  <block id="d00f03f39f8119980cb5240353d345b1" category="inline-link-macro">次のセクションでは、 Login VSI での単一サーバの負荷テストについて説明します</block>
  <block id="af5c949297d5415f4710bd1af3f1e7a7" category="paragraph"><block ref="af5c949297d5415f4710bd1af3f1e7a7" category="inline-link-macro-rx"></block></block>
  <block id="18dbdef148da0fb68861cf1b6aeeeb40" category="summary">NetApp VDS を使用したハイブリッド VDI により、サービスプロバイダとエンタープライズ仮想デスクトップ管理者は、ユーザに影響を与えることなく、簡単にリソースを他のクラウド環境に拡張できます。NetApp HCI 上にオンプレミスリソースを配置すると、 GPU リソースをより細かく制御でき、コンピューティングノードやストレージノードをオンデマンドで拡張できます。</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">この解決策環境のユースケースは次のとおりです。</block>
  <block id="f9bfa55b1c8ab8884a1452fa3c9cb975" category="list-text">クラウドにバーストして、リモートの需要急増に対応します デスクトップとアプリケーション</block>
  <block id="6b53dc409ecc50a533e93345ddf1f2ee" category="list-text">長時間のリモートデスクトップおよびアプリケーションの運用における TCO を削減 フラッシュストレージと GPU リソースをオンプレミスでホストできます</block>
  <block id="f1de7e15d0b0c3caaafa1a47204338c7" category="list-text">クラウド全体にわたるリモートデスクトップとアプリケーションの管理が容易 環境</block>
  <block id="f9ce5b54f5428c82364a39f17156cc4f" category="list-text">ソフトウェアサービスを使用して、リモートデスクトップとリモートアプリケーションを体験できます オンプレミスのリソースを使用するモデル</block>
  <block id="675ee473db5bbe3911c19a4e43f8ec3f" category="list-text">の要件を理解したい EUC / VDI アーキテクト ハイブリッド VDS</block>
  <block id="a7f381741a2ff77b61bc4b7bc2e3d04f" category="list-text">ネットアップのパートナーが、お客様の支援を希望しています リモートデスクトップとアプリケーションのニーズ</block>
  <block id="efa648658230830c2b9ac1a0647002d7" category="list-text">リモートデスクトップに対応したい既存の NetApp HCI ユーザ アプリケーションのニーズも高まります</block>
  <block id="2fa4089eb34d18d2b64eaab8eed9692d" category="inline-link-macro">次のページ： NetApp Virtual Desktop Service の概要</block>
  <block id="bf817f81e35d1d9f2620def86f22dcc3" category="paragraph"><block ref="bf817f81e35d1d9f2620def86f22dcc3" category="inline-link-macro-rx"></block></block>
  <block id="b4f83b03956523a39e8bbbd0895f0f29" category="section-title">Cloud Insights の機能です</block>
  <block id="52f9ec21735243ad9917cda3ca077d32" category="section-title">GPU</block>
  <block id="3d564c1c20cf4265a5094ead9dc937f6" category="paragraph">ネットアップ Suresh Thoppay</block>
  <block id="64241e0b33fb869cb12ff8e1ec74f806" category="summary">NetApp VDS では、 ID 認証に Azure Active Directory 、 NTLM / Kerberos 認証に Azure Active Directory ドメインサービスを使用します。ADConnect ツールを使用すると、オンプレミスの Active Directory ドメインを Azure Active Directory と同期できます。</block>
  <block id="92726ab5faeb2cb9208eaac9af0346bd" category="doc">ユーザ管理</block>
  <block id="c758de7e1477d6707c6709441d41a5e9" category="paragraph">ポータルから新しいユーザを追加することも、既存のユーザに対してクラウドワークスペースを有効にすることもできます。ワークスペースとアプリケーションサービスの権限は、個々のユーザまたはグループによって制御できます。管理ポータルでは、ポータルやワークスペースなどの権限を制御する管理ユーザを定義できます。</block>
  <block id="b1bb3db86aec5efef6f7cc0d0d7c6331" category="paragraph">次の図は、 NetApp VDS のユーザ管理を示しています。</block>
  <block id="ed5018356119de97fa1ab09c0eeab65a" category="paragraph"><block ref="ed5018356119de97fa1ab09c0eeab65a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1350c851c78a6cdb31c6fe46ddb499c2" category="paragraph">各ワークスペースは、次の図に示すように、 Cloud Workspace OU の下にある専用の Active Directory 組織単位（ OU ）に存在します。</block>
  <block id="a5484d6de39aa020af1aa382d6d52c5e" category="paragraph"><block ref="a5484d6de39aa020af1aa382d6d52c5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3fad2f68853fae9ef870ed5535896790" category="paragraph">詳細については、を参照してください<block ref="b5d59c719b42a4e7d2b711482aa2f54d" category="inline-link-rx"></block> NetApp VDS のユーザ権限とユーザ管理。</block>
  <block id="48a8649f1ce9d97848d70480ce7fea9c" category="paragraph">データセンターの API 呼び出しを使用して Active Directory グループを CRAUserGroup として定義すると、そのグループ内のすべてのユーザーが、 UI を使用して管理するために CloudWorkspace にインポートされます。クラウドワークスペースがユーザに対して有効になっている場合、 VDS はユーザのホームフォルダ、設定権限、ユーザプロパティの更新などを作成します。</block>
  <block id="9e30d1bf5e5278a123ad0ddab43066b7" category="paragraph">VDI ユーザー使用可能を選択した場合、 VDS はそのユーザー専用のシングルセッション RDS マシンを作成します。プロビジョニングするテンプレートとデータストアを指定するよう求められます。</block>
  <block id="093d2ddf98cacaf853b6f986ca9bd647" category="paragraph"><block ref="093d2ddf98cacaf853b6f986ca9bd647" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46bccf4889fab263d6edc63e631883a7" category="inline-link-macro">次の手順：ワークスペース管理</block>
  <block id="e98fdb0b8697a2cf005527be51872d0d" category="paragraph"><block ref="e98fdb0b8697a2cf005527be51872d0d" category="inline-link-macro-rx"></block></block>
  <block id="57eae0e26c1c0bbaec9110d010f68f7a" category="summary">NetApp HCI は、ストレージノードとコンピューティングノードが混在するハイブリッドクラウドインフラです。モデルに応じて、 2 ラックユニットまたはシングルラックユニットのいずれかとして使用できます。VM の導入に必要なインストールと設定は、 NetApp Deployment Engine （ NDE ）で自動化されています。コンピューティングクラスタは VMware vCenter で管理され、ストレージクラスタは NDE で導入された vCenter Plug-in で管理されます。</block>
  <block id="855faa205a8f23993f1a0fe1ac2cde2f" category="doc">NetApp HCI の概要</block>
  <block id="b6ab683d50d83f639ae697569117a54b" category="paragraph">NetApp HCI は次の機能を処理します。</block>
  <block id="d15278d453245d004f8fd55cff421171" category="list-text">バージョンのアップグレード</block>
  <block id="b783caf332f2c3190dcb6ced64290f5a" category="list-text">イベントを vCenter にプッシュしています</block>
  <block id="79adeb760f6909dd746e1e7adae6cd58" category="list-text">vCenter Plug-in の管理</block>
  <block id="a45e04274259a13dff2a10641a0fd97f" category="list-text">サポート用の VPN トンネル</block>
  <block id="227590ca6f7ff3f3cc72e49cf277625f" category="list-text">NetApp Active IQ コレクタ</block>
  <block id="b0088ee645cccd0951013eb53d0b3816" category="list-text">NetApp クラウドサービスをオンプレミスに拡張し、ハイブリッドクラウドインフラを実現次の図は、 HCI のコンポーネントを示しています。</block>
  <block id="1a811712e3bea62b6f5bd1851b149fc3" category="paragraph"><block ref="1a811712e3bea62b6f5bd1851b149fc3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65f0d96af236e344bd739fd20df1fa5d" category="paragraph">ストレージノードは、半幅または全幅サイズのラックユニットとして使用できます。ストレージノードは最低 4 つ必要で、クラスタは最大 40 ノードまで拡張できます。ストレージクラスタは、複数のコンピューティングクラスタ間で共有できます。すべてのストレージノードには、書き込みパフォーマンスを向上させるためにキャッシュコントローラが搭載されています。1 つのノードで、 4K ブロックサイズで 5 万または 10 万 IOPS を実現します。</block>
  <block id="d31f04e865057f7055f2d8287b92ba2d" category="paragraph">NetApp HCI ストレージノードでは、最小、最大、バーストの QoS 制限を定めた NetApp Element ソフトウェアが実行されます。ストレージクラスタにはタイプの異なるストレージノードを混在させることができますが、 1 つのストレージノードの容量は合計容量の 1/3 以下にする必要があります。</block>
  <block id="bc1a52314ab38efacf0a83e9df0b01cc" category="paragraph">コンピューティングノードには、半幅、全幅、 2 ラックサイズのラックユニットを使用できます。NetApp HCI H410C と H610C には拡張性に優れた Intel Skylake プロセッサが採用されています。H615C には、拡張性に優れた第 2 世代 Intel Cascade Lake プロセッサが搭載されています。GPU を搭載したコンピューティングモデルは 2 つあります。 H610C は NVIDIA M10 カードを 2 基、 H615C は NVIDIA T4 カードを 3 基搭載しています。</block>
  <block id="683876986e8fe1045fa768b4a8675ea9" category="paragraph"><block ref="683876986e8fe1045fa768b4a8675ea9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9667ae1b4be7e4c088e175844fd675e6" category="paragraph">NVIDIA T4 には RT コアが 40 基搭載されており、リアルタイムレイトレーシングに必要なコンピューティング能力を提供します。デザイナーやエンジニアと同じサーバモデルをアーティストが使用して、水面に反射する光を現実のように表現したリアルな画像を作成できるようになりました。この RTX 対応 GPU は、毎秒最大 5 ギガレイのリアルタイムレイトレーシングパフォーマンスを実現します。NVIDIA T4 を Quadro Virtual Data Center Workstation （ Quadro vDWS ）ソフトウェアと組み合わせて使用することで、アーティストは影、反射、屈折を正確に再現した、写真のようにリアルなデザインをあらゆる場所のすべてのデバイス上に作成できます。</block>
  <block id="bee5034948808ff859affdc8ba03b52c" category="paragraph">Tensor コアは、ディープラーニング推論ワークロードの実行を可能にします。これらのワークロードを実行している場合、 Quadro vDWS を搭載した NVIDIA T4 のパフォーマンスは、 CPU のみのサーバを搭載した VM の最大 25 倍です。1 ラックユニットに NVIDIA T4 カードを 3 基搭載した NetApp H615C は、グラフィックスとコンピューティングの負荷の高いワークロードに最適な解決策です。</block>
  <block id="1f99f286804bf2f5a91a1cdd1733decf" category="paragraph">次の図に、 NVIDIA GPU カードとその機能の比較を示します。</block>
  <block id="67c0c3f98979352a9ed10f0de3d551f3" category="paragraph"><block ref="67c0c3f98979352a9ed10f0de3d551f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b4fc2931642829391b479ea5fb1e9d" category="paragraph">M10 GPU は、現在でもナレッジワーカーのユースケースに最適な TCO 解決策です。ただし、仮想ワークステーション、グラフィックスパフォーマンス、リアルタイムのインタラクティブレンダリング、推論など、さまざまなユースケースに使用できる GPU での標準化を希望する場合には、 T4 が最良の代替ソリューションです。T4 では、同じ GPU リソースを使用して異なるワークロードを実行できます。たとえば、日中は VDI を実行し、同じリソースを使用して夜間にコンピューティングワークロードを実行できます。</block>
  <block id="fe046fc197d12a64da1ea78423a2a809" category="paragraph">コンピューティングクラスタ内のノード数は VMware によって決まります。現在は VMware vSphere 7.0 Update 1 で 96 です。Enhanced vMotion Compatibility （ EVC ）が有効な場合、クラスタ内に異なるモデルのコンピューティングノードを混在させることができます。</block>
  <block id="f0bee2b90db3a99440b1a724c49ce1a2" category="inline-link-macro">次は NVIDIA ライセンスです</block>
  <block id="e0bca2831f4cccfcaebc75e9555a1719" category="paragraph"><block ref="e0bca2831f4cccfcaebc75e9555a1719" category="inline-link-macro-rx"></block></block>
  <block id="868ab86f19065016e9a2f077c5ec1ede" category="summary">タスクワーカーは、利用可能なアプリケーションのリストからアプリケーションをすばやく起動できます。アプリケーションサービスは、リモートデスクトップサービスセッションホストからアプリケーションをパブリッシュします。WVD を使用すると、アプリケーショングループは、複数セッションの Windows 10 ホストプールから同様の機能を提供します。</block>
  <block id="aa08bd8b0522ea3a5e9ace598db7162c" category="doc">アプリケーション管理</block>
  <block id="f83a66a518ff3f3f44725a09d9666710" category="paragraph">オフィスワーカーがユーザに給電する場合は、サービスボードを使用して手動でプロビジョニングするか、または NetApp VDS のスクリプト化されたイベント機能を使用して自動でプロビジョニングすることができます。</block>
  <block id="546d3f7d3bb8a664a6ba4a3fb2f68c30" category="inline-link">ネットアップのアプリケーション使用資格ページ</block>
  <block id="175ba74f5b7d0ecd3f531c5fce21a240" category="paragraph">詳細については、を参照してください<block ref="03e02ecfc967e94041a86f599e14ac44" category="inline-link-rx"></block>。</block>
  <block id="ba5e495048f0fa35302184aa505386a9" category="inline-link-macro">次のステップ：データ管理</block>
  <block id="51688bc4609022e20e8c1cb051fb4489" category="paragraph"><block ref="51688bc4609022e20e8c1cb051fb4489" category="inline-link-macro-rx"></block></block>
  <block id="91af64270656f51ceebeabc4b79ecb07" category="summary">ネットアップ VDS は、必要なコードベースに基づいて利用可能なセットアップアプリケーションを使用して Microsoft Azure に導入できます。</block>
  <block id="c4e1987e3c1416cefd772fd61f28dfb4" category="paragraph">を参照してください<block ref="f8270911b627accef36841f0608bc58d" category="inline-link-rx"></block> 導入手順については、を参照して</block>
  <block id="4c9affd9b517fc81a601ea0861dc5399" category="inline-link-macro">次のステップ：ハイブリッドクラウド環境</block>
  <block id="2045518eb8a77a5284f073d0387f9a58" category="paragraph"><block ref="2045518eb8a77a5284f073d0387f9a58" category="inline-link-macro-rx"></block></block>
  <block id="bf6d8e47240024519d1dbb6f5582ce66" category="summary">グラフィックス・ワークステーションは通常、製造、医療、エネルギー、メディアおよびエンターテイメント、教育、教育などの業界で使用されています。 アーキテクチャなど。モバイル性は、グラフィックスを多用するアプリケーションには限定されることがよくあります。</block>
  <block id="942cd85feff07ce32d619d2f724254a8" category="doc">業界向けソリューション</block>
  <block id="fb987436787e4263bfee440b93703026" category="paragraph">問題のモビリティに対応するため、仮想デスクトップサービスは、タスクワーカーからエキスパートユーザまで、クラウドまたは NetApp HCI でハードウェアリソースを使用して、あらゆるタイプの従業員にデスクトップ環境を提供します。 には、柔軟な GPU 構成のオプションも含まれます。VDS を使用すると、ラップトップ、タブレット、その他のモバイルデバイスを使用して、どこからでも作業環境にアクセスできます。</block>
  <block id="68ae3286d2356ff8dd51c2a397ca20eb" category="paragraph">ANSYS Fluent'ANSYS Mechanical 'Autodesk AutoCAD'Autodesk Inventor'Autodesk 3ds Max などのソフトウェアを使用して製造ワークロードを実行するには ' 次の手順に従います Dassault Syst è mes SOLIDWORKS 、 Dassault Syst è mes CATIA 、 PTC Creo 、 Siemens PLM NX など さまざまなクラウド（ 2021 年 1 月現在）で利用可能な GPU を次の表に示します。</block>
  <block id="f5168df5bb95078acdfb440f5975a601" category="cell">GPU モデル</block>
  <block id="1668ca1bd914c1d847f23b491319ac91" category="cell">Microsoft Azure</block>
  <block id="b314ebdba178173db01ffda8d3a5af67" category="cell">Google Compute （ GCP ）</block>
  <block id="943ca3782b28d89aff2f86a50b332b3c" category="cell">Amazon Web Services （ AWS ）</block>
  <block id="8df8a98ff17d4d77329f5da80da051e8" category="cell">オンプレミス（ NetApp HCI ）</block>
  <block id="aaba9e920b39aa997c69800a9e589cd4" category="cell">NVIDIA M60</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">はい。</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">いいえ</block>
  <block id="e095ad80d900786110d53ecd5cbd3e3e" category="cell">NVIDIA T4</block>
  <block id="c909ed1507c6d5537f0cc0966e83d3f1" category="cell">NVIDIA P100</block>
  <block id="c015c1cc95335d3b867c145c056df10b" category="cell">NVIDIA P4</block>
  <block id="e8130bb14c9382769c22861fb54683b3" category="paragraph">他のユーザとの共有デスクトップセッションや、専用の個人用デスクトップも利用できます。仮想デスクトップには、 1 ～ 4 台の GPU を搭載することも、 NetApp HCI で部分的な GPU を利用することもできます。NVIDIA T4 は汎用性に優れた GPU カードで、幅広いユーザワークロードのニーズに対応できます。NetApp HCI H615C の各 GPU カードには、 16GB のフレームバッファメモリとサーバあたり 3 枚のカードが搭載されています。1 台の H615C サーバでホストできるユーザの数は、ユーザワークロードによって異なります。</block>
  <block id="4d8b78a5288c49df59136421211718c9" category="cell">ユーザ / サーバ</block>
  <block id="704316eb872cbca84a8b30d74c2708a4" category="cell">ライト（ 4GB ）</block>
  <block id="6f3a945a32dd8eba9f2fae42715f7246" category="cell">メディア（ 8GB ）</block>
  <block id="adb5e5b63d256f3854fc7276b3e8d14a" category="cell">重量（ 16GB ）</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12.</block>
  <block id="8938ba807f25f2cd88559b9f84bbc3de" category="paragraph">ユーザタイプを確認するには、アプリケーションで一般的なタスクを実行している間に GPU プロファイラツールを実行します。GPU プロファイラは、メモリ要求、表示数、およびユーザが必要とする解像度をキャプチャします。その後、要件を満たす vGPU プロファイルを選択できます。</block>
  <block id="1b014a2b6e4c329b9696aae7afac88db" category="paragraph">GPU を搭載した仮想デスクトップでは、最大 8K の表示解像度がサポートされます。また、ユーティリティ nView では、 1 つのモニタを複数の領域に分割して、異なるデータセットで動作させることができます。</block>
  <block id="30f1a84c728d67b9606115a1531aa9c3" category="paragraph">ONTAP ファイルストレージでは、次のメリットを実現できます。</block>
  <block id="826f3d14d0c34cd0f8ced37e07a1537d" category="list-text">4 、 000 億個のファイルを含むストレージで最大 20PB まで拡張可能な単一のネームスペース。管理情報は必要ありません</block>
  <block id="1d7ab3c9a162bc81b216bdc0948094f2" category="list-text">グローバルを使用して世界中にまたがることができるネームスペースです ファイルキャッシュ</block>
  <block id="2d4169e0cb52db60fd11576990b38a54" category="list-text">管理対象のネットアップストレージでセキュアマルチテナンシーを実現</block>
  <block id="a44c13ec320997e84b87b0fef150c39f" category="list-text">ネットアップを使用したオブジェクトストアへのコールドデータの移行 FabricPool</block>
  <block id="3749fba0ca78e5e5c70f899da89be2c3" category="list-text">ファイルシステム分析によるクイックファイル統計</block>
  <block id="63d0ec819ea12b4e83e0ef4a1cd2bb1c" category="list-text">ストレージクラスタの容量を最大 24 ノードまで拡張可能 パフォーマンスの向上を実現</block>
  <block id="818a13118ddb0908ba00c1b7ca18dc2c" category="list-text">クォータを使用してストレージスペースを制御し、保証する機能 パフォーマンスと QoS 制限</block>
  <block id="ef94cd0a62341c72316393b1044582f8" category="list-text">暗号化によるデータの保護</block>
  <block id="c1e36bb7dca3b0da98164eb5956e3f0f" category="list-text">データ保護とコンプライアンスに関する幅広い要件に対応</block>
  <block id="6a632279908ad5d56ab46a826de6c9f2" category="list-text">柔軟なビジネス継続性オプションを提供</block>
  <block id="3c2622109ae4dc55b73e9bb6516e5616" category="paragraph"><block ref="3c2622109ae4dc55b73e9bb6516e5616" category="inline-link-macro-rx"></block></block>
  <block id="0581202e42d61d6dfe4875c70d00cdac" category="summary">NetApp Virtual Desktop Service は、仮想デスクトップおよびアプリケーション環境を消費しやすくするだけでなく、ビジネス上の課題にも重点的に対応します。NetApp HCI で VDS を拡張することで、インラインの重複排除、コンパクション、シンプロビジョニング、圧縮など、 VDS 環境でネットアップの強力な機能を使用できます。</block>
  <block id="df6f0981c6f92ef3adb9059f5b387e4a" category="paragraph"><block ref="df6f0981c6f92ef3adb9059f5b387e4a" category="inline-link-macro-rx"></block></block>
  <block id="a3af49b9146a6a36e8bea4c525797782" category="summary">このページでは、 DCConfig Tool 、 TestVdc Tools 、およびログファイルについて説明します。</block>
  <block id="d56ee3058d1c4ab634cd3e1e606f2064" category="doc">ツールとログ</block>
  <block id="626b1761e15913fc6f955e1d76a0ac10" category="section-title">DCConfig ツール</block>
  <block id="65bbb1c25836b86f699bd2141a545958" category="paragraph">DCCconfig ツールは、サイトを追加するための次のハイパーバイザーオプションをサポートしています。</block>
  <block id="2c76e52255da65e5fcf88143f91aa431" category="paragraph"><block ref="2c76e52255da65e5fcf88143f91aa431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da2595b668536baaea606e674ade5181" category="paragraph"><block ref="da2595b668536baaea606e674ade5181" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8688a5dde644921ea673f5bc2dde55c3" category="paragraph"><block ref="8688a5dde644921ea673f5bc2dde55c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b462233b13790bce7e4c6449d02cf930" category="list-text">ワークスペースの SMB パスを変更します。</block>
  <block id="ee347a7998de9774369e6853f1ed7bcc" category="paragraph"><block ref="ee347a7998de9774369e6853f1ed7bcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c524c01ee30f2f1597bb3e90c721dd8c" category="list-text">プロビジョニングコレクションのサイトを変更します。</block>
  <block id="ccb9931a262a0b169576103526fa2ab2" category="paragraph"><block ref="ccb9931a262a0b169576103526fa2ab2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af6ba12de0b8c93d5f768c83143c7d99" category="section-title">ログファイル</block>
  <block id="881784d32d0ec795e6fd477e7c0fe8f7" category="paragraph"><block ref="881784d32d0ec795e6fd477e7c0fe8f7" category="inline-link-macro-rx"></block></block>
  <block id="21a1e68164f738b8be1dae11d5a694b3" category="section-title">データ保護</block>
  <block id="6abbceca4793ffe4b329045f63b4d219" category="doc">運用管理</block>
  <block id="787e198d8fa4e242ef62df0a63fc0f5d" category="inline-link">[Troubleshooting Failed VDA Actions] ページ</block>
  <block id="8086a7a818fcf045c7b05845b97629ed" category="paragraph">VDS ログファイルの詳細については、を参照してください<block ref="0ecc734e7dc5f9a5685babbaab9faaa5" category="inline-link-rx"></block>。</block>
  <block id="88a80237ffcd0c20f5f4d4e7f9eda875" category="inline-link">VDA Components and Permissions （ VDA コンポーネントと権限）ページ</block>
  <block id="000ea3efdd5a83f774a0c189fa2dcdc3" category="paragraph">必要な最小権限の詳細については、を参照してください<block ref="573c5bde2dc73c6cb4f63bbc5571c0e2" category="inline-link-rx"></block>。</block>
  <block id="81bb80b99b1ba5d80f9ba049cbd0c42f" category="inline-link">仮想マシンのクローニングページ</block>
  <block id="91aa73f3df8edb27ce6b20c984ff5d3e" category="paragraph">サーバのクローンを手動で作成する場合は、を参照してください<block ref="837d5521d53fff809b7ef3ad6b17ecfa" category="inline-link-rx"></block>。</block>
  <block id="7d71ba8ea6767ea10d7cd61cbd787f89" category="inline-link">ディスク容量の自動拡張機能ページ</block>
  <block id="abf872062b9eb23bdf6d671c27508d96" category="paragraph">VM ディスクのサイズを自動的に増やす方法については、を参照してください<block ref="627eb07506141f4255cfbedd7fe89646" category="inline-link-rx"></block>。</block>
  <block id="cc6d8546c611bac5ab11fa1a5948ac1d" category="inline-link">End User Requirements ページ</block>
  <block id="e148ddcb2ae92c77834ae7f48df04786" category="paragraph">クライアントを手動で設定するゲートウェイアドレスを指定するには、を参照してください<block ref="3a5e891ac91af8fef1ca1458249fe76e" category="inline-link-rx"></block>。</block>
  <block id="efb9afc2e01262d41bf1fa60ddc36414" category="paragraph">NetApp Cloud Insights は、 Web ベースの監視ツールです。ネットアップやその他のサードパーティインフラコンポーネントで実行されているインフラやアプリケーションを完全に可視化できます。Cloud Insights は、リソースの監視、トラブルシューティング、最適化のためにプライベートクラウドとパブリッククラウドの両方をサポートしています。</block>
  <block id="4894eb73d4d2ad7eaebb0968e871cb70" category="paragraph">データコレクタからの指標をエージェントなしで収集するには、 Acquisition Unit VM （ Windows または Linux ）だけをプライベートクラウドにインストールする必要があります。エージェントベースのデータコレクタを使用すると、 Windows パフォーマンスモニタまたは Tegraf がサポートする入力エージェントからカスタムメトリックを取得できます。</block>
  <block id="32e49e2645f559763ede8e346bbcb816" category="paragraph">次の図は、 Cloud Insights VDS ダッシュボードを示しています。</block>
  <block id="cb9ecf4f0010c9ec12b73a00e06a9237" category="paragraph"><block ref="cb9ecf4f0010c9ec12b73a00e06a9237" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3bd1406c323c740b5b2f2a7615ad62ca" category="paragraph">NetApp Cloud Insights の詳細については、を参照してください<block ref="5fdb6e8524eb99916602753c65f2f24e" category="inline-link-rx"></block>。</block>
  <block id="48a2bc9c10adbea95074594015793272" category="summary">ワークスペースはデスクトップ環境で構成されます。この環境は、オンプレミスまたは任意のサポートクラウド環境でホストされる共有リモートデスクトップセッションにすることができます。Microsoft Azure では、 Windows 仮想デスクトップを使用してデスクトップ環境を永続化できます。各ワークスペースは、特定の組織またはクライアントに関連付けられます。</block>
  <block id="1da2374b50f497e208c8dab11e6b2c98" category="doc">ワークスペース管理</block>
  <block id="42a6c6312ce8b92836d9e74d89998e89" category="paragraph"><block ref="42a6c6312ce8b92836d9e74d89998e89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d49083c2604eac2881e01b4acea428e" category="admonition">各ワークスペースは、特定の配置に関連付けられます。</block>
  <block id="2a1fdca12b05c0f5292a8670b24cb478" category="paragraph">ワークスペースには、関連するアプリケーションとアプリケーションサービス、共有データフォルダ、サーバ、 WVD インスタンスが含まれます。各ワークスペースでは、パスワードの複雑さの適用、多要素認証、ファイル監査などのセキュリティオプションを制御できます。</block>
  <block id="f29490b04a344e19674ee8d1db337d14" category="paragraph">ワークスペースでは、追加のサーバの電源投入、サーバあたりのユーザ数の制限、または特定の期間に使用可能なリソースのスケジュールの設定（常にオン / オフ）を行うためのワークロードスケジュールを制御できます。リソースは、オンデマンドでウェイクアップするように設定することもできます。</block>
  <block id="421b47ffd946ca083b65cd668c6b17e6" category="inline-link">ビデオ</block>
  <block id="ff13351bb4dc0c877064ec1672d6723f" category="inline-link-macro">次の例は、アプリケーション管理です</block>
  <block id="bb974af58c318849f0fce8f7c3ecdf37" category="paragraph"><block ref="bb974af58c318849f0fce8f7c3ecdf37" category="inline-link-macro-rx"></block></block>
  <block id="7d37fde7375502ef1013412159477502" category="summary">ネットアップは、 WVD やリモートアプリケーションによる仮想デスクトップの高速プロビジョニングなどの多くのクラウドサービスを提供し、 Azure NetApp Files との迅速な統合も実現しています。</block>
  <block id="28850fd0c108cc5f990fc4b4b52ab60d" category="doc">ネットアップ仮想デスクトップサービスの概要</block>
  <block id="0276a1f5f692f2e9635f3733b371cf70" category="paragraph">Microsoft Azure Windows Virtual Desktop サービスを使用すると、リモートデスクトップサービスコンポーネントのメンテナンスを Microsoft が行い、お客様はクラウド内でのワークスペースのプロビジョニングに集中できます。お客様は、 VDI 環境を管理するために特別なスキルを必要とする完全なスタックをプロビジョニングして管理する必要があります。</block>
  <block id="51db16f7b26a08952beb43836ad3f31d" category="paragraph">NetApp VDS を使用すると、ブローカー、ゲートウェイ、エージェントなどのアーキテクチャコンポーネントのインストール場所を気にすることなく、仮想デスクトップを迅速に導入できます。環境を完全に管理する必要があるお客様は、プロフェッショナルサービスチームと協力して目標を達成できます。お客様は VDS をサービスとして利用するため、主なビジネス上の課題に注力できます。</block>
  <block id="139562ef7df2deed82d586ebe297a082" category="paragraph">ネットアップの VDS は、 AWS 、 Azure 、 GCP 、プライベートクラウド環境の複数の導入を一元管理するソフトウェアサービスです。Microsoft Windows Virtual Desktop は、 Microsoft Azure でのみ使用できます。NetApp VDS は、他の環境で Microsoft リモートデスクトップサービスのオーケストレーションを行います。</block>
  <block id="416feb9f77def2ffedaab40a538d47e5" category="paragraph">次の図に、導入トポロジの例を示します。</block>
  <block id="e377917f3505cdb9fc72b74164df5928" category="paragraph"><block ref="e377917f3505cdb9fc72b74164df5928" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d271ca257d56879fcc9ed95d82aabaa7" category="paragraph">各展開は、 Active Directory ドメインに関連付けられ、ワークスペースおよびアプリケーションのアクセスエントリポイントをクライアントに提供します。複数の Active Directory ドメインを持つサービスプロバイダまたは企業は、通常、より多くの導入環境を持っています。複数のリージョンにまたがる単一の Active Directory ドメインには、通常、複数のサイトを含む単一の導入環境があります。</block>
  <block id="3e8cd47ad0ab71d0b3891f85212ccdbc" category="paragraph">各導入環境には独自のプラットフォームサービスがあり、 Cloud Workspace Manager （ REST API エンドポイント）、 HTML 5 ゲートウェイ（ VDS 管理ポータルから VM に接続）、 RDS ゲートウェイ（クライアントのアクセスポイント）、およびドメインコントローラで構成されます。次の図は、 RDS 実装用の VDS コントロールプレーンアーキテクチャを示しています。</block>
  <block id="38606818aeffd06d174e51013afc23a1" category="paragraph"><block ref="38606818aeffd06d174e51013afc23a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58cad6a2c8c8ff1a585bf8d6ca94560" category="paragraph">RDS 環境では、 Windows とブラウザから NetApp VDS にクライアントソフトウェアを使用して簡単にアクセスできます。クライアントソフトウェアを使用して、顧客のロゴとイメージを含めるようにカスタマイズできます。ユーザーの資格情報に基づいて、承認されたワークスペースとアプリケーションへのユーザーアクセスを提供します。ゲートウェイの詳細を設定する必要はありません。</block>
  <block id="c2dcf4d443be38a737d1e580fb4b86ec" category="paragraph">次の図は、 NetApp VDS クライアントを示しています。</block>
  <block id="8e7d56f1d99fdc8080a747bf8b1eda75" category="paragraph"><block ref="8e7d56f1d99fdc8080a747bf8b1eda75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e4318c1c6ae62544ba67e7c0fe55649" category="paragraph">次の図は、 Azure WVD 実装用の VDS コントロールプレーンアーキテクチャを示しています。</block>
  <block id="ba9e4c82a95db68279bffa8ca8a8803f" category="paragraph"><block ref="ba9e4c82a95db68279bffa8ca8a8803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d648a5d4acf66674fb86cc7be05bd5e" category="paragraph">必要なコンポーネントの導入と構成に加えて、ネットアップ VDS はユーザ管理、アプリケーション管理、リソースの拡張、最適化も行います。</block>
  <block id="3ea30729e0e7f0d666400ccc1a6f7bc3" category="paragraph">ネットアップの VDS では、ユーザを作成したり、既存のユーザアカウントにクラウドワークスペースやアプリケーションサービスへのアクセスを許可したりできます。ポータルは、パスワードのリセットや、一部のコンポーネントの管理の委譲にも使用できます。ヘルプデスク管理者またはレベル 3 の技術者は、トラブルシューティングのためのユーザーセッションをシャドウイングしたり、ポータル内からサーバーに接続したりすることができます。</block>
  <block id="91d75bd7e517ef4b563021e6d23d8cb9" category="inline-link-macro">次の手順： NetApp HCI の概要</block>
  <block id="3806ab54895f78b6c34b626314f84e6e" category="paragraph"><block ref="3806ab54895f78b6c34b626314f84e6e" category="inline-link-macro-rx"></block></block>
  <block id="2cdacde3c74a59c779ff64324954b86f" category="summary">ネットアップの仮想デスクトップサービス（ VDS ）は、主要なパブリッククラウドとプライベートクラウドで Remote Desktop Services （ RDS ）のオーケストレーションを実現します。VDS は、 Microsoft Azure で Windows Virtual Desktop （ WVD ）をサポートします。VDS は、 WVD または RDS の導入後に実行する必要がある多くのタスクを自動化します。たとえば、 SMB ファイル共有（ユーザプロファイル、共有データ、およびユーザホームドライブ用）の設定、 Windows の機能、アプリケーションとエージェントのインストール、ファイアウォール、ポリシーなどを有効にします。</block>
  <block id="acb7add6e3cf0ca01c52e60466c321ca" category="doc">TR-4861 ：『 Hybrid Cloud VDI with Virtual Desktop Service 』</block>
  <block id="bb6a5b934db24610665e58e743983ae4" category="paragraph">ユーザは専用デスクトップ、共有デスクトップ、およびリモートアプリケーション用の VDS を使用します。VDS では、デスクトップのアプリケーション管理を自動化するスクリプト化されたイベントが提供され、管理するイメージの数が削減されます。</block>
  <block id="38e3c8e108e8e361d0712cdfe23e0b38" category="paragraph">VDS では、パブリッククラウド環境とプライベートクラウド環境の導入を処理するための単一の管理ポータルが提供されます。</block>
  <block id="07d07e20c1ad9bd1a3e99e2303879ff9" category="paragraph">2020 年のリモートワーカーの急増により、ビジネス継続性の要件が変化しています。IT 部門は、仮想デスクトップを迅速にプロビジョニングするという新たな課題に直面しています。そのためには、オンプレミスとクラウドのリソースのプロビジョニングを簡単に行えるハイブリッドクラウドのプロビジョニング即応性、リモート管理、 TCO のメリットが必要です。次のようなハイブリッドクラウド解決策が必要です。</block>
  <block id="44ff202cbab5f506b48c6021b19c4b1c" category="list-text">新型コロナウイルス感染症ワークスペースの実際の状況に対処して、柔軟なワークモデルを実現します グローバルダイナミクスを備えています</block>
  <block id="53f994926861d0a62f2893b66d8b2025" category="list-text">タスクワーカーからパワーユーザまで、すべての従業員の作業環境の導入を簡素化し、迅速化することで、シフトワークを可能にします</block>
  <block id="831955bd9eabf6724f4e4b01acbb833c" category="list-text">物理的な場所に関係なく、リッチでセキュアな VDI リソースを提供することで、従業員をモバイル化します</block>
  <block id="ab02aa4712e65c237e92874eeef51ecd" category="list-text">ハイブリッドクラウドの導入を簡易化</block>
  <block id="074890ea8810b95d9b381027ff9baef2" category="list-text">リスク軽減管理を自動化して簡素化します</block>
  <block id="60e1de201d0c183e889577e990975f1a" category="paragraph"><block ref="60e1de201d0c183e889577e990975f1a" category="inline-link-macro-rx"></block></block>
  <block id="49fc376ed35249f3841846ede4dab884" category="inline-link">NetApp Cloud Central</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">追加情報の参照先</block>
  <block id="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link"><block ref="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link-rx"></block></block>
  <block id="bc0f3321a29c580fa0e3cca0c00ee7cd" category="list-text">VMware 製品ドキュメント<block ref="3bdcd80def6a1e2849d8b38049a04af9" category="inline-link-rx"></block></block>
  <block id="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link"><block ref="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link-rx"></block></block>
  <block id="0f185ccd88416daec4eee0a846d110b8" category="list-text">ネットアップの製品マニュアル<block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="doc">推奨される ESXi ホストとその他の ONTAP 設定</block>
  <block id="0416d04b345b434b120840c30ddaf0a1" category="paragraph">ネットアップでは、 ONTAP を使用する際に適切に動作する ESXi ホストのマルチパスと HBA タイムアウトの設定を、テスト結果に基づいて作成しました。これらは、 VMware vSphere 用の ONTAP ツールを使用して簡単に設定できます。サマリダッシュボードで、ホストシステムポートレットの設定の編集をクリックするか、 vCenter でホストを右クリックして、 ONTAP ツール &gt; 推奨値の設定を選択します。9.8 リリースで現在推奨されているホスト設定は次のとおりです。</block>
  <block id="dec4361376291bf7e7976c204f3a6cc8" category="cell">ホスト設定</block>
  <block id="024c7088f8cb994f40e5d60b87c10cbb" category="cell">ネットアップが推奨する値</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3.HardwareAcceleratedLocking</block>
  <block id="2eabcf9ece81cd6f8095d869d0ecfdb5" category="cell">そのままにします（ VMware のデフォルトは 1 ）。</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete の 2 つのオプションがあります</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">Net.TcpipHeapSize の場合</block>
  <block id="abcf68baf479cae32e490eb770477d84" category="cell">vSphere 6.0 以降： 32 に設定他のすべての NFS 設定の場合は、 30 に設定されます。</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">Net.TcpipHeapMax</block>
  <block id="5f039752b957a359dac1c1e45051a844" category="cell">vSphere 6.0 以降では、 1536 に設定します。</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes の場合</block>
  <block id="d75533d93e425c0e677c7115b33e8152" category="cell">vSphere 6.0 以降では、 256 に設定されます。他のすべての NFS 構成では、 64 に設定されます。</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.MaxVolumes の場合</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">vSphere 6.0 以降では、 256 に設定されます。</block>
  <block id="6f4edfb9f3990d73482442c70e5fc2a0" category="cell">NFS.MaxQueueDepth</block>
  <block id="0e61218c55cae3476207bca2c2f35ca7" category="cell">vSphere 6.0 以降では、 128 に設定されます。</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures の略</block>
  <block id="8a14ec18b6563675357f1050563de774" category="cell">すべての NFS 設定について、 10 に設定されます。</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">nfs.HeartbeatFrequency</block>
  <block id="072f9680861841ae9a13008a99667a75" category="cell">すべての NFS 設定について、 12 に設定されます。</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">nfs.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">すべての NFS 設定について、 5 に設定されます。</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">SunRPC.MaxConnPerIP</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">vSphere 7.0 以降では 128 に設定されます。</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">パス選択ポリシー</block>
  <block id="1e304108bae216d7b24d43f9bc868298" category="cell">FC パスの ALUA を使用する場合は、 RR （ラウンドロビン）に設定されます。それ以外の構成では、すべて FIXED に設定されます。この値を RR に設定すると、最適化されたすべてのアクティブなパスで負荷を分散できます。FIXED は、 ALUA に対応していない従来の構成用の値で、プロキシ I/O を防止できますつまり、 Data ONTAP 7-Mode を実行する環境でハイアベイラビリティ（ HA ）ペアの他方のノードに I/O が送られないようにすることができます。</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize</block>
  <block id="acaf935911b20ef844daea256f8181b1" category="cell">すべての構成で 32 に設定されます。この値を設定すると、 I/O エラーの防止に役立ちます。</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.qFullThreshold</block>
  <block id="ab1224ed1cd7c63073af652a3bd92a35" category="cell">すべての構成で 8 に設定します。この値を設定すると、 I/O エラーの防止に役立ちます。</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Emulex FC HBA タイムアウト</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">デフォルト値を使用します。</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">QLogic FC HBA タイムアウト</block>
  <block id="d7e64409eb99602fc3b57a9f0b9287d6" category="cell">すべての iSCSI パスで RR （ラウンドロビン）に設定されます。この値を RR に設定すると、最適化されたすべてのアクティブなパスで負荷を分散できます。</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">ONTAP ツールでは、 ONTAP FlexVol および LUN の作成時に特定のデフォルト設定も指定されます。</block>
  <block id="b97847dc22c9e1f02417ab38785b34e6" category="cell">ONTAP ツール</block>
  <block id="c003231c67265f34100a284092c0cf1f" category="cell">デフォルト設定です</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">Snapshot リザーブ（ -percent-snapshot-space ）</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">フラクショナルリザーブ（ -fractional-reserve ）</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">アクセス時間の更新（ -atime-update ）</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">いいえ</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">最小限の先読み（ -min-readahead ）</block>
  <block id="eee57b9c7d333899f3df6ffd10ec50df" category="cell">スケジュールされた Snapshot コピー</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">ストレージ効率</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">有効</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">ボリュームギャランティ</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">なし（シンプロビジョニング）</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">ボリュームのオートサイズ</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">grow_shrink</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">LUN のスペースリザベーション</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">無効</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">LUN スペースの割り当て</block>
  <block id="0464f851d84d05f0a9db9051354e5581" category="section-title">その他のホストマルチパス構成に関する考慮事項</block>
  <block id="5fcb3de72ca1920517439049153d961d" category="paragraph">現在使用可能な ONTAP ツールで設定されていませんが、以下の設定オプションを検討することを推奨します。</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">ハイパフォーマンスな環境で、または単一の LUN データストアでパフォーマンスをテストする場合は、ラウンドロビン（ VMW_PSP_RR ）パス選択ポリシー（ PSP ）の負荷分散設定をデフォルトの IOPS 設定 1000 から 1 に変更することを検討します。VMware の技術情報を参照<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> 詳細については、</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">パス選択プラグインとポリシー</block>
  <block id="249afbf456bd04d574e8d362d5bf133c" category="list-text">vSphere 6.7 Update 1 では、 VMware がラウンドロビン PSP 用に新しいレイテンシの負荷分散メカニズムを導入しました。新しいオプションでは、 I/O に最適なパスを選択する際に、 I/O 帯域幅とパスレイテンシが考慮されます1 つのパスに別のパスよりも多くのネットワークホップがある場合や、 NetApp All SAN Array システムを使用している場合など、パス接続に同等でない環境では、この方法を使用するとメリットが得られます。を参照してください<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> を参照してください。</block>
  <block id="3b2287aeb862e195f44c02694fff89fe" category="summary">SnapCenter では、複数のジョブに適用可能なバックアップポリシーを作成できます。これらのポリシーでは、スケジュール、保持、レプリケーションなどの機能を定義できます。VMware スナップショットを作成する前に、ハイパーバイザの機能を活用して I/O を休止する、オプションの VM 整合性スナップショットを選択できます。</block>
  <block id="b1c93d491ba776d955eb2e3b90908fb9" category="doc">vSphere 向けのその他の機能</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="section-title">データ保護</block>
  <block id="343775d7b18c4ca0af9b7fad57690839" category="paragraph">VM のバックアップと迅速なリカバリは、 ONTAP for vSphere の大きな特長の 1 つです。この機能は、 SnapCenter Plug-in for VMware vSphere を使用して vCenter 内で簡単に管理できます。Snapshot コピーを使用すると、パフォーマンスに影響を与えることなく VM やデータストアのコピーをすばやく作成し、 SnapMirror を使用してセカンダリシステムに送信し、長期にわたるオフサイトでのデータ保護を実現できます。このアプローチでは、変更された情報のみを格納することで、ストレージスペースとネットワーク帯域幅を最小限に抑えます。</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">（推奨）</block>
  <block id="8cc688149346249b3a92e59282755f3e" category="paragraph">SnapCenter では、複数のジョブに適用可能なバックアップポリシーを作成できます。これらのポリシーでは、スケジュール、保持、レプリケーションなどの機能を定義できます。VMware スナップショットを作成する前に、ハイパーバイザの機能を活用して I/O を休止する、オプションの VM 整合性スナップショットを選択できます。ただし、 VMware スナップショットはパフォーマンスへの影響があるため、ゲストファイルシステムを休止する必要がないかぎり、一般には推奨されません。代わりに、 ONTAP の Snapshot コピーを使用して一般的な保護を行い、 SnapCenter プラグインなどのアプリケーションツールを使用して SQL Server や Oracle などのトランザクションデータを保護します。これらの Snapshot コピーは VMware （整合性） Snapshot とは別のものであり、長期的な保護に適しています。VMware スナップショットはのみです<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> パフォーマンスやその他の影響があるため、短期的な使用に適しています。</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">これらのプラグインは、物理環境と仮想環境の両方でデータベースを保護する拡張機能を提供します。vSphere では、これらのプロトコルを使用して、 RDM LUN 、ゲスト OS に直接接続された iSCSI LUN 、 VMFS または NFS データストア上の VMDK ファイルにデータが格納されている SQL Server または Oracle データベースを保護できます。プラグインでは、さまざまなタイプのデータベースバックアップを指定し、オンラインまたはオフラインのバックアップをサポートし、ログファイルとともにデータベースファイルを保護できます。プラグインは、バックアップとリカバリに加えて、開発やテスト目的でのデータベースのクローニングにも対応しています。</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">次の図は、 SnapCenter の導入例を示しています。</block>
  <block id="54ee9d8cd5db70a761321f3e7d168445" category="paragraph"><block ref="54ee9d8cd5db70a761321f3e7d168445" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">ディザスタリカバリ機能を強化するには、 ONTAP 用 NetApp SRA と VMware Site Recovery Manager の使用を検討してください。DR サイトへのデータストアのレプリケーションをサポートするだけでなく、レプリケートしたデータストアをクローニングすることで DR 環境を無停止でテストすることもできます。SRA に組み込まれている自動化機能を使用すると、災害からのリカバリや、システム停止が解決したあとの本番環境の再保護も簡単に実行できます。</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">最後に、最高レベルのデータ保護を実現するために、 NetApp MetroCluster を使用した VMware vSphere Metro Storage Cluster （ vMSC ）設定を検討してください。vMSC は、同期レプリケーションとアレイベースのクラスタリングを組み合わせた VMware 認定の解決策です。高可用性クラスタと同じメリットを提供しますが、複数のサイトに分散してサイト障害から保護します。NetApp MetroCluster は、同期レプリケーション向けの対費用効果の高い構成を提供します。ストレージコンポーネントのあらゆる単一障害から透過的にリカバリでき、サイト障害時にコマンド 1 つでリカバリできます。vMSC の詳細については、を参照してください<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>。</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">スペース再生</block>
  <block id="d490382851fbc5bd6720046bf9bc0c03" category="paragraph">VM がデータストアから削除されたときに、他の目的でスペースを再生することができます。NFS データストアを使用している場合、 VM が削除されるとすぐにスペースが再生されます（もちろん、このアプローチはボリュームがシンプロビジョニングされている場合、つまりボリュームギャランティが none に設定されている場合にのみ有効です）。ただし、 VM のゲスト OS 内でファイルが削除されても、 NFS データストアではスペースが自動的に再生されません。LUN ベースの VMFS データストアの場合、 ESXi およびゲスト OS は、問題 VAAI UNMAP プリミティブをストレージに（シンプロビジョニングを使用している場合に）再利用できます。リリースによっては、このサポートは手動と自動のどちらかになります。</block>
  <block id="6a2bff0a8d10ca0fc6c782e7978f696a" category="inline-link">2057513</block>
  <block id="8927aab76c49d1deb0b407fd261d5aa6" category="inline-link">ストレージスペースの再生</block>
  <block id="0c5a70f66ff77925d7dd7192191ec8f2" category="paragraph">vSphere 5.5 以降では、 vmkfstools – y コマンドに代わって、空きブロック数を指定する esxcli storage vmfs unmap コマンドが使用されます（ VMware KB を参照）<block ref="1d61bd4e8925f7d5aac61e083b728439" category="inline-link-rx"></block> 詳細については、を参照してください）。vSphere 6.5 以降では、 VMFS 6 を使用している場合、スペースは自動的に非同期で再利用される必要があります（を参照）<block ref="a9ae15a1c91a14939aefb313015202e6" category="inline-link-rx"></block> vSphere のドキュメントを参照）。ただし、必要に応じて手動で実行することもできます。この自動マッピング解除は ONTAP でサポートされ、 VMware vSphere 用の ONTAP ツールでは低優先度に設定されます。</block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="section-title">VM とデータストアのクローニング</block>
  <block id="d355cf5d1a16095124a54902f7cf49db" category="paragraph">ストレージオブジェクトをクローニングすると、追加の VM のプロビジョニングやバックアップ / リカバリ処理などの用途に使用できるコピーを簡単に作成できます。vSphere では、 VM 、仮想ディスク、 VVOL 、またはデータストアをクローニングできます。クローニングされたオブジェクトは、多くの場合、自動化されたプロセスによってさらにカスタマイズできます。vSphere では、フルコピークローンとリンククローンの両方がサポートされます。リンククローンでは、元のオブジェクトとは別に変更が追跡されます。</block>
  <block id="78f8f8d69825dfe8e6085151fa565f28" category="paragraph">リンククローンはスペースを節約するのに適していますが、 vSphere が VM に対して処理する I/O 量が増えるため、その VM のパフォーマンスや場合によってはホスト全体のパフォーマンスに影響します。そのため、 NetApp のお客様は、ストレージシステムベースのクローンを使用して、ストレージの効率的な使用とパフォーマンスの向上という両方のメリットを得ることがよくあります。</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">次の図は、 ONTAP クローニングを示しています。</block>
  <block id="8ee3cd3dba25fb32f1bc38cb528ac998" category="paragraph"><block ref="8ee3cd3dba25fb32f1bc38cb528ac998" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">クローニングは、 ONTAP ソフトウェアを実行するシステムに複数のメカニズムを使用してオフロードできます。通常は、 VM 、 VVol 、データストアのレベルでオフロードします。これには次のものが含まれます。</block>
  <block id="3b6d066ffdecb2beb542ef68e773d4ae" category="list-text">NetApp vSphere APIs for Storage Awareness （ VASA ） Provider を使用した VVol のクローニング。ONTAP クローンは、 vCenter で管理される VVol Snapshot コピーをサポートするために使用されます。 VVol Snapshot コピーはスペース効率に優れており、作成や削除の I/O の影響を最小限に抑えることができます。VM のクローニングは vCenter を使用して行うこともでき、 1 つのデータストア / ボリューム内かデータストア / ボリューム間かに関係なく、 ONTAP にオフロードされます。</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">vSphere APIs – Array Integration （ VAAI ）を使用した vSphere のクローニングと移行：SAN 環境と NAS 環境の両方で、 VM のクローニング処理を ONTAP にオフロードできます（ネットアップでは、 NFS 用の VAAI を有効にするために ESXi プラグインを提供しています）。vSphere は、 NAS データストア内のコールド（電源オフ） VM にのみオフロードします。一方、ホット VM （クローニングと Storage vMotion ）の処理も SAN にオフロードされます。ONTAP では、ソース、デスティネーション、インストールされている製品ライセンスに基づいて最も効率的なアプローチを採用しています。この機能は VMware Horizon View でも使用されています。</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA （ VMware Site Recovery Manager で使用）。ここでは、クローンを使用して、 DR レプリカのリカバリを無停止でテストします。</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">SnapCenter などのネットアップのツールを使用したバックアップとリカバリVM クローンは、バックアップ処理の検証や VM バックアップのマウントに使用され、個々のファイルをコピーできるようにします。</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">ONTAP オフロードクローニングは、 VMware 、ネットアップ、サードパーティのツールから実行できます。ONTAP にオフロードされたクローンには、いくつかのメリットがあります。ほとんどの場合、スペース効率に優れており、オブジェクトの変更にのみ対応するストレージが必要です。読み取りや書き込みのパフォーマンスには影響しません。また、高速キャッシュでブロックを共有することでパフォーマンスが向上する場合もあります。また、 CPU サイクルとネットワーク I/O も ESXi サーバからオフロードされます。FlexVol を使用する従来のデータストア内でのコピーオフロードは、 FlexClone ライセンスを使用すると高速かつ効率的ですが、 FlexVol 間のコピーの方が低速になる可能性があります。VM テンプレートをクローンのソースとして管理する場合は、スペース効率に優れた高速クローンを作成するために、テンプレートをデータストアボリューム内に配置することを検討してください（フォルダやコンテンツライブラリを使用してテンプレートを整理します）。</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">ONTAP 内で直接ボリュームまたは LUN をクローニングして、データストアをクローニングすることもできます。NFS データストアの場合は、 FlexClone テクノロジでボリューム全体をクローニングし、 ONTAP からクローンをエクスポートして、別のデータストアとして ESXi にマウントできます。VMFS データストアの場合は、ボリューム内の LUN 、または 1 つ以上の LUN を含むボリューム全体を ONTAP でクローニングできます。VMFS を含む LUN を通常のデータストアとしてマウントして使用するためには、 LUN を ESXi igroup にマッピングし、 ESXi から再署名を受ける必要があります。ただし一部の一時的なユースケースでは、クローニングされた VMFS を再署名なしでマウントすることができます。クローニングしたデータストア内の VM は、個別にクローニングした VM と同様に登録、再設定、およびカスタマイズすることができます。</block>
  <block id="1c12a8dd266e356901d22c0b7711369d" category="paragraph">バックアップや FlexClone 用の SnapRestore など、追加のライセンス機能を使用してクローニングを強化できる場合があります。これらのライセンスは、追加コストなしでライセンスバンドルに含まれていることがよくあります。FlexClone ライセンスは、 VVOL のクローニング処理、および VVOL の管理対象 Snapshot コピー（ハイパーバイザーから ONTAP にオフロード）をサポートするために必要です。FlexClone をデータストア / ボリューム内で使用すると、特定の VAAI ベースのクローンの品質を向上させることもできます（ブロックコピーではなく、スペース効率に優れたコピーが瞬時に作成されます）。また、 DR レプリカのリカバリをテストする際に SRA で使用され、クローニング処理用に SnapCenter でバックアップコピーを参照して個々のファイルをリストアする際にも使用されます。</block>
  <block id="6d30b2619de7fa18e965516b291a1937" category="section-title">ストレージ効率とシンプロビジョニング</block>
  <block id="616c027f14ee5f1bbc866171c4017141" category="paragraph">ネットアップは、プライマリワークロードに初めて重複排除を適用するなどの Storage Efficiency の革新的なテクノロジを業界でリードしてきました。インラインデータコンパクションは、圧縮機能を強化し、小さなファイルと I/O を効率的に格納する機能です。ONTAP は、インライン重複排除とバックグラウンド重複排除のほか、インライン圧縮とバックグラウンド圧縮の両方をサポートしています。</block>
  <block id="8f105eeb6dc3fc4ce0d4758aeab4a256" category="paragraph">次の図は、 ONTAP の Storage Efficiency 機能の効果を組み合わせたものです。</block>
  <block id="4b7a9b58ab55917c054d5a636481a8b8" category="paragraph"><block ref="4b7a9b58ab55917c054d5a636481a8b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e89f9787f44321e33f85595321efc66" category="paragraph">vSphere 環境で ONTAP の Storage Efficiency 機能を使用する際の推奨事項を次に示します。</block>
  <block id="c2eea4e122397fa75d749bdbdcd4302d" category="list-text">重複排除によって削減されるデータ量は、データにどれくらい共通部分があるかによって異なります。ONTAP 9.1 以前では、データ重複排除はボリュームレベルで機能しましたが、 ONTAP 9.2 以降のアグリゲート重複排除では、 AFF システムのアグリゲート内のすべてのボリュームのデータが重複排除されます。削減効果を最大化するために、類似するオペレーティングシステムやアプリケーションを 1 つのデータストア内にグループ化する必要はなくなりました。</block>
  <block id="59eb554aa77d0e4dfdc304b3b914dd76" category="list-text">ブロック環境で重複排除のメリットを実現するには、 LUN をシンプロビジョニングする必要があります。VM 管理者からは引き続き LUN がプロビジョニング済み容量として認識されますが、重複排除による削減効果は他のニーズに使用できるようにボリュームに戻されます。これらの LUN は、シンプロビジョニングされた FlexVol ボリュームに導入することを推奨します（ VMware vSphere 用の ONTAP ツールでは、ボリュームのサイズが LUN よりも約 5% 大きくなるように設定しています）。</block>
  <block id="1e84230a4e75abc233d64344b14fd511" category="list-text">NFS FlexVol ボリュームにはシンプロビジョニングも推奨されます（デフォルトです）。NFS 環境では、シンプロビジョニングされたボリュームを使用しているストレージ管理者と VM 管理者の両方に、重複排除による削減効果がすぐに反映されます。</block>
  <block id="b26ed63d0f1199652537e2c4b6752130" category="list-text">シンプロビジョニング環境 VM も同様です。ネットアップでは、一般にシックプロビジョニングではなくシンプロビジョニングされた VMDK を推奨しています。シンプロビジョニングを使用する場合は、スペース不足の問題を回避するために、 VMware vSphere 、 ONTAP 、またはその他の使用可能なツール用の ONTAP ツールで利用可能なスペースを監視してください。</block>
  <block id="041f3a2c9d939c181dbd2a95595455d0" category="list-text">ONTAP システムでシンプロビジョニングを使用した場合はパフォーマンスが低下しないことに注意してください。データは使用可能なスペースに書き込まれるため、書き込みパフォーマンスと読み取りパフォーマンスが最大限に高まります。この事実にもかかわらず、 Microsoft フェイルオーバークラスタリングやその他の低レイテンシアプリケーションなどの一部の製品では、保証されたプロビジョニングや固定プロビジョニングが必要になる場合があります。また、サポートの問題を回避するには、これらの要件に従うことを推奨します。</block>
  <block id="473c8efc5f9b8640820a9cc1f9c84862" category="list-text">重複排除による削減効果を最大限に高めるために、ハードディスクベースのシステムでのバックグラウンド重複排除または AFF システムでの自動バックグラウンド重複排除のスケジュールを設定することを検討してください。ただし、スケジュールされたプロセスは実行時にシステムリソースを使用するため、非アクティブな時間帯（週末など）にスケジュールを設定するか、より頻繁に実行して処理される変更データの量を減らすことが理想的です。AFF システムでの自動バックグラウンド重複排除は、フォアグラウンドアクティビティへの影響を大幅に軽減します。バックグラウンド圧縮（ハードディスクベースのシステムの場合）でもリソースが消費されるため、パフォーマンス要件が限定されたセカンダリワークロードでのみ考慮する必要があります。</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">こちらの技術情報アーティクル</block>
  <block id="ac2fab512a521d04e53c7257ef490187" category="list-text">NetApp AFF システムは、主にインラインの Storage Efficiency 機能を使用します。7-Mode Transition Tool 、 SnapMirror 、ボリューム移動などのブロックレプリケーションを使用するネットアップのツールを使用してデータを移動する場合は、圧縮スキャナやコンパクションスキャナを実行して、効率化による削減効果を最大限に高めると効果的です。このネットアップサポートを確認してください<block ref="a24ae202a787a3e4695f02339b72bb57" category="inline-link-rx"></block> を参照してください。</block>
  <block id="af21d2d4e0d0faaa6435e780ed7fbc49" category="list-text">圧縮や重複排除によって削減できるブロックが Snapshot コピーによってロックされる場合があります。スケジュールされたバックグラウンドの効率化スキャナまたはワンタイムスキャナを使用する場合は、次の Snapshot コピーが作成される前に、それらの効率化処理が実行および完了していることを確認してください。Snapshot コピーと保持設定を確認して、特にバックグラウンドジョブやスキャナジョブを実行する前に、必要な Snapshot コピーだけを保持していることを確認してください。</block>
  <block id="8f4468ee9f4f074a9f705cd8240de3d9" category="paragraph">次の表に、さまざまなタイプの ONTAP ストレージ上にある仮想ワークロードのストレージ効率化のガイドラインを示します。</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">ワークロード</block>
  <block id="84f3306d313cbbe707b0df3807aa77ef" category="cell">Storage Efficiency に関するガイドライン</block>
  <block id="5325da9878854628027602da18e5fc14" category="cell">Flash Pool の機能です</block>
  <block id="9aa1187640093122ffdb7e1c18f8586d" category="cell">ハードディスクドライブ</block>
  <block id="9bbf225892f3ce69fc504d145abe3ded" category="cell">VDI および SVI</block>
  <block id="1be6174441cf80d01c59eb7a9c004498" category="paragraph">プライマリワークロードとセカンダリワークロード：</block>
  <block id="738b6df06bc30a1f2fa6d500095bfceb" category="list-text">アダプティブインライン圧縮</block>
  <block id="f801303ba7009e27cce2fe9a73dc5ebe" category="list-text">インライン重複排除</block>
  <block id="f94a70bfe4407315e07db5e64706e531" category="list-text">バックグラウンド重複排除</block>
  <block id="95f3762d2d933ff2c0f6e30ef2c767c9" category="list-text">インラインデータコンパクション</block>
  <block id="22be9b04282591df89574efb0e9d2315" category="paragraph">プライマリワークロードには次の機能を使用：</block>
  <block id="e37f23785e68eb0a9d5afd7457b0903e" category="paragraph">セカンダリワークロードの場合：</block>
  <block id="7901e1160498e7aff40dc0f858411c54" category="list-text">バックグラウンドアダプティブ圧縮</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="section-title">サービス品質（ QoS ）</block>
  <block id="f437881fa7e42bf0e4563bbec8176f81" category="paragraph">ONTAP ソフトウェアを実行するシステムでは、 ONTAP ストレージ QoS 機能を使用して、ファイル、 LUN 、ボリューム、 SVM 全体などの異なるストレージオブジェクトに対するスループットを MBps や IOPS （ 1 秒あたりの I/O 数）で制限できます。</block>
  <block id="fb4aa9631cd742ae8a88f672b4464b37" category="paragraph">スループット制限は、他のワークロードに影響しないように、導入前に不明なワークロードやテストワークロードを制御するのに役立ちます。また、 Bully ワークロードが特定された場合に、この 2 つを使用して抑制することもできます。ONTAP 9.2 では SAN オブジェクトに、 ONTAP 9.3 では NAS オブジェクトに一貫したパフォーマンスを提供するために、 IOPS に基づく最小サービスレベルもサポートされています。</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">NFS データストアの場合は、 QoS ポリシーを FlexVol 全体またはボリューム内の個々の VMDK ファイルに適用できます。ONTAP LUN を使用する VMFS データストアでは、 LUN を含む FlexVol ボリュームには QoS ポリシーを適用できますが、 ONTAP が VMFS ファイルシステムを認識しないため、個々の VMDK ファイルには適用できません。VVol を使用する場合は、ストレージ機能プロファイルと VM ストレージポリシーを使用して、個々の VM に最小 QoS と最大 QoS を設定できます。</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">オブジェクトに対する QoS の最大スループット制限は、 MBps と IOPS のいずれかまたは両方で設定できます。両方を使用する場合は、最初に到達した制限が ONTAP によって適用されます。ワークロードには複数のオブジェクトを含めることができ、 QoS ポリシーは 1 つ以上のワークロードに適用できます。ポリシーを複数のワークロードに適用した場合は、ポリシーの制限はワークロード全体に適用されます。ネストされたオブジェクトはサポートされません（たとえば、ボリューム内のファイルには個別のポリシーを設定することはできません）。QoS の最小値は IOPS 単位でのみ設定できます。</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">ONTAP QoS ポリシーの管理とオブジェクトへの適用に現在使用できるツールは次のとおりです。</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">ONTAP CLI</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">ONTAP システムマネージャ</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation のサポートを利用できます</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">NetApp PowerShell Toolkit for ONTAP 』を参照してください</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">VMware vSphere VASA Provider 用の ONTAP ツール</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">NFS 上の VMDK に QoS ポリシーを割り当てる場合は、次のガイドラインに注意してください。</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">ポリシーは 'vmname.vmdk （仮想ディスク記述子ファイル）や 'vmname.vmx （ VM 記述子ファイル）ではなく ' 実際の仮想ディスクイメージを含む 'vmname-flat.vmdk に適用する必要があります</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">仮想スワップ・ファイル（「 vmname.vswp 」）などの他の VM ファイルにはポリシーを適用しないでください。</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">vSphere Web クライアントを使用してファイルパスを検索する場合は、「 -flat.vmdk 」と「」の情報が結合されていることに注意してください。VMDK とは ' という名前のファイルを 1 つだけ示しますVMDK ですが '-flat.vmdk のサイズです正しいパスを取得するには、ファイル名に「 -flat」 を追加します。</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">VMFS と RDM 、 ONTAP SVM （ SVM として表示）、 LUN パス、シリアル番号などの LUN に QoS ポリシーを割り当てるには、 ONTAP Tools for VMware vSphere のホームページのストレージシステムメニューから QoS ポリシーを取得します。ストレージシステム（ SVM ）を選択し、 Related Objects &gt; SAN の順に選択します。この方法は、いずれかの ONTAP ツールを使用して QoS を指定する場合に使用します。</block>
  <block id="8ce0096ff26ebe0a38466de6a64f461d" category="paragraph">VVol ベースの VM には、 VMware vSphere または Virtual Storage Console 7.1 以降の ONTAP ツールを使用して、最大 QoS と最小 QoS を簡単に割り当てることができます。VVol コンテナのストレージ機能プロファイルを作成するときは、パフォーマンス機能の下に最大 IOPS または最小 IOPS の値を指定し、この SCP を VM のストレージポリシーで参照します。このポリシーは VM を作成するときに使用するか、ポリシーを既存の VM に適用します。</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">FlexGroup データストアでは、 ONTAP ツールを VMware vSphere 9.8 以降で使用する場合に、 QoS 機能が強化されています。QoS は、データストア内のすべての VM 、または特定の VM に簡単に設定できます。詳細については、本レポートの「 FlexGroup 」セクションを参照してください。</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">ONTAP の QoS と VMware の SIOC</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">ONTAP の QoS と VMware vSphere の Storage I/O Control （ SIOC ）は、 vSphere 管理者とストレージ管理者が組み合わせて、 ONTAP ソフトウェアを実行するシステムでホストされる vSphere VM のパフォーマンスを管理できる、相互に補完するテクノロジです。各ツールには、次の表に示すようにそれぞれの長所があります。VMware vCenter と ONTAP ではスコープが異なるため、一部のオブジェクトは一方のシステムで認識および管理でき、もう一方のシステムではできません。</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">プロパティ（ Property ）</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">ONTAP QoS</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">VMware SIOC</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">アクティブになっている場合</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">ポリシーは常にアクティブです</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">競合が発生している（データストアのレイテンシがしきい値を超えている）場合</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">単位のタイプ</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS 、 MBps</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS 、共有数</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">対象となる vCenter またはアプリケーション</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">複数の vCenter 環境、その他のハイパーバイザーとアプリケーションがあります</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">単一の vCenter サーバ</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">VM に QoS を設定？</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">NFS 上の VMDK のみ</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">NFS 上または VMFS 上の VMDK です</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">LUN （ RDM ）で QoS を設定？</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">LUN （ VMFS ）への QoS の設定</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">ボリューム（ NFS データストア）への QoS の設定</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">SVM （テナント）に QoS を設定？</block>
  <block id="86aad9b5d177180a5b9e828a8e05e819" category="cell">ポリシーベースのアプローチ</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">はい。ポリシー内のすべてのワークロードで共有することも、ポリシー内の各ワークロードにフルに適用することもできます。</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">はい。 vSphere 6.5 以降が必要です。</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">ライセンスが必要です</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">ONTAP に付属しています</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise Plus</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="section-title">VMware Storage Distributed Resource Scheduler の略</block>
  <block id="06604b0172f4ae639ffe8c44fa7c77d8" category="paragraph">VMware Storage Distributed Resource Scheduler （ SDRS ）は、現在の I/O レイテンシとスペース使用量に基づいて VM をストレージに配置する vSphere の機能です。その後、 VM や VMDK の配置先として最適なデータストアをデータストアクラスタ内から選択し、システムを停止することなくデータストアクラスタ（ポッドとも呼ばれます）内のデータストア間で VM や VMDK を移動します。データストアクラスタとは、類似したデータストアを vSphere 管理者の観点から単一の消費単位に集約したものです。</block>
  <block id="5735cfd4d72f50fd28717ac30361b503" category="paragraph">SDRS を NetApp ONTAP Tools for VMware vSphere と併用する場合は、まずプラグインを使用してデータストアを作成し、 vCenter を使用してデータストアクラスタを作成し、そこにデータストアを追加する必要があります。データストアクラスタを作成したら、プロビジョニングウィザードの詳細ページからデータストアクラスタにデータストアを直接追加できます。</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">SDRS に関するその他の ONTAP のベストプラクティスは、次のとおりです。</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">クラスタ内のすべてのデータストアで同じタイプのストレージ（ SAS 、 SATA 、 SSD など）を使用し、すべて VMFS データストアまたは NFS データストアとし、レプリケーションと保護の設定を同じにします。</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">デフォルト（手動）モードでは SDRS の使用を検討してください。このアプローチでは、推奨事項を確認し、適用するかどうかを決定できます。VMDK の移行による影響を次に示します。</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">SDRS がデータストア間で VMDK を移動すると、 ONTAP のクローニングや重複排除によるスペース削減効果は失われます。重複排除機能を再実行すれば、削減効果を取り戻すことができます。</block>
  <block id="cc1aa351f771fc36d1542fa93e1fac8e" category="list-text">SDRS で VMDK を移動したあとに、移動された VM によってスペースがロックされないように、ソースデータストアで Snapshot コピーを再作成することを推奨します。</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">同じアグリゲート上のデータストア間で VMDK を移動してもメリットはほとんどなく、 SDRS はアグリゲートを共有する可能性のある他のワークロードを可視化できません。</block>
  <block id="a30850531baecbfbe4486d4be9e79e30" category="section-title">ストレージポリシーベースの管理と VVOL</block>
  <block id="f2606439d8a3fed353e38254458c0a32" category="paragraph">VMware vSphere APIs for Storage Awareness （ VASA ）を使用すると、ストレージ管理者は、明確に定義された機能を使用してデータストアを簡単に設定でき、 VM 管理者は、相互にやり取りすることなく、いつでも VM をプロビジョニングするためのこれらの機能を使用できます。仮想化ストレージの運用を合理化し、複雑な作業を回避する方法を確認するには、このアプローチを検討することをお考えください。</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">VASA が導入される前は、 VM 管理者が VM ストレージポリシーを定義することもできましたが、適切なデータストアを特定するには、多くの場合、ドキュメントや命名規則を使用する必要がありました。VASA を使用すると、ストレージ管理者は、パフォーマンス、階層化、暗号化、レプリケーションなど、さまざまなストレージ機能を定義できます。1 つのボリュームまたはボリュームセットの一連の機能を、ストレージ機能プロファイル（ SCP ）と呼びます。</block>
  <block id="a3af04d147e48682c8be6bd0c1b66520" category="paragraph">SCP は、 VM のデータ VVOL の最小および最大 QoS をサポートします。最小 QoS は AFF システムでのみサポートされます。VMware vSphere 用の ONTAP ツールには、 ONTAP システム上の VVOL の VM の詳細なパフォーマンスと論理容量を表示するダッシュボードがあります。</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">次の図は、 VMware vSphere 9.8 VVol ダッシュボード用の ONTAP ツールを示しています。</block>
  <block id="d3fcb217aa8b45eb8a95f8958c1f7746" category="paragraph"><block ref="d3fcb217aa8b45eb8a95f8958c1f7746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6257d346f635c1b16a2f39df0830a48" category="paragraph">ストレージ機能プロファイルを定義したら、そのプロファイルを使用して要件を定義するストレージポリシーを使用して VM をプロビジョニングできます。vCenter では、 VM ストレージポリシーとデータストアストレージ機能プロファイルのマッピングに基づいて、互換性があるデータストアのリストを選択対象として表示できます。この方法のことをストレージポリシーベースの管理と呼びます。</block>
  <block id="ca100a4ba1d4641f17806479f93c8b1a" category="paragraph">VASA は、ストレージを照会して一連のストレージ機能を vCenter に返すためのテクノロジを提供します。VASA ベンダープロバイダは、ストレージシステムの API およびコンストラクトと、 vCenter が認識可能な VMware API との間の変換機能を提供します。ネットアップの VASA プロバイダ for ONTAP は、 VMware vSphere アプライアンス VM 用の ONTAP ツールの一部として提供されます。 vCenter プラグインは、 VVol データストアのプロビジョニングと管理のインターフェイスと、ストレージ機能プロファイル（ SCP ）の定義機能を提供します。</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="79f0d5feb7ec25a16c407f3f585eabb2" category="paragraph">ONTAP は、 VMFS データストアと NFS データストアの両方をサポートしています。SAN データストアで VVOL を使用すると、 VM レベルのきめ細かさなど、 NFS のメリットの一部を活用できます。ここでは考慮すべきベストプラクティスをいくつか示します。また、追加情報はにあります<block ref="4f23d4db151ca74200684ac8aef53fed" category="inline-link-rx"></block>：</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">VVOL データストアは、複数のクラスタノードにある複数の FlexVol で構成できます。ボリュームごとに機能が異なる場合でも、最もシンプルなアプローチは 1 つのデータストアです。SPBM により、互換性のあるボリュームが VM に使用されています。ただし、すべてのボリュームが 1 つの ONTAP SVM に含まれていて、単一のプロトコルでアクセスできる必要があります。各プロトコルでノードごとに 1 つの LIF で十分です。1 つの VVOL データストアで複数の ONTAP リリースを使用することは避けてください。リリースによってストレージ機能が異なる場合があります。</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">VVol データストアの作成と管理には、 VMware vSphere プラグインの ONTAP ツールを使用します。データストアとそのプロファイルの管理に加え、必要に応じて、 VVOL にアクセスするためのプロトコルエンドポイントが自動的に作成されます。LUN を使用する場合、 LUN PE は 300 以上の LUN ID を使用してマッピングされます。ESXi ホストの詳細システム設定「 Disk .MaxLUN 」で 300 より大きい LUN ID 番号が許可されていることを確認します（デフォルトは 1 、 024 ）。この手順を実行するには、 vCenter で ESXi ホストを選択し、次に Configure タブを選択して、 Advanced System Settings のリストから「 Disk .MaxLUN 」を探します。</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">VASA Provider 、 vCenter Server （アプライアンスまたは Windows ベース）、または VMware vSphere 用の ONTAP ツールは相互に依存するため、 VVOL データストアにインストールしたり移行したりしないでください。これらのツールは、停電やその他のデータセンターの停止が発生した場合に管理しなくなるためです。</block>
  <block id="27bd00c8827fc3d77d1b5650103b676f" category="list-text">VASA Provider VM を定期的にバックアップします。VASA Provider が格納された従来のデータストアの Snapshot コピーを少なくとも 1 時間に 1 回は作成してください。VASA Provider の保護とリカバリの詳細については、こちらを参照してください<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>。</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">次の図は、 VVOL のコンポーネントを示しています。</block>
  <block id="6aadcb77504dae1dbfed2e4d1c969158" category="paragraph"><block ref="6aadcb77504dae1dbfed2e4d1c969158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">クラウドへの移行とバックアップ</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">ONTAP のもう 1 つの強みは、ハイブリッドクラウドを幅広くサポートすることで、オンプレミスのプライベートクラウドのシステムとパブリッククラウドの機能を統合できることです。vSphere と組み合わせて使用できるネットアップのクラウドソリューションには、次のものがあります。</block>
  <block id="67464b4510c09197c8a5e16ba6702435" category="list-text">* Cloud Volume 。 * NetApp Cloud Volumes Service for AWS または GCP と Azure NetApp Files for ANF は、主要なパブリッククラウド環境でハイパフォーマンスなマルチプロトコルマネージドストレージサービスを提供します。VMware Cloud VM ゲストで直接使用できます。</block>
  <block id="0ac7b95ec26051fb8842ae35427ecc22" category="list-text">* Cloud Volumes ONTAP 。 * NetApp Cloud Volumes ONTAP データ管理ソフトウェアは、お客様が選択したクラウド上のデータを管理、保護、柔軟性、効率性で保護します。Cloud Volumes ONTAP は、 NetApp ONTAP ストレージソフトウェアを基盤としたクラウドネイティブのデータ管理ソフトウェアです。Cloud Volumes ONTAP インスタンスをオンプレミスの ONTAP システムと一緒に導入、管理する際には、 Cloud Manager と組み合わせて使用できます。NAS および iSCSI SAN の高度な機能に加え、 Snapshot コピーや SnapMirror レプリケーションなどの統合データ管理機能も利用できます。</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">* Cloud Backup Service * 。クラウドサービスまたは SnapMirror クラウドを使用して、パブリッククラウドストレージを使用してオンプレミスシステムからデータを保護します。Cloud Sync を使用すると、 NAS 、オブジェクトストア、 Cloud Volumes Service ストレージ間でデータを移行し、同期を維持できます。</block>
  <block id="fa9b5353337118a51ced7968bccc02a0" category="inline-link">より多くの VM Snapshot コピーを格納する</block>
  <block id="c79f1f00e1e3c8f100e8604eec888859" category="list-text">* ONTAP * FabricPool は、 FabricPool データの階層化を迅速かつ容易にします。Snapshot コピーのコールドブロックは、パブリッククラウドまたはプライベート StorageGRID オブジェクトストアのオブジェクトストアに移行でき、 ONTAP データが再びアクセスされると自動的にリコールされます。または、 SnapVault ですでに管理されているデータの第 3 レベルの保護としてオブジェクト階層を使用することもできます。この方法を使用すると、を実行できます<block ref="1d0add9d2d81e2d7e790f727021e53aa" category="inline-link-rx"></block> プライマリおよびセカンダリ ONTAP ストレージシステム。</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">* ONTAP Select * 。ネットアップの Software-Defined Storage を使用して、インターネット経由でプライベートクラウドをリモートの施設やオフィスに拡張できます。 ONTAP Select を使用すれば、ブロックサービスやファイルサービスのほか、エンタープライズデータセンターと同じ vSphere データ管理機能をサポートできます。</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">VM ベースのアプリケーションを設計する際は、将来のクラウドのモビリティを考慮してください。たとえば、アプリケーションファイルとデータファイルを一緒に配置するのではなく、データ用に別の LUN または NFS エクスポートを使用します。これにより、 VM とデータを別々にクラウドサービスに移行できます。</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">vSphere データの暗号化</block>
  <block id="eb969673f581d94df982f8e2a6001f30" category="paragraph">現在、保管データを暗号化で保護する必要性はますます高まっています。最初は財務情報と医療情報に重点を置いていましたが、ファイル、データベース、その他の種類のデータに保存されているすべての情報を保護することに関心が高まっています。</block>
  <block id="77652ecf0c76f1d4194171dc720320be" category="paragraph">ONTAP ソフトウェアを実行するシステムでは、保存データの暗号化を使用してあらゆるデータを簡単に保護できます。NetApp Storage Encryption （ NSE ）は、 ONTAP を備えた自己暗号化ディスクドライブを使用して、 SAN と NAS のデータを保護します。また、 NetApp Volume Encryption と NetApp Aggregate Encryption も、シンプルなソフトウェアベースの手法として、ディスクドライブ上のボリュームを暗号化します。このソフトウェア暗号化は、特殊なディスクドライブや外部キー管理ツールを必要とせず、 ONTAP のお客様は追加料金なしで利用できます。クライアントやアプリケーションを停止することなくアップグレードして使用を開始でき、オンボードキーマネージャなどの FIPS 140-2 レベル 1 標準で検証されます。</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">VMware vSphere 上で実行される仮想アプリケーションのデータを保護する方法はいくつかあります。1 つは、 VM 内のソフトウェアをゲスト OS レベルで使用してデータを保護する方法です。別の方法として、 vSphere 6.5 などの新しいハイパーバイザーでは VM レベルの暗号化がサポートされるようになりました。ただし、ネットアップのソフトウェア暗号化はシンプルで使いやすく、次のようなメリットがあります。</block>
  <block id="92fbd315c4413db381567a775570b78c" category="list-text">* 仮想サーバの CPU には影響しません。 * 仮想サーバ環境によっては、アプリケーションに使用可能なすべての CPU サイクルが必要ですが、ハイパーバイザーレベルの暗号化では最大 5 倍の CPU リソースが必要です。暗号化ソフトウェアがインテルの AES-NI 命令セットをサポートして暗号化ワークロードをオフロードしている場合でも（ NetApp ソフトウェアの暗号化がサポートされているため）、古いサーバと互換性のない新しい CPU の要件が原因でこのアプローチが実現できない場合があります。</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">* オンボードキーマネージャを含む。 * ネットアップのソフトウェア暗号化機能には、追加料金なしでオンボードキーマネージャが含まれているため、購入や使用が複雑な高可用性キー管理サーバなしで簡単に利用を開始できます。</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">* ストレージ効率への影響はありません。 * 重複排除や圧縮などの Storage Efficiency テクノロジは現在広く使用されており、フラッシュディスクメディアをコスト効率よく使用する上で鍵となります。ただし、一般に、暗号化されたデータは重複排除も圧縮もできません。ネットアップのハードウェアとストレージの暗号化は下位レベルで動作し、他のアプローチとは異なり、業界をリードするネットアップの Storage Efficiency 機能を最大限に活用できます。</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">* データストアのきめ細かい暗号化が容易。 * NetApp Volume Encryption を使用すると、各ボリュームに専用の AES 256 ビットキーが設定されます。変更が必要な場合は、 1 つのコマンドで変更できます。このアプローチは、テナントが複数ある場合や、さまざまな部門やアプリケーションに対して個別に暗号化を証明する必要がある場合に適しています。この暗号化はデータストアレベルで管理されるため、個々の VM の管理よりもはるかに簡単です。</block>
  <block id="088124cfa6d59c647e63177c5a4af318" category="paragraph">ソフトウェアの暗号化を簡単に開始できます。ライセンスのインストールが完了したら、パスフレーズを指定してオンボードキーマネージャを設定し、新しいボリュームを作成するかストレージ側のボリューム移動を実行して暗号化を有効にします。ネットアップでは、 VMware ツールの今後のリリースで、暗号化機能のサポートをさらに統合する予定です。</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager を使用すると、仮想インフラ内の VM を可視化し、仮想環境内のストレージやパフォーマンスの問題を監視してトラブルシューティングすることができます。</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">ONTAP の一般的な仮想インフラ環境には、さまざまなコンポーネントがコンピューティングレイヤ、ネットワークレイヤ、ストレージレイヤに分散して配置されています。VM アプリケーションのパフォーマンス低下は、各レイヤのさまざまなコンポーネントでレイテンシが生じていることが原因である可能性があります。</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">次のスクリーンショットは、 Active IQ Unified Manager の仮想マシンビューを示しています。</block>
  <block id="8aa017c9f67ad32dd7301ecf52b61d72" category="paragraph"><block ref="8aa017c9f67ad32dd7301ecf52b61d72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager のトポロジビューには、仮想環境の基盤となるサブシステムが表示され、コンピューティングノード、ネットワーク、またはストレージでレイテンシ問題が発生したかどうかが確認されます。また、修復手順を実行して基盤となる問題に対応するために、パフォーマンス低下の原因となっているオブジェクトが強調表示されます。</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">次のスクリーンショットは、 AIQUM の拡張トポロジを示しています。</block>
  <block id="e9659be2b7d3d69eccdb443ed2acec75" category="paragraph"><block ref="e9659be2b7d3d69eccdb443ed2acec75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d336a329d910c32fb90337a372f596fc" category="summary">NetApp ONTAP ソフトウェアは、 VMware vSphere 環境向けのストレージ解決策を約 20 年にわたって業界をリードしてきました。また、コストを削減しながら管理を簡易化する革新的な機能を継続的に追加しています。このドキュメントでは、導入の合理化、リスクの軽減、管理の簡易化を実現するために、最新の製品情報とベストプラクティスを含む ONTAP 解決策 for vSphere について説明します。</block>
  <block id="952fd691754e388c7b7ba473cf410aff" category="doc">TR-4597 ：『 VMware vSphere for ONTAP 』</block>
  <block id="b4191f5f6b40e39be6030dbbc9052330" category="paragraph">ネットアップ Karl Konnerth</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">ベストプラクティスは、ガイドや互換性リストなどの他のドキュメントを補うものです。ラボテストに基づいて開発されており、ネットアップのエンジニアやお客様は広範な現場経験を積んでいます。すべての環境で機能する唯一のサポート対象となるわけではありませんが、一般に、ほとんどのお客様のニーズを満たす最もシンプルなソリューションです。</block>
  <block id="737453909be77692f8cfdf08a17cee61" category="inline-link-macro">ONTAP および vSphere のリリース固有の情報</block>
  <block id="18b198d3d2381f05dd78bab3c8cec60c" category="paragraph">本ドキュメントでは、 vSphere 6.0 以降で実行される最近のリリースの ONTAP （ 9.x ）の機能について説明します。を参照してください <block ref="4c9a6d8ccb9dfca3b5ae6e43e9663c99" category="inline-link-macro-rx"></block> 特定のリリースに関する詳細については、を参照してください。</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">ONTAP for vSphere を選ぶ理由</block>
  <block id="4b401b0a40ae220c77961312c8238cdb" category="paragraph">数万人のお客様が、 SAN と NAS の両方のプロトコルをサポートするユニファイドストレージシステム、スペース効率に優れたネットアップの Snapshot コピーを使用した堅牢なデータ保護機能など、 vSphere のストレージ解決策として ONTAP を選択した理由は数多くあります。 アプリケーションデータの管理に役立つ豊富なツールを備えています。ハイパーバイザーとは別のストレージシステムを使用すると、さまざまな機能をオフロードして、 vSphere ホストシステムへの投資を最大限に活用できます。このアプローチにより、ホストリソースをアプリケーションワークロードに集中できるだけでなく、ストレージ運用によるアプリケーションのランダムなパフォーマンスへの影響も回避できます。</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">vSphere と ONTAP を併用すると、ホストハードウェアと VMware ソフトウェアのコストを削減できます。また、一貫した高パフォーマンスを維持しながら、低コストでデータを保護することもできます。仮想化されたワークロードはモバイル対応であるため、 Storage vMotion を使用して、 VMFS 、 NFS 、または VVOL データストア間で VM を移動するさまざまなアプローチを、すべて同じストレージシステム上で検討できます。</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">お客様が現在重視している主な要因は次のとおりです。</block>
  <block id="dc4489aacb3c4d74b8253c49732b73e9" category="list-text">* ユニファイド・ストレージ。 * ONTAP ソフトウェアを実行するシステムは、いくつかの重要な方法で統合されています。当初、このアプローチは NAS プロトコルと SAN プロトコルの両方を指していましたが、 ONTAP は業界をリードする SAN プラットフォームであり続けており、 NAS における従来の強みもあります。vSphere 環境では、このアプローチは仮想デスクトップインフラ（ VDI ）向けのユニファイドシステムと仮想サーバインフラ（ VSI ）の組み合わせを意味する場合もあります。ONTAP ソフトウェアを実行するシステムは一般に、従来のエンタープライズアレイに比べて VSI の方が安価ですが、同じシステムで VDI を処理するための高度な Storage Efficiency 機能も備えています。また、 ONTAP は、 SSD から SATA までさまざまなストレージメディアを統合し、クラウドへの拡張を容易にします。パフォーマンスのためにフラッシュアレイを 1 台、アーカイブ用の SATA アレイ、クラウド用のシステムを 1 台購入する必要はありません。ONTAP は、これらすべてを 1 つにまとめます。</block>
  <block id="ec8cd066c60323f007135b1f083b64de" category="list-text">* 仮想ボリュームとストレージポリシーベースの管理。 * ネットアップは、 vSphere Virtual Volumes （ VVol ）の開発において VMware との早期設計パートナーであり、アーキテクチャに関する情報提供と、 VVol および VMware vSphere APIs for Storage Awareness （ VASA ）の早期サポートを提供しています。このアプローチにより、きめ細かな VM ストレージ管理が VMFS にもたらされるだけでなく、ストレージポリシーベースの管理によるストレージプロビジョニングの自動化もサポートされています。このアプローチにより、ストレージアーキテクトは、 VM 管理者が簡単に利用できるさまざまな機能を備えたストレージプールを設計できます。ONTAP は VVOL 規模でストレージ業界をリードし、 1 つのクラスタで数十万もの VVol をサポートします。一方、エンタープライズアレイや小規模なフラッシュアレイベンダーは、アレイあたり数千の VVol をサポートします。ネットアップは、 VVOL 3.0 のサポートに向けて、今後追加される機能で、きめ細かな VM 管理の進化も推進しています。</block>
  <block id="fd5311fb87e61b58d3c3d278df26af4f" category="list-text">* ストレージ効率。 * ネットアップは、本番環境のワークロードに重複排除を提供した最初のベンダーでしたが、この分野の最初または最後のイノベーションではありませんでした。まずは、パフォーマンスに影響を与えない、スペース効率に優れたデータ保護メカニズムである ONTAP Snapshot コピーと、本番環境やバックアップ用に VM の読み取り / 書き込みコピーを瞬時に作成する FlexClone テクノロジからスタートしました。ネットアップは、重複排除、圧縮、ゼロブロック重複排除などのインライン機能を提供し、高価な SSD のストレージを最後まで絞ります。ONTAP は最近、圧縮機能を使用して、より小さな I/O 処理とファイルをディスクブロックに圧縮する機能を追加しました。これらの機能を組み合わせることで、 VSI では最大 5 分の 1 、 VDI では最大 30 分の 1 のコストを削減できました。</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">* ハイブリッド・クラウド。 * オンプレミスのプライベート・クラウド、パブリック・クラウド・インフラストラクチャー、または両方の利点を組み合わせたハイブリッド・クラウドのいずれに使用しても、 ONTAP ソリューションはデータ管理を合理化し、最適化するためのデータ・ファブリックの構築を支援します。まずハイパフォーマンスのオールフラッシュシステムを導入し、データ保護とクラウドコンピューティングのためにディスクストレージシステムとクラウドストレージシステムのどちらかと組み合わせます。Azure 、 AWS 、 IBM 、 Google のクラウドから選択して、コストを最適化し、ロックインを回避できます。必要に応じて、 OpenStack とコンテナテクノロジの高度なサポートを活用できます。ネットアップ ONTAP では、クラウドベースのバックアップ（ SnapMirror クラウド、 Cloud Backup Service 、 Cloud Sync ）やストレージ階層化 / アーカイブツール（ FabricPool ）も提供しており、運用コストの削減とクラウドの幅広いリーチの活用を支援します。</block>
  <block id="0c157ce4e4fd6289dbf0b282993c2f80" category="list-text">* その他。 * NetApp AFF A シリーズアレイの卓越したパフォーマンスを活用して、コストを管理しながら仮想インフラを高速化できます。スケールアウト ONTAP クラスタを使用して、ストレージシステムのメンテナンスからアップグレード、完全な交換まで、完全なノンストップオペレーションを実現します。ネットアップの暗号化機能を追加コストなしで使用して、保存データを保護できます。きめ細かいサービス品質機能により、パフォーマンスがビジネスサービスレベルを満たしていることを確認します。これらはすべて、業界をリードするエンタープライズデータ管理ソフトウェアである ONTAP に付属する幅広い機能の一部です。</block>
  <block id="7be2e69e5d19c282db8d81c60a51c862" category="summary">このページでは、 VMware vSphere 環境に NetApp ONTAP ストレージ解決策を実装するためのベストプラクティスについて説明します。</block>
  <block id="ff53ee8001042abcefe5c912d0b5012f" category="section-title">vSphere のデータストアとプロトコルの機能</block>
  <block id="7a787d6880ccfe1032af2f4288ce3901" category="paragraph">VMware vSphere と ONTAP ソフトウェアを実行しているシステム上のデータストアの接続には、次の 5 つのプロトコルが使用されます。</block>
  <block id="6b8f0029ce30f9b4d5fe0def33875511" category="list-text">FC</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="list-text">iSCSI</block>
  <block id="cbc9a42283809f1edcb32b4a495813f9" category="paragraph">FC 、 FCoE 、 NVMe/FC 、および iSCSI はブロックプロトコルで、 vSphere Virtual Machine File System （ VMFS ）を使用して、 ONTAP ボリューム内の ONTAP LUN またはネームスペースに VM を格納します。vSphere 7.0 以降では、 VMware は本番環境でのソフトウェア FCoE をサポートしなくなりました。NFS はファイルプロトコルで、 VM をデータストア（ ONTAP ボリューム）に配置し、 VMFS を必要としません。SMB 、 iSCSI 、 NFS は、ゲスト OS から ONTAP に直接使用することもできます。</block>
  <block id="0f2f72ef3f176b98134caf100a06cf5f" category="inline-link">VMware 構成の最大数</block>
  <block id="6a6d2374b838393f6805b58d97c2c490" category="paragraph">以下の表に、 vSphere でサポートされる従来のデータストア機能と ONTAP を示します。この情報は VVOL データストアには該当しませんが、通常は、サポートされている ONTAP リリースを使用する環境 vSphere 6.x および 7.x リリースには該当します。を参照することもできます<block ref="26c5407c98ec413c85131fd8c0d178b4" category="inline-link-rx"></block> 個々の vSphere リリースに固有の制限を確認するため。</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">機能 / 特徴</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC / FCoE</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">の形式で入力し</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">VMFS または raw デバイスマッピング（ RDM ）</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS または RDM</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">データストアまたは LUN の最大数</block>
  <block id="468abcddfc22ae5cb2288b9937b300fb" category="cell">256 ターゲット / HBA</block>
  <block id="72097e262592a146da0e4e856068965b" category="cell">256 個のターゲット</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256 でデフォルトの NFS がマウントされます。MaxVolumes は 8 です。VMware vSphere 用の ONTAP ツールを使用して 256 まで増やす。</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">データストアの最大サイズ</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64TB</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">100TB 以上の FlexVol ボリュームと FlexGroup ボリューム</block>
  <block id="a4b27c6cd629522064dc48306e2bf8bb" category="cell">データストアの最大ファイルサイズ （ vSphere バージョン 5.5 および VMFS 5 またはを使用する VMDK 用 以降）</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62TB</block>
  <block id="ddf38e51732c3f7da57dc13c31a5483b" category="cell">vSphere でサポートされる最大サイズは 16TB 62TB です。</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">LUN またはファイルシステムごとのキューの深さの最適値</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">次の表に、サポートされる VMware ストレージ関連機能を示します。</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">容量 / 機能</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">vMotion</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">Storage vMotion の機能です</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">VMware HA</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">ストレージ分散リソーススケジューラ（ SDRS ）</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">VMware vStorage APIs for Data Protection （ VADP ）対応のバックアップソフトウェア</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">VM 内の Microsoft Cluster Service （ MSCS ）またはフェイルオーバークラスタリング</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">はい *</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">サポート対象外</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">フォールトトレランス</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">Site Recovery Manager の略</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">シンプロビジョニングされた VM （仮想ディスク）</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">はい VAAI を使用しない場合、 NFS 上のすべての VM に対してこの設定がデフォルトです。</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">VMware 標準マルチパス</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Windows Server フェールオーバークラスタリングのセットアップ</block>
  <block id="547211ca8a6b93fee863925a03cd341b" category="paragraph">* VMFS データストア内でマルチライター対応の VMDK を使用する代わりに、 Microsoft クラスタにゲスト内 iSCSI を使用することを推奨します。このアプローチは Microsoft と VMware によって完全にサポートされており、 ONTAP （オンプレミスまたはクラウドの ONTAP システムへの SnapMirror ）を使用した優れた柔軟性、設定と自動化が容易で、 SnapCenter で保護できます。vSphere 7 で、新しいクラスタ化された VMDK オプションが追加されました。これは、マルチライター対応の VMDK とは異なりますが、クラスタ化された VMDK をサポートする FC プロトコル経由で提供されるデータストアが必要です。その他の制限が適用されます。「 VMware 」を参照してください<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> 設定ガイドラインについては、ドキュメントを参照してください</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">次の表に、サポートされる ONTAP ストレージ管理機能を示します。</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">データ重複排除</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">アレイ内での容量削減</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">データストア内での容量削減</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">シンプロビジョニング</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">データストアまたは RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">データストア</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">データストアのサイズを変更</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">拡張のみ</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">拡張、自動拡張、縮小</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Windows 、 Linux アプリケーション用の SnapCenter プラグイン（ゲスト内）</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">VMware vSphere 用の ONTAP ツールを使用した監視とホストの設定</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">VMware vSphere 用の ONTAP ツールを使用したプロビジョニング</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">次の表に、サポートされるバックアップ機能を示します。</block>
  <block id="1208a2df45bea7d2edea13f0b0cbc686" category="cell">ONTAP の Snapshot コピー</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">複製バックアップでサポートされる SRM</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">Volume SnapMirror の略</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">VMDK イメージアクセス</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">VADP 対応のバックアップソフトウェア</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">VADP 対応のバックアップソフトウェア、 vSphere Client 、 vSphere Web Client データストアブラウザ</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">VMDK のファイルレベルアクセス</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">VADP 対応のバックアップソフトウェア、 Windows のみ</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">VADP 対応のバックアップソフトウェアとサードパーティ製アプリケーション</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">NDMP の単位</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">データストアまたは VM</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">ストレージプロトコルを選択</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">ONTAP ソフトウェアを実行するシステムは、主要なストレージプロトコルをすべてサポートしているため、既存および計画されているネットワークインフラやスタッフのスキルに応じて、お客様は環境に最適なものを選択できます。ネットアップのテストでは、一般に、ほぼ同じ速度の回線で実行されているプロトコル間の違いはほとんど見られませんでした。そのため、物理プロトコルのパフォーマンスよりもネットワークインフラとスタッフの能力に重点を置くことを推奨します。</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">プロトコルの選択を検討する際には、次の要素が役立ちます。</block>
  <block id="c0ab9c6170165211885267a562d057a2" category="list-text">* 現在のお客様の環境。 * 一般に、 IT チームはイーサネット IP インフラの管理のスキルを持っていますが、すべてのチームが FC SAN ファブリックの管理のスキルを持っているわけではありません。ただし、ストレージトラフィック用に設計されていない汎用 IP ネットワークを使用すると、うまく機能しない場合があります。現在利用しているネットワークインフラストラクチャ、計画的な改善点、およびそれらを管理するためのスタッフのスキルと可用性を考慮します。</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">* セットアップの容易さ * FC ファブリックの初期構成（追加のスイッチとケーブル配線、ゾーニング、 HBA とファームウェアの相互運用性の検証）に加えて、ブロックプロトコルを使用するには、 LUN の作成とマッピング、ゲスト OS による検出とフォーマットも必要です。作成およびエクスポートされた NFS ボリュームは、 ESXi ホストによってマウントされ、使用可能な状態になります。NFS では、ハードウェアの認定や管理に関する特別なファームウェアはありません。</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">* 管理の容易さ。 * SAN プロトコルでは、より多くのスペースが必要な場合、 LUN の拡張、新しいサイズの検出のための再スキャン、ファイルシステムの拡張など、いくつかの手順が必要です。LUN の拡張は可能ですが、 LUN のサイズを縮小することはできず、未使用スペースのリカバリには追加の作業が必要になる場合があります。NFS を使用すると、簡単なサイジングが可能です。このサイズ変更は、ストレージシステムで自動化できます。SAN では、ゲスト OS のトリム / マッピング解除コマンドを使用してスペース再生が可能で、削除されたファイルのスペースをアレイに戻すことができます。NFS データストアでは、このようなスペース再生がより困難になります。</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">* ストレージスペースの透過性。 * シンプロビジョニングによって削減効果が即座に現れるため、 NFS 環境では一般にストレージ利用率が見やすくなります。同様に、重複排除とクローニングによる削減効果は、同じデータストア内の他の VM や他のストレージシステムボリュームで即座に利用できます。一般に、 VM の密度は NFS データストア内でも高くなります。管理するデータストアが少ないため、重複排除による削減効果が向上すると同時に管理コストも削減されます。</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">データストアのレイアウト</block>
  <block id="066ed1c180617b2f9028c1f789078de4" category="paragraph">ONTAP ストレージシステムは、 VM および仮想ディスク用のデータストアを柔軟に作成できます。を使用する場合、 ONTAP の多くのベストプラクティスが適用されますが vSphere 用のデータストアをプロビジョニングする VSC （を参照） <block ref="311a0f5ed21de3c81d57d9c08f2ace49" category="inline-link-macro-rx"></block>) 、考慮すべきその他のガイドラインを次に示します。</block>
  <block id="73ab3808ccb313675f9b890edf67fd09" category="list-text">ONTAP NFS データストアを使用して vSphere を導入することで、高性能でありながら管理が容易な実装を実現でき、ブロックベースのストレージプロトコルでは達成できない VM / データストア比率が提供されます。このアーキテクチャでは、データストア密度を 10 倍に増やすことも可能で、それに伴いデータストアの数は減少します。データストアのサイズを大きくするとストレージ効率が向上し、運用上のメリットが得られますが、ハードウェアリソースのパフォーマンスを最大限に引き出すためには、少なくとも 4 つのデータストア（ FlexVol ボリューム）を使用して 1 つの ONTAP コントローラに VM を格納することを検討してください。また、異なるリカバリポリシーを使用してデータストアを確立することもできます。ビジネスニーズに応じて、他のバックアップやレプリケーションの頻度を増やすことができます。設計に応じて拡張できるため、 FlexGroup ボリュームで複数のデータストアを使用する必要はありません。</block>
  <block id="68281e9d236ee27e21f68ce5838462f1" category="list-text">FlexVol ボリューム、および ONTAP 9.8 以降の FlexGroup ボリューム、 NFS データストアの使用を推奨します。VMware vSphere 用の ONTAP ツールでは現在サポートされていないため、 qtree などの他の ONTAP ストレージコンテナの使用は一般に推奨されません。データストアレベルのクォータや VM ファイルクローンの恩恵を受ける高度に自動化された環境では、 1 つのボリューム内の複数の qtree としてデータストアを導入すると便利です。</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">FlexVol ボリュームデータストアの適切なサイズは 4~8TB です。このサイズは、パフォーマンス、管理のしやすさ、データ保護のバランスが取れた適切なサイズです。小規模構成から開始して（ 4TB など）、必要に応じてデータストアを拡張します（最大 100TB まで）。小規模なデータストアは、バックアップや災害からのリカバリにかかる時間が短く、クラスタ間で迅速に移動できます。使用済みスペースの変化に応じてボリュームを自動的に拡張または縮小するには、 ONTAP のオートサイズを使用することを検討してください。VMware vSphere データストアプロビジョニングウィザードの ONTAP ツールでは、新しいデータストアに対してデフォルトでオートサイズが使用されます。拡張および縮小のしきい値と最大および最小サイズは、 System Manager またはコマンドラインを使用して追加でカスタマイズできます。</block>
  <block id="12346208f1923ebe162c32f3c4ccf23a" category="list-text">または、 VMFS データストアを、 FC 、 iSCSI または FCoE でアクセスする LUN で構成することもできます。VMFS を使用すると、クラスタ内の各 ESX サーバから同時に従来型の LUN にアクセスすることができます。VMFS データストアは、最大 64TB まで拡張でき、最大 32 個の 2TB LUN （ VMFS 3 ）または単一の 64TB LUN （ VMFS 5 ）で構成できます。ONTAP の最大 LUN サイズは、ほとんどのシステムで 16TB で、すべての SAN アレイシステムで 128TB です。したがって、ほとんどの ONTAP システムでは、最大サイズの VMFS 5 データストアを、 4 つの 16TB LUN を使用して作成できます。複数の LUN （ハイエンドの FAS または AFF システムを使用）で構成される高 I/O ワークロードではパフォーマンス上のメリットがありますが、このメリットは、データストア LUN の作成、管理、保護の複雑さが増し、可用性のリスクが高まることによって相殺されます。ネットアップでは、通常、各データストアに 1 つの大きな LUN を使用し、 16TB を超えるデータストアを追加する必要がある場合にのみスパンすることを推奨しています。NFS と同様に、複数のデータストア（ボリューム）を使用することで、 1 台の ONTAP コントローラのパフォーマンスを最大化することを検討してください。</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">古いゲストオペレーティングシステム（ OS ）では、パフォーマンスとストレージ効率を最大化するために、ストレージシステムとのアライメントが必要でした。しかし、 Microsoft や Linux ディストリビュータ（ Red Hat など）が提供する、ベンダーがサポートする最新の OS では、ファイルシステムのパーティションを仮想環境の基盤となるストレージシステムのブロックにアライメントするように調整する必要はありません。アライメントが必要な古い OS を使用している場合は、ネットアップサポートの技術情報で「 VM のアライメント」に関する記事を検索するか、ネットアップの営業担当者またはパートナー担当者に TR-3747 のコピーを請求してください。</block>
  <block id="3c8b400142a84af9ebe6262bce512ccb" category="list-text">パフォーマンス上のメリットはなく、ストレージ効率と Snapshot コピーのスペース使用量にも影響するため、ゲスト OS でのデフラグユーティリティの使用は避けてください。また、仮想デスクトップのゲスト OS で検索インデックスを無効にすることを検討してください。</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP は、革新的な Storage Efficiency 機能で業界をリードし、使用可能なディスクスペースを最大限に活用できるようにしています。AFF システムでは、デフォルトのインライン重複排除機能と圧縮機能により、この効率性がさらに向上しています。データはアグリゲート内のすべてのボリュームにわたって重複排除されるため、類似するオペレーティングシステムやアプリケーションを 1 つのデータストア内にまとめて、最大限の削減効果を得る必要はありません。</block>
  <block id="154cd001dd3ef8eabdf209f4faf2ddde" category="inline-link">TR-3633 ：『 Data ONTAP を基盤にした Oracle データベース』 Data ONTAP</block>
  <block id="8f2f733fd8f32e7aaa1ee62e48a55117" category="list-text">場合によっては、データストアが不要なこともあります。パフォーマンスと管理性を最大限に高めるためには、データベースや一部のアプリケーションなどの高 I/O アプリケーションにはデータストアを使用しないでください。代わりに、ゲストが管理する NFS や iSCSI ファイルシステムなど、ゲスト所有のファイルシステムや RDM を使用することを検討してください。アプリケーションに関する具体的なガイダンスについては、ご使用のアプリケーションに関するネットアップのテクニカルレポートを参照してください。例：<block ref="8cb1dd6561aaa08584e14e742f429a3e" category="inline-link-rx"></block> 仮想化に関するセクションと役立つ詳細情報が記載されています。</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">第 1 クラスのディスク（または強化された仮想ディスク）を使用すると、 vSphere 6.5 以降を搭載した VM に関係なく、 vCenter で管理されるディスクを使用できます。主に API で管理されますが、 VVol では特に OpenStack ツールや Kubernetes ツールで管理する場合に便利です。ONTAP および VMware vSphere 用の ONTAP ツールでサポートされています。</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">データストアと VM 移行</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">別のストレージシステム上の既存のデータストアから ONTAP に VM を移行する際は、いくつか注意しておくべきプラクティスがあります。</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Storage vMotion を使用して、仮想マシンの大部分を ONTAP に移動します。このアプローチでは、実行中の VM を停止する必要がなくなるだけでなく、インラインの重複排除や圧縮などの ONTAP の Storage Efficiency 機能を使用して、移行時にデータを処理できます。vCenter 機能を使用してインベントリリストから複数の VM を選択し、適切なタイミングで移行をスケジュール（ Ctrl キーを押しながら [ アクション ] をクリック）することを検討します。</block>
  <block id="008116a0d875d0de070d1a10314abbaa" category="list-text">適切なデスティネーションデータストアへの移行を慎重に計画することもできますが、多くの場合、一括で移行して必要に応じてあとから整理する方が簡単です。Snapshot スケジュールの変更など、データ保護に関する特定のニーズがある場合は、このアプローチを使用して別のデータストアへの移行を実施できます。</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">ほとんどの VM とそのストレージは、実行中（ホット）に移行できますが、 ISO 、 LUN 、 NFS ボリュームなどの接続されたストレージ（データストア内にない）を別のストレージシステムから移行する場合は、コールドマイグレーションが必要になることがあります。</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">TR-4534</block>
  <block id="282806c282d96fdf15b71278587f2bfe" category="list-text">より慎重な移行が必要な仮想マシンには、接続されたストレージを使用するデータベースやアプリケーションなどがあります。一般に、移行を管理するためのアプリケーションのツールの使用を検討します。Oracle の場合は、 RMAN や ASM などの Oracle ツールを使用してデータベース・ファイルを移行することを検討してください。を参照してください<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> を参照してください。同様に、 SQL Server の場合は、 SQL Server Management Studio を使用するか、 SnapManager for SQL Server や SnapCenter などのネットアップのツールを使用することを検討します。</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="section-title">VMware vSphere 用の ONTAP ツール</block>
  <block id="00f47a68ebd81ba943b17dbc30d78db6" category="paragraph">ONTAP ソフトウェアを実行しているシステムで vSphere を使用する際に最も重要なベストプラクティスは、 VMware vSphere プラグイン（旧 Virtual Storage Console ）用の ONTAP ツールをインストールして使用することです。この vCenter プラグインは、 SAN と NAS のどちらを使用している場合でも、ストレージ管理を簡易化し、可用性を向上させ、ストレージコストと運用オーバーヘッドを削減します。データストアのプロビジョニングのベストプラクティスを使用して、マルチパスと HBA タイムアウト（これらは付録 B で説明）用の ESXi ホスト設定を最適化します。vCenter プラグインであるため、 vCenter サーバに接続するすべての vSphere Web Client で使用できます。</block>
  <block id="21eddd0bd26d119e0602b3ceb65aff45" category="paragraph">このプラグインは、 vSphere 環境で他の ONTAP ツールを使用する場合にも役立ちます。このプラグインでは、 NFS Plug-in for VMware VAAI をインストールできます。これにより、 VM のクローニング処理、シック仮想ディスクファイルのスペースリザベーション、および ONTAP Snapshot コピーオフロードで、 ONTAP へのコピーオフロードが可能になります。</block>
  <block id="80303385ad0f7147caa1af6d2162852b" category="paragraph">VASA Provider for ONTAP の多くの機能を使用するための管理インターフェイスでもあり、 VVol でのストレージポリシーベースの管理がサポートされています。VMware vSphere 用の ONTAP ツールを登録したら、ストレージ機能プロファイルを作成してストレージにマッピングし、データストアがプロファイルに一定期間にわたって準拠していることを確認します。VASA Provider には、 VVol データストアの作成と管理を行うためのインターフェイスも用意されています。</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">一般に、 vCenter 内で VMware vSphere インターフェイス用の ONTAP ツールを使用して、従来のデータストアと VVol データストアをプロビジョニングし、ベストプラクティスに従っていることを確認することを推奨します。</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">一般的なネットワーク</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">ONTAP ソフトウェアを実行しているシステムで vSphere を使用する場合のネットワーク設定の構成は簡単で、他のネットワーク構成と同様です。考慮すべき点をいくつか挙げます。</block>
  <block id="9600865cce7d923667012211ddac46de" category="list-text">ストレージネットワークのトラフィックを他のネットワークから分離します。専用の VLAN を使用するか、ストレージ用に別個のスイッチを使用することで、別のネットワークを実現できます。ストレージネットワークがアップリンクなどの物理パスを共有している場合は、十分な帯域幅を確保するために QoS または追加のアップリンクポートが必要になることがあります。ホストをストレージに直接接続しないでください。スイッチを使用すると冗長パスが確保され、 VMware HA が自動で機能します。</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">ジャンボフレームは、必要に応じてネットワークでサポートされていれば、特に iSCSI を使用している場合に使用できます。使用する場合は、ストレージと ESXi ホストの間のパスにあるすべてのネットワークデバイスや VLAN で設定が同じであることを確認してください。そうしないと、パフォーマンスや接続の問題が発生する可能性があります。MTU は、 ESXi 仮想スイッチ、 VMkernel ポート、および各 ONTAP ノードの物理ポートまたはインターフェイスグループでも同一の設定にする必要があります。</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">ネットワークフロー制御は、 ONTAP クラスタ内のクラスタネットワークポートでのみ無効にすることを推奨します。データトラフィックに使用される残りのネットワークポートについては、推奨されるベストプラクティスはありません。必要に応じて有効または無効にしてください。を参照してください<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> を参照してください。</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">ESXi および ONTAP ストレージアレイをイーサネットストレージネットワークに接続するときは、接続先のイーサネットポートを Rapid Spanning Tree Protocol （ RSTP ；高速スパニングツリープロトコル）のエッジポートとして設定するか、 Cisco の PortFast 機能を使用して設定することを推奨します。ネットアップでは、 Cisco の PortFast 機能を使用していて、 ESXi サーバまたは ONTAP ストレージアレイへの 802.1Q VLAN トランキングが有効になっている環境では、 Spanning-Tree PortFast trunk 機能を有効にすることを推奨します。</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">リンクアグリゲーションのベストプラクティスとして次を推奨します。</block>
  <block id="102e4f88579e89519d8c614561d5e302" category="list-text">Cisco の Virtual PortChannel （ vPC ）などのマルチシャーシリンクアグリゲーショングループアプローチを使用して、 2 つの別々のスイッチシャーシ上のポートのリンクアグリゲーションをサポートするスイッチを使用します。</block>
  <block id="f331781b955fd46506835e783c953ed4" category="list-text">LACP が設定された dvSwitches 5.1 以降を使用していない場合、 ESXi に接続されているスイッチポートの LACP を無効にします。</block>
  <block id="eb8cf3a79d16ed9f0e2c1de65c379bc5" category="list-text">IP ハッシュを使用したダイナミックマルチモードインターフェイスグループを使用して、 ONTAP ストレージシステム用のリンクアグリゲートを作成するために LACP を使用します。</block>
  <block id="8ebcba6104088fb46f64395277d21edd" category="list-text">ESXi で IP ハッシュチーミングポリシーを使用します。</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">次の表に、ネットワーク設定項目とその適用先をまとめます。</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">項目</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">スイッチ</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">ノード</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">IP アドレス</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">いいえ **</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">リンクアグリゲーション</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">仮想スイッチ</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">いいえ *</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">VMkernel と VM ポートグループ</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">フロー制御</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">スパニングツリー</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU （ジャンボフレーム用）</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">仮想スイッチと VMkernel ポート（ 9000 ）</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">○（最大に設定）</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">○（ 9000 ）</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">フェイルオーバーグループ</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">○（作成）</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">○（選択）</block>
  <block id="93e04df6f821105fd0ab88e95eaee167" category="paragraph">* SVM LIF は、 VLAN や MTU などが設定されたポート、インターフェイスグループ、または VLAN インターフェイスに接続されますが、設定は SVM レベルで管理されません。</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">** これらのデバイスには管理用に独自の IP アドレスがありますが、 ESXi ストレージネットワークのコンテキストでは使用されません。</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN （ FC 、 FCoE 、 NVMe/FC 、 iSCSI ）、 RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">vSphere では、ブロックストレージ LUN を 3 通りの方法で使用します。</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">VMFS データストアを使用する場合</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">raw デバイスマッピング（ RDM ）で使用</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">ソフトウェアイニシエータがアクセスおよび制御する LUN として使用 VM ゲスト OS から作成します</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS は、共有ストレージプールであるデータストアを提供する、高性能なクラスタファイルシステムです。VMFS データストアは、 NVMe/FC プロトコルによってアクセスされる FC 、 iSCSI 、 FCoE 、または NVMe ネームスペースを使用してアクセスする LUN で構成できます。VMFS を使用すると、クラスタ内の各 ESX サーバから同時に従来型の LUN にアクセスすることができます。ONTAP の最大 LUN サイズは通常 16TB であるため、最大サイズの 64TB （このセクションの最初の表を参照）の VMFS 5 データストアは、 4 つの 16TB LUN を使用して作成されます（すべての SAN アレイシステムが最大 VMFS LUN サイズ 64TB をサポート）。ONTAP LUN アーキテクチャでは個々のキュー深度が小さくないため、 ONTAP の VMFS データストアは、比較的簡単な方法で従来のアレイアーキテクチャよりも大規模に拡張できます。</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">vSphere は、ストレージデバイスへの複数のパスを標準でサポートします。この機能はネイティブマルチパス（ NMP ）と呼ばれます。NMP は、サポートされるストレージシステムのストレージタイプを検出し、使用中のストレージシステムの機能をサポートするように NMP スタックを自動的に設定できます。</block>
  <block id="6bf646772584de04f877d166e564b5ff" category="paragraph">NMP と NetApp ONTAP はどちらも、 Asymmetric Logical Unit Access （ ALUA ；非対称論理ユニットアクセス）による最適パスと非最適パスのネゴシエーションをサポートします。ONTAP では、アクセス対象の LUN をホストするノード上のターゲットポートを使用する直接データパスが、 ALUA の最適パスとなります。ALUA は、 vSphere と ONTAP の両方でデフォルトで有効になっています。NMP は ONTAP クラスタを ALUA として認識し、 ALUA ストレージアレイタイププラグイン（ VMW_SATP_ALUA ）を使用し、ラウンドロビンパス選択プラグイン（「 VMW_PSP_RR 」）を選択します。</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6 は、最大 256 個の LUN と、 LUN への最大 1 、 024 個の合計パスをサポートします。これらの制限を超える LUN やパスは、 ESXi で認識されません。最大数の LUN を使用した場合、 LUN あたりのパス数は最大 4 つです。大規模な ONTAP クラスタでは、 LUN 数の上限に達する前にパス数の制限に達する可能性があります。この制限に対処するため、 ONTAP では、リリース 8.3 以降の選択的 LUN マップ（ SLM ）がサポートされています。</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="a1319b3463fde689889152797a3cf966" category="paragraph">SLM は、特定の LUN へのパスをアドバタイズするノードを制限します。ネットアップのベストプラクティスでは、各 SVM のノードごとに少なくとも 1 つの LIF を配置し、 SLM を使用して、 LUN とその HA パートナーをホストするノードへのアドバタイズパスを制限することを推奨しています。他のパスは存在しますが、デフォルトではアドバタイズされません。SLM 内で、レポートノードの追加引数および削除引数を使用して通知されたパスを変更することができます。8.3 より前のリリースで作成された LUN ではすべてのパスがアドバタイズされるため、ホストしている HA ペアへのパスのみがアドバタイズされるように変更する必要があることに注意してください。SLM の詳細については、のセクション 5.9 を参照してください<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>。以前のポートセットの方式を使用すると、 LUN の使用可能なパスをさらに削減できます。ポートセットを使用すると、 igroup 内のイニシエータが LUN を認識する際に経由可能なパス数を減らすことができます。</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM はデフォルトでは有効になっています。ポートセットを使用しないかぎり、これ以上の設定は必要ありません。</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Data ONTAP 8.3 より前のバージョンで作成した LUN の場合、 lun mapping remove-reporting-nodes コマンドを実行して SLM を手動で適用し、 LUN レポートノードを削除し、 LUN へのアクセスを LUN の所有者ノードとその HA パートナーに制限します。</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">ブロックプロトコル（ iSCSI 、 FC 、 FCoE ）は、一意の名前に加え、 LUN ID とシリアル番号を使用して LUN にアクセスします。FC と FCoE は Worldwide Name （ WWNN および WWPN ）を使用し、 iSCSI は iSCSI Qualified Name （ IQN ）を使用します。ストレージ内での LUN へのパスはブロックプロトコルにとっては意味がないため、どこにも表示されません。したがって、 LUN のみが含まれるボリュームは内部でマウントする必要がなく、データストアで使用される LUN を含むボリュームのジャンクションパスも必要ありません。ONTAP の NVMe サブシステムも同様に機能します。</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">考慮すべきその他のベストプラクティス：</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">可用性と移動性を最大限に高めるために、 ONTAP クラスタ内の各ノード上の各 SVM に論理インターフェイス（ LIF ）が作成されていることを確認します。ONTAP SAN では、各ファブリックに対して 1 つずつ、ノードごとに 2 つの物理ポートと LIF を使用することを推奨します。ALUA を使用してパスが解析され、アクティブな最適化（直接）パスとアクティブな非最適化パスが特定されます。ALUA は FC 、 FCoE 、および iSCSI に使用されます。</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">iSCSI ネットワークの場合、複数の仮想スイッチがある場合は、 NIC チーミングを使用して、異なるネットワークサブネット上の複数の VMkernel ネットワークインターフェイスを使用します。また、複数の物理スイッチに接続された複数の物理 NIC を使用して、 HA を実現し、スループットを向上させることもできます。次の図に、マルチパス接続の例を示します。ONTAP では、 2 つ以上のスイッチに接続された 2 つ以上のリンクでフェイルオーバーするシングルモードインターフェイスグループを設定するか、 LACP または他のリンクアグリゲーションテクノロジをマルチモードインターフェイスグループと併用して HA を実現し、リンクアグリゲーションのメリットを活かすことができます。</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">Challenge Handshake Authentication Protocol （ CHAP ）が ESXi でターゲット認証に使用されている場合には、 CLI （「 vserver iscsi security create 」）または System Manager （ Storage &gt; SVMs &gt; SVM Settings &gt; Protocols &gt; iSCSI ）を使用して ONTAP にも設定する必要があります。</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">LUN と igroup の作成と管理には、 VMware vSphere の ONTAP ツールを使用します。プラグインによってサーバの WWPN が自動的に判別され、適切な igroup が作成されます。また、ベストプラクティスに従って LUN を設定し、正しい igroup にマッピングします。</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">物理互換モードと仮想互換モード</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">RDM は管理が難しくなり、前述のように制限されたパスを使用するため、使用には注意が必要です。ONTAP LUN は両方をサポートします<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM ：</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">『 ONTAP NVMe/FC Host Configuration Guide 』を参照してください</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">vSphere 7.0 での NVMe/FC の使用については、以下を参照してください<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> および<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>次の図に、 vSphere ホストから ONTAP LUN へのマルチパス接続を示します。</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">vSphere を使用すると、エンタープライズクラスの NFS アレイを使用して、 ESXi クラスタ内のすべてのノードへのデータストアへの同時アクセスを提供できます。データストアのセクションで説明したように、 vSphere で NFS を使用すると、使いやすさが向上し、ストレージ効率を可視化できるというメリットがあります。</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">vSphere で ONTAP NFS を使用する際に推奨されるベストプラクティスは次のとおりです。</block>
  <block id="265e673c00294cf97a90c3b0d4fcb076" category="list-text">ONTAP クラスタ内の各ノードの各 SVM で、 1 つの論理インターフェイス（ LIF ）を使用します。データストアごとの LIF の過去の推奨事項は不要になりました。直接アクセス（同じノード上の LIF とデータストア）は最適ですが、パフォーマンスへの影響は一般に最小（マイクロ秒）であるため、間接アクセスを考慮しないでください。</block>
  <block id="83deede0d0158f0f2469080b6208e88a" category="list-text">VMware は、 VMware Infrastructure 3 以降で NFSv3 をサポートしています。vSphere 6.0 では NFSv4.1 がサポートされるようになり、 Kerberos セキュリティなどの高度な機能が使用できるようになりました。NFSv3 ではクライアント側のロックが使用され、 NFSv4.1 ではサーバ側のロックが使用されます。ONTAP ボリュームは両方のプロトコルでエクスポートできますが、 ESXi は 1 つのプロトコルでしかマウントできません。この単一プロトコルのマウントにより、他の ESXi ホストが同じデータストアを別のバージョンでマウントすることができるわけではありません。すべてのホストが同じバージョン、つまり同じロック形式を使用するように、マウント時に使用するプロトコルバージョンを指定してください。NFS のバージョンをホスト間で混在させないでください。可能であれば、ホストプロファイルを使用して準拠しているかどうかを確認します</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">NFSv3 と NFSv4.1 間ではデータストアが自動変換されないため、新しい NFSv4.1 データストアを作成し、 Storage vMotion を使用して新しいデータストアに VM を移行します。</block>
  <block id="a9577e779ab70bdd45392b1e0125cc77" category="list-text">本レポートの執筆時点では、ネットアップは VMware との連携を継続して、 NFSv4.1 データストアの問題やストレージフェイルオーバーの問題を解決しています。これらの問題は、近日中に解決される予定です。</block>
  <block id="04826f858f8ad9c66b9d805ca9ff88a3" category="list-text">NFS エクスポートポリシーは、 vSphere ホストによるアクセスの制御に使用されます。複数のボリューム（データストア）で 1 つのポリシーを使用できます。NFSv3 では、 ESXi で sys （ UNIX ）セキュリティ形式が使用され、 VM を実行するためにルートマウントオプションが必要となります。ONTAP では、このオプションはスーパーユーザと呼ばれます。スーパーユーザオプションを使用する場合は、匿名ユーザ ID を指定する必要はありません。-anon` と --allow-suid に異なる値を持つエクスポートポリシールールは、 ONTAP 原因ツールで SVM の検出に関する問題が発生する可能性があることに注意してください。ポリシーの例を次に示します。</block>
  <block id="822366735aef72f1a9429ac86dda7338" category="list-text">Access Protocol ： nfs3</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">クライアント一致仕様： 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">RO アクセスルール： sys</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">RW アクセスルール： sys</block>
  <block id="0fd74b9f6a61e12b4a204b3489bd05a9" category="list-text">匿名 UID ：</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">superuser ： sys</block>
  <block id="c184ce6b86d2e6fbf8681d61637c101b" category="list-text">NetApp NFS Plug-in for VMware VAAI を使用する場合、エクスポートポリシールールの作成時または変更時にプロトコルを「 nfs 」に設定する必要があります。VAAI コピーオフロードが機能するためには NFSv4 プロトコルが必要です。プロトコルを「 nfs 」に指定すると、 NFSv3 バージョンと NFSv4 バージョンの両方が自動的に組み込まれます。</block>
  <block id="44e8816851b6d24723bf0e06c3b8b40d" category="list-text">NFS データストアのボリュームは SVM のルートボリュームからジャンクションされるため、 ESXi がデータストアボリュームに移動してマウントするためにはルートボリュームへのアクセス権も必要となります。ルートボリューム、およびデータストアボリュームのジャンクションがネストされているその他のボリュームのエクスポートポリシーには、 ESXi サーバに読み取り専用アクセスを許可するルールが含まれている必要があります。VAAI プラグインを使用したルートボリュームのポリシーの例を次に示します。</block>
  <block id="88b77eec23ea926d7dac5b6ec36713d2" category="list-text">Access Protocol の略。nfs （ nfs3 と nfs4 の両方を含む）</block>
  <block id="2e5d116b123742b0c1f9b9266e3d45e4" category="list-text">クライアント一致仕様。192.168.42.21</block>
  <block id="e79bd23a286e2e109f901ac7b9fc1052" category="list-text">RO アクセスルール。システム</block>
  <block id="6854a3cd4d70ef13145d55305c745f1c" category="list-text">RW アクセスルール：なし（ルートボリュームに最適なセキュリティ）</block>
  <block id="629cac79e5ae376b5235b5cb87c8c03d" category="list-text">匿名 UID の形式です。</block>
  <block id="e76eb6f8b3ceafc6b70386efb46a8295" category="list-text">スーパーユーザ：sys （ VAAI を使用するルートボリュームでも必要）</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">VMware vSphere 用の ONTAP ツール（最も重要なベストプラクティス）を使用：</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">VMware vSphere 用の ONTAP ツールを使用してデータストアをプロビジョニングすると、エクスポートポリシーの自動管理が簡易化されます。</block>
  <block id="55cf2206291fced620eed577cb8c8a42" category="list-text">プラグインを使用して VMware クラスタ用のデータストアを作成するときは、単一の ESX サーバではなくクラスタを選択します。これにより、データストアがクラスタ内のすべてのホストに自動的にマウントされます。</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">プラグインのマウント機能を使用して、既存のデータストアを新しいサーバに適用します。</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">VMware vSphere 用の ONTAP ツールを使用しない場合は、すべてのサーバ、または追加のアクセス制御が必要なサーバクラスタごとに、 1 つのエクスポートポリシーを使用します。</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">ONTAP にはフレキシブルボリュームのネームスペース構造が用意されており、ジャンクションを使用してボリュームをツリーにまとめることができますが、このアプローチは vSphere には価値がありません。ストレージのネームスペース階層に関係なく、データストアのルートに各 VM 用のディレクトリが作成されます。そのため、単に SVM のルートボリュームに vSphere のボリュームのジャンクションパスをマウントすることがベストプラクティスです。これは、 VMware vSphere 用の ONTAP ツールでデータストアをプロビジョニングする方法です。ジャンクションパスがネストされていないと、ルートボリューム以外のボリュームに依存しているボリュームがないこと、またボリュームをオフラインにするか破棄するかによって意図的に他のボリュームへのパスに影響が及ぶこともありません。</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">NFS データストアの NTFS パーティションのブロックサイズは 4K で十分です。次の図は、 vSphere ホストから ONTAP NFS データストアへの接続を示しています。</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">次の表に、 NFS のバージョンとサポートされる機能を示します。</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">vSphere の機能</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">vMotion と Storage vMotion</block>
  <block id="05807e454c19f244770adae059b3c330" category="cell">高可用性</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">フォールトトレランス</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">ホストプロファイル</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">Storage DRS</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">ストレージ I/O の制御</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM の場合</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">仮想ボリューム</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">ハードウェアアクセラレーション（ VAAI ）</block>
  <block id="aa32fdb70496d9a7395ef0d3ccb1c986" category="cell">○（ vSphere 6.5 以降、 NetApp VAAI プラグイン 1.1.2 ）</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Kerberos 認証</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">○（ vSphere 6.5 以降で拡張して、 AES 、 krb5i ）</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">マルチパスのサポート</block>
  <block id="4cdf980fd6cee432c76402bb142269e9" category="cell">× （ ESXi 6.5 以降ではセッショントランキングを通じてサポートされ、 ONTAP では pNFS を通じてサポートされます）</block>
  <block id="54452390cac5f65f3bcec580ba079531" category="section-title">FlexGroup</block>
  <block id="f203949f2e35204098b66b9c1519b66e" category="paragraph">ONTAP 9.8 では、 vSphere で FlexGroup データストアがサポートされるようになり、 VMware vSphere 9.8 リリース用の ONTAP ツールも追加されています。FlexGroup を使用すると、大容量のデータストアを簡単に作成でき、複数のコンスティチュエントボリュームを自動的に作成して、 ONTAP システムのパフォーマンスを最大限に高めることができます。フル機能の ONTAP クラスタを利用して、拡張性に優れた単一の vSphere データストアで FlexGroup を使用できます。</block>
  <block id="6829bc8d3038be0130fd2b409ad5e560" category="paragraph">ONTAP 9.8 では、 vSphere のワークロードを使用した広範なシステムテストに加えて、 FlexGroup データストアのコピーオフロードメカニズムも新たに追加されました。強化されたコピーエンジンを使用して、バックグラウンドのコンスティチュエント間でファイルをコピーすると同時に、ソースとデスティネーションの両方でアクセスを許可します。複数のコピーを使用すると、構成要素内で、スペース効率に優れた使用可能なファイルクローンを、大規模に応じて即座に利用できます。</block>
  <block id="760383437e8e5cbe4a2560753da783fb" category="paragraph">ONTAP 9.8 では、 FlexGroup ファイルの新しいファイルベースのパフォーマンス指標（ IOPS 、スループット、レイテンシ）も追加されました。これらの指標は、 VMware vSphere ダッシュボードや VM レポート用の ONTAP ツールで確認できます。VMware vSphere プラグイン用の ONTAP ツールでは、最大 IOPS と最小 IOPS の組み合わせを使用してサービス品質（ QoS ）ルールを設定することもできます。これらは、データストア内のすべての VM に対して個別に設定することも、特定の VM に対して個別に設定することもできます。</block>
  <block id="50783a97403d748762dff691da2d3723" category="paragraph">ネットアップが新たに開発したベストプラクティスをいくつかご紹介します。</block>
  <block id="d190c5fcdf8146c1dd7aad1140be4e64" category="list-text">FlexGroup プロビジョニングのデフォルトを使用する。VMware vSphere 用の ONTAP ツールは vSphere 内で FlexGroup を作成およびマウントするため推奨されますが、 ONTAP System Manager やコマンドラインを使用すると特別なニーズを満たすことができます。さらに、ノードあたりのコンスティチュエントメンバー数などのデフォルトも使用します。これは、 vSphere でテスト済みの構成メンバー数であるためです。</block>
  <block id="9f3fa65c2cc36eabd2228b984c30c5e1" category="list-text">FlexGroup データストアのサイジングを行う場合、 FlexVol は、より大容量のネームスペースを作成する複数の小さい FlexGroup で構成されることに注意してください。そのため、最大の仮想マシンの 8 倍以上のサイズのデータストアに設定してください。たとえば、使用している環境に 6TB の VM がある場合、 FlexGroup データストアのサイズは 48TB 以上にする必要があります。</block>
  <block id="5fbee6b763967c822bb1e4a31665b11d" category="list-text">FlexGroup によるデータストアスペースの管理を許可します。オートサイズと Elastic サイジングは、 vSphere データストアでテスト済みです。データストアの容量がフルに近くなった場合は、 VMware vSphere 用の ONTAP ツールまたは別のツールを使用して、 FlexGroup ボリュームのサイズを変更します。FlexGroup は、容量と inode をコンスティチュエント間で分散して維持し、容量が許容される場合はフォルダ（ VM ）内のファイルに同じコンスティチュエントへの優先順位を付けます。</block>
  <block id="c4528ad57baf62254d165d4e907e6f59" category="list-text">VMware とネットアップは、現在、一般的なマルチパスネットワークアプローチをサポートしていません。NFSv4.1 では、ネットアップは pNFS をサポートしていますが、 VMware はセッショントランキングをサポートしています。NFSv3 は、ボリュームへの複数の物理パスをサポートしていません。ONTAP 9.8 を使用した FlexGroup の場合、 VMware vSphere 用の ONTAP ツールを 1 つのマウントにすることを推奨します。これは、間接アクセスによる影響が通常は最小限（マイクロ秒）であるためです。ラウンドロビン DNS を使用して、 FlexGroup 内の異なるノード上の LIF に ESXi ホストを分散することは可能ですが、その場合、 VMware vSphere 用の ONTAP ツールを使用せずに FlexGroup を作成してマウントする必要があります。その場合、パフォーマンス管理機能は使用できません。</block>
  <block id="f5f11bb6aa98d02453eca36d5d1d2e19" category="list-text">FlexGroup vSphere データストアのサポートは、 9.8 リリースで最大 1500 台の VM でテスト済みです。</block>
  <block id="f48591b3ae898f29a551a2995a7dcfe8" category="list-text">コピーオフロードには、 NFS Plug-in for VMware VAAI を使用します。クローニングは FlexGroup データストア内で強化 ONTAP されますが、 FlexVol ボリュームと FlexGroup ボリュームの間で VM をコピーする場合に、 ESXi ホストコピーと比べてパフォーマンス面で大きなメリットはありません。</block>
  <block id="57a0d1deb8da99d321814990d26d21ed" category="list-text">VMware vSphere 9.8 用の ONTAP ツールを使用すると、 ONTAP メトリック（ダッシュボードと VM レポート）を使用して FlexGroup VM のパフォーマンスを監視し、個々の VM の QoS を管理できます。現時点では、これらの指標は ONTAP コマンドや API では使用できません。</block>
  <block id="ad971da24ec0a38449ebf31e4e2c9332" category="list-text">QoS （最大 / 最小 IOPS ）は、個々の VM に対して、またはデータストア内のすべての VM に対して設定できます。すべての VM に QoS を設定すると、 VM ごとに個別に設定する必要がなくなります。今後は、新規または移行された VM には適用されません。新しい VM に QoS を設定するか、データストア内のすべての VM に QoS を再適用してください。</block>
  <block id="3c9d41390700cbdfb2c273f00df0d6fd" category="list-text">SnapCenter Plug-in for VMware vSphere リリース 4.4 では、プライマリストレージシステム上の FlexGroup データストア内の VM のバックアップとリカバリがサポートされています。SnapMirror を手動で使用して FlexGroup をセカンダリシステムにレプリケートできるが、 SCV 4.4 ではセカンダリコピーが管理されない。</block>
  <block id="c0ddbacfe0f703e62904558059e40001" category="summary">ここでは、 ONTAP および vSphere の特定のリリースでサポートされる機能について説明します。リリースの特定の組み合わせについては、 NetApp Interoperability Matrix で確認することを推奨します。</block>
  <block id="bc8be72fdc9d6054f356bb2b7f80fd12" category="inline-link">NetApp Interoperability Matrix を参照してください</block>
  <block id="2f6ae9fa35fbcb0ec3205505ee027642" category="paragraph">ここでは、 ONTAP および vSphere の特定のリリースでサポートされる機能について説明します。ネットアップでは、リリースの特定の組み合わせをで確認することを推奨します<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block>。</block>
  <block id="7912c2100fd9b3b96b0b03e7a068fc9a" category="section-title">ONTAP リリース</block>
  <block id="8ee2892e0fb10cc58205a3d682abdb58" category="paragraph">本ドキュメントの発行時点で、ネットアップは、以下のリリースファミリーを完全にサポートしています。</block>
  <block id="0fcf2ee62acd9eae83b609a0e7ecaa72" category="list-text">ONTAP 9.5</block>
  <block id="7dd2a92fd3f41a5334edf46f95d77e71" category="list-text">ONTAP 9.6</block>
  <block id="3447b91e516e4fc6b5dba827fcb68bee" category="list-text">ONTAP 9.7</block>
  <block id="2abfff2974f589f7a217325f304e0ec5" category="list-text">ONTAP 9.8</block>
  <block id="ee4651b72d795faf25a1382eb1315a95" category="section-title">vSphere および ESXi のサポート</block>
  <block id="c3123497dcfdcdf46908ad18a51928ca" category="paragraph">NetApp ONTAP は、 vSphere ESXi ホストを幅広くサポートしています。上記の 4 つのメジャーリリースファミリー（ 9.5 、 9.6 、 9.7 、および 9.8 ）は、 6.0 、 6.5 、 7.0 （これらのリリースの更新を含む）を含む最近の vSphere リリースのデータストレージプラットフォームとして完全にサポートされています。NFS v3 の相互運用性は幅広く、ネットアップではハイパーバイザーを含むすべてのクライアントをサポートしていますが、これらのクライアントには NFS v3 標準に準拠しています。NFSv4.1 のサポートは vSphere 6.0 から 7.0 までに制限されています。</block>
  <block id="8276b4666ec9fee7d71b01f6ee2b9955" category="paragraph">SAN 環境については、ネットアップでは SAN コンポーネントの広範なテストを実施しています。一般に、ネットアップは標準の x86-64 ラックサーバと Cisco UCS サーバを、 iSCSI 接続用の標準イーサネットアダプタと組み合わせてサポートしています。FC 環境、 FCoE 環境、 NVMe / FC 環境では、 HBA ファームウェアやドライバの必要性が原因で、より具体的にサポートが定義されています。</block>
  <block id="a9854fb3ed44e3b8e9236c5b70405101" category="paragraph">必ずをチェックしてください<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block> 特定のハードウェアとソフトウェアの設定のサポートを確認するため。</block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">NFS Plug-in for VMware VAAI のこと</block>
  <block id="eb3ac5aa51c1cacfa31cee70ac6586f0" category="paragraph">ESXi ホスト向けのこのプラグインは、 VAAI を使用して ONTAP に処理をオフロードします。最新リリースの 1.1.2 では、 Kerberos （ krb5 と krb5i ）のサポートなど、 NFSv4.1 データストアがサポートされます。ESXi 6.0 、 6.5 、および 7.0 と ONTAP 9.5-9.8 を併用できます。</block>
  <block id="b2dd36bd4918e00f8b2e15e6d62a4b94" category="section-title">VASA Provider</block>
  <block id="15c15a65e1486d45a44c6f61927ef836" category="paragraph">NetApp VASA プロバイダは VVol のプロビジョニングと管理をサポートします（セクション 3.7 を参照）。最近の VASA Provider リリースでは、 ESXi 6.0 、 6.5 、 7.0 と ONTAP 9.5-9.8 がサポートされています。</block>
  <block id="c13550c8bc0f9b77e92bd2533221de9d" category="paragraph">VMware vSphere 用の ONTAP ツールは、 ONTAP ストレージと vSphere を一緒に管理するための鍵です（これを使用することがベストプラクティスです）。最新リリース 9.8 は、 vSphere 6.5 および 7.0 と ONTAP 9.5-9.8 でサポートされています。</block>
  <block id="02d4482d332e1aef3437cd61c9bcc624" category="doc">お問い合わせください</block>
  <block id="3dd3a0a8eebc543e239dc4af5d76b322" category="paragraph">このテクニカルレポートに関するご意見やご要望はありますか？</block>
  <block id="19610155b973358e47466063b4b079a4" category="summary">ONTAP は、仮想化に使用されるすべての主要なストレージプロトコルをサポートしています。たとえば、 SAN 環境向けの iSCSI 、 Fibre Channel （ FC ）、 Fibre Channel over Ethernet （ FCoE ）、 Non-Volatile Memory Express over Fibre Channel （ NVMe/FC ）、ゲスト接続用の NFS （ v3 および v4.1 ）、 SMB または S3 などです。お客様は、環境に最適なものを自由に選択でき、必要に応じてプロトコルを 1 つのシステムで組み合わせることができます。</block>
  <block id="93b698fac9d8f378474fb0765494c4e6" category="doc">vSphere 向けの ONTAP 機能</block>
  <block id="9985b4390c40137573e6da05caf85874" category="section-title">プロトコル</block>
  <block id="561327c79c453379a7f11cb38aabf666" category="paragraph">ONTAP は、仮想化に使用されるすべての主要なストレージプロトコルをサポートしています。たとえば、 SAN 環境向けの iSCSI 、 Fibre Channel （ FC ）、 Fibre Channel over Ethernet （ FCoE ）、 Non-Volatile Memory Express over Fibre Channel （ NVMe/FC ）、ゲスト接続用の NFS （ v3 および v4.1 ）、 SMB または S3 などです。お客様は、自社の環境に最適なものを自由に選び、 1 つのシステム上で必要に応じてプロトコルを組み合わせることができます（たとえば、 NFS データストアの一般的な使用方法を、いくつかの iSCSI LUN やゲスト共有で強化できます）。</block>
  <block id="99dd82c3472eab7ec4ea64a848fe032d" category="paragraph">仮想ワークロードの管理に役立つ ONTAP の機能が多数あります。追加の製品ライセンスが必要な製品も、次のセクションで説明します。スタンドアロンツールとしてパッケージ化されたものもあれば、 ONTAP 向けのものもあれば、ネットアップポートフォリオ全体のパッケージ化されたものもあります。</block>
  <block id="671534601eb09388581f095632f815b2" category="paragraph">ONTAP の基本機能の詳細は、以下のとおりです。</block>
  <block id="ef97088865d8960cc5a3a20f3c10f469" category="list-text">* ネットアップの Snapshot コピー。 * ONTAP は、 Snapshot コピーの作成時や使用時にパフォーマンスに影響を与えることなく、 VM やデータストアの Snapshot コピーを瞬時に作成できます。パッチの適用前またはシンプルなデータ保護のために、 VM のリストアポイントを作成する際に使用できます。これらは VMware （整合性）スナップショットとは異なります。ONTAP の Snapshot コピーを作成する最も簡単な方法は、 SnapCenter Plug-in for VMware vSphere を使用して VM とデータストアをバックアップすることです。</block>
  <block id="dbef3659822e80f91a3a561ed6d0b0cd" category="list-text">* Storage Efficiency 。 * ONTAP は、インラインおよびバックグラウンドの重複排除と圧縮、ゼロブロック重複排除、データコンパクションをサポートしています。</block>
  <block id="287c4830bc87771bdf2b3ae9880ab67e" category="list-text">* ボリュームと LUN の移動。 * ONTAP クラスタ内の vSphere データストアと VVOL をサポートするボリュームや LUN を無停止で移動できます。これにより、パフォーマンスと容量のバランスを取り、無停止での保守とアップグレードをサポートできます。</block>
  <block id="ba96d4d48c1ff15e2732b37e2e7a435c" category="list-text">* QoS により、個々の LUN 、ボリューム、またはファイルのパフォーマンスを管理できます。この機能を使用すると、不明な VM や Bully VM を制限したり、重要な VM に十分なパフォーマンスリソースを確保したりできます。</block>
  <block id="a946b6511f13dc2fbdaf1581d804d5b4" category="list-text">* NetApp Volume Encryption 、 NetApp Aggregate Encryption 。 * ネットアップの暗号化オプションは、ソフトウェアベースで簡単に保存データを保護します。</block>
  <block id="28f638810590337576cbbe9979329c21" category="list-text">* FabricPool 。 * この機能は、コールドデータをブロックレベルで自動的に別のオブジェクトストアに階層化し、高価なフラッシュストレージを解放します。</block>
  <block id="ff8a0108cd7cd5019bfee6b6be672b17" category="inline-link">ONTAP REST API</block>
  <block id="9455a10ec937dafee664ae1e0e4fd98c" category="inline-link">Ansible モジュール</block>
  <block id="4fe65be709b755cfdf83cf3ff5534e52" category="list-text">* REST 、 Ansible *<block ref="71191ff17e34498b2463e6167736896a" category="inline-link-rx"></block> ストレージとデータの管理を自動化するには、を参照してください<block ref="d4fc0de110866702e0b8608590b39b64" category="inline-link-rx"></block> ONTAP システムの構成を管理します。 ONTAP の一部の機能は vSphere のワークロードには適していません。たとえば、 ONTAP 9.8 より前の FlexGroup では完全なクローニングはサポートされておらず、 vSphere ではテストされていません（ vSphere での使用に関する最新情報については、「 FlexGroup 」の項を参照してください）。FlexCache は、読み取り主体のワークロード向けに設計されているため、 vSphere にも最適ではありません。キャッシュが元のボリュームから切断されていると、両方の側で NFS データストアエラーが発生する場合があります。</block>
  <block id="85402a535d923d0511a02d404893d1ba" category="section-title">ONTAP ライセンス</block>
  <block id="4a9fdcb14826a67d38a7b84170c54ea9" category="paragraph">仮想ワークロードの管理に役立つ ONTAP の一部の機能には、追加コストなし、ライセンスバンドル内、個別選択のいずれでも、追加ライセンスが必要です。多くのお客様にとって、最もコスト効率の高いアプローチはライセンスバンドルです。vSphere と関連する主なライセンスとその使用方法は次のとおりです。</block>
  <block id="c598be4d4f9f8c476e7f51d6ef5ff139" category="list-text">* FlexClone 。 * FlexClone を使用すると、 ONTAP のボリュームやファイルのクローンを、スペース効率に優れた方法で瞬時に作成できます。このクローニングは、 VMware vSphere Storage API – Array Integration （ VAAI ）によって処理がストレージシステムにオフロードされる場合、バックアップ検証とリカバリ（ SnapCenter ソフトウェア）、および VVOL のクローニングと Snapshot コピーに使用されます。使用方法は次のとおりです。</block>
  <block id="25d6e9f6ac28ecf0d97aaf9f6609f4d4" category="list-text">VAAI はオフロードコピー用の ONTAP でサポートされており、 vSphere のクローニング処理と移行（ Storage vMotion ）処理をサポートしています。FlexClone ライセンスは NetApp FlexVol ボリューム内に高速クローンを作成できますが、ライセンスがない場合でも、低速のブロックコピーを使用してクローンを作成できます。</block>
  <block id="6f9f0acae1b8d33078f1c061dcc662a3" category="list-text">VVol 機能を使用するには、 FlexClone ライセンスが必要です。この機能を使用すると、 1 つのデータストア内またはデータストア間で VVol をクローニングできます。また、 vSphere で管理される VVol の Snapshot コピーを、ストレージシステムにオフロードして実行できます。</block>
  <block id="4370ed35c8063100f2a5b8da39b82668" category="list-text">ストレージレプリケーションアダプタ（ SRA ）は VMware Site Recovery Manager で使用されます。また、 NAS 環境と SAN 環境の両方でリカバリをテストするには、 FlexClone ライセンスが必要です。検出、リカバリ、再保護のワークフローについては、 FlexClone なしで SRA を使用できます。</block>
  <block id="3117cf0d132cfe6180ee3db3d5250f7f" category="list-text">* SnapRestore 。 * SnapRestore テクノロジにより、データをコピーすることなく、ボリュームをインプレースで瞬時にリカバリできます。この機能は、 SnapCenter などのネットアップのバックアップおよびリカバリツールで必要です。 を使用して、検証およびリストア処理用にデータストアをマウントします。</block>
  <block id="a30ea87a20e5dd5b267ec41f29219a1d" category="list-text">* SnapMirror 。 * SnapMirror テクノロジにより、オンプレミスとクラウドの ONTAP システム間で、シンプルで高速なデータレプリケーションを実現できます。SnapMirror は、バージョンに依存しない論理レプリケーションをサポートしています。ブロックレプリケーションのパフォーマンスにより、変更されたデータのみがセカンダリシステムに送信されます。データはミラーポリシーやバックアップポリシーで保護できるため、ディザスタリカバリだけでなく、バックアップの長期データ保持にも対応できます。SnapMirror は、非同期関係と同期関係をサポートしています。 ONTAP 9.8 では、 SnapMirror のビジネス継続性機能を使用して、透過的なアプリケーションフェイルオーバーが実現します。</block>
  <block id="23862d7fc14d71369b9feaeb8d7f98b9" category="paragraph">SnapMirror は Site Recovery Manager を使用した SRA レプリケーションに必要です。また、 SnapCenter でセカンダリストレージシステムに Snapshot コピーをレプリケートするためにも必要です。</block>
  <block id="0fdef6775eeade832499deceb497e1d8" category="list-text">* SnapCenter * SnapCenter ソフトウェアは、アプリケーションと整合性のあるデータ保護とクローン管理を実現する、拡張性に優れたユニファイドプラットフォームとプラグインのスイート製品です。AFF ライセンスは、 FAS システムと SnapCenter システムのデータ保護ライセンスバンドルに含まれています。SnapCenter Plug-in for VMware vSphere は、 FAS 、 AFF 、 Cloud Volumes ONTAP 、 ONTAP Select のいずれかのストレージシステムを使用している場合に無償で提供されます。ただし、 SnapRestore と FlexClone のライセンスが必要です。</block>
  <block id="a20c69bb9262b2ab09ca5248996e7d63" category="list-text">* MetroCluster 。 * NetApp MetroCluster は、キャンパスエリアまたはメトロポリタンエリアにおける高可用性とディザスタリカバリを組み合わせた同期レプリケーション解決策で、サイト障害とハードウェア停止の両方からシステムを保護します。データ損失ゼロ（ RPO ゼロ）と高速リカバリ（ RTO が数分以内）で、障害からの透過的なリカバリを実現します。vSphere 環境では、 vSphere Metro Storage Cluster 構成の一部として使用されます。</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="section-title">ONTAP の仮想化ツール</block>
  <block id="7b0abbba24b3ff594f013e524b352ef1" category="paragraph">ネットアップでは、 ONTAP および vSphere と組み合わせて使用し、仮想環境を管理できるスタンドアロンのソフトウェアツールをいくつか提供しています。ONTAP ライセンスには、追加コストなしで次のツールが含まれています。vSphere 環境でこれらのツールがどのように連携するかについては、図 1 を参照してください。</block>
  <block id="abdbcbccf079982daa8ac87124199525" category="paragraph">VMware vSphere 用の ONTAP ツールは、 vSphere とともに ONTAP ストレージを使用するための一連のツールです。vCenter プラグインは、以前 Virtual Storage Console （ VSC ）と呼ばれていたもので、 SAN と NAS のどちらを使用している場合でも、ストレージ管理と効率化機能の簡易化、可用性の向上、ストレージコストと運用オーバーヘッドの削減を実現します。データストアのプロビジョニングのベストプラクティスを使用して、 NFS 環境およびブロックストレージ環境用の ESXi ホスト設定を最適化します。以上のメリットのために、ネットアップでは、 ONTAP ソフトウェアを実行しているシステムで vSphere を使用する際のベストプラクティスとして、これらの ONTAP ツールを使用することを推奨します。vCenter のサーバアプライアンスとユーザインターフェイス拡張機能の両方が含まれています。</block>
  <block id="72c2a2003ef348468d72454dc1a4e214" category="paragraph">NetApp NFS Plug-in for VMware は、 ESXi ホストが ONTAP 上の NFS データストアで VAAI 機能を使用できるようにするためのプラグインです。クローン処理、シック仮想ディスクファイル用のスペースリザベーション、 Snapshot コピーオフロードをサポートしています。コピー処理をストレージにオフロードしても、完了までの時間が必ずしも短縮されるとは限りませんが、 CPU サイクル、バッファ、キューなどのホストリソースがオフロードされます。VMware vSphere 用の ONTAP ツールを使用して、 ESXi ホストにプラグインをインストールできます。</block>
  <block id="e3454e6928ae7a5f9e8a89f5999b80ad" category="section-title">VASA Provider for ONTAP の略</block>
  <block id="708dacf32313dbab741753dcc3ea39fd" category="paragraph">VASA Provider for ONTAP は、 VMware vStorage APIs for Storage Awareness （ VASA ）フレームワークをサポートしています。VMware vSphere 用の ONTAP ツールの一部として提供され、導入を容易にする単一の仮想アプライアンスとして提供されます。VASA Provider では、 VM ストレージのプロビジョニングと監視に役立つように vCenter Server と ONTAP を接続します。VMware Virtual Volumes （ VVol ）のサポート、ストレージ機能プロファイルと個々の VM VVol のパフォーマンスの管理、およびプロファイルの容量と準拠状況の監視用アラームが可能になります。</block>
  <block id="0d05ff779ab06152e20062d098f7eb4a" category="section-title">Storage Replication Adapter の各サポートレベル</block>
  <block id="33aa22e838a3c843929f5b6b75f6c56c" category="paragraph">SRA は、 VMware Site Recovery Manager （ SRM ）と一緒に使用され、本番サイトとディザスタリカバリサイト間のデータレプリケーションを管理して、 DR レプリカの無停止でのテストを行います。検出、リカバリ、再保護のタスクを自動化します。Windows SRM サーバおよび SRM アプライアンス用の SRA サーバアプライアンスと SRA アダプタの両方が含まれています。SRA は、 VMware vSphere 用の ONTAP ツールに含まれています。</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">次の図は、 vSphere 用の ONTAP ツールを示しています。</block>
  <block id="f7e876d450acee7c9ed7b18438440fb2" category="paragraph"><block ref="f7e876d450acee7c9ed7b18438440fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9a06854085afcd104157eb7f0b66c3a" category="summary">ネットアップソリューションの自動化では、構成と管理に RedHat Ansible を利用します。</block>
  <block id="a123daaac5749e4d0965aca160f0adfd" category="doc">NetApp 解決策の自動化</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="section-title">手順</block>
  <block id="d1029167179320d8b6d70b11c3d01bd3" category="list-text">Ansible コントロールノードの要件：</block>
  <block id="9ced761647f5d80fe615526ffff63937" category="list-text">次のパッケージがインストールされた Ubuntu / Debian マシン：</block>
  <block id="ca60b3698dd3d27a5f91e4dc0a1a2546" category="list-text">Python3</block>
  <block id="4ce3ea126bb844d4f8c4ce1a65cbe3ae" category="list-text">Pip3</block>
  <block id="881cbd1ce3fdb52f73a82f8674a2a364" category="list-text">Ansible （バージョン 2.10.0 より前）</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="list-text">Git</block>
  <block id="6e3d8a0ff7934b777031953fe936bac8" category="paragraph">上記の要件がインストールされていない新しい Ubuntu / Debian マシンを使用している場合は、次の手順に従ってそのマシンを Ansible の制御ノードとしてセットアップします。</block>
  <block id="532d3723890df934cc5c2c39477405a2" category="list-text">.sh ファイルを作成します</block>
  <block id="e95a2c08843a70246648b7107a26cec4" category="list-text">以下の内容をファイルに貼り付けます</block>
  <block id="86c8310d98a974adb7ac7c4025dd8b5c" category="list-text">ファイルを実行可能にします</block>
  <block id="22db3e24628482683b9bf06c38e497ee" category="list-text">スクリプトの実行（ルートとして）</block>
  <block id="d82dd9b3245382b365106db0568113e8" category="summary">ネットアップのソリューションを自動化すれば、多くの一般的なインフラタスクやアプリケーションタスクの導入、設定、実行を自動化できます。</block>
  <block id="90305bb6fba97091f683e8b82f9bf805" category="summary">ネットアップのソリューションを自動化すれば、多くの一般的なインフラタスクやアプリケーションタスクの導入、設定、実行を自動化できます。</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">はじめに</block>
  <block id="d78228187c1a83d3bb4d8e97cd657807" category="paragraph">自動化によってネットアップのソリューションの利用が簡易化されます。</block>
  <block id="88b11dbb43daa1023e1e0eac175e0e04" category="section-title">Ansible Control ノードのセットアップ</block>
  <block id="cc720ba6fbd83dd2b0c222e5b1d4419c" category="paragraph">Ansible はエージェントレスの自動化ツールであるため、 1 台のマシン（ Ansible の制御ノード）にインストールするだけで済みます。制御ノードを使用すると、リモートマシン全体を管理できます。リモートマシンの設定を追加する必要はありません。</block>
  <block id="1fd37248272971c6b09693c66e545794" category="inline-link-macro">RHEL8/CentOS8</block>
  <block id="62cb08c48fa7398e2b2fbf365a240e90" category="inline-link-macro">RHEL7/CentOS7</block>
  <block id="7eaf289636bc8d4f8b29b333a0f32dc2" category="inline-link-macro">Ubuntu / Debian</block>
  <block id="e10dea45c0463fb061f253f8deef6de6" category="paragraph">Ansible をインストールする OS のタイプに基づいて、次のいずれかのリンクをクリックして制御ノードのセットアップの詳細な手順を確認します。 <block ref="7dc121073254da4302fc5dcbe0722747" category="inline-link-macro-rx"></block>。 <block ref="965292dac53abeffbcc140f60ed9445a" category="inline-link-macro-rx"></block>。 <block ref="9c83d13c300fc83e32dbf47b4d277c36" category="inline-link-macro-rx"></block></block>
  <block id="5c263f30899f93ff7ccd457ad3eb956f" category="list-text">次のパッケージがインストールされた RHEL / CentOS マシン：</block>
  <block id="7b643b0eef9cf1199195fa05b77fc3c8" category="paragraph">上記の要件がインストールされていない新しい RHEL / CentOS マシンがある場合は、次の手順に従ってそのマシンを Ansible の制御ノードとしてセットアップします。</block>
  <block id="d2052f202108defaf6afc7831ba59362" category="list-text">RHEL-8/RHEL-7 の Ansible リポジトリを有効にします</block>
  <block id="61fbc2f21db84f17551fda6893429d16" category="list-text">RHEL-8 （ root として次のコマンドを実行）</block>
  <block id="77cd42f765e6b40764459a64a979f90c" category="list-text">RHEL-7 （ root として次のコマンドを実行）</block>
  <block id="3fa16e80574aff03c27de1253474a20f" category="list-text">インベントリ変数がある場合は、その変数を変数フィールドに貼り付けます。</block>
  <block id="c7fa74fb4cbaab9d336a8e55bf164684" category="list-text">名前と概要を入力します</block>
  <block id="dca91c3343cc0ad062506cdd14eb7d41" category="summary">ハイブリッドクラウド、デスクトップ仮想化、およびコンテナソリューションの関連資料に追加された最新情報</block>
  <block id="07e257430bade6bc5bce1c2170c6fc0d" category="paragraph">最新のハイブリッドクラウド、デスクトップ仮想化、コンテナソリューションとソリューションの資料の概要</block>
  <block id="2bdc87f51d413e6d2fa23dd26238501f" category="inline-link-macro">VMware vSphere for ONTAP の略</block>
  <block id="4b47c65474ab7fae9b08ddf38d598971" category="inline-link-macro">ネットアップの仮想デスクトップサービス（ VDS ）を使用したハイブリッドクラウド VDI</block>
  <block id="dea91bec9e85387a496bb2c228fc7dc3" category="list-text"><block ref="dea91bec9e85387a496bb2c228fc7dc3" category="inline-link-macro-rx"></block></block>
  <block id="da38226e07ff21f147182bb08be38f6f" category="inline-link">ネットアップを使用したベアメタル環境での Anthos</block>
  <block id="ac1da2af455fc001ba8b58af0e62d151" category="list-text"><block ref="ac1da2af455fc001ba8b58af0e62d151" category="inline-link-rx"></block></block>
  <block id="bfd22ae6cd60e663ed70e43729a64b1a" category="summary">ハイブリッドクラウド、デスクトップ仮想化、コンテナ解決策の機能に関する一連のブログ</block>
  <block id="0ffff76bcc7d5f89f6a352694b916dbd" category="doc">ハイブリッドクラウド、デスクトップ仮想化、およびコンテナに関するブログ</block>
  <block id="0aef0d80b80eebee0590e019fffb3715" category="paragraph">ハイブリッドクラウド、デスクトップ仮想化、およびコンテナソリューションの特定の機能を紹介するブログの概要。</block>
  <block id="b4a5303e0fac342c604f2250a077e3be" category="summary">AI と最新のデータ分析に新たに追加された機能です ソリューション関連資料</block>
  <block id="6c359c33f91503466661c814919afe18" category="paragraph">最新の AI / 最新データ分析ソリューションとソリューションの資料の概要</block>
  <block id="e7f098b026755d10f2c3f16d0ff0b1db" category="inline-link">設計ガイド</block>
  <block id="1027b152cc3e8165ce099ede9548be95" category="list-text"><block ref="1027b152cc3e8165ce099ede9548be95" category="inline-link-rx"></block></block>
  <block id="dfb1e9c5f4c5835e6e1a4173130a49c9" category="inline-link">導入ガイド</block>
  <block id="983044e3ba861493c43c08b9285c3125" category="list-text"><block ref="983044e3ba861493c43c08b9285c3125" category="inline-link-rx"></block></block>
  <block id="d91f70a15d40fe5795af6ded9555e095" category="list-text"><block ref="d91f70a15d40fe5795af6ded9555e095" category="inline-link-rx"></block></block>
  <block id="8e9465b5d4318c8ef9039dfe684619d5" category="list-text"><block ref="8e9465b5d4318c8ef9039dfe684619d5" category="inline-link-rx"></block></block>
  <block id="9004ee13f10e4aa331cdbb0e05878d3f" category="inline-link">GitHub のツールキットにアクセスします</block>
  <block id="604c2d197444e12a03e7c1ba2830e768" category="list-text"><block ref="604c2d197444e12a03e7c1ba2830e768" category="inline-link-rx"></block></block>
  <block id="0f984f9309c692c61a7fc7cc418f3aaf" category="summary">BData Protection および Security ソリューションに新たに追加された機能 クイックリファレンスガイド</block>
  <block id="d6aa2099009bf5a43f1d5210308a91de" category="paragraph">最新のデータ保護およびセキュリティソリューションとソリューションの資料の概要。</block>
  <block id="44516140f9860119a65bb3fc45b9ff39" category="inline-link">PCI-DSS 用 NetApp HCI Verified Architecture</block>
  <block id="5b03dcf0205060a9490f1d572aee619e" category="list-text"><block ref="5b03dcf0205060a9490f1d572aee619e" category="inline-link-rx"></block></block>
  <block id="4725a75839c620bb95363c5f7f2ee9bc" category="cell">VMware Horizon</block>
  <block id="c6f59500cff9fc154e284a0b9b18bb83" category="summary">ネットアップの自動化機能に関する一連のビデオとデモ 解決策</block>
  <block id="cff1a9d42f081481f7d374df8bcbb26b" category="doc">解決策自動化のビデオとデモ</block>
  <block id="4e59e2d3d9f78c4e87a82b3cbcc7e1a3" category="paragraph">ネットアップソリューションの自動化機能の具体的な機能を紹介するビデオとデモの概要</block>
  <block id="6a0ecfbed3f66ec0b5d8989880431ad7" category="summary">データ保護とセキュリティ解決策の機能に関する一連のブログ</block>
  <block id="16be77be7dcecad552bca4efda1efcb1" category="doc">データ保護とセキュリティのブログ</block>
  <block id="fdaef51553bfad628d1d8ee4cd314d79" category="paragraph">データ保護およびセキュリティソリューションの特定の機能を紹介するブログの概要。</block>
  <block id="f3c961b3fcb2ae7229add932837c205a" category="summary">ビジネスアプリケーションとエンタープライズに関する一連のビデオとデモ Database 解決策の機能</block>
  <block id="f7164629c6d69e9fc50c2435382e23c8" category="doc">ビジネスアプリケーションとエンタープライズデータベースのビデオとデモ</block>
  <block id="9c8f0f2cea03121d5372f653983bb29b" category="paragraph">ビジネスアプリケーションとエンタープライズデータベースソリューションの特定の機能を紹介するビデオとデモの概要。</block>
  <block id="a0d2b6fe9ab0a7e386c4c21f70331226" category="section-title">ケーススタディ</block>
  <block id="33be49f7ebc56eb7d336a201f7ac0df6" category="inline-link">Azure NetApp Files を使用して SAP を運用</block>
  <block id="626865aeb52c00e03e8f0df7695c5a5c" category="list-text"><block ref="626865aeb52c00e03e8f0df7695c5a5c" category="inline-link-rx"></block></block>
  <block id="e131204502a58630f2f72937238604c8" category="section-title">ビデオ / デモ</block>
  <block id="e9194e819cadddfb8f6c5e69d11e366b" category="inline-link">Oracle データベース向けのネットアップソリューション</block>
  <block id="2c389096a43e749160e32214cb4a3b89" category="list-text"><block ref="2c389096a43e749160e32214cb4a3b89" category="inline-link-rx"></block></block>
  <block id="2b1dd692c0da980c4ec2ad9fd523c47d" category="inline-link">Azure NetApp Files 上の SQL 高可用性クラスタ</block>
  <block id="99945a626f3fb01dbeac75f40a6c2c8e" category="list-text"><block ref="99945a626f3fb01dbeac75f40a6c2c8e" category="inline-link-rx"></block></block>
  <block id="46b8f9361fae73f13467cd1aaff186ba" category="summary">ネットアップソリューション資料に対する最近の変更点のログ</block>
  <block id="679ce0aa9d3d54bfddd37e1b78b802de" category="doc">ネットアップソリューションの変更ログ</block>
  <block id="aceacf14369d872e8cb00f62613f52c6" category="paragraph">ネットアップソリューション資料に対する最近の変更点。最新の変更が最初に表示されます。</block>
  <block id="2e130352b486464834bcc7dda1ff2603" category="cell">VMware 仮想化</block>
  <block id="408649df4ac74ae19e47eef7d060c5cb" category="cell">解決策の自動化</block>
  <block id="cf04feec36847ba9c9671b28661cd1fc" category="sidebar">ネットアップソリューションのドキュメント</block>
  <block id="6174d88cc7c0409df3e035a5c9d089cb" category="sidebar">変更ログ</block>
  <block id="e799e148c709b216080d260919cc9b9f" category="sidebar">AI による最新データ分析</block>
  <block id="91770f038cd944a1d3b9b347edeb2b10" category="sidebar">新機能</block>
  <block id="17c3771ed0b6c1ae15740eff715e9922" category="sidebar">ビデオとデモ</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="sidebar">ブログ</block>
  <block id="0333ddced253ee1c6929eda5612dea92" category="sidebar">自動化をリクエスト</block>
  <block id="b0ac6120dada9135114784db22a59940" category="sidebar">最新のデータ分析</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">Splunk SmartStore を使用した NetApp StorageGRID</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E シリーズ E5700 および Splunk Enterprise</block>
  <block id="1c4dff0a00340691e103ef63154df371" category="sidebar">Google Anthos</block>
  <block id="4549cdf15178a5f0535be7f0f86cdb4d" category="sidebar">エンタープライズデータベース</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="sidebar">Oracle データベース</block>
  <block id="c880b35e02dbb5854452c86028138e2a" category="sidebar">NetApp ONTAP への Oracle データベースの導入</block>
  <block id="bc113eb23aa0579a5e1d93e97ca13635" category="sidebar">NetApp EF シリーズを基盤にした Oracle データベース</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server の場合</block>
  <block id="7c02456b91ace7501ea6f18d1657dcf7" category="sidebar">Microsoft SQL Server の刷新</block>
  <block id="5c008a8422e884d74da1d4b50a7ada55" category="sidebar">NetApp EF シリーズでの Microsoft SQL Server のベストプラクティスガイド</block>
  <block id="9a9891facf2fa1c878c0fc18c6638005" category="sidebar">AI 統合インフラ</block>
  <block id="2967ab4748573d0cb6f2c4084c4fd70f" category="sidebar">NetApp E シリーズリファレンスアーキテクチャを使用した BeeGFS</block>
  <block id="1db760587a86f5c1b9ab39aa8cf8cf3d" category="sidebar">NetApp E シリーズストレージによる IBM Spectrum Scale の導入</block>
  <block id="08479c0355c887a02e772206b0d5d7f5" category="sidebar">AI および ML 向けの NetApp ONTAP および Lenovo ThinkSystem SR670 トレーニングワークロードのモデル化</block>
  <block id="e648dd2d4df65a903e9c1204d81abaed" category="sidebar">用 NetApp AFF A800 および富士通サーバ PRIMERGY GX2570 M5 AI と ML モデルのトレーニングワークロード</block>
  <block id="6a571fb799acb43b64f874729f838e2a" category="sidebar">データパイプライン、データレイク、管理</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">自動運転ワークロード向けの NetApp StorageGRID データレイク</block>
  <block id="ce3b746194cb1fb7d96dfe14187115e0" category="sidebar">データキャッシング機能を備えたハイブリッドクラウド AI オペレーティングシステム</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">ビッグデータ環境から AI へのデータの移動 環境</block>
  <block id="f1e7c981dec3bcee348bda96c55363c4" category="sidebar">NVIDIA を使用した会話型 AI</block>
  <block id="d5c1931461d1e204a84a486796df2cca" category="sidebar">実行： AI を使用したネットアップオーケストレーション解決策</block>
  <block id="c0a0f5bbb431dea70000d73b29e50249" category="sidebar">AI を実行することでクラスタと GPU の利用率を最適化</block>
  <block id="09c995632f33d1ee4a581eb951793f35" category="sidebar">AI インストールを実行</block>
  <block id="5c9e37e6d7e6f5e3a76854d8343d626b" category="sidebar">AI ダッシュボードとビューを実行します</block>
  <block id="29ebede332931243e314d8a3f333c1a7" category="sidebar">Run AI CLI でのジョブの送信</block>
  <block id="2943702718c42a5063e0c70598cebdc6" category="sidebar">自動運転ワークロード向けの NetApp ONTAP AI 解決策設計</block>
  <block id="d11813566a7c636e892d384601baf2c3" category="sidebar">ヘルスケア向け NetApp ONTAP AI リファレンスアーキテクチャ：診断イメージング</block>
  <block id="ab8526a90cc9cc979ddd23c87fff57bd" category="sidebar">金融サービスのワークロード向けの NetApp ONTAP AI リファレンスアーキテクチャ</block>
  <block id="6efd886c994d37b6577e22359be2310e" category="sidebar">NetApp E シリーズと BeeGFS を使用した AI 導入</block>
  <block id="3863e8a73e226ce0c0a6ad02b90ee75b" category="sidebar">Quantum StorNext with NetApp E-Series Systems Design Guide 』を参照してください</block>
  <block id="7891972f4586e6ee183ea541991ebe9f" category="sidebar">Quantum StorNext with NetApp E-Series Systems Deployment Guide 』を参照してください</block>
  <block id="861a3cbb41e90c0f7d83b50b7522b0bd" category="sidebar">ビジネスアプリケーション</block>
  <block id="f27edcc7a209983dc37cbcdb0df49ce7" category="sidebar">仮想デスクトップ</block>
  <block id="a87e5ca19422686ef96f1e6799e9111d" category="sidebar">仮想デスクトップサービス（ VDS ）</block>
  <block id="dede82866780d163734b443c5f4d484e" category="sidebar">ネットアップの仮想デスクトップサービスによるハイブリッドクラウド VDI</block>
  <block id="b89c617ff394cc85df3935994baa194b" category="sidebar">Login VSI を使用した単一サーバの負荷テスト</block>
  <block id="a1da2a2d050a6b61256020afd015a056" category="sidebar">業界向けソリューション</block>
  <block id="739169d2451850e6df7246db70c28cc7" category="sidebar">ESG テクニカル検証：『 VDI at Enterprise Scale with NetApp Virtual Desktop Service 』</block>
  <block id="3acc5e85d752378c6f1b9154f379b475" category="sidebar">VMware によるエンドユーザコンピューティング（設計ガイド）</block>
  <block id="87e25a8d0e462ac8d7158e587f376605" category="sidebar">VMware と NVIDIA GPU を使用したエンドユーザコンピューティング（設計ガイド）</block>
  <block id="d840a196af6c9e07c3ac3b20b15fb724" category="sidebar">VMware と NVIDIA GPU を使用したエンドユーザコンピューティング（導入ガイド）</block>
  <block id="f93781578174ca3309bd3ac126884af4" category="sidebar">VMware for 3D Graphics によるエンドユーザコンピューティング</block>
  <block id="8619770bb94b4ac2d3ef4a8639dac91f" category="sidebar">Ansible コントロールノードをセットアップ（ CLI ベースの導入向け）</block>
  <block id="47ac29a4a2e3c3e4581e035d792ee4ac" category="sidebar">RHEL / CentOS マシンの場合</block>
  <block id="d74c216bc36310fb7cb045522918e606" category="sidebar">Ubuntu / Debian マシンの場合</block>
  <block id="073616205ad0e6bcb86754e5a151281a" category="sidebar">AWX/Ansible タワーをセットアップします （ AWX/ タワーベースの導入の場合）</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">自動化を申請</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">『 Apache Spark Workload with NetApp Storage 解決策』（導入ガイド）</block>
  <block id="b278438874f41a76068d02368e65aa3e" category="doc">このリポジトリについて</block>
  <block id="404af48e0cb5f84306fbd93fac2ff8be" category="paragraph">ネットアップソリューションリポジトリの簡単な紹介 - 特定のソリューションの参照先と、このリポジトリの使用方法</block>
  <block id="45ac6b09a3b8f5ea07ca656ca8dea987" category="section-title">リポジトリのナビゲーション</block>
  <block id="c28e40ef527e43509a0fcd3b114ff824" category="paragraph">リポジトリのナビゲーションは、ページの左側に表示されるメインのサイドバーで管理されます。ソリューションは、ネットアップソリューションの「テクノロジタワー」と定義された上位レベルの技術領域に分類されます。</block>
  <block id="e9982e506e30915713c7485a2e77633b" category="section-title">技術タワーの概要</block>
  <block id="d67372be0bd12a2ddbcf795ccfacc7de" category="cell">* セクション *</block>
  <block id="f14c276c07197ebef1394a5a219087a1" category="cell">* 概要 *</block>
  <block id="f5f0336c80fe8cdd5a51752c1ce61ac3" category="cell">データ分析ソリューションのコレクション（例 Splunk SmartStore 、 Apache Spark など）</block>
  <block id="d83d094e8e3ce7450bf099061814d148" category="cell">Red Hat Ansible による解決策自動化の開始方法の概要</block>
  <block id="a0067ab2420cbaebc335efc5c2433c45" category="inline-link-macro">変更ログ</block>
  <block id="1144ef243d0744e29b8bb83edad3cd0d" category="paragraph">リポジトリに対するすべての主要な変更（新しいソリューション、メジャーアップデート、新しいビデオ / デモなど）は、で追跡されます <block ref="95485865b5d32e0932da8207f23060b5" category="inline-link-macro-rx"></block>。</block>
  <block id="bea4c2c8eb82d05891ddd71584881b56" category="section-title">フィードバック</block>
  <block id="3523ec156cfc8217bb64d1273e5663fa" category="sidebar">ネットアップのソリューションについて</block>
  <block id="4be1d7a9b1a8d85ed7d1cf5c72b23928" category="paragraph">ネットアップの仮想デスクトップサービスは、 Microsoft のリモートデスクトッププロトコルを使用して仮想デスクトップのセッションとアプリケーションにアクセスします。特定のサーバモデルでホストできる最大ユーザ数を決定するために、 Login VSI ツールを使用しました。Login VSI は、特定の間隔でのユーザログインをシミュレートし、ドキュメントのオープン、メールの読み書き、 Excel や PowerPoint での作業、ドキュメントの印刷、ファイルの圧縮、ランダムな休憩などのユーザ操作を実行します。また、応答時間も測定します。サーバの使用率が低い場合はユーザの応答時間が短く、ユーザセッションが追加されると応答時間が長くなります。Login VSI は、初回のユーザログインセッションに基づいてベースラインを決定し、ベースラインからのユーザ応答が 2 秒を超えると最大ユーザセッション数を報告します。</block>
  <block id="65f671ed80b2c6f0cc371ab295230a3a" category="paragraph">次の図は、 H615C の Login VSI の応答時間とアクティブなセッションを示しています。</block>
  <block id="5c29ae1e9123280c1975dbc407f3eca3" category="paragraph">次の図に、 vSphere ホストおよび VM に対する H615C Login VSI テスト中の Cloud Insights のパフォーマンス指標を示します。</block>
  <block id="ca32c5a534baaf5f6dc3e6e6fed62450" category="doc">GPU に関する考慮事項</block>
  <block id="aaca2e6fe88c6861582a8d1a20acfd4f" category="summary">仮想デスクトップサービスの ONTAP 機能。</block>
  <block id="bc9c47c8423d4537fdbf118b09a80084" category="doc">仮想デスクトップサービスの ONTAP 機能</block>
  <block id="472986236003195075a1428fe6103f4c" category="paragraph">次の ONTAP 機能は、仮想デスクトップサービスでの使用に適しています。</block>
  <block id="6128a47ce6baa55dbad9293234f2f65c" category="list-text">* スケールアウトファイルシステム。 * ONTAP FlexGroup ボリュームは 20PB 以上のサイズに拡張でき、 1 つのネームスペースに 4 、 000 億を超えるファイルを格納できます。クラスタには最大 24 個のストレージノードを含めることができ、各ノードには、使用するモデルに応じた柔軟な数のネットワークインターフェイスカードを使用できます。</block>
  <block id="960f11687b64143d44db7f4ffcb33ef2" category="paragraph">ユーザの仮想デスクトップ、ホームフォルダ、ユーザプロファイルコンテナ、共有データなどは、ファイルシステムの制限を気にせずに、必要に応じて拡張できます。</block>
  <block id="ab7ad572d2251b9b27fa0213fde8531f" category="list-text">* ファイルシステム分析。 * XCP ツールを使用して、共有データの分析情報を取得できます。ONTAP 9.8+ と ActiveIQ の Unified Manager を使用すると、ファイルのメタデータ情報の照会と取得、コールドデータの特定を簡単に実行できます。</block>
  <block id="885f3e34ca03dc8ff35c0bac51b384f7" category="list-text">* クラウドの階層化。 * コールドデータをクラウド内のオブジェクトストアや、データセンター内の任意の S3 互換ストレージに移行できます。</block>
  <block id="fb38ee94b865e67571a08316a3baac38" category="list-text">* ファイルバージョン。 * ユーザは、 NetApp ONTAP Snapshot コピーで保護されているファイルをリカバリできます。ONTAP の Snapshot コピーでは変更されたブロックのみが記録されるため、スペース効率に優れています。</block>
  <block id="9b7db1dd6f422e5f07ded1d3b7b04d90" category="list-text">* グローバル・ネームスペース。 * ONTAP FlexCache テクノロジーにより、ファイル・ストレージのリモート・キャッシュが可能になり、 ONTAP ストレージ・システムを含む複数の場所で共有データを容易に管理できます。</block>
  <block id="827aa7cb1ad6ddbf99e040efe34725a8" category="list-text">* セキュアマルチテナンシーのサポート。 * 1 つの物理ストレージクラスタを、それぞれ独自のボリューム、ストレージプロトコル、論理ネットワークインターフェイス、 ID および認証ドメイン、管理ユーザなどを持つ複数の仮想ストレージアレイとして提供できます。そのため、テスト、開発、本番環境など、複数のビジネスユニットや環境でストレージアレイを共有することができます。</block>
  <block id="6c36afe01468d888b334a4432dcac4b2" category="paragraph">パフォーマンスを保証するために、アダプティブ QoS を使用して使用済みスペースまたは割り当て済みスペースに基づいてパフォーマンスレベルを設定し、クォータを使用してストレージ容量を制御することができます。</block>
  <block id="b1a678f5f86de8ff8a5b9b1c4b3772b8" category="list-text">* VMware 統合。 * VMware vSphere 用 ONTAP ツールは、データストアのプロビジョニング、 vSphere ホストのベストプラクティスの実装、および ONTAP リソースの監視を行うための vCenter プラグインを提供します。</block>
  <block id="9b12997ae1d332c9003c444a6ff8918a" category="paragraph">ONTAP は、 SCSI / ファイルの処理をストレージアレイにオフロードするための vStorage API for Array Integration （ VAAI ）をサポートしています。ONTAP は、 vStorage APIs for Storage Awareness （ VASA ）もサポートしており、ブロックプロトコルとファイルプロトコルの両方をサポートしています。</block>
  <block id="025e05e390f2d7ef7708bb42d81e1eeb" category="paragraph">SnapCenter Plug-in for VMware vSphere を使用すると、ストレージアレイの Snapshot 機能を使用して仮想マシンのバックアップとリストアを簡単に実行できます。</block>
  <block id="3452f822915108b5d640f3288959e7fd" category="paragraph">ActiveIQ Unified Manager は、 vSphere 環境でストレージネットワークをエンドツーエンドで可視化できる機能を提供します。管理者は、 ONTAP でホストされている仮想デスクトップ環境で発生する可能性のあるレイテンシの問題を簡単に特定できます。</block>
  <block id="c9559fb9abb51cf76cc973d06c7e730c" category="list-text">* セキュリティコンプライアンス。 * ActiveIQ Unified Manager では、複数の ONTAP システムを監視し、ポリシー違反のアラートを通知できます。</block>
  <block id="875c0a88cb08e888c642bbcc19cb33a2" category="list-text">* マルチプロトコル対応。 * ONTAP はブロック（ iSCSI 、 FC 、 FCoE 、 NVMe/FC ）、ファイル（ NFSv3 、 NFSv4.1 、 SMB2.x 、および smb3.x ）のストレージプロトコル、およびオブジェクト（ S3 ）ストレージプロトコル。</block>
  <block id="4ac79aa8e1431a96a08ba58c1e17a104" category="list-text">* 自動化のサポート。 * ONTAP は、 VDS 管理ポータルでタスクを自動化する REST API 、 Ansible 、 PowerShell モジュールを提供します。</block>
  <block id="60ece3fee8421729100872ec44f1cda9" category="summary">導入の一環として、ユーザプロファイル、共有データ、およびホームドライブフォルダをホストするファイルサービス方式を選択できます。使用可能なオプションは、ファイルサーバ、 Azure ファイル、 Azure NetApp Files です。ただし、導入後に、 Command Center ツールを使用してこの選択を変更し、任意の SMB 共有を参照することができます。NetApp ONTAP を使用してホストすると、さまざまなメリットがあります。</block>
  <block id="ef9fd867f3eaed93e0806bd027825218" category="inline-link">データ層を変更します</block>
  <block id="1b8c33cc721641b8b0555f2d7b5c2773" category="inline-link-macro">NetApp ONTAP を使用してホストすると、さまざまなメリットがあります。</block>
  <block id="698e77d7e678617a2ae27ca2525bfbf7" category="paragraph">導入の一環として、ユーザプロファイル、共有データ、およびホームドライブフォルダをホストするファイルサービス方式を選択できます。使用可能なオプションは、ファイルサーバ、 Azure ファイル、 Azure NetApp Files です。ただし、導入後に、 Command Center ツールを使用してこの選択を変更し、任意の SMB 共有を参照することができます。 <block ref="50056d02f0a90e2e837160c093f1b22b" category="inline-link-macro-rx"></block>。SMB 共有を変更する方法については、を参照してください<block ref="336429df384a16f14c12cbc8dba62525" category="inline-link-rx"></block>。</block>
  <block id="1afc494dd7d35016d9524e06b68dbf2a" category="paragraph">今回の検証では、コアリソースと管理リソースを Azure 上の同じ VM に導入し、エッジリソースを NetApp HCI 上に配置しました。コアは大量のデータアクセスが必要な領域であり、エッジはコアのサブセットであることに注意してください。ソフトウェアをインストールしたら、使用前にライセンスをアクティブ化する必要があります。これには、次の手順を実行します。</block>
  <block id="70366038f1d44fef6c71f615b677b9cf" category="list-text">[ ライセンスの設定 ] セクションで、 [ ここをクリックしてライセンスの有効化を完了します ] リンクを使用します。次に、コアを登録します。</block>
  <block id="a2184b1f206fd35eeb448e9937bdabe7" category="paragraph">任意のクライアントマシンから、ファイルサーバ上の共有にアクセスするために使用した管理者は、 UNC パス \\&lt;edge サーバ名 &gt;\FASTDATA\&lt;core サーバ名 &gt;\&lt; バックエンドファイルサーバ名 &gt;\&lt; 共有名 &gt;` を使用して GFC エッジからアクセスできます。管理者は、このパスをエッジロケーションのユーザードライブマッピング用のユーザーログオンスクリプトまたは GPO に含めることができます。</block>
  <block id="a067b7082c28e7dbf856ab55b29d1acb" category="paragraph">Salesforce のデータ保護のデモについては、を参照してください<block ref="dd6e5767407887626a36af7b68defda9" category="inline-link-rx"></block>。</block>
  <block id="0fe8a299bf61a0d1bbca5d975dc94fcc" category="paragraph">NetApp VDS を使用したハイブリッド VDI により、サービスプロバイダとエンタープライズ仮想デスクトップ管理者は、ユーザに影響を与えることなく、簡単にリソースを他のクラウド環境に拡張できます。オンプレミスのリソースを使用することで、リソースをより効率的に管理でき、需要に応じて幅広い選択肢（コンピューティング、 GPU 、ストレージ、ネットワーク）を選択できます。</block>
  <block id="95404d16cb98456e438a61d79a0a31d9" category="paragraph">NetApp HCI は、ストレージノードとコンピューティングノードが混在するハイブリッドクラウドインフラです。モデルに応じて、 2 ラックユニットまたはシングルラックユニットのいずれかとして使用できます。VM の導入に必要なインストールと設定は、 NetApp Deployment Engine （ NDE ）で自動化されています。コンピューティングクラスタは VMware vCenter で管理され、ストレージクラスタは NDE で導入された vCenter Plug-in で管理されます。mNode と呼ばれる管理 VM が NDE の一部として導入されます。</block>
  <block id="449aaf51a6dfa9c0e17423ae5938d674" category="inline-link">VMware との互換性ガイド</block>
  <block id="1046a3e2377d26c40f75eb2cd2f268da" category="admonition">ネットアップでは、表示されているコンピューティングサーバに接続されたストレージをサポートしてい を参照してください<block ref="72cc7e3e2b2d7f777e05aa309ef5f733" category="inline-link-rx"></block>。</block>
  <block id="bdced20c33601e0149aecb44114cfdc5" category="paragraph">H610C コンピューティングノードは 2 ラックユニットで、 H615C は 1 ラックユニットのサイズで、消費電力は少なくなります。H615C は、 H.264 および H.265 （ High Efficiency Video Coding [HEVC] ） 4 ： 4 ： 4 のエンコードとデコードをサポートします。また、 VP9 デコーダの主流化が進む中、 YouTube が提供する WebM コンテナパッケージでもビデオに VP9 コーデックを使用しています。</block>
  <block id="29707848401dd26f02baed07b9a416c1" category="paragraph">ネットアップ VDS は、必要なコードベースに基づいて利用可能なセットアップアプリケーションを使用して Microsoft Azure に導入できます。現在のリリースが利用可能です<block ref="deb5bc0c1293f06a53a77d04b921abbd" category="inline-link-rx"></block> また、今後リリースされる製品のプレビュー版もご用意しています<block ref="b5073644bfe6db36c388c6bdbca64b49" category="inline-link-rx"></block>。</block>
  <block id="33491606222aecbfbdfa3fc8f13ffded" category="paragraph">NetApp Virtual Desktop Service は、仮想デスクトップおよびアプリケーション環境を消費しやすくするだけでなく、ビジネス上の課題にも重点的に対応します。VDS をオンプレミスの ONTAP 環境で拡張することで、高速クローン、インライン重複排除、コンパクション、シンプロビジョニングなど、 VDS 環境でネットアップの強力な機能を使用できます。 圧縮機能を使用できます。これらの機能により、オールフラッシュストレージでストレージコストを削減し、パフォーマンスを向上させることができます。VMware vSphere ハイパーバイザーでは、仮想ボリュームと vSphere API を使用してアレイを統合することで、サーバのプロビジョニング時間を最小限に抑えることができます。お客様は、ハイブリッドクラウドを使用して、要件の厳しいワークロードに適した環境を選択し、コストを削減できます。オンプレミスで実行されるデスクトップセッションは、ポリシーに基づいてクラウドリソースにアクセスできます。</block>
  <block id="2eb34c5311117b56d2c8eb33494052a3" category="paragraph">共有データのワークスペース固有のドライブレターマッピングは、 GPO を使用して処理できます。プロフェッショナルサービスまたはサポートチームは、 Active Directory OU 名、 FSLogix の導入を有効または無効にするオプション、さまざまなタイムアウト値などの詳細タブを使用して設定をカスタマイズできます。</block>
  <block id="f6c93f3609bb3be799ed32b6a601d5fc" category="section-title">コマンドセンター（以前は TestVdc ツールと呼ばれていました）</block>
  <block id="46433f623976c5af8ebdc7ab92816a48" category="inline-link">コマンドセンターの概要</block>
  <block id="bf69b43c185864d35a461d8f1c3ea56e" category="paragraph">Command Center と必要なロールを起動するには、を参照してください <block ref="d7ce3bd63a8a34b9b1630abb82acb951" category="inline-link-rx"></block>。</block>
  <block id="b425cca2998cc4a7041a0baf7681e912" category="paragraph">次の操作を実行できます。</block>
  <block id="017b9aa293da801da252c728736f02db" category="inline-link">自動ログ</block>
  <block id="580acc766c3f0e464b462d271028dc32" category="paragraph"><block ref="5f6615a18cd0f2f0bcfb7578db5d1c9e" category="inline-image-macro-rx" type="image"></block>チェックしてください <block ref="11597d7347faee3da56e0e01d5ba1de2" category="inline-link-rx"></block> 詳細については、</block>
  <block id="d1c59e5cbf684efb4f69f300e72a4ac9" category="doc">運用管理</block>
  <block id="8a883bd6e43add9d94d923704bc177a7" category="inline-link-macro">次の手順：ツールとログ</block>
  <block id="28f1e69837c0c21f4dcb8260d6ab5e97" category="paragraph"><block ref="28f1e69837c0c21f4dcb8260d6ab5e97" category="inline-link-macro-rx"></block></block>
  <block id="fb67e63246489555a7e8929a138ced4c" category="paragraph">ワークスペースはデスクトップ環境で構成されます。これは、オンプレミスでホストされている共有リモートデスクトップセッションや、サポートされている任意のクラウド環境で構成されます。Microsoft Azure では、 Windows 仮想デスクトップを使用してデスクトップ環境を永続化できます。各ワークスペースは、特定の組織またはクライアントに関連付けられます。新しいワークスペースを作成するときに使用できるオプションを次の図に示します。</block>
  <block id="5a70681d968007936b9d092ba1a93313" category="paragraph">必要に応じて、導入 VM リソースのデフォルト設定をワークスペースで上書きできます。WVD の場合、 WVD ホストプール（セッションホストとアプリケーショングループを含む）および WVD ワークスペースは、クラウドワークスペース管理スイートポータルから管理することもできます。WVD ホストプールの詳細については、こちらを参照してください<block ref="283c24f69dac0d05b60b041138870b19" category="inline-link-rx"></block>。</block>
  <block id="c70675dc3857ae45ab2475f60c0f1f85" category="paragraph">ネットアップは、 WVD またはリモートアプリケーションによる仮想デスクトップの高速プロビジョニング、 Azure NetApp Files との迅速な統合など、多数のクラウドサービスを提供します。</block>
  <block id="8b32dee3fc7d9223248420cb828c5527" category="paragraph">従来、 IT 部門はリモートデスクトップサービスのプロビジョニングと顧客への提供に数週間かかっていました。プロビジョニングとは別に、アプリケーション、ユーザプロファイル、共有データ、グループポリシーオブジェクトを管理してポリシーを適用することは困難です。ファイアウォールルールは複雑さを増し、別のスキルセットとツールを必要とします。</block>
  <block id="fd9a0083b0a0e084ce6fb8d2ca64272f" category="paragraph">Microsoft では、 Windows 10 のマルチセッションを、 Azure 上の Windows Virtual Desktop 環境専用に提供しています。認証と ID は仮想デスクトップテクノロジによって処理されます。 WVD を使用するには、 Azure Active Directory と（ AD Connect との間で）同期された Azure Active Directory と、 Active Directory に参加したセッション VM が必要です。RDS では、ユーザ ID と認証、および VM ドメインの参加と管理に Active Directory が必要</block>
  <block id="9ea3c4f34057d91531ae286e3efe62c3" category="paragraph">Azure の WVD の場合、 Microsoft は NetApp VDS で消費されるプラットフォームサービスを提供します。他の環境では、 NetApp VDS は Microsoft リモートデスクトップサービスの導入と構成をオーケストレーションします。NetApp VDS は、 WVD Classic と WVD ARM の両方をサポートし、既存のバージョンのアップグレードにも使用できます。</block>
  <block id="71110c8ffc8b198bc951f6e587fbcddf" category="paragraph">Azure WVD の実装では、 Microsoft がクライアントのアクセスエントリポイントを処理し、さまざまな OS でネイティブに使用できる Microsoft WVD クライアントによって使用できます。Web ベースのポータルからもアクセスできます。クライアントソフトウェアの構成は、グループポリシーオブジェクト (GPO) または顧客が優先するその他の方法で処理する必要があります。</block>
  <block id="061d5215d4dd8b8e2b7d9f2498a4a8c3" category="paragraph">ネットアップの VDS では、作成したイメージテンプレートを使用することも、クラウドベースのプロビジョニングの市場にある既存のテンプレートを使用することもできます。管理するイメージの数を減らすために、ベースイメージを使用できます。また、付属のフレームワークを使用して、必要な追加アプリケーションをプロビジョニングし、 chocolatey 、 MSIX アプリケーションアタッチ、 PowerShell などのコマンドラインツールを含めることができます。カスタムスクリプトでも、マシンライフサイクルイベントの一部として使用できます。</block>
  <block id="fd324b11a163d2dae6bf3f9654381d16" category="inline-link-macro">次の手順：仮想デスクトップサービスの ONTAP 機能</block>
  <block id="25838148a81bcaa2b7e931ef8cd65a13" category="paragraph"><block ref="25838148a81bcaa2b7e931ef8cd65a13" category="inline-link-macro-rx"></block></block>
  <block id="93e14ba37d069eff22130cf694c451c1" category="summary">NetApp AFF は、低レイテンシのパフォーマンス、統合データプロテクション、マルチプロトコルサポート、ノンストップオペレーションを実現する堅牢なオールフラッシュストレージプラットフォームです。NetApp ONTAP データ管理ソフトウェアを搭載した NetApp AFF は、ストレージシステムのメンテナンスからアップグレード、完全な交換に至るまで、ノンストップオペレーションを実現します。</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">解決策の概要</block>
  <block id="9ecccbf5710194af15cca545b567957a" category="section-title">NetApp ONTAP on NetApp AFF / FAS</block>
  <block id="13a74472f5a5018f40319d30a728d03e" category="paragraph">NetApp ONTAP は、わかりやすい GUI 、自動化統合機能を備えた REST API 、 AI に基づく予測分析と修正措置、ハードウェアの無停止アップグレード、ストレージ間インポートなどの機能を備えた強力なストレージソフトウェアツールです。</block>
  <block id="3716516b242be48f15f8cbce6557a296" category="paragraph">ONTAP は以下の機能を提供します。</block>
  <block id="3e23168685787e9deffccb3bdb29d98a" category="list-text">NFS 、 CIFS 、 iSCSI 、 FC 、 FCoE を同時にデータアクセスと管理できるユニファイドストレージシステム FC-NVMe プロトコルが必要です。</block>
  <block id="11927aa24f71bc959d85115c8dd8c3a9" category="list-text">導入モデルには、オンプレミスのオールフラッシュ、ハイブリッド、オール HDD のハードウェア構成、 ONTAP Select などのサポートされるハイパーバイザーを使用する VM ベースのストレージプラットフォーム、 Cloud Volumes ONTAP などのクラウドがあります。</block>
  <block id="65c42edcb28a34e276f92dd9b2172613" category="list-text">ONTAP システムでは、データの自動階層化、インラインデータ圧縮、重複排除、コンパクションがサポートされ、データストレージ効率が向上しています。</block>
  <block id="f0a8a62c8d7ea4d12a7f1c95b40d3cb3" category="list-text">ワークロードベースの QoS 制御ストレージ：</block>
  <block id="1e16ebc829d46d68a51d55ac22293b1e" category="list-text">パブリッククラウドとのシームレスな統合により、データの階層化と保護を実現ONTAP は、あらゆる環境に対応する堅牢なデータ保護機能も備えています。</block>
  <block id="613db5a747bd15eeccbcbedce5bd8888" category="list-text">* NetApp Snapshot コピー。 * 最小限のディスク・スペースでデータをポイント・イン・タイムで高速バックアップし、パフォーマンス・オーバーヘッドを追加する必要はありません。</block>
  <block id="8f666d296151faf9c472110831227243" category="list-text">* NetApp SnapMirror 。 * 1 つのストレージ・システムから別のストレージ・システムへデータの Snapshot コピーをミラーリングします。ONTAP では、他の物理プラットフォームやクラウドネイティブのサービスへのデータのミラーリングもサポートされています。</block>
  <block id="5685b3f13393b751231ff096f77e6747" category="list-text">* NetApp SnapLock 。 * 指定された期間にわたって上書きまたは消去できない特殊なボリュームに書き込むことにより、書き換え不可能なデータを効率的に管理します。</block>
  <block id="dff1063d1e007396b7fb75f266dd48b7" category="list-text">* NetApp SnapVault 。 * は、複数のストレージ・システムのデータを、指定されたすべてのシステムのバックアップとして機能する中央の Snapshot コピーにバックアップします。</block>
  <block id="779cb4084f09228e9562ca3bedc5555c" category="list-text">* NetApp SyncMirror 。 * 同じコントローラに物理的に接続された 2 つの異なるディスクプレックスに対して、データをリアルタイムで RAID レベルでミラーリングします。</block>
  <block id="929a0581ca4b2982313e21e51effbc10" category="list-text">* NetApp SnapRestore * を使用すると、 Snapshot コピーからオンデマンドでバックアップされたデータを迅速にリストアできます。</block>
  <block id="774a065cb3548cc61fb0ec3bc1494fbe" category="inline-link">ONTAP 9 ドキュメンテーション・センター</block>
  <block id="fce4095b40c80c8632028b9837563736" category="list-text">* NetApp FlexClone 。 * Snapshot コピーに基づいて、ネットアップボリュームの読み書き可能なフルコピーを瞬時にプロビジョニングできます。ONTAP の詳細については、を参照してください<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>。</block>
  <block id="c389369b80a8ce8ead607b4c7088682e" category="paragraph">NetApp ONTAP は、オンプレミス、仮想環境、クラウド環境で利用できます。</block>
  <block id="75714c8168a0c2a2594249ece5acf44c" category="paragraph"><block ref="75714c8168a0c2a2594249ece5acf44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0694d53b19f7a5e452e776ee3d2e9a4" category="paragraph">NetApp Trident は、オープンソースで、 Google Cloud Anthos を含むコンテナや Kubernetes ディストリビューション向けに完全にサポートされているストレージオーケストレーションツールです。NetApp ONTAP ソフトウェアを含む、ネットアップのストレージポートフォリオ全体と連携します。Trident は CSI に完全に準拠しているため、ストレージ管理者の手を煩わせることなく、ネットアップのストレージシステムからストレージをプロビジョニングして管理できるので、 DevOps ワークフローが高速化されます。Trident は、 Kubernetes API エンドポイントと直接通信するオペレータとして導入され、 NetApp ストレージシステム上でボリュームを作成および管理することによって、コンテナのストレージ要求を永続ボリューム要求（ PVC ）の形式で処理します。</block>
  <block id="dad787ba7494eee7d6dbd3cef7e5900e" category="paragraph">永続ボリューム（ PVS ）は、 Kubernetes 環境で定義されたストレージクラスに基づいてプロビジョニングされます。ストレージ管理者が作成したストレージバックエンド（プロジェクトのニーズに応じてカスタマイズ可能）とストレージシステムモデルを使用して、圧縮、特定のディスクタイプ、 QoS レベルなど、パフォーマンスを保証する高度なストレージ機能をいくつでも実行できます。</block>
  <block id="73cdbc9c6537713844b52fa7c0f1e655" category="paragraph">NetApp Trident の詳細については、を参照してください<block ref="9f564c4a71f7ad715885fb9db4485dda" category="inline-link-rx"></block> ページ</block>
  <block id="3068002de1b5d66a6a163ddc9883ad94" category="paragraph">Trident は、ネットアップポートフォリオの各システムとサービスでストレージをオーケストレーションします。</block>
  <block id="6d906f4c160e6416d4f0c02a0fb9696c" category="paragraph"><block ref="6d906f4c160e6416d4f0c02a0fb9696c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c572f7c92d4b91543f94621d03cf993" category="section-title">Google Cloud の Anthos</block>
  <block id="885a32398324f13cbf847894ab05bb41" category="paragraph">Google Cloud の Anthos は、クラウドベースの Kubernetes データセンター解決策で、アプリケーション開発に重点を置いたアジャイルワークフローを採用しながら、最新のハイブリッドクラウドインフラを構築、管理できます。ベアメタル上の Anthos は、オンプレミスの物理サーバ上で直接実行する Anthos の機能を拡張し、ハイパーバイザーレイヤーを必要とせずに Google Cloud の Anthos GKE クラスタと相互運用できます。</block>
  <block id="581adec598400d9d02114736724b28d3" category="paragraph">コンテナ、サービスメッシュ、その他の変革テクノロジを採用することで、ローカルおよびクラウドベースの環境で一貫したアプリケーション開発サイクルと本番環境対応のワークロードを体験できるようになります。</block>
  <block id="b7fd1509ff5472f08e8216f563c9c8af" category="list-text">* Google Cloud Marketplace for Kubernetes Applications 。 * キュレーションされたコンテナアプリケーションのカタログを利用して、簡単に導入できます。</block>
  <block id="5204c290ae3b1ebca311a7ca7d447791" category="list-text">* Anthos * に移行。オンプレミスからクラウドへの物理サービスと VM の自動移行を実現します。図 3 は、 Anthos 解決策と、オンプレミスのデータセンターに導入し、クラウドのインフラと相互接続する方法を示しています。</block>
  <block id="608fd0ec5cdb56ad3d3e6d9595ec6f19" category="inline-link">Anthos の Web サイト</block>
  <block id="1192e096cd21e1aa81d806fe9e5d2213" category="paragraph">Anthos の詳細については、を参照してください<block ref="717e02fd176ae4981315950f42bdf0a6" category="inline-link-rx"></block>。</block>
  <block id="70f64e61deea67473fb9951b8f5888b3" category="paragraph">次の図は、 Google Cloud の Anthos アーキテクチャを示しています。</block>
  <block id="99d1b69697dd97e963c0a8145277719d" category="paragraph"><block ref="99d1b69697dd97e963c0a8145277719d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa69ca65720dd2e4eef99ebfb7816268" category="section-title">ベアメタルの Anthos</block>
  <block id="761fffea4910d62111da90337e75abb5" category="paragraph">ベアメタル上の Anthos は、お客様のプライベートデータセンターに導入されている GKE の拡張機能です。オンプレミスの Anthos クラスタ内のコンテナで実行するように設計されたものと同じアプリケーションを導入できます。ベアメタル上の Anthos は、ユーザが選択した Linux オペレーティングシステムを使用して物理サーバ上で直接動作し、本格的なハイブリッドクラウド環境を提供します。この環境は、データセンターのコアまたはエッジで動作します。</block>
  <block id="9eb2eb227133ada575ae959b570e545c" category="paragraph">ベアメタル上の Anthos には次のようなメリットがあります。</block>
  <block id="d966dba0352f5bc4bd7cec115bb0f6f4" category="list-text">* ハードウェアに依存しません。 * お客様は、最適化されたハードウェアプラットフォームを選択して、既存のデータセンターで Anthos を実行できます。</block>
  <block id="69dd75c781331ee9a4c6b2b30d065262" category="list-text">* コスト削減。 * Google Cloud 環境でリソースをプロビジョニングする代わりに、アプリケーションの導入に独自の物理リソースを使用することで、大幅なコスト削減を実現できます。</block>
  <block id="22c97b10f741190427f7bf14aaa217c3" category="list-text">* 開発して公開 * アプリケーションの開発中にオンプレミス環境を使用できます。これにより、アプリケーションをクラウドで公開する前に、ローカルデータセンターのプライバシーでアプリケーションをテストできます。</block>
  <block id="0f9f68e8f2e2599804f40d8fc0861b6d" category="list-text">* パフォーマンスの向上。 * 低レイテンシと最高レベルのパフォーマンスを必要とする負荷の高いアプリケーションは、ハードウェアの近くで実行できます。</block>
  <block id="895cc29ffb809aaf615d5db487a23c7c" category="list-text">* 管理と運用。 * ベアメタルの Anthos には、ネットワーク機能、ライフサイクル管理機能、診断機能、ヘルスチェック、ロギング、 監視機能を提供します。</block>
  <block id="04b942b754be5e16fc9d5b114dd70bb7" category="inline-link-macro">次：解決策の要件</block>
  <block id="dea54f5c884510a9da9977e2655c0a5a" category="paragraph"><block ref="dea54f5c884510a9da9977e2655c0a5a" category="inline-link-macro-rx"></block></block>
  <block id="b6bd3694e26914bcad3a91cd2d709e12" category="summary">ネットアップと Google Cloud は数年前から強力な関係を築いてきました。ネットアップは最初に、 Cloud Volumes ONTAP と Cloud Volumes Service を使用してクラウドデータサービスを Google Cloud に導入しました。この関係をさらに強化するために、解決策プラットフォームをオンプレミスの Google Cloud Anthos で使用できるようになりました。オンプレミス環境は、ハイパーバイザーベースのハイブリッドマルチクラウド Kubernetes NetApp HCI を VMware vSphere 上に導入した環境です。次にネットアップは、 NetApp Trident 、 ONTAP 、 NFS プロトコル向け Anthos Ready 認定を受けて、コンテナ向けの動的な永続的ストレージを提供しています。</block>
  <block id="6de80120fa9469d052fc37775d89d5ca" category="doc">WP-7337 ：『 Anthos on Bare Metal 』</block>
  <block id="3e2875179d9d16600aa48cbb428cefbb" category="paragraph">ネットアップと Google Cloud は数年前から強力な関係を築いてきました。ネットアップは最初に、 Cloud Volumes ONTAP と Cloud Volumes Service を使用して Google Cloud 向けのクラウドデータサービスを導入しました。この関係をさらに強化するために、解決策プラットフォームをオンプレミスの Google Cloud Anthos で使用できるようになりました。オンプレミス環境は、ハイパーバイザーベースのハイブリッドマルチクラウド Kubernetes NetApp HCI を VMware vSphere 上に導入した環境です。次にネットアップは、 NetApp Trident 、 ONTAP 、 NFS プロトコル向け Anthos Ready 認定を受けて、コンテナ向けの動的な永続的ストレージを提供しています。</block>
  <block id="edb5855aa73d26775d73760286fad940" category="paragraph">Anthos は、お客様の環境のベアメタルサーバに直接インストールできるようになりました。これにより、お客様はハイパーバイザを使用せずに Google Cloud をローカルデータセンターに拡張することができます。さらに、 NetApp ONTAP ストレージオペレーティングシステムと NetApp Trident の機能を活用すれば、コンテナ向けの永続的ストレージを統合することで、プラットフォームの機能を拡張できます。</block>
  <block id="8310f10ba877c17b561c1119aa03a750" category="paragraph">この組み合わせにより、 Google Cloud が提供するサポート、サービスレベル、月額課金、オンデマンドの柔軟性と組み合わせることで、サーバ、ストレージ、ネットワークの潜在的な可能性を最大限に引き出すことができます。独自のハードウェア、ネットワーク、ストレージを使用しているため、アプリケーションの規模、セキュリティ、ネットワークのレイテンシを直接制御でき、管理対象アプリケーションとコンテナ化されたアプリケーションをベアメタルの Anthos で利用できます。</block>
  <block id="5cb451e1c66a533348d9c913d8c630e3" category="inline-link-macro">次の手順：解決策の概要</block>
  <block id="7133ec6c94c3cb3dd5d77dce10f8fd70" category="paragraph"><block ref="7133ec6c94c3cb3dd5d77dce10f8fd70" category="inline-link-macro-rx"></block></block>
  <block id="91286d4add9b720fd5ff3bb121e12b2f" category="paragraph">このドキュメントでは、 NetApp ONTAP ストレージプラットフォームと、ベアメタルプラットフォーム上の Google Cloud の Anthos の構成と検証について説明します。 NetApp Trident は、 Kubernetes 向けオープンソースストレージオーケストレーションツールで、ステートフルアプリケーションコンテナ向けの永続的ストレージの導入と管理を行います。</block>
  <block id="4d7f7f28f54da25e8386b6cfbcbda861" category="summary">この解決策の現在の展開は、 Google Cloud チームが提供するツールを使用して、 2 つの厳格な検証プロセスを実施しました。</block>
  <block id="9fc7e91d0cfa196bee652e5b3ab8991b" category="doc">解決策の検証</block>
  <block id="1bee22d71e0dda5649b05ac8074a7994" category="paragraph">この解決策の現在の展開は、 Google Cloud チームが提供するツールを使用して、 2 つの厳格な検証プロセスを実施しました。これらの検証には、次のテストのサブセットが含まれます。</block>
  <block id="9ce4b6121b9169f9a57e370bc063e43a" category="list-text">Anthos 対応プラットフォームのパートナー検証：</block>
  <block id="b490ae83108f0a60d2d464f37aed5b33" category="list-text">ベアメタルプラットフォームサービス上のすべての Anthos がインストールされ、実行中であることを確認します。</block>
  <block id="132b0b7921ef1247c2db8a06ebb68fa0" category="list-text">ベアメタルクラスタ上の物理 Anthos を 4 つのワーカーノードから 3 つにスケールダウンし、さらに 4 つに戻します。</block>
  <block id="5d80842c7c4c549fffd35b71989523c6" category="list-text">カスタムネームスペースを作成および削除します。</block>
  <block id="bd4534ff45d2d6e71d15c4133153f039" category="list-text">Nginx Web サーバーの配置を作成し、レプリカの数を増やして展開を拡大します。</block>
  <block id="afdfab7c351a97a8f8e386c8c07eead0" category="list-text">Nginx アプリケーションの入力を作成し、 index.html をクリックして接続を確認します。</block>
  <block id="e093cbb18731dc9a857dff2a5a9c5b0d" category="list-text">すべてのテストスイートアクティビティを正常にクリーンアップし、クラスタをテスト前の状態に戻す。</block>
  <block id="6c91e0c5fc919c3ee9adc7909c3331b7" category="list-text">Anthos 対応ストレージのパートナー検証：</block>
  <block id="5aacb1c1d8ec3130c7bfc91d7678968c" category="list-text">永続的ボリューム要求を使用して導入を作成します。</block>
  <block id="1f8b95da3c7377c3616667d09bfbcf96" category="list-text">NetApp Trident を使用して、要求された永続的ボリュームをプロビジョニングし、 NetApp ONTAP から接続します。</block>
  <block id="5fac429b30f448d8149f93a83869e87f" category="list-text">永続ボリュームの接続解除と再接続を検証してください。</block>
  <block id="5a1ed343aaa28f6d14745016b7c06cf7" category="list-text">ノード上の他のポッドからの永続ボリュームへの読み取り専用アクセスをマルチ接続で検証する。</block>
  <block id="7c14d31217a85dc93c1505315501ef24" category="list-text">オフラインボリュームのサイズ変更処理を検証します。</block>
  <block id="b6ab6f9d0bc58a79facf618d65db092c" category="list-text">クラスタの拡張処理が永続的ボリュームに実行されていることを確認します。</block>
  <block id="4b774a4819b60036fd16dae7b1618fe7" category="inline-link-macro">次は終わりです</block>
  <block id="fa789d11a4863ab2ab7271940566105a" category="paragraph"><block ref="fa789d11a4863ab2ab7271940566105a" category="inline-link-macro-rx"></block></block>
  <block id="c12328be87e4d79e79b3db80bd6ff03f" category="list-text">NetApp ONTAP ドキュメントセンター</block>
  <block id="0b98c026ddf9e406d439373d2dab724b" category="inline-link"><block ref="0b98c026ddf9e406d439373d2dab724b" category="inline-link-rx"></block></block>
  <block id="63d46b0efa85a58196faf13e5aa20d7d" category="paragraph"><block ref="63d46b0efa85a58196faf13e5aa20d7d" category="inline-link-rx"></block></block>
  <block id="712cab3570d004ba67a47d7ff8df208b" category="inline-link"><block ref="712cab3570d004ba67a47d7ff8df208b" category="inline-link-rx"></block></block>
  <block id="a5526c10a9a8b42f6aab833b33a57eaf" category="paragraph"><block ref="a5526c10a9a8b42f6aab833b33a57eaf" category="inline-link-rx"></block></block>
  <block id="a3df86c144842761b9bcb0b540edbefe" category="inline-link"><block ref="a3df86c144842761b9bcb0b540edbefe" category="inline-link-rx"></block></block>
  <block id="8d3014f959efddffaea116898b063218" category="paragraph"><block ref="8d3014f959efddffaea116898b063218" category="inline-link-rx"></block></block>
  <block id="50465c19760e2a5476479f1f4a464119" category="summary">ネットアップのベアメタル環境に導入された Anthos は、インフラをカスタマイズできるため、コンテナベースのワークロードを効率的に実行できる堅牢なプラットフォームを提供します。</block>
  <block id="f887fad1ad196c388701d07189696570" category="paragraph">ネットアップのベアメタル環境に導入された Anthos は、インフラをカスタマイズできるため、コンテナベースのワークロードを効率的に実行できる堅牢なプラットフォームを提供します。お客様は、サーバインフラとサポート対象のオペレーティングシステムを自由に使用したり、既存のインフラに解決策を導入したりできます。NetApp ONTAP と NetApp Trident の統合により、これらの環境の機能と柔軟性が大幅に向上し、コンテナ向けの永続的ストレージを効率的にプロビジョニングおよび管理することで、ステートフルなアプリケーションワークロードをサポートします。Google Cloud のポテンシャルをネットアップのデータセンターに拡大することで、完全にサポートされ、可用性と拡張性に優れ、フルマネージドの Kubernetes 解決策を活用してアプリケーションワークロードの開発と運用を行うことができます。</block>
  <block id="40a15e6807b47955e7b7a9b1bd330b01" category="inline-link-macro">次へ：追加情報の検索場所。</block>
  <block id="3ae752a47170fdc4f7ff5ed3204c1fb5" category="paragraph"><block ref="3ae752a47170fdc4f7ff5ed3204c1fb5" category="inline-link-macro-rx"></block></block>
  <block id="9f9077091d74fb2c701c8c8c4a837c16" category="summary">この解決策の初期検証では、 WWT のアドバンスト・テクノロジー・センター（ ATC ）で環境を構築するために、ネットアップはワールド・ワイド・テクノロジー（ WWT ）と提携しました。Anthos は、 Google Cloud が提供する bmctl ツールを使用してベアメタルインフラに導入されています。次のセクションでは、検証に使用する導入環境について詳しく説明します。</block>
  <block id="06dc93ff20817f0d5fb8a07f8e43d6cb" category="doc">導入の概要</block>
  <block id="195d9c1693fc10788ad8da5d4d9d2402" category="paragraph">NetApp 解決策を搭載したベアメタル環境の Anthos は、 3 台の Anthos コントロールプレーンノードと 4 台の Anthos ワーカーノードを備えた、可用性に優れたハイブリッドクラスタとして構築されました。</block>
  <block id="d0236eb3bd180706e0eaca7d726c66e6" category="paragraph">使用されているコントロールプレーンノードは、シャーシ内にホストされている Cisco UCS B200M3 ブレードサーバであり、それぞれに 1 つの仮想ネットワークインターフェイスカード（ vNIC ）を使用して設定されていました。これにより、耐障害性を実現するために、 Cisco UCS プラットフォームレベルで A/B フェールオーバーが可能になります。Cisco UCS シャーシは、アップストリームで Cisco UCS 6248 ファブリックインターコネクトのペアに接続され、ファブリック A とファブリック B に沿ってトラフィックを分離するための異なるパスを提供しますこれらのファブリックインターコネクトは、アップストリームで Cisco Nexus 5548 データセンタースイッチのペアに接続され、 WWT のコアネットワークに接続されます。</block>
  <block id="3753f99ef321c354828532bad11422ec" category="paragraph">ワーカーノードは、 HP ProLiant DL360 ノードで、それぞれベアメタルの Anthos でサポートされている Linux ディストリビューションの 1 つである Red Hat Enterprise Linux 8.2 、 CentOS 8.2 、 Ubuntu 20.04 LTS 、または Ubuntu 18.04 LTS を実行していました。Red Hat Enterprise Linux 8 および CentOS 8 のノードは、 LACP モードで NIC チームを実行し、フォールトトレランスを実現するために Nexus 9K C93180YC-FX スイッチ 2 つにケーブル接続しました。Ubuntu サーバを LACP モードでネットワークボンディング用に設定し、フォールトトレランスを実現するために、同じ Nexus 9K スイッチペアに接続しました。</block>
  <block id="a847089866aa2e6d9077cdc08cce930b" category="paragraph">ONTAP 9.7 ソフトウェアを実行する NetApp AFF A300 ストレージシステムを設置し、 Anthos ワーカーノードと同じ Nexus 9K スイッチペアに物理的に接続しました。これらのネットワークアップリンクをインターフェイスグループ（ a0a ）に集約し、ワーカーノードがストレージシステムと対話できるよう適切なデータネットワーク VLAN をタグ付けしました。Storage Virtual Machine （ SVM ）は、 NFS プロトコルをサポートするデータ LIF と Trident のストレージ処理専用の SVM を使用して作成されたもので、ベアメタルクラスタの Anthos に導入されたコンテナに永続的ストレージを提供します。永続ボリュームは、完全にサポートされている Kubernetes 向け NetApp オープンソースストレージオーケストレーションツールの最新リリースである NetApp Trident 20.10 によって提供されました。</block>
  <block id="e5b1fecda3d68cda9e216e0e73b26dec" category="paragraph">次の図は、解決策と上部のラックデータセンタースイッチを物理的にケーブル接続した図です。</block>
  <block id="aa5914d8b6d8a27fd4df86fef0c0395a" category="paragraph"><block ref="aa5914d8b6d8a27fd4df86fef0c0395a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7a105940efa6ed6c71004ff40b8347" category="paragraph">次の図は、ネットアップパートナーの WWT のラボでハードウェアの導入と検証に使用されている解決策の論理ビューを示しています。</block>
  <block id="ff8f4395cfa334d6d144e3a2426e7b96" category="paragraph"><block ref="ff8f4395cfa334d6d144e3a2426e7b96" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8d3f61f51562ad245b65242dc92c0da" category="inline-link-macro">次の例は、解決策の検証です。</block>
  <block id="b1d15269d6e9cabdf17337c73e6a5f07" category="paragraph"><block ref="b1d15269d6e9cabdf17337c73e6a5f07" category="inline-link-macro-rx"></block></block>
  <block id="b2f35a84b813ef160b585d350d2fcd58" category="summary">ハードウェアに依存しないベアメタル上の Anthos 機能により、ユースケースに最適化されたコンピューティングプラットフォームを選択できます。したがって、既存のインフラに合わせて、設備投資を削減できます。</block>
  <block id="5f95fbda20eeb9ce0859afe2ac6f42fa" category="doc">解決策の要件</block>
  <block id="7d4009b9254a61f6afd71a2656a3a78f" category="section-title">コンピューティング：お客様所有のサーバを使用</block>
  <block id="dee41946d9d6ca32131352cb4374f12b" category="paragraph">次の表に、この解決策の実装に必要なコンピューティングハードウェアコンポーネントの最小数を示します。ただし、使用されるハードウェアモデルはお客様の要件に応じて異なる場合があります。</block>
  <block id="c64518704ce0c0d5501a45763f464276" category="cell">使用方法</block>
  <block id="602f72fff77475a16eff159759656261" category="cell">ハードウェアおよびモデル</block>
  <block id="06e9950a2c1bb489cf54d03d4547e913" category="cell">管理ノード</block>
  <block id="b349dcffed4594674c8ce6c91e72e42f" category="cell">Cisco UCS B200</block>
  <block id="fcb81a84511da525a1581c4ccc00d0fb" category="cell">ワーカーノード</block>
  <block id="4867cc2ab4385d91c3a36d6ace67a984" category="cell">HP ProLiant DL360</block>
  <block id="2c0b20f0fbc047d58ca10a50c6a32bc7" category="section-title">ストレージ： NetApp ONTAP</block>
  <block id="604e83a5a6c4302c60ee5e331dcd342c" category="paragraph">次の表に、解決策の実装に必要なストレージハードウェアコンポーネントの最小数を示します。ただし、使用するハードウェアモデルはお客様の要件に応じて異なる場合があります。</block>
  <block id="eb8440af98c502b8095408e970297e6b" category="cell">NetApp AFF A300</block>
  <block id="e8d610d6c2d243856beaade33b5aa123" category="cell">2 （ HA ペア × 1 ）</block>
  <block id="b6ce11f078022a4ab598b8016db52a13" category="paragraph">次の表に示したソフトウェアバージョンは、ネットアップとパートナー様による解決策の検証に使用されています。ただし、使用されるソフトウェアコンポーネントはお客様の要件に応じて異なる場合があります。</block>
  <block id="128b9c7509f09d8ff4b08e87def0ac74" category="cell">3 人の管理者の OS</block>
  <block id="836a05a21ac6df3b6bcf9838895b017e" category="cell">Worker4 上の OS</block>
  <block id="bbd243e896202aa0eb00ce19d8a7fea8" category="cell">Worker3 上の OS</block>
  <block id="4077fabc9a8b0e761cfd9bf752e03c8a" category="cell">18.04</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS の場合</block>
  <block id="aaad0494526f271ca02ebd06a79e7382" category="cell">Worker2 上の OS</block>
  <block id="2a568439f8e6ff92daa9925ce8a03adf" category="cell">8.2</block>
  <block id="7ac53708026d8515ce15cc154e95f46b" category="cell">Worker1 上の OS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="7cf4fea896dee61293d729d9985621d7" category="cell">コンテナオーケストレーション</block>
  <block id="ca9f0d77f73d954e88e6ab43539ac7cb" category="cell">1.6.0</block>
  <block id="ea704238343d48baa3a08f039015185f" category="cell">Storage OS</block>
  <block id="f33749dd101d316dcf2e6953732629f9" category="cell">9.7P8.</block>
  <block id="8fe1ffd8f7dcf339dd4f34aabb6e1c99" category="cell">Container Storage Management （コンテナストレージ管理）</block>
  <block id="a84024ce06ef98519b3b51300b2c8fbf" category="cell">20.10</block>
  <block id="37979dccdf7857a1abffb7df7c837853" category="admonition">このマルチ OS 環境は、ベアメタル解決策上のサポートされている OS バージョンの Anthos との相互運用性を示しています。導入のために、お客様が 1 つまたは一部のオペレーティングシステムで標準化されると予想されます。</block>
  <block id="d94e09dc1956d9513e690f8d24852f05" category="inline-link">ベアメタルドキュメント上の Anthos</block>
  <block id="dea0bcd20b41ad5a5b5830e0facf5d5d" category="paragraph">ベアメタルハードウェアおよびソフトウェアの要件を満たす Anthos の場合は、を参照してください<block ref="39597b4f74e08019db4cace51500cfd6" category="inline-link-rx"></block> ページ</block>
  <block id="71196ec10a92c76a666a93f55523b96e" category="inline-link-macro">次の例は、導入の概要です。</block>
  <block id="1b8d67e147d4d9c532832778cca5fee8" category="paragraph"><block ref="1b8d67e147d4d9c532832778cca5fee8" category="inline-link-macro-rx"></block></block>
  <block id="7324b08f5dfbdb08191404d3fdacfcbd" category="cell">AI ベースのソリューションのコレクション。ソリューションは次のいずれかのカテゴリに分類されます。 [navy]#AI 統合インフラ #[navy]#Data Pipelines 、 Data Lakes and Management #[navy]#use Cases #</block>
  <block id="b3f656e5589b8507fed35a5cde55c7ce" category="cell">エンドユーザコンピューティングソリューションの集合。ソリューションは次のいずれかのカテゴリに分類されます。 [navy] # Virtual Desktop Service （ VDS ） # [navy] # VMware Horizon # [navy] # Citrix Virtual Apps and Desktops # [navy] # Virtual Desktop Applications#</block>
  <block id="f4d9ebd0d9f8b0ed1329093e48c11221" category="cell">コンテナベースのソリューションの集合。ソリューションは、 [navy] #Red Hat OpenShift #[navy] #Google Anthos# のカテゴリの 1 つに分類されています</block>
  <block id="c343bf84179077b4550742e0222d3349" category="cell">ビジネスアプリケーションソリューションのコレクション。ソリューションは、 [navy] #sap# というカテゴリのいずれかに分類されます</block>
  <block id="8a0b9e6043677d9587a3e02ced9a6dfd" category="cell">データベースソリューションの集合。ソリューションは次のいずれかのカテゴリに分類されます。 [navy] # SAP HANA # [navy] # Oracle# [navy] # Microsoft SQL Server#</block>
  <block id="9411dea29d318927759a55cff454b3dd" category="inline-link-macro">次は、業界向けソリューションです。</block>
  <block id="ee3f381f10f3f075a22913a348a89edf" category="paragraph"><block ref="ee3f381f10f3f075a22913a348a89edf" category="inline-link-macro-rx"></block></block>
  <block id="ec7f98a3714557d87968dc6a898f7912" category="inline-link">ONTAP で VMware Tanzu を活用して Kubernetes への移行を加速</block>
  <block id="32e124b0349f41e06bf1e03f11950665" category="list-text"><block ref="32e124b0349f41e06bf1e03f11950665" category="inline-link-rx"></block></block>
  <block id="526cee55e2936716b5481f8a933bd217" category="inline-link">VVOL をネットアップおよび VMware の Tanzu Basic で使用する方法、パート 1</block>
  <block id="c2240101c5a3a188541ce87c59265df9" category="list-text"><block ref="c2240101c5a3a188541ce87c59265df9" category="inline-link-rx"></block></block>
  <block id="2e933c421900ce4ed68883bfdf00a487" category="inline-link">VVOL をネットアップおよび VMware の Tanzu Basic で使用する方法、パート 2</block>
  <block id="fe72963b1d3021a9f6d8ae34414601c3" category="list-text"><block ref="fe72963b1d3021a9f6d8ae34414601c3" category="inline-link-rx"></block></block>
  <block id="e2a1b52ebd707739003f77464bbcaa80" category="sidebar">FlexPod デスクトップ仮想化ソリューション</block>
  <block id="9efcc0ad3c93b238cc0495e3c87b715f" category="inline-link">Ansible による FlexPod での Oracle 19C RAC の自動導入</block>
  <block id="9c4ada146a28af07eecc939b540c3541" category="list-text"><block ref="9c4ada146a28af07eecc939b540c3541" category="inline-link-rx"></block></block>
  <block id="14c4dbb7c61081eee1c499c4cf138c96" category="sidebar">FlexPod データセンター上の Oracle 19C RAC データベースと Cisco UCS FC 経由の NetApp AFF A800 をサポートしています</block>
  <block id="4c1c4ad5c7782eafb30ad4704dbf4419" category="inline-link">VVOL をネットアップおよび VMware の Tanzu Basic で使用する方法、パート 3</block>
  <block id="4d066173d8401c92a19650e99dcaae5d" category="list-text"><block ref="4d066173d8401c92a19650e99dcaae5d" category="inline-link-rx"></block></block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">このセクションでは、 Trident で実行したいさまざまな処理の例を紹介します。</block>
  <block id="4330c34147b36030c50afe1d04ec2213" category="paragraph">以降のコマンド例では、「 pb_fg_all 」という名前の同じボリュームを、セクションの例で作成した各 Trident バックエンドに対して 1 回ずつ、 2 回インポートしています <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>、手順 1.同じボリュームをこの 2 つの方法でインポートすると、（既存の FlexGroup ボリューム）を複数の LIF にまたがって複数回マウントできます。詳細については、セクションを参照してください <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>、手順 1.PVC の詳細については、を参照してください<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。ボリュームインポート機能の詳細については、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">「 accessModes 」の値「 ReadOnlyMany 」は、 PVC 仕様ファイルの例で指定されています。「 accessMode 」フィールドの詳細については、を参照してください<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。</block>
  <block id="e6d82e60d43fe02e01930addfe670e8f" category="admonition">次の例で指定するバックエンド名 インポートコマンドは、で作成されたバックエンドに対応します の例を参照してください <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>、手順 1.次の例で指定した StorageClass 名 PVC 定義ファイルは、作成された StorageClasses に対応しています を参照してください <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>、手順 1.</block>
  <block id="e149d2e1fdb31ad28f79dd3d2c7ee8ff" category="paragraph">Trident を使用して、ネットアップストレージシステムまたはプラットフォームで新しいボリュームをプロビジョニングできます。次のコマンド例は、新しい FlexVol ボリュームのプロビジョニングを表示します。この例では、セクションの例で作成した StorageClass を使用してボリュームがプロビジョニングされます <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>、ステップ 2 。</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">次の PVC 定義ファイル例では 'accessModes' の値 ReadWriteMany が指定されています「 accessMode 」フィールドの詳細については、を参照してください<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。</block>
  <block id="467941822b3a557a8db7197e12285f14" category="paragraph">この解決策の作成の一環として、パフォーマンスを簡単に比較しました。Kubernetes を使用して、 NetApp AI の標準ベンチマークジョブをいくつか実行しました。また、ベンチマークの結果を、単純な Docker run コマンドを使用して実行した実行結果と比較しました。パフォーマンスに顕著な違いは見られませんでした。このため、 Kubernetes を使用してコンテナ化された AI トレーニングジョブをオーケストレーションしても、パフォーマンスに悪影響が及ばないことがわかりました。パフォーマンス比較の結果については、次の表を参照してください。</block>
  <block id="0e91d2e60705ecb1730e9b96510019af" category="list-text">の手順に従って、 NVIDIA DeepOps をダウンロードします<block ref="6fb71807bf6999d2aec034d498e3ebf6" category="inline-link-rx"></block> NVIDIA DeepOps GitHub サイトで入手できます。</block>
  <block id="5c18e4efa8c5cc9efb26e3f748b4e26d" category="list-text">の手順に従って、クラスタに Kubernetes を導入します 。<block ref="b336a8bbad16f0e8d58bf87e261f51fa" category="inline-link-rx"></block> NVIDIA DeepOps GitHub サイトで入手できます。</block>
  <block id="52d84951381eb0ab7a285dd32b31702c" category="paragraph">Kubeflow は、データサイエンティストのワークスペースとして機能する、新しい Jupyter Notebook サーバの迅速なプロビジョニングを可能にします。Kubeflow を使用して新しい Jupyter Notebook サーバをプロビジョニングするには、次のタスクを実行します。Kubeflow コンテキスト内の Jupyter Notebook の詳細については、を参照してください<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block>。</block>
  <block id="095efbb867f01094d56c633d3337a412" category="list-text">ワークスペースボリュームの詳細を指定します。新しいボリュームを作成するように選択した場合は、そのボリュームまたは PVC がデフォルトの StorageClass を使用してプロビジョニングされます。Trident を利用するストレージクラスがデフォルトとして指定されているため StorageClass <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>を指定した場合、ボリュームまたは PVC は Trident でプロビジョニングされます。このボリュームは、 Jupyter Notebook Server コンテナ内のデフォルトワークスペースとして自動的にマウントされます。別のデータボリュームに保存されていないユーザーがサーバー上に作成したノートブックは、自動的にこのワークスペースボリュームに保存されます。そのため、ノートブックは再起動後も維持されます。</block>
  <block id="555e44b3745904843417371073338d08" category="list-text">データボリュームを追加次に、「 pb-fg-all 」という名前の既存の PVC を指定し、デフォルトのマウントポイントを受け入れる例を示します。</block>
  <block id="37a742c47c216725dd178d8c3c7a3f31" category="list-text">ノートブックサーバーが完全にプロビジョニングされるまで待ちます。指定した Docker イメージを使用してサーバをプロビジョニングしたことがない場合は、イメージのダウンロードが必要になるため、これには数分かかることがあります。サーバーが完全にプロビジョニングされると、 Jupyter Notebook サーバー管理ページの [ ステータス ] 列に緑色のチェックマークが表示されます。</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">「 ONTAP-NAS-flexgroup 」の Trident バックエンドタイプには、かなり大きな最小 PVC サイズがあります。デフォルトでは、 Kubeflow はサイズが数 GB しかない PVC のプロビジョニングを試みます。したがって、 Kubeflow の導入の目的で、「 ONTAP-NAS-flexgroup 」バックエンドタイプをデフォルトの StorageClass として使用する StorageClass を指定しないでください。</block>
  <block id="04e3c704baa1b4c23cd48a18c10fcf39" category="list-text">クラスタに Kubeflow を導入するには、に従ってください<block ref="5e7f04c1dfa70dd058d2720be031c44b" category="inline-link-rx"></block> NVIDIA DeepOps GitHub サイトで入手できます。</block>
  <block id="b714a06d49f16f8b7f988d95734d177f" category="list-text">Kubeflow ネームスペース内に展開されているすべてのポッドに「ステータス」が「実行中」であることを確認し、ネームスペース内に展開されているコンポーネントがエラー状態でないことを確認します。すべてのポッドが起動するまでに数分かかることがあります。</block>
  <block id="64f559cf2e77f73aca6bd3dc9649f62c" category="paragraph">デフォルトのユーザ名は「 admin@kubeflow.org 」で、デフォルトのパスワードは「 12341234 」です。追加ユーザを作成するには、の手順に従います<block ref="f529217f090b2c9cc3764f14abdec5f7" category="inline-link-rx"></block>。</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">NetApp Data Science Toolkit for Kubernetes</block>
  <block id="c5da96d7204df28dd9fdc33139c8a776" category="paragraph">。<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> エアーフローと組み合わせて使用できます。NetApp Data Science Toolkit とエアフローを組み合わせることで、エアフローによって自動化されたワークフローにネットアップのデータ管理操作を組み込むことができます。</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">通気の例</block>
  <block id="9fc322b3a5bb56d2d6ac18c15773d1c2" category="paragraph">を参照してください<block ref="c50bba54faf39c027cd571674d44a9c0" category="inline-link-rx"></block> ツールキットの通気と使用方法の詳細については、 NetApp Data Science Toolkit GitHub リポジトリのセクションを参照してください。</block>
  <block id="1e698f68960fb964df99e73068c9377c" category="list-text">ネットアップでは、 NetApp AFF システムで使用する各データ LIF （データアクセスを提供する論理ネットワークインターフェイス）に対して、 FlexGroup 対応の Trident バックエンドを作成することを推奨します。これにより、 LIF 間でボリュームマウントを分散させることができます</block>
  <block id="a905494ad30a6d54678a2122c04bfd54" category="summary">Jupyter Notebook と Kubeflow パイプラインの例</block>
  <block id="80e94617849fe0b057f3edcc76a6ac72" category="doc">ノートブック PC とパイプラインの例</block>
  <block id="3da57858cd6a76521b38784effc6a06f" category="paragraph">。<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> Kubeflow と組み合わせて使用できます。NetApp Data Science Toolkit と Kubeflow を使用すると、次のようなメリットがあります。</block>
  <block id="624a53dc5871ce49612a285ee2bf367e" category="list-text">データサイエンティストは、 Jupyter Notebook 内から、ネットアップの高度なデータ管理操作を直接実行できます。</block>
  <block id="1c7d37cb415e8b7777b071784911a77a" category="list-text">Kubeflow Pipelines フレームワークを使用すると、ネットアップの高度なデータ管理処理を自動化されたワークフローに組み込むことができます。</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Kubeflow の例</block>
  <block id="987823970c7b662272fb9e0058bf5ff1" category="paragraph">を参照してください<block ref="3eb5d4ffd5360858e22dfb9799f211d7" category="inline-link-rx"></block> ツールキットと Kubeflow を使用する場合の詳細については、 NetApp Data Science Toolkit GitHub リポジトリのセクションを参照してください。</block>
  <block id="1703cadf8e847114fb353feaaf03beb9" category="summary">このセクションでは、 ONTAP AI ポッドに Kubernetes を導入する際に実行可能なさまざまなハイパフォーマンスジョブの例を示します。</block>
  <block id="993143e7434e63409a07cf3e8c422505" category="list-text">FlexGroup が有効な Trident ごとに別々のストレージクラスを作成することを推奨します セクションで作成したバックエンド <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>、手順 1.これらの Granular StorageClasses を使用すると、 StorageClass 仕様ファイルで指定されている特定のバックエンドとして、特定の LIF （ Trident バックエンドの作成時に指定した LIF ）に対応する NFS マウントを追加できます。以降のコマンド例では、 2 つのを作成しています StorageClasses を使用して、バックエンドの 2 つの例に対応しています セクションで作成されます <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>、手順 1.StorageClasses の詳細については、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="f053cb3a491d2bc48d41230b10a9b164" category="list-text">に対応するストレージクラスを作成することも推奨します セクションで作成した FlexVol 対応の Trident バックエンド <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>、ステップ 2 。以下のコマンド例は、 FlexVol ボリューム用の単一のストレージクラスの作成を示しています。</block>
  <block id="86608a0b346f307c76f8ae00c9f6bcb9" category="summary">このレポートでは、データネームスペースを迅速にクローニングする方法について説明します。トレーサビリティとバージョン管理のためにデータやモデルのベースラインをほぼ瞬時に作成する AI トレーニングワークフローを定義および実装する方法を説明します。また、複数のサイトや地域間でデータをシームレスに複製し、 Jupyter Notebook ワークスペースをすばやくプロビジョニングして、大規模なデータセットにアクセスする方法も示します。</block>
  <block id="27114500e25aba7a27847b772d396575" category="paragraph">あらゆる規模の企業や組織が、多くの業界で、人工知能（ AI ）、機械学習（ ML ）、ディープラーニング（ DL ）を導入して、現実世界の問題を解決し、革新的な製品やサービスを提供し、競争が激化する市場で優位に立つことになりつつあります。AI 、 ML 、 DL の利用が増えるにつれ、ワークロードの拡張性やデータの可用性など、多くの課題に直面しています。このドキュメントでは、ネットアップのデータ管理機能と一般的なオープンソースのツールやフレームワークとのペアリングを行う解決策である NetApp AI コントロールプレーンを使用して、これらの課題に対処する方法について説明します。</block>
  <block id="98300151efa6f504dee4866e49cf2078" category="paragraph">このレポートでは、データネームスペースを迅速にクローニングする方法について説明します。また、サイトやリージョン間でデータをシームレスにレプリケートし、統合された AI / ML / DL データパイプラインを構築する方法も示します。さらに、トレーサビリティとバージョン管理のためにデータやモデルベースラインをほぼ瞬時に作成する AI 、 ML 、 DL トレーニングワークフローの定義と実装についても説明します。この解決策を使用すると、すべてのモデルトレーニングを、モデルのトレーニングや検証に使用したデータセットまでトレースできます。最後に、このドキュメントでは、 Jupyter Notebook ワークスペースを、大規模なデータセットにすばやくプロビジョニングする方法を説明します。</block>
  <block id="9d50c340b35848862ab6ecbdadc401ed" category="paragraph">ネットアップの AI コントロールプレーンは、データサイエンティストやデータエンジニアをターゲットとするため、ネットアップや ONTAP ® に関する専門知識は最小限に抑えられます。この解決策を使用すると、シンプルで使い慣れたツールやインターフェイスを使用してデータ管理機能を実行できます。ネットアップストレージがすでにある環境では、ネットアップの AI コントロールプレーンを今すぐテストできます。解決策のテストドライブを希望していても、ネットアップストレージがない場合は、にアクセスしてください<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>クラウドベースのネットアップストレージ解決策を使用すれば、数分で稼働を開始できます。次の図に、解決策を視覚的に示します。</block>
  <block id="14ede02439184c7c75e53410ffa40370" category="list-text">すでに稼働しているネットアップストレージアプライアンス、ソフトウェア定義インスタンス、クラウドストレージサービスで、 Trident でサポートされているものを使用している。</block>
  <block id="07d8795f785e6495307106596d07402e" category="list-text">Trident は、次のいずれかの方法で導入できます。</block>
  <block id="040d3466a6f1c45ca2e523c9354dfdc7" category="inline-link">Trident の導入手順</block>
  <block id="bb6989644edf59b8c5e0de0c25b6f8b6" category="list-text">NVIDIA DeepOps を使用して Kubernetes クラスタを導入した場合は、 NVIDIA DeepOps を使用して Kubernetes クラスタに Trident を導入することもできます。Trident で DeepOps を導入する方法については、を参照してください<block ref="77e542aaaac8c5d2482c94ca2d79c997" category="inline-link-rx"></block> NVIDIA DeepOps GitHub サイトで入手できます。</block>
  <block id="b6463ef77c88b4c74dd6c4b1479d1bae" category="list-text">NVIDIA DeepOps を使用して Kubernetes クラスタを導入していない場合や Trident を手動で導入する場合は、次の手順で Trident を導入できます<block ref="73e6be38c8ff1e0c58865c34876a2e98" category="inline-link-rx"></block> Trident のドキュメントTrident バックエンドと Kubernetes StorageClass を少なくとも 1 つずつ作成してください。Backends と StorageClasses の詳細については、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。</block>
  <block id="7cfdcb466d040b6c8f9c85e9981b9652" category="inline-link-macro">ONTAP AI 導入向けの Kubernetes StorageClasses の例</block>
  <block id="180b707bbdd9c2fc8001a966c6c7d029" category="admonition">解決策 AI ポッドにネットアップ AI コントロールプレーン ONTAP を導入する場合は、を参照してください <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block> さまざまな Trident バックエンドの例を紹介します とを作成します <block ref="d495c2f5a68f6923824470c0096419c8" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="10dedd24e41d2fa9b5a5e681dd5b4882" category="summary">このページには、コンテナ、 Kubernetes 、 NetApp Trident などの情報を含め、ネットアップが AI プロジェクトをどのように進められるかを理解するための背景情報が含まれています。</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">さまざまなビジネスプロセスと機能を自動化します。</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">最新の AI トレーニングと推論のワークロードには、超並列処理機能が必要です。そのため、 GPU の並列処理機能は汎用 CPU よりもはるかに優れているため、 GPU を使用した AI 処理も増えています。</block>
  <block id="c01fb6f699235f8c5d36bdda9e155c77" category="paragraph">Apache Airflow は、複雑なエンタープライズワークフローのプログラムによるオーサリング、スケジューリング、監視を可能にするオープンソースのワークフロー管理プラットフォームです。ETL やデータパイプラインのワークフローを自動化する目的でよく使用されますが、こうした種類のワークフローに限定されるわけではありません。Airflow プロジェクトは Airbnb が開始しましたが、業界で非常に人気があり、現在は Apache Software Foundation の後援を受けています。空気の流れは Python で書かれており、 Python スクリプトを使用して空気の流れが作られています。また、空気の流れは、「コードとしての設定」という原則に基づいて設計されています。 現在、多くの企業のエアフローユーザが Kubernetes の上で通気を実行しています。</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">ダイレクト非周期グラフ（ DAG ）</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">エアーフローでは、ワークフローは Directed Acyclic Graphs （ DAG ）と呼ばれます。DAG は、 DAG の定義に応じて、順番に実行されるタスク、並列タスク、またはその組み合わせで実行されるタスクで構成されます。エアーフロースケジューラは、 DAG 定義で指定されているタスクレベルの依存関係を維持しながら、一連のワーカーに対して個々のタスクを実行します。DAG は Python スクリプトを使用して定義および作成されます。</block>
  <block id="dc188738e6cc2e9f8314e1b95f18ebfd" category="section-title">NetApp Cloud Sync の略</block>
  <block id="2e386ef1ace3f8ea71edbaa6f9cbbd00" category="paragraph">Cloud Sync は、高速でセキュアなデータ同期を実現するネットアップのサービスです。オンプレミスの NFS または SMB ファイル共有、 NetApp StorageGRID 、 NetApp ONTAP S3 、 NetApp Cloud Volumes Service 、 Azure NetApp Files 、 AWS S3 、 AWS EFS 、 Azure Blob 、 Google Cloud Storage または IBM Cloud Object Storage を使用すると、 Cloud Sync は必要な場所に迅速かつ安全にファイルを移動できます。</block>
  <block id="c1bea6c8c836c6911127e6fe3fde762a" category="paragraph">転送されたデータは、ソースとターゲットの両方で完全に使用できます。Cloud Sync では、事前に定義されたスケジュールに基づいて、更新がトリガーされたときやデータの継続的な同期を行うときに、データをオンデマンドで同期できます。いずれにせよ、 Cloud Sync は差分のみを移動するため、データレプリケーションにかかる時間とコストを最小限に抑えることができます。</block>
  <block id="18c24ab391d7e12f4abcfea370fb4e81" category="paragraph">Cloud Sync は、セットアップや使用がきわめて簡単なソフトウェアサービス（ SaaS ）ツールです。Cloud Sync によって実行されるデータ転送は、データブローカーによって実行されます。Cloud Sync データブローカーは、 AWS 、 Azure 、 Google Cloud Platform 、オンプレミスに導入できます。</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="0e4fcaf78d0d4feda27a31ecb6944b58" category="paragraph">NetApp XCP は、ネットアップとネットアップ間のデータ移行およびファイルシステムに関する分析情報を提供するクライアントベースのソフトウェアです。XCP は、大量のデータセットとハイパフォーマンスな移行を処理するために、利用可能なすべてのシステムリソースを活用することで、最大限のパフォーマンスを実現するように設計されています。ファイルシステムを完全に可視化するために XCP を使用すると、レポート生成オプションが利用できます。</block>
  <block id="9a3914e340e4b09762f8231f9fd0ddaa" category="paragraph">NetApp XCP は、 NFS プロトコルと SMB プロトコルをサポートする単一パッケージで提供されます。NFS データセット用の Linux バイナリと SMB データセット用の Windows 実行可能ファイルが XCP に含まれています。</block>
  <block id="adc911d4d2f4e0008e765523cff39824" category="paragraph">NetApp XCP File Analytics は、ファイル共有を検出し、ファイルシステム上でスキャンを実行し、ファイル分析用のダッシュボードを提供するホストベースのソフトウェアです。XCP File Analytics は、ネットアップシステムと他社システムの両方に対応し、 Linux ホストまたは Windows ホストで動作して、 NFS および SMB エクスポートファイルシステムの分析を提供します。</block>
  <block id="ebbcd572ece7625ba24f2c3ecda6d5b5" category="paragraph">Kubernetes クラスタでシングルノードの AI ジョブと ML ジョブを実行するには、導入ジャンプホストから次のタスクを実行します。Trident を使用すると、数ペタバイトのデータが含まれる可能性のあるデータボリュームをすばやく簡単に作成し、 Kubernetes のワークロードからアクセスできます。Kubernetes ポッド内からこのようなデータボリュームにアクセスできるようにするには、ポッドの定義で PVC を指定します。このステップは Kubernetes ネイティブの運用であり、ネットアップの専門知識は不要です。</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">また、ストレージ帯域幅を最大限にするために、必要なトレーニングデータを含むボリュームが、このジョブで作成されるポッド内に 2 回マウントされます。ポッドには別のボリュームもマウントされています。この 2 つ目のボリュームには、結果と指標を格納します。これらのボリュームは、 PVC の名前を使用してジョブ定義内で参照されます。Kubernetes ジョブの詳細については、を参照してください<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block>。</block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="summary">このセクションでは、 Kubernetes クラスタ内に通気を導入するために完了しておく必要のあるタスクについて説明します。</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">Kubernetes 以外のプラットフォームに通気を導入することも可能です。Kubernetes 以外のプラットフォームに通気を導入することは、この解決策の範囲外です。</block>
  <block id="678c0949a1824bf54eba73ab0a2609d8" category="paragraph">通気を導入する前に、 Kubernetes クラスタ内にデフォルトのストレージクラスを指定する必要があります。エアフロー導入プロセスでは、デフォルトのストレージクラスを使用して新しい永続ボリュームのプロビジョニングが試行されます。StorageClass がデフォルトの StorageClass として指定されていない場合、導入は失敗します。クラスタ内でデフォルトの StorageClass を指定するには、の手順に従ってください <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>。クラスタ内ですでにデフォルトの StorageClass を指定している場合は、この手順を省略できます。</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Helm を使用してエアフローを導入します。に従ってください<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> アーティファクトハブの公式エアフロー図については、を参照してください。以下のコマンド例は、 Helm を使用したエアーフローの配置を示しています。必要に応じて 'custom-values/yaml ファイルの値を変更 ' 追加 ' または削除します</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">すべての通気ポッドが稼働中であることを確認します。すべてのポッドが起動するまでに数分かかる場合があります。</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">通気 Web サービスにアクセスできることを確認します。</block>
  <block id="6a8e19652a540e359304ba812d39ea8e" category="paragraph"><block ref="6a8e19652a540e359304ba812d39ea8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0de039e647bc53dcce6e7bceb8605cbf" category="paragraph">あらゆる規模の企業や組織が、あらゆる業界で、人工知能（ AI ）、機械学習（ ML ）、ディープラーニング（ DL ）を活用して、現実世界の問題を解決し、革新的な製品やサービスを提供し、競争が激化する市場で優位に立つことが求められています。AI 、 ML 、 DL の利用が増えるにつれ、ワークロードの拡張性やデータの可用性など、多くの課題に直面しています。これらの課題には、 NetApp AI コントロールプレーン解決策を使用して対処できます。</block>
  <block id="cae02473f4798da0fdd40f4f598b1d96" category="paragraph">この解決策を使用すると、データネームスペースのクローンを迅速に作成できます。さらに、トレーサビリティとバージョン管理のためにデータやモデルベースラインをほぼ瞬時に作成する AI 、 ML 、 DL のトレーニングワークフローを定義して実装できます。この解決策を使用すると、すべてのモデルトレーニングを、モデルがトレーニングされ、検証されたデータセットに戻すことができます。最後に、この解決策を使用すると、 Jupyter Notebook ワークスペースをすばやくプロビジョニングし、大規模なデータセットにアクセスできます。</block>
  <block id="696dba9a093d4ac7b67234745dd57835" category="paragraph">この解決策はデータサイエンティストとデータエンジニアを対象としているため、ネットアップまたは ONTAP に関する専門知識は最小限で済みます。この解決策を使用すると、シンプルで使い慣れたツールやインターフェイスを使用してデータ管理機能を実行できます。さらに、この解決策では、完全なオープンソースおよび無償のコンポーネントを使用しています。したがって、ネットアップストレージがすでにある環境では、この解決策を実装できます。この解決策でドライブをテストしたいが、ネットアップストレージはまだお持ちでない場合は、を参照してください<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>また、クラウドベースの NetApp Storage 解決策を使用すれば、いつでも稼働を開始できます。</block>
  <block id="3a607d0e3fa64fd7558e11352f751dd0" category="summary">NetApp AI コントロールプレーン解決策は、このような特定のハードウェアには依存しません。</block>
  <block id="976cf3edd8adeff2e75cd7a9dd0dae21" category="paragraph">NetApp AI コントロールプレーン解決策は、このような特定のハードウェアには依存しません。解決策は、 Trident でサポートされている、任意のネットアップ物理ストレージアプライアンス、ソフトウェア定義インスタンス、クラウドサービスと互換性があります。例としては、ネットアップ AFF ストレージシステム、 Azure NetApp Files 、ネットアップ Cloud Volumes Service 、ネットアップ ONTAP Select ソフトウェアで定義されるストレージインスタンス、ネットアップ Cloud Volumes ONTAP インスタンスなどがあります。また、使用する Kubernetes のバージョンが Kubeflow および NetApp Trident でサポートされていれば、どの Kubernetes クラスタにも解決策を実装できます。Kubeflow でサポートされる Kubernetes バージョンの一覧については、を参照してください<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>。Trident でサポートされている Kubernetes のバージョンのリストについては、を参照してください<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>。解決策の検証に使用した環境の詳細については、次の表を参照してください。</block>
  <block id="204dd0a482d284a7fb87c908f713f9bd" category="cell">Ubuntu 20.04.2 LTS の場合は</block>
  <block id="76a7e6383604f84ace970ce86ba76a9f" category="cell">Kubernetes GPU ワーカーノード</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="cell">NetApp AFF A220</block>
  <block id="d1d73cf191d1afbd40e85644467cae8b" category="cell">NetApp ONTAP 9.7 P6</block>
  <block id="47354877541923135499c38a6606138a" category="cell">2.0.1</block>
  <block id="ecfa741d55b7b1a85bd61a2307877c8c" category="cell">8.0.8</block>
  <block id="fd99a7ef225418315b041ad631a5674c" category="cell">19.03.12</block>
  <block id="56765472680401499c79732468ba4340" category="cell">1/2</block>
  <block id="48d02190984e4f8526f99f9cd9550e08" category="cell">1.18.9</block>
  <block id="d58d49f83f534f5d71b20750bb7927c7" category="cell">21.01.2.</block>
  <block id="7a04e1f765218bcbfc633ef331b312b8" category="inline-link">61898cdfda</block>
  <block id="7855beff2fafbce2cf0df4d67f8dfed7" category="cell">コミット時点でマスターブランチから Trident 導入機能を利用できるようになりました <block ref="686ead03155c78694e1a59db0970fc1a" category="inline-link-rx"></block>; バージョン 21.03 の他のすべての機能</block>
  <block id="fad62e8b886e655813cc4ce635152f62" category="sidebar">Trident の導入</block>
  <block id="fb6b632cdd61e02434568081cbbf0fae" category="paragraph">使用してください <block ref="a5f81f398e43efd62a061a201309bfa7" category="inline-link-rx"></block> コンテンツの変更をリクエストしたり、コンテンツに関するフィードバックを提供したりすることができます。フィードバックが適切に処理されるよう、できるだけ具体的にご記入ください。</block>
  <block id="9e2c62f406d88ad1ee253efd74f593df" category="sidebar">新しい解決策を提案する</block>
  <block id="7fd861566be88364067d817b54a44688" category="sidebar">解決策に関するご意見・ご要望</block>
  <block id="12797522e94d75727dd0a05a4ed9f5ff" category="sidebar">NVIDIA を使用した ONTAP AI</block>
  <block id="687350c847aefbf978e16be26609d101" category="sidebar">NVIDIA DGX A100 システム搭載の ONTAP AI 設計ガイド</block>
  <block id="4c7a8c5b878fcdf733694f638b393b6b" category="sidebar">NVIDIA DGX A100 システムによる ONTAP AI 導入ガイド</block>
  <block id="74c684b866e5fcffcc9c5165a491d5b2" category="sidebar">NVIDIA DGX A100 システムと Mellanox Spectrum を搭載した ONTAP AI イーサネットスイッチ設計ガイド</block>
  <block id="f8363659ae3ab117a0afa4163ca69fc7" category="sidebar">NVIDIA DGX A100 システムと Mellanox Spectrum を搭載した ONTAP AI イーサネットスイッチ導入ガイド</block>
  <block id="0c3efd7c1aae12456ab9935ae5fd15e0" category="sidebar">NVIDIA DGX A100 システムと BeeGFS を搭載した EF シリーズ AI</block>
  <block id="c70e778edabe427cd2db90132a56e456" category="sidebar">NVIDIA DGX A100 システムと BeeGFS 設計を搭載した EF シリーズ AI</block>
  <block id="06aa576b3e3e95c5df800228d146af65" category="sidebar">NVIDIA DGX A100 システムと BeeGFS を搭載した EF シリーズ AI の導入</block>
  <block id="38d9ffc674675d65fbb8aabd7e47acd3" category="sidebar">FlexPod ソリューション</block>
  <block id="d4c96dcd516adf0c5bde093b0b7b7255" category="summary">このページでは、 NetApp ONTAP ストレージ上に Oracle19c を導入するための自動化方式について説明します。</block>
  <block id="cb59b87e00d11222bfd9159d0d23836f" category="doc">はじめに</block>
  <block id="def8ebf26c2dec5f6af5a00893fae037" category="paragraph">この解決策は、 AWX/Tower 環境または Ansible コントロールホストの CLI で実行されるように設計されています。</block>
  <block id="008ba800d97cb969def651e93f0d93fb" category="section-title">AWX ／タワー</block>
  <block id="a481f1841043d60245f18522a86731b1" category="paragraph">AWX / タワー環境の場合は、 ONTAP クラスタ管理と Oracle サーバ（ IP およびホスト名）のインベントリの作成、クレデンシャルの作成、 NetApp Automation Github から Ansible コードを取得するプロジェクトの設定、および自動化を開始するジョブテンプレートの設定を案内されます。</block>
  <block id="5055de7b9d28f88e537f99f34959c80c" category="list-text">環境に固有の変数を入力し、ジョブテンプレートのその他の VAR フィールドにコピーして貼り付けます。</block>
  <block id="d116f375db402ba471f519c0a4df15dc" category="list-text">ジョブテンプレートに変数を追加したら、自動化を起動できます。</block>
  <block id="8ca0a52cf9938328875e0a8803ae71dd" category="list-text">ジョブテンプレートは、 ontap/config 、 linux_config 、および ORACLE_config のタグを指定することで、 3 つのフェーズで実行されます。</block>
  <block id="da3d0d670ace8a327170aa25ee29f272" category="section-title">Ansible コントロールホストを介して CLI に接続します</block>
  <block id="6a5f01bc22c397ee84e04e48c178e980" category="inline-link-macro">RHEL 7/8 または CentOS 7/8 の場合は、こちらをクリックしてください</block>
  <block id="7946c3996884ee105962c5334bfd9fef" category="inline-link-macro">Ubuntu / Debian の場合はこちら</block>
  <block id="28e934ddab7714830f8afe8d3b641dc9" category="list-text">Ansible 制御ホストが設定されたら、 Ansible Automation リポジトリのクローンを Git で作成できます。</block>
  <block id="f667be8dac02593d217a02ac5bfb18de" category="list-text">ONTAP クラスタ管理 IP および Oracle サーバの管理 IP の IP またはホスト名を使用して hosts ファイルを編集してください。</block>
  <block id="95bd15e6b4a109de659c54c331c06284" category="list-text">環境に固有の変数を入力し ' 変数 .yml ファイルにコピーして貼り付けます</block>
  <block id="ca548be3e5f238d32286d43dc4c89f7b" category="list-text">各 Oracle ホストには、ホスト固有の変数を含むホスト名で識別される変数ファイルがあります。</block>
  <block id="87192ebbcab92216d25fd694a282971d" category="list-text">すべての変数ファイルが完了したら 'ONTAP_config' 'linux_config' および 'ORACLE_config' のタグを指定することで ' 3 つのフェーズでプレイブックを実行できます</block>
  <block id="5a2ebfb8baa378cfcfcba58bbb1380c2" category="section-title">要件</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">環境</block>
  <block id="9d5cfca4ad04b54536e5ad15210f7dc2" category="cell">* Ansible 環境 *</block>
  <block id="eebc1357e7d1e88ed4e4908d5ae86c0b" category="cell">AWX/Tower または Linux ホストを Ansible コントロールホストにします</block>
  <block id="3f0733e14ebf265f0abf4b32371043ac" category="cell">Ansible v.2.10 以上</block>
  <block id="3c91a74236fab100f024452f6df13b5e" category="cell">Python 3.</block>
  <block id="215b38d177939de20bbb7b7913ce32c1" category="cell">Python ライブラリ - NetApp-lib-xmltodict-jmespath</block>
  <block id="d911b17f4f4cdcca62a04ad77aa9403d" category="cell">* ONTAP *</block>
  <block id="0a928fe81d89083ed303ea3d9f1af8c9" category="cell">ONTAP バージョン 9.3-9.7</block>
  <block id="10aadda84b1b1da26c3757dfdb59379d" category="cell">データアグリゲート × 2</block>
  <block id="9f998f9668ffe69c62d78760d1c531f0" category="cell">NFS VLAN および ifgrp が作成されました</block>
  <block id="ba5f343281b90f0408008806c66bce86" category="cell">* Oracle サーバ *</block>
  <block id="6f1de5f0d7966ebf5f8d255fe28ebffe" category="cell">RHEL 7/8</block>
  <block id="aa596da3b79631d86c0d35e1c4b03aac" category="cell">Oracle Linux 7/8</block>
  <block id="814e8f57514db6134b6ffcd7a4ce20a6" category="cell">NFS 、パブリック、オプションの管理用のネットワークインターフェイス</block>
  <block id="515f291f3ecc550c5d13cf31fadba91d" category="cell">Oracle サーバ上の Oracle インストールファイル</block>
  <block id="ae9205dab0c26cca7762be5149a93923" category="section-title">自動化の詳細</block>
  <block id="ba0676e7ae183e2c0bbd54261818154f" category="paragraph">この自動導入は、 3 つのロールで構成される Ansible プレイブックを使用して設計されています。ロールは ONTAP 、 Linux 、 Oracle の各構成に対応しています。次の表に、自動化されるタスクを示します。</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">ロール</block>
  <block id="ef615563c8e8ea902c7fcac3cd2c4246" category="cell">タスク</block>
  <block id="9bb642814808cd0cab510ddfb9e5969c" category="cell">* ONTAP_CONFIG *</block>
  <block id="c0563eda0fb9d63778efe04a13a5d744" category="cell">ONTAP 環境の事前チェック</block>
  <block id="79b814c8267c6b7822e78ab4624db8e0" category="cell">Oracle 用の NFS ベースの SVM の作成</block>
  <block id="0c981d6164da0d8e69cdb199966316b0" category="cell">エクスポートポリシーが作成されました</block>
  <block id="99179ac01bbb0236fc540871377c55c4" category="cell">Oracle 用のボリュームの作成</block>
  <block id="db738705829d97db1e287ad8ea9e5400" category="cell">NFS LIF の作成</block>
  <block id="089c4c184b079d771501d8ceb0f3bb05" category="cell">*linux_config*</block>
  <block id="3ea572544d30a39d236496578f980d13" category="cell">マウントポイントを作成し、 NFS ボリュームをマウント</block>
  <block id="db6c0f994cc39fbf66d58eea6c627e6a" category="cell">NFS マウントを確認</block>
  <block id="6a882e7966e7869ab1d2112a0b1c0074" category="cell">OS 固有の設定</block>
  <block id="6e6d41d1398fafd8809de20e831c9ce3" category="cell">Oracle ディレクトリを作成します</block>
  <block id="6f965a5d44e1653dac9825f465f71c84" category="cell">hugepages を設定します</block>
  <block id="be577868fe0712b7bbb6d5cb5eae613c" category="cell">SELinux とファイアウォールデーモンを無効にする</block>
  <block id="bb6f16330211bf24baa83db38b11e4a9" category="cell">サービスを有効にして開始します</block>
  <block id="e9e5cefa281d2c696aac82ef9c756f51" category="cell">ファイル記述子のハードリミットを増やします</block>
  <block id="a4acc779f882208c081f943aedfeab5c" category="cell">pam.d セッションファイルを作成します</block>
  <block id="d03021f9e02b9fa9ebac591ad4bfea08" category="cell">* ORACLE_CONFIG *</block>
  <block id="5e706781d4bf141c80e249a244179235" category="cell">Oracle ソフトウェアのインストール</block>
  <block id="1a98fce6d77de1126bf3cb8247747621" category="cell">Oracle リスナーを作成します</block>
  <block id="841df7bfbef212936073c6d261d4dba9" category="cell">Oracle データベースを作成します</block>
  <block id="845a6e024025bb13aafdc167511e5e7d" category="cell">Oracle 環境構成</block>
  <block id="666113957f940ba4319b4f0d9c3e86c0" category="cell">PDB 状態を保存します</block>
  <block id="264bca6ddd5a16346460d9c21e8f926d" category="cell">インスタンスアーカイブモードを有効にします</block>
  <block id="620ca5ae835411d2031ca0fdbbbe61a1" category="cell">DNFS クライアントを有効にしてください</block>
  <block id="4d7e6c9b84f6f86cf4817262ad424eeb" category="cell">OS のリブート間のデータベースの自動起動とシャットダウンを有効にします</block>
  <block id="bf60025632dd0c4a2cf35e8b33e80619" category="section-title">デフォルトパラメータ</block>
  <block id="ebda2606845855cc07ce0ce15ecf8a00" category="paragraph">自動化を簡易化するために、必要な Oracle 導入パラメータが多数デフォルト値であらかじめ設定されています。通常、ほとんどの環境でデフォルトパラメータを変更する必要はありません。上級ユーザーは ' デフォルト・パラメータを変更する際に注意してくださいデフォルトのパラメータは、各ロールフォルダの defaults ディレクトリにあります。</block>
  <block id="452eff11ca6d680a279a3e81b8dc8974" category="section-title">導入手順</block>
  <block id="1cf7ad9cd74067dd3f4aee3c1690ea32" category="paragraph">開始する前に ' 次の Oracle インストール・ファイルとパッチ・ファイルをダウンロードし '/tmp/archive' ディレクトリに配置しますこのディレクトリには ' 展開する各 DB サーバ上のすべてのユーザに対する読み取り ' 書き込み ' および実行のアクセス権が含まれます自動化タスクは、その特定のディレクトリにある指定されたインストールファイルを検索して、 Oracle のインストールと構成を行います。</block>
  <block id="19adadc497199e16f07f9744d43b2899" category="paragraph">Github リポジトリに記載されているライセンス情報をお読みください。このリポジトリ内のコンテンツにアクセス、ダウンロード、インストール、または使用することにより、ライセンスの条項に同意したものとみなされます <block ref="07d15b3b85718d883b437fb3739e59a7" category="inline-link-rx"></block>。</block>
  <block id="87d624bc8a7f555a711e7214ee002eec" category="paragraph">このリポジトリ内のコンテンツの作成および / または派生著作物の共有に関しては、一定の制限事項があります。の条件を必ずお読みください <block ref="49480c711afcff6aca610d8294731030" category="inline-link-rx"></block> コンテンツを使用する前に。すべての条件に同意しない場合は、このリポジトリのコンテンツにアクセスしたり、コンテンツをダウンロードしたり、使用したりしないでください。</block>
  <block id="5abe869dd828ac1e4527f07db79841a8" category="inline-link-macro">AWX/Tower の導入手順の詳細については、こちらを参照してください</block>
  <block id="c3bcf861ccc9247a7c0a9b4749747e4e" category="inline-link-macro">CLI の導入については、こちらをご覧ください</block>
  <block id="f867ea86471dd6849f2c840cf13d1536" category="paragraph">準備ができたら、をクリックします <block ref="0ecf76284fbf596cdd030af085c16a3b" category="inline-link-macro-rx"></block> または <block ref="42cd9508ebf775e8df0efba80be76af7" category="inline-link-macro-rx"></block>。</block>
  <block id="13d13fda6fbfbd83ab30f9a5bee17b08" category="section-title">Oracle19c for ONTAP の NFS への自動導入</block>
  <block id="9ce6d30135c2644ff34390c65af4061b" category="paragraph">組織は環境を自動化して、効率を高め、導入を高速化し、手動作業を削減しています。Ansible などの構成管理ツールを使用して、エンタープライズデータベースの運用を合理化しています。この解決策では、 Ansible を使用して、 Oracle 19C のプロビジョニングと設定を NetApp ONTAP で自動化する方法を紹介します。ストレージ管理者、システム管理者、 DBA は、新しいストレージの一貫した迅速な導入、データベースサーバの構成、 Oracle 19C ソフトウェアのインストールを可能にすることで、次のようなメリットを得ることができます。</block>
  <block id="5291cb8e681983247b899ce2364188f2" category="list-text">設計の複雑さと人為的ミスを排除し、繰り返し実行可能な一貫した導入とベストプラクティスを実装する</block>
  <block id="a90516bf4597e04e1a97bd9cb37087d8" category="list-text">ストレージのプロビジョニング、 DB ホストの構成、 Oracle のインストールにかかる時間を短縮</block>
  <block id="a54e59b6b063d8a2bf18acffab877d09" category="list-text">データベース管理者、システム管理者、ストレージ管理者の生産性を向上</block>
  <block id="d18d76441366273feb36bde890ad5e1c" category="list-text">ストレージとデータベースを簡単に拡張できます</block>
  <block id="7d85c5a5f016aefeda6b89687f1307bb" category="paragraph">ネットアップは、検証済みの Ansible モジュールとロールをお客様に提供し、 Oracle データベース環境の導入、構成、ライフサイクル管理を迅速化します。この解決策では、以下の作業に役立つ Ansible の Playbook コードを提供しています。</block>
  <block id="547b893b7cd300d6a8335f5b179ad12e" category="list-text">Oracle データベース用の ONTAP NFS ストレージを作成して設定します</block>
  <block id="36bb01ec9f02292fb44b9f10f57ceae7" category="list-text">Oracle 19C を Red Hat Enterprise Linux 7/8 または Oracle にインストールします Linux 7/8.</block>
  <block id="548bf87c41c9d3bb76981decbd599c90" category="list-text">ONTAP NFS ストレージ上に Oracle 19C を設定します</block>
  <block id="0dd197c8abd1f3c3607887dbc615148f" category="doc">Oracle のインストールを検証します</block>
  <block id="f673434da0f39c1b4366cbc45f67da8a" category="admonition">インストールが正常に完了した場合は、 Oracle プロセスが一覧表示されます Oracle DB のサポートを開始しました</block>
  <block id="91bcd024d07cb33293902b287b0cc68c" category="paragraph">[oracle @localhost ~] $sqlplus / AS sysdba</block>
  <block id="b95bce10ef504692a6d971d3a30ac8c4" category="paragraph">SQL * Plus ：リリース 19.0.0.0.0 - 木曜日 5 月 6 日 12 ： 52 ： 51 2021 バージョン 19.8.0.0.0 の製造</block>
  <block id="a2494ba30f29d91ff6876152fc693ab3" category="paragraph">Copyright （ c ） 1982 、 2019 、 OracleAll rights reserved.</block>
  <block id="ce8b3f5af3f95d98bbbf478e4c37024f" category="paragraph">接続先： Oracle Database 19C Enterprise Edition Release 19.0.0.0.0 - Production Version 19.8.0.0.0</block>
  <block id="28a359e505158300600d776ae9347cac" category="paragraph">SQL&gt;</block>
  <block id="63102463594ac5bd274343651065779d" category="paragraph">SQL&gt; 名前の選択、 log_mode は V$ データベースから、名前 log_mode は ---- - - - - - - - - - - CDB2 ARCHIVELOG</block>
  <block id="7d8bf5a6b847068ff3c0eb0ca0892acf" category="paragraph">SQL&gt; PDB を表示</block>
  <block id="33c7676f0bdcf42bed62c146feaf485c" category="paragraph">SQL&gt; col svrname フォーム A30 SQL&gt; col dirname フォーム A30 SQL&gt; select svrname 、 dirname 、 nfsversion from v$dnfs_servers ；</block>
  <block id="d6bee2dc52f5708cd8af49c1c263c714" category="paragraph">SVRNAME NFSVERVERSION-------------------------------- -------------- - - - - - - - - - - - - - 172.21.126.200/rhelora03_u02 NFSv4 3.0 172.21.126.200/rhelora03_u03 NFSv4 3.0 172.21.126.200/rhelora03_u01 NFSv3.0 を NFSv4 3.00 に戻します</block>
  <block id="ea12870da72347cdd45bc11ae4d603dc" category="paragraph">[oracle @ localhost ~] $sqlplus システム @ // localhost ： 1523 / cdb2_pdb1.cie.netapp.com</block>
  <block id="aff680efe40afd832819af131e324051" category="paragraph">SQL * Plus ：リリース 19.0.0.0.0 - 木曜日 5 月 6 日 13 ： 19 ： 57 2021 バージョン 19.8.0.0.0 の製造</block>
  <block id="6c3d252188792733323cf879b5d196cf" category="paragraph">パスワード「 Last Successful login time ： Wed May 05 2021 17 ： 11 ： 11-04 ： 00 」を入力します</block>
  <block id="531fea2bb939d7c35cad66fde1640511" category="paragraph">SQL&gt; show user user is "system" SQL&gt; show con_name CON_name CDB2_PDB1</block>
  <block id="52320018ddc230fda7bdeccfda8b9f0a" category="section-title">サポートが必要な場所</block>
  <block id="1b6a5f8b328d3175066895d7ff5ea576" category="inline-link">ネットアップの解決策自動化コミュニティでは、余裕期間のチャネルがサポートさ</block>
  <block id="12f178498803c606c23e7166dcefb0cb" category="paragraph">ツールキットに関するサポートが必要な場合は、にご参加ください <block ref="f1bb21e2ce6888d898ae31a2098245a1" category="inline-link-rx"></block> また、ソリューション自動化チャネルを検索して、質問や問い合わせを投稿しましょう。</block>
  <block id="d0db3f5a4a306cff20be4187b3ef3445" category="doc">VAR</block>
  <block id="6551468cb4811e7add616eea103efea9" category="doc">ステップバイステップの導入手順</block>
  <block id="0e6b1c16527d2792d391c578bbf12efe" category="section-title">CLI による Oracle 19C データベースの導入</block>
  <block id="57daddd847cdbab22b7363630de48a2f" category="inline-link-macro">「はじめに」および「要件」セクション</block>
  <block id="82ba94e85d91493ea6c88423c0b34605" category="paragraph">このセクションでは、 CLI を使用して Oracle19c データベースを準備および導入するために必要な手順について説明します。を確認しておきます <block ref="598ea103507880273a5a1840cac102d8" category="inline-link-macro-rx"></block> それに応じて環境の準備を整えます。</block>
  <block id="0f2d7675188dbfc7b9df587588bff71b" category="section-title">Oracle19c repo をダウンロードします</block>
  <block id="4e2b619426350db7e7d5b09c96b8010b" category="section-title">hosts ファイルを編集します</block>
  <block id="b183e47af1fa85c93e4a4368205c3249" category="paragraph">導入前に、次の手順を実行します。</block>
  <block id="c4ab1530ffd8a3306d47c804ca88240c" category="list-text">hosts ファイル na_oracle19c_deploy ディレクトリを編集します。</block>
  <block id="bc1dd0e50a3c20e78cc2d680eaf32378" category="list-text">ONTAP で、 IP アドレスをクラスタ管理 IP に変更します。</block>
  <block id="6475f51ce7ff0a21a5635ea50b1f1a86" category="list-text">[Oracle] グループの下に、 Oracle ホスト名を追加します。DNS または hosts ファイルを使用してホスト名を IP アドレスに解決しておくか、ホストで指定する必要があります。</block>
  <block id="5c3f5e9dc815ca28c7cf1ff64cdc61a2" category="list-text">これらの手順を完了したら、変更を保存します。</block>
  <block id="b27994a7bba852ac9a8f1a262413e68b" category="paragraph">次の例は、ホストファイルを示しています。</block>
  <block id="1caa2eee0ed6a6c5c6edcbc0320e8671" category="paragraph">この例では、 Playbook を実行し、 Oracle 19C を 2 台の Oracle DB サーバに同時に導入しています。1 つの DB サーバでテストすることもできます。この場合、設定が必要なホスト変数ファイルは 1 つだけです。</block>
  <block id="d11927d6f93a4edaa78dc52c6e34fd5f" category="admonition">このプレイブックの内容は、導入する Oracle ホストとデータベースの数に関係なく同じです。</block>
  <block id="030c98564d5fbd7c8672a76e2a593b21" category="section-title">host_vars で host_name .yml ファイルを編集します</block>
  <block id="86c40bb4891f3e6b34a2eece7bb19532" category="paragraph">各 Oracle ホストには、ホスト固有の変数を含むホスト名で識別されるホスト変数ファイルがあります。ホストには任意の名前を指定できます。Host VAR Config セクションから「 host_vars 」を編集してコピーし、目的の「 host_name.yml 」ファイルに貼り付けます。</block>
  <block id="93be2ec6954884b83ac9df8117967949" category="admonition">青の項目は、環境に合わせて変更する必要があります。</block>
  <block id="5bbe8264b4d6c6787657c66d4017c183" category="section-title">ホスト VAR 構成</block>
  <block id="44505c1007599884b05c0148599ad1b0" category="section-title">vars.yml ファイルを編集します</block>
  <block id="41cdd95196e2753968e0d69375c41825" category="paragraph">変数 .yml` ファイルは 'Oracle の導入に向けて ' 環境固有のすべての変数（ ONTAP 'Linux'Oracle ）を統合します</block>
  <block id="271f9ccf9c8189bb1888d25c7f0e025b" category="list-text">変数を VAR セクションから編集してコピーし、変数を自分の「 vars.yml 」ファイルに貼り付けます。</block>
  <block id="78d77851709e21512097cee585c59d0c" category="section-title">プレイブックを実行します</block>
  <block id="8f42d9f703ada5b4f1374ca96a4f1cec" category="paragraph">必要な環境の前提条件を完了し ' 変数を vars.yml' および 'Your_host.yml' にコピーした後 ' プレイブックを導入する準備が整いました</block>
  <block id="6226590ec5d4a109e4b93317425994c1" category="admonition">&lt;username&gt; は、環境に合わせて変更する必要があります。</block>
  <block id="24b2767982b51deb19947fb3e94279c6" category="section-title">同じ Oracle ホストに追加のデータベースを導入します</block>
  <block id="5cc75d1029461de7ddcd02bbc784af26" category="paragraph">このプレイブックの Oracle 部分では、 1 回の実行につき Oracle サーバ上に Oracle コンテナデータベースが 1 つ作成されます。同じサーバ上に追加のコンテナデータベースを作成するには、次の手順を実行します。</block>
  <block id="b4a35a2d5c3a4f3efb7c77f6bcd2a905" category="list-text">host_vars 変数を改訂します。</block>
  <block id="5641cb71d4e10abef15918c2dd828917" category="list-text">ステップ 3 に戻ります - 'host_vars' の下の 'host_name.yml' ファイルを編集します</block>
  <block id="ffcc6e6df9c3839334c063a9223c65b3" category="list-text">Oracle SID を別の名前文字列に変更します。</block>
  <block id="a936a5fabc881eb3591658385409dfb8" category="list-text">リスナーポートを別の番号に変更します。</block>
  <block id="24f0029973c35b16fc49847b27215915" category="list-text">EM Express をインストールしている場合は、 EM Express ポートを別の番号に変更します。</block>
  <block id="365c64de6adc281d7f484029d1356855" category="list-text">変更したホスト変数を 'host_vars' の下の Oracle ホスト変数ファイルにコピーして貼り付けます</block>
  <block id="b64219fd8290ac8a154f733df0825dbb" category="list-text">上記のように 'ORACLE_CONFIG' タグを使用してプレイブックを実行します インチ <block ref="1c892654e23ff69bf71caefc702aa8b4" category="inline-xref-macro-rx"></block>。</block>
  <block id="c150393fd3b1bd9d801cbd062234f73d" category="section-title">AWX/Tower の導入 Oracle 19C データベース</block>
  <block id="32003b051ef9368756d1e9cd79796719" category="section-title">1. 環境のインベントリ、グループ、ホスト、およびクレデンシャルを作成します</block>
  <block id="2c8b94d570dd5a63a27d112e32a1c799" category="paragraph">このセクションでは、ネットアップの自動化ソリューションを使用する環境を準備するための AWX/Ansible タワーでのインベントリ、グループ、ホスト、アクセスクレデンシャルのセットアップについて説明します。</block>
  <block id="134d501fee5367069f0746f15302ce1f" category="list-text">インベントリを設定します。</block>
  <block id="af2c7dd4ecef5e42e9bc8f88213d51d9" category="list-text">リソース→インベントリ→追加と進み、インベントリの追加をクリックします。</block>
  <block id="56fc26ef1c8ae54dced3529eec65fa26" category="list-text">名前と組織の詳細を入力し、 [ 保存 ] をクリックします。</block>
  <block id="fe0981da08a8d2f4fed2006bafd9fb30" category="list-text">インベントリページで、作成されたインベントリをクリックします。</block>
  <block id="65d119ae335d9e7c9c798b3e6db1b2d0" category="list-text">[ グループ ] サブメニューに移動し、 [ 追加 ] をクリックします。</block>
  <block id="396641e01a7451ca821b5d7d1377b0c7" category="list-text">ONTAP のグループの名前を入力し、グループ変数（ある場合）を貼り付けて、 [ 保存 ] をクリックします。</block>
  <block id="a4f13b6e4100f2d5db093eb54a3ffe0c" category="list-text">Oracle の別のグループに対してこの手順を繰り返します。</block>
  <block id="6f29f21d5f3e40494291fb357b9f4f73" category="list-text">作成した ONTAP グループを選択し、 Hosts サブメニューに移動して、 Add New Host をクリックします。</block>
  <block id="8d92ffd9d0d2b033d05731ec4af50af8" category="list-text">ONTAP クラスタ管理 IP の IP アドレスを入力し、ホスト変数（存在する場合）を貼り付けて、 [ 保存 ] をクリックします。</block>
  <block id="f1254ecbe57ff98d850d541b8a1ab988" category="list-text">このプロセスは、 Oracle グループおよび Oracle ホストの管理 IP / ホスト名に対して繰り返す必要があります。</block>
  <block id="f11c5853bdca384314b28c9c59f2d6d0" category="list-text">クレデンシャルタイプを作成する。ONTAP を使用するソリューションでは、ユーザ名とパスワードのエントリを照合するようにクレデンシャルタイプを設定する必要があります。</block>
  <block id="c87e3da0a9f8d5eeacea4eac9bef80ea" category="list-text">[ 管理 ] → [ 資格情報の種類 ] に移動し、 [ 追加 ] をクリックします。</block>
  <block id="e6bf632438290fdf98265b2b18943118" category="list-text">名前と概要を指定します。</block>
  <block id="5f5a0974b600f86bd4e77595282fcf70" category="list-text">入力構成に次の内容を貼り付けます。</block>
  <block id="1616edbabbc3bbfd22afe144d1929386" category="list-text">次の内容をインジェクター設定に貼り付けます。</block>
  <block id="c4053f20c3fe50fe899484a64367439e" category="list-text">クレデンシャルを設定します。</block>
  <block id="41dcc8a8aaaa79a511ba0ab4e6bde225" category="list-text">[ リソース ] → [ 資格情報 ] に移動し、 [ 追加 ] をクリックします。</block>
  <block id="cc865c923bcb1c61acf9985311675b93" category="list-text">ONTAP の名前と組織の詳細を入力します。</block>
  <block id="ea314f484653e7f9f25144ea61d34888" category="list-text">ONTAP 用に作成したカスタム資格情報タイプを選択します。</block>
  <block id="179cae6336461d9f165e8fa87146362a" category="list-text">[ タイプの詳細 ] で、ユーザー名、パスワード、および vsadmin-readonly を入力します。</block>
  <block id="659fb4c811f1a73cf40492056e6d3c3f" category="list-text">[ 資格情報に戻る ] をクリックし、 [ 追加 ] をクリックします</block>
  <block id="3b9c90c4bf202563a3cdeda5ec78fac2" category="list-text">Oracle の名前と組織の詳細を入力します。</block>
  <block id="9ef3fcc446a5f500717f9b5e9291bce4" category="list-text">マシンクレデンシャルタイプを選択します。</block>
  <block id="9fadc5c4eed350a8a1423628227dad59" category="list-text">Type Details （タイプの詳細）に、 Oracle ホストのユーザー名とパスワードを入力します。</block>
  <block id="b4ca3125325138b1dbfc309e6bd67b80" category="list-text">適切な特権昇格方式を選択し、ユーザ名とパスワードを入力します。</block>
  <block id="51b04d83367483575e89740841d94262" category="section-title">2. プロジェクトを作成します</block>
  <block id="e56fa1e2655db1bc7664a00295bd62a2" category="list-text">[ リソース ] → [ プロジェクト ] に移動し、 [ 追加 ] をクリックします。</block>
  <block id="9c78f8d8687776e79018ded982e14c25" category="list-text">名前と組織の詳細を入力します</block>
  <block id="4096a1870a258e9d46585f08d4906f21" category="list-text">Source Control Credential Type フィールドで Git を選択します。</block>
  <block id="784148c4a03cf22250dddc5756684e39" category="list-text">入力するコマンド <block ref="4509731a8f0f86cf7d8a010739dfd7c5" category="inline-link-rx"></block> をソース管理 URL として指定します。</block>
  <block id="7557bd62e953fb4d48f07977151ea94f" category="list-text">[ 保存 ] をクリックします .</block>
  <block id="99bc2ea435ea8ae0ed38ef3051a4350a" category="list-text">ソースコードが変更されたときに、プロジェクトの同期が必要になることがあります。</block>
  <block id="14e017f358e18dd612a468713206093f" category="section-title">3. Oracle host_vars を設定します</block>
  <block id="05557c38b20e42173356b53f42c92152" category="paragraph">このセクションで定義した変数は、個々の Oracle サーバとデータベースに適用されます。</block>
  <block id="ac886b852fd1b481e9c7e68c217b5e21" category="list-text">次の組み込み Oracle ホスト変数または host_vars フォームに、環境固有のパラメータを入力します。</block>
  <block id="e1847b1a99378b07a0df71cf2baac5da" category="list-text">青のフィールドにすべての変数を入力します。</block>
  <block id="741c92ab2429ff59927918c7a07ad9a5" category="list-text">変数の入力が完了したら、フォームの [ コピー ] ボタンをクリックして、 AWX またはタワーに転送されるすべての変数をコピーします。</block>
  <block id="1e1ea51549ac2a644a3e965113c1d370" category="list-text">AWX またはタワーに戻って、 Resources （リソース）→ Hosts （ホスト）に移動し、 Oracle サーバ設定ページを選択して開きます。</block>
  <block id="0d630b14098a793ac4586173286d0805" category="list-text">[ 詳細 ] タブで、編集をクリックし、コピーした変数を手順 1 から YAML タブの [ 変数 ] フィールドに貼り付けます。</block>
  <block id="c6dca9e669d097298fc6059b27f96e09" category="list-text">システム内の他の Oracle サーバについても、この手順を繰り返します。</block>
  <block id="7890327bd98d1ec932e453254511754d" category="section-title">4. グローバル変数を設定します</block>
  <block id="e5cac740ce6bd43e6ff83881e150d0f3" category="paragraph">このセクションで定義する変数は、すべての Oracle ホスト、データベース、および ONTAP クラスタに適用されます。</block>
  <block id="87b55102ec2889891b0258253b739244" category="list-text">次の組み込みグローバル変数または変数フォームに環境固有のパラメータを入力します。</block>
  <block id="7d2a3c2ad9ee2eeb7547d205d30b9335" category="list-text">すべての変数を青のフィールドに入力します。</block>
  <block id="099f04b51539ed973890f1d1af2d5063" category="list-text">変数の入力が完了したら、フォームの [ コピー ] ボタンをクリックして、 AWX またはタワーに転送されるすべての変数を次のジョブテンプレートにコピーします。</block>
  <block id="c807b1735c1915c52547b9f7e917b55d" category="section-title">5. ジョブテンプレートを設定して起動します。</block>
  <block id="b1171f0b44b8d9b11ac555972ebc8c3b" category="list-text">ジョブテンプレートを作成します。</block>
  <block id="0fd181172a82ebe5219e9a30e5d97c0d" category="list-text">[ リソース ] → [ テンプレート ] → [ 追加 ] に移動し、 [ ジョブテンプレートの追加 ] をクリックします。</block>
  <block id="3dcca032e3328f54206079a87830aa27" category="list-text">ジョブタイプを選択します。 Run は、プレイブックに基づいてシステムを設定します。 Check は、実際にシステムを設定することなく、プレイブックの事前チェックを実行します。</block>
  <block id="daefcb84cec2b58089094a64cefb845f" category="list-text">対応するインベントリ、プロジェクト、プレイブック、およびクレデンシャルを選択します。</block>
  <block id="b01c6189ccdc531874f3442803680525" category="list-text">実行するデフォルトのプレイブックとして、 all_cplaybook.yml を選択します。</block>
  <block id="ce150ce9cfe145db199958e7cd2ecce0" category="list-text">手順 4 からコピーしたグローバル変数を YAML タブの Template Variables フィールドに貼り付けます。</block>
  <block id="e8f0426d97d09775fb78bdeb793b0b3e" category="list-text">[ ジョブタグ ] フィールドの [ 起動時にプロンプトを表示する ] チェックボックスをオンにします。</block>
  <block id="31e2568c13fbdaaad088eb3b665dea9d" category="list-text">ジョブテンプレートを起動します。</block>
  <block id="3624b34cb634949984bcb28c79fd327f" category="list-text">[ リソース ] → [ テンプレート ] に移動します。</block>
  <block id="56ae7378358ba2b1c55c47283f544991" category="list-text">目的のテンプレートをクリックし、 [ 起動 ] をクリックします。</block>
  <block id="ad7ad1bbc416fda1f9518ff4004d891c" category="list-text">ジョブタグの起動時にプロンプトが表示されたら、 requires_config と入力します。requires_config の下にある Create Job Tag 行をクリックして、ジョブタグを入力する必要がある場合があります。</block>
  <block id="b9ef793a3db3f07ed7dc808f4709c6ca" category="admonition">requireation_config により、他のロールを実行するための正しいライブラリが確保されます。</block>
  <block id="6ac039e55dcf8a249f5122b1fdbbf60e" category="list-text">[ 次へ ] をクリックし、 [ 起動 ] をクリックしてジョブを開始します。</block>
  <block id="06f392c8dfb4783859e67f16fed69bc7" category="list-text">ジョブの出力と進行状況を監視するには、表示→ジョブをクリックします。</block>
  <block id="7f6a02c24592bd309f31b5a72a0f8d6d" category="list-text">ジョブタグの起動を求めるプロンプトが表示されたら、「 ONTAP_config 」と入力します。ジョブタグを入力するには、 ONTAP_config の下にある「ジョブタグの作成」行をクリックする必要があります。</block>
  <block id="18c003af9ed29d295877baabf7b42ce1" category="list-text">ジョブ出力およびを監視するには、表示→ジョブをクリックします 進捗状況</block>
  <block id="c0029d5cdcaae1ceef3bed244b3ab3c6" category="list-text">ONTAP_CONFIG ロールの完了後、 linux_config のプロセスを再度実行します。</block>
  <block id="fc71758268fe1c3aba4b75df3ee0560f" category="list-text">目的のテンプレートを選択し、 [ 起動 ] をクリックします。</block>
  <block id="bbe073bafc2875db8b48e59284636931" category="list-text">linux_config でジョブタグタイプの起動時にプロンプトが表示されたら、 linux_config のすぐ下にある「ジョブタグの作成」行を選択して、ジョブタグを入力する必要があります。</block>
  <block id="bc43b7acafead2cdee67de733ae10b13" category="list-text">ジョブの出力と進行状況を監視するには、表示→ジョブを選択します。</block>
  <block id="e73718535637e07111f6a4925685c0bd" category="list-text">linux_config ロールが完了したら、 ORACLE_config のプロセスを再度実行します。</block>
  <block id="574f8726a5cc088da32ab84269c8e0f8" category="list-text">[ リソース ] → [ テンプレート ] に移動します。</block>
  <block id="252b85bc679cb8ecdccbcd127c65b795" category="list-text">ジョブタグの起動時にプロンプトが表示されたら、 ORACLE_config と入力します。ORACLE_config の直下にある「ジョブタグの作成」行を選択して、ジョブタグを入力する必要がある場合があります。</block>
  <block id="6757805f64ddba2566927ece0d9f30e1" category="section-title">6. 同じ Oracle ホストに追加のデータベースを配置します</block>
  <block id="4edc1d4492ab93edbbb0a67c0c265b84" category="paragraph">このプレイブックの Oracle 部分では、 1 回の実行につき Oracle サーバ上に Oracle コンテナデータベースが 1 つ作成されます。同じサーバ上に追加のコンテナデータベースを作成するには、次の手順を実行します。</block>
  <block id="a12a0fa7fe728658376da87df04fa7c2" category="list-text">host_vars 変数を改訂。</block>
  <block id="ba52bf2d165115d60675d61a4b84b0c6" category="list-text">手順 2 - Oracle host_vars の設定に戻ります。</block>
  <block id="d9fa63a6f267402d4cf6068165e04a38" category="list-text">EM Express をインストールする場合は、 EM Express ポートを別の番号に変更します。</block>
  <block id="23f5c9b4f57b3075f9890f1bc1896ebe" category="list-text">改訂されたホスト変数を Host Configuration Detail タブの Oracle Host Variables フィールドにコピーして貼り付けます。</block>
  <block id="4d4426a703dd8227727fef5758b680d8" category="list-text">ORACLE_config タグのみを使用して、導入ジョブテンプレートを起動します。</block>
  <block id="e9dcec3e531a3cec5ee733f23baab91d" category="inline-link-macro">NFS への Oracle 19C for ONTAP の自動導入</block>
  <block id="e10944318a093524b44d6671144720e9" category="list-text"><block ref="e10944318a093524b44d6671144720e9" category="inline-link-macro-rx"></block></block>
  <block id="a90193527119bcbd79a1084d94ec3914" category="paragraph">ネットアップソリューションの最新の自動化機能の概要。</block>
  <block id="544c3a861d86ce6658187399d91aaa44" category="paragraph">ソリューションの検証と設計の目的の 1 つは、解決策を簡単に利用できるようにすることです。そのため、当社のソリューションを通じて提供されるインフラやアプリケーションの導入と構成は、自動化によって簡易化されていることが何よりも重要です。ネットアップでは、 Red Hat Ansible による自動化で解決策の利用を簡易化できるよう取り組んでいます。</block>
  <block id="9043d5bb11e7b216a7308f7a9761d9fd" category="paragraph">Ansible はオープンソースの自動化エンジンで、 IT チームはアプリケーションの導入、クラウドのプロビジョニング、設定管理など、さまざまな IT ニーズを自動化できます。Ansible はエージェントレスであるため、カスタムのセキュリティインフラは必要ありません。SSH を使用して制御システムから複数のシステムをリモートで自動化できるため、面倒で反復的な IT ニーズの自動化を検討している IT チームにとって堅牢な解決策となります。</block>
  <block id="8d9887ce2700536b12e7847e2163026e" category="paragraph">NetApp 解決策の自動化機能を初めて使用する場合は、以下のセクションに従って Ansible コントローラを設定できます。</block>
  <block id="6061668c9cb1cddb071099d0e9da5444" category="paragraph">RedHat Ansible の詳細については、のドキュメントを参照してください<block ref="228582a93333b3e21d695cbcfe7060d2" category="inline-link-rx"></block>。</block>
  <block id="4d3d20acde2dac77a5502c201323aa01" category="doc">NetApp 解決策の自動化</block>
  <block id="2aa17d37bd2483f97468ab7653396786" category="paragraph">このセクションでは、ネットアップの自動化ソリューションを使用する環境を準備する AWX/Ansible タワーのパラメータを設定するために必要な手順について説明します。</block>
  <block id="0fb1db9928d7fc107d96c13f1918b639" category="list-text">リソース→インベントリ→追加と進み、インベントリの追加をクリックします。</block>
  <block id="2623b8eb8fcaecc009c3b78cc6e7d391" category="list-text">名前と組織の詳細を入力し、 [ 保存 ] をクリックします。</block>
  <block id="cc243ac3e015aef331656a4bff40241c" category="list-text">インベントリページで、作成したインベントリリソースをクリックします。</block>
  <block id="b0ddb214e9aa4a84bc80e6af8c6b2adf" category="list-text">インベントリ変数がある場合は、その変数を変数フィールドに貼り付けます。</block>
  <block id="5d7863780eab69b6b968cfc9dc6e66bc" category="list-text">[ グループ ] サブメニューに移動し、 [ 追加 ] をクリックします。</block>
  <block id="ec51931bb91bc912d609f2099974dfd9" category="list-text">グループの名前を入力し、必要に応じてグループ変数にコピーして、 [ 保存 ] をクリックします。</block>
  <block id="8f9cbdc13fdcb31ff345f10ba333ac59" category="list-text">作成したグループをクリックし、 Hosts サブメニューに移動して、 Add New Host をクリックします。</block>
  <block id="98e7a99b463b825a87899d25486e46ea" category="list-text">ホストのホスト名と IP アドレスを入力し、必要に応じてホスト変数に貼り付けて、 Save をクリックします。</block>
  <block id="3caf9a56384a30eb8dee819e3abc14d6" category="list-text">クレデンシャルタイプを作成する。ONTAP 、 Element 、 VMware 、またはその他の HTTPS ベースの転送接続を使用するソリューションの場合は、ユーザ名とパスワードのエントリに一致するクレデンシャルタイプを設定する必要があります。</block>
  <block id="615b6214c17105ae4915a8c8a632025b" category="list-text">[ 管理 ] → [ 資格情報の種類 ] に移動して、 [ 追加 ] をクリックし</block>
  <block id="846bb9303e5cc4395e96eba0d4c7d50a" category="list-text">次の内容を入力構成に貼り付けます。</block>
  <block id="333a40c5632e0507a83f6a191f0b69b3" category="list-text">インジェクタの設定に次の内容を貼り付けます。</block>
  <block id="e31908e83a96aee8550446309c4ef7e0" category="list-text">クレデンシャルの設定</block>
  <block id="de06c7b54d4158f81a8c4d4a02b61eb0" category="list-text">リソース→資格情報に移動して、追加をクリックします。</block>
  <block id="e5b5f57b6910910a3f9a486e88088608" category="list-text">正しいクレデンシャルタイプを選択します。標準 SSH ログインを使用する場合は、「 Machine 」タイプを選択するか、作成したカスタムクレデンシャルタイプを選択します。</block>
  <block id="9256ee926473942ba849050ef0450b7f" category="list-text">対応するその他の詳細情報を入力し、 [ 保存 ] をクリックします。</block>
  <block id="29d192f714134f2e257058cfcf763722" category="list-text">プロジェクトを設定します。</block>
  <block id="1b892b7661c6a3ae2b57cbf4233c3af5" category="list-text">リソース→プロジェクトに移動し ' 追加をクリックします</block>
  <block id="936784ca62c93ca666e77fd10733247c" category="list-text">ソース管理資格情報タイプとして Git を選択します。</block>
  <block id="9f4fd9b4a4c75c02d1b469e8dd75d9fb" category="list-text">特定の解決策に対応するソース制御 URL （または git クローン URL ）を貼り付けます。</block>
  <block id="95acbbc0424478165cdbe3a62849cbc3" category="list-text">Git URL がアクセス制御されている場合は、必要に応じて、 Source Control Credential で対応するクレデンシャルを作成して添付します。</block>
  <block id="a934d780fa0cb0e8495a0a1cabd0f501" category="list-text">ジョブテンプレートを設定します。</block>
  <block id="10c610c9225adcc92ca1b284b5bbb04b" category="list-text">名前と概要を入力します</block>
  <block id="e33edf61d02fc69c2087dcc3c42177e1" category="list-text">ジョブタイプを選択します。 Run は、プレイブックに基づいてシステムを設定し、 Check は実際にシステムを設定することなく、プレイブックの事前チェックを実行します。</block>
  <block id="57cf64ce7890d12e5a41d18b83979ffd" category="list-text">このプレイブックに対応するインベントリ、プロジェクト、クレデンシャルを選択します</block>
  <block id="fc6b15b1dd73bb25477aed453b9a02f2" category="list-text">ジョブテンプレートの一部として実行するプレイブックを選択します。</block>
  <block id="9a7d90740af07bcdd2c628a6f6ae966c" category="list-text">通常、変数は実行時に貼り付けられます。そのため、実行時に変数を入力するように求めるプロンプトを表示するには、必ず [ 変数 ] フィールドに対応する [ 起動時にプロンプトを表示 ] チェックボックスをオンにしてください。</block>
  <block id="3454f07e6f81a48099e0d144ca38ec7a" category="list-text">必要に応じてその他の詳細情報を入力し、 [ 保存 ] をクリックします。</block>
  <block id="0b55c84dbc04b54418b0d507f7b8f669" category="list-text">起動時にプロンプトが表示されたら変数を入力し、 [ 再起動 ] をクリックします。</block>
  <block id="54d2cdd3035ca1cdff5803c30f2ed2e1" category="sidebar">Oracle データベースを導入しています</block>
  <block id="699700175d80778f1738d906ee9540d5" category="sidebar">設置と要件</block>
  <block id="210fdbe41d80b2e8690a970de86a7ffb" category="sidebar">Oracle 19C AWX/Tower の自動導入</block>
  <block id="13cf6478a61a7904a3062d587248fb75" category="sidebar">Oracle 19C CLI の自動導入</block>
  <block id="645198fb2e03205a7f761aeaff8ef26f" category="sidebar">NetApp 解決策の自動化と Ansible での作業を開始する方法について説明します</block>
  <block id="4a85fdd5a26454abc330a5ec2a46a326" category="paragraph">21.01 リリースでは、 Trident Operator のインストールを容易にするために Helm チャートを使用できるようになりました。</block>
  <block id="52d012c119e8e080d08f6a1592f8f9ec" category="section-title">Helm を使用して Trident Operator をインストールします</block>
  <block id="449774824d889f1d6ebc0bbcc4920493" category="list-text">Helm コマンドを実行し、ユーザークラスタに trident 名前空間を作成しながら、 Helball ディレクトリ内の tarball から Trident 演算子をインストールします。</block>
  <block id="615767b52353571ac174e22f1a984aa3" category="inline-link-macro">NetApp ONTAP NFS</block>
  <block id="c93e7ef2934826b1393251e9f7d9e331" category="inline-link-macro">NetApp ONTAP iSCSI の略</block>
  <block id="d0e0904111acb167badbf5f196ad1205" category="inline-link-macro">NetApp Element iSCSI の略</block>
  <block id="3605e05aa598ff405b5edffc1bf474f1" category="summary">ネットアップを使用した Red Hat OpenShift でのマルチテナンシーの構成</block>
  <block id="13148717f8faa9037f37d28971dfc219" category="doc">検証</block>
  <block id="12cdc5f68c3a0ca10544c0a57e866249" category="list-text">project-1 に割り当てられたストレージクラスを使用して 'project-1 に PVC を作成します</block>
  <block id="a345b6be662b316a3b3e3cfbc7566b31" category="list-text">project-1 にポッドを作成し、前の手順で作成した PVC をマウントします。</block>
  <block id="8e27501b578972bd7b65468deaa482ca" category="list-text">project-2 に割り当てられたストレージクラスを使用して 'project-1 に PVC を作成します</block>
  <block id="71bc5a6f1f0141981e0034b388233917" category="list-text">PROJECT -2 で PVC を作成します。</block>
  <block id="0d843e91c3b8f62457e19b2d32ecace3" category="list-text">プロジェクト 2 でポッドを作成します。</block>
  <block id="5d77fe4a6bb4c5e88c5c18510b3c4749" category="doc">NetApp Element ：ネットアップを使用した Red Hat OpenShift</block>
  <block id="8921c6e9843ba7487c77f4dce1467111" category="paragraph">NetApp Element ソフトウェアは、拡張性に優れたモジュラ型のパフォーマンスを提供し、ストレージノードごとに容量とスループットを保証します。NetApp Element システムは、 1 つのクラスタで 4~100 ノードまで拡張でき、高度なストレージ管理機能も多数備えています。</block>
  <block id="27765508a97a89684590658c3465fb70" category="inline-link">ネットアップの SolidFire Web サイト</block>
  <block id="d37eaafbb6dfb29673d63ff988ff4f41" category="paragraph">NetApp Element ストレージ・システムの詳細については、を参照してください<block ref="0d1d77e6774527457304fa15f73899a1" category="inline-link-rx"></block>。</block>
  <block id="dbafa7c074ef7efc3c778b69c0ad31b5" category="paragraph">NetApp Element ソフトウェアは、 iSCSI ストレージプロトコルを利用します。これは、従来の TCP/IP ネットワーク上で SCSI コマンドをカプセル化する標準的な方法です。SCSI 標準が変更された場合や、イーサネットネットワークのパフォーマンスが向上した場合、 iSCSI ストレージプロトコルには変更は必要ありません。</block>
  <block id="23e6b910b28346537f5696478fffe779" category="paragraph">すべてのストレージノードには管理 IP とストレージ IP が設定されますが、 NetApp Element ソフトウェアは、クラスタ内のすべてのストレージトラフィックについて、ストレージ仮想 IP アドレス（ SVIP アドレス）を 1 つアドバタイズします。iSCSI のログインプロセスでは、ストレージはターゲットボリュームが別のアドレスに移動されたことを応答するため、ネゴシエーションプロセスを続行できません。その後、ホスト側の再設定を必要としないプロセスで、ホストはログイン要求を新しいアドレスに再発行します。このプロセスは、 iSCSI ログインリダイレクトと呼ばれます。</block>
  <block id="f8cd3dfe225577e230dc2699ebbbfe34" category="list-text">* 最大 IOPS 。 * NetApp Element ソフトウェアクラスタが特定のボリュームに提供する平常時の最大 IOPS 。</block>
  <block id="5fec85270e969240cc769f429b9c8cdc" category="list-text">* VRF 対応 VLAN 。 * データセンターのセキュリティと拡張性をさらにサポートするため、 NetApp Element ソフトウェアを使用すると、 VRF に似た機能を持つテナント VLAN を有効にできます。この機能には、次の 2 つの主要機能が追加されて</block>
  <block id="eaea554ececf5b64515f0833c56b3de4" category="list-text">* IP サブネットの重複または重複 * 。この機能を使用すると、テナント環境にテンプレートを追加し、各テナント VLAN に同じ IP サブネットから IP アドレスを割り当てることができます。この機能は、 IPspace の拡張と保持が重要なサービスプロバイダ環境に役立ちます。</block>
  <block id="6893566c26b28e197cebdefdcc6af3ae" category="list-text">* 重複排除。 * システムには、一意の 4K ブロックのみが保存されます。重複する 4K ブロックは格納済みのデータバージョンに自動的に関連付けられます。データはブロックドライブに格納され、 NetApp Element ソフトウェアの Helix データ保護を使用してミラーリングされます。このシステムは、システム内の容量消費と書き込み処理数を大幅に削減します。</block>
  <block id="215de8162cb5ac909005881f92812fb0" category="list-text">* シンプロビジョニング。 * この機能は、必要なときに必要な量のストレージを提供し、オーバープロビジョニングされたボリュームや利用率の低いボリュームによる容量消費を排除します。</block>
  <block id="da9c9b2b4164632e569069fe1e7c53ee" category="admonition">Element は自動化を目的として設計されました。ストレージ機能はすべて API を使用して利用できます。これらの API は、システムの制御に UI で使用される唯一のメソッドです。</block>
  <block id="ec22e01e7cd5087ef746b3db5852da6e" category="doc">拡張：プロジェクトの追加</block>
  <block id="5790e2b8b367726e78500054d959d6f7" category="image-alt">拡張用の SVM を作成</block>
  <block id="c9e86337c7483c8d45e5e535829d2163" category="list-text">新しいプロジェクトを作成します。</block>
  <block id="8efa8222e644f71e636f98917439566d" category="list-text">プロジェクト 3 の開発者用に RoleBinding を作成します。これは、 developer-project-3 の役割を、 project-3 の対応するグループ (OCP-project-3) にバインドします。</block>
  <block id="e1f01c3341da15c9079bf5996c059811" category="list-text">Red Hat OpenShift クラスタにストレージ管理者としてログインします</block>
  <block id="55da75937cfedfe97c220c1e9d556d84" category="list-text">project-3 用のストレージクラスを作成し、 project-3 専用のバックエンドのストレージプールを使用するように設定します。</block>
  <block id="6efdcf6ed405066371d23375541816a1" category="list-text">ResourceQuota を作成して ' プロジェクト 3 のリソースを制限しますストレージを要求するストレージは ' 他のプロジェクト専用のストレージになります</block>
  <block id="68d13ef3d87e892878a6e6cbb44d1f21" category="doc">RHV への Red Hat OpenShift 導入：ネットアップを使用した Red Hat OpenShift</block>
  <block id="8fe3ce682e72fe87e56e5b11e1c2cd36" category="inline-link-macro">次のレポート：追加情報：ネットアップでの Red Hat OpenShift</block>
  <block id="5dbd13d011610e2b4d57bd4ca3fd685f" category="paragraph"><block ref="5dbd13d011610e2b4d57bd4ca3fd685f" category="inline-link-macro-rx"></block></block>
  <block id="122aacda8785e42ca8fd7bd6ebce84f8" category="paragraph">VMware vSphere は、 ESXi ハイパーバイザー上で実行される多数の仮想サーバとネットワークを一元管理するための仮想化プラットフォームです。</block>
  <block id="68bc8529d7c57946fe13e6b3399ee287" category="inline-link">VMware vSphere の Web サイト</block>
  <block id="80888e73d00a224bebfc22e8e4539b6d" category="paragraph">VMware vSphere の詳細については、を参照してください<block ref="8e822bbeb5824c0a05189bf9ff98da5c" category="inline-link-rx"></block>。</block>
  <block id="cb4d59b9004b7c584811a3d656f78bc5" category="section-title">VMware vSphere には次の機能があります。</block>
  <block id="cfb123c76f1c7a506310e1162d7ae235" category="paragraph"><block ref="cfb123c76f1c7a506310e1162d7ae235" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e75b582a8823d532f6022b43ac209538" category="paragraph">VMware vSphere 上の Red Hat OpenShift は、仮想ローカルエリアネットワーク（ VLAN ）を使用して、ネットワークトラフィックを論理的に分離するように設計されています。この構成は、お客様のニーズに合わせて拡張することも、特定のネットワークサービスをさらに分離することもできます。次の表に、ネットアップで解決策を検証する際に解決策を実装するために必要な VLAN を示します。</block>
  <block id="3c8c5d8387f173924ffeb2bf88084dba" category="cell">物理ノードと IPMI の管理</block>
  <block id="c61d980d5248923d65a5dfe7f8818011" category="cell">VM ネットワーク</block>
  <block id="fc221309746013ac554571fbd180e1c8" category="cell">181</block>
  <block id="c846a1f843522d592b784a66368abed3" category="cell">ONTAP NFS 用のストレージネットワーク</block>
  <block id="6cdd60ea0045eb7a6ec44c54d29ed402" category="cell">184</block>
  <block id="5e6094f6f2176409f469ee445fcf3f50" category="cell">ONTAP iSCSI 用のストレージネットワーク</block>
  <block id="eecca5b6365d9607ee5a9d336962c534" category="cell">185</block>
  <block id="45cf0331a91fdc3679a78fdd8f7c60a7" category="cell">ESXi ノード、 vCenter Server 、 ONTAP Select の管理</block>
  <block id="11967d5f57969ea4713204eace8fbf4e" category="cell">NetApp Element iSCSI 用のストレージネットワーク</block>
  <block id="0bad9231e1bf61bc343a986739f155c1" category="paragraph">OpenShift Container Platform を導入する前に、次のインフラを用意する必要があります。</block>
  <block id="9934283c0bf98610b4be1803b9ad3430" category="inline-link">vSphere 6.7 ドキュメント：「 DRS アフィニティルールの使用</block>
  <block id="291f24f63dc31f9f921b09c567fc963f" category="paragraph">アフィニティグループを設定するには、を参照してください<block ref="4b14049244eae7b3d11ef8e44785dd4e" category="inline-link-rx"></block>。</block>
  <block id="7b65abec68958867d7dd5f43b3b06e08" category="inline-link">Red Hat OpenShift カスタマイズを使用して vSphere にクラスタをインストールします</block>
  <block id="a0e01d06503f271c1de7acc0acd01733" category="doc">NVA-1160 ：ネットアップでの Red Hat OpenShift</block>
  <block id="44815e873492015d6a8ab6362de8da6c" category="list-text">ベアメタル、 Red Hat OpenStack Platform 、 Red Hat Virtualization 、 VMware vSphere に IPI （インストーラでプロビジョニングされたインフラ）を使用して導入した Red Hat OpenShift の導入と管理が容易です。</block>
  <block id="03bb323d052d033ea0b5b2cab17f1219" category="list-text">OSP 、 RHV 、 vSphere 、または OpenShift Virtualization を使用したベアメタルに導入された Red Hat OpenShift を使用して、エンタープライズコンテナと仮想化ワークロードのパワーを組み合わせたもの。</block>
  <block id="2748d7182409b378e23f62724be778fd" category="list-text">ノンストップオペレーションとアップグレード</block>
  <block id="42c487483a8feee3cc0365881a4cc265" category="paragraph">ネットアップとともに Red Hat OpenShift を導入することで、これらの課題に対応し、お客様が選択したデータセンター環境に RedHat OpenShift IPI を完全に自動で導入できるようになり、それぞれの問題に対処できる解決策が提供されます。</block>
  <block id="70240bc0debcb080aa08dbd9e7b9a525" category="paragraph">詳細については、 OpenShift の Web サイトを参照してください<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>。</block>
  <block id="aa4193984de53d2a6d8fcc2d77c09bda" category="paragraph">詳細については、ネットアップの Web サイトをご覧ください<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>。</block>
  <block id="e7e767d7c0e58b16e57d3ab16150db80" category="cell">テクノロジ</block>
  <block id="601712ded7a71b0842984ad41b6aad39" category="cell">12.3</block>
  <block id="765bb3744268ca0de607208bfdc8a37a" category="cell">ストレージオーケストレーション</block>
  <block id="2454407b9991c6c5f417a2feb8ea7970" category="cell">4.6 EUS 、 4.7</block>
  <block id="9c4e78a1b7e7b4981aced1e10d037c6d" category="cell">Red Hat OpenStack Platform</block>
  <block id="de45aa336111dfa1825c54726464307c" category="cell">プライベートクラウドインフラ</block>
  <block id="3c5825a0d4bdb85c67182ef89bc9c7eb" category="cell">16.1</block>
  <block id="f9a97ed4e88eeab44f2693afa0eb2089" category="cell">4 月 4 日</block>
  <block id="e690fa655ec589e6d0abb58164d5ccfd" category="doc">追加情報：ネットアップを使用した Red Hat OpenShift</block>
  <block id="6f4e4d9fbe846fd8bf7decf7dcffbd63" category="list-text">NetApp のドキュメント</block>
  <block id="1497398039e94eb756be9a3cff5649c7" category="inline-link"><block ref="1497398039e94eb756be9a3cff5649c7" category="inline-link-rx"></block></block>
  <block id="f2d3084aa0f70da5e15757ee3292cda7" category="paragraph"><block ref="f2d3084aa0f70da5e15757ee3292cda7" category="inline-link-rx"></block></block>
  <block id="21b11dbf6ab3c6d36a76f280fe8ec75d" category="list-text">Red Hat OpenShift のドキュメント</block>
  <block id="74201863479cf5c9b89330c920283301" category="inline-link"><block ref="74201863479cf5c9b89330c920283301" category="inline-link-rx"></block></block>
  <block id="3e10ed3875c45f9dc9064324660fc2b1" category="paragraph"><block ref="3e10ed3875c45f9dc9064324660fc2b1" category="inline-link-rx"></block></block>
  <block id="06fd33ae9f869a89e860634ec94b9793" category="list-text">Red Hat OpenStack Platform のドキュメント</block>
  <block id="647d438a62673b6a6c9830682f6bc128" category="inline-link"><block ref="647d438a62673b6a6c9830682f6bc128" category="inline-link-rx"></block></block>
  <block id="705a39bc1a12c50103a847633c3f7493" category="paragraph"><block ref="705a39bc1a12c50103a847633c3f7493" category="inline-link-rx"></block></block>
  <block id="8d79e9650a1f62f89d77743225e203c0" category="list-text">Red Hat Virtualization のドキュメント</block>
  <block id="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link"><block ref="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link-rx"></block></block>
  <block id="6d6038842b529e3d97aa9a8a9d81d866" category="paragraph"><block ref="6d6038842b529e3d97aa9a8a9d81d866" category="inline-link-rx"></block></block>
  <block id="4666fc2f640685636f115f8b2b6b8ce0" category="list-text">VMware vSphere のドキュメント</block>
  <block id="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link"><block ref="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link-rx"></block></block>
  <block id="71aa41fc980571d5a324adedae614f9c" category="paragraph"><block ref="71aa41fc980571d5a324adedae614f9c" category="inline-link-rx"></block></block>
  <block id="737c38dd225185612ac8fa148ae9583e" category="inline-link">Red Hat OpenStack Platform の Web サイト</block>
  <block id="19fb2090425be8f78441166e8f1d8d6f" category="paragraph">OSP の詳細については、を参照してください<block ref="9c79780f89511512bd5bf54ce21d04de" category="inline-link-rx"></block>。</block>
  <block id="f5fdcf6d68d437c59942a35d79b8c7b1" category="paragraph"><block ref="f5fdcf6d68d437c59942a35d79b8c7b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2ba7e785c49050f48da9aacc45c2b85" category="cell">サービス</block>
  <block id="2938c7f7e560ed972f8a4f68e80ff834" category="cell">ダッシュボード</block>
  <block id="85fb7708d989f936cb51ef53a8af080f" category="cell">地平線</block>
  <block id="d5a9efab6df20a9e132b774795775dde" category="cell">OpenStack サービスの管理に使用する Web ブラウザベースのダッシュボード。</block>
  <block id="c9c5c65fb4af9cf90eb99b3b84424189" category="cell">ID</block>
  <block id="1ce2096c300f78bbb8389ca2603e6dd9" category="cell">Keystone</block>
  <block id="91c68681aadba9c0e8308f7d0b3cc416" category="cell">OpenStack サービスの認証と許可、およびユーザ、プロジェクト、ロールの管理を一元化するサービスです。</block>
  <block id="88fac409baf592beb25e285d8663edcb" category="cell">中性子</block>
  <block id="0283e46fd80198d441eb742b88cf96f1" category="cell">OpenStack サービスのインターフェイス間の接続を提供します。</block>
  <block id="a7173cc5cdd0e31df00cd34f058b1d33" category="cell">Cinder の場合</block>
  <block id="597dab3a2b3c74e3c266b2f65ec28619" category="cell">仮想マシン（ VM ）の永続的なブロックストレージボリュームを管理します。</block>
  <block id="6e747c4965495f2e26bf17e647aa0083" category="cell">ノバ</block>
  <block id="f13c04e9c49274cd31bd8092c8f50304" category="cell">コンピューティングノードで実行されている VM を管理およびプロビジョニングします。</block>
  <block id="10ec3a0506fab7073649337ca7be7979" category="cell">Glance</block>
  <block id="d9ff71ddcb6bbbe8ad48ae8b678369d4" category="cell">VM イメージやボリューム Snapshot などのリソースを格納するためのレジストリサービス。</block>
  <block id="ae832e9b5bda2699db45f3fa6aa8c556" category="cell">Swift</block>
  <block id="41c380458dfcdc118ef573a2d98c6acb" category="cell">ユーザにファイルおよび任意のデータの格納および取得を許可します。</block>
  <block id="aa96a21412def0d916f43b639424f8e4" category="cell">テレメータ</block>
  <block id="8fb4b5e28f192236eaa9e4972f810dbd" category="cell">Ceilometer</block>
  <block id="ed622b9c64858cc66a01c58893b5d39d" category="cell">クラウドリソースの使用状況を測定できます。</block>
  <block id="7d486371bb65b0633535ceba4189d8ed" category="cell">熱</block>
  <block id="abaa6ebae60b74638c54a43f3341db8e" category="cell">リソーススタックの自動作成をサポートする、テンプレートベースのオーケストレーションエンジン。</block>
  <block id="5ddbd3cec63b14995bf6a5823b692de7" category="paragraph">NetApp 解決策を使用した Red Hat OpenShift では、 2 つのデータスイッチを使用して 25Gbps でプライマリデータ接続を提供します。また、ストレージノードのインバンド管理用に 1Gbps で接続を提供する管理スイッチをさらに 2 台使用し、 IPMI 機能のアウトオブバンド管理も行います。</block>
  <block id="c546b983b02d8654c5b245147d99dcf0" category="paragraph">ネットアップとともに Red Hat OpenShift を実装することで、仮想ローカルエリアネットワーク（ VLAN ）を使用してネットワークトラフィックを論理的に分離するように設計されています。この構成は、お客様のニーズに合わせて拡張することも、特定のネットワークサービスをさらに分離することもできます。次の表に、ネットアップで解決策を検証する際に解決策を実装するために必要な VLAN を示します。</block>
  <block id="414b4843c124e72b43bccf2948a53a41" category="cell">物理ノードの管理に使用するネットワークと、皮肉なことに IPMI サービス。</block>
  <block id="e8cbca2d71bd2aeff622a07b4ffad6c2" category="cell">Swift などのインフラサービスをサポートするためにボリュームを直接マッピングするためのコントローラノードのネットワーク。</block>
  <block id="757b505cfd34c64c85ca5b5690ee5293" category="cell">201</block>
  <block id="e103375dfc18f23e4fc072903e894fe9" category="cell">ストレージ Cinder</block>
  <block id="0bdfa6389eb47674a02f6049f342785d" category="cell">環境に導入された仮想インスタンスにブロックボリュームを直接マッピングして接続するためのネットワーク。</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202.</block>
  <block id="772d9a23b79ccb504fa0590644934c3b" category="cell">内部 API</block>
  <block id="e44f5f63400b0975b884dc2980ee3a61" category="cell">API 通信、 RPC メッセージ、データベース通信を使用する OpenStack サービス間の通信に使用するネットワーク。</block>
  <block id="34ed066df378efacc9b924ec161e7639" category="cell">301</block>
  <block id="6252d0571760e3d285e2e41a2b1e7743" category="cell">テナント</block>
  <block id="577bcc914f9e55d5e4e4f82f9f00e7d4" category="cell">302</block>
  <block id="cdc529b5e11a981e4597195c5f1c53b5" category="cell">OpenStack Object Storage （ Swift ）は、このネットワークを使用して、対象のレプリカノード間でデータオブジェクトを同期します。プロキシサービスは、ユーザ要求と基盤となるストレージレイヤの中間インターフェイスとして機能します。プロキシは受信要求を受信し、要求されたデータを取得するために必要なレプリカを検索します。</block>
  <block id="11b9842e0a271ff252c1903e7132cd68" category="cell">303</block>
  <block id="5214f1e2490f3878e307fd6f81f9f77f" category="cell">PXE</block>
  <block id="16d856c79e739181f35adfe5b791c650" category="cell">OpenStack Director は、 OSP Overcloud のインストールをオーケストレーションするための、皮肉なベアメタルプロビジョニングサービスの一部として PXE ブートを提供します。</block>
  <block id="966b6dfb6b0819cc10644bea3115cf20" category="cell">3484</block>
  <block id="b206a1b4ea1097761f78e8876f6da779" category="cell">外部</block>
  <block id="dfeb9598fbfb97cc6bbcc0aff2c785d6" category="cell">3485</block>
  <block id="32223320445c4cf46444e40ebde18b7e" category="cell">SSH アクセス、 DNS トラフィック、ネットワークタイムプロトコル（ NTP ）トラフィックなど、システム管理機能へのアクセスを提供します。このネットワークは、コントローラ以外のノードのゲートウェイとしても機能します。</block>
  <block id="ab4f2b5fd96ca65349119909c1eada2d" category="cell">3486</block>
  <block id="f2260a90424f1d412334d1b3467abd22" category="list-text">ホスト名の完全な解決を可能にする DNS サーバが少なくとも 1 つ必要です。</block>
  <block id="d70672769aa84f2a999291a645e67355" category="list-text">解決策内のサーバの時刻を同期できる NTP サーバが 3 台以上ある。</block>
  <block id="478a3526bd6097c6b7a330fd6aae410e" category="list-text">（オプション） OpenShift 環境でのアウトバウンドのインターネット接続。</block>
  <block id="9c0af999b760fac2aa82d9d105fa7a7e" category="paragraph">サーバグループには、配置を管理できる最大 10 個の仮想インスタンスがデフォルトで存在します。Nova のデフォルトクォータを更新することで変更できます。</block>
  <block id="8aea038e418642b1735131358c24a866" category="inline-link">OpenStack インスタンス用にアフィニティおよび非アフィニティを設定するにはどうすればよいですか？</block>
  <block id="47a822101acb11c74a4877a3d0b77093" category="inline-link">Red Hat OpenShift カスタマイズを使用した OpenStack へのクラスタのインストール</block>
  <block id="e38be1dc20a2b358b917b60fe2677b39" category="doc">NetApp Element iSCSI 構成</block>
  <block id="27ef1192cd037c8978195be045fa054e" category="list-text">エンドポイント行のユーザ、パスワード、および MVIP 値を編集します。</block>
  <block id="d1b7418d19df7144a98dfde725db068c" category="list-text">「仮想 IP 」の値を編集します。</block>
  <block id="3ae96676432caea17595a22525bd9660" category="admonition">このファイルに定義されているオプションのフィールド「 fsType 」があります。iSCSI バックエンドでは、この値を特定の Linux ファイルシステムタイプ（ XFS 、 ext4 など）に設定することも、 OpenShift が使用するファイルシステムを決定できるようにするために削除することもできます。</block>
  <block id="7183f006fd74d941c838f003380f3f46" category="list-text">oc` コマンドを実行して ' ストレージ・クラスを作成します</block>
  <block id="71cb54ab06aa16af27a0ec2157972648" category="list-text">ストレージクラスを作成したら、最初の永続的ボリューム要求（ PVC ）を作成する必要があります。sample_inputs にもあるこのアクションを実行するために使用できるサンプルの 'pvc-basicy.yaml ファイルがあります</block>
  <block id="afc499f2f95809cedce5c8922067065f" category="list-text">このファイルに対して行う必要がある唯一の編集は '`torageClassName` フィールドが作成したものと一致することを確認することですプロビジョニングするワークロードによって必要に応じて、 PVC 定義をさらにカスタマイズできます。</block>
  <block id="02eb9c3824b0b8eae9723daa7a2912d1" category="list-text">「 OC 」コマンドを発行して、 PVC を作成します。作成中の元のボリュームのサイズによっては作成にしばらく時間がかかることがあるため、作成が完了した時点でこのプロセスを監視できます。</block>
  <block id="9d312703c40c2d87b835076063682d59" category="paragraph">NetApp ONTAP は、わかりやすい GUI 、自動化統合機能を備えた REST API 、 AI に基づく予測分析と修正措置、無停止のハードウェアアップグレード、ストレージ間インポートなどの機能を備えた強力なストレージソフトウェアツールです。</block>
  <block id="48235fec2427a785c4a09d7150fc11fc" category="inline-link">ネットアップの ONTAP Web サイト</block>
  <block id="e65027864c84a42fc0799d878ffa0005" category="paragraph">NetApp ONTAP ストレージシステムの詳細については、を参照してください<block ref="be9464a7a83e639a645a801fff2791d9" category="inline-link-rx"></block>。</block>
  <block id="81bf516f5b38ea41d503a2670a9dc144" category="paragraph"><block ref="81bf516f5b38ea41d503a2670a9dc144" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a69e0f8303b40f9f4d56038d3d260c9" category="section-title">NetApp AFF/FAS</block>
  <block id="d4c312c600a949fb72436c2d10568a90" category="paragraph">どちらのシステムも、 NetApp ONTAP データ管理ソフトウェアを搭載しています。 NetApp は、可用性が高く、クラウドと統合されたシンプルなストレージ管理を実現する業界最先端のデータ管理ソフトウェアで、データファブリックのニーズに応じたエンタープライズクラスのスピード、効率性、セキュリティを提供します。</block>
  <block id="992c24be8f66e4259b38ce763c115251" category="paragraph">NetApp AFF / FAS プラットフォームの詳細については、をクリックしてください<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>。</block>
  <block id="b008e805d13d953ddb5cbb220d8ef9b6" category="paragraph">ONTAP Select は、お客様の環境のハイパーバイザーに導入できる、ソフトウェアで定義された NetApp ONTAP の導入です。VMware vSphere または KVM にインストールでき、ハードウェアベースの ONTAP システムの全機能とエクスペリエンスを提供します。</block>
  <block id="3f0bbee5abf3eed060d4147cb0d060b9" category="paragraph">ONTAP Select の詳細については、をクリックしてください<block ref="7c1424ed7be035c303f12b0763e38ece" category="inline-link-rx"></block>。</block>
  <block id="f0f4b6de2040d7dc57e7f4f6baee7ec3" category="paragraph">NetApp Cloud Volumes ONTAP は、クラウドで導入される NetApp ONTAP のバージョンで、 Amazon AWS 、 Microsoft Azure 、 Google Cloud などのさまざまなパブリッククラウドに導入できます。</block>
  <block id="c7fa0d52c3955385f084d0e67c59f963" category="paragraph">Cloud Volumes ONTAP の詳細については、をクリックしてください<block ref="75c9b0075008bbe40ac851ad7f6dda6a" category="inline-link-rx"></block>。</block>
  <block id="b2b7104a419a54dcb2763bddc6a0a47c" category="section-title">Red Hat OpenShift には次の機能があります。</block>
  <block id="ec55e5ffb2376dada4b2eb066c1fd9fd" category="section-title">Red Hat OpenShift の IPI インストール</block>
  <block id="a91a379e59fea6610134af1efa3dfe87" category="paragraph">OpenShift の Installer Provisioned Infrastructure （ IPI ）導入には、次の高度な手順が含まれます。</block>
  <block id="d1befa03c79ca0b84ecc488dea96bc68" category="inline-link">Web サイト</block>
  <block id="a07879007b1202a533ff3ef18bc0d197" category="list-text">Red Hat OpenShift をご覧ください<block ref="36af4d1b80928d398e137421c95a1013" category="inline-link-rx"></block> SSO クレデンシャルでログインします。</block>
  <block id="c9a2aa5906b4dad4a982c3a9c51d31f3" category="list-text">に従ってください<block ref="04512308a1627dc41acfeed51ef16ba3" category="inline-link-rx"></block> Red Hat が提供する、お客様の環境への導入サービスです。</block>
  <block id="aa9095c5ba77e3549672e5c4fae1fedc" category="inline-link-macro">ベアメタルで実装された OpenShift</block>
  <block id="fecab6277bc7322982f127ce83dee308" category="list-text"><block ref="fecab6277bc7322982f127ce83dee308" category="inline-link-macro-rx"></block></block>
  <block id="5f6a8f3661e7319797d4eab6792350e6" category="inline-link-macro">Red Hat OpenStack Platform 上の OpenShift</block>
  <block id="ff3de63c4917b45d20525986d5b29962" category="list-text"><block ref="ff3de63c4917b45d20525986d5b29962" category="inline-link-macro-rx"></block></block>
  <block id="f88eb30a75027b557910958c7306cb4e" category="inline-link-macro">Red Hat 仮想化を基盤とした OpenShift</block>
  <block id="92fb5c16a9f212d49c0c5fb48ebc9144" category="list-text"><block ref="92fb5c16a9f212d49c0c5fb48ebc9144" category="inline-link-macro-rx"></block></block>
  <block id="2772c11e552b243e60a34490c4174ff9" category="inline-link-macro">VMware vSphere 上の OpenShift</block>
  <block id="83fc4dbe543f82a9e50bc1bd4c74fb70" category="list-text"><block ref="83fc4dbe543f82a9e50bc1bd4c74fb70" category="inline-link-macro-rx"></block></block>
  <block id="3a374bfcdd912b5071f863e2b9f0eefa" category="list-text"><block ref="3a374bfcdd912b5071f863e2b9f0eefa" category="inline-link-macro-rx"></block></block>
  <block id="70b44fe3d3567f3f2a5ccd67ff8ac852" category="list-text"><block ref="70b44fe3d3567f3f2a5ccd67ff8ac852" category="inline-link-macro-rx"></block></block>
  <block id="eeaa3ef2816f113fd1978b036eefc4a4" category="doc">解決策の検証とユースケース：ネットアップを使用した Red Hat OpenShift</block>
  <block id="9e766e668731b912ea84be747f0d6b4b" category="paragraph">このページに記載する例は、ネットアップでの Red Hat OpenShift の解決策の検証と使用事例です。</block>
  <block id="6f60a8e202d6d4f297230695ffa9c1a6" category="inline-link-macro">永続的ストレージを使用した Jenkins CI/CD パイプラインの導入</block>
  <block id="20b131c747c2ab8c4c617107b04dfe76" category="list-text"><block ref="20b131c747c2ab8c4c617107b04dfe76" category="inline-link-macro-rx"></block></block>
  <block id="b830a759b7bbee23da50f11979fb8f27" category="doc">永続的ストレージを使用した Jenkins CI / CD パイプラインの導入：ネットアップでの Red Hat OpenShift</block>
  <block id="4d4480c77d84881f85763c51fb0a0ebb" category="doc">ビデオとデモ：ネットアップを使用した Red Hat OpenShift</block>
  <block id="051525dd6e814133d477a1812a4164c2" category="inline-link-macro">ビデオ： NetApp HCI for Red Hat OpenShift on Red Hat Virtualization Deployment</block>
  <block id="817cc3ec794caf508075034f1fa54315" category="list-text"><block ref="817cc3ec794caf508075034f1fa54315" category="inline-link-macro-rx"></block></block>
  <block id="92637d8d513510f7c1f5bfac6e1cce9b" category="paragraph">Trident を NetApp ONTAP ストレージシステムと統合するには、ストレージシステムとの通信を可能にするバックエンドを作成する必要があります。</block>
  <block id="3ca99f0e09d3b1ea097a113dd72c9317" category="list-text">ダウンロードしたインストールアーカイブのサンプルバックエンドファイルは、「 sample -input 」フォルダ階層にあります。iSCSI を提供している NetApp ONTAP システムの場合は、「 backend-ontap -san.json 」ファイルを作業ディレクトリにコピーし、ファイルを編集します。</block>
  <block id="fa346018b8222fdc195d0b73016cf5a0" category="list-text">このファイルで管理 LIF 、データ LIF 、 SVM 、ユーザ名、パスワードの値を編集します。</block>
  <block id="38ace6c607c7db13cd4cc319f9b0225b" category="list-text">このバックエンドファイルを設定した状態で、次のコマンドを実行して最初のバックエンドを作成します。</block>
  <block id="89441fb0b16307f49090afa2b479b9fa" category="list-text">ダウンロードしたインストールアーカイブのサンプルバックエンドファイルは、「 sample -input 」フォルダ階層にあります。NFS を提供している NetApp ONTAP システムの場合は、「 backend-ontap/nas.json 」ファイルを作業ディレクトリにコピーし、ファイルを編集します。</block>
  <block id="87f6ff6bf74013e1dfe6df49a1cf1986" category="list-text">backendName 、 managementLIF 、 dataLIF 、 SVM 、ユーザ名を編集します。 パスワードの値を入力します。</block>
  <block id="00d6947fd6a153943286b857dcd0f339" category="admonition">このファイルに定義されているオプションのフィールド「 fsType 」があります。この行は NFS バックエンドで削除できます。</block>
  <block id="254f642527b45bc260048e30704edb39" category="doc">設定</block>
  <block id="064dceba374668ef0734be5f9e182682" category="cell">* Cluster-admin*</block>
  <block id="e033ab3bea3b8a20afb5852070df0203" category="cell">Storage Admin 用の ClusterRoles および RoleBindings を作成します</block>
  <block id="293d08622718634a8518b6fcc6376617" category="cell">ロールとロールの作成特定のアクセス権を割り当てる開発者のためのバインド プロジェクト</block>
  <block id="3e97e469255cd3686174c371f50961f9" category="cell">[ オプション ] 特定のノードでポッドをスケジュールするようにプロジェクトを設定します</block>
  <block id="93ffd2b1215bc47cc78b020f89e922ef" category="cell">* ストレージ管理者 *</block>
  <block id="043ab42cdcbdacc4691c26ee52ed8ccd" category="cell">NetApp ONTAP に SVM を作成する</block>
  <block id="be09a24f118a66330a40633e9d5ebfca" category="cell">Trident バックエンドを作成</block>
  <block id="55995e8c220e05b3e75252cccf5752be" category="cell">ストレージクラスを作成します</block>
  <block id="4e00898ecc4e6640083ccff8d85fbe87" category="cell">* 開発者 *</block>
  <block id="67a3852a946bc539243cc1e5f8982d03" category="section-title">ベアメタル上の OpenShift には次の機能があります。</block>
  <block id="096e71732ebcd1f43544a7159596cb17" category="paragraph"><block ref="096e71732ebcd1f43544a7159596cb17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb18861dc375756df1a31b7ed3c03f38" category="paragraph"><block ref="bb18861dc375756df1a31b7ed3c03f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5a0639a1bbc3695e0ebaf4c3affe363" category="paragraph">ネットアップ解決策を使用した Red Hat OpenShift は、仮想ローカルエリアネットワーク（ VLAN ）を使用して、ネットワークトラフィックを論理的に分離するように設計されています。</block>
  <block id="3d9073c9e531118eb3aff0f20647c86f" category="cell">ベアメタルノードと IPMI の管理</block>
  <block id="44a94f76baabd05ab407f76c946326c8" category="cell">クラスタが使用可能になると、 OpenShift サービス用のネットワーク</block>
  <block id="846325c36d78e7582d8bfcab277ca67a" category="cell">Network for PXE boot and installation of bare metal nodes （ベアメタルノードの PXE ブートおよびインストール用ネットワーク IPI を使用</block>
  <block id="2d7e48e226974692ed3f522a2baef6db" category="paragraph">RHV 上の Red Hat OpenShift は、仮想ローカルエリアネットワーク（ VLAN ）を使用して、さまざまな目的でネットワークトラフィックを論理的に分離するように設計されています。この構成は、お客様のニーズに合わせて拡張することも、特定のネットワークサービスをさらに分離することもできます。次の表に、ネットアップで解決策を検証する際に解決策を実装するために必要な VLAN を示します。</block>
  <block id="3083202a936b7d0ef8b680d7ae73fa1a" category="cell">344</block>
  <block id="de4e964e7be880b328384cfedd5873d9" category="paragraph">このドキュメントで説明する検証済みのアーキテクチャは、 2 つの RHV-H ハイパーバイザーノードを導入し、ホスト型エンジンと導入済み VM を両方のホストで管理して 2 つのハイパーバイザー間で移行できるフォールトトレラントな構成を確保することによって、 HA 処理に適した最小限のハードウェア導入を示しています。</block>
  <block id="df1b58247681ba5f974a572d530dbdf9" category="paragraph">アフィニティとは、 VM やホストのセットに対してルールを定義する方法で、グループ内の同じホストで複数の VM が実行されるか、別々のホストで実行されるかを決定します。VM とホストで構成されるアフィニティグループを作成することで、 VM に適用されます。このアフィニティグループには同じパラメータと条件が設定されます。アフィニティグループ内の VM がグループ内の同じホストで実行されているのか、または別々のホストで実行されているのかに応じて、アフィニティグループのパラメータでは正のアフィニティまたは負のアフィニティを定義できます。</block>
  <block id="f38d8cd9caeb9a037c470b7d061392a0" category="paragraph">アフィニティグループを設定するには、を参照してください<block ref="eb1587f3cb611d53dba5bde41d49122a" category="inline-link-rx"></block>。</block>
  <block id="ff94444190436ee7694d15be2dde0f29" category="list-text">NetApp ONTAP ストレージクラスタ</block>
  <block id="b645e117fe786bf56128cde2dec3971a" category="list-text">Red Hat OpenShift クラスタ</block>
  <block id="0d46ef98dfe52c8d01c0c5ace93d8165" category="section-title">Red Hat OpenShift –クラスタリソース</block>
  <block id="3c73122271c9219b54ca745b732adc28" category="list-text">同様に、 project-2 の開発者ロールを作成します。</block>
  <block id="36e36b60ddb8f46fe0b9b4e8f4dce56f" category="list-text">ストレージ管理者用の ClusterRoleBindings を設定します。</block>
  <block id="ced38b1f1c19446862c601754b82b94c" category="list-text">ロールの作成 - developer-project-1 のロールを project-1 の対応するグループ (OCP-project-1) にバインドする開発者のバインディング。</block>
  <block id="2aa292f2ff8b13fe141ca55c27bc29c2" category="list-text">同様に、開発者の役割を project-2 の対応するユーザーグループにバインドする開発者の RoleBindings を作成します。</block>
  <block id="d008c60ddb28c0bbad1dfabdd77327fc" category="doc">設定：ストレージ管理者のタスク</block>
  <block id="3f8bc17bf8dd138aa2915235f0a9c0d3" category="image-alt">ONTAP での SVM の作成</block>
  <block id="4350d40426f8c94f6ca046609969adb2" category="list-text">同様に、 project-2 に対してストレージクラスを作成し、 project-2 に専用のバックエンドのストレージプールを使用するように設定します。</block>
  <block id="2ee847ebe129ae778860d6dd2da21cf6" category="list-text">ResourceQuota を作成して ' プロジェクト 1 内のリソースを制限し ' 他のプロジェクト専用のストレージを要求します</block>
  <block id="c689ae18a0f5e47541dcec4afb6e187a" category="list-text">同様に 'ResourceQuota を作成して 'project-2 内のリソースを制限し ' 他のプロジェクト専用のストレージを要求します</block>
  <block id="950496934d91d07bb089d6ed0999b5a9" category="paragraph">詳細または概要については、以下の概要ビデオをご覧ください。</block>
  <block id="b923f56ad2a53fa1a3ca1160e48f141e" category="section-title">AWX / タワー型の導入</block>
  <block id="ab81e47672e89830ec16c581f44cb23c" category="list-text">パート 1 ：はじめに、要件、自動化の詳細、 AWX/Tower の初期構成</block>
  <block id="cf7bbd18f18fdc73ee49ffea888126c7" category="list-text">パート 2 ：変数とプレイブックの実行</block>
  <block id="f5e227cfa54c5693c512c6adf41a3772" category="section-title">CLI の導入</block>
  <block id="0b8a09b5974336d1f5e510d18205c03c" category="list-text">パート 1 ：はじめに、要件、自動化の詳細、 Ansible Control Host Setup を確認する</block>
  <block id="c232cfc0ae9806d3ad6d34a51df58229" category="sidebar">ネットアップを利用した Red Hat OpenShift</block>
  <block id="cdc53c90644739ab9cb455ad8b663d7b" category="sidebar">Red Hat OpenShift の概要</block>
  <block id="f99e4eb05e28c150680cb72ca8410d93" category="sidebar">NetApp ONTAP を使用して Red Hat OpenShift にマルチテナンシーを設定します</block>
  <block id="51a25aff8c490f11d9be543c7af23a0d" category="sidebar">クラスタ管理者のタスク</block>
  <block id="244e9cd91466ef1240c125511568880a" category="sidebar">ストレージ管理者のタスク</block>
  <block id="bc967dc2d57e6eff184a821bf7577a80" category="sidebar">拡張性</block>
  <block id="0fd00a19fb12bb899dfe7cefbcbbcb79" category="inline-link">Red Hat OpenShift への NetApp Trident のインストール– Docker 「 toomanyrequests 」問題の解決方法</block>
  <block id="43e5d9153d1fc4a35be5f57189605919" category="list-text"><block ref="43e5d9153d1fc4a35be5f57189605919" category="inline-link-rx"></block></block>
  <block id="4b4d60be85b0c53c72ae4b8a05deacef" category="paragraph">ほとんどの Kubernetes ディストリビューションには、 Red Hat OpenShift など、デフォルトでインストールされる NFS バックエンドをマウントするパッケージとユーティリティが付属しています。</block>
  <block id="22f48c519a73ce4759edffb196331422" category="paragraph"><block ref="22f48c519a73ce4759edffb196331422" category="inline-image-macro-rx" type="image"></block></block>
  <block id="943dbb8750d636d9918af903ac016c0e" category="paragraph">ネットアップでは、 Red Hat OpenShift に導入されたアプリケーションのストレージプロビジョニング用に、ネットアップの Trident ストレージオーケストレーションツールで認定されているストレージプラットフォームを複数用意しています。</block>
  <block id="0186ffea1bd2c7ff6458a3a619d01ea2" category="paragraph"><block ref="0186ffea1bd2c7ff6458a3a619d01ea2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cc957c67b836ddc993931d8d2253032" category="paragraph">NetApp Cloud Volumes Service （ AWS / GCP ）と Azure NetApp Files は、クラウドでファイルベースのストレージを提供します。</block>
  <block id="faad8e024544c328d584c28118fb4102" category="paragraph">NetApp Element ストレージシステムは、拡張性に優れた環境でブロックベース（ iSCSI ）のユースケースに対応します。</block>
  <block id="85a240011ba49404bf70606e37c41c96" category="paragraph">以下のページでは、 Red Hat OpenShift with NetApp 解決策で検証されたネットアップストレージシステムに関する追加情報について説明します。</block>
  <block id="65cd53ff19e601ea00bf9688be4dd86a" category="summary">NetApp ONTAP を使用した Red Hat OpenShift Virtualization</block>
  <block id="ad3a2e9007d848afd0c15ffc402781bb" category="doc">ワークフロー： NetApp ONTAP を使用した Red Hat OpenShift Virtualization</block>
  <block id="55c7e45b50d0b012faf4bce31b6ad05d" category="section-title">Snapshot から VM を作成します</block>
  <block id="f991e1a54e399d272c7d968dcdfdb690" category="paragraph">OpenShift で Snapshot 処理を実行するには、リソース VolumeSnapshotClass 、 VolumeSnapshot 、および VolumeSnapshotContent を定義する必要があります。</block>
  <block id="0e2d1628ef03c4400cd293c3143cabb3" category="list-text">VolumeSnapshotContent は、クラスタ内のボリュームから作成された実際の Snapshot です。このデータストアは、 Storage 用の PersistentVolume に似た、クラスタ全体のリソースです。</block>
  <block id="8ca4876558d3675f7a3e2c452c62a215" category="list-text">ボリューム Snapshot は、ボリュームの Snapshot 作成要求です。これは、 PersistentVolumeClaim に似ています。</block>
  <block id="7f9fbed02a61699d31f7d9a0eb11bc81" category="list-text">VolumeSnapshotClass を使用すると、管理者はボリューム Snapshot のさまざまな属性を指定できます。これにより、同じボリュームから作成された異なる Snapshot に対して異なる属性を設定できます。</block>
  <block id="7f7858938c48bb9f08341c0e41c9162d" category="image-alt">Snapshot アーキテクチャの VM</block>
  <block id="99bf6e1ad41f7875d5b7ec9f857c4f0f" category="paragraph">VM の Snapshot を作成するには、次の手順を実行します。</block>
  <block id="52f0977d1e65469f01e2f290e637a8f1" category="list-text">スナップショットクラスの名前を入力し、ドライバの csi.trident.netapp.io を入力して、 Create をクリックします。</block>
  <block id="508073b07367d898823f1841627451d4" category="image-alt">Snapshot クラスを作成します</block>
  <block id="2bde7e02152796551174ea391bda0b60" category="list-text">ソース VM に接続されている PVC を特定し、その PVC の Snapshot を作成します。「ストレージ」＞「ボリュームスナップショット」と選択し、「ボリュームスナップショットの作成」をクリックします。</block>
  <block id="b9513caba1fba7b4291a9e22bc512de5" category="list-text">Snapshot を作成する PVC を選択し、 Snapshot の名前を入力するか、デフォルトを受け入れて、適切な VolumeSnapshotClass を選択します。[ 作成 ] をクリックします。</block>
  <block id="a7a384e6f13cae2ef877b4dd78fd48ad" category="image-alt">Snapshot を作成します</block>
  <block id="d8ae3e40f0f0dba0b7c7ba5b8eea845a" category="list-text">これにより、その時点で PVC のスナップショットが作成されます。</block>
  <block id="e9b3b34ca8f917d1968a106e682f1a97" category="section-title">スナップショットから新しい VM を作成します</block>
  <block id="5160cd070df38f982551c5fea6f1c844" category="list-text">新しい PVC の詳細を入力し、 Restore をクリックします。これにより、新しい PVC が作成されます。</block>
  <block id="0d695454ca10516a832452b6123c5bb5" category="image-alt">Snapshot を新しい PVC にリストアします</block>
  <block id="75b0d3500d81c7799a5b84eca57d6d04" category="list-text">Create をクリックして、新しい VM を作成します。</block>
  <block id="57dc3c96f32e4895e89eab4a248088f5" category="list-text">VM が正常に作成されたら、にアクセスして、新しい VM の状態が、スナップショット作成時に PVC を使用してスナップショットを作成した VM の状態と同じであることを確認します。</block>
  <block id="8bd534d3b6bc8d2541df052e053ed65d" category="section-title">Trident Operator を手動でインストールします</block>
  <block id="e32d70a13ba1767d9a373fe9a0535531" category="section-title">ワーカーノードをストレージ用に準備する</block>
  <block id="b09d268106fd9cbfffd1dc848382a150" category="section-title">ストレージシステムバックエンドを作成</block>
  <block id="7f3417590f5bba5cf5eb34fb288135f1" category="inline-link-macro">次：解決策の検証 / ユースケース：ネットアップを使用した Red Hat OpenShift 。</block>
  <block id="7a38916784a7216f98837f315958c175" category="paragraph"><block ref="7a38916784a7216f98837f315958c175" category="inline-link-macro-rx"></block></block>
  <block id="eed1ab12478f3384bfca66e2b382aefc" category="doc">NetApp ONTAP を使用して Red Hat OpenShift Virtualization を導入します</block>
  <block id="7dc3a10e876dbab2b177f35c0b436f3a" category="list-text">Red Hat OpenShift クラスタ（バージョン 4.6 以降） RHCOS ワーカーノードを使用するベアメタルインフラストラクチャにインストールします</block>
  <block id="b5762731ee8c7a3d9a7ce9abe3804cf0" category="list-text">OpenShift クラスタは、インストーラでプロビジョニングされたインフラを介してインストールする必要があります （ IPI ）</block>
  <block id="7ed0bc09bfa62b64806b6b5c2f4378c7" category="list-text">VM の HA を維持するには、マシンの健全性チェックを導入します</block>
  <block id="43b1ab0e04b8f87e603cc790967d2886" category="list-text">NetApp ONTAP クラスタ</block>
  <block id="d4c321b9edd8d817bdc7ca442e71e3af" category="list-text">ONTAP クラスタの SVM で設定された Trident バックエンド</block>
  <block id="cfcf3a62902e36f3d966271cc090b65c" category="list-text">Red Hat OpenShift クラスタへのクラスタ管理者アクセス</block>
  <block id="af91af16b4791d61bb2e9206807a658d" category="list-text">NetApp ONTAP クラスタへの管理者アクセス</block>
  <block id="e281839ef9ef6cb1eadcc2aa7d6d63be" category="list-text">tridentctl および OC ツールがインストールされている管理ワークステーション $PATH に追加されました</block>
  <block id="314f04ff1024e623d43e0cda9a9df410" category="paragraph">OpenShift Virtualization は、 OpenShift クラスタにインストールされたオペレータによって管理されるため、メモリ、 CPU 、およびストレージに追加のオーバーヘッドが発生します。このオーバーヘッドは、クラスタのハードウェア要件を計画する際に考慮する必要があります。のドキュメントを参照してください<block ref="f9421eaa4175c3e9f421a9acaf6f00d6" category="inline-link-rx"></block> 詳細：</block>
  <block id="be51a7d8687b0a6254a274c1e0100052" category="paragraph">ノード配置ルールを設定して、 OpenShift Virtualization オペレータ、コントローラ、 VM をホストする OpenShift クラスタノードのサブセットを指定することもできます。OpenShift Virtualization のノード配置ルールを設定するには、のドキュメントに従ってください<block ref="325820076f9012df5bb7261c397a527f" category="inline-link-rx"></block>。</block>
  <block id="a805b74dbb589c916a1ebf0e08601665" category="paragraph">OpenShift Virtualization を基盤とするストレージについては、特定の Trident バックエンドからストレージを要求する専用のストレージクラスを用意し、そのストレージクラスを専用の SVM でバックアップすることを推奨します。これにより、 OpenShift クラスタ上で VM ベースのワークロードに提供されるデータに関して、レベルのマルチテナンシーが維持されます。</block>
  <block id="adb787dc1bae0d1c8dee5bd61d49c235" category="inline-link-macro">次の例は、オペレータを介して導入します。</block>
  <block id="6166597c75dc82b2cc8c50a0d5d74400" category="paragraph"><block ref="6166597c75dc82b2cc8c50a0d5d74400" category="inline-link-macro-rx"></block></block>
  <block id="286c0d2f200233e63709210881b700c4" category="paragraph">前の手順で設定したマルチテナントアーキテクチャを検証するには、次の手順を実行します。</block>
  <block id="f4da6475fc7e97756adf2751840e077d" category="list-text">OCP-project-1-user として、 project-1 の開発者としてログインします。</block>
  <block id="2d7fbbcee3114769610fea6ef6f4cdf0" category="list-text">アクセス権をチェックして新しいプロジェクトを作成してください</block>
  <block id="145d2249af633a497182f76e714d1f2e" category="list-text">PVC に関連付けられている PV を確認します</block>
  <block id="d424ec829e7a6f56de4d74835b97103a" category="list-text">PV とそのボリュームが、 NetApp ONTAP 上のプロジェクト 1 専用の SVM に作成されていることを確認します。</block>
  <block id="7b929f9e235c85c6b73ed2ee867c5514" category="list-text">ポッドが実行中かどうか、およびボリュームがマウントされているかどうかを確認します。</block>
  <block id="1149bf04288dfa82d0e3b713a6e66aa1" category="list-text">PVC 「 test-pvc-project-1-sc-2 」および「 test-pvc-project-2-ssc-1 」が作成されていないことを確認します。</block>
  <block id="43700888cdcd166f379f95bd1751ae63" category="list-text">アクセス権をチェックして新しいプロジェクトを作成してください。</block>
  <block id="32579947c29f341292c3ce775140178b" category="list-text">アクセスを検証してプロジェクトを表示します</block>
  <block id="9e97a1398bb4a0499bb69bf1c9e67d6a" category="list-text">ユーザーがで ResourceQuotas を表示または編集できるかどうかを確認します プロジェクト 1</block>
  <block id="17a658c4329ed475a82d2e02c0406118" category="list-text">ユーザーがストレージクラスを表示するためのアクセス権を持っていることを確認します</block>
  <block id="aa177e49bfc4cc0182f57218ce6bdd4d" category="list-text">ストレージクラスについては ' アクセスを確認してください</block>
  <block id="997cef2cfb8ccc12d8739c63e69794f3" category="list-text">ストレージクラスを編集するためにユーザーのアクセス権を検証します</block>
  <block id="9eb6f7c0e27dd8274a30b43a4aee8d53" category="inline-link-macro">次のステップ：スケーリング</block>
  <block id="acd8a990c476bd6cb45a9044361ba723" category="paragraph"><block ref="acd8a990c476bd6cb45a9044361ba723" category="inline-link-macro-rx"></block></block>
  <block id="b8603f3d585261d0005c7c5e51108d19" category="paragraph">iSCSI ログインリダイレクトは、 NetApp Element ソフトウェアクラスタの重要な要素です。ホストログイン要求を受信すると、ノードは、 IOPS とボリュームの容量要件に基づいて、トラフィックを処理するクラスタのメンバーを決定します。ボリュームは NetApp Element ソフトウェアクラスタ全体に分散され、単一のノードがボリュームのトラフィックを大量に処理している場合や新しいノードが追加された場合に再配置されます。特定のボリュームの複数のコピーがアレイ全体に割り当てられます。</block>
  <block id="772db62cf9ecb837ed4f0a91a5963492" category="paragraph">この方法では、ノード障害のあとにボリュームの再配分が発生しても、ログアウトして新しい場所にリダイレクトしてログインした場合を超えてホスト接続には影響はありません。iSCSI ログインリダイレクションを使用する NetApp Element ソフトウェアクラスタは、無停止のアップグレードと運用が可能な自己回復型のスケールアウトアーキテクチャです。</block>
  <block id="0e4136a9f4ad3204c07db26d3c28a546" category="paragraph">マルチテナント構成でストレージリソースを使用する新しいプロジェクトを追加する場合、マルチテナンシーを違反しないように追加の設定が必要になります。マルチテナントクラスタでプロジェクトを追加するには、次の手順を実行します。</block>
  <block id="c8acb1fa89b1ec9d78799a2dd4aa8b59" category="list-text">NetApp ONTAP クラスタにストレージ管理者としてログインします。</block>
  <block id="d0ed0d7b81278233c852e4a0d8aa123b" category="list-text">「ストレージ -&gt; ストレージ VM 」に移動し、「追加」をクリックします。project-3 専用の新しい SVM を作成します。また、 SVM とそのリソースを管理するには vsadmin アカウントを作成します。</block>
  <block id="b0c67e9a89c7ece3169ab5849bb0e411" category="list-text">Red Hat OpenShift クラスタにクラスタ管理者としてログインします</block>
  <block id="46c82384780a492254c43d461363d9ac" category="list-text">project-3 の開発者ロールを作成します。</block>
  <block id="21ac9e9bbb2cfc707143311f4601af1c" category="admonition">ここで説明するロール定義は単なる例です。開発者ロールは、エンドユーザの要件に基づいて定義する必要があります。</block>
  <block id="2ca2d57f42208b6e7e9026b491595f41" category="list-text">Trident バックエンドを作成し、 project-3 専用の SVM にマッピングします。ONTAP クラスタ管理者を使用する代わりに、 SVM の vsadmin アカウントを使用してバックエンドを SVM に接続することを推奨します。</block>
  <block id="c4dcda95616fac9215b5dac3cde37220" category="admonition">この例では ONTAP と NAS のドライバを使用しています。ユースケースに基づいてバックエンドを作成するための適切なドライバを使用します。</block>
  <block id="8628ed29313534f54f01e0da36e66ab7" category="admonition">Trident が Trident プロジェクトにインストールされているとします。</block>
  <block id="1dea1d57247580b530335ec2d484f8a5" category="list-text">他のプロジェクトの ResourceQuotas にパッチを適用して ' プロジェクト内のリソースがプロジェクト 3 専用のストレージからストレージにアクセスするのを制限します</block>
  <block id="4e42a1e911325b5048e50f7b5ea73d1f" category="section-title">VM ライブマイグレーション</block>
  <block id="09e113cd46b4487f140ee07899ea3359" category="image-alt">VM ライブマイグレーションのアーキテクチャ</block>
  <block id="660b7fa756d01df7c4338afb9050abb1" category="paragraph">共有 ReadWriteAny アクセス権を持つ PVC にバインドされた VM を作成するには、次の手順を実行します。</block>
  <block id="416d6e9d0df33a74dd38603be60453c1" category="list-text">目的の OS を選択し、 Next （次へ）をクリックします。選択した OS には、すでに起動ソースが設定されているとしましょう。</block>
  <block id="e1b595d3037639bdea165dde4b1f3906" category="list-text">[Review and Create] ペインで、 VM を作成して VM の詳細を提供するプロジェクトを選択します。ブートソースがクローンとして選択されていることを確認し、選択した OS に適切な PVC が割り当てられた CD-ROM から起動します。</block>
  <block id="998a8df469c318f9cd606b44664cea5d" category="list-text">[ 仮想マシンのカスタマイズ ] をクリックし、 [ ストレージ ] をクリックします。</block>
  <block id="ef44ba6bf4a3e677b41b361628554b88" category="image-alt">ディスク RWX にアクセスできるようにします</block>
  <block id="2ae6b586f76075c7d71faff7ba9d2a41" category="list-text">[ 確認 ] をクリックして確定し、 [ 仮想マシンの作成 ] をクリックします。</block>
  <block id="18c830e61a7a92c60804118ef362933c" category="paragraph">OpenShift クラスタ内の別のノードに VM を手動で移行するには、次の手順を実行します。</block>
  <block id="cc58a226305ad2362de0317c1fd8261b" category="list-text">移行する VM の場合は、省略記号をクリックし、 Migrate the Virtual Machine （仮想マシンの移行）をクリックします。</block>
  <block id="b5839595a4132807edfc858d9f6d90ad" category="list-text">メッセージが表示されたら、 [ 移行 ] をクリックして確認します。</block>
  <block id="d0f501bd9588700bc91fe10b7d3f761a" category="admonition">OpenShift クラスタ内の VM インスタンスは、 evictionStrategy が LiveMigrate に設定されている場合、元のノードがメンテナンスモードになると、自動的に別のノードに移行します。</block>
  <block id="ca77161ad6ca11bca347f347b181c25f" category="inline-link-macro">次：ワークフロー： VM のクローニング</block>
  <block id="294f8e986041208286bb2300b191a2ff" category="paragraph"><block ref="294f8e986041208286bb2300b191a2ff" category="inline-link-macro-rx"></block></block>
  <block id="a181412a291a7d0ae8a71300abf746b8" category="section-title">本番環境の導入に関するベストプラクティス</block>
  <block id="bd690c49b77b8274786240fa94d9d880" category="section-title">少なくとも 3 つのボリュームからなる ESXi クラスタに OpenShift を導入します ノード</block>
  <block id="9dc31e1598f94b9476a025632cee3e19" category="section-title">仮想マシンとホストのアフィニティを設定します</block>
  <block id="ed3ecd4254cc054c70ddee702d7ed519" category="section-title">OpenShift 環境にカスタムインストールファイルを使用します</block>
  <block id="f5b3b6b5d5a71b2934abd61ddb561ce2" category="inline-link-macro">次：ネットアップストレージの概要</block>
  <block id="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="paragraph"><block ref="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="inline-link-macro-rx"></block></block>
  <block id="4711a0fd2fa3c3625080f399e5261ecd" category="paragraph">ネットアップ解決策を使用した Red Hat OpenShift は、次のユースケースでお客様に卓越した価値を提供するように設計されています。</block>
  <block id="aacc79f269e716528198eabb064b216b" category="inline-link-macro">次のレポートは、 Red Hat OpenShift の概要です</block>
  <block id="62857c2aca7eeae2c1f44104c3fc7dde" category="paragraph"><block ref="62857c2aca7eeae2c1f44104c3fc7dde" category="inline-link-macro-rx"></block></block>
  <block id="639813d9aa126816c3f9e9de2a45ce17" category="paragraph">OSP は、コンピューティング、ストレージ、ネットワークリソースを管理する一連の制御サービスによって実装される IaaS （インフラサービス）クラウドです。この環境の管理には Web ベースのインターフェイスを使用します。このインターフェイスを使用すると、管理者とユーザは OpenStack リソースの制御、プロビジョニング、自動化を行うことができます。さらに、 OpenStack インフラは、広範なコマンドラインインターフェイスと API を通じて管理者とエンドユーザにフルオートメーション機能を提供します。</block>
  <block id="e2ab8aafc6151adfa655ffd5d2425e7d" category="section-title">OpenStack サービス</block>
  <block id="9a14258452ea5da50d562e08e5b9291c" category="section-title">少なくとも 3 つのコンピューティングノードで構成された OSP プライベートクラウドに OpenShift を導入します。</block>
  <block id="7a595c63e0ebc069af3da46e3d1c8fee" category="section-title">仮想マシンとホストのアフィニティを設定します</block>
  <block id="d90e13a49726d9175649113d81f4caa7" category="paragraph">アフィニティグループを設定するには、を参照してください<block ref="f5b5be16184c5362a1ca218025e91581" category="inline-link-rx"></block>。</block>
  <block id="4e3f9a03501932f914205c4ad0e682ea" category="list-text">* NetApp FlexClone 。 * Snapshot コピーに基づいて、ネットアップボリュームの読み書き可能なフルコピーを瞬時にプロビジョニングできます。</block>
  <block id="96f474208f638efbbd85fac3a46a2ed4" category="paragraph">ONTAP の詳細については、を参照してください<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>。</block>
  <block id="e80842c9211bc376ee42d583c70ae408" category="section-title">ネットアップのプラットフォーム</block>
  <block id="14a9bacc4b197037f54eb0c4c7e1970c" category="paragraph">そのため、組織は、たとえば、すべてのワークロードを単一のクラスタで実行しながら、各ワークロードに専用のクラスタのメリットを提供することで、両方の世界で最も優れたソリューションを見つけることができます。</block>
  <block id="cde9f9f8fcae0cdc6624895868803d60" category="list-text">クラスタリソースを許可することで設備投資と運用コストを削減 を共有します</block>
  <block id="943a49720e6c85fa9692af2a5ebd8829" category="list-text">運用と管理のオーバーヘッドを軽減</block>
  <block id="f51a58b3ab19c778652fcff9dd39ca55" category="list-text">セキュリティ侵害のクロスコンタミネーションからワークロードを保護</block>
  <block id="181cfddfdb055879df4d55323a14c473" category="list-text">リソースの競合による予期しないパフォーマンスの低下からワークロードを保護</block>
  <block id="d463f48696e58e286e9c0d594169b395" category="inline-link-macro">次の例は、アーキテクチャです</block>
  <block id="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="paragraph"><block ref="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="inline-link-macro-rx"></block></block>
  <block id="482f4dddd14a12f4ece48aef54de313c" category="summary">Red Hat OpenShift Container Platform は、開発と IT の運用を単一のプラットフォーム上に統合し、オンプレミスとハイブリッドクラウドのインフラ全体でアプリケーションを一貫して構築、導入、管理します。Red Hat OpenShift は、コンテナベースのワークロード向けに設計された、世界をリードするエンタープライズ Linux ディストリビューションである Kubernetes や Red Hat Enterprise Linux CoreOS など、オープンソースのイノベーションと業界標準に基づいて構築されています。</block>
  <block id="e68e90b5707502c9f2fc1361ac071b3d" category="paragraph">Red Hat OpenShift Container Platform は、開発と IT の運用を単一のプラットフォーム上に統合し、オンプレミスとハイブリッドクラウドのインフラ全体でアプリケーションを一貫して構築、導入、管理します。Red Hat OpenShift は、コンテナベースのワークロード向けに設計された、世界をリードするエンタープライズ Linux ディストリビューションである Kubernetes や Red Hat Enterprise Linux CoreOS など、オープンソースのイノベーションと業界標準に基づいて構築されています。OpenShift は Cloud Native Computing Foundation （ CNCF ）認定 Kubernetes プログラムの一部であり、コンテナワークロードの移植性と相互運用性を提供します。</block>
  <block id="d383250f88949df87bac7768b697ccb6" category="list-text">* セルフサービスプロビジョニング * 開発者は、最も多くのツールを使用して、必要に応じてアプリケーションをすばやく簡単に作成できます。また、運用環境全体を完全に制御できます。</block>
  <block id="df45d857ed72e8e5ed370c6fdfd1e305" category="list-text">* 永続的ストレージ。 * 永続的ストレージをサポートすることにより、 OpenShift Container Platform はステートフルアプリケーションとクラウドネイティブステートレスアプリケーションの両方を実行できます。</block>
  <block id="29ee9790b817110f2303080d5b295946" category="list-text">* 継続的統合および継続的開発（ CI / CD ）。 * このソースコードプラットフォームは、大規模なビルドおよび展開イメージを管理します。</block>
  <block id="a0f0997dded25d9aa9c767f29c17c249" category="list-text">* オープンソース標準 * これらの標準は、オープンソース・テクノロジに加えて、コンテナオーケストレーションのための Open Container Initiative （ OCI ）および Kubernetes を組み込みます。お客様は、特定のベンダーのテクノロジやビジネスロードマップに制限されることはありません。</block>
  <block id="7dc3d12ecda66373091607ba18ef4434" category="list-text">* CI/CD パイプライン * OpenShift は、 CI/CD パイプラインをすぐに使用できるサポートを提供します。これにより、開発チームはアプリケーション配信プロセスのすべてのステップを自動化し、アプリケーションのコードまたは構成に加えられたすべての変更に対して実行することができます。</block>
  <block id="95e4c6a8e27cc92068d97ef795477714" category="list-text">* 役割ベースのアクセス制御 (RBAC) 。 * この機能は、大規模な開発者グループの編成を支援するチームとユーザーの追跡を提供します。</block>
  <block id="d565eddf8e07af916519ec07f8712204" category="list-text">* ビルドとデプロイを自動化。 * OpenShift により、開発者はコンテナ化されたアプリケーションを構築することも、プラットフォームでアプリケーションソースコードやバイナリからコンテナを構築することもできます。プラットフォームは、アプリケーションに定義された特性に基づいて、これらのアプリケーションのインフラストラクチャへの導入を自動化します。たとえば、割り当てられるリソースの量や、サードパーティのライセンスに準拠するために導入するインフラストラクチャ上の場所などです。</block>
  <block id="4fe0bdfd5a2ae34ba1a93860fd91d2fd" category="list-text">* 一貫性のある環境。 * OpenShift により、開発者やアプリケーションのライフサイクル全体でプロビジョニングされた環境が、オペレーティングシステムからライブラリ、ランタイムバージョン（ Java ランタイムなど）まで一貫していることを確認します。 また、一貫性のない環境から発生したリスクを除去するために、使用中のアプリケーションランタイム（ Tomcat など）も削除できます。</block>
  <block id="64f8957eb1a3bb6a1e9ebd391e76925a" category="list-text">* 構成管理。 * 構成と機密性の高いデータ管理はプラットフォームに組み込まれており、アプリケーションの構築に使用されるテクノロジーや導入される環境に関係なく、一貫性のある、環境に依存しないアプリケーション構成がアプリケーションに確実に提供されるようにします。</block>
  <block id="5efb308bdb8052c1aa3fe8333f459fe5" category="list-text">* アプリケーションログとメトリック。 * 迅速なフィードバックは、アプリケーション開発の重要な要素です。OpenShift に統合された監視機能とログ管理機能により、開発者はアプリケーションがどのように変化しても動作しているかを調査し、アプリケーションのライフサイクルの早い段階で問題を修正できるようになります。</block>
  <block id="fe8c2f8039053e077a0ca678496b72aa" category="section-title">Red Hat OpenShift の導入方法</block>
  <block id="220887aee59c37fa79fc366cba7dad4e" category="section-title">ネットアップが検証済みの OpenShift 環境</block>
  <block id="e85b6a5686bf01c916e1c3b442e8db44" category="inline-link-macro">ネットアップを使用して Red Hat OpenShift でマルチテナンシーを構成します</block>
  <block id="29a3155f4e27ac61f0e6d1e00866c981" category="list-text"><block ref="29a3155f4e27ac61f0e6d1e00866c981" category="inline-link-macro-rx"></block></block>
  <block id="781cf19a6329e508987456098cde8c79" category="list-text"><block ref="781cf19a6329e508987456098cde8c79" category="inline-link-macro-rx"></block></block>
  <block id="0b41ceffa053ec5210732b1f8d0f0c5d" category="inline-link-macro">次は、ビデオとデモです</block>
  <block id="232b127190e97018e70ee81d28e36117" category="paragraph"><block ref="232b127190e97018e70ee81d28e36117" category="inline-link-macro-rx"></block></block>
  <block id="3a724344bfc1b086a678d66814f20dd7" category="summary">このセクションでは、継続的インテグレーション、継続的デリバリー、またはデプロイメントパイプラインを Jenkins で展開し、解決策の動作を検証する手順について説明します。</block>
  <block id="ff587ce314d6f90660779e9d75cafe53" category="paragraph">このセクションでは、 Jenkins との継続的統合 / 継続的配信または導入（ CI / CD ）パイプラインを導入して解決策の動作を検証する手順について説明します。</block>
  <block id="9eb8af4dd2c3557a24b914601b6ae465" category="section-title">Jenkins の導入に必要なリソースを作成します</block>
  <block id="6baa4bd25992de2d17278ade0d3090ad" category="list-text">「テンプレートをインスタンス化」をクリックします。</block>
  <block id="c7b4a6da6ab2733552de61d67b38a39e" category="list-text">デフォルトでは、 Jenkins アプリケーションの詳細が入力されます。要件に基づいてパラメータを変更し、 [ 作成（ Create ） ] をクリックします。このプロセスでは、 OpenShift で Jenkins をサポートするために必要なリソースがすべて作成されます。</block>
  <block id="f913f3c8b073438c23eb36c9cf8237ac" category="section-title">VM を作成します</block>
  <block id="71dd19ec5a595517b0b57750ad1a6568" category="paragraph">VM は、オペレーティングシステムとデータをホストするボリュームを必要とするステートフルな導入です。CNV では、 VM がポッドとして実行されるため、 VM は Trident 経由で NetApp ONTAP にホストされた PVS によってバックアップされます。これらのボリュームはディスクとして接続され、 VM のブートソースを含むファイルシステム全体が格納されます。</block>
  <block id="e01cb9126428f7417091e42362dcb6cb" category="image-alt">VM アーキテクチャを作成する</block>
  <block id="51f24796fdd958a7a4ab9fb9a1086c9a" category="paragraph">OpenShift クラスタ上に仮想マシンを作成するには、次の手順を実行します。</block>
  <block id="9b992d4161d9af3e77a9c4e35f9d7652" category="image-alt">VM のブートソースを作成します</block>
  <block id="fe46fcd3bb2eadd55896f6a4e9af5b05" category="list-text">選択したオペレーティングシステムにすでにブートソースが設定されている場合は、前の手順を省略できます。</block>
  <block id="c119644bb97e69cc47555d48ff5ead07" category="list-text">仮想マシンをカスタマイズする場合は、 [ 仮想マシンのカスタマイズ ] をクリックし、必要なパラメータを変更します。</block>
  <block id="8b2c60e63de0927cca5bd9401cdd4647" category="list-text">[ 仮想マシンの作成 ] をクリックして仮想マシンを作成します。これにより、対応するポッドがバックグラウンドでスピンアップされます。</block>
  <block id="ba7734e1db4ae3c0a25330f01ced054d" category="paragraph">ブート・ソースが URL またはレジストリからテンプレートまたはオペレーティング・システム用に構成されている場合 'OpenShift Virtualization-os-images' プロジェクトに PVC を作成し 'KVM ゲスト・イメージを PVC にダウンロードしますテンプレート PVC に、対応する OS の KVM ゲストイメージを格納できるだけの十分なプロビジョニングスペースがあることを確認する必要があります。これらの PVC は、任意のプロジェクトでそれぞれのテンプレートを使用して作成されると、クローン作成され、ルートディスクとして仮想マシンに接続されます。</block>
  <block id="2188a3011c4ccaa5490bcaca14a05579" category="inline-link-macro">次のワークフロー： VM のライブマイグレーション</block>
  <block id="a997d50e238a53b066824f32046c10ab" category="paragraph"><block ref="a997d50e238a53b066824f32046c10ab" category="inline-link-macro-rx"></block></block>
  <block id="f64f81d4393ab1fc9545c35c8eb9f74d" category="paragraph">次のビデオでは、このドキュメントに記載されている機能の一部を紹介します。</block>
  <block id="5e217c79c499978721e658f868053d3f" category="inline-link-macro">次のレポート：追加情報：ネットアップでの Red Hat OpenShift</block>
  <block id="d2fb587a433995783f0688b22359272d" category="paragraph"><block ref="d2fb587a433995783f0688b22359272d" category="inline-link-macro-rx"></block></block>
  <block id="8e0bd613649f232fe1f718134898ea21" category="paragraph">Trident を NetApp ONTAP ストレージシステムと統合するには、ストレージシステムとの通信を可能にするバックエンドを作成する必要があります。</block>
  <block id="44b1200b793638d4a3aebd1bee591e12" category="paragraph">マルチテナント解決策では、必要以上に多くのクラスタリソースにアクセスすることはできません。つまり、マルチテナンシー構成の一部として構成するリソースセット全体が、クラスタ管理者、ストレージ管理者、および各プロジェクトに取り組む開発者に分けられます。</block>
  <block id="1ceba10f8902735a18e8c3bb3e8a3052" category="paragraph">次の表に、各ユーザが実行する各タスクを示します。</block>
  <block id="2a5eb41b2d7fd04d01836f89ab790852" category="cell">ストレージリソースクォータを作成します</block>
  <block id="4edd9914739183e9cb724a222261a01f" category="inline-link-macro">次の手順：前提条件</block>
  <block id="8013a47a037d25fa6d9671120cfc1ee5" category="paragraph"><block ref="8013a47a037d25fa6d9671120cfc1ee5" category="inline-link-macro-rx"></block></block>
  <block id="2c65eb4e4300c763b9d8ffcdc45660fc" category="paragraph">OpenShift Virtualization をインストールするには、次の手順を実行します。</block>
  <block id="bb761e1ed8ef4412cddb399e81488f83" category="list-text">クラスタ管理者アクセス権を持つ Red Hat OpenShift ベアメタルクラスタにログインします。</block>
  <block id="3f4b86cf3e8a535371d3937bd126d789" category="list-text">Perspective ドロップダウンから Administrator を選択します。</block>
  <block id="78146e6a44100deebbe276c19e6c437a" category="image-alt">OpenShift Operator Hub</block>
  <block id="016a229c1180d24870be44f7391c5678" category="list-text">OpenShift Virtualization タイルを選択し、 Install をクリックします。</block>
  <block id="fe87c9ebb6d1db5af643c2101dd83c2d" category="image-alt">OpenShift Virtualization Operator Tile を使用します</block>
  <block id="d2770f20a312c7d906cf3d8a97d335a2" category="list-text">Install Operator （オペレータのインストール）画面で、デフォルトのパラメータをすべてそのままにして、 Install （インストール）をクリックします。</block>
  <block id="66b5ae84d6c0a470bb131b7aeb63f734" category="image-alt">OpenShift Virtualization Operator Details （ OpenShift 仮想化オペレータ詳細</block>
  <block id="11458c333e4903e54ca46f822ba6a3b6" category="list-text">オペレータによるインストールが完了するまで待ちます。</block>
  <block id="5f27d84a5a158e75ab7ac4543ca7c1be" category="image-alt">OpenShift Virtualization Operator インストール</block>
  <block id="49598c5badb95e31a9894d5dc277f301" category="list-text">オペレータがインストールされたら、 Create HyperConverged をクリックします。</block>
  <block id="f63ea68253a91a92e8afb2e42bf0fb36" category="image-alt">OpenShift Virtualization Operator - ハイパーコンバージドを作成</block>
  <block id="0e4308133099865567bc6a19f0abcb88" category="list-text">[Create HyperConverged ( ハイパーコンバージドの作成 )] 画面で、 [Create ( 作成 )] をクリックし、すべてのデフォルトパラメータを受け入れます。このステップでは、 OpenShift Virtualization のインストールを開始します。</block>
  <block id="c57b56755457ec355801b1e17915fc47" category="image-alt">OpenShift Virtualization Operator - ハイパーコンバージドの詳細</block>
  <block id="ee0ffac6ee8f4e224a044d95e68aa30d" category="list-text">OpenShift CNV ネームスペースですべてのポッドが running 状態に移行し、 OpenShift Virtualization オペレータが Succeeded 状態になると、オペレータは使用可能な状態になります。これで、 OpenShift クラスタで VM を作成できるようになります。</block>
  <block id="423e88e20ace3dbca3f9d5bd3b109cef" category="image-alt">OpenShift Virtualization Operator のインストールが完了しました</block>
  <block id="46af5002087f682df1feb9b3339d1f68" category="inline-link-macro">次の手順：ワークフロー： VM を作成します。</block>
  <block id="066b9e10038ca1d47643166f151f910c" category="paragraph"><block ref="066b9e10038ca1d47643166f151f910c" category="inline-link-macro-rx"></block></block>
  <block id="7e4be32047fe5b09a23fd956cd4e82f0" category="section-title">少なくとも 3 つの RHV クラスタに OpenShift を導入します ノード</block>
  <block id="b98f17dd49fc6d1c2a9b58922fae2686" category="paragraph">VM とホストのアフィニティを有効にすると、 OpenShift マスターを複数のハイパーバイザーノードに分散できます。</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">テクノロジ要件</block>
  <block id="c4ff2177ae2f8ed9c3e5353068cf2195" category="section-title">Red Hat OpenShift –ストレージリソース</block>
  <block id="6c7eefdca8e3859011afa00995879a32" category="inline-link-macro">次へ：設定</block>
  <block id="0c86c0f2c0ad5b82864ef1b20a904132" category="paragraph"><block ref="0c86c0f2c0ad5b82864ef1b20a904132" category="inline-link-macro-rx"></block></block>
  <block id="7652dcfa1608f7891f4e5c9b462354be" category="paragraph">この課題に対処するために、 Red Hat は OpenShift バージョン 4.6 から始まる OpenShift Virtualization （以前のコンテナネイティブ仮想化）を導入しました。OpenShift Virtualization 機能を使用すると、同じ OpenShift Container Platform インストール上でコンテナとともに仮想マシンを実行および管理できるため、オペレータを介して VM の導入と管理を自動化するハイブリッド管理機能が提供されます。OpenShift Virtualization では、 OpenShift で VM を作成するだけでなく、 VMware vSphere 、 Red Hat Virtualization 、 Red Hat OpenStack Platform の各環境からの VM のインポートもサポートします。</block>
  <block id="269bac1ed5128eacc45c06318333642a" category="image-alt">OpenShift 仮想化</block>
  <block id="8a5bcb32f7cb878beee68d6f84b3ada7" category="paragraph">Red Hat OpenShift Virtualization の詳細については、のドキュメントを参照してください<block ref="3339eb5909b80aa35681f9f3f9478c17" category="inline-link-rx"></block>。</block>
  <block id="2bd77ae4e72f37c837a2da8cfa83e210" category="inline-link-macro">次の手順：導入の前提条件</block>
  <block id="3a86ddb85761278fa813d15edecbc2b1" category="paragraph"><block ref="3a86ddb85761278fa813d15edecbc2b1" category="inline-link-macro-rx"></block></block>
  <block id="ad8905a47eb465223ebe7acf569732b1" category="doc">Configuration ：クラスタ管理者のタスク</block>
  <block id="552eab1d1ea09d0d1733b97dee6609a1" category="paragraph">Red Hat OpenShift cluster-admin によって次のタスクが実行されます。</block>
  <block id="8a4ffd494b5e8af3ac1be2cd9ab254fb" category="list-text">Red Hat OpenShift クラスタに cluster-admin としてログインします。</block>
  <block id="7ccd4d72e4addf5c27c53bafaeb3fdbd" category="list-text">異なるプロジェクトに対応する 2 つのプロジェクトを作成します。</block>
  <block id="6c98bfb16f2e9bbebd943c1f8592306d" category="list-text">project-1 の開発者ロールを作成します。</block>
  <block id="7428df2e0e503f4cabb43a4667bc1983" category="list-text">すべての OpenShift およびネットアップストレージリソースは、通常はストレージ管理者が管理します。ストレージ管理者向けのアクセスは、 Trident のインストール時に作成された Trident オペレータロールによって制御されます。これに加えて、ストレージ管理者は ResourceQuotas にアクセスして、ストレージの消費方法を制御する必要があります。</block>
  <block id="7d03daab3e74958fc08ebc0c90e0a6a2" category="inline-link-macro">次：ストレージ管理者のタスク</block>
  <block id="f3d9bb76442ab5c11e6af4dd328b2559" category="paragraph"><block ref="f3d9bb76442ab5c11e6af4dd328b2559" category="inline-link-macro-rx"></block></block>
  <block id="6c0ed744c737f30af364d229639c8288" category="paragraph">ストレージ管理者が次のリソースを設定する必要があります。</block>
  <block id="64244866ddff81ded5e6aaa49055c6aa" category="list-text">NetApp ONTAP クラスタに admin としてログインします。</block>
  <block id="c9bd46366e9fb78552566f1e7a13633a" category="list-text">project-1 のバックエンドを作成し、プロジェクト専用の SVM にマッピングします。ONTAP クラスタ管理者を使用する代わりに、 SVM の vsadmin アカウントを使用してバックエンドを SVM に接続することを推奨します。</block>
  <block id="4a6c648106c1ff38316705bf986de601" category="list-text">同様に、 project-2 の Trident バックエンドを作成し、 project-2 に専用の SVM にマッピングします。</block>
  <block id="9a45d41277a2e8ce29709826a31fb482" category="list-text">次に、ストレージクラスを作成します。StoragePools パラメータを設定して、 project-1 専用のバックエンドのストレージプールを使用するように project-1 のストレージクラスを作成し、これを設定します。</block>
  <block id="7f9ddc8224f28e1481299160807c876d" category="inline-link-macro">次のステップ：検証</block>
  <block id="93a1440c4dcba82f234a9305a9445144" category="paragraph"><block ref="93a1440c4dcba82f234a9305a9445144" category="inline-link-macro-rx"></block></block>
  <block id="b917a2bfe0dd0160c3ad88751f355f5d" category="inline-link-macro">次：クラスタ管理者のタスク</block>
  <block id="7a9f102fda0e3438bff54da4acdbccbb" category="paragraph"><block ref="7a9f102fda0e3438bff54da4acdbccbb" category="inline-link-macro-rx"></block></block>
  <block id="4b6826f4f20a8e7e7a3b42ccb81d514f" category="section-title">VM のクローニング</block>
  <block id="0ea820e58acf3d0c3acac3f64518c517" category="image-alt">VM クローニングアーキテクチャ</block>
  <block id="a1dbf280b3b5da141010127710d68ba7" category="paragraph">CSI ボリュームクローニングには、次のような一定の制限事項があります。</block>
  <block id="7f8cb9ac957166d3d134bf9df8861f5b" category="list-text">送信元 PVC と宛先 PVC は同じプロジェクト内に存在する必要があります。</block>
  <block id="058d8141e417cb514573ba1a70e2e0cd" category="list-text">クローニングは、同じストレージクラス内でサポートされます。</block>
  <block id="611b1b227968093cc5c73e69f7ac0fda" category="list-text">クローニングを実行できるのは、ソースボリュームとデスティネーションボリュームで同じボリュームモード設定を使用している場合のみです。たとえば、ブロックボリュームは別のブロックボリュームにしかクローニングできません。</block>
  <block id="557d036c1a69ab0889c0820deb1e88de" category="paragraph">OpenShift クラスタ内の VM は、次の 2 つの方法でクローニングできます。</block>
  <block id="e1230e5b1f51d793ea14fb31df500399" category="list-text">ソース VM をシャットダウンします</block>
  <block id="29ec5d7b455e19c4f8141df877a9af0a" category="list-text">ソース VM を稼働させます</block>
  <block id="84d19f7437a8329c49099517eccd37dc" category="section-title">ソース VM をシャットダウンします</block>
  <block id="375000776ee4694734b1d066c46e7096" category="list-text">Clone Virtual Machine をクリックして、新しい VM の詳細を指定します。</block>
  <block id="b22c43b0906ef8ba78f3fbb7d5b1ff20" category="image-alt">VM をクローニングする</block>
  <block id="cf702a835a3fd4b019603d29ec402106" category="list-text">Clone Virtual Machine をクリックします。これにより、ソース VM がシャットダウンされ、クローン VM の作成が開始されます。</block>
  <block id="82cfb538b52ee01d4a9901d4d2cfad4d" category="list-text">この手順が完了すると、クローニングした VM のコンテンツにアクセスして確認できるようになります。</block>
  <block id="3c7aa222cd4c9ee079b31567a347c05f" category="paragraph">既存の VM は、ソース VM の既存の PVC をクローニングしてから、クローン PVC を使用して新しい VM を作成することによってもクローニングできます。この方法では、ソース VM をシャットダウンする必要はありません。シャットダウンせずに VM をクローニングするには、次の手順を実行します。</block>
  <block id="545ce69617c1c157be6073dcc63bfbae" category="list-text">Clone PVC をクリックして、新しい PVC の詳細を提供します。</block>
  <block id="e659422cf737778a2fb1cdd50cc8003e" category="image-alt">PVC を複製します</block>
  <block id="07c24ffdbaf9583216cca9f030058c11" category="list-text">次に、 Clone をクリックします。これにより、新しい VM の PVC が作成されます。</block>
  <block id="19e005e0709674157e554800d5ea7ef9" category="list-text">VM が作成されたら、にアクセスし、新しい VM がソース VM のクローンであることを確認します。</block>
  <block id="fdbfc131399a8776fecd30fa821de4d0" category="inline-link-macro">次：ワークフロー： Snapshot から VM を作成します。</block>
  <block id="c5c4205f35e83d4dc33cfa7821ceb5a7" category="paragraph"><block ref="c5c4205f35e83d4dc33cfa7821ceb5a7" category="inline-link-macro-rx"></block></block>
  <block id="b1c770f25b823d4453567c0ff9d7cf67" category="summary">このページでは、 VMware vSphere 環境に NetApp ONTAP NFS バージョン 3 データストアを導入する手順を説明します。</block>
  <block id="168dbfe414d4d4089585360152953a57" category="doc">vSphere NFS データストア - バージョン 3 と ONTAP</block>
  <block id="bbe48fb854ea022537208eeeff822f91" category="section-title">このタスクについて</block>
  <block id="2be27a78c84ba5629cd9f2c22983240a" category="paragraph">ONTAP NAS ストレージを使用した NFS バージョン 3 データストアの作成。</block>
  <block id="1563a554e82b055714efd37bc6d1fdd6" category="paragraph">自動プロビジョニングの場合は、次のいずれかのスクリプトを使用します。 <block ref="a45ba722ee80832fb205d0588df91e01" category="inline-xref-macro-rx"></block>、 <block ref="d9559d06f0afa5b213d78afb48b783e7" category="inline-xref-macro-rx"></block>または <block ref="e5e7d2f44064f3bfeddfdbea251f7835" category="inline-xref-macro-rx"></block>。</block>
  <block id="6ac65708de8f04eeb173ca99f3eb19fa" category="section-title">必要なもの</block>
  <block id="106a118b8a267220cb2c40a4bb68b684" category="list-text">vSphere 環境と ONTAP を管理するために必要な基本スキル。</block>
  <block id="00c46d0ea9cdf9a5a37b8af04896741f" category="list-text">ONTAP ストレージシステム（ FAS / AFF / CVO / ONTAP Select / Cloud Volume Service / Azure NetApp Files ） ONTAP 9.8 以降を実行している</block>
  <block id="d5ba6255ccf331629f7b1b4598223d33" category="list-text">ONTAP クレデンシャル（ SVM 名、ユーザ ID 、パスワード）</block>
  <block id="190ba592a6988abfd7566be9b5c8217a" category="list-text">NFS の ONTAP ネットワークポート、 SVM 、および LUN の情報</block>
  <block id="d5cb637f6500cfa77d4190ebdfd8cce0" category="inline-link-macro">完了した NFS 設定ワークシート</block>
  <block id="915142cb27ebec8265b54739a95840b5" category="list-text"><block ref="915142cb27ebec8265b54739a95840b5" category="inline-link-macro-rx"></block></block>
  <block id="24c066a87410cc7b08ad4b5ca45565d7" category="list-text">vCenter Server クレデンシャル</block>
  <block id="a9ab6317871b5547fc7bf0dd22151f00" category="list-text">vSphere 7.0 以降の vSphere ホスト情報</block>
  <block id="d7850596008b347e3797ad7dcb7252e5" category="list-text">NFS VMkernel アダプタの IP 情報</block>
  <block id="9068992a529de63b07b7c2250be12f87" category="list-text">ネットワークスイッチ</block>
  <block id="0675fa9a38b420775f29ec7a62d9a8a0" category="list-text">ONTAP システムのネットワークデータポートと接続された vSphere ホストで使用</block>
  <block id="a7fb6a7233e9c40554334921be362af1" category="list-text">NFS 用に設定されている VLAN</block>
  <block id="44786c36009327ad04469602f3f96832" category="list-text">（任意） ONTAP ネットワークデータポート用に設定されたリンクアグリゲーション</block>
  <block id="503023bddb3bd1c7803b35b4ace6aa7a" category="list-text">ONTAP ツール for VMware vSphere の導入、設定、利用可能な状態</block>
  <block id="f3a29486bed19a90f2da6d007818b427" category="section-title">手順</block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">Interoperability Matrix Tool （ IMT ）</block>
  <block id="4b18348d39655902cd0e183596a82856" category="list-text">との互換性を確認します<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="bc295a5edde99316e021476fd74118c6" category="inline-link-macro">NFS 構成がサポートされていることを確認します。</block>
  <block id="564210524eadeca61542a5680bf0afca" category="list-text"><block ref="564210524eadeca61542a5680bf0afca" category="inline-link-macro-rx"></block></block>
  <block id="e103d9cdc55ef0be25a4fd8054bc28bc" category="list-text">次の ONTAP および vSphere タスクを実行します。</block>
  <block id="cfa5eceb5ac37d5ebd3af6f265d9ce4c" category="section-title">ONTAP タスク</block>
  <block id="c54d1c547e26987b98af73634278c77a" category="inline-link-macro">NFS の ONTAP ライセンスを確認</block>
  <block id="8174503ab9e5dc2fe2f74068f651770d" category="list-text"><block ref="8174503ab9e5dc2fe2f74068f651770d" category="inline-link-macro-rx"></block></block>
  <block id="5d3f3e14f3096740cb085fa81836d595" category="list-text">「 system license show 」コマンドを使用して、 NFS がリストされていることを確認します。</block>
  <block id="8b3434ec0db76b4d537ae9c645aa913c" category="list-text">ライセンスを追加するには 'license add-license-code &lt;license code&gt; を使用します</block>
  <block id="135850bb72d05ca77b8b8f846429fe71" category="inline-link-macro">NFS の設定ワークフローに従います。</block>
  <block id="01a85c06aae02abe9083e7e02d90661f" category="list-text"><block ref="01a85c06aae02abe9083e7e02d90661f" category="inline-link-macro-rx"></block></block>
  <block id="722a3f8fc9c281f41b6ca7a69ca15ec0" category="section-title">VMware vSphere タスク</block>
  <block id="2281b9d958567868b171298a8df5cdee" category="inline-link-macro">vSphere 用の NFS クライアント設定のワークフローに従います。</block>
  <block id="c80c5160cfe2127b3ab167103b20488c" category="paragraph"><block ref="c80c5160cfe2127b3ab167103b20488c" category="inline-link-macro-rx"></block></block>
  <block id="63d5049791d9d79d86e9a108b0a999ca" category="section-title">参照</block>
  <block id="3f297ef15cde0668e93b35f2752fd4fd" category="section-title">次の手順</block>
  <block id="883a5adf98ba177c28c5bc7d95e28763" category="paragraph">これらのタスクが完了すると、 NFS データストアで仮想マシンのプロビジョニングを利用できるようになります。</block>
  <block id="53001b412ce4896686a413a19f6dcc5f" category="listing-title">Ansible の Playbook</block>
  <block id="5a44477fe5ac4beac2dc6574097cf079" category="summary">このページでは、 VMware vSphere 環境に NetApp ONTAP ストレージ iSCSI VMFS データストアを導入する手順を説明します。</block>
  <block id="6d5f52fb3cf097647a57da8b55e5b08f" category="doc">ONTAP を使用した vSphere 従来のブロックストレージプロビジョニング</block>
  <block id="7c2d57185437da757ecede58f5a842d4" category="paragraph">VMware vSphere では、 ONTAP SAN プロトコルをサポートする次の VMFS データストアオプションがサポートされています。</block>
  <block id="c90881491d716de5c0ed7f9f4b09a3ad" category="cell">VMFS データストアのオプション</block>
  <block id="a9181ef164a32ec0949c2cf63315ca31" category="cell">ONTAP SAN プロトコルのサポート</block>
  <block id="5903a917b575023b60264c602c220771" category="inline-link-macro">Fibre Channel （ FC ；ファイバチャネル）</block>
  <block id="a4bce6d7794ee38a14e6a6d3785039f9" category="cell"><block ref="a4bce6d7794ee38a14e6a6d3785039f9" category="inline-link-macro-rx"></block></block>
  <block id="a6105c0a611b41b08f1209506350279e" category="cell">はい。</block>
  <block id="8da5577a58a95e2ebe9c6dd4f19f6c11" category="inline-link-macro">Fibre Channel over Ethernet （ FCoE ）</block>
  <block id="40b814244a055d57c1af5fd02e4a8747" category="cell"><block ref="40b814244a055d57c1af5fd02e4a8747" category="inline-link-macro-rx"></block></block>
  <block id="b26caac6068e09e5f849cfcb3e8c0c90" category="cell"><block ref="b26caac6068e09e5f849cfcb3e8c0c90" category="inline-link-macro-rx"></block></block>
  <block id="c38e870d503879d110dbddd5bf388ab2" category="cell">iSCSI Extensions for RDMA （ iSER ）</block>
  <block id="7fa3b767c460b54a2be4d49030b349c7" category="cell">いいえ</block>
  <block id="de5a656362f0d785d2cc7d3097a507ef" category="inline-link-macro">FC を使用した NVMe over Fabric （ NVMe/FC ）</block>
  <block id="71a94ffc9bd97f314990ee2cd7a87154" category="cell"><block ref="71a94ffc9bd97f314990ee2cd7a87154" category="inline-link-macro-rx"></block></block>
  <block id="16d2954ba1640e32b21c312695337233" category="cell">RDMA over Converged Ethernet （ NVMe/RoCE ）を使用した NVMe over Fabric</block>
  <block id="344567ba51767dd5805c908c602fb10e" category="admonition">iSER または NVMe/RoCE VMFS が必要な場合は、 SANtricity ベースのストレージシステムをチェックしてください。</block>
  <block id="8ce83a5c4c3183c4e25f0d8d7b657ffc" category="summary">このページでは、 VMware vSphere 環境での NFS データストアのサポートについて説明します。</block>
  <block id="3769193a46f06731838a6d904cf1da37" category="doc">ONTAP を使用した、 vSphere の従来型ファイルストレージのプロビジョニング</block>
  <block id="8d3005420a2cb4cc915402d9c5604538" category="paragraph">VMware vSphere では次の NFS プロトコルがサポートされていますが、どちらも ONTAP をサポートしています。</block>
  <block id="78aa97ac78d1291969b5893edcfe448a" category="inline-link-macro">NFS バージョン 3</block>
  <block id="fb110cc4ad992a0846c0eaea7fbf2d94" category="list-text"><block ref="fb110cc4ad992a0846c0eaea7fbf2d94" category="inline-link-macro-rx"></block></block>
  <block id="2d6affbd5ec6eb1f6009383ca5ba9b2b" category="inline-link-macro">NFS バージョン 4.1</block>
  <block id="3f65d9416139ab7c1ff75966bccf6f7d" category="list-text"><block ref="3f65d9416139ab7c1ff75966bccf6f7d" category="inline-link-macro-rx"></block></block>
  <block id="fc5929c224818a87a89047d2813dd2c5" category="inline-link-macro">この NFS クライアントバージョンの比較</block>
  <block id="ce51dd3c15b8a6638d0c212b990ae643" category="paragraph">vSphere に適した NFS バージョンを選択する方法については、を参照してください <block ref="8055fbd4933fc4c8b583fa212ff14ff2" category="inline-link-macro-rx"></block>。</block>
  <block id="e69b470437a857bf2d9517ce4ef8d2c1" category="summary">このページでは、 VMware vSphere 環境に NetApp ONTAP ストレージ FC VMFS データストアを導入する手順を説明します。</block>
  <block id="91d9498cf61618ef81368a106318efd2" category="doc">vSphere VMFS データストア - Fibre Channel ストレージバックエンドに ONTAP を使用</block>
  <block id="b6e52e53cc59b8620dcdc05f2b812be4" category="paragraph">このセクションでは、 ONTAP Fibre Channel （ FC ；ファイバチャネル）ストレージを使用した VMFS データストアの作成について説明します。</block>
  <block id="6b70d8f91894fa50b3c04af804f090b6" category="list-text">vSphere 環境およびを管理するために必要な基本的なスキル ONTAP</block>
  <block id="0335588c7903659bdeaa310c8f7bcdf4" category="list-text">｛ ONTAP_version ｝ を実行している ONTAP ストレージシステム（ FAS/AFF/CVO/ONTAP Select / ASA ）</block>
  <block id="fdb8f60c37b623874df816146436f56b" category="list-text">ONTAP クレデンシャル（ SVM 名、ユーザ ID 、パスワード）</block>
  <block id="d0a36a0dcdef62d026caa08afbaa4a42" category="inline-link-macro">入力した FC 構成ワークシート</block>
  <block id="5c42144bb611ba366591a823d4c2955e" category="list-text"><block ref="5c42144bb611ba366591a823d4c2955e" category="inline-link-macro-rx"></block></block>
  <block id="c7f58b1f94665d7ebf6f107970d1b91b" category="list-text">vSphere ホスト情報</block>
  <block id="cdce6351191da46d795898e4570b8da2" category="list-text">｛ vsphere_version ｝</block>
  <block id="63fc76a195a29345d466bc86f293ca14" category="list-text">ファブリックスイッチ</block>
  <block id="46fdd1539543376bfbbf2cc6da976539" category="list-text">単一のイニシエータの単一ターゲットゾーンを作成します。</block>
  <block id="df7f994fb0c494b66708667a64b2c406" category="list-text">イニシエータごとにゾーンを 1 つ作成します（単一のイニシエータゾーン）。</block>
  <block id="5a1cb943a687396a356750829002d982" category="list-text">各ゾーンに、 SVM の ONTAP FC 論理インターフェイス（ WWPN ）であるターゲットを含めます。SVM ごとに、ノードごとに少なくとも 2 つの論理インターフェイスが必要です。物理ポートの WWPN は使用しないでください。</block>
  <block id="d13dd15101d292f5b2c56e5be828fec8" category="section-title">VMFS データストアのプロビジョニング</block>
  <block id="95877ca095b0f0a0a981f8a12d234ad5" category="paragraph">VMFS データストアをプロビジョニングするには、次の手順を実行します。</block>
  <block id="195e1a47999aff0fbaa4eb8d97be6c40" category="inline-link-macro">FCP 構成がサポートされています</block>
  <block id="e1b87801d0d31fd947fb52aa411c2815" category="list-text">を確認します <block ref="a0240d867f430aa7cc80ec129fc2bdb1" category="inline-link-macro-rx"></block>。</block>
  <block id="e7dc6b39e7e5bd6df8fa93e90a426161" category="list-text">「 system license show 」コマンドを使用して、 FCP が一覧表示されていることを確認します。</block>
  <block id="d1b0a5732b3cb229ef0f788fbb095f05" category="list-text">ライセンスを追加するには 'license add-license-code &lt;license code&gt; を使用します</block>
  <block id="86a53381cefd41dcca81850274f0203a" category="list-text">SVM で FCP プロトコルが有効になっていることを確認します。</block>
  <block id="169e237a691059b9ac1933f0e7be8f56" category="inline-link-macro">既存の SVM の FCP を確認します。</block>
  <block id="5bb60b756067a0334c310be1e2260c3b" category="list-text"><block ref="5bb60b756067a0334c310be1e2260c3b" category="inline-link-macro-rx"></block></block>
  <block id="fab6621b43b19a018afc1860a5b85c21" category="inline-link-macro">既存の SVM で FCP を設定</block>
  <block id="7d4ca3fa89beb77990d305e17ed9ba64" category="list-text"><block ref="7d4ca3fa89beb77990d305e17ed9ba64" category="inline-link-macro-rx"></block></block>
  <block id="0d195904efc6cfb176bbc04e93c2947d" category="inline-link-macro">FCP で新しい SVM を作成します。</block>
  <block id="df062a6cafa16aee5f7ea64ea6991776" category="list-text"><block ref="df062a6cafa16aee5f7ea64ea6991776" category="inline-link-macro-rx"></block></block>
  <block id="5aab5d056538757626dd0562a563471a" category="list-text">FCP 論理インターフェイスが SVM で使用可能であることを確認します。</block>
  <block id="aa01379022dd5b86e18f436c76f651f5" category="list-text">「 Network Interface show 」を使用して、 FCP アダプタを確認します。</block>
  <block id="f89eac3d097d3dae5c0159f0da84b1c7" category="list-text">GUI を使用して SVM を作成する場合、論理インターフェイスはそのプロセスの一部です。</block>
  <block id="946b60eb8bd4945ad82b28fd9ccd3c63" category="list-text">ネットワーク・インターフェイスの名前を変更するには ' Network Interface modify を使用します</block>
  <block id="52fa81ab62bea2599ed516f01925678d" category="inline-link-macro">LUN を作成してマッピングします。</block>
  <block id="c8ecf540bebb63423545ecd3d02c6ca0" category="list-text"><block ref="a2b18e9ce335dd856363e6613d961c1a" category="inline-link-macro-rx"></block> VMware vSphere 用の ONTAP ツールを使用する場合は、この手順を省略してください。</block>
  <block id="e4f7ebeb9544fb23a73028ab714ca87c" category="section-title">VMware vSphere タスク</block>
  <block id="7407e0a15262132133381a890e36e47a" category="inline-link-macro">ストレージアダプタ情報</block>
  <block id="c57f32bc5ce6f95f5f9bec8260ecdb08" category="inline-link-macro">ONTAP ツールを使用して VMFS データストアをプロビジョニングする</block>
  <block id="b3a5f140339b1ca0940c5875b2a76d0b" category="list-text"><block ref="89ebfed741bd060c10a4a1472581f4e2" category="inline-link-macro-rx"></block>。</block>
  <block id="6fe85aae6e8fa231a1f417edfeef3759" category="doc">vSphere VMFS データストア - iSCSI ストレージバックエンド（ ONTAP を使用）</block>
  <block id="4f6f7882fc7b858bc0eb3e3a41991494" category="paragraph">このセクションでは、 ONTAP iSCSI ストレージを使用した VMFS データストアの作成について説明します。</block>
  <block id="383b1f30f341cb0eff11db96d70e9f50" category="list-text">vSphere 環境と ONTAP を管理するために必要な基本的なスキル。</block>
  <block id="47c341511ad626bfba98caeaa0762774" category="list-text">iSCSI の ONTAP ネットワークポート、 SVM 、および LUN の情報</block>
  <block id="f76f5dc5c6861d7938aa8d60b08976c8" category="inline-link-macro">完了した iSCSI 構成ワークシート</block>
  <block id="275e54409e966e03b62ee630e4856daa" category="list-text"><block ref="275e54409e966e03b62ee630e4856daa" category="inline-link-macro-rx"></block></block>
  <block id="c7e4d06c6b5e45fbb711be2b15976173" category="list-text">iSCSI VMkernel アダプタの IP 情報</block>
  <block id="3a6f48cf422509b67592ce2a0b4dd558" category="list-text">iSCSI 用に設定されている VLAN</block>
  <block id="a9df884192a193f56d8208439b4d1fca" category="list-text">との互換性を確認します<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block>。</block>
  <block id="881de4e9f9e9dba55f3d9f09d3fc8eac" category="inline-link-macro">iSCSI 構成がサポートされていることを確認します。</block>
  <block id="6a2fb6d042919f5807315156f926ab10" category="list-text"><block ref="6a2fb6d042919f5807315156f926ab10" category="inline-link-macro-rx"></block></block>
  <block id="f04a1b9690234d25ff072d6719666947" category="inline-link-macro">iSCSI の ONTAP ライセンスを確認します</block>
  <block id="41bf6980693d9ba9f5e7a797fe2f4417" category="list-text"><block ref="0767ceac1f7ac130ade75fb7fae3fc53" category="inline-link-macro-rx"></block>。</block>
  <block id="3ffc628bd3f213f0998146fb5262f366" category="list-text">「 system license show 」コマンドを使用して、 iSCSI がリストされているかどうかを確認します。</block>
  <block id="97035bc2443de65f877c3fddd838c6ae" category="inline-link-macro">SVM で iSCSI プロトコルが有効になっていることを確認します。</block>
  <block id="3807dbdaab3b890b6a293c99c7b46f63" category="list-text"><block ref="3807dbdaab3b890b6a293c99c7b46f63" category="inline-link-macro-rx"></block></block>
  <block id="cb66a92bc9fa6195f8b2914bcf868664" category="list-text">iSCSI ネットワーク論理インターフェイスが SVM で使用可能であることを確認します。</block>
  <block id="da91d0d17d1f671a0af23e7ebb96ec92" category="admonition">GUI を使用して SVM を作成すると、 iSCSI ネットワークインターフェイスも作成されます。</block>
  <block id="da6a83da2309e8dbd81bb5b55c7c9602" category="list-text">ネットワークインターフェイスを表示または変更するには ' ネットワークインタフェースコマンドを使用します</block>
  <block id="53fd22677faa2085c1fc51f1d116faff" category="admonition">ノードごとに 2 つの iSCSI ネットワークインターフェイスを推奨します。</block>
  <block id="69fea75e454b43e67ba176dddb604159" category="inline-link-macro">iSCSI ネットワークインターフェイスを作成</block>
  <block id="bd494b2c15d88a1dfa29c308b39e8f6e" category="inline-link-macro">データ iSCSI サービスがサービスポリシーに含まれていることを確認します。</block>
  <block id="c0e1d066d0482fc5cc1554edaa3f36b2" category="inline-link-macro">ジャンボフレームが有効になっていることを確認します。</block>
  <block id="a355e4512cfabb746ee4c05a87a61107" category="list-text"><block ref="a355e4512cfabb746ee4c05a87a61107" category="inline-link-macro-rx"></block></block>
  <block id="5ccd820a879b8d1daef5e44125431184" category="inline-link-macro">LUN を作成してマッピングします。</block>
  <block id="5c9b297b088335a8562568dc59549c7d" category="list-text">iSCSI VLAN で少なくとも 1 つの NIC が使用可能であることを確認します。パフォーマンスとフォールトトレランスを向上させるために、 2 枚の NIC を推奨します。</block>
  <block id="fe9e58c95c20042a4032ef737d6e8400" category="inline-link-macro">vSphere ホストで使用可能な物理 NIC の数を特定します。</block>
  <block id="96cf3cacac94299a7630f48f5cf5b7e3" category="list-text"><block ref="96cf3cacac94299a7630f48f5cf5b7e3" category="inline-link-macro-rx"></block></block>
  <block id="87d3329dab6e8f24601b6f45d40614ea" category="inline-link-macro">iSCSI イニシエータを設定します。</block>
  <block id="fd823eb37045485458bb3d5d52ddc46f" category="inline-link-macro">iSCSI 用 TCP / IP スタックが利用可能であることを確認します</block>
  <block id="875d65383afa504aad11a619d920adc7" category="list-text"><block ref="025b4ff12eca60b6c5b5be76597b5e95" category="inline-link-macro-rx"></block>。</block>
  <block id="e45f6655250b094b5a8370ff511869c3" category="inline-link-macro">iSCSI ポートグループが使用可能であることを確認します</block>
  <block id="4c93429599cf15be2af5aa0f59131c17" category="list-text"><block ref="5e67546a702454fa060946b3e582d0e9" category="inline-link-macro-rx"></block>。</block>
  <block id="b7b554d373b5992838a126134a03ba0d" category="list-text">通常、複数のアップリンクポートを持つ単一の仮想スイッチを使用します。</block>
  <block id="879d70f2184599f483fd94f0f274163f" category="list-text">1:1 のアダプタマッピングを使用します。</block>
  <block id="9f60e3586ab900b8f879404be003b539" category="list-text">iSCSI VMkernel アダプタが有効になっていて NIC の数が一致していて、 IP が割り当てられていることを確認します。</block>
  <block id="3e6e09b1cda3200c7407173a3473a103" category="inline-link-macro">iSCSI ソフトウェアアダプタを iSCSI VMkernel アダプタにバインド</block>
  <block id="70d687ef257c5d00e0d85844c0101c77" category="list-text"><block ref="70d687ef257c5d00e0d85844c0101c77" category="inline-link-macro-rx"></block></block>
  <block id="187fbd973609969af8f47e857f8579c4" category="inline-link-macro">ONTAP Tools を使用して VMFS データストアをプロビジョニングします</block>
  <block id="1e9df60603ff2a9fe2495b189aecc647" category="list-text"><block ref="efecd5d76f6fc92c9c9a8111cf809724" category="inline-link-macro-rx"></block>。すべてのデータストアについて、同じ手順を繰り返します。</block>
  <block id="5f4723c28ea2b13a27b86c1116720a8a" category="inline-link-macro">ハードウェアアクセラレーションのサポートを確認します。</block>
  <block id="aa0cfa24dd578f0629299a21b453583c" category="list-text"><block ref="aa0cfa24dd578f0629299a21b453583c" category="inline-link-macro-rx"></block></block>
  <block id="1d3fa7ee382266d716ba7a360f30f188" category="paragraph">これらのタスクが完了すると、 VMFS データストアで仮想マシンのプロビジョニングに使用できるようになります。</block>
  <block id="93ac3f76e97265952e309b2cbb980030" category="summary">このページでは、 NetApp ONTAP NFS バージョン 4 のデータストアを VMware vSphere 環境に導入する手順を説明します。</block>
  <block id="11bbb95c80fd3935828f1472bade3ae4" category="doc">vSphere NFS データストア - ONTAP バージョン 4.1</block>
  <block id="0a339846bb9d45c2252cf84f27f8390e" category="paragraph">このセクションでは、 ONTAP NAS ストレージを使用した NFS バージョン 4.1 データストアの作成について説明します。</block>
  <block id="d5ffdd3b223c5bb3d1d66e5756977564" category="list-text">vSphere 環境およびを管理するために必要な基本的なスキル ONTAP</block>
  <block id="a65c730562f6a5feffebe8a600829c71" category="list-text">ONTAP ストレージシステム（ FAS / AFF / CVO / ONTAP Select / クラウドボリュームサービス / Azure ネットアップファイル） ｛ ONTAP_version ｝ を実行しています</block>
  <block id="8e7f2b8f8c015d7ce248683387c1daf5" category="list-text">vSphere ホスト情報 ｛ vsphere_version ｝</block>
  <block id="7d0a7cdd836d94b19d4ecbce81ba2c1e" category="list-text">ONTAP システムのネットワークデータポート、 vSphere ホストを接続します</block>
  <block id="d4e890b3139e840bac898dc24d2330a3" category="list-text">VMware vSphere 向け ONTAP ツールの導入、設定、利用可能な状態</block>
  <block id="f2f6f93a63f235f63bf8a14ad398ddd0" category="inline-link">Interoperability Matrix Tool （ IMT ）</block>
  <block id="2c364f266e330209041f2cf854afab91" category="list-text">との互換性を確認します<block ref="975c7893d48b02c6727b59b0582d74bc" category="inline-link-rx"></block></block>
  <block id="863feef43abaa752e441459bd37722c3" category="list-text">以下の ONTAP および vSphere タスクを実行します。</block>
  <block id="1b2d2406823c016e35ebeddf0ec29c66" category="inline-link-macro">NFS の ONTAP ライセンスを確認</block>
  <block id="7209cd833425a764d216b4e565ac65c6" category="list-text"><block ref="7209cd833425a764d216b4e565ac65c6" category="inline-link-macro-rx"></block></block>
  <block id="55d2948d4abb6ad9ea1e2b6a5b73460b" category="list-text">「 system license show 」コマンドを使用して、 NFS がリストされているかどうかを確認します。</block>
  <block id="0a5e80a3066e5036387d5026a58fe582" category="inline-link-macro">NFS の設定ワークフローに従います</block>
  <block id="4b9e38c0f910614d9be47f85cf0f07bc" category="list-text"><block ref="4b9e38c0f910614d9be47f85cf0f07bc" category="inline-link-macro-rx"></block></block>
  <block id="4344c7f5d714fb1797033b7d9cca43fd" category="inline-link-macro">vSphere 用 NFS クライアント構成のワークフローに従います。</block>
  <block id="c9fb47d82da1089992044972b4b65103" category="paragraph"><block ref="c9fb47d82da1089992044972b4b65103" category="inline-link-macro-rx"></block></block>
  <block id="a7ba4bd9aa10b0456b8f13ef40a2d1d5" category="summary">このページでは、 VMware vSphere 環境に NetApp ONTAP ストレージ FCoE VMFS データストアを導入する手順を説明します。</block>
  <block id="1937a4bfde18bb02682d378132d0b6a9" category="doc">vSphere VMFS Datastore - Fibre Channel over Ethernet ストレージプロトコル ONTAP を使用します</block>
  <block id="66439ac6171413528646918952bff23e" category="paragraph">このセクションでは、 Fibre Channel over Ethernet （ FCoE ）転送プロトコルを使用して ONTAP ストレージに VMFS データストアを作成する方法について説明します。</block>
  <block id="b087c7e1213b84e69de1a6e5214cd942" category="list-text">｛ ONTAP_version ｝ を実行している ONTAP ストレージシステム（ FAS/AFF/CVO/ONTAP Select ）</block>
  <block id="d9da372e69584852a9808bfa9fcc99a9" category="inline-link-macro">サポートされる FCoE の組み合わせ</block>
  <block id="b61947ecee08267d1f6930ccbd646d52" category="list-text"><block ref="b61947ecee08267d1f6930ccbd646d52" category="inline-link-macro-rx"></block></block>
  <block id="08b42ec45ef1147093b9161cc743b0a0" category="inline-link-macro">設定ワークシートに記入</block>
  <block id="bcf78e9148ebbc12ed4a54d2149cc2bc" category="list-text"><block ref="bcf78e9148ebbc12ed4a54d2149cc2bc" category="inline-link-macro-rx"></block></block>
  <block id="80ba2a0b5b5ae31742a18c682e724b6e" category="list-text">ONTAP FC データポートまたは vSphere ホストを接続</block>
  <block id="52dd4b667b031cd80a33b9d176e43827" category="list-text">N_Port ID Virtualization （ NPIV ）機能が有効になっている場合</block>
  <block id="d7b3fbe677a7bffd7e387a3578d6b481" category="inline-link-macro">FC / FCoE ゾーニングが設定されました</block>
  <block id="434da439fcd2a7729ac67cef537d6651" category="list-text"><block ref="434da439fcd2a7729ac67cef537d6651" category="inline-link-macro-rx"></block></block>
  <block id="5d914ccaef7b5404838cb47cff27fa11" category="list-text">FCoE のサポート</block>
  <block id="b74438cda33fca6618da9e30ef5fee5d" category="list-text">DCB のサポート</block>
  <block id="69b788fe29f78e1fb439efd1bec08ab6" category="inline-link-macro">FCoE のジャンボフレーム</block>
  <block id="e92f4c11834e879e94fa441894d8e9c9" category="list-text"><block ref="e92f4c11834e879e94fa441894d8e9c9" category="inline-link-macro-rx"></block></block>
  <block id="42cdbee955a0e208306a321b74a948b1" category="section-title">VMFS データストアをプロビジョニングする</block>
  <block id="f067d14dc86c5c0ec984803b3485a7a6" category="inline-link-macro">FCoE 構成がサポートされていることを確認します</block>
  <block id="79d164739c1e0aaf7f56e13c2a4c66ac" category="list-text"><block ref="4201ef99768aac8f72883e5cb6ec656f" category="inline-link-macro-rx"></block>。</block>
  <block id="1a04100ec801e5e2d1708d89eb1159b6" category="inline-link-macro">FCP の ONTAP ライセンスを確認します。</block>
  <block id="7fcd357d480b8eaa4a38cdbbddfd6c97" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block></block>
  <block id="f2a0a9000f5ff3910235e570c0ac5e44" category="list-text">「 system license show 」コマンドを使用して、 FCP が一覧表示されていることを確認します。</block>
  <block id="e5b8ca3e9ff580bcc9315fabcb34312e" category="list-text">SVM で FCP プロトコルが有効になっていることを確認します。</block>
  <block id="015c565181667d59b83b7761e35682d1" category="inline-link-macro">FCP で新しい SVM を作成します。</block>
  <block id="de4606f963140e2d2d0a3df251ffd646" category="list-text"><block ref="de4606f963140e2d2d0a3df251ffd646" category="inline-link-macro-rx"></block></block>
  <block id="2d6fd01ea0767b50e214a74ff1fcfae0" category="list-text">FCP 論理インターフェイスが SVM で使用可能になっていることを確認します。</block>
  <block id="ee7f4720a3fc60686c4a9f7429a60cbc" category="list-text">ネットワーク・インターフェイスの名前を変更するには ' Network Interface modify を使用します</block>
  <block id="6e67c7d604ae439f60ceb51480fdbb1c" category="inline-link-macro">LUN を作成してマッピングします</block>
  <block id="e4eeb9421963195597743339d2f38ff6" category="list-text"><block ref="96e32c32f267ac1d65d603f36f017a41" category="inline-link-macro-rx"></block>； VMware vSphere 用の ONTAP ツールを使用する場合は、この手順を省略してください。</block>
  <block id="f6c0391a150cfd40a68682285c56e835" category="inline-link-macro">ストレージアダプタ情報</block>
  <block id="60f05805eb8189d665c19856d5388e3c" category="list-text">HBA ドライバがインストールされていることを確認しますVMware がサポートする HBA には、すぐに使用できるドライバとが付属しています は、に表示されている必要があります <block ref="c5f1cce809af8cfecf09908d33f4c097" category="inline-link-macro-rx"></block>。</block>
  <block id="d4f43ea12f3f521c93fb3dd4d93c428d" category="summary">このページでは、 VMware vSphere 環境に VMFS データストア用の NetApp ONTAP NVMe/FC ストレージを導入する手順について説明します。</block>
  <block id="9e433440cdaf3b61716784200e8abf6d" category="doc">vSphere VMFS データストア - NVMe / FC と ONTAP</block>
  <block id="9367f3df6c8d54eba1da3cd9c5fa2776" category="paragraph">このセクションでは、 NVMe/FC を使用した ONTAP ストレージを使用した VMFS データストアの作成について説明します。</block>
  <block id="7890464cdce93f078097395e27132775" category="inline-link-macro">NVMe/FC の基本的な知識</block>
  <block id="c6e7cd589502f52a9398e779ede56d14" category="list-text"><block ref="62a43aa3bd2eb01e27a6091d3017311c" category="inline-link-macro-rx"></block>。</block>
  <block id="62eadfe081f86e1f9a72988a4feb7bfc" category="inline-link-macro">記入済みの FC 構成ワークシート</block>
  <block id="f186921a73873df63dc496b515bc2099" category="list-text"><block ref="f186921a73873df63dc496b515bc2099" category="inline-link-macro-rx"></block></block>
  <block id="c4436d4a190778b7ec1e9461f6454bdd" category="list-text">vCenter Server の各サービスを提供</block>
  <block id="5fd6c6da49bc906cc217c5aff2041a52" category="list-text">vSphere ホスト情報（ ｛ vsphere_version ｝ ）</block>
  <block id="71d4977f0fd6be92644e1ff9f8096637" category="section-title">VMFS データストアをプロビジョニングする</block>
  <block id="f42c50210dcc0a3a69c8258256e75e4b" category="inline-link-macro">NVMe/FC 構成がサポートされていることを確認します。</block>
  <block id="5312bcc81ee6d7bce6549b2089c9d1ac" category="list-text"><block ref="5312bcc81ee6d7bce6549b2089c9d1ac" category="inline-link-macro-rx"></block></block>
  <block id="6ad7e9002145710745843d16314895e3" category="inline-link-macro">NVMe ネームスペースとサブシステムを作成する</block>
  <block id="06badf30aa173febc3374aceef25c5ce" category="list-text"><block ref="06badf30aa173febc3374aceef25c5ce" category="inline-link-macro-rx"></block></block>
  <block id="9761a89a99469e468e71b7a0087be29d" category="inline-link-macro">vSphere ホストの NVMe ドライバのインストールと検証のタスクを実行します</block>
  <block id="926e4d89379d3dde2510965ca53771af" category="list-text"><block ref="926e4d89379d3dde2510965ca53771af" category="inline-link-macro-rx"></block></block>
  <block id="e229fd9b7b8948ddebf276bda8a9145e" category="inline-link-macro">VMFS データストアを作成します</block>
  <block id="3dbbea9263919f89335d7ba053f09a39" category="list-text"><block ref="3dbbea9263919f89335d7ba053f09a39" category="inline-link-macro-rx"></block></block>
  <block id="ad1cf94aab71c9962e22037ed60d41e9" category="list-text"><block ref="ad1cf94aab71c9962e22037ed60d41e9" category="inline-link-macro-rx"></block></block>
  <block id="e6ba927c9d14295015e39be05cf54040" category="inline-link-macro">NetApp ONTAP に Red Hat OpenShift を実装するマルチテナンシー</block>
  <block id="ab439bcac737f2565970fe2612976b75" category="list-text"><block ref="ab439bcac737f2565970fe2612976b75" category="inline-link-macro-rx"></block></block>
  <block id="ad95c47343e102dc30ec33fa6f1ccc55" category="inline-link-macro">NVA-1160 - ネットアップでの Red Hat OpenShift</block>
  <block id="1043b5153afff839b84d714aa9127913" category="list-text"><block ref="1043b5153afff839b84d714aa9127913" category="inline-link-macro-rx"></block></block>
  <block id="d48e549b4fdcc889e0243c53bbb4dda0" category="sidebar">解決策の検証とユースケース</block>
  <block id="d6bf2b10101446c7afd28ff94926fc44" category="sidebar">オペレータを介して展開します</block>
  <block id="e6b088db24ebe67ed0e9567d309387ec" category="sidebar">ワークフロー</block>
  <block id="88c506562ebadd679bb16d76a4558619" category="sidebar">VM のクローニング</block>
  <block id="6c30682e8603121e14abe8bab7bd88f3" category="sidebar">VMware Virtualization for ONTAP の略</block>
  <block id="c0bf5949fe87e1e5caf42e4746cd0080" category="sidebar">VMware vSphere と ONTAP のベストプラクティス</block>
  <block id="f5344fe4d88d29ee79ba6110f60cfa9b" category="list-text">Ansible 制御ホストとして使用できるように Linux ホストを設定するには、<block ref="8688caf90b0dc445f61be35cbf93ed1a" category="inline-link-macro-rx"></block>または<block ref="2b00e81c1e240a58c4df0e850699511b" category="inline-link-macro-rx"></block></block>
  <block id="9b64a6dfae1f3fa326b750c2790c79fe" category="summary">このセクションでは、 Azure NetApp Files SMB ボリュームを使用して AOAG 構成に SQL データベース資産をリアルタイムで導入する方法について説明します。</block>
  <block id="5ca1071c67ab704b04ed27747f213551" category="doc">リアルタイムの高レベル・リファレンス・デザイン</block>
  <block id="bb0357d1c0b3b8ebd31a43c9b30f3745" category="list-text">ノード数： 4.</block>
  <block id="7f4f30d96e1d0a820a6962ad6ac994ee" category="list-text">データベース数： 21</block>
  <block id="f28735e3e5e57049aa575b3f0ec83c61" category="list-text">可用性グループの数： 4.</block>
  <block id="96fb94ba9fad0b4452c212b21df61eab" category="list-text">バックアップの保持： 7 日</block>
  <block id="a8d1485807d36562316fb8b2254bca57" category="list-text">バックアップアーカイブ： 365 日</block>
  <block id="4afa49afd4ebc3638f3e000d65825370" category="admonition">Azure NetApp Files 共有を使用して Azure 仮想マシンに SQL Server と FCI を導入すると、コスト効率に優れたモデルでデータのコピーを 1 つ作成できます。この解決策では、ファイルパスがセカンダリレプリカと異なる場合に、追加ファイル操作の問題を回避できます。</block>
  <block id="ab030ea777250278c4f110a497eeef88" category="paragraph"><block ref="ab030ea777250278c4f110a497eeef88" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4822d9597460a9166778308da312709c" category="paragraph">次の図は、 AOAG 内のデータベースがノード全体に分散していることを示しています。</block>
  <block id="af316199cc8e77dcbb6fb560cbc4c44c" category="paragraph"><block ref="af316199cc8e77dcbb6fb560cbc4c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">データレイアウト</block>
  <block id="35c33dd0c5565dbdba04dc2b313d7a2e" category="paragraph">ユーザデータベースファイル（ .mdf ）とユーザデータベーストランザクションログファイル（ .ldf ）は、 tempdb とともに同じボリュームに格納されます。サービスレベルは Ultra です。</block>
  <block id="9b7d6479a15395afefc6d7f9e38a4f17" category="paragraph">構成は 4 つのノードと 4 つの AGS で構成されます。21 個のデータベース（ Dynamic AX 、 SharePoint 、 RDS コネクションブローカー、インデックスサービスの一部）はすべて Azure NetApp Files ボリュームに格納されます。ノード上のリソースを効果的に使用するために、 AOAG ノード間でデータベースが分散されます。WSFC には、 AOAG 構成に属する 4 つの D32 v3 インスタンスが追加されています。これらの 4 つのノードは Azure Virtual Network でプロビジョニングされ、オンプレミスから移行されることはありません。</block>
  <block id="fcbd19b726fdd6160dfe2ab43f285a55" category="paragraph">* 注： *</block>
  <block id="09a10f0ab048cde1d7b704392ba05d9a" category="list-text">アプリケーションの性質と実行するクエリに応じて、ログのパフォーマンスとスループットが向上する必要がある場合は、データベースファイルを Premium サービスレベルに配置し、 Ultra サービスレベルでログを格納できます。</block>
  <block id="51368a236b969e288242f0b0b615cf74" category="list-text">tempdb ファイルが Azure NetApp Files に配置されている場合は、 Azure NetApp Files ボリュームをユーザのデータベースファイルから分離する必要があります。AOAG でのデータベースファイルの配布例を次に示します。</block>
  <block id="2e66f3d288799e6f4235b883bb2f693c" category="list-text">Snapshot コピーベースのデータ保護のメリットを維持するために、データとログのデータを同じボリュームに統合しないことを推奨します。</block>
  <block id="1452bcdb4aeb229a2c2e503f9bbba753" category="list-text">セカンダリデータベースのファイルパスが対応するプライマリデータベースのパスと異なる場合、プライマリレプリカで実行されるアドオンファイル処理がセカンダリデータベースで失敗する可能性があります。この状況は、プライマリノードとセカンダリノードで共有パスが異なる場合（コンピュータアカウントが異なることが原因）に発生することがあります。この障害が発生すると、セカンダリデータベースが原因によって中断される可能性があります。拡張またはパフォーマンスのパターンを予測できず、あとでファイルを追加する予定の場合は、 Azure NetApp Files を使用した SQL Server フェイルオーバークラスタも許容される解決策です。ほとんどの環境では、 Azure NetApp Files がパフォーマンス要件を満たしています。</block>
  <block id="19f59b74448f6a27519db281a44e4b12" category="section-title">データ移行</block>
  <block id="cd6b4503e07d15cebc0842bb8da7b765" category="paragraph">オンプレミスの SQL Server ユーザデータベースを Azure 仮想マシンの SQL Server に移行するには、いくつかの方法があります。移行はオンラインとオフラインのどちらでも実行できます。選択するオプションは、 SQL Server のバージョン、ビジネス要件、および組織内で定義されている SLA によって異なります。データベース移行プロセス中のダウンタイムを最小限に抑えるために、 AlwaysOn オプションまたはトランザクションレプリケーションオプションのどちらかを使用することを推奨します。これらの方法を使用できない場合は、データベースを手動で移行できます。</block>
  <block id="2d4221f1ee93c102ca047daac1fba4a7" category="paragraph">マシン間でデータベースを移動するための最もシンプルで徹底的にテストされたアプローチは、バックアップとリストアです。通常は、データベースバックアップのあとにデータベースバックアップのコピーを Azure に作成します。そのあとでデータベースをリストアできます。最適なデータ転送パフォーマンスを実現するには、圧縮されたバックアップファイルを使用してデータベースファイルを Azure VM に移行します。本ドキュメントで紹介している高度な設計では、 Azure ファイルストレージのバックアップ方法と Azure ファイルの同期を使用し、 Azure NetApp Files にリストアするアプローチを採用しています。</block>
  <block id="623f8382f97ee8df2d7af54439833812" category="admonition">Azure Migrate は、 SQL Server ワークロードの検出、評価、移行に使用できます。</block>
  <block id="fbc25f1c70f1a9c133715cac6d66b21b" category="paragraph">移行を実行するには、次の手順を実行します。</block>
  <block id="d807caa187d2fea33bab50ed1e1c79bb" category="list-text">要件に基づいて、接続をセットアップします。</block>
  <block id="59f59f1aebe4fc18ab054480b3a1098a" category="list-text">オンプレミスのファイル共有場所へのフルデータベースバックアップを実行</block>
  <block id="4891d727582d5df766ee6737fe7fb761" category="list-text">Azure ファイル同期を使用して、バックアップファイルを Azure ファイル共有にコピーします。</block>
  <block id="135899cc34886eb6ce9baf7211d4adb5" category="list-text">目的のバージョンの SQL Server で VM をプロビジョニングします。</block>
  <block id="fbef0b11b7ee9e0d709d3d1c6efbd4d4" category="list-text">コマンド・プロンプトから copy コマンドを使用して ' バックアップ・ファイルを VM にコピーします</block>
  <block id="b9786aca69df61c5165147929b4ced89" category="list-text">フルデータベースを Azure 仮想マシン上の SQL Server にリストアします。</block>
  <block id="e937691d64dcb1188cbbcbcd83d87d2f" category="admonition">21 のデータベースをリストアするには、約 9 時間かかりました。この方法はこのシナリオに特有です。ただし、状況や要件に応じて、以下に示すその他の移行方法を使用できます。</block>
  <block id="2b9d85faa379ef985ae3851810db1403" category="paragraph">オンプレミスの SQL Server から Azure NetApp Files にデータを移動するためのその他の移行オプションには、次のものがあります。</block>
  <block id="90248308f9c24bd3bf817ee129838603" category="list-text">データファイルとログファイルを切り離し、 Azure Blob Storage にコピーして、 URL からマウントされた ANF ファイル共有を使用して Azure VM 内の SQL Server に接続します。</block>
  <block id="82ce70205698ed956d1fce48af1360c0" category="inline-link">Azure レプリカの追加ウィザード</block>
  <block id="e5e07f1ff84f0082089e4fec71ed43a4" category="list-text">常時稼働の可用性グループをオンプレミスに導入する場合は、を使用します<block ref="aea558e3371e9956f5e03828309464a0" category="inline-link-rx"></block> をクリックして Azure でレプリカを作成し、フェイルオーバーを実行します。</block>
  <block id="eedc53c13a9992999dba36bda1b62255" category="inline-link">トランザクションレプリケーション</block>
  <block id="47a43d904457c52da2918f290a0ae5cb" category="list-text">SQL Server を使用します<block ref="21bf5f41b40b598aae9dd55aa9dcb960" category="inline-link-rx"></block> Azure SQL Server インスタンスをサブスクライバとして設定するには、レプリケーションを無効にして、ユーザに Azure データベースインスタンスをポイントさせます。</block>
  <block id="bf4614882fd1000329cfcb76f98f6c17" category="list-text">Windows インポート / エクスポートサービスを使用して、ハードドライブを出荷します。</block>
  <block id="be062cdcabbb3055334e8f19b4bdf378" category="section-title">バックアップとリカバリ</block>
  <block id="b855582b6472c4fbe2a5f606191e66d6" category="paragraph">バックアップとリカバリは、 SQL Server 環境にとって重要な要素です。AOAG などの高可用性ソリューションと組み合わせて、さまざまなデータ障害および損失シナリオから迅速にリカバリするための適切な安全ネットを用意する必要があります。CommVault などのサードパーティ製バックアップツールでは、 SQL Server データベースの休止ツール、 Azure バックアップ（ストリーミング）、またはアプリケーションと整合性のあるデータベースバックアップを実行できます。</block>
  <block id="3896e1102f68b0bc974f324bb134f6e6" category="inline-link">SCSQLAPI ツール</block>
  <block id="e372173044ccba12657b2e3dbff1879b" category="paragraph">Azure NetApp Files の Snapshot テクノロジを使用すると、パフォーマンスやネットワーク利用率に影響を与えることなく、ユーザデータベースのポイントインタイム（ PiT ）コピーを簡単に作成できます。また、このテクノロジを使用すると、新しいボリュームに Snapshot コピーをリストアしたり、ボリュームの状態を、ボリュームリバート機能を使用して Snapshot コピーが作成された時点の状態にすばやくリバートしたりできます。Azure NetApp Files スナップショットプロセスは非常に高速で効率的で、 Azure バックアップのストリーミングバックアップとは異なり、毎日のバックアップを複数作成できます。1 日に複数の Snapshot コピーを作成できるため、 RPO と RTO が大幅に短縮されます。Snapshot コピーの作成前にデータに損傷がなく、ディスクに適切にフラッシュされるようにアプリケーションの整合性を追加するには、 SQL Server データベースの休止ツールを使用します <block ref="b800e9e09a17fc5b41967404ec8e47ac" category="inline-link-rx"></block>; このリンクにアクセスするには、 NetApp SSO ログインクレデンシャルが必要です）。このツールは PowerShell から実行できます。 PowerShell では、 SQL Server データベースを休止し、アプリケーションと整合性のあるバックアップ用ストレージ Snapshot コピーを作成できます。</block>
  <block id="04666a337d02195d17089298f5773f4c" category="paragraph">* 注： *</block>
  <block id="a4d5ac6087b7ce119cfe6b7ad4d77ee5" category="list-text">SCSQLAPI ツールは、 2016 および 2017 バージョンの SQL Server のみをサポートします。</block>
  <block id="fdcb10d4c2db07cf930247a4f9898ec5" category="list-text">SCSQLAPI ツールは、一度に 1 つのデータベースでのみ動作します。</block>
  <block id="2f65ae42dc3aa8b735406a2d56ceb6fb" category="list-text">各データベースのファイルを別々の Azure NetApp Files ボリュームに配置して、それらのファイルを分離します。</block>
  <block id="879351e17b2cd6d740ac0974e9ff8a5a" category="inline-link">Azure バックアップ</block>
  <block id="794b24c8957eec03a1402459d32f6810" category="paragraph">SCSQL API には大きな制限があるため、<block ref="10a72c6743c3c6714e03b5537ec15603" category="inline-link-rx"></block> SLA 要件を満たすためにデータ保護に使用されていた。Azure Virtual Machine と Azure NetApp Files で実行される SQL Server のストリームベースのバックアップを提供します。Azure Backup では、 15 分の RPO を実現し、ログバックアップと PIT リカバリを最大 1 秒まで頻繁に実行できます。</block>
  <block id="423e555c5ec3885f2bb5d9d2d6627f63" category="section-title">監視</block>
  <block id="fe58430a0bb00057a08eed382c5d82b2" category="paragraph">Azure NetApp Files は、時系列データ用の Azure Monitor と統合されており、割り当てられたストレージ、実際のストレージ使用量、ボリューム IOPS 、スループット、ディスク読み取りバイト / 秒に関する指標を提供します。 ディスク書き込みバイト / 秒、ディスク読み取り / 秒、ディスク書き込み / 秒、および関連するレイテンシ。このデータを使用して、アラート生成によるボトルネックを特定し、健常性チェックを実行して、 SQL Server 環境が最適な構成で実行されていることを確認できます。</block>
  <block id="48419e90c914ae5fa935283404de8a2a" category="paragraph">この HLD では、 ScienceLogic を使用して、適切なサービスプリンシパルを使用してメトリックを公開することで Azure NetApp Files を監視します。次の図は、 Azure NetApp Files Metric オプションの例です。</block>
  <block id="2bede5da6907dcdcebc6a8f407f07467" category="paragraph"><block ref="2bede5da6907dcdcebc6a8f407f07467" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fe292df6373534e554d5a7938bc3c3b" category="section-title">シッククローンを使用した DevTest</block>
  <block id="652f67778e6d02c7b5bfe46a3e579f7f" category="paragraph">Azure NetApp Files を使用すると、アプリケーション開発サイクル中に現在のデータベースの構造とコンテンツを使用して実装が必要な機能をテストするためのデータベースのコピーを瞬時に作成でき、データの抽出と操作を行うツールを使用してデータウェアハウスにデータを取り込むことができます。 また、誤って削除または変更されたデータをリカバリすることもできます。このプロセスでは Azure Blob コンテナからデータをコピーする必要がないため、非常に効率的です。ボリュームのリストア後は読み取り / 書き込み処理に使用できるため、検証と製品化までの時間が大幅に短縮されます。この機能は、 SCSQLAPI と併用してアプリケーションの整合性を保つ必要があります。このアプローチでは、別の継続的なコスト最適化手法に加えて、 Restore to New volume オプションを活用する Azure NetApp Files も提供されます。</block>
  <block id="e4665dd99280634e4b44ff82666fbb9f" category="list-text">Snapshot コピーから作成されたボリュームに Restore New Volume オプションを使用すると、容量プールの容量が使用されます。</block>
  <block id="0031911d8ba66a79d06b9819afd4f082" category="list-text">REST または Azure CLI を使用してクローンボリュームを削除すると、追加のコストを回避できます（容量プールの拡張が必要になった場合）。</block>
  <block id="cb4d46fdcb0881652013c495d90ae732" category="section-title">ハイブリッドストレージの選択肢</block>
  <block id="e6a1767911a937e11cc1750fcc4256c3" category="paragraph">ネットアップでは、 SQL Server 可用性グループのすべてのノードに同じストレージを使用することを推奨していますが、場合によっては複数のストレージオプションを使用できます。このシナリオは、 Azure NetApp Files で、 AOAG のノードが Azure NetApp Files SMB ファイル共有に接続され、 2 つ目のノードが Azure Premium ディスクに接続されている場合に発生します。このような場合は、 Azure NetApp Files SMB 共有にユーザデータベースのプライマリコピーが保持され、 Premium ディスクがセカンダリコピーとして使用されていることを確認してください。</block>
  <block id="009d3d51226fdccd09052934b65100db" category="list-text">このような環境でフェイルオーバーの問題を回避するには、 SMB ボリュームで継続的可用性が有効になっていることを確認してください。継続的可用性属性を持たないストレージレイヤでバックグラウンドでメンテナンスを実施すると、データベースで障害が発生する可能性があります。</block>
  <block id="918e9d895272e6a326c6585e05ae4c08" category="list-text">データベースのプライマリコピーは Azure NetApp Files SMB ファイル共有に保持します。</block>
  <block id="1a5c3601eda1cd38072323e418968743" category="section-title">ビジネス継続性</block>
  <block id="064ea84d2e6072b28bfd7a8b36aed3db" category="paragraph">ディザスタリカバリは、一般にあらゆる導入で後回しになっています。ただし、ビジネスへの影響を回避するために、設計および導入の初期段階でディザスタリカバリに対処する必要があります。Azure NetApp Files では、クロスリージョンレプリケーション（ CRR ）機能を使用して、予期しないリージョンの停止を処理するためにブロックレベルでボリュームデータをペアリングされたリージョンにレプリケートできます。CRR 対応のデスティネーション・ボリュームは読み取り処理に使用できるため、災害復旧シミュレーションに最適です。さらに 'CRR デスティネーションを最小のサービス・レベル（ Standard など）で割り当てることにより ' 全体的な TCO を削減できますフェイルオーバーが発生した場合はレプリケーションを解除することで対応するボリュームを読み取り / 書き込み可能にすることができます。また、動的なサービスレベル機能を使用してディザスタリカバリコストを大幅に削減することで、ボリュームのサービスレベルを変更することもできます。これは Azure NetApp Files 独自の機能で、 Azure 内でブロックレプリケーションを実行します。</block>
  <block id="86258094262f66b30d10068d1d9c29d4" category="section-title">長期的な Snapshot コピーのアーカイブ</block>
  <block id="65bd92a3b5fcfea7efeb973a0a2483d8" category="inline-link">AzCopy</block>
  <block id="e6bf440e9e7e787ce92e6f8661daf9e9" category="paragraph">多くの組織では、 Snapshot データをデータベースファイルから長期的に保持することが必須のコンプライアンス要件として求められています。このプロセスはこの HLD では使用されませんが、を使用した単純なバッチスクリプトを使用すると簡単に実行できます<block ref="f326c7b047cd071718d141dba06c550f" category="inline-link-rx"></block> をクリックして Azure BLOB コンテナに Snapshot ディレクトリをコピーします。スケジュールされたタスクを使用して、特定のスケジュールに基づいてバッチスクリプトを実行できます。このプロセスは簡単で、次の手順で構成されます。</block>
  <block id="dfdc6514d824f948d82ee2ac6515603f" category="list-text">AzCopy V10 実行ファイルをダウンロードします。これは 'exe` ファイルであるため ' インストールするものはありません</block>
  <block id="5434519f37049a19d388fb3edabd08f7" category="list-text">コンテナレベルで適切な権限を持つ SAS トークンを使用して 'AzCopy を承認します</block>
  <block id="73facdc1e77927e1c0d4c2f66c6fedf9" category="list-text">AzCopy が承認されると、データ転送が開始されます。</block>
  <block id="a2c31034ac77c6ad0ce6dae2a7882d73" category="list-text">バッチファイルでは、 SAS トークンに表示される % 文字をエスケープする必要があります。そのためには、 SAS トークン文字列で既存の % 文字の横に % 文字を追加します。</block>
  <block id="0eed577952fd376af1fa48aa241e3df7" category="inline-link">セキュアな転送が必要です</block>
  <block id="b2f731ca364e7df30cd69650bdc19d46" category="list-text">。<block ref="7e9be5c7f255e20f7f3a81046108dcad" category="inline-link-rx"></block> ストレージアカウントの設定によって、ストレージアカウントへの接続が Transport Layer Security （ TLS ）で保護されるかどうかが決まります。この設定はデフォルトで有効になっています。次のバッチスクリプト例は、 Snapshot コピーディレクトリから指定された BLOB コンテナにデータを再帰的にコピーします。</block>
  <block id="f2c225fb316953652d9040f71e76717c" category="paragraph">PowerShell で次のコマンドが実行されます。</block>
  <block id="e7cc24e4ddff469c6304653aea869597" category="list-text">長期保持用の同様のバックアップ機能も、近日中に Azure NetApp Files で使用可能になります。</block>
  <block id="03930ecbc2c505278298d571631e23bb" category="list-text">バッチスクリプトは、任意のリージョンの BLOB コンテナにデータをコピーする必要がある場合に使用できます。</block>
  <block id="a39ae09f8be4327fc176cfeb76a0e366" category="section-title">コストの最適化</block>
  <block id="07ecdeff0f5a70968e882eb4ace6f576" category="paragraph">ボリュームの形状変更とサービスレベルの動的変更をデータベースに対して完全に透過的に行うことで、 Azure NetApp Files は Azure で継続的なコスト最適化を実現します。この HLD では、この機能を使用して、ワークロードの急増に対処するためにストレージを追加でオーバープロビジョニングすることを回避しています。</block>
  <block id="bf511e8b678dd2ecee162930e6c8c9e6" category="paragraph">ボリュームのサイズ変更は、 Azure 機能と Azure アラートログを組み合わせて作成すると簡単に実行できます。</block>
  <block id="75b7d47e2aa19968e092ab7ddb108a3f" category="summary">オールクラウドにも、ストレッチデータベースを使用したハイブリッドクラウドにも、 Azure NetApp Files は、データベースワークロードの導入と管理に最適なオプションを提供します。データ要件はアプリケーションレイヤとシームレスに連携し、 TCO を削減します。</block>
  <block id="d8d2e6021f496c4e4a31a3d5d51c0a97" category="paragraph">このドキュメントでは、 Azure NetApp Files を使用した Microsoft SQL Server 環境の計画、設計、最適化、拡張に関する推奨事項について説明します。この推奨事項は、実装によって大きく異なる場合があります。適切な解決策は、導入の技術的な詳細と、プロジェクトの背景にあるビジネス要件の両方によって異なります。</block>
  <block id="56925354251a536c23de1174d3001595" category="section-title">重要なポイント</block>
  <block id="033e6e43f2148e187e072dc7e6585802" category="paragraph">本ドキュメントの主な内容は次のとおりです。</block>
  <block id="b2b363e230905b04f6e9c7263aa93f42" category="list-text">Azure NetApp Files を使用して、 SQL Server クラスタのデータベースおよびファイル共有監視をホストできるようになりました。</block>
  <block id="4d6ec76303888bc681d543d1f4593c55" category="list-text">アプリケーションの応答時間を短縮し、 99.9999% の可用性を実現して、必要なときに必要な場所で SQL Server データにアクセスできるようにします。</block>
  <block id="408e4b7fbec4ba85e097b9393d2b27a7" category="list-text">シンプルで瞬時のサイズ変更により、 SQL Server の導入と、 RAID ストライピングなどの継続的な管理の全体的な複雑さを緩和できます。</block>
  <block id="41642b38214243168d907d92759dde36" category="list-text">インテリジェントな運用機能を利用すれば、 SQL Server データベースを数分で導入し、開発サイクルを短縮できます。</block>
  <block id="61a32d891a5f7bca599a014bc56eec61" category="list-text">Azure クラウドが移行先である場合、最適化された導入に最適なストレージ解決策は Azure NetApp Files です。</block>
  <block id="4db58285a0e634acd6843c40f7a6f4e0" category="paragraph">このドキュメントに記載されている情報の詳細については、次の Web サイトのリンクを参照してください。</block>
  <block id="d53a72004974ee8431ee292856c0bba3" category="list-text">Azure NetApp Files を使用した解決策アーキテクチャ</block>
  <block id="653ba0610595f0695c3ceb2c59afed59" category="inline-link"><block ref="653ba0610595f0695c3ceb2c59afed59" category="inline-link-rx"></block></block>
  <block id="d5ec9321fb49816034de6b296ef6baa2" category="paragraph"><block ref="d5ec9321fb49816034de6b296ef6baa2" category="inline-link-rx"></block></block>
  <block id="ba110408cece764b57b56f1129b3ba2e" category="list-text">Azure NetApp Files for SQL Server の導入のメリット</block>
  <block id="62b5dbc436fc2540c46476bd8e484c11" category="inline-link"><block ref="62b5dbc436fc2540c46476bd8e484c11" category="inline-link-rx"></block></block>
  <block id="44594562b4f528fe8d864bd3f48ddff6" category="paragraph"><block ref="44594562b4f528fe8d864bd3f48ddff6" category="inline-link-rx"></block></block>
  <block id="7aa91f5f0414f1488ce2f5324e63d12e" category="list-text">『 SQL Server on Azure Deployment Guide Using Azure NetApp Files 』を参照してください</block>
  <block id="9021ea474df74856b145a78c58c35e05" category="inline-link"><block ref="9021ea474df74856b145a78c58c35e05" category="inline-link-rx"></block></block>
  <block id="52a5313d9aca117b5d167e6be79c5bc7" category="paragraph"><block ref="52a5313d9aca117b5d167e6be79c5bc7" category="inline-link-rx"></block></block>
  <block id="49217b0d4a68c88899c93d24203a34b4" category="list-text">耐障害性、高可用性、 Azure NetApp Files との耐障害性を備えています</block>
  <block id="9e5e063336d276080a054861016aadd8" category="inline-link"><block ref="9e5e063336d276080a054861016aadd8" category="inline-link-rx"></block></block>
  <block id="7ff89d0ad939652d37cbab9b6f420f65" category="paragraph"><block ref="7ff89d0ad939652d37cbab9b6f420f65" category="inline-link-rx"></block></block>
  <block id="a2810b66f557bf43f1c602ecfe7f52b1" category="summary">このドキュメントでは、 Azure NetApp Files で Azure 仮想マシンを利用して SQL Server Always On 可用性グループ（ AOAG ）をリアルタイムで導入する方法について説明します。</block>
  <block id="0ecccb1d48727b6da357728efe7b6375" category="doc">TR-4877 ：『 SQL Server on Azure NetApp Files - Real Deployment View 』</block>
  <block id="4eae423bbc6520b4a8fa4d0d4de28b8a" category="paragraph">ネットアップ、 Niyaz Mohamed</block>
  <block id="8ae2b9aab28b6c00df7581f99f9211ef" category="paragraph">IT 組織は絶えず変化しています。Gartner のレポートでは、すべてのデータベースのほぼ 75% が 2022 年までにクラウドベースストレージが必要になると報告されています。Microsoft SQL Server は、業界をリードするリレーショナルデータベース管理システム（ RDBMS ）として、 Windows プラットフォームで設計されたアプリケーションや組織に最適です。エンタープライズリソースプランニング（ ERP ）から分析、コンテンツ管理まで、 SQL Server に依存します。SQL Server は、大規模なデータセットを管理する方法を変革し、アプリケーションを強化して、スキーマやクエリのパフォーマンスの要求に対応できるようにしました。</block>
  <block id="eae371fd2d593d80849fab02c4e8b90b" category="paragraph">ほとんどの IT 組織は、クラウドファーストのアプローチを採用しています。変革フェーズにあるお客様は、現在の IT 環境を評価し、評価と調査の演習に基づいてデータベースワークロードをクラウドに移行します。柔軟性 / バースト性、データセンターの終了、データセンターの統合、サポート終了シナリオ、合併、合併など、お客様をクラウドへ移行させる要因には次のものがあります。 買収など。移行の理由は、組織ごとの優先事項と、それぞれのビジネスの優先事項によって異なります。クラウドに移行する際には、 SQL Server データベースクラウドの導入を有効に活用するために、適切なクラウドストレージを選択することが非常に重要です。</block>
  <block id="f9468c81b3d59ac0030570c4f58e95f1" category="section-title">ユースケース</block>
  <block id="cf8b0bda1e058c1f8383f434c4da9b71" category="paragraph">SQL Server 環境を Azure に移行し、 SQL Server を Azure の膨大なプラットフォームサービス（ PaaS ）機能（ Azure Data Factory 、 Azure IoT Hub 、 Azure Machine Learning など）と統合することで、デジタル変革をサポートするための大きなビジネス価値が生まれます。また、クラウドを採用することで、各事業部門は、 CAPEX モデルや従来のプライベートクラウドモデルに頼らずに、生産性に重点を置き、新機能や拡張機能（ DevTest ユースケース）をより迅速に提供することができます。このドキュメントでは、 Azure NetApp Files で Azure 仮想マシンを利用して SQL Server Always On 可用性グループ（ AOAG ）をリアルタイムで導入する方法について説明します。</block>
  <block id="239a02aaaf9289a3093f682835f65f88" category="paragraph">Azure NetApp Files は、継続的な可用性が確保されたファイル共有を備えたエンタープライズクラスのストレージを提供しますSQL Server の本番用データベースの SMB ファイル共有には、継続的可用性を備えた共有が必要です。これにより、コントローラのアップグレードや障害などのシステム停止を伴うシナリオにおいて、ノードは常にデータベースストレージにアクセスできます。継続的な可用性が確保されたファイル共有により、ストレージノード間でデータをレプリケートする必要がなくなります。Azure NetApp Files は、 SMB 3.0 のスケールアウト、永続的ハンドル、透過的なフェイルオーバー機能を使用して、計画的停止と計画外停止の間のノンストップオペレーション（ NDO ）をサポートします。これには、多くの管理タスクが含まれます。</block>
  <block id="f47a858d79de9725a0d6881541748e9b" category="paragraph">クラウドへの移行を計画する場合は、常に最適な使用方法を評価する必要があります。アプリケーション移行で最も一般的かつ簡単なアプローチはリホスト（リフトアンドシフトとも呼ばれます）です。このドキュメントの例では、リホスト方法を使用しています。Azure NetApp Files を使用した Azure 仮想マシン上の SQL Server では、オンプレミスのハードウェアを管理しなくても、クラウド上で SQL Server のフルバージョンを使用できます。SQL Server 仮想マシン（ VM ）は、従量課金制でもライセンスコストを簡易化し、開発、テスト、環境の更新シナリオ向けに柔軟性とバースト性の高い機能を提供します。</block>
  <block id="64899c745691f41e5b1dc01d3a4487d2" category="summary">このセクションでは、クラウドで Azure NetApp Files を SQL Server に使用する場合に考慮する必要があるさまざまな問題について説明します。</block>
  <block id="bb4695a70b92668f0a7927d04580db60" category="doc">考慮すべき要因</block>
  <block id="4dd91c7652639dacea041fe6033e2627" category="section-title">VM パフォーマンス</block>
  <block id="e6ac657ee6eac68b739c5cc437863922" category="inline-link">メモリの最適化</block>
  <block id="68e5d4a238cdfe033afa141123484499" category="paragraph">パブリッククラウドのリレーショナルデータベースのパフォーマンスを最適化するには、適切な VM サイズを選択することが重要です。Microsoft では、オンプレミスサーバ環境の SQL Server と同じデータベースパフォーマンス調整オプションを引き続き使用することを推奨しています。使用<block ref="187f54af8632f4f6696d6052e8b74aec" category="inline-link-rx"></block> SQL Server ワークロードのパフォーマンスを最適化するための VM サイズ。既存の導入環境のパフォーマンスデータを収集し、適切なインスタンスを選択しながら RAM と CPU の利用率を確認します。ほとんどの導入環境では、 D 、 E 、または M シリーズのいずれかを選択できます。</block>
  <block id="8b2db846b8ed65b2919d93a68b819a43" category="list-text">SQL Server ワークロードのパフォーマンスを最大限に高めるには、メモリに最適化された VM サイズを使用します。</block>
  <block id="32a3b4d7b7e6cf1ecde48636119e0288" category="list-text">ネットアップと Microsoft は、適切なメモリと VCORE の比率に基づいてインスタンスタイプを選択する前に、ストレージのパフォーマンス要件を特定することを推奨しています。これは、適切なネットワーク帯域幅を備えた低いインスタンスタイプを選択して、 VM のストレージスループットの制限に克服するのにも役立ちます。</block>
  <block id="0abdff1d9e33eca61c14ccafe8012cd5" category="section-title">VM の冗長性</block>
  <block id="9fecd525b2d9ad39ac38bbfc4d05ee17" category="inline-link">可用性セット</block>
  <block id="26075dbb6cfad683e0d9bd0d29c570b8" category="inline-link">可用性ゾーン</block>
  <block id="e936e004eab3eccfc1e7f46a3187dfd1" category="paragraph">冗長性と高可用性を高めるには、 SQL Server VM を同じにする必要があります<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> または別のものです<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>。Azure VM を作成する場合は、アベイラビリティセットとアベイラビリティゾーンのどちらかを設定する必要があります。 Azure VM を両方に含めることはできません。</block>
  <block id="94eeeae1e60f97a446e8c4f69d6d6f43" category="paragraph">高可用性を実現するには、 SQL Server AOAG または Always On フェイルオーバークラスタインスタンス（ FCI ）を構成することを推奨します。AOAG の場合、これには仮想ネットワーク内の Azure Virtual Machine 上の SQL Server の複数のインスタンスが含まれます。データベースレベルで高可用性が必要な場合は、 SQL Server 可用性グループを設定することを検討してください。</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">ストレージ構成</block>
  <block id="fa32aac4116ce1980c311f004157a133" category="paragraph">Microsoft SQL Server では、ストレージオプションとして SMB ファイル共有を導入できます。SQL Server 2012 以降、システムデータベース（マスター、モデル、 msdb 、または tempdb ）、 およびユーザデータベースは、ストレージオプションとして Server Message Block （ SMB ；サーバメッセージブロック）ファイルサーバとともにインストールできます。この環境は、 SQL Server のスタンドアロンと SQL Server FCI の両方に対応しています。</block>
  <block id="250548ef00796e6a203215b1d550bb0d" category="admonition">SQL Server データベース用のファイル共有ストレージでは、継続的可用性がサポートされている必要があります。これにより、ファイル共有データに中断なくアクセスできます。</block>
  <block id="45a6af9c92529e3da9ccdbeae9d692ac" category="paragraph">Azure NetApp Files は、あらゆる要求の厳しいワークロードに対応できる高性能なファイルストレージを提供し、ブロックストレージソリューションに比べて SQL Server の TCO を削減します。ブロックストレージでは、 VM の I/O およびディスク処理の帯域幅に制限があり、ネットワーク帯域幅の制限だけが Azure NetApp Files に適用されます。つまり、 Azure NetApp Files には VM レベルの I/O 制限は適用されません。これらの I/O 制限がない場合、 Azure NetApp Files に接続された小規模な VM で SQL Server を実行することも、はるかに大規模な VM で SQL Server を実行することもできます。Azure NetApp Files は、コンピューティングとソフトウェアのライセンスコストを削減することで、 SQL Server の導入コストを削減します。Azure NetApp Files for SQL Server 環境を使用することによるコスト分析とパフォーマンス上のメリットの詳細については、を参照してください<block ref="458fda910151e8d66385b2aabb6cd60e" category="inline-link-rx"></block>。</block>
  <block id="9d2b7eb8bc76e60b0d9cd237d67a34fb" category="paragraph">Azure NetApp Files for SQL Server を使用する利点は次のとおりです。</block>
  <block id="8ee22743237d82e9adc18a596977a138" category="list-text">Azure NetApp Files を使用すると、インスタンスを小さくしてコンピューティングコストを削減できます。</block>
  <block id="3de639403ea86ae87a5883d359deb4ab" category="list-text">また、 Azure NetApp Files はソフトウェアライセンスコストを削減し、全体的な TCO を削減します。</block>
  <block id="46790c8fe72176f6262b4b5531482ee5" category="list-text">ボリュームを再構築して動的なサービスレベル機能を利用すると、安定状態のワークロードのサイジングを行い、オーバープロビジョニングを回避することでコストを最適化できます。</block>
  <block id="860d93b2ef30525111fa6440bf4d5bd7" category="list-text">冗長性と高可用性を高めるには、 SQL Server VM を同じにする必要があります<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> または違う<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>。ユーザ定義のデータファイルが必要な場合は、ファイルパスの要件を考慮してください。その場合は、 SQL FCI over SQL AOAG を選択します。</block>
  <block id="c6fbfcd868e29e37e88eaeff82a7f430" category="inline-link">\\ANFSMB-b4ca.anf.test\sqldb および \\ANFSMB-b4ca.anf.test\sqldb\</block>
  <block id="e2bed4e218692d056237b3ae3d24293c" category="list-text">次の UNC パスがサポートされます。<block ref="cb8cdd6ee3ebeed12086142f1a66cc3e" category="inline-link-rx"></block>。</block>
  <block id="0b4d3828f5dae91cd27e48bffa786d91" category="list-text">ループバック UNC パスはサポートされていません。</block>
  <block id="db3d2f4f54b992af225801eb51ea7387" category="list-text">サイジングには、オンプレミス環境の履歴データを使用します。OLTP ワークロードの場合は、ワークロードの平均時間とピーク時間、ディスク読み取り回数 / 秒、ディスク書き込み回数 / 秒のパフォーマンスカウンタを使用して、ターゲット IOPS とパフォーマンス要件を一致させます。Data Warehouse および Reporting のワークロードの場合は、ワークロードの平均時間とピーク時間、およびディスクの読み取りバイト数 / 秒とディスクの書き込みバイト数 / 秒を使用して、ターゲットのスループットを調整します平均値は、ボリュームの形状変更機能と組み合わせて使用できます。</block>
  <block id="da3259c6aa3dafdc8ca15c687022a5cd" category="section-title">継続的可用性を備えた共有を作成</block>
  <block id="f7ee3eee4fa679986e37911272d13a29" category="inline-link">継続的可用性を備えた共有を作成しています</block>
  <block id="de7d92d6f4ac1f140ac05886ec017f09" category="paragraph">Azure ポータルまたは Azure CLI を使用して、継続的可用性を備えた共有を作成する。ポータルで、 [ 継続的な可用性を有効にする ] プロパティオプションを選択します。Azure CLI では、「 azz netappfiles volume create with the sm-continuously-available - AVL 」オプションを「 $True 」に設定して、共有を継続的可用性を備えた共有として指定します。継続的可用性を有効にした新しいボリュームの作成の詳細については、を参照してください<block ref="86e4b436e8054cc83fccec640f98e218" category="inline-link-rx"></block>。</block>
  <block id="9a3932b7bdfdbb892087fd595ec7acb9" category="list-text">次の図に示すように、 SMB ボリュームの継続的可用性を有効にします。</block>
  <block id="c012fe8c05a3d9875a4f87cee09d1ca9" category="list-text">管理者以外のドメインアカウントを使用する場合は、そのアカウントに必要なセキュリティ権限が割り当てられていることを確認してください。</block>
  <block id="762783478495f0889d01a59db256f92c" category="list-text">共有レベルで適切な権限を設定し、適切なファイルレベルの権限を設定します。</block>
  <block id="bfb74db6a55528f52e8ecb83a507a043" category="inline-link">既存の SMB ボリュームを継続的可用性を使用するように変換します</block>
  <block id="3cad4a4fcd378074292bfc2ff45fd4ca" category="list-text">既存の SMB ボリュームでは継続的可用性プロパティを有効にできません。既存のボリュームを変換して継続的な可用性が確保された共有を使用するには、 NetApp Snapshot テクノロジを使用します。詳細については、を参照してください<block ref="25dc0603f84029cfd15a97a37903a54c" category="inline-link-rx"></block>。</block>
  <block id="015dd90c833178044ff327aee63f72ec" category="paragraph"><block ref="015dd90c833178044ff327aee63f72ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">パフォーマンス</block>
  <block id="ee38206503545cf54ad072dee7f8ab1a" category="paragraph">Azure NetApp Files は、 Standard （テラバイトあたり 16mbps ）、 Premium （テラバイトあたり 64MBps ）、 Ultra （テラバイトあたり 128MBps ）の 3 つのサービスレベルをサポートします。データベースワークロードのパフォーマンスを最適化するには、適切なボリュームサイズをプロビジョニングすることが重要です。Azure NetApp Files では、ボリュームのパフォーマンスとスループット制限は次の要素の組み合わせに基づいて決まります。</block>
  <block id="b87f5218989e854f2889f939a4e2ec06" category="list-text">ボリュームが属する容量プールのサービスレベル</block>
  <block id="9320cce40e9ab4d677bfcc78eddc64d5" category="list-text">ボリュームに割り当てられているクォータ</block>
  <block id="2d98af90367bed299b95066a85be0a17" category="list-text">容量プールのサービス品質（ QoS ）タイプ（ auto または manual ）</block>
  <block id="a6f08c2897faaf4d449d71d87f473ff1" category="inline-link">Azure NetApp Files のサービスレベル</block>
  <block id="ac56170d8576092b90989d467f2d383e" category="paragraph">詳細については、を参照してください<block ref="1e8ed0f384e427209ce2e9dfbaed249d" category="inline-link-rx"></block>。</block>
  <block id="79bcc7c0be7625b4b6b95ac8189ec45e" category="paragraph"><block ref="79bcc7c0be7625b4b6b95ac8189ec45e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">パフォーマンスの検証</block>
  <block id="af3948d0fe6860f3a865cd04abebc009" category="inline-link">SQL Server Storage Benchmark （ SB ）ツール</block>
  <block id="01384acc34d886b9383610a7494ca75a" category="paragraph">あらゆる導入同様、 VM とストレージをテストすることが重要です。ストレージの検証には、 HammerDB 、 Apploader 、などのツールを使用します<block ref="df8d6ca8d2831e94c0812b2b971f8958" category="inline-link-rx"></block>、または適切な読み取り / 書き込み混在の任意のカスタムスクリプトまたは fio を使用する必要があります。ただし、 SQL Server のワークロードのほとんどは、ビジー状態の OLTP ワークロードでも、読み取りが 80~90% 、書き込みが 10~20% 近くになることに注意してください。</block>
  <block id="10fde396dd4a669ec17689dd7cf8b599" category="paragraph">パフォーマンスを確認するために、 Premium サービスレベルを使用してボリュームに対してクイックテストを実行しました。このテストでは、ボリュームサイズを 100GB から 2TB にオンザフライで拡張しました。アプリケーションへのアクセスを中断することなく、データの移行もゼロでした。</block>
  <block id="6fab14b7b6a90422e865a3b09497edaa" category="paragraph"><block ref="6fab14b7b6a90422e865a3b09497edaa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eedfe317eed7692e9d95ba36177a80e9" category="paragraph">ここでは、 HammerDB を使用して導入した、リアルタイムのパフォーマンステストの別の例を示します。このテストでは、 vCPU 8 個、 500GB Premium SSD 、 500GB SMB Azure NetApp Files ボリュームを含む小規模インスタンスを使用しました。HammerDB は、 80 のウェアハウスと 8 人のユーザで構成されています。</block>
  <block id="c365893719ad3de45f14fa9c19408eca" category="paragraph">次のグラフから、 Azure NetApp Files では、 1 分あたりのトランザクション数が 2.6x で、同等のサイズのボリューム（ 500GB ）を使用した場合のレイテンシが 4 分の 1 に削減されたことがわかります。</block>
  <block id="d50d666921da97fdc14e35f752474e41" category="paragraph">さらに、 vCPU が 32 個、 Azure NetApp Files が 16TB の大容量インスタンスへのサイズ変更によって、テストを実施しました。1 分あたりのトランザクション数は大幅に増加し、レイテンシは常に 1 ミリ秒に抑えられました。HammerDB は、このテストで 80 個のウェアハウスと 64 人のユーザで構成されました。</block>
  <block id="3b38e0407e747349840c72259c5da930" category="paragraph"><block ref="3b38e0407e747349840c72259c5da930" category="inline-image-macro-rx" type="image"></block></block>
  <block id="892725223bbd64ebec595545eeaf8c28" category="paragraph">Azure NetApp Files を使用すると、ボリュームのサイズを透過的に無停止で変更でき、ダウンタイムやアプリケーションへの影響なしでサービスレベルを変更できます。これは、動的なコスト管理が可能な独自の機能で、ピーク時の指標を使用してデータベースのサイジングを行う必要を回避できます。安定した状態のワークロードを利用できるため、初期投資が不要になります。ボリュームの形状変更とサービスレベルの動的変更を使用すると、データアクセスを維持しながら、 I/O を一時停止することなく、 Azure NetApp Files ボリュームの帯域幅とサービスレベルをほぼ瞬時にオンデマンドで調整できます。</block>
  <block id="44aaafbc17f2a4fcbd6d52e1c8ee0cae" category="paragraph">LogicApp や関数などの Azure PaaS ソリューションを使用すると、特定の webhook または alert ルールトリガーに基づいてボリュームのサイズを簡単に変更し、ワークロードの要件を満たしながらコストを動的に処理できます。</block>
  <block id="d613d5e1ef7a7f52eed191ef1066a08a" category="paragraph">たとえば、安定した動作に 250Mbps のデータを必要とするデータベースがありますが、 400Mbps のピークスループットも必要とします。この場合、安定したパフォーマンスの要件を満たすために、 Premium サービスレベルに 4TB ボリュームを追加して導入する必要があります。ピーク時のワークロードに対処するには、 Azure の機能を使用して特定の期間でボリュームサイズを 7TB に増やしてから、導入コストを抑えるためにボリュームのサイズを縮小します。この構成では、ストレージのオーバープロビジョニングを回避できます。</block>
  <block id="6ff1dafebf930a9c5fef12bf43046987" category="sidebar">エンタープライズアプリケーションとデータベース</block>
  <block id="e340bc103d02ce2b8e016eb60705029c" category="sidebar">SAP と SAP HANA に対応しています</block>
  <block id="760b7d532df381143dc946fd59bf0b62" category="sidebar">Azure NetApp Files 上の SQL Server</block>
  <block id="61def2ac347af2f10fd60cd67052a311" category="sidebar">リファレンス・デザイン（リアルタイムの高レベル設計）</block>
  <block id="45ab5f50e70c77a29d7191bf77c1ea15" category="paragraph">ハイブリッドクラウド、デスクトップ仮想化、およびコンテナソリューションの特定の機能を紹介するビデオとデモをご覧ください。</block>
  <block id="3699cb747ce71b2fed488fef61ad35be" category="inline-link-macro">ワークロードの移行 - ネットアップを使用した Red Hat OpenShift</block>
  <block id="4c37a5afd480a0042f69d7628cadd57d" category="summary">ネットアップを使用した Red Hat OpenShift での Kubernetes 向けの高度なクラスタ管理</block>
  <block id="43288d8129021b1fe8b4bc6784e65b32" category="doc">機能：ネットアップを使用した Red Hat OpenShift での Kubernetes 向けの高度なクラスタ管理</block>
  <block id="d10b633b8bd8d022c66a52d93e0ed6ce" category="section-title">クラスタのライフサイクル管理</block>
  <block id="8b9449bdfc859a900fc4da7c79420145" category="paragraph">さまざまな OpenShift クラスタを管理するには、クラスタを作成するか、 Advanced Cluster Management にインポートします。</block>
  <block id="0becde0fcfda03aec9c722d042326324" category="list-text">新しい OpenShift クラスタを作成するには、次の手順を実行します。</block>
  <block id="50dfc508091b37338da8357e63e6a405" category="image-alt">プロバイダ接続を追加します</block>
  <block id="2984cab36bd51d5446963e671e808f5d" category="image-alt">クラスタを追加</block>
  <block id="e6d9a6b38dd36fd9870260249ba5fc1f" category="list-text">既存のクラスタをインポートするには、次の手順を実行します。</block>
  <block id="9a618414b83afe67c19abcf935be6dbd" category="image-alt">既存のクラスタをインポートする</block>
  <block id="c812d1382d834648706b3bf1e6848135" category="list-text">複数のクラスタを作成してインポートしたら、 1 つのコンソールからクラスタを監視および管理できます。</block>
  <block id="068e5ec1cc0eaa7c2596be7eb1b40194" category="inline-link-macro">次の項目：機能 - アプリケーションライフサイクル管理。</block>
  <block id="0405bd6ea905b8d563fd501d933a3e51" category="paragraph"><block ref="0405bd6ea905b8d563fd501d933a3e51" category="inline-link-macro-rx"></block></block>
  <block id="31fd0c2c8d388a4cd2c6459234743476" category="section-title">オブザーバビリティ</block>
  <block id="7a6ccefec75a946583cffdd0a8a47e09" category="image-alt">オブザーバビリティホームページ</block>
  <block id="4a973ae1a908770e354f949d3c0592f8" category="image-alt">ポッドを確認します</block>
  <block id="8a373f777de729c082b5be2d80b7eca6" category="image-alt">ノードを監視します</block>
  <block id="2ececa2c251a851a85e976daae558c81" category="image-alt">クラスタを確認します</block>
  <block id="a883982d5f8961021329c238318d4e2b" category="inline-link-macro">次の手順：機能 - リソースを作成します。</block>
  <block id="5ca146f2101c14a961df161060f86cb9" category="paragraph"><block ref="5ca146f2101c14a961df161060f86cb9" category="inline-link-macro-rx"></block></block>
  <block id="de59be6e44d20d9dd12412571b745c5f" category="section-title">アプリケーションのライフサイクル管理</block>
  <block id="fa19c463235a810b3a93333d6ee51d6c" category="paragraph">アプリケーションを作成して一連のクラスタ全体で管理するには、</block>
  <block id="6b41f909eb299f214abfb15580583456" category="image-alt">アプリケーションを作成します</block>
  <block id="bcb3e5b76f189a87ea350550f86de83f" category="list-text">アプリケーションコンポーネントがインストールされると、アプリケーションがリストに表示されます。</block>
  <block id="d70fc022d09a33f4044c81cd670a71b6" category="image-alt">アプリケーションリスト</block>
  <block id="672d326704c3be4bebf6c816a48495e7" category="list-text">これで、アプリケーションをコンソールから監視および管理できるようになります。</block>
  <block id="0787d747a308cc786b50363313ccf714" category="inline-link-macro">次のステップ：機能 - ガバナンスとリスク</block>
  <block id="f4c7ffc89dab76d5a6dccad54114c204" category="paragraph"><block ref="f4c7ffc89dab76d5a6dccad54114c204" category="inline-link-macro-rx"></block></block>
  <block id="06fdae3f02fee5cbe172f1574564c925" category="doc">Kubernetes 向けの高度なクラスタ管理：ネットアップを使用した Red Hat OpenShift</block>
  <block id="30c15b5a84f4fb26cd25b38dc787b22d" category="paragraph">コンテナ化されたアプリケーションを開発環境から本番環境に移行する際、多くの組織では、そのアプリケーションのテストと導入をサポートするために複数の Red Hat OpenShift クラスタが必要になります。この機能を利用することで、多くの組織は、 OpenShift クラスタ上で複数のアプリケーションやワークロードをホストしています。そのため、組織ごとにクラスタのセットを管理する必要があり、 OpenShift の管理者は、複数のオンプレミスデータセンターとパブリッククラウドにまたがるさまざまな環境で複数のクラスタを管理および管理するという新たな課題に直面する必要があります。これらの課題に対処するために、 Red Hat は Kubernetes 向けの高度なクラスタ管理機能を導入しました。</block>
  <block id="a7516c278242a08b85090e24cbf67218" category="paragraph">Red Hat OpenShift クラスタに Red Hat Advanced Cluster Management for Kubernetes をアドオンとしてインストールし、このクラスタをすべての処理の中央コントローラとして使用します。このクラスタはハブクラスタと呼ばれ、ユーザが Advanced Cluster Management に接続するための管理プレーンを公開します。Advanced Cluster Management コンソールからインポートまたは作成されたその他のすべての OpenShift クラスタは、ハブクラスタによって管理され、管理対象クラスタと呼ばれます。Klusterlet というエージェントを管理対象クラスタにインストールし、ハブクラスタに接続し、クラスタライフサイクル管理、アプリケーションライフサイクル管理、オブザーバビリティ、およびセキュリティコンプライアンスに関連するさまざまなアクティビティの要求を処理します。</block>
  <block id="b1000f23e43dfac19b53c74d7ebe66c8" category="image-alt">ACM アーキテクチャ</block>
  <block id="a376445fd812a7fa27714e6b11bc6163" category="paragraph">詳細については、のドキュメントを参照してください<block ref="50c0dc50e188cf3a7847d9a813fd829e" category="inline-link-rx"></block>。</block>
  <block id="a99137a02f570225903b02b175e289a4" category="paragraph"><block ref="a99137a02f570225903b02b175e289a4" category="inline-link-macro-rx"></block></block>
  <block id="7c613b296892d4712b9041d3081282f8" category="summary">ネットアップを使用した Red Hat OpenShift での Kubernetes 向けの高度なクラスタ管理。</block>
  <block id="78e1aefe2bbb2518f1156636e761e479" category="paragraph">OpenShift クラスタに Kubernetes 向けの高度なクラスタ管理をインストールするには、次の手順を実行します。</block>
  <block id="b17056cdbd9ec695d4348e1ad799ace4" category="list-text">OpenShift クラスタをハブクラスタとして選択し、 cluster-admin 権限でログインします。</block>
  <block id="2e5d3941e033e96d5317cc2bbd1da914" category="image-alt">ACM タイル</block>
  <block id="cc5a9dd5971b8369354db684e5dbfe2b" category="image-alt">ACM タイルの詳細</block>
  <block id="72b342ddabad6a9ec11df82389c40b88" category="image-alt">ACM オペレータタイルを取り付ける</block>
  <block id="64524f91c2fdfcd54b4bbcab35392908" category="image-alt">ACM オペレータのインストールが進行中です</block>
  <block id="e0d84ec6a5b8f92909a7a3bef11455c1" category="image-alt">ACM オペレータのマルチクラスターハブ</block>
  <block id="344f0cb43d1b2e7a719bea808fe7c5bf" category="image-alt">マルチクラスタハブ画面を作成します</block>
  <block id="851548d1ad843a23609f325e8b54e72d" category="image-alt">ACM オペレータが取り付けられている</block>
  <block id="c7aa79f0c31ac15d728ee47c7e6eaee2" category="image-alt">マルチクラスタハブ対応</block>
  <block id="f761fad3f1c25e94d5f46ebd9e23a901" category="image-alt">ACM コンソールルート</block>
  <block id="4488e277b96ae08def5eb77c2d8c6e74" category="inline-link-macro">次のページ：機能 - クラスタのライフサイクル管理。</block>
  <block id="8a4d50965d8a3c708bdb16a716d64246" category="paragraph"><block ref="8a4d50965d8a3c708bdb16a716d64246" category="inline-link-macro-rx"></block></block>
  <block id="ddb9608f0f25d56d00a539a63333efa0" category="list-text"><block ref="ddb9608f0f25d56d00a539a63333efa0" category="inline-link-macro-rx"></block></block>
  <block id="86c2cc4630e619e2c08c32f54e844297" category="section-title">複数のクラスタにリソースを作成する</block>
  <block id="24800112d59462f8ea9ff03f5dd456a7" category="image-alt">リソースを作成する</block>
  <block id="5568d55567785f154c987872c1684bfa" category="doc">ワークロードの移行：ネットアップを使用した Red Hat OpenShift</block>
  <block id="f41043c73a62a435944d8abfb45094cb" category="list-text">管理対象クラスタの Red Hat OpenShift クラスタ（バージョン 4.4.4 よりも大きい）</block>
  <block id="374185e020d06ceed3f020af518a1c14" category="list-text">Kubernetes 向けの Advanced Cluster Management 向けの Red Hat サブスクリプション</block>
  <block id="9afcd045ce0197d71ba631e3fbe43095" category="paragraph">高度なクラスタ管理は OpenShift クラスタのアドオンであるため、ハブクラスタと管理対象クラスタで使用される機能に基づいて、ハードウェアリソースには一定の要件と制限があります。クラスタのサイジングを行う際は、これらの問題について考慮する必要があります。のドキュメントを参照してください<block ref="a5d2b81b971715f092f7296621743e22" category="inline-link-rx"></block> 詳細：</block>
  <block id="65a62318377ddbc5fe3f73548dc3d677" category="paragraph">オプションで、ハブクラスタにインフラストラクチャコンポーネントをホストする専用ノードがあり、それらのノードにのみ Advanced Cluster Management リソースをインストールする場合は、それに応じてそれらのノードに公差とセレクタを追加する必要があります。詳細については、のドキュメントを参照してください<block ref="df4d7b25534e8f26e8ab3acc1c646101" category="inline-link-rx"></block>。</block>
  <block id="3f71071db67a1d6b5b63e2d9cc6b0e93" category="inline-link-macro">次の手順：インストール。</block>
  <block id="2a9cc50366c16ec40c1a5132f8fe5533" category="paragraph"><block ref="2a9cc50366c16ec40c1a5132f8fe5533" category="inline-link-macro-rx"></block></block>
  <block id="03cae7751c31cc76a90cf5e94e86eb3a" category="section-title">ガバナンスとリスク</block>
  <block id="9d7264067197bc9ff368288f98750fd6" category="paragraph">この機能を使用すると、異なるクラスタのコンプライアンスポリシーを定義し、それらのクラスタが準拠していることを確認できます。ポリシーを設定して、ルールの逸脱や違反について通知したり修正したりできます。</block>
  <block id="f6262e5369e2b989638aaa9d4f333d91" category="image-alt">コンプライアンスポリシーを作成します</block>
  <block id="0a1575621f2b12d5216e6d1c95eed2e6" category="list-text">必要なポリシーをすべて設定したら、 Advanced Cluster Management でポリシーやクラスタの違反を監視して修正できます。</block>
  <block id="38c080ff2128a92954fb61942ea497c0" category="image-alt">ポリシーの監視</block>
  <block id="465d1c9d2d9ea711e43e2e20077e10f9" category="inline-link-macro">次の機能 - 観察性。</block>
  <block id="056789fad8ccaddf0ac3b4ef0a68b61a" category="paragraph"><block ref="056789fad8ccaddf0ac3b4ef0a68b61a" category="inline-link-macro-rx"></block></block>
  <block id="119ad672b0d69ab3f968877b6ec83dd3" category="list-text"><block ref="119ad672b0d69ab3f968877b6ec83dd3" category="inline-link-macro-rx"></block></block>
  <block id="25a72d771c3846ba4da8732220f7a588" category="sidebar">エンタープライズアプリケーションデータベース</block>
  <block id="d313887d8fa4b2493a50d1e00bad440e" category="sidebar">アプリケーションライフサイクル管理</block>
  <block id="f55899cffbf639043209795d5a1af970" category="sidebar">リソースの作成</block>
  <block id="c8d20ce0b6bb23d912f3368f706d5794" category="summary">ネットアップのソリューションは、お客様の最も重要なビジネスニーズをサポートするためにネットアップの製品とサービスのポートフォリオを強調する、戦略的機能とテクノロジ機能のセットです。</block>
  <block id="a4957cf974ce20219897bbbf5b131cb8" category="paragraph">管理者は、プロジェクトのニーズやストレージシステムモデルに基づいて複数のストレージバックエンドを構成し、圧縮、特定のディスクタイプ、 QoS レベルなどの高度なストレージ機能を有効にして一定のレベルのパフォーマンスを保証できます。定義されたバックエンドは、プロジェクトの開発者が永続的ボリューム要求（ PVC ）を作成し、永続的ストレージをオンデマンドでコンテナに接続するために使用できます。</block>
  <block id="b62bb4786ef52ad76706950add6991dd" category="paragraph">20.04 リリース以降、 Trident のセットアップは Trident オペレータによって実行されます。オペレータが大規模な導入を容易にし、 Trident インストールの一部として導入されたポッドの自己修復などの追加サポートを提供します。</block>
  <block id="3ce67d5de6974f67e0048e6fdbf89498" category="admonition">場合によっては、お客様の環境で Trident の導入のカスタマイズが必要になることもあります。このような場合は、 Trident のオペレータを手動でインストールし、含まれているマニフェストを更新して配置をカスタマイズすることもできます。</block>
  <block id="1315b42a551dafb715ab654d8eb5af40" category="list-text">Trident にはこのファイルを渡すオプションがないため、まず、ユーザクラスタの「 kubeconfig 」ファイルの場所を環境変数として設定します。</block>
  <block id="693642fbb464db49c22715a536e99c3f" category="paragraph">iSCSI プロトコルによるブロックストレージボリュームのマッピングを許可するようにワーカーノードを準備するには、その機能をサポートするために必要なパッケージをインストールする必要があります。</block>
  <block id="cccb85b5e6a9a19187087f71254d1fb2" category="paragraph">Red Hat OpenShift では、 MCO （マシン構成オペレータ）を展開後にクラスタに適用することによって処理されます。</block>
  <block id="7b8e6ef8272a81ebcc108ee3fcf4eac8" category="list-text">OCP Web コンソールにログインし、 [ 計算 ]&gt;[ マシン構成 ] に移動します。[ マシン構成の作成 ] をクリックします。YAML ファイルをコピーして貼り付け、 [ 作成 ] をクリックします。</block>
  <block id="c25282bfd8c140d1f79c25362637f744" category="paragraph">マルチパスを使用しない場合：</block>
  <block id="541c76e8762c84e3e0488f91c8062e08" category="paragraph">マルチパスを使用する場合：</block>
  <block id="d9f036d3b9f84b626f8a777480066cab" category="list-text">構成の作成後、約 20~30 分で設定がワーカーノードに適用され、再ロードされます。「 OC GET MCP 」を使用してマシン構成が適用されているかどうかを確認し、ワーカーのマシン構成プールが更新されていることを確認します。ワーカーノードにログインして、 iscsid サービスが実行されている（マルチパスを使用している場合、 multipathd サービスが実行されている）ことを確認することもできます。</block>
  <block id="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="list-text"><block ref="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="inline-link-macro-rx"></block></block>
  <block id="d7b539d4bc16fbdf1477adddfda6c802" category="list-text"><block ref="d7b539d4bc16fbdf1477adddfda6c802" category="inline-link-macro-rx"></block></block>
  <block id="2e5d36490241211379006b7f6934bf06" category="list-text"><block ref="2e5d36490241211379006b7f6934bf06" category="inline-link-macro-rx"></block></block>
  <block id="25d77826c061b84a0c036f43e02aa129" category="doc">OpenShift Virtualization のインストール：ネットアップでの Red Hat OpenShift</block>
  <block id="762a14964ee1713d320b8beefaf55b17" category="inline-link-macro">ビデオ： Installing OpenShift Virtualization - Red Hat OpenShift with NetApp 』</block>
  <block id="5ac70ba9dc4ef90bfb3a829919c8044d" category="list-text"><block ref="5ac70ba9dc4ef90bfb3a829919c8044d" category="inline-link-macro-rx"></block></block>
  <block id="aad993afc3c78a3a38ae471fa2ae1060" category="inline-link-macro">ビデオ： Deploying a Virtual Machine with OpenShift Virtualization - Red Hat OpenShift with NetApp</block>
  <block id="1c9dc04aa9e0e0aaf52a33af61d8d630" category="list-text"><block ref="1c9dc04aa9e0e0aaf52a33af61d8d630" category="inline-link-macro-rx"></block></block>
  <block id="114856cfc010d937269afe29138175fc" category="doc">OpenShift Virtualization による仮想マシンの導入：ネットアップを使用した Red Hat OpenShift</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">価値</block>
  <block id="bbaff12800505b22a853e8b7f4eb6a22" category="inline-link">連絡先</block>
  <block id="d3db539e5d56da6e251021138c5fe53f" category="section-title">ネットアップと VMware のソリューションの詳細をご確認ください</block>
  <block id="09f93ac387258fa68c085baba3c8fc44" category="inline-link">NetApp &amp;amp; VMware ：より優れた組み合わせ</block>
  <block id="fb758bbc93c23b25607ef41f302d4eef" category="list-text"><block ref="35ef54e3b8ad8ec505bab4b973f86177" category="inline-link-rx"></block></block>
  <block id="b6741313b8f46ab1018ebd6a361c22a4" category="inline-link">ONTAP 9.8 VMware の最新機能の概要</block>
  <block id="d393be6d50183d7362f0adb8bc92ae08" category="list-text"><block ref="d393be6d50183d7362f0adb8bc92ae08" category="inline-link-rx"></block></block>
  <block id="b25a3522acbb33341ccacac99424fcce" category="inline-link">SnapCenter プラグイン for VMware vSphere の活用</block>
  <block id="a65898b7011ddfb663cdba62f90581c6" category="list-text"><block ref="a65898b7011ddfb663cdba62f90581c6" category="inline-link-rx"></block></block>
  <block id="60b0390f50a5ad13d613d49cfe1bce0b" category="inline-link">ネットアップと NVMe で VMware のパフォーマンスを再定義</block>
  <block id="f6dde7f191b6b8f8351902b139ec8672" category="list-text"><block ref="f6dde7f191b6b8f8351902b139ec8672" category="inline-link-rx"></block></block>
  <block id="c576371db342dc9cb166c73b0e157fb5" category="inline-link">AWS 上の VMware クラウド向けの低コストのパフォーマンスを実現する世界です</block>
  <block id="89487ceb1ada10e49befbbaed3b714ec" category="list-text"><block ref="89487ceb1ada10e49befbbaed3b714ec" category="inline-link-rx"></block></block>
  <block id="a88a91878fb958db59873117d16ad078" category="inline-link">仮想デスクトップインフラ（ VDI ）：従業員向けワークステーションをオンデマンドで提供します</block>
  <block id="9467ff6388811a059199513a0a484f0b" category="list-text"><block ref="9467ff6388811a059199513a0a484f0b" category="inline-link-rx"></block></block>
  <block id="d5e64137a19403f8c1c89f50546b82c5" category="inline-link">VMware on AWS ：アーキテクチャとサービスのオプション</block>
  <block id="6cb2c8a80e576f132097e4d28cec24cd" category="list-text"><block ref="6cb2c8a80e576f132097e4d28cec24cd" category="inline-link-rx"></block></block>
  <block id="cd4efd0ada1938b240dd48aa08010f04" category="inline-link">NetApp Cloud Volumes Service API で AWS エクスペリエンスを最適化するためのプログラミング</block>
  <block id="f61369e9428a21eb1090be340ef36f16" category="list-text"><block ref="f61369e9428a21eb1090be340ef36f16" category="inline-link-rx"></block></block>
  <block id="6d14f3ca0f5be54f01fd579906dd80bb" category="inline-link">Kubernetes ： vSphere と Tanzu で Kubernetes を実行する</block>
  <block id="ef8e103737164442c629df5b5d98769d" category="list-text"><block ref="ef8e103737164442c629df5b5d98769d" category="inline-link-rx"></block></block>
  <block id="92061b0dd7904e2299ac65ed9bc2d6af" category="inline-link">ネットアップとともに VMware Tanzu を紹介します</block>
  <block id="ae7c9beb8e4adca6da75607ee83e2403" category="list-text"><block ref="ae7c9beb8e4adca6da75607ee83e2403" category="inline-link-rx"></block></block>
  <block id="7e0caac7f6d493fab662f4f4d65ae213" category="section-title">仮想化データファブリックを構築</block>
  <block id="f1f4041236ed90e2a5e65e9a3c858875" category="section-title">ネットアップの VMware 向け最新ソリューションをご確認ください</block>
  <block id="0e8dd76bc961a90df87833953de6d067" category="inline-link">VMware vSphere と ONTAP ：ネットアップのソリューション</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="inline-link">SnapCenter Plug-in for VMware vSphere</block>
  <block id="730c2cf92bbe409c31ef1f39cf25377a" category="list-text"><block ref="730c2cf92bbe409c31ef1f39cf25377a" category="inline-link-rx"></block></block>
  <block id="c375e5bb7184da46adef700a9a36d674" category="inline-link">ネットアップの最新の NVMeoF VMware vSphere ワークロードの設計と検証</block>
  <block id="b54be27467e63a98d65e6b17a914e373" category="list-text"><block ref="902dd483e9192a0b4645b4c8be7acbff" category="inline-link-rx"></block></block>
  <block id="b860a89f6215a92f2320f0afe4e0ee05" category="inline-link">VMware と SQL Server 向けの、ネットアップの最新の NVMeoF クラウド対応フラッシュ解決策</block>
  <block id="0ebff16085636352cc1aa1e5b0003bdb" category="list-text"><block ref="ac70b8666634dd9095602966c4c61093" category="inline-link-rx"></block></block>
  <block id="eccda9b55035b56259299545d5781136" category="inline-link">VMware Tanzu &amp; ONTAP で Kubernetes への移行を加速</block>
  <block id="bb79e474557eb86fc30118354eef0039" category="list-text"><block ref="5dd92e330c2d45255a2025ee1eedd52d" category="inline-link-rx"></block></block>
  <block id="7f8cf1c43494d40e935f5e99e38ce659" category="inline-link">AWS で VMware Cloud を実行するコストを削減</block>
  <block id="f0d8a1b084d604c4db4319a2c5bbd522" category="list-text"><block ref="f0d8a1b084d604c4db4319a2c5bbd522" category="inline-link-rx"></block></block>
  <block id="7128c22bfdae1fe8be75c9a9ee56eca9" category="inline-link">『 Best Practices for VMware vSphere and NetApp ONTAP 』を参照してください</block>
  <block id="d2fa143a4aaef3477f2edb0d92676341" category="inline-link">VMware 環境 - ONTAP を使用して NVMe-oF で実行しましょう</block>
  <block id="e9c2b8b8a9962013c07f83742ca35f0e" category="inline-link">ONTAP ツールと VMware SRM を使用した VVol のディザスタリカバリ</block>
  <block id="f156fde75de09cf5f045522cf738b2c7" category="inline-link">ONTAP ツールを使用した FlexGroup データストアのプロビジョニングと管理</block>
  <block id="977a548ba3853fdac6d708915a1b752a" category="inline-link">NetApp NFS VAAI プラグインの更新</block>
  <block id="233398cd850d9903958583fd85621f6d" category="inline-link">NetApp ONTAP FlexGroup を使用したスケールアウト仮想デスクトップ</block>
  <block id="e308c2a1dacddb5bc6ffa093081111e4" category="inline-link">データファブリック向けの VMware のバックアップとリカバリ</block>
  <block id="a81738572d94bce863615a7d94a84051" category="inline-link">SnapCenter Plug-in for VMware vSphere によるデータ保護の簡易化</block>
  <block id="c10a86f3b9530baf3bed3b02aaaf873f" category="section-title">柔軟性に優れたハイブリッドクラウドと最新化された VMware 向けアプリケーションインフラを導入できます</block>
  <block id="f20368920280b50131814db2f83fda66" category="inline-link">NetApp All Flash FAS 上での VMware データストアの設計</block>
  <block id="841a1e2733baa662db1207d5075a798f" category="inline-link">自動化 - ONTAP で VMware クラウドを構築しましょう</block>
  <block id="253d309203cf1f2c1bb57255bd0a5bdc" category="inline-link">VMware VM を Google Cloud に移行します</block>
  <block id="3ca2b14e719d79aed66780282e879db4" category="section-title">ネットアップと VMware のエキスパートが支援します</block>
  <block id="20475522c77401af1c203f23942ffda5" category="inline-link">VMware ソリューションディスカッションフォーラムに参加します</block>
  <block id="1dccc60a61431b3ef3f48709a0f68de7" category="list-text"><block ref="1dccc60a61431b3ef3f48709a0f68de7" category="inline-link-rx"></block></block>
  <block id="a5810200dda7a3f37fc7eae5378cc8f3" category="inline-link">ネットアップグローバルサービスチームにお問い合わせください</block>
  <block id="efb954cbfdbe0c54f04c904a2719b98a" category="list-text"><block ref="efb954cbfdbe0c54f04c904a2719b98a" category="inline-link-rx"></block></block>
  <block id="3a8a3991c7ef251983bda0fd052b9b10" category="inline-link">TR-4890</block>
  <block id="3cbee33bcafaf0315e821a3331b91eb5" category="inline-link">ネットアップのフルサポートの並列ファイルシステム解決策 BeeGFS</block>
  <block id="63de7cb3a054a3754335c60a0c8ba878" category="paragraph">注：同じデータセットへの共有アクセスを必要とする多数の GPU サーバを対象とした大規模な HPC スタイルの分散トレーニング、または並列ファイルシステムを必要とする場合は、チェックアウトしてください <block ref="f82f3a4db7a848244fd5070f378c86fb" category="inline-link-rx"></block>。本テクニカルレポートでは、この情報を記載する方法について説明します <block ref="99c493838dffa23aa6d1149e33e3edf0" category="inline-link-rx"></block> ネットアップの AI コントロールプレーンの一部として提供されます。この解決策は、数台の NVIDIA DGX A100 システムで構成される 140 ノードの SuperPOD まで拡張できるように設計されています。</block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">このドキュメントに記載されている情報の詳細については、以下のドキュメントや Web サイトを参照してください。</block>
  <block id="7d9ee37e3155d571b441d63bcbc54709" category="inline-link"><block ref="7d9ee37e3155d571b441d63bcbc54709" category="inline-link-rx"></block></block>
  <block id="52c629361849219069b336f56f1556d0" category="list-text">TR-4400 ：『 VMware vSphere Virtual Volumes with ONTAP 』<block ref="b7bf139d6051615d8c8e01b6b63dacc3" category="inline-link-rx"></block></block>
  <block id="18df8e05a5400abd9d0980b1c5bc9ef3" category="list-text">TR-4015 『 SnapMirror Configuration Best Practice Guide for ONTAP 9 』<block ref="e361bd9d6f7b20da762bc23fcb3d09c2" category="inline-link-rx"></block></block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="249b98331fa56dc46bf6ba51dc6c39d5" category="list-text">RBAC User Creator for ONTAP の略<block ref="6b15b91279acfce2bbee060bdb17db43" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="1a57e0f74e725c1a5e2d53b4d4b4460d" category="list-text">VMware vSphere リソース用の ONTAP ツール<block ref="80c496cd9ab75e5683007d8f66ca6fbf" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="91a48e1708df22b7464bced79c745ad2" category="list-text">VMware Site Recovery Manager のドキュメント<block ref="92ad802ced4838839b492be6d0bf427d" category="inline-link-rx"></block></block>
  <block id="014a2413d22e5ac39371ac1333e38898" category="paragraph">を参照してください<block ref="99cfde592e1d7fa7832b186d73ee4002" category="inline-link-rx"></block> ネットアップサポートサイトで、本ドキュメントに記載されている製品や機能のバージョンがお客様の環境でサポートされるかどうかを確認してください。NetApp IMT には、ネットアップがサポートする構成を構築するために使用できる製品コンポーネントやバージョンが定義されています。サポートの可否は、お客様の実際のインストール環境が公表されている仕様に従っているかどうかによって異なります。</block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">可能であれば、必ず ONTAP ツールを使用してデータストアとボリュームをプロビジョニングしてください。ボリューム、ジャンクションパス、 LUN 、 igroup 、エクスポートポリシーが その他の設定は互換性のある方法で構成されます。</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">運用上のベストプラクティス</block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="section-title">データストアおよびプロトコル</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM では、 ONTAP 9 で iSCSI 、ファイバチャネル、および NFS バージョン 3 をサポートしているのは、 SRA 経由のアレイベースのレプリケーションを使用している場合です。SRM は、従来のデータストアまたは VVOL データストアでの NFS バージョン 4.1 のアレイベースのレプリケーションをサポートしていません。</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">接続を確認するために、 DR サイトの新しいテスト用データストアをデスティネーション ONTAP クラスタからマウントしてアンマウントできることを必ず確認してください。データストアの接続に使用する各プロトコルをテストします。テスト用データストアは SRM の指示に従ってすべてのデータストアの自動化を実行するため、 ONTAP ツールを使用して作成することを推奨します。</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">SAN プロトコルは各サイトで同機種にする必要があります。NFS と SAN を混在させることはできますが、 SAN プロトコルを 1 つのサイト内に混在させないでください。たとえば、サイト A では FCP を、サイト B では iSCSI を使用できますサイト A では、 FCP と iSCSI の両方を使用しないでくださいその理由は、 SRA がリカバリサイトに混在する igroup を作成しないため、 SRM が SRA に指定されたイニシエータリストをフィルタリングしないためです。</block>
  <block id="150f8d9d5018ff00285d9aa158451d7b" category="paragraph">以前のガイドでは、 LIF を作成してデータの局所性を確保することを推奨つまり、必ず、ボリュームを物理的に所有するノード上の LIF を使用してデータストアをマウントします。これは、 ONTAP 9 の最新バージョンでは必須ではなくなりました。可能 ONTAP であれば、クラスタを対象とした特定のクレデンシャルがあれば、データに対してローカルな LIF 間での負荷分散は引き続き行われますが、高可用性やパフォーマンスの要件ではありません。</block>
  <block id="ef6e8713285283721507f92e3c3ec674" category="paragraph">オートサイズで十分な緊急容量を確保できない場合にスペース不足の状態になったときに Snapshot コピーを自動的に削除してアップタイムを確保するように設定 ONTAP できます。デフォルトの設定では、 SnapMirror によって作成された Snapshot コピーは自動的には削除されません。SnapMirror Snapshot コピーが削除された場合、 NetApp SRA は関連ボリュームのレプリケーションを反転および再同期できません。ONTAP によって SnapMirror Snapshot コピーが削除されないようにするには、 Snapshot の自動削除機能を設定してください。</block>
  <block id="a4f47f677f45e1e7075186d98e4f3ec1" category="paragraph">SAN データストアを含むボリュームの場合はボリュームのオートサイズを「 grow 」に設定し、 NFS データストアの場合は「 GROE_SHシュリンク 」に設定する必要があります。を参照してください<block ref="ee2474fa4563985f2f3ebe16d4e1ab3a" category="inline-link-rx"></block> を参照してください。</block>
  <block id="e6955db66b8dc4aee170ebdb0b560249" category="section-title">SPBM と VVol</block>
  <block id="3077a08ffed60acebf18d37874130d44" category="paragraph">SRM 8.3 以降では、 VVol データストアを使用した VM の保護がサポートされています。SnapMirror スケジュールは、次のスクリーンショットに示すように、 ONTAP のツール設定メニューで VVOL のレプリケーションが有効になっている場合、 VASA Provider によって VM ストレージポリシーに公開されます。</block>
  <block id="399c1894baf71c0529aa0fba66ea18fb" category="paragraph">次の例は、 VVol レプリケーションを有効にする方法を示しています。</block>
  <block id="b180e7f35111dca8acd6c56cdbcabb3e" category="paragraph"><block ref="b180e7f35111dca8acd6c56cdbcabb3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">次のスクリーンショットは、 VM ストレージポリシーの作成ウィザードに表示される SnapMirror スケジュールの例を示しています。</block>
  <block id="43c130b36e9e2b3d61409aa974f89fc7" category="paragraph"><block ref="43c130b36e9e2b3d61409aa974f89fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783a951245ce43eb84161804072a38c6" category="paragraph"><block ref="783a951245ce43eb84161804072a38c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">VVOL データストア用にレプリケートされたボリュームを作成します</block>
  <block id="18231879821321e0aed7de84fe876766" category="paragraph">以前の VVOL データストアとは異なり、レプリケートされた VVOL データストアはレプリケーションを有効にして最初から作成する必要があります。また、 SnapMirror 関係を持つ ONTAP システムで事前に作成されたボリュームを使用する必要があります。そのためには、クラスタピアリングや SVM ピアリングなどの設定を事前に行う必要があります。これらの作業は ONTAP 管理者が行う必要があります。複数のサイトにわたって ONTAP システムを管理する担当者と、主に vSphere の運用を担当する担当者を厳密に分離できるためです。</block>
  <block id="0a8c8293003bf411817ef3cedf18a2a9" category="paragraph">これは、 vSphere 管理者の代わりに新たな要件となります。ボリュームは ONTAP ツールの範囲外に作成されるため、定期的な再検出スケジュール期間が設定されるまで ONTAP 管理者が行った変更を認識することはありません。そのため、 VVOL で使用するボリュームまたは SnapMirror 関係を作成したときは常に再検出を実行することを推奨します。次のスクリーンショットに示すように、ホストまたはクラスタを右クリックし、 NetApp ONTAP tools &gt; Update Host and Storage Data を選択します。</block>
  <block id="dd5e006520a09e3975e52f6fb8991fd2" category="paragraph"><block ref="dd5e006520a09e3975e52f6fb8991fd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">VVOL と SRM については、 1 つ注意が必要です。保護された VM と保護されていない VM を同じ VVOL データストアに混在させないでください。これは、 SRM を使用して DR サイトにフェイルオーバーする場合、保護グループに属する VM のみが DR でオンラインになるためです。そのため、再保護（ SnapMirror を DR から本番環境に戻して再保護）する際に、フェイルオーバーされなかった VM が上書きされて、貴重なデータが含まれる可能性があります。</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">アレイペアについて</block>
  <block id="6dd3f3008fe81f402905b00c8dca007c" category="paragraph">アレイペアごとにアレイマネージャが作成されます。SRM ツールと ONTAP ツールでは、クラスタクレデンシャルを使用している場合でも、各アレイペアリングを SVM の範囲で実行します。これにより、管理対象に割り当てられている SVM を基に、各テナント間で DR ワークフローを分割できます。特定のクラスタに対して複数のアレイマネージャを作成でき、非対称にすることができます。異なる ONTAP 9 クラスタ間でファンアウトまたはファンインを実行できます。たとえば、クラスタ 1 の SVM A と SVM B をクラスタ 2 の SVM C に、クラスタ 3 の SVM D に、またはその逆にレプリケートできます。</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">SRM でアレイペアを設定する場合は、 ONTAP ツールに追加するのと同じ方法でアレイペアを SRM に追加する必要があります。つまり、アレイペアは同じユーザ名、パスワード、および管理 LIF を使用する必要があります。これは、 SRA がアレイと正しく通信するための要件です。次のスクリーンショットは、 ONTAP ツールでのクラスタの表示方法と、アレイマネージャへのクラスタの追加方法を示しています。</block>
  <block id="7ec48584a43ed8a9b1dda55398d97cf4" category="paragraph"><block ref="7ec48584a43ed8a9b1dda55398d97cf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">複製グループについて</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">レプリケーショングループには、同時にリカバリされる仮想マシンの論理集合が含まれます。レプリケーショングループは、 ONTAP ツール VASA Provider で自動的に作成されます。ONTAP の SnapMirror レプリケーションはボリュームレベルで実行されるため、ボリューム内のすべての VM が同じレプリケーショングループに属します。</block>
  <block id="b57ec021fce4e5261ba61df6f0c013af" category="paragraph">レプリケーショングループについて考慮する必要がある要素と、 FlexVol ボリュームに VM を分散する方法にはいくつかの要素があります。同様の VM を同じボリュームにグループ化すると、アグリゲートレベルの重複排除が行われていない古い ONTAP システムでもストレージ効率が向上しますが、グループ化することでボリュームのサイズが増大し、ボリュームの I/O 同時実行が減少します。最新の ONTAP システムでパフォーマンスとストレージ効率の最適なバランスを実現するには、同じアグリゲート内の FlexVol ボリュームに VM を分散します。その結果、アグリゲートレベルの重複排除を利用して、複数のボリューム間で I/O の並列化を促進します。保護グループ（以下で説明）には複数のレプリケーショングループを含めることができるため、ボリューム内の VM を 1 つにまとめてリカバリできます。このレイアウトの欠点は、 Volume SnapMirror ではアグリゲートの重複排除が考慮されないため、ブロックがネットワーク経由で何度も転送されることです。</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">レプリケーショングループの最後の考慮事項の 1 つは、各グループがその性質によって論理整合グループになることです（ SRM 整合グループと混同しないようにしてください）。これは、ボリューム内のすべての VM が同じ Snapshot を使用して同時に転送されるためです。したがって、相互に整合性が必要な VM がある場合は、同じ FlexVol に格納することを検討してください。</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">保護グループについて</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">保護グループでは、 VM とデータストアをグループ単位で定義し、グループをまとめて保護サイトからリカバリします。保護対象サイトとは、通常の安定状態での運用中、保護グループで構成された VM が存在する場所です。SRM には保護グループの複数のアレイマネージャが表示される場合がありますが、保護グループは複数のアレイマネージャにまたがることはできません。このため、異なる SVM 上の複数のデータストアに VM ファイルをまたがって配置することはできません。</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">リカバリ・プランについて</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">リカバリプランでは、同じプロセスでリカバリする保護グループを定義します。同じリカバリプランに複数の保護グループを設定できます。また、リカバリプランの実行オプションを増やすには、 1 つの保護グループを複数のリカバリプランに含めることもできます。</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">リカバリプランを使用すると、 SRM 管理者は、 VM を優先グループ 1 （最大）から 5 （最小）に割り当てて、リカバリワークフローを定義できます。デフォルトは 3 （中）です。優先度グループ内で、 VM に依存関係を設定できます。</block>
  <block id="6d72567442b1f361e3c0e89cbc7dfd6a" category="paragraph">たとえば、会社のデータベースに Microsoft SQL Server を使用するティア 1 ビジネスクリティカルなアプリケーションを使用しているとします。したがって、優先度グループ 1 に VM を配置することにします。優先度グループ 1 では、サービスの提供順序の計画を開始します。Microsoft Windows ドメイン・コントローラを起動してから Microsoft SQL Server を起動してください。アプリケーション・サーバの前にオンラインになっている必要があります。依存関係は特定の優先グループ内でのみ適用されるため、これらのすべての VM を優先グループに追加してから、依存関係を設定します。</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">アプリケーションチームと連携してフェイルオーバーシナリオに必要な処理の順序を把握し、それに応じてリカバリ計画を作成することを強く推奨します。</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">テストフェイルオーバー</block>
  <block id="2772828493452c4a2ff21f8b2b66a1a7" category="paragraph">ベストプラクティスとして、保護対象の VM ストレージの構成を変更する場合は、必ずテストフェイルオーバーを実行してください。これにより、災害発生時に、 Site Recovery Manager が想定される RTO ターゲット内でサービスをリストアできるかどうかを信頼できます。</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">特に VM ストレージの再設定後にゲストアプリケーションの機能を確認することを推奨します。</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">テストリカバリ処理を実行すると、 VM 用の ESXi ホストにプライベートテスト用のバブルネットワークが作成されます。ただし、このネットワークは物理ネットワークアダプタに自動的には接続されないため、 ESXi ホスト間の接続は提供されません。DR テスト時に異なる ESXi ホストで実行されている VM 間の通信を可能にするために、 DR サイトの ESXi ホスト間に物理プライベートネットワークを作成します。テスト用ネットワークがプライベートであることを確認するために、テスト用のバブルネットワークを物理的に分離するか、 VLAN や VLAN タギングを使用して分離します。このネットワークは本番用ネットワークから分離する必要があります。 VM がリカバリされると、実際の本番用システムと競合する可能性のある IP アドレスを持つ本番用ネットワークに配置することはできなくなります。SRM でリカバリプランを作成する際、テスト中に VM を接続するためのプライベートネットワークとして、作成したテストネットワークを選択できます。</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">テストが検証されて不要になったら、クリーンアップ処理を実行します。クリーンアップを実行すると、保護されている VM が初期状態に戻り、リカバリプランが Ready 状態にリセットされます。</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">フェイルオーバーに関する考慮事項</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">サイトのフェイルオーバーに関しては、このガイドに記載されている処理の順序に加えて、その他にもいくつかの考慮事項があります。</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">競合する問題の 1 つに、サイト間のネットワークの違いがあります。環境によっては、プライマリサイトと DR サイトで同じネットワーク IP アドレスを使用できる場合があります。この機能は、拡張仮想 LAN （ VLAN ）または拡張ネットワークセットアップと呼ばれます。それ以外の環境では、プライマリサイトと DR サイトで別々のネットワーク IP アドレス（異なる VLAN など）を使用する必要があります。</block>
  <block id="1b41638d2115765dc12f82d77ce70138" category="paragraph">VMware では、この問題を解決する方法をいくつか提供しています。1 つは、 VMware NSX -T Data Center のようなネットワーク仮想化テクノロジーです。ネットワークスタック全体を運用環境からレイヤ 2 ～ 7 に抽象化し、より移植性の高いソリューションを実現します。NSX オプションの詳細については 'SRM で確認できます<block ref="99d78d594865360c3d4b527bf0a2a7f6" category="inline-link-rx"></block>。</block>
  <block id="09a74136e56a63c5aba38b89802d9080" category="paragraph">SRM では、リカバリ時に VM のネットワーク設定を変更することもできます。IP アドレス、ゲートウェイアドレス、 DNS サーバなどの設定が再設定されます。リカバリ時に個々の VM に適用されるさまざまなネットワーク設定を、リカバリプランの VM のプロパティ設定で指定できます。</block>
  <block id="99f0a91111e8acb2462e8df5ecf0ab8f" category="paragraph">VMware の dr-ip-customizer というツールを使用すると、リカバリプランで複数の VM のプロパティを個別に編集しなくても、 SRM で VM ごとに異なるネットワーク設定を適用できます。このユーティリティの使用方法については、 VMware のマニュアルを参照してください<block ref="b959814092e3e6cdc8d22e768887e618" category="inline-link-rx"></block>。</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">再保護</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">リカバリ後、リカバリサイトが新しい本番用サイトになります。リカバリ処理によって SnapMirror レプリケーションが解除されたため、新しい本番用サイトは今後の災害から保護されません。新しい本番用サイトは、リカバリ後すぐに別のサイトで保護することを推奨します。元の本番サイトが運用されている場合、 VMware 管理者は、元の本番サイトを新しいリカバリサイトとして使用して新しい本番サイトを保護できるため、保護の方向を実質的に変えることができます。再保護は、致命的でない障害でのみ使用できます。そのため、元の vCenter Server 、 ESXi サーバ、 SRM サーバ、および対応するデータベースを最終的にリカバリ可能な状態にする必要があります。使用できない場合は、新しい保護グループと新しいリカバリプランを作成する必要があります。</block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">フェイルバック</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">フェイルバック処理は、基本的に以前とは異なる方向のフェイルオーバーです。ベストプラクティスとして、フェイルバックを実行する前に、元のサイトが許容可能なレベルの機能に戻っていること、つまり元のサイトにフェイルオーバーしていることを確認することを推奨します。元のサイトが侵害されたままの場合は、障害が十分に修正されるまでフェイルバックを遅らせる必要があります。</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">フェイルバックのもう 1 つのベストプラクティスとして、再保護の完了後、および最終フェイルバックの実行前に、常にテストフェイルオーバーを実行することがあります。これにより、元のサイトに配置されたシステムで処理が完了できるかどうかを確認できます。</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">元のサイトを再保護する</block>
  <block id="2a0c13d7b927063987bf931a141f2662" category="paragraph">フェイルバックの完了後、再保護を再度実行する前に、サービスが正常に戻っていることをすべての利害関係者に確認する必要があります。</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">フェイルバック後の再保護を実行すると、基本的に環境は最初の状態に戻り、 SnapMirror レプリケーションが本番用サイトからリカバリサイトに再度実行されます。</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">ONTAP では、 Storage Virtual Machine （ SVM ）の概念を採用して、セキュアなマルチテナント環境で厳密にセグメント化します。</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">導入のベストプラクティス</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">SMT の SVM のレイアウトとセグメント化</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">ONTAP では、 Storage Virtual Machine （ SVM ）の概念を採用して、セキュアなマルチテナント環境で厳密にセグメント化します。ある SVM の SVM ユーザは、別の SVM のリソースにアクセスしたりリソースを管理したりすることはできませんこれにより、 ONTAP テクノロジを活用できます。ビジネスユニットごとに別々の SVM を作成して、同じクラスタ上で独自の SRM ワークフローを管理することで、全体的なストレージ効率を高めることができます。</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">SVM を対象としたアカウントと SVM 管理 LIF を使用して ONTAP を管理することを検討し、セキュリティ制御を強化するだけでなく、パフォーマンスも向上させます。SRA は、物理リソースを含むクラスタ全体のすべてのリソースを処理する必要がないため、 SVM を対象とした接続を使用する場合は本質的にパフォーマンスが向上します。その代わり、特定の SVM に抽象化された論理資産だけを認識する必要があります。</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">NAS プロトコルのみを使用する（ SAN アクセスなし）場合は、次のパラメータを設定することで、 NAS 向けに最適化された新しいモードを利用することもできます（ SRA と VASA は、アプライアンスで同じバックエンドサービスを使用するため）。</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">コントロール・パネルに \\https://&lt;IP address&gt;:9083' からログインして '[Web Based CLI interface] をクリックします</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">コマンド VP updateconfig -key=enable.qtree.enable -value=true' を実行します</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">コマンド VP updateconfig -key=enable.optimized.sra_value =true' を実行します</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">コマンド VP reloadconfig を実行します。</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">VVOL に ONTAP ツールを導入する際の考慮事項について説明します</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">SRM で VVol を使用する場合は、クラスタを対象としたクレデンシャルとクラスタ管理 LIF を使用してストレージを管理する必要があります。これは、 VM ストレージポリシーに必要なポリシーを満たすためには、 VASA Provider で基盤となる物理アーキテクチャを理解しておく必要があるためです。たとえば、オールフラッシュストレージを必要とするポリシーが設定されている場合、 VASA Provider では、どのシステムがオールフラッシュであるかを認識できる必要があります。</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">ONTAP Tools アプライアンスを管理している VVOL データストアに格納しないことを推奨します。その結果、アプライアンスがオフラインのためにアプライアンスのスワップ VVOL を作成できず、 VASA Provider の電源をオンにできなくなることがあります。</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">ONTAP 9 システムの管理に関するベストプラクティス</block>
  <block id="b4cbecf196108ad163c73c4e4194dde2" category="paragraph">前述したように、クラスタまたは SVM を対象としたクレデンシャルと管理 LIF を使用して ONTAP クラスタを管理できます。パフォーマンスを最適化するために、 VVOL を使用していないときは SVM を対象としたクレデンシャルの使用を検討してください。ただし、その場合は、いくつかの要件について確認しておく必要があります。また、機能の一部は失われます。</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">デフォルトの vsadmin SVM アカウントには、 ONTAP ツールのタスクを実行するために必要なアクセスレベルがありません。そのため、新しい SVM アカウントを作成する必要があります。</block>
  <block id="8557644859e03f54860c95ffb0bcfd53" category="list-text">ONTAP 9.8 以降を使用 https://&lt;IP している場合は、 ONTAP の System Manager の Users メニューを使用して、 ONTAP ツールアプライアンスの JSON ファイル（アドレス： 9083/VSC/config/ ）とともに、 RBAC の最小権限のユーザアカウントを作成することを推奨します。管理者パスワードを使用して JSON ファイルをダウンロードしてください。これは SVM またはクラスタを対象としたアカウントに使用できます。</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">ネットアップサポートサイトの Toolchest</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">ONTAP 9.6 以前を使用している場合は、で使用可能な RBAC User Creator （ RUC ）ツールを使用する必要があります<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>。</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">vCenter UI プラグイン、 VASA Provider 、 SRA サーバはすべて完全に統合されたサービスであるため、 vCenter UI で ONTAP ツール用のストレージを追加する場合と同じ方法で、 SRM で SRA アダプタにストレージを追加する必要があります。そうしないと、 SRA サーバが SRA アダプタ経由で SRM から送信された要求を認識しない可能性があります。</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">SVM を対象としたクレデンシャルを使用している場合、 NFS パスのチェックは実行されませんこれは、物理的な場所が SVM から論理的に抽象化されているためです。ただしこれは原因の問題ではありません。最新の ONTAP システムで間接パスを使用してもパフォーマンスが著しく低下することはなくなりました。</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">Storage Efficiency によるアグリゲートのスペース削減量が報告されないことがあります。</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">サポートされている場合、負荷共有ミラーを更新することはできません。</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">SVM を対象としたクレデンシャルで管理されている ONTAP システムでは、 EMS ロギングが実行されない場合があり</block>
  <block id="963739e9818c0bf4d8959b5cdf6a7956" category="summary">SRM で VVOL レプリケーションを使用する場合、 SRA と従来のデータストアで使用するワークフローは大きく異なります。</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">VVol レプリケーションを使用する場合の SRM のトラブルシューティング</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">SRM で VVOL レプリケーションを使用する場合、 SRA と従来のデータストアで使用するワークフローは大きく異なります。たとえば、アレイマネージャの概念はありません。そのため、「 discoverarrays 」コマンドと「 discoverdevices 」コマンドは表示されません。</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">トラブルシューティングを行う場合は、以下に示す新しいワークフローについて理解しておくと役立ちます。</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">queryReplicationPeer ： 2 つのフォールトドメイン間のレプリケーション契約を検出します。</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">queryFaultDomain ：障害ドメインの階層を検出します。</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">queryReplicationGroup ：ソースドメインまたはターゲットドメインに存在するレプリケーショングループを検出します。</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">syncReplicationGroup ：ソースとターゲット間でデータを同期します。</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">queryPointInTimeReplica ：ターゲット上のポイントインタイムレプリカを検出します。</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">testFailoverReplicationGroupStart ：テストフェイルオーバーを開始します。</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">testFailoverReplicationGroupStop ：テストフェイルオーバーを終了します。</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">promoteReplicationGroup ：テスト中のグループを本番環境に昇格します。</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">prepareFailoverReplicationGroup ：災害復旧の準備をします。</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">FailoverReplicationGroup ：ディザスタリカバリを実行します。</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">revertReplicateGroup ：逆方向のレプリケーションを開始します。</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">queryMatchingContainer: 指定されたポリシーを使用したプロビジョニング要求を満たす可能性のあるコンテナを（ホストまたはレプリケーショングループとともに）検索します。</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">queryResourceMetadata ： VASA Provider からすべてのリソースのメタデータを検出し、リソース利用率を回答として queryMatchingContainer 関数に返すことができます。</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">VVOL レプリケーションの設定時に表示される最も一般的なエラーは、 SnapMirror 関係を検出できないエラーです。これは、ボリュームおよび SnapMirror 関係が ONTAP ツールを対象としたものではないためです。そのため、 SnapMirror 関係が常に完全に初期化されていることを確認し、レプリケートされた VVOL データストアを作成する前に両方のサイトの ONTAP ツールで再検出を実行することを推奨します。</block>
  <block id="dcaf091737df278b1b4bdd2e37c10a75" category="summary">NetApp ONTAP は、 2002 年に最新のデータセンターに導入されて以来、 VMware vSphere 環境向けストレージ解決策として業界をリードしてきました。また、コストを削減しながら管理を簡易化する革新的な機能を継続的に追加しています。</block>
  <block id="1fdf67ffe178876efb8b8cacfb0f052b" category="doc">TR-4900 ：『 VMware Site Recovery Manager with NetApp ONTAP 9 』</block>
  <block id="cc6ab3d11d2dc330a573866f7c9f67aa" category="paragraph">Chance Bingen 、ネットアップ</block>
  <block id="60398bdc931fc67a9b6d781434c3a15a" category="section-title">ONTAP for vSphere の略</block>
  <block id="09d6c6a1868cc36795c7a0f8f84e50c9" category="paragraph">NetApp ONTAP は、 2002 年に最新のデータセンターに導入されて以来、 VMware vSphere 環境向けストレージ解決策として業界をリードしてきました。また、コストを削減しながら管理を簡易化する革新的な機能を継続的に追加しています。このドキュメントでは、 ONTAP 解決策 for VMware Site Recovery Manager （ SRM ）について説明します。 SRM は、最新の製品情報や、導入の合理化、リスクの軽減、継続的な管理の簡素化に役立つベストプラクティスを含む、業界をリードする VMware のディザスタリカバリ（ DR ）ソフトウェアです。</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">ベストプラクティスは、ガイドや互換性ツールなどの他のドキュメントを補うものです。ラボテストに基づいて開発されており、ネットアップのエンジニアやお客様は広範な現場経験を積んでいます。推奨されるベストプラクティスがお客様の環境に適していない場合もありますが、一般に最もシンプルなソリューションであり、ほとんどのお客様のニーズに対応できます。</block>
  <block id="c3edc14dbc5862176444f521372d1744" category="paragraph">本ドキュメントでは ONTAP 、 VMware vSphere （ NetApp Storage Replication Adapter [SRA] と VASA Provider [VP] を含む）のサポートされているバージョン、および VMware Site Recovery Manager 8 で使用される、最近のリリースの ONTAP 9 の機能に焦点を当てています。4.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">SRM で ONTAP を使用する理由</block>
  <block id="3c41d5be62c97a13079e9c7abf078292" category="paragraph">ONTAP ソフトウェアを基盤とするネットアップのデータ管理プラットフォームは、 SRM に最も広く採用されているストレージソリューションの一部です。理由は豊富です。セキュアでハイパフォーマンスなユニファイドプロトコル（ NAS と SAN ）を備えたデータ管理プラットフォームは、ストレージ効率の定義、マルチテナンシー、サービス品質管理、 SnapMirror によるスペース効率に優れた Snapshot コピーとレプリケーションによるデータ保護を提供します。VMware ワークロードを保護するためにネイティブのハイブリッドマルチクラウド統合を活用し、多数の自動化ツールやオーケストレーションツールを簡単に利用できます。</block>
  <block id="0d573b6a27c08499fee406e3db49812f" category="paragraph">SnapMirror をアレイベースのレプリケーションに使用すると、 ONTAP で最も実績のある成熟したテクノロジの 1 つを活用できます。SnapMirror を使用すると、 VM やデータストア全体ではなく、変更されたファイルシステムブロックのみをコピーして、データを安全かつ効率的に転送できます。重複排除、圧縮、コンパクションなどのスペース削減効果を活用できます。最新の ONTAP システムで、バージョンに依存しない SnapMirror が使用されるようになり、ソースとデスティネーションのクラスタを柔軟に選択できるようになりました。SnapMirror は、災害復旧のための最も強力なツールの 1 つとなりました。</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">従来の NFS 、 iSCSI 、ファイバチャネル接続データストア（現在は VVOL データストアをサポート）のいずれを使用している場合でも、 SRM は、ディザスタリカバリやデータセンター移行の計画とオーケストレーションに ONTAP の機能のメリットを活用する堅牢なファーストパーティ製品を提供します。</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">SRM での ONTAP 9 の活用方法</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM は、 ONTAP システムの高度なデータ管理テクノロジを活用して、 3 つの主要コンポーネントで構成される仮想アプライアンスである VMware vSphere 用 ONTAP ツールと統合します。</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">vCenter プラグイン（旧 Virtual Storage Console （ VSC ））は、 SAN と NAS のどちらを使用している場合でも、ストレージ管理と効率化機能の簡易化、可用性の向上、ストレージコストと運用オーバーヘッドの削減を実現します。データストアのプロビジョニングのベストプラクティスを使用して、 NFS 環境およびブロックストレージ環境用の ESXi ホスト設定を最適化します。以上のメリットのために、 ONTAP ソフトウェアを実行するシステムで vSphere を使用する場合はこのプラグインを推奨します。</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">VASA Provider for ONTAP は、 VMware vStorage APIs for Storage Awareness （ VASA ）フレームワークをサポートしています。VASA Provider では、 VM ストレージのプロビジョニングと監視に役立つように vCenter Server と ONTAP を接続します。VMware Virtual Volumes （ VVol ）のサポートと、ストレージ機能プロファイル（ VVol レプリケーション機能を含む）の管理、および個々の VM VVol のパフォーマンスの管理が可能になります。また、容量の監視やプロファイルへの準拠に関するアラームも生成されます。SRM と一緒に使用すると、 VASA Provider for ONTAP で VVOL ベースの仮想マシンをサポートできます。 SRM サーバに SRA アダプタをインストールする必要はありません。</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA は SRM と一緒に使用され、従来の VMFS データストアと NFS データストアの本番サイトとディザスタリカバリサイト間での VM データのレプリケーションを管理します。また、 DR レプリカの無停止テストにも使用できます。検出、リカバリ、再保護のタスクを自動化します。Windows SRM サーバおよび SRM アプライアンス用の SRA サーバアプライアンスと SRA アダプタの両方が含まれています。</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">SRM サーバに SRA アダプタをインストールして設定し、 VASA Provider で VVol 以外のデータストアを保護したり VVOL のレプリケーションを有効にしたりしたあとで、ディザスタリカバリ用に vSphere 環境を設定する作業を開始できます。</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">SRA と VASA Provider には、 SRM サーバ用のコマンド / 制御インターフェイスが用意されており、 VMware 仮想マシン（ VM ）を含む ONTAP FlexVol や、 SRA を保護する SnapMirror レプリケーションを管理できます。</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">SRM 8.3 以降では、 SRM サーバへの新しい SRM VVol Provider 制御パスが導入され、 SRA を使用せずに vCenter サーバおよびその経由で VASA Provider に通信できるようになりました。これにより、 SRM サーバは緊密に統合するための完全な API を提供するため、以前よりもはるかに ONTAP クラスタの制御を活用できました。</block>
  <block id="53e971f0dfb3ef96ca359dcb648176b9" category="paragraph">SRM は、ネットアップ独自の FlexClone テクノロジを使用して、 DR プランを無停止でテストし、 DR サイトの保護されたデータストアのクローンをほぼ瞬時に作成できます。SRM はサンドボックスを作成して安全にテストし、真の災害が発生した場合に組織とお客様を保護します。そのため、組織は災害時にフェイルオーバーを実行できます。</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">実際に災害が発生した場合や、計画的な移行の場合でも、 SRM では、最終的な SnapMirror 更新（必要な場合）を使用して、データセットに最新の変更を送信できます。その後、ミラーを解除し、 DR ホストにデータストアをマウントします。この時点で、計画済みの戦略に基づいて、 VM の電源を任意の順序で自動的にオンにすることができます。</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">SRM と ONTAP などのユースケース：ハイブリッドクラウドと移行</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">Equinix 内の NetApp Private Storage</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">SRM 環境に ONTAP の高度なデータ管理機能を統合することで、ローカルストレージオプションに比べて、拡張性とパフォーマンスが大幅に向上します。それだけではありませんが、ハイブリッドクラウドの柔軟性を備えています。ハイブリッドクラウドを使用すると、 FabricPool を使用して、未使用のデータブロックをハイパフォーマンスアレイから希望するハイパースケーラに階層化してコストを削減できます。これは、 NetApp StorageGRID などのオンプレミスの S3 ストアである可能性があります。また、 ONTAP Select （ CVO ）やを使用して、ソフトウェアで定義される Cloud Volumes ONTAP やクラウドベースの DR でエッジベースのシステムに SnapMirror を使用することもできます<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> Amazon Web Services （ AWS ）、 Microsoft Azure 、 Google Cloud Platform （ GCP ）で、クラウド内に完全に統合されたストレージ、ネットワーク、コンピューティングサービスのスタックを構築できます。</block>
  <block id="10ae334f731d3c4fabafa8017f7a3ab2" category="paragraph">FlexClone により、ストレージ設置面積がほぼゼロのクラウドサービスプロバイダーのデータセンター内でテストフェールオーバーを実行できます。組織を保護することで、かつてないほどコストを削減できます。</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">SRM は、 SnapMirror を使用して、計画的な移行を実行することもできます。これにより、 VM を 1 つのデータセンターから別のデータセンターに効率的に転送したり、独自のデータセンターや、任意の数のネットアップパートナーサービスプロバイダを介して VM を転送したりできます。</block>
  <block id="a9b73ebef33c98ef5a1044177d2b49f3" category="summary">VMware vCenter Site Recovery Manager は、ディザスタリカバリ製品です。自動オーケストレーションを提供し、一元的なリカバリプランの無停止テストを提供して、仮想化されたすべてのアプリケーションのディザスタリカバリ管理を簡素化します。</block>
  <block id="06f589670c0d0455912cc8bb70b78701" category="paragraph">Site Recovery Manager を NetApp ONTAP システムに導入することで、ディザスタリカバリのコストと複雑さを大幅に削減できます。ネットアップは、高性能で管理しやすく拡張性に優れたストレージアプライアンスと堅牢なソフトウェア製品により、 vSphere 環境をサポートする柔軟なストレージおよびデータ管理ソリューションを提供します。</block>
  <block id="00549aec33ddcae6a708ed7368a7bcd0" category="paragraph">このガイドで紹介するベストプラクティスと推奨事項は、すべての解決策に当てはまるわけではありません。本ドキュメントには、 SRM DR 計画の計画、導入、管理のガイドラインを提供するベストプラクティスと推奨事項がまとめられています。VMware vCenter Site Recovery 環境をネットアップストレージ上に計画および導入する際は、ネットアップの VMware エキスパートにご相談ください。ネットアップの VMware エキスパートが、あらゆる vSphere 環境のニーズとニーズを迅速に特定し、それに応じてストレージの解決策を調整できます。</block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">従来の仮想アプライアンスからの移行に対応した ONTAP ツールには、豊富な新機能と上限があり、 VVOL が新たにサポートされるようになりました。</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">SRM および ONTAP ツールの新機能</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">vSphere および Site Recovery Manager の最新バージョン</block>
  <block id="aa73b07f008975ca9fcabf87bfafb167" category="paragraph">SRM 8.3 以降と 9.7.1 以降の ONTAP ツールでは、 VMware vSphere 7 で実行されている VM を保護できるようになりました。</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">ネットアップは、約 20 年にわたり VMware との緊密なパートナーシップを共有し、できるだけ早く最新リリースのサポートを提供するよう努めています。ソフトウェアの最新の組み合わせについては、必ず NetApp Interoperability Matrix Tool （ IMT ）で確認してください。</block>
  <block id="63fe9875fcf8108a4dca29a0795d8674" category="paragraph">NetApp IMT が見つかります<block ref="dd81e3609a71c92c2a90d9165ca7bb00" category="inline-link-rx"></block>。</block>
  <block id="23a6222620917211381cf4455d9e0a83" category="section-title">VVol のサポート（ SRM でも SPBM が重要である理由）</block>
  <block id="a36269071ceeb480e636654c4620f7fb" category="paragraph">8.3 リリースから、 SRM は VVol とアレイベースのレプリケーションを活用して、 Storage Policy-Based Management （ SPBM ；ストレージポリシーベースの管理）をサポートするようになりました。これを実現するために、 SRM サーバが更新され、 vCenter サーバの SMS サービスと通信して VASA 関連のタスクを実行する新しい SRM VVol プロバイダサービスが追加されました。</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">このアーキテクチャのメリットの 1 つは、すべての処理に VASA を使用するため、 SRA が不要になったことです。</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM は vSphere ツールボックスの強力なツールで、プライベートクラウド環境とハイブリッドクラウド環境の自動化フレームワークによって、シンプルで予測可能な一貫したストレージサービスを利用できます。SPBM では、多様な顧客層のニーズを満たすサービスクラスを定義できます。SRM では、堅牢な業界標準のディザスタリカバリオーケストレーションと自動化を必要とする重要なワークロードに対して、レプリケーション機能をお客様に提供できるようになりました。</block>
  <block id="48e2854d95fac45929940abc72062193" category="section-title">vVol アーキテクチャ 2.3 では、アプライアンスベースの SRM サーバがサポートされます</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">従来の Windows ベースのプラットフォームに加え、光子 OS ベースの SRM サーバもサポートされるようになりました。</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">SRA アダプタを、希望する SRM サーバタイプに関係なくインストールできるようになりました。</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">IPv6 のサポート</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6 が次の制限付きでサポートされるようになりました。</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">vCenter 6.7 以降</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">SRM 8.2 （ 8.1 、 8.3 、および 8 ）ではサポートされていません。4 がサポートされています）</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">Interoperability Matrix Tool で確認してください</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">を確認します<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> 最新の認定バージョンについては、を参照してください。</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">パフォーマンスの向上</block>
  <block id="3efd4ca8de094abf49f004186cd70fff" category="paragraph">SRM タスクを実行するには、運用パフォーマンスが重要な要件です。最新の RTO と RPO の要件を満たすために、 SRA と ONTAP ツールで 2 つの新しい機能強化が行われました。</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">* 同時再保護処理のサポート。 * この機能を有効にすると、最初に SRA 9.7.1 で導入された、 2 つ以上のリカバリプランに対して再保護を同時に実行できるため、フェイルオーバーまたは移行後のデータストアの再保護に要する時間を短縮し、 RTO と RPO のパラメータ内に抑えることができます。</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">* ONTAP ツール 9.8 では、 NAS 専用に最適化された新しいモードが追加されました。 * SVM を対象としたアカウントを使用して、 NFS ベースのデータストアのみで ONTAP クラスタに接続している場合は、サポートされている環境でピークパフォーマンスが得られるように NAS 専用に最適化モードを有効</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">拡張性の向上</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">SRM 8.3 以降で使用する ONTAP ツールでは、 SRA で最大 500 個の保護グループ（ PG ）がサポートされるようになりました。</block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">同期レプリケーション</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">待望の新機能として、 ONTAP 9.5 以降を搭載した SnapMirror Synchronous （ SM-S ）があります。この機能は、ミッションクリティカルなアプリケーションに対して、ボリュームレベルで RPO ゼロのデータレプリケーション解決策を提供します。SM-S には、 ONTAP ツール 9.8 以降が必要です。</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">REST API をサポート</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">SRA サーバの設定を REST API で管理できるようになりました。自動化ワークフローの構築を支援するために Swagger UI が追加されていますまた 'https://&lt;appliance&gt;:8143/api/rest/swagger-ui.html#/` にある ONTAP ツール・アプライアンスからも参照できます</block>
  <block id="160f88ca0bed5b24e94c809f4e22f1e7" category="summary">ONTAP 9 では、クラスタの物理コンポーネントはクラスタ管理者には見えますが、クラスタを使用しているアプリケーションやホストからは直接見えません。</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">レプリケーショントポロジ</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">ONTAP 9 では、クラスタの物理コンポーネントはクラスタ管理者には見えますが、クラスタを使用しているアプリケーションやホストからは直接見えません。物理コンポーネントは共有リソースのプールを提供し、このリソースプールから論理クラスタリソースが構築されます。アプリケーションとホストは、ボリュームと LIF を含む SVM 経由でのみデータにアクセスします。</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">VMware vCenter Site Recovery Manager では、各 NetApp SVM がアレイとして扱われます。SRM は、特定のアレイ間（または SVM から SVM ）のレプリケーションレイアウトをサポートしています。</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">1 つの VM が、次の理由から、複数の SRM アレイ上で仮想マシンディスク（ VMDK ）または RDM を所有することはできません。</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM は SVM のみを認識し、個々の物理コントローラは認識しません。</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">SVM は、クラスタ内の複数のノードにまたがる LUN とボリュームを制御できます。</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">ベストプラクティス</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">サポートされるかどうかを判断するには、このルールに注意してください。 SRM と NetApp SRA を使用して VM を保護するには、 VM のすべての部分が 1 つの SVM 上にのみ存在する必要があります。このルールは、保護対象サイトとリカバリサイトの両方に適用されます。</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">サポートされる SnapMirror レイアウト</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">次の図は、 SRM と SRA でサポートされる SnapMirror 関係のレイアウトシナリオを示しています。レプリケートされたボリューム内の各 VM は、各サイトの 1 つの SRM アレイ（ SVM ）上のデータのみを所有します。</block>
  <block id="39d3085abe6ccb914d8535de8a5f3e37" category="paragraph"><block ref="39d3085abe6ccb914d8535de8a5f3e37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ae7670cf947a397bdf6a882fbcc912a" category="paragraph"><block ref="1ae7670cf947a397bdf6a882fbcc912a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="111d3212464dba203cbd675a0338dcbc" category="paragraph"><block ref="111d3212464dba203cbd675a0338dcbc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5dc3a606b05b41db22793ed3c1a72db" category="paragraph"><block ref="c5dc3a606b05b41db22793ed3c1a72db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">サポートされている Array Manager レイアウト</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">次のスクリーンショットに示すように、 SRM でアレイベースレプリケーション（ ABR ）を使用すると、保護グループは単一のアレイペアに分離されます。このシナリオでは、リカバリサイトで「 S VM1 」と「 S VM2 」は「 S VM3 」と「 S VM4 」とピア関係にあります。ただし、保護グループを作成するときに選択できるアレイペアは 2 つのうちの 1 つだけです。</block>
  <block id="68a1b289711a591ed50627014cd01ce9" category="paragraph"><block ref="68a1b289711a591ed50627014cd01ce9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">サポートされないレイアウトです</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">サポート対象外の構成では、個々の VM が所有する複数の SVM にデータ（ VMDK または RDM ）があります。次の図に示す例では、「 VM1 」には 2 つの SVM 上のデータがあるため、 SRM で保護するように「 VM1 」を設定することはできません。</block>
  <block id="5c251a65e8394fbeaf104ba1a1cad2e1" category="paragraph"><block ref="5c251a65e8394fbeaf104ba1a1cad2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="paragraph"><block ref="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">1 つのネットアップボリュームを 1 つのソース SVM から同じ SVM または異なる SVM の複数のデスティネーションにレプリケートするレプリケーション関係は、 SnapMirror ファンアウトと呼ばれます。SRM ではファンアウトはサポートされていません。次の図の例では 'VM1 は SnapMirror で 2 つの異なる場所にレプリケートされるため 'SRM で保護するように構成できません</block>
  <block id="688890bdbdfd2d73a05a09883f3c4b40" category="paragraph"><block ref="688890bdbdfd2d73a05a09883f3c4b40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">SnapMirror カスケード</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SnapMirror でソースボリュームをデスティネーションボリュームにレプリケートし、そのデスティネーションボリュームを SnapMirror で別のデスティネーションボリュームにレプリケートする SnapMirror 関係のカスケードを、 SRM ではサポートしていません。次の図に示すシナリオでは、 SRM を使用してサイト間のフェイルオーバーを実行することはできません。</block>
  <block id="2990fc44e9ba827a397e96e1c278a02a" category="paragraph"><block ref="2990fc44e9ba827a397e96e1c278a02a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror と SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">NetApp SnapVault ソフトウェアを使用すると、ネットアップストレージシステム間でエンタープライズデータをディスクベースでバックアップできます。SnapVault と SnapMirror は同じ環境内に共存できますが、 SRM でサポートされているのは、 SnapMirror 関係のフェイルオーバーだけです。</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">NetApp SRA は、「 mirror vault 」ポリシータイプをサポートします。</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault は ONTAP 8.2 で一から再構築されました。以前の Data ONTAP 7-Mode で使用されていたユーザは共通点に注意する必要がありましたが、このバージョンの SnapVault では主に拡張機能が追加されています。大きな進歩の 1 つは、 SnapVault 転送時にプライマリデータの Storage Efficiency を維持できることです。</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">アーキテクチャの重要な変更点は、 7-Mode SnapVault の場合と同様に、 ONTAP 9 の SnapVault でも qtree レベルではなくボリュームレベルでレプリケートされる点です。つまり、 SnapVault 関係のソースはボリュームでなければならず、そのボリュームは SnapVault セカンダリシステム上の独自のボリュームにレプリケートされる必要があります。</block>
  <block id="f7b20cbc14027c7711d53d03a84f31af" category="paragraph">SnapVault を使用する環境では、具体的にはプライマリストレージシステムに Snapshot コピーという名前が作成されます。実装した構成に応じて、指定した Snapshot コピーは、 SnapVault スケジュールまたは NetApp Active IQ Unified Manager などのアプリケーションによってプライマリシステム上に作成できます。プライマリシステムで作成された名前付きの Snapshot コピーは、 SnapMirror デスティネーションにレプリケートされ、そこから SnapVault デスティネーションに保存されます。</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">ソースボリュームは、ボリュームが DR サイトの SnapMirror デスティネーションにレプリケートされるカスケード構成で作成でき、そこから SnapVault デスティネーションに保存されます。ファンアウト関係では、一方のデスティネーションが SnapMirror デスティネーション、もう一方が SnapVault デスティネーションであるソースボリュームも作成できます。ただし、 SRM フェイルオーバーまたはレプリケーションの反転時に、 SRA は、 SnapMirror デスティネーションボリュームを SnapVault のソースとして使用するように SnapVault 関係を自動では再設定しません。</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">TR-4015 『 SnapMirror Configuration Best Practice Guide for ONTAP 9 』</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">SnapMirror および SnapVault for ONTAP 9 の最新情報については、を参照してください<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">SnapVault と SRM を同じ環境で使用する場合、通常は DR サイトの SnapMirror デスティネーションから SnapVault バックアップを実行する、 SnapMirror から SnapVault へのカスケード構成を使用することを推奨します。災害が発生すると、この構成によってプライマリサイトにアクセスできなくなります。リカバリサイトに SnapVault デスティネーションを配置すると、フェイルオーバー後に SnapVault バックアップを再設定して、リカバリサイトで SnapVault バックアップを継続できるようになります。</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">VMware 環境では、各データストアに Universal Unique Identifier （ UUID ）が割り当てられ、各 VM には一意の Managed Object ID （ MOID ）が割り当てられます。SRM は、フェイルオーバーやフェイルバックの実行時にこれらの ID を維持しません。SRM はフェイルオーバーでデータストア UUID と VM MOID を維持しないため、これらの ID に依存するアプリケーションは SRM フェイルオーバーのあとに再設定する必要があります。たとえば、 SnapVault レプリケーションを vSphere 環境と調整する NetApp Active IQ Unified Manager などがあります。</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">次の図に、 SnapMirror から SnapVault へのカスケード構成を示します。SnapVault デスティネーションがプライマリサイトの停止の影響を受けない DR サイトまたは第 3 のサイトにある場合、フェイルオーバー後にバックアップを続行できるように環境を再設定できます。</block>
  <block id="b56afb9a43332c671116b9fa3d597867" category="paragraph"><block ref="b56afb9a43332c671116b9fa3d597867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">次の図は、 SRM を使用して SnapMirror レプリケーションをプライマリサイトに反転したあとの構成を示しています。SnapMirror ソースから SnapVault バックアップが実行されるように環境が再設定されている。このセットアップは、 SnapMirror SnapVault のファンアウト構成です。</block>
  <block id="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="paragraph"><block ref="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">SRM でフェイルバックを実行し、 SnapMirror 関係が再度反転されると、本番環境のデータはプライマリサイトに戻ります。SnapMirror と SnapVault のバックアップにより、 DR サイトへのフェイルオーバー前と同じ方法でこのデータを保護できるようになりました。</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Site Recovery Manager 環境での qtree の使用</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">qtree は、 NAS のファイルシステムクォータを適用可能な特殊なディレクトリです。ONTAP 9 では qtree を作成でき、 SnapMirror でレプリケートされたボリュームに配置できます。ただし、 SnapMirror では、個々の qtree のレプリケーションまたは qtree レベルのレプリケーションは実行できません。すべての SnapMirror レプリケーションは、ボリュームレベルで実行されます。このため、 SRM で qtree を使用することは推奨されません。</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">FC と iSCSI の混在環境</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">サポート対象の SAN プロトコル（ FC 、 FCoE 、 iSCSI ）の場合、 ONTAP 9 は LUN サービスを提供します。 LUN サービスの提供とは、 LUN を作成して、接続されているホストにマッピングする機能です。クラスタは複数のコントローラで構成されるため、個々の LUN へのマルチパス I/O で管理される論理パスが複数あります。ホスト上で Asymmetric Logical Unit Access （ ALUA ；非対称論理ユニットアクセス）が使用されるため、 LUN への最適なパスが選択され、データ転送用にアクティブになります。LUN への最適パスが変わった場合（格納先ボリュームが移動された場合など）、 ONTAP 9 は自動的にこの変更を認識し、システムを停止することなく調整します。最適パスが利用できなくなった場合、 ONTAP は無停止で他の利用可能なパスに切り替えることができます。</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM と NetApp SRA の環境では、一方のサイトで FC プロトコルを使用し、もう一方のサイトで iSCSI プロトコルを使用できます。ただし、 FC 接続のデータストアと iSCSI 接続のデータストアを同じ ESXi ホストで混在させたり、同じクラスタ内の別のホストで使用したりすることはできません。この構成は SRM ではサポートされていません。 SRM フェイルオーバーまたはテストフェイルオーバーの実行中、 SRM は要求に応じて ESXi ホストのすべての FC イニシエータと iSCSI イニシエータを含めます。</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM と SRA では、保護サイトとリカバリサイト間での FC プロトコルと iSCSI プロトコルの混在をサポートしています。ただし、各サイトで FC または iSCSI のどちらかのプロトコルを 1 つだけ使用し、同じサイトで両方のプロトコルを使用することはできません。1 つのサイトに FC プロトコルと iSCSI プロトコル両方を設定する必要がある場合、一部のホストで iSCSI を使用し、他のホストで FC を使用することを推奨します。また、 VM がどちらか一方のホストグループまたは他方のホストグループにフェイルオーバーするように設定されるように、 SRM リソースマッピングを設定することも推奨します。</block>
  <block id="1918f1bc0ea91d0e5d8e37878d5ab562" category="sidebar">NetApp ONTAP 9 を搭載した VMware Site Recovery Manager</block>
  <block id="e88a70d67e9de42d391fd019f2d06484" category="summary">このドキュメントに記載されている情報の詳細については、以下のドキュメントや Web サイトを参照してください。</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="doc">追加情報</block>
  <block id="b49efd5b259d6a3bceda1ebb8e34064a" category="list-text">データセット： TuSimple</block>
  <block id="61554b11b65c50bf7a094a86d699c8d5" category="inline-link"><block ref="61554b11b65c50bf7a094a86d699c8d5" category="inline-link-rx"></block></block>
  <block id="b150fd9c1d7740c871626031a398c8a3" category="paragraph"><block ref="b150fd9c1d7740c871626031a398c8a3" category="inline-link-rx"></block></block>
  <block id="a3a3504f7b11916e352125a598e15797" category="list-text">ディープラーニングネットワークアーキテクチャ：空間的な畳み込みニューラルネットワーク</block>
  <block id="6467a460cb421335f9f5b0523c38c9a6" category="inline-link"><block ref="6467a460cb421335f9f5b0523c38c9a6" category="inline-link-rx"></block></block>
  <block id="35527148b08f99f1d85797af833430dc" category="paragraph"><block ref="35527148b08f99f1d85797af833430dc" category="inline-link-rx"></block></block>
  <block id="cc1881adebe7ddf5b873966741a32ef1" category="list-text">分散型ディープラーニングトレーニングフレームワーク： Horovod</block>
  <block id="732f85d0d5eaa9222831dd5290518ff2" category="inline-link"><block ref="732f85d0d5eaa9222831dd5290518ff2" category="inline-link-rx"></block></block>
  <block id="655c281079d0281fcf4b8f2f08634c16" category="paragraph"><block ref="655c281079d0281fcf4b8f2f08634c16" category="inline-link-rx"></block></block>
  <block id="934b1fbd011b584c4878284f454f812e" category="list-text">実行： AI コンテナオーケストレーション解決策： run ： AI 製品の概要</block>
  <block id="64b899832bfcad18bb426fb355a0d03b" category="inline-link"><block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="b78ec84f003a4d277e318031a163e191" category="paragraph"><block ref="b78ec84f003a4d277e318031a163e191" category="inline-link-rx"></block></block>
  <block id="275dbaaa3169640f82917075918df905" category="list-text">実行： AI インストールドキュメント</block>
  <block id="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link"><block ref="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link-rx"></block></block>
  <block id="517046a8acf2e7fa61798debc5b6e25e" category="inline-link"><block ref="517046a8acf2e7fa61798debc5b6e25e" category="inline-link-rx"></block></block>
  <block id="b8b2e04f115b148d49a8cb477ed86af9" category="paragraph"><block ref="f03e58e4917966d9b82995c8ce69643b" category="inline-link-rx"></block><block ref="3530112fad5ba376549c9e0750df83f3" category="inline-link-rx"></block></block>
  <block id="8787c0bfc5af7ce34db56c9a5739f788" category="list-text">実行時のジョブの送信： AI CLI</block>
  <block id="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link"><block ref="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link-rx"></block></block>
  <block id="ca4ef6cf830a9de78ea71279d0d5417c" category="paragraph"><block ref="ca4ef6cf830a9de78ea71279d0d5417c" category="inline-link-rx"></block></block>
  <block id="984fd97f526f8afe9d2472b0894b84c2" category="inline-link"><block ref="984fd97f526f8afe9d2472b0894b84c2" category="inline-link-rx"></block></block>
  <block id="65640a241681656a4410cd7184278c9b" category="paragraph"><block ref="65640a241681656a4410cd7184278c9b" category="inline-link-rx"></block></block>
  <block id="33a756969a35b0a9029bf2a2c10e6d67" category="list-text">Azure クラウドリソース： Azure NetApp Files</block>
  <block id="99ac98f589f6b551211f31e86cb9a212" category="inline-link"><block ref="99ac98f589f6b551211f31e86cb9a212" category="inline-link-rx"></block></block>
  <block id="3085d4407b575d4a8938814c7db17d92" category="paragraph"><block ref="3085d4407b575d4a8938814c7db17d92" category="inline-link-rx"></block></block>
  <block id="f938809a358080d4c7a941e59abfca40" category="list-text">Azure Kubernetes Service の略</block>
  <block id="21d0acc34f6416d6ebd8074617c57439" category="inline-link"><block ref="21d0acc34f6416d6ebd8074617c57439" category="inline-link-rx"></block></block>
  <block id="91c4b230ded9b13564b447ba71304aeb" category="paragraph"><block ref="91c4b230ded9b13564b447ba71304aeb" category="inline-link-rx"></block></block>
  <block id="d9d650693b25d0540fbb606b1d1fbe4e" category="list-text">Azure VM SKUs</block>
  <block id="08318cbecd61665ab1824d118c1029a5" category="inline-link"><block ref="08318cbecd61665ab1824d118c1029a5" category="inline-link-rx"></block></block>
  <block id="3e05fd8f7e2e0ac6116dd746a8823eaa" category="paragraph"><block ref="3e05fd8f7e2e0ac6116dd746a8823eaa" category="inline-link-rx"></block></block>
  <block id="b9a1a7c8f2194407b24183f7826d2e44" category="list-text">Azure VM と GPU SKU</block>
  <block id="6046df9266bb79e1d99f9c232c1835e3" category="inline-link"><block ref="6046df9266bb79e1d99f9c232c1835e3" category="inline-link-rx"></block></block>
  <block id="d0bf246853f6f35070f6a8231d468c87" category="paragraph"><block ref="d0bf246853f6f35070f6a8231d468c87" category="inline-link-rx"></block></block>
  <block id="43a545df8285ba2aba289a52824f250d" category="inline-link"><block ref="43a545df8285ba2aba289a52824f250d" category="inline-link-rx"></block></block>
  <block id="944823ac69152177e369bd5d9a61a02f" category="paragraph"><block ref="944823ac69152177e369bd5d9a61a02f" category="inline-link-rx"></block></block>
  <block id="a9359a0f51034e1b1972f7690fe03f71" category="list-text">ネットアップのデータファブリック</block>
  <block id="781262103885a96ffc9275431a7ef132" category="inline-link"><block ref="781262103885a96ffc9275431a7ef132" category="inline-link-rx"></block></block>
  <block id="93e35e3e458c1d81846aa83c346e240e" category="paragraph"><block ref="93e35e3e458c1d81846aa83c346e240e" category="inline-link-rx"></block></block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="a6214fe1ac9a6825ffe38f3b34489c9d" category="summary">ネットアップの Run AI は、このテクニカルレポートの作成時にパートナー関係を結び、 Azure NetApp Files 独自の機能と、 AI ワークロードのオーケストレーションを簡易化する Run AI プラットフォームを実証しています。</block>
  <block id="a55106260c16aab506cebfb58e07e030" category="paragraph">ネットアップと Run ： AI は、このテクニカルレポートの作成時にパートナー関係を結び、 Azure NetApp Files 独自の機能と、 AI ワークロードのオーケストレーションを簡易化する AI プラットフォームを、 RUN の手法で実証しています。このテクニカルレポートでは、分散レーン検出トレーニングのためにデータパイプラインとワークロードオーケストレーションのプロセスを合理化するリファレンスアーキテクチャを提供します。</block>
  <block id="4e51614a389f3ad4fa17e2ce7ad984e7" category="paragraph">その結果、大規模な分散トレーニング（特にパブリッククラウド環境）に関しては、リソースのオーケストレーションとストレージのコンポーネントは解決策の重要な要素となります。データ管理によって複数の GPU 処理が妨げられることがないようにすることで、 GPU サイクルの利用率を最適化できます。そのため、大規模な分散トレーニングのために、システムをできるだけ費用対効果の高いものにすることができます。</block>
  <block id="269c35b1959d92e9ef6665bb4c60ad5d" category="paragraph">ネットアップが提供するデータファブリックを使用すると、データサイエンティストやデータエンジニアは、手動操作なしでオンプレミスとクラウドを連携させ、同期データを保持できるため、この課題を克服できます。つまり、データファブリックによって、 AI ワークフローを複数の場所に分散して管理するプロセスがスムーズになります。また、コンピューティングと分析、トレーニング、検証に必要なときに必要な場所でデータを利用できるため、オンデマンドでのデータ可用性が容易になります。この機能により、データ統合だけでなく、データパイプライン全体の保護とセキュリティも実現できます。</block>
  <block id="7a879e305f90568b91e8623ce5f9ee39" category="summary">2019 年 5 月より、 Microsoft は Azure ネイティブのファーストパーティポータルサービスを提供し、 NetApp ONTAP テクノロジを基盤とするエンタープライズ NFS および SMB ファイルサービスを提供しています。</block>
  <block id="0bf51d984b6a6d3fddc0e24f62eb1a14" category="doc">TR-4886 ：『 Distributed training in Azure ： Lane detection - 解決策 design 』</block>
  <block id="0ab5aa2896d8eed7732e69be5e5782b4" category="paragraph">Muneer Ahmad 氏と Verron Martina 氏、ネットアップの Ronen Dar 、 RUN ： AAI</block>
  <block id="a89ade32996e322edf837476febbc9bd" category="paragraph">2019 年 5 月より、 Microsoft は Azure ネイティブのファーストパーティポータルサービスを提供し、 NetApp ONTAP テクノロジを基盤とするエンタープライズ NFS および SMB ファイルサービスを提供しています。この開発は、 Microsoft とネットアップの戦略的パートナーシップによって推進されており、ワールドクラスの ONTAP データサービスの Azure への対応範囲がさらに拡大しています。</block>
  <block id="d6312cb01ee08559dbaa35c308e72268" category="paragraph">業界をリードするクラウドデータサービスプロバイダであるネットアップは、 AI インフラを仮想化する企業である AI の運用を共同で開始し、 GPU 利用率を最大限に活用して AI の実験を高速化しました。このパートナーシップでは、多数の実験を並行して実行し、データへの高速アクセスを実現し、無限のコンピューティングリソースを活用することで、 AI を加速できます。Run ： AI は、リソースの割り当てを自動化することで GPU 利用率を最大限に高めます。実績のある Azure NetApp Files のアーキテクチャにより、データパイプラインに障害が生じることをなくし、あらゆる実験を最高の速度で実行できます。</block>
  <block id="5234f8ee670afed8c398940a707f25df" category="paragraph">ネットアップと RUN ： AI が力を合わせて、お客様に Azure で AI 導入を実現するための将来を見据えたプラットフォームを提供しています。分析やハイパフォーマンスコンピューティング（ HPC ）から自律判断（お客様は必要なときに必要なものだけを購入することで IT 投資を最適化できる）まで、ネットアップと RUN のアライアンスによって、 AI は Azure クラウドでの単一の統合エクスペリエンスを提供します。</block>
  <block id="ecb81ab37e1d2a7ed6dfce3807622e3d" category="summary">このセクションでは、ラン AI オーケストレーションツールを使用して大規模なレーン検出分散トレーニングを実行するためのプラットフォームの設定について詳しく説明します。</block>
  <block id="0714a752696f8feed939bbf52a6214f7" category="doc">レーン検出–実行による分散トレーニング： AI</block>
  <block id="dbf10b854b8b7fc90297279e7ad0f745" category="paragraph">このセクションでは、ランオーケストレーションツール AI を使用して大規模なレーン検出分散トレーニングを実行するためのプラットフォームの設定について詳しく説明します。ここでは、すべての解決策要素のインストールと、前述のプラットフォームでの配布トレーニングジョブの実行について説明します。ML のバージョン管理には、 NetApp SnapshotTM を使用し、 RUN ： AI の実験によってデータとモデルの再現性を達成しました。ML のバージョン管理は、モデルの追跡、チームメンバー間での作業の共有、結果の再現性、生産への新しいモデルバージョンのローリング、データソースの作成に重要な役割を果たします。ネットアップの ML バージョン管理（ Snapshot ）は、各実験に関連するデータ、トレーニング済みモデル、ログのポイントインタイムバージョンをキャプチャできます。豊富な API サポートにより、実行中の AI プラットフォームとの統合が容易になります。トレーニングの状態に基づいてイベントをトリガーするだけで済みます。また、コードや Kubernetes （ Kubernetes ）上で実行されているコンテナに何も変更を加えずに、実験全体の状態をキャプチャする必要もあります。</block>
  <block id="25d19977e35c6d286c5b051982ae3f3c" category="paragraph">最後に、このテクニカルレポートは、 AKS を介して複数の GPU 対応ノードでパフォーマンスを評価する方法をラップアップします。</block>
  <block id="1987a7039dccb848f2e8ce693ba3faff" category="section-title">TuSimple データセットを使用したレーン検出のユースケースに関する分散トレーニング</block>
  <block id="f75a7cb3d80e7be148c1ce86a4347011" category="paragraph">このテクニカルレポートでは、レーン検出用の TuSimple データセットに対して分散トレーニングを実行します。Horovod は、 AKS を使用して Kubernetes クラスタ内の複数の GPU ノードでデータ分散トレーニングを同時に実施するためのトレーニングコードで使用されます。コードは、 TuSimple データのダウンロードおよび処理用のコンテナイメージとしてパッケージされています。処理されたデータは、 NetApp Trident プラグインによって割り当てられた永続ボリュームに格納されます。トレーニングでは、 1 つ以上のコンテナイメージが作成され、データのダウンロード時に作成された永続ボリュームに格納されたデータが使用されます。</block>
  <block id="58b4798157820b4e4415d8136cf60fe9" category="paragraph">データとトレーニングのジョブを送信するには、 run ： AI を使用してリソースの割り当てと管理をオーケストレーションします。Run ： AI では、 Horovod に必要な Message Passing Interface （ MPI ；メッセージパッシングインターフェイス）処理を実行できます。このレイアウトでは、複数の GPU ノードが相互に通信して、各トレーニング mini バッチの実行後にトレーニングの重みを更新できます。また、 UI や CLI からトレーニングを監視できるため、実験の進捗状況を簡単に監視できます。</block>
  <block id="ecbeff08f5ec15c6952355b518d4ae02" category="paragraph">NetApp Snapshot はトレーニングコードに統合されており、あらゆる実験に対応するデータの状態とトレーニング済みモデルをキャプチャします。この機能を使用すると、使用するデータとコードのバージョン、および生成された関連するトレーニング済みモデルを追跡できます。</block>
  <block id="63addc90b28c066bd235c900fed65314" category="section-title">AK のセットアップとインストール</block>
  <block id="50f7d8213ee52350926ec407074e68f1" category="inline-link">AKS クラスタを作成します</block>
  <block id="55b295c729173e8c0c745bb036b03270" category="paragraph">AKS クラスタのセットアップとインストールは、に進みます<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block>。次に、次の一連の手順を実行します。</block>
  <block id="8f9d847fad9782b080de76b0161b1c45" category="list-text">ノードのタイプ（システム（ CPU ）ノードまたはワーカー（ GPU ）ノードのいずれであるか）を選択するときは、次のいずれかを選択します。</block>
  <block id="957d1a35f975177c3fd161490f3e2d83" category="list-text">「 agentpool 」という名前のプライマリ・システム・ノードを 'Standard _ DS2_v2' サイズに追加しますデフォルトの 3 つのノードを使用します。</block>
  <block id="8853a13db2e2a03cb5b2f1186fbcd0a6" category="list-text">'Standard_NC6s_v3' プール・サイズを使用して 'Worker ノード gpupool' を追加しますGPU ノードには最小 3 ノードを使用します。</block>
  <block id="5085043d6dea89934a2e516fc46f891a" category="paragraph"><block ref="5085043d6dea89934a2e516fc46f891a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633b880bff72a9f1c1114df31dec55bf" category="admonition">導入には 5 ～ 10 分かかります。</block>
  <block id="f55bb34768c41f91318fb57b85c1def9" category="inline-link">ツールをインストールします</block>
  <block id="6369fc9d36c9d56cbebefdeccda5fbff" category="list-text">導入が完了したら、 Connect to Cluster （クラスタへの接続）をクリックします。新しく作成した AKS クラスタに接続するには、ローカル環境（ラップトップ / PC ）から Kubernetes コマンドラインツールをインストールします。にアクセスします<block ref="bcd577f96ff7023ec6fd5c904f040896" category="inline-link-rx"></block> OS に応じてインストールします。</block>
  <block id="811c47e56617f97db3579bc32a9085c9" category="inline-link">ローカル環境に Azure CLI をインストールします</block>
  <block id="ea5d45554a3e9cb9cbc0ddea4c228b28" category="list-text"><block ref="2db79c584144175dd0bb69b6c7045fc9" category="inline-link-rx"></block>。</block>
  <block id="825ca3bff78c42ec87920dfbce105fae" category="list-text">端末から AKS クラスタにアクセスするには、まず「 AZ login 」と入力し、クレデンシャルを入力します。</block>
  <block id="3394029cd334ed00686c86c088d73c24" category="list-text">次の 2 つのコマンドを実行します。</block>
  <block id="193937b265ce655417f00a79334d3937" category="list-text">Azure CLI で、次のコマンドを入力します。</block>
  <block id="cbf78d8bb0be543834c56e61560773b0" category="admonition">ここで示したように 6 つのノードがすべて稼働していれば、 AKS クラスタをローカル環境に接続することができます。</block>
  <block id="e8085ec7505cfe6f3cfbe2c2628386dc" category="paragraph"><block ref="e8085ec7505cfe6f3cfbe2c2628386dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0143a2caee1b9ab090de587206b65fe6" category="section-title">Azure NetApp Files の委譲されたサブネットを作成します</block>
  <block id="450cf7e7f8262fdaa3454c2e11aad687" category="paragraph">Azure NetApp Files の委任されたサブネットを作成するには、次の手順を実行します。</block>
  <block id="0ca30ab1eb5e523356720465eb7439c8" category="list-text">Azure ポータル内の仮想ネットワークに移動します。新しく作成した仮想ネットワークを検索します。この例では、 AKs-vnet などのプレフィックスが必要です。仮想ネットワークの名前をクリックします。</block>
  <block id="ce0c628aca3577055043c7f8364600d9" category="paragraph"><block ref="ce0c628aca3577055043c7f8364600d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25157709e5a253560f5ec68b8262563c" category="list-text">[ サブネット ] をクリックし、上部のツールバーから [ サブネット + ] を選択します。</block>
  <block id="d9bf5876b80dbf558587f06630e3915c" category="paragraph"><block ref="d9bf5876b80dbf558587f06630e3915c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a07ef5dbc59d5ba150de82d519fb4f8" category="list-text">サブネットに「 ANF 」などの名前を付け、サブネットの委任の見出しの下で、 Microsoft.NetApp/volumes を選択します。他のものは変更しないでください。[OK] をクリックします。</block>
  <block id="a8ccea52e17d54aea1295a99ab4d5c2e" category="paragraph"><block ref="a8ccea52e17d54aea1295a99ab4d5c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d182b62071ada1a29e4f9c26487c1121" category="paragraph">Azure NetApp Files ボリュームはアプリケーションクラスタに割り当てられ、 Kubernetes で永続ボリューム要求（ PVC ）として使用されます。この割り当てにより、ボリュームをさまざまなサービスに柔軟にマッピングし、 Jupyter ノートブック PC やサーバーレス関数などに対応することができます</block>
  <block id="a74ff852d3b3b8447b0306018a76c4f1" category="paragraph">サービスのユーザは、プラットフォームのストレージをさまざまな方法で消費できます。Azure NetApp Files の主な利点は次のとおりです。</block>
  <block id="a7c5a83cc4ccf14374e496bcbb4363f5" category="list-text">スナップショットを使用できるようになります。</block>
  <block id="ea437fe76a4bba5bf335daccbbd24b50" category="list-text">Azure NetApp Files ボリュームに大量のデータを格納できます。</block>
  <block id="cedebf66380d43f58c07dfb1d4d686a6" category="list-text">Azure NetApp Files ボリュームのモデルを大量のファイルセットで実行する場合は、そのモデルのパフォーマンス向上が必要になります。</block>
  <block id="75ab13308585f62c3cd57a246d0e0c64" category="section-title">Azure NetApp Files セットアップ</block>
  <block id="8c060d9ae24c7bc4518e54cd5ed13098" category="inline-link">クイックスタート： Azure NetApp Files をセットアップし、 NFS ボリュームを作成します</block>
  <block id="fd01c32c80d631ed4bebff78fa83b23e" category="paragraph">Azure NetApp Files のセットアップを完了するには、まず、の説明に従って を設定する必要があります<block ref="2f4e63e538c7dd311b18db058621cef8" category="inline-link-rx"></block>。</block>
  <block id="e26f032bd6f7f5636860d6b94ac84859" category="paragraph">ただし、 Trident からボリュームを作成するため、 Azure NetApp Files 用の NFS ボリュームを作成する手順は省略できます。続行する前に、次のものがあることを確認してください。</block>
  <block id="e953b5e281d40c5db3cc047889eec4f2" category="inline-link">Azure NetApp Files とネットアップのリソースプロバイダに登録（ Azure Cloud Shell を使用）</block>
  <block id="3b46d13fb20fe6a92456f742b5732774" category="list-text"><block ref="527fb205c939c551ed93f597562513fb" category="inline-link-rx"></block>。</block>
  <block id="d0652e942d3d4b469179248d72ccaa5c" category="inline-link">Azure NetApp Files でアカウントを作成</block>
  <block id="82a51bbfec23ca7366c216813caeacc8" category="list-text"><block ref="874637dbfce24ba5a63adadd91968dc9" category="inline-link-rx"></block>。</block>
  <block id="02209b9e3a221b39bf0ce87641e7afc6" category="inline-link">容量プールをセットアップする</block>
  <block id="7b4cb99ad8c150ff95b1a65d0f0524cc" category="list-text"><block ref="0fa33cef09dfad4c8795f42dd9dd5248" category="inline-link-rx"></block> （必要に応じて、 4TiB Standard または Premium 以上）。</block>
  <block id="1c7c9057bf4f7aee40c5a117c160c0fd" category="section-title">AKS 仮想ネットワークおよび Azure NetApp Files 仮想ネットワークのピアリング</block>
  <block id="998069ab494c49ade2cc77591c02d9fa" category="paragraph">次に、次の手順に従って、 Azure NetApp Files VNet とともに AKS 仮想ネットワーク（ VNet ）のピア関係を設定します。</block>
  <block id="bf12dce8dcc6febfeddec5ed2570e7d7" category="list-text">Azure ポータル上部の検索ボックスに「 virtual networks 」と入力します。</block>
  <block id="3f961f79effdf0aa37042e1733ee53ef" category="list-text">vnet AK - vnet-name をクリックして、検索フィールドにピアを入力します。</block>
  <block id="0249aa06ef3e10e8754106189b542be4" category="list-text">+ Add をクリックして、次の表に示す情報を入力します。</block>
  <block id="6f16a5f8ff5d75ab84c018adacdfcbb7" category="cell">フィールド</block>
  <block id="88645c17102d75583e93db9aa716b012" category="cell">Value または概要のいずれかです</block>
  <block id="f80824cb9ab9f704542dec0c71c5f38b" category="cell">ピアリングリンク名</block>
  <block id="5d43607a5a0ebb50f3ea9348485daa15" category="cell">AKs-vnet-name_-to-anf</block>
  <block id="62912b52e584278e26870d9e5092e723" category="cell">サブスクリプション ID</block>
  <block id="7d97336a164d9ce685e88a121141b189" category="cell">ピアリング先の Azure NetApp Files VNet のサブスクリプション</block>
  <block id="82a60e720574cf435dda0a03976e8323" category="cell">VNet ピアリングパートナー</block>
  <block id="d2ade9376eb8b87db099330d20c4f180" category="cell">Azure NetApp Files VNet の略</block>
  <block id="5b92ad691782a9e4cc701e479c90997f" category="admonition">デフォルトでは、アスタリスク以外のすべてのセクションはそのままにしておきます</block>
  <block id="0e5883528161213f3edc02dd718e1693" category="list-text">[Add] または [OK] をクリックして、仮想ネットワークにピアリングを追加します。</block>
  <block id="12eee9bf8836d675f26602260016f7da" category="inline-link">仮想ネットワークピアリングを作成、変更、削除します</block>
  <block id="fa1f15d2aebd0592f338ea9f49e06377" category="paragraph">詳細については、を参照してください<block ref="610fa6db13a2eefe4a391b16732fbbf0" category="inline-link-rx"></block>。</block>
  <block id="91d2f55da5f23abbcf1a0656897d101b" category="paragraph">Trident は、アプリケーションコンテナの永続的ストレージ向けにネットアップが管理しているオープンソースプロジェクトです。Trident は、ポッドとして実行される外部プロビジョニングコントローラとして実装され、ボリュームを監視し、プロビジョニングプロセスを完全に自動化します。</block>
  <block id="4088b2a65b2a3182209479dced5e78c5" category="paragraph">NetApp Trident では、トレーニングデータセットとトレーニング済みモデルを格納する永続的ボリュームを作成して接続することで、 Kubernetes との円滑な統合が可能です。データサイエンティストやデータエンジニアは、データセットを手動で保存して管理する手間をかけることなく、 Kubernetes クラスタを簡単に使用できます。Trident では、論理的な API 統合を通じてデータ管理関連のタスクが統合されるため、データサイエンティストは新しいデータプラットフォームの管理を習得する必要もありません。</block>
  <block id="77dc68d199719a4b8f5eba742ecb7056" category="paragraph">Trident ソフトウェアをインストールするには、次の手順を実行します。</block>
  <block id="2f2e9ef9449e2f31756b1d3683a207b3" category="inline-link">最初に Helm をインストールします</block>
  <block id="089f0e488d4e2b1a4b02d6d6b638c9d3" category="list-text"><block ref="b3c10ddb3b7f0e3e121ce123f60cc497" category="inline-link-rx"></block>。</block>
  <block id="e12559703ec38e80de7b94fecc84a043" category="list-text">Trident 21.01.1 インストーラをダウンロードして展開します。</block>
  <block id="7ee913d1a8b01e1a461f9eb99b0bba74" category="list-text">ディレクトリを 'trident-installer' に変更します</block>
  <block id="8ad5650fb94bff45b328581838d836fd" category="list-text">tridentctl' をシステムの $path.` のディレクトリにコピーします</block>
  <block id="6da8d48465deb31425595b33a9172acf" category="list-text">Helm を使用して Kubernetes クラスタに Trident をインストールします。</block>
  <block id="7b09729551ddb1a7445f559eb1186978" category="list-text">ディレクトリを Helm ディレクトリに変更します。</block>
  <block id="27b4c36cae8d1c4fd515d289942c87cc" category="list-text">Trident をインストール</block>
  <block id="cea04f1ceb2ba2472ec50de3a03a689c" category="list-text">Trident ポッドのステータスを通常の Kubernetes クラスタの方法で確認します。</block>
  <block id="6ac3c5fc780260af91dd10523188e6fd" category="list-text">すべてのポッドが稼働中の場合は、 Trident がインストールされているので移行を推奨します。</block>
  <block id="7862dabe13bf66a99fcfd3a6b1af4d94" category="section-title">Azure NetApp Files のバックエンドとストレージクラスをセットアップする</block>
  <block id="7e98dce86779e84763b71398d851f7bb" category="paragraph">Azure NetApp Files バックエンドとストレージクラスをセットアップするには、次の手順を実行します。</block>
  <block id="dadab4bead78e450739c0f56bad40cda" category="list-text">ホームディレクトリに切り替えます。</block>
  <block id="65b8f7db2e9a3793e76d2ec3787f71fa" category="inline-link">プロジェクトリポジトリ</block>
  <block id="03636accad716972f761628ea21e43f6" category="list-text">をクローニングします<block ref="2b240ffa21ddbdc99d1706dee4302f7e" category="inline-link-rx"></block> lane -detection -SCNN-horovod`</block>
  <block id="0ea725833b806058fe7810e6be91f9c0" category="list-text">'trident-config' ディレクトリに移動します</block>
  <block id="c51fa2034e7d5d97ec8c31248fc18e98" category="list-text">Azure サービスの原則を作成します（サービスの原則は、 Trident が Azure と通信して Azure NetApp Files リソースにアクセスする方法です）。</block>
  <block id="7c794fc1e683a6843753158bb92cab75" category="paragraph">出力は次の例のようになります。</block>
  <block id="203565dfd87ac32927ce5a828d45babd" category="list-text">Trident のバックエンド JSON ファイルを作成します。</block>
  <block id="d7e47f31bf1c921dd5e28ee7e6f5cd34" category="list-text">任意のテキストエディタを使用して 'anf-backend.json ファイル内の下の表の次のフィールドに入力します</block>
  <block id="8c443e170595ba0feac007ffb92cb49a" category="cell">サブスクリプション ID</block>
  <block id="deb6a9aaa10be6bb24feea6a3540128c" category="cell">お客様の Azure サブスクリプション ID</block>
  <block id="bc54592d6183695b841c6d1880ec0bf8" category="cell">tenantID のこと</block>
  <block id="b147f00fa948b22faa89aa8044904495" category="cell">Azure テナント ID （前の手順での AZ AD SP の出力から取得）</block>
  <block id="93c5bebdea9c94a0740fe6fd9bb250f0" category="cell">ClientID</block>
  <block id="5760e6800c58c7dc9ee68efdc6db38de" category="cell">自分の appID （前のステップでの AZ 広告 SP の出力から）</block>
  <block id="2b53761249254ce6b502f521e5cc0683" category="cell">clientSecret</block>
  <block id="0571f76a94493cb2020d6c3b7453a367" category="cell">パスワード（前の手順での AZ AD SP の出力からの）</block>
  <block id="25e6b7ea847b31b4f88b60acd65052db" category="paragraph">ファイルは次の例のようになります。</block>
  <block id="49356331b94221561b7751ae1f5343a9" category="list-text">構成ファイルとして 'anf-backend.json を使用して 'trident' 名前空間に Azure NetApp Files バックエンドを作成するように Trident に指示します</block>
  <block id="bd9c5e9bd5f130a6fbdbcaeb04656652" category="list-text">ストレージクラスを作成します。</block>
  <block id="a9fa0a3d8bf1bce76ef654f0a047b8fe" category="list-text">k8 ユーザは、ストレージクラスを名前で指定する PVC を使用してボリュームをプロビジョニングします。次のコマンドを使用して ' 前の手順で作成した Azure NetApp Files バックエンドを参照するストレージ・クラス 'azurenetappfiles' を作成するよう 'Kubernetes クラスタに指示します</block>
  <block id="5e121b263b32950e629eaf774c12da78" category="list-text">次のコマンドを使用して、ストレージクラスが作成されたことを確認します。</block>
  <block id="202ed88f7ec48eda708f6c062786f474" category="paragraph"><block ref="202ed88f7ec48eda708f6c062786f474" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72611a189b0331f709788d99912a1bd7" category="section-title">ボリューム Snapshot コンポーネントを AKS に導入してセットアップします</block>
  <block id="3ea90db69187da57e9739e033add6801" category="paragraph">適切なボリューム Snapshot コンポーネントがあらかじめクラスタにインストールされていない場合は、次の手順を実行して、これらのコンポーネントを手動でインストールできます。</block>
  <block id="c3987ca9f11aad20ef5d2ae0dd30f9cb" category="admonition">AK 1.18.14 には Snapshot コントローラが事前にインストールされていません。</block>
  <block id="312e34d756f6ef39f0bd74e2f844773f" category="list-text">次のコマンドを使用して、スナップショットベータ版の CRD をインストールします。</block>
  <block id="529616f838a47cade6e5fac6f879ce5a" category="list-text">GitHub の次のドキュメントを使用して、 Snapshot Controller をインストールします。</block>
  <block id="90a2427d3a3145723cd2a130c5372865" category="inline-link">ボリューム Snapshot クラス</block>
  <block id="8f2838f14b6a64dd466dc23bcf7e3c01" category="list-text">ボリュームスナップショットを作成する前に 'K8s'volumesnapshotclass' を設定します<block ref="cba124de563550c68e57cf9a6641a5d1" category="inline-link-rx"></block> セットアップが完了している必要があります。Azure NetApp Files のボリューム Snapshot クラスを作成し、ネットアップの Snapshot テクノロジを使用して ML のバージョン管理を実現します。volumesnapshotclass NetApp-csi-snapclass' を作成し ' 次のようにデフォルトの ` volumesnapshotclass 」に設定します</block>
  <block id="adc3a39a071327998da9cc6708ef4fe8" category="paragraph"><block ref="adc3a39a071327998da9cc6708ef4fe8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="770bec683fa99c1a917babb074d95e66" category="list-text">次のコマンドを使用して、ボリュームの Snapshot コピークラスが作成されたことを確認します。</block>
  <block id="99b5a364457d91999df6ca6488b800f2" category="paragraph"><block ref="99b5a364457d91999df6ca6488b800f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d9a6cca62c9095cbae70692ef82741c" category="section-title">「 AI Installation 」を実行します</block>
  <block id="d1d2b81816d977b7a9d3480a495beda5" category="paragraph">Run ： AI をインストールするには、次の手順を実行します。</block>
  <block id="7899a1a12ecf76a5676a6d5ddb64842f" category="inline-link">Run ： AI クラスタを AKS にインストールします</block>
  <block id="54437101a8cdfe297499d517331ced60" category="list-text"><block ref="400679f1b873ae4a832f018613d486cc" category="inline-link-rx"></block>。</block>
  <block id="5f854e827ba37f66f45f8e47643e23ea" category="list-text">app.runai.ai にアクセスし、 [ 新しいプロジェクトの作成 ] をクリックして、レーン検出という名前を付けます。'runai' で始まる名前空間を Kubernetes クラスタに作成し ' そのあとにプロジェクト名を付けますこの場合、作成される名前空間は runai-lane detection になります。</block>
  <block id="e699d582d1b58a9a23ebd74cab11d5bc" category="paragraph"><block ref="e699d582d1b58a9a23ebd74cab11d5bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="546524b2c8ed6fd083c9286159ebd55a" category="inline-link">インストール実行： AI CLI</block>
  <block id="f3a9807f54199fd5dbad651af2ea853a" category="list-text"><block ref="6291ffcd5a23a3d0b996bc90930ef0b3" category="inline-link-rx"></block>。</block>
  <block id="08d1d73b27232763a82ef46a413779ce" category="list-text">ターミナルで、次のコマンドを使用して、 LANE 検出をデフォルトの実行として AI プロジェクトに設定します。</block>
  <block id="0ca589f93fd9565aa5fc097fd66437ae" category="paragraph"><block ref="0ca589f93fd9565aa5fc097fd66437ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cd1a85dd18a7a0b8f1d07b4240fafcf" category="list-text">Create ClusterRole and ClusterRoleBinding for the project namespace (`lane detection など ) 」という名前空間に属するデフォルトのサービスアカウントには ' ジョブの実行中に "volumeSnapshot" 操作を実行する権限があります</block>
  <block id="351495b134e625df33dfb5230d6eab7b" category="list-text">次のコマンドを使用して、名前空間を一覧表示し、「 runai-lane -detection 」が存在することを確認します。</block>
  <block id="bd546162071f28fd50f8c977ac61149e" category="paragraph">次のような出力が表示されます。</block>
  <block id="8c33c9910dfecb6260489cd05f43b275" category="paragraph"><block ref="8c33c9910dfecb6260489cd05f43b275" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f23930532ba19f8970c6dcb4b6ad778f" category="list-text">次のコマンドを使用して、 ClusterRole 「 netappsnapshot 」および ClusterRoleBinding 「 netappsnapshot 」を作成します。</block>
  <block id="7e3ec6f763cd8a13380162aba60c47e0" category="section-title">TuSimple データセットを実行時の AI ジョブとしてダウンロードして処理します</block>
  <block id="c0cc307d9f63d0a096f8d6e3193cd561" category="paragraph">TuSimple データセットを実行としてダウンロードして処理するプロセス。 AI ジョブはオプションです。このプロセスでは、次の手順を実行します。</block>
  <block id="52eeaf7bac6d3e2111d129a11d0bafed" category="list-text">Docker イメージをビルドしてプッシュするか、既存の Docker イメージを使用する場合は、この手順を省略します（「 m uneer7589/download-tusimple:1.0 」など）</block>
  <block id="0d5647db76048e129c1146a822abbdd8" category="list-text">ホームディレクトリに移動します。</block>
  <block id="02c403c221afbdccdc4f7182e2eb5cb7" category="list-text">プロジェクト「 lane detection - SCNN-horovod` のデータディレクトリに移動します。</block>
  <block id="eed104c2f8af7c3526ec55b8cc69dde7" category="list-text">「 build_image.sh 」シェル・スクリプトを変更し、 Docker リポジトリを自分のものに変更します。たとえば、「 `m uneer7589` 」を Docker リポジトリ名に置き換えます。Docker イメージ名とタグ（「 ownload -tusimple 」や「 1.0 」など）を変更することもできます。</block>
  <block id="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="paragraph"><block ref="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed49e04589e6c9071bbd1af307f83a0" category="list-text">スクリプトを実行して Docker イメージを構築し、次のコマンドを使用して Docker リポジトリにプッシュします。</block>
  <block id="8ebf5e70d0ed304519c7c9b525d80af1" category="list-text">実行を送信します。 AI ジョブをダウンロードして抽出し、前処理し、 TupSimple LANE 検出データセットを「 pvc 」に格納します。このデータセットは、 NetApp Trident によって動的に作成されます。</block>
  <block id="050d58b165aef32cad86839521b721b2" category="list-text">実行ファイルを送信するには、次のコマンドを使用します。 AI job ：</block>
  <block id="83b4fb868b7505e293871c3e5accc98c" category="list-text">次の表に情報を入力して、実行ファイルを送信します。 AI job ：</block>
  <block id="e50d72d773874b2be58530daec43900c" category="cell">名前</block>
  <block id="37e9bb74490b0ac510effff5a546f11d" category="cell">ジョブの名前</block>
  <block id="5503ed8f71ae365eb6f5e8221562a0eb" category="cell">- PVC</block>
  <block id="626299ff067d1e6a178beced1631ab43" category="cell">[StorageClassName]: Size:ContainerMountPath という形式の PVC では、ストレージクラス azurenetappfiles で Trident を使用して、オンデマンドで PVC を作成します。この場合の永続ボリューム容量は 100Gi で、パス /mnt にマウントされます。</block>
  <block id="0247d7fb481075907b9eb467cfe90e3a" category="cell">イメージ（ Image ）</block>
  <block id="b30f1ca8b35fd6ccab829a959f414a51" category="cell">このジョブのコンテナの作成時に使用する Docker イメージ</block>
  <block id="22a55ba6c8590fa98f1b3234141f2848" category="paragraph"><block ref="22a55ba6c8590fa98f1b3234141f2848" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af270e479cd849e4a9cb6d17b76585ef" category="list-text">送信された RUN ： AI ジョブのリストを表示します。</block>
  <block id="f740410b6ea33d3ffc740140cc23a0e2" category="paragraph"><block ref="f740410b6ea33d3ffc740140cc23a0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51869a860c4af748ec2815d406929a17" category="list-text">送信されたジョブログを確認してください。</block>
  <block id="ab353387b0e5276e03aecae4cc95d150" category="paragraph"><block ref="ab353387b0e5276e03aecae4cc95d150" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84dd51baa0cf15db0a639dbb6d5d8ee" category="list-text">作成された「 pvc 」をリストします。次のステップでトレーニングを行うには ' この pvc コマンドを使用します</block>
  <block id="cc2e05fe54a847aee415a2deb0b7f13e" category="paragraph"><block ref="cc2e05fe54a847aee415a2deb0b7f13e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b20e4749f78095f0b9adf5c3cad36f81" category="list-text">実行中のジョブを確認します： AI UI （または app.run.ai` ）。</block>
  <block id="ced39410c19f3968638fc81e16743f32" category="paragraph"><block ref="ced39410c19f3968638fc81e16743f32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3dee54cb181d3bfde644600fb15bbac4" category="section-title">Horovod を使用して、分散レーン検出トレーニングを実施します</block>
  <block id="645e2c981858a720c673c6a782efd9ea" category="paragraph">Horovod を使用した分散型レーン検出トレーニングの実行は、オプションのプロセスです。ただし、実行する手順は次のとおりです。</block>
  <block id="04e568eec6dda4a0cfb1fc6680509d35" category="list-text">Docker イメージをビルドしてプッシュするか、既存の Docker イメージを使用する場合はこの手順を省略します（例：「 muneer7589/dist lane -detection ： 3.1 ）：」</block>
  <block id="b01fdc5088b4a04549ed5e7cc71f898b" category="list-text">ホームディレクトリに切り替えます。</block>
  <block id="14e21ef8495bc1dd543db0aebbe06c5b" category="list-text">プロジェクトディレクトリの lane -detection -SCNN-horovod. に移動します</block>
  <block id="0a27aa824e245e7b31f5f8d990636ead" category="list-text">「 build_image.sh 」シェルスクリプトを変更し、 Docker リポジトリを自分のものに変更します（たとえば、「 m uneer7589 」を Docker リポジトリ名に置き換えます）。Docker イメージ名とタグも変更できます（「 dist-dlane detection 」や「 3.1 」など）。</block>
  <block id="c9ce95c3d4cf96d5e894e4a834754cb6" category="paragraph"><block ref="c9ce95c3d4cf96d5e894e4a834754cb6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2776d43d1e635424496622f14cfd745c" category="list-text">スクリプトを実行して Docker イメージを構築し、 Docker リポジトリにプッシュします。</block>
  <block id="b9bcfd06c5cdfc67a00ffe8a0c846318" category="list-text">RUN ：「分散型トレーニング（ MPI ）実行のための AI ジョブ」を提出します。</block>
  <block id="f3b76b64a9761cfb85f0ddc37d910fef" category="list-text">実行の送信を使用：前述のステップで PVC を自動的に作成するための AI （データのダウンロード用）のみ RWO アクセスを許可します。これにより、複数のポッドまたはノードが分散トレーニング用に同じ PVC にアクセスすることはできません。アクセスモードを ReadWriteMany に更新し、 Kubernetes パッチを使用して更新します。</block>
  <block id="2874172b683ddc4047fd63f29baf543d" category="list-text">まず、次のコマンドを実行して PVC のボリューム名を取得します。</block>
  <block id="bcc0952c2970bfd6c85cd65050e00533" category="paragraph"><block ref="bcc0952c2970bfd6c85cd65050e00533" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64ac0e4e6343f4593e210b98f9c91de" category="list-text">ボリュームにパッチを適用し、アクセスモードを ReadWriteMany に更新します（次のコマンドでは、ボリューム名を各自のに置き換えてください）。</block>
  <block id="7a9d347cf2f324e82478a9cf243448f7" category="list-text">次の表の情報を使用して、分散トレーニングジョブを実行するための AI MPI ジョブを実行します。</block>
  <block id="b068931cc450442b63f5b3d276ea4297" category="cell">名前</block>
  <block id="e4580c1854231c935f0cf2eb4609d97a" category="cell">配布トレーニングジョブの名前</block>
  <block id="384dd16a327b7f16278642f008c27fab" category="cell">大きなシャン</block>
  <block id="fc9fed4d0a3cb207102499ba041f2603" category="cell">大容量の /dev/shm デバイスを RAM にマウントする共有ファイルシステムであり、複数の CPU ワーカーがバッチを処理して CPU RAM にロードするために十分な共有メモリを提供します。</block>
  <block id="530968b205d33b3869aa32e2933fbfad" category="cell">プロセス</block>
  <block id="403e4aa48fedb1c5777ee913b2f2bedb" category="cell">配布されたトレーニングプロセスの数</block>
  <block id="0aa0be2a866411d9ff03515227454947" category="cell">GPU</block>
  <block id="031492a2d708ca774bd08c099eb4dd79" category="cell">このジョブでジョブに割り当てる GPU / プロセスの数には、 3 つの GPU ワーカープロセスがあります（ --processes=3 ）。各プロセスは 1 つの GPU で割り当てられます（ --GPU 1 ）。</block>
  <block id="642542e40351edbd731ebad352b31317" category="cell">PVC</block>
  <block id="c50723a53a74a682495f8c3810ce4a65" category="cell">前のジョブ（ download-tusimple-data-0 ）によって作成された既存の永続ボリューム（ pvc -pdownload -tusimple-data-0 ）を使用し、パス /mnt にマウントします</block>
  <block id="8c236f63f205a50942b609a6d45734a7" category="cell">コンテナで設定する環境変数を定義します</block>
  <block id="61dcf83940f915d0c5fe5b985eed7be8" category="cell">ワーカーを使用します</block>
  <block id="f84e120605e14d9755a1ed2e8e03cea6" category="cell">引数を true に設定すると、マルチプロセスのデータロードがオンになります</block>
  <block id="90b186f5d2a6890e77373c8aa60461e7" category="cell">num_Workers</block>
  <block id="a10574eb8e119b847fb5ab95b788e723" category="cell">データローダーワーカープロセスの数</block>
  <block id="61c67ea819106ff81c08249014791d3b" category="cell">batch_size</block>
  <block id="243f7fe32e2dbb7748c1a018fe60016e" category="cell">トレーニングバッチサイズ</block>
  <block id="d07f4474a5e5996da9b6e57abb250331" category="cell">使用 _ VAL</block>
  <block id="919bc92a851c1d3e2c467e844398b751" category="cell">引数を true に設定すると、検証が可能になります</block>
  <block id="c4407b612c3b5e2c00c1b5522c686c84" category="cell">Val_batch_size</block>
  <block id="597765782da042e86019b4c919a86248" category="cell">検証バッチサイズ</block>
  <block id="18e0d33045db50bb37e6f2fcd5c0b842" category="cell">Snapshot の有効化</block>
  <block id="67c5deea68dff022b0f807ffb3bf56e2" category="cell">引数を true に設定すると、 ML バージョン管理のためにデータとトレーニング済みのモデルスナップショットを取得できます</block>
  <block id="cdd7dd1603420ef6c3efe7b264205137" category="cell">pvc_name</block>
  <block id="d95926771c9100db9ba3e3247c86a192" category="cell">スナップショットを作成する PVC の名前。上記のジョブ送信では、データセットとトレーニング済みモデルで構成される Pvc-de-download-tusimple-data-0 のスナップショットを作成します</block>
  <block id="b302d66ab7f3f0c94236ff26c8ead4d9" category="inline-image-macro">エラー：グラフィックイメージがありません</block>
  <block id="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="paragraph"><block ref="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3299ed00d03beff0cc2ebaf178a91786" category="list-text">送信されたジョブを一覧表示します。</block>
  <block id="2e593aa2ccf62807184e56a543d23e97" category="paragraph"><block ref="2e593aa2ccf62807184e56a543d23e97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82abe908a319245230ef0f3ec84c263f" category="list-text">送信されたジョブログ：</block>
  <block id="dab56217fc48a1919fee48434a7c7204" category="paragraph"><block ref="dab56217fc48a1919fee48434a7c7204" category="inline-image-macro-rx" type="image"></block></block>
  <block id="981528b0e4cd4a19c56310c6b9c915ce" category="list-text">実行中のトレーニングジョブを確認します。次の図に示すように、 AI GUI （または app.runai.ai): run ： AI Dashboard ）。最初の図は、分散トレーニングジョブ用に割り当てられた 3 つの GPU を AKS の 3 つのノードに分散し、 2 番目の実行である AI ジョブの詳細を示しています。</block>
  <block id="d8cbd4299e4baf5de5572bf6af32dd52" category="paragraph"><block ref="d8cbd4299e4baf5de5572bf6af32dd52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90fdc4068f0b660d1d6b102946986bd1" category="paragraph"><block ref="90fdc4068f0b660d1d6b102946986bd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e8bb0b427c33dd6cf63d1a3a37c7022" category="list-text">トレーニングが完了したら、作成され、実行済みの NetApp Snapshot コピーである AI ジョブを確認します。</block>
  <block id="6c94f812a836696605e3e2b6bd5ca768" category="paragraph"><block ref="6c94f812a836696605e3e2b6bd5ca768" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4c0a1395081fc81855e465c493f4967" category="section-title">NetApp Snapshot コピーからデータをリストアします</block>
  <block id="ec8de1dcfce51c9d877901e2f6f5971e" category="paragraph">NetApp Snapshot コピーからデータをリストアするには、次の手順を実行します。</block>
  <block id="5adc4d7860e7ad0f78ada0bb1f0eaca6" category="list-text">プロジェクトディレクトリの lane -detection -SCNN-horovod' に移動します</block>
  <block id="6344772f26907403fed713060f33b8f4" category="list-text">「 restore-snaphot-pvc.yaml 」を変更し、「 ataSource `name」 フィールドをデータのリストア元の Snapshot コピーに更新します。また、データを復元する PVC 名を変更することもできます。この例では、「 restored-tusimple」 です。</block>
  <block id="b3b5448c329ac882bc890a1be1a1b369" category="paragraph"><block ref="b3b5448c329ac882bc890a1be1a1b369" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f8efb3d1b86c88cfab193291776b6ad" category="list-text">「 restore -snapshot-pvc.yaml 」を使用して新しい PVC を作成します。</block>
  <block id="34c7c2e95019754701182fe2ab194499" category="paragraph"><block ref="34c7c2e95019754701182fe2ab194499" category="inline-image-macro-rx" type="image"></block></block>
  <block id="070856555a817dbf9a4061542b2098ca" category="list-text">復元されたばかりのデータをトレーニングに使用する場合、ジョブ送信は以前と同じです。次のコマンドに示すように、トレーニングジョブの送信時に「 pvc_name 」を復元された「 pvc_name 」に置き換えるだけです。</block>
  <block id="e945ddc4d35a9c49a17bd00c53db05a6" category="section-title">パフォーマンス評価</block>
  <block id="3451b157ef07ae84bfaba5fb6639c1ba" category="paragraph">解決策のリニアな拡張性を示すために、 GPU × 1 と GPU × 3 という 2 つのシナリオでパフォーマンステストを実施しました。GPU 割り当て、 GPU とメモリの使用率、シングルノードと 3 ノードの異なるメトリックは、 TuSimple LANE 検出データセットのトレーニング中に取得されました。データは、トレーニングプロセス中のリソース使用率を分析するために 5 倍に増加します。</block>
  <block id="b8077d533d2f9918c47d330cbac4392d" category="inline-link-macro">Azure NetApp Files サービスレベル</block>
  <block id="da9b7dc2993c3c848d5d9a9a15806d8c" category="paragraph">解決策を使用すると、まず小規模なデータセットを配置し、一部の GPU で作業を開始できます。GPU の需要とデータ量が増加した場合、標準階層ではテラバイト規模まで動的にスケールアウトし、 Premium 階層にすばやくスケールアップして、データを移動することなく、テラバイトあたりのスループットを 4 倍にすることができます。このプロセスの詳細については、を参照してください。 <block ref="bdbab4daa7de478307acc7147c869853" category="inline-link-macro-rx"></block>。</block>
  <block id="090a231c840a0cb23aa29c8d1afc7832" category="paragraph">1 つの GPU での処理時間は 12 時間 45 分でした。3 つのノードにまたがる 3 つの GPU での処理時間は約 4 時間 30 分でした。</block>
  <block id="49eca64b9f03702167beb48ebd38587b" category="paragraph">本ドキュメントの以降の各セクションにある図は、個々のビジネスニーズに基づくパフォーマンスと拡張性の例を示しています。</block>
  <block id="abfc10c2bc00a990735e6d27797295a8" category="paragraph">次の図は、 1 つの GPU 割り当てとメモリ使用率を示しています。</block>
  <block id="8d7e3abab70510c3f4636ff7bf953250" category="paragraph"><block ref="8d7e3abab70510c3f4636ff7bf953250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31a3d2def4927574922946c38f043c0b" category="paragraph">次の図は、シングルノードの GPU 利用率を示しています。</block>
  <block id="58cf0f270760f08ac96254402d0696dc" category="paragraph"><block ref="58cf0f270760f08ac96254402d0696dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dcca9cfd87d9f2087d720ef187655cea" category="paragraph">次の図は、シングルノードのメモリサイズ（ 16GB ）を示しています。</block>
  <block id="e22d39f2830d0f3e3944644d0f605d41" category="paragraph"><block ref="e22d39f2830d0f3e3944644d0f605d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="576c0843e21d5ee884a067aa7b6a1a40" category="paragraph">次の図は、シングルノードの GPU 数（ 1 ）を示しています。</block>
  <block id="ef855771be83c072ebaafc60d2d1933f" category="paragraph"><block ref="ef855771be83c072ebaafc60d2d1933f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2c50f1b8fc86c36cc0df94dd14b46b9" category="paragraph">次の図は、シングルノードの GPU 割り当て（ % ）を示しています。</block>
  <block id="e295f84458327d01315b814d8deb2aea" category="paragraph"><block ref="e295f84458327d01315b814d8deb2aea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b2b7f256373eac14419bfec5b84b21" category="paragraph">次の図は、 GPU の割り当てとメモリという 3 つのノードにまたがる 3 つの GPU を示しています。</block>
  <block id="e763ef0e4b7cb9d022bf6db49319c570" category="paragraph"><block ref="e763ef0e4b7cb9d022bf6db49319c570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94ab4242b167972f7a9f0513ca772555" category="paragraph">次の図は、 3 つのノードの使用率（ % ）にまたがる 3 つの GPU を示しています。</block>
  <block id="d786146ae56597413fa5be548126cda9" category="paragraph"><block ref="d786146ae56597413fa5be548126cda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c31ecb239228cac5e96860d42f9a4d" category="paragraph">次の図は、 3 つのノードにまたがる 3 つの GPU のメモリ利用率（ % ）を示しています。</block>
  <block id="2224958fd5113068ac8a3b55a336661b" category="paragraph"><block ref="2224958fd5113068ac8a3b55a336661b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79f05e8f99917560625d1cf3f2d4fc5d" category="inline-link">サービスレベル</block>
  <block id="07c1fda2408980b5d53ea06ad3cc5ed1" category="paragraph">既存のボリュームのサービスレベルを変更するには、を使用する別の容量プールにボリュームを移動します<block ref="bc9fbd5fd43d884f02abe6a6f9b51339" category="inline-link-rx"></block> 必要なのはボリュームです。ボリュームの既存のサービスレベル変更では、データを移行する必要はありません。また、ボリュームへのアクセスにも影響しません。</block>
  <block id="5e2ff0b5dc3206032a81aa3aecb7c462" category="section-title">ボリュームのサービスレベルを動的に変更する</block>
  <block id="58e691ddc6184f73e5d6b513ca5a3c49" category="paragraph">ボリュームのサービスレベルを変更するには、次の手順を実行します。</block>
  <block id="3f19b438418ed162387a3050b304c89b" category="list-text">Volumes （ボリューム）ページで、サービスレベルを変更するボリュームを右クリックします。［ プールの変更 ］ を選択します</block>
  <block id="5acf521dbc5099b2ec33a64efac89595" category="paragraph"><block ref="5acf521dbc5099b2ec33a64efac89595" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6533c4186062235d8b7f47e232e92597" category="list-text">プールの変更ウィンドウで、ボリュームの移動先とする容量プールを選択します。[OK] をクリックします。</block>
  <block id="3f0874d07ce6ae728a6dcdda7903f9cd" category="paragraph"><block ref="3f0874d07ce6ae728a6dcdda7903f9cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb935c59f24539e0966b7ab5c761e862" category="section-title">サービスレベルの変更を自動化</block>
  <block id="1391028ed384c93fd59fd5a0097f9181" category="paragraph">動的サービスレベルの変更は現在、パブリックプレビューで有効になっていますが、デフォルトでは有効になっていません。Azure サブスクリプションでこの機能を有効にするには、次の手順を実行します<block ref="5c3671452d40598396b030d5c9c6dc27" category="inline-link-rx"></block>」</block>
  <block id="407443b5508c517acd825fbcddb7ab4c" category="inline-link">AZ netappfiles ボリューム： Azure NetApp Files （ ANF ）ボリュームリソースの管理</block>
  <block id="1d3afb31c5d2a81fca940ae760671a1c" category="list-text">Azure では、 CLI コマンドでも次のコマンドを使用できます。Azure NetApp Files のプール・サイズの変更の詳細については、を参照してください<block ref="8b45caafcc8d758d5c37edb19f8a2761" category="inline-link-rx"></block>。</block>
  <block id="ebd5b070cb8457b94f1916baa92c3c7d" category="inline-link">Azure NetApp Files ボリュームのプールを変更します</block>
  <block id="d5460fd5fbfbf643b9a4bc1d1de279d0" category="list-text">ここに示す 'set-aznetappfilesvolumepool' コマンドレットを使用すると、 Azure NetApp Files ボリュームのプールを変更できます。ボリュームプールのサイズ変更の詳細については、を参照してください<block ref="70c8d95cde8b63eae0d37a8b81a31482" category="inline-link-rx"></block>。</block>
  <block id="ca6d5ad374e3cf268dec341c0c398442" category="summary">このアーキテクチャでは、 AI や機械学習（ ML ）の分散型トレーニングプロセスであるレーン検出において、最も演算負荷の高い部分に焦点が当てられています。</block>
  <block id="8cb13336dc020a2fb7bca9d4e940cc64" category="paragraph">このアーキテクチャでは、 AI や機械学習（ ML ）の分散型トレーニングプロセスであるレーン検出において、最も演算負荷の高い部分に焦点が当てられています。車線検知は、自動運転で最も重要な作業の 1 つであり、車線区分線の位置を特定することで車両を誘導するのに役立ちます。車線標示などの静的コンポーネントは、車両を高速道路でインタラクティブかつ安全に走行させる。</block>
  <block id="0721542454dcaa77c97cd9c545d9063f" category="paragraph">畳み込みニューラルネットワーク（ CNN ）ベースのアプローチでは、シーンの理解とセグメント化が新たなレベルにまで押しつけられています。長い構造やリージョンが含まれているオブジェクト（ポール、車線の陰など）は適切に機能しませんが、空間的畳み込みニューラルネットワーク（ SCNN ）は、 CNN を豊かな空間レベルに一般化します。同一層のニューロン間で情報を伝播できるため、車線、ポール、トラックなどの構造化された物体（オ結論を含む）に最適です。この互換性は、空間情報を強化し、滑らかさと連続性を維持できるためです。</block>
  <block id="df38a65c87631c9530cc3a6832ea7a7d" category="paragraph">モデルがデータセット内のさまざまなコンポーネントを学習し、区別できるように、数千ものシーンイメージをシステムに挿入する必要があります。これらのイメージは天候、日中か夜、マルチレーンハイウェーの道および他の交通条件を含んでいる。</block>
  <block id="f7759f002b4a60b5c837abb7f8936037" category="paragraph">トレーニングには、質の高いデータと量のニーズがあります。1 つの GPU または複数の GPU でトレーニングを完了するには、数日から数週間かかることがあります。データ分散トレーニングは、マルチノードの GPU を複数使用することでプロセスを高速化できます。Horovod は、分散トレーニングを提供する一方で、 GPU のクラスタ間でデータを読み取ることは障害となる可能性があるフレームワークの 1 つです。Azure NetApp Files は、超高速、高スループット、一貫した低レイテンシを実現し、スケールアウト / スケールアップ機能を提供して、 GPU がコンピューティング容量の最適な値に活用されるようにします。当社の実験では、 SCNN を使用してレーン検出をトレーニングするために、クラスタ全体のすべての GPU が平均で 96% 以上使用されていることが確認されました。</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="section-title">対象読者</block>
  <block id="0ca450eccdc7141b5e85e9e691a7f16b" category="paragraph">データサイエンスには、 IT とビジネスに関する複数の分野が組み込まれているため、ターゲットを絞ったオーディエンスには複数のペルソナが含まれます。</block>
  <block id="8acb1f50d0ada4e1149c01a5aa15b9ce" category="list-text">データサイエンティストは、選択したツールとライブラリを柔軟に使用する必要があります。</block>
  <block id="d0ba3808090644db73caeb23fcc2b17c" category="list-text">データエンジニアは、データフローの仕組みと、データが格納されている場所を把握する必要があります。</block>
  <block id="22a8c99419dee54a28ed1e2355a6706b" category="list-text">自動運転のユースケースエキスパート。</block>
  <block id="18f66c4bad233033dabddf6ff1289eeb" category="list-text">クラウド（ Azure ）リソースのセットアップと管理を担当するクラウド管理者およびアーキテクト。</block>
  <block id="4c9b6067f04f945e9247ecd00c22e328" category="list-text">DevOps エンジニアは、新しい AI / ML アプリケーションを継続的統合 / 継続的導入（ CI / CD ）パイプラインに統合するためのツールを必要としています。</block>
  <block id="53720cf6403ac6b8a2402cce66c79d4f" category="list-text">ビジネスユーザは、 AI / ML アプリケーションにアクセスしたいと考えています。</block>
  <block id="68dcdc6243e54c14b4c41c129d574c43" category="paragraph">このドキュメントでは、 Azure NetApp Files 、 Run ： AI 、 Microsoft Azure の 3 つの役割がそれぞれビジネスにもたらす価値について説明します。</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="section-title">解決策テクノロジ</block>
  <block id="8017303b9b2c96742151083f089fc51f" category="paragraph">このセクションでは、 Azure クラウドで完全に稼働する規模の分散トレーニング解決策を実装することで、レーン検出のユースケースに必要なテクノロジについて説明します。次の図は、解決策アーキテクチャの概要を示しています。</block>
  <block id="f17291da16ed3dd7b705548f16706120" category="paragraph">この解決策で使用される要素は次のとおりです。</block>
  <block id="f28c5620810ae2a6961a1811277a7ff8" category="list-text">Azure Kubernetes Service （ AKS ）</block>
  <block id="03023f4a63d3d8f8ff86ff8246f75b9a" category="list-text">NVIDIA GPU を搭載した Azure コンピューティング SKU</block>
  <block id="ae5ba69294a1b9feb03e6dd75395092c" category="list-text">実行： AI</block>
  <block id="951370659c41a55ac9f80ff19c2f4b26" category="paragraph">ここに記載されているすべての要素へのリンクをに示します <block ref="c8b73068ae16e202922904f7ed452f8e" category="inline-link-macro-rx"></block> セクション。</block>
  <block id="00d9279819736707d2b224ec427a8aae" category="paragraph"><block ref="00d9279819736707d2b224ec427a8aae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6a2faff353ad4e74bf3ee92e5d8b9c6" category="section-title">クラウドリソースとサービスの要件</block>
  <block id="5b691a1a00c6c03be70e559f55ae4fef" category="paragraph">次の表に、解決策の実装に必要なハードウェアコンポーネントを示します。解決策の実装で使用されるクラウドコンポーネントは、お客様の要件に応じて異なる場合があります。</block>
  <block id="5f3bc5eb45e6b472bf3345d1036945e9" category="cell">AK</block>
  <block id="55b8660903ebaaed924e945432fe269e" category="cell">少なくとも 3 つのシステムノードと 3 つの GPU ワーカーノードが必要です</block>
  <block id="3580a6b3e7ba0d55af17daee07244cbd" category="cell">仮想マシン（ VM ） SKU システムノード</block>
  <block id="8f75b0af54b5e672a660f4f1f1557f18" category="cell">3 つの Standard_DS2_v2</block>
  <block id="a6066b29e1c4603af2c5c46cf549f764" category="cell">VM SKU GPU ワーカーノード</block>
  <block id="6aa4bab72f83c0b68587ee208f2c9ab0" category="cell">3 つの Standard_NC6s_v3</block>
  <block id="3468e131592d70a22139936f3fb21403" category="cell">4TB の標準ティア</block>
  <block id="cb251883efe045266871b7dd15229644" category="cell">バージョンまたはその他の情報</block>
  <block id="bb451ae1fa5a629a0307949d38a60e2d" category="cell">AK - Kubernetes バージョン</block>
  <block id="f2d1dd8f39098da402272f7606fd2638" category="cell">1.18.14</block>
  <block id="13c5eaa211a3778d391d5c8f65b80234" category="cell">AI CLI を実行</block>
  <block id="89633b9d6f401377b6ece0682b92530a" category="cell">v2.2.25</block>
  <block id="4b138e2d1492b1e550d42348c65cbf82" category="cell">実行： AI Orchestration Kubernetes Operator バージョン</block>
  <block id="6db851ff24c4b893a85242e63bbea119" category="cell">1.0.109</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">ホロボド</block>
  <block id="4a7724061c17f8cf5be61a8adf4c170f" category="cell">0.21.2</block>
  <block id="44adee2c140fc723412bae93732e5993" category="cell">20.01.1</block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">ONTAP VASA プロバイダでは、異なるストレージへのフェイルオーバーがサポートされます。たとえば、システムは、エッジの場所にある ONTAP Select からコアデータセンターの AFF システムにフェイルオーバーできます。ストレージの類似性に関係なく、レプリケーションが有効な VM ストレージポリシーのストレージポリシーマッピングとリバースマッピングを常に設定して、リカバリサイトで提供されるサービスが期待される要件を満たしていることを確認する必要があります。次のスクリーンショットは、ポリシーマッピングの例を示しています。</block>
  <block id="70be05b3500f28affc2d048f81c4f7ab" category="sidebar">Azure の分散トレーニング - レーン検出</block>
  <block id="7767872606b9c99eb656c9568c1fdd83" category="sidebar">レーン検出– AI を実行する分散トレーニング</block>
  <block id="11eb332ab75184a78c40c9174e16f520" category="video-title">ネットアップと VMware ：力を合わせて</block>
  <block id="b761cb4d962320708880627e8e2fe971" category="inline-link-macro">ONTAP を使用した VMware vSphere Virtual Volumes</block>
  <block id="5b90454e2bf0f381c8f7fc928ef6fb9e" category="list-text"><block ref="5b90454e2bf0f381c8f7fc928ef6fb9e" category="inline-link-macro-rx"></block></block>
  <block id="5ab6c918ee903c74a7d7c97b2432ebaf" category="section-title">最新の VMware ソリューションのビデオデモをご覧ください</block>
  <block id="04e008204e728ef166ffc8c85db580ed" category="list-text"><block ref="04e008204e728ef166ffc8c85db580ed" category="inline-link-macro-rx"></block></block>
  <block id="207681662de4971035cc8d5c9347c986" category="list-text"><block ref="207681662de4971035cc8d5c9347c986" category="inline-link-macro-rx"></block></block>
  <block id="8ca7386c3cb63b01ffc6387ba41427ae" category="list-text"><block ref="8ca7386c3cb63b01ffc6387ba41427ae" category="inline-link-macro-rx"></block></block>
  <block id="c2a201ca982ecfefdcfec43a8df28397" category="list-text"><block ref="c2a201ca982ecfefdcfec43a8df28397" category="inline-link-macro-rx"></block></block>
  <block id="a8e3bfc2dc840604c0168dd5f89aacec" category="list-text"><block ref="a8e3bfc2dc840604c0168dd5f89aacec" category="inline-link-macro-rx"></block></block>
  <block id="6ef66ca131701cfdb70302d3099b7550" category="list-text"><block ref="6ef66ca131701cfdb70302d3099b7550" category="inline-link-macro-rx"></block></block>
  <block id="9934e59457fa5f31d39a58f1d55ac5d5" category="list-text"><block ref="9934e59457fa5f31d39a58f1d55ac5d5" category="inline-link-macro-rx"></block></block>
  <block id="f09e9fdda59d2e9d9172bd89b5dc9369" category="list-text"><block ref="f09e9fdda59d2e9d9172bd89b5dc9369" category="inline-link-macro-rx"></block></block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="section-title">ビデオ</block>
  <block id="8ff6498eeabd53b4271d75f543dc3bc4" category="list-text"><block ref="8ff6498eeabd53b4271d75f543dc3bc4" category="inline-link-macro-rx"></block></block>
  <block id="4d0f73eb280cb12c373e099d1c320690" category="list-text"><block ref="4d0f73eb280cb12c373e099d1c320690" category="inline-link-macro-rx"></block></block>
  <block id="f1c2408ffc6e67ac6b34eb8da2b3039c" category="list-text"><block ref="f1c2408ffc6e67ac6b34eb8da2b3039c" category="inline-link-macro-rx"></block></block>
  <block id="baa1898009cc7495f8c4e7732ce7433a" category="list-text"><block ref="baa1898009cc7495f8c4e7732ce7433a" category="inline-link-macro-rx"></block></block>
  <block id="7518aab5e189037f632ee46ea9e3cf07" category="video-title">『 Deploying Dynamic Persistent NetApp Storage for VMware Tanzu 』、パート 1</block>
  <block id="f86bf601d6e42c44cf076ea1772ae13c" category="video-title">『 Deploying Dynamic Persistent NetApp Storage for VMware Tanzu 』、パート 2</block>
  <block id="bf5c12d4eed319d2dc2b2b7279944f71" category="video-title">『 Deploying Dynamic Persistent NetApp Storage for VMware Tanzu 』、パート 3</block>
  <block id="a398d57165e21c951dd9c9def41598a9" category="inline-link-macro">VMware Cloud on AWS ：富士通が CVO を使用して何百万ドルものコストを削減する方法をご紹介</block>
  <block id="d750d47d5e87a6c526e7b40e12eab95b" category="list-text"><block ref="d750d47d5e87a6c526e7b40e12eab95b" category="inline-link-macro-rx"></block></block>
  <block id="334af7a3f788d83aa889d1ca7bd769f5" category="summary">このページでは、 ONTAP の Storage Efficiency について説明します。</block>
  <block id="c13f924c3ceac59a16a8a1ea96d43c91" category="doc">ONTAP の Storage Efficiency 機能</block>
  <block id="241a4f0482dfad2f5fc79419b18356c0" category="section-title">Storage Efficiency について</block>
  <block id="185081022bfbcfda8db4798eb4eed8c0" category="paragraph">ネットアップは、本番環境のワークロードで重複排除を初めて実現したのですが、この分野の最初または最後のイノベーションではありませんでした。まずは、パフォーマンスに影響を与えない、スペース効率に優れたデータ保護メカニズムである ONTAP Snapshot コピーと、本番環境やバックアップ用に VM の読み取り / 書き込みコピーを瞬時に作成する FlexClone テクノロジからスタートしました。ネットアップは、重複排除、圧縮、ゼロブロック重複排除などのインライン機能を提供し、高価な SSD のストレージを最後まで絞ります。ONTAP は最近、 Storage Efficiency を強化するためにコンパクション機能を追加しました。</block>
  <block id="d019495551b4899a9019567122f1e076" category="list-text">* インラインのゼロブロック重複排除。ゼロブロックのスペースを無駄に消費しません。</block>
  <block id="7634d08ecc5702f74271a3313502ec02" category="list-text">* インライン圧縮。 * データブロックを圧縮して、必要な物理ストレージ量を減らします。</block>
  <block id="8b7bb53489bfc2a6808c1d76314fa0d4" category="list-text">* インライン重複排除。 * ディスク上の既存のブロックが使用されていた受信ブロックを削除します。</block>
  <block id="b762ae2f528b0eca55e7be3f599e909d" category="list-text">* インラインデータコンパクション。 * より小さな I/O 処理とファイルを各物理ブロックにパックします。</block>
  <block id="fba6442665875d123719f22baafc619d" category="inline-image-macro">ストレージの効率化</block>
  <block id="f468c00b41afc3485647008dcf80cba1" category="paragraph"><block ref="f468c00b41afc3485647008dcf80cba1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8405ea940cfeab85adddf9d3ed915a97" category="paragraph">重複排除、データ圧縮、データコンパクションを一緒に、または個別に実行して、 FlexVol で最適なスペース削減効果を得ることができます。これらの機能を組み合わせることで、 VSI では最大 5 分の 1 、 VDI では最大 30 分の 1 のコストを削減できました。</block>
  <block id="b8c11cd315128247329c3d878c2143fe" category="inline-link">重複排除、データ圧縮、データコンパクションによるストレージ効率の向上</block>
  <block id="65bbb718266195d68e8d1accfc443e28" category="admonition">ONTAP の Storage Efficiency 機能の詳細については、を参照してください<block ref="f358a7faf94e9f579d11f8fc4efdbdec" category="inline-link-rx"></block> ONTAP 9 ドキュメントセンターを参照してください。</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">Virtual Volumes （ VVol ）と Storage Policy Based Management （ SPBM ）</block>
  <block id="25e09c324ad3c89ee3aa01454fce14cd" category="section-title">VVol と SPBM について</block>
  <block id="ab3304a5226d57b9bcaf0c7b3f819735" category="paragraph">ネットアップは、 vSphere Virtual Volumes （ VVol ）の開発において VMware と初期の設計パートナーとして、アーキテクチャに関する情報提供と、 VVol および VMware vSphere APIs for Storage Awareness （ VASA ）のサポートを提供していました。このアプローチにより、 VM のきめ細かなストレージ管理が VMFS にもたらされるだけでなく、 Storage Policy-Based Management （ SPBM ）を通じてストレージプロビジョニングの自動化もサポートされています。</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">SPBM は、仮想化環境で使用できるストレージサービスと、プロビジョニングされたストレージ要素の間の抽象化レイヤとして機能するフレームワークを、ポリシーを通じて提供します。このアプローチにより、ストレージアーキテクトは、 VM 管理者が簡単に利用できるさまざまな機能を備えたストレージプールを設計できます。仮想マシンのワークロード要件をプロビジョニングされたストレージプールと照合することで、仮想マシンごとまたは仮想ディスクレベルのさまざまな設定をきめ細かく制御できます。</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">ONTAP は VVol の規模においてストレージ業界をリードし、 1 つのクラスタで数十万もの VVol をサポートします。一方、エンタープライズアレイや小規模なフラッシュアレイベンダーは、アレイあたり数千の VVol をサポートします。また、 VVOL 3.0 をサポートする機能が追加され、 VM のきめ細かな管理が進化しています。</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">TR-4400 ：『 VMware vSphere Virtual Volumes with ONTAP 』</block>
  <block id="69173613658292fc2adeb513b12f29ca" category="admonition">VMware vSphere Virtual Volumes 、 SPBM 、および ONTAP の詳細については、を参照してください<block ref="354226c2546b1aed39f1c0c484e6a98a" category="inline-link-rx"></block>。</block>
  <block id="01a7d7174ccc6593753679eefec17d49" category="summary">このページでは、 VMware vSphere 環境で ONTAP の基本機能を自動化するメリットについて説明します。</block>
  <block id="1406aa071af210d31c6a2951fe66ddcc" category="doc">ONTAP と vSphere の自動化の概要</block>
  <block id="8e2b0503a0ad76f57c96738d7f0a3b0d" category="section-title">VMware の自動化</block>
  <block id="b5845209cb81dad561de4abe6e4481c4" category="paragraph">VMware ESX の最初の日から VMware 環境を管理するには、自動化が不可欠です。インフラをコードとして導入し、手法をプライベートクラウドの運用に拡張できるため、拡張性、柔軟性、自己プロビジョニング、効率性に関する懸念を軽減できます。</block>
  <block id="f7c9a2e2ec395a7e4b605bb3df40abf8" category="paragraph">自動化は、次のカテゴリに分類できます。</block>
  <block id="cba6f5a209d4f2ac1839f1c1e0a10051" category="list-text">* 仮想インフラストラクチャの導入 *</block>
  <block id="f41d0733c4edc0bf273a3d0587efb21e" category="list-text">* ゲストマシンの操作 *</block>
  <block id="7f2a4b0fa787b1f058accb56cc377af8" category="list-text">* クラウド運用 *</block>
  <block id="290a03d97ea4e48144d20f313e0a0826" category="paragraph">インフラの自動化に関して、管理者にはさまざまなオプションがあります。ホストプロファイルやカスタマイズ仕様などのネイティブ vSphere 機能を使用して、 VMware ソフトウェアコンポーネント、オペレーティングシステム、ネットアップストレージシステムで使用可能な API に仮想マシンを追加することで、重要なドキュメントやガイダンスを利用できます。</block>
  <block id="217dd73ccc3bd89b5d4e35d0bf50ea6c" category="paragraph">Data ONTAP 8.0.1 以降では、 ESX 4.1 以降を実行する ESX ホストで、 VMware vSphere APIs for Array Integration （ VAAI ）の特定の機能がサポートされます。VAAI は、 VMware vSphere ESXi ホストとストレージデバイス間の通信を可能にする一連の API です。これらの機能を使用すると、 ESX ホストからストレージシステムに処理の負荷をオフロードし、ネットワークスループットを向上させることができます。これらの機能は、正しい環境の ESX ホストで自動的に有効になります。VAAI 機能を使用している範囲は、 VAAI カウンタに含まれる統計情報で確認できます。</block>
  <block id="16123583d64fd438c5d7f5b61a1c1d2f" category="paragraph">VMware 環境の導入を自動化するための最も一般的な開始点は、ブロックベースまたはファイルベースのデータストアのプロビジョニングです。対応する自動化を開発する前に、実際のタスクの要件を確認することが重要です。</block>
  <block id="a78bd4dd1db96affe0c2889376cccf53" category="paragraph">VMware 環境の自動化の詳細については、次のリソースを参照してください。</block>
  <block id="ebd98e15bf07fe37dfdc879f9d0d1f48" category="inline-link">NetApp Pub</block>
  <block id="6123648b7dec055b609781b4d47c1b26" category="list-text"><block ref="6c65ff4f1dfb7aa26df896b1c9c849eb" category="inline-link-rx"></block>。ネットアップの構成管理と自動化：</block>
  <block id="7c4272bef0cc405b65fc74e3791664bc" category="inline-link">VMware 向けの Ansible Galaxy Community</block>
  <block id="59fb42204e71850f7fd7024e5e6a1058" category="list-text"><block ref="c471bcaf7efa6fb129f37edaa7c41a56" category="inline-link-rx"></block>。VMware 向けの Ansible リソースの集まり。</block>
  <block id="1ec695bd70399ce37180f1d84a33d151" category="inline-link">VMware ｛ code ｝ のリソース</block>
  <block id="489c5322cef99651507b070e2240b6a8" category="list-text"><block ref="77e0562f07512a7a248241b7170b6944" category="inline-link-rx"></block>。フォーラム、設計基準、サンプルコード、開発者ツールなど、ソフトウェア定義データセンターのソリューションを設計するために必要なリソース。</block>
  <block id="1e6584aafa5ae98aebb88d3ddecdaae5" category="doc">vSphere 管理者向けの ONTAP の概要</block>
  <block id="135b7f440129fbbacbc948adfb10ccec" category="paragraph">NetApp ONTAP は、オンプレミス環境とクラウド環境のどちらに導入しても、ストレージやデータの管理を簡易化し、 VMware 環境を明確に補完します。ネットアップの SAN ベースと NAS ベースのどちらの VMware アーキテクチャでも、業界最高レベルのデータ保護、 Storage Efficiency テクノロジ、卓越したパフォーマンスを実現できることは、何万ものお客様が vSphere 環境向けのストレージ解決策として ONTAP を選択している理由の 1 つです。</block>
  <block id="f93e431aaf745d4b5e4ecbd6c005b564" category="paragraph">ネットアップでは、仮想化環境の管理という課題に直面しているお客様をサポートするために、さまざまな VMware 製品の VMware プラグイン、検証、および認定資格を多数提供しています。ネットアップは、 VMware が仮想化に何をもたらすかをストレージとデータの管理に活用することで、お客様は物理ストレージの管理ではなく、中核となるコンピテンシーに注力できます。VMware とネットアップの 20 年近くにわたるこのパートナーシップは、 VMware Cloud Foundation や Tanzu などの新しいテクノロジが出現したときに、 vSphere の基盤を引き続きサポートしつつ、お客様に高い価値を提供し続けています。</block>
  <block id="b4e56252f38c98dde71bd489a93805fc" category="paragraph">お客様が重視する主な要因は次のとおりです。</block>
  <block id="d6f750861d7ae27706ca32ed1f4c1ac8" category="list-text">* ユニファイドストレージ *</block>
  <block id="04d737333774adefb9817d0115bab79b" category="list-text">* ストレージ効率 *</block>
  <block id="c44a0be5f0db0511994f2f8e76afeb25" category="list-text">* 仮想ボリュームとストレージ・ポリシー・ベースの管理 *</block>
  <block id="d78a5fe569360bb327d51dd5060d723c" category="list-text">* ハイブリッドクラウド *</block>
  <block id="45649dc755190fc40be0b7e38ec84851" category="paragraph">サポートされているネットアップと VMware のソリューションの詳細については、次のリソースを参照してください。</block>
  <block id="ec1bd76731eb238fa601fb03391f78d4" category="inline-link">NetApp Interoperability Matrix Tool を参照してください</block>
  <block id="d46e58d91be6ffba761ab9bd05a46fc5" category="list-text"><block ref="b47ad5992ee82e05d51ff22d87ae20c3" category="inline-link-rx"></block> IMTIMT では、 FC / FCoE 、 iSCSI 、 NFS 、 CIFS の各構成の構築に使用できる正規のコンポーネントとバージョンを定義しています。</block>
  <block id="8034c6a17370dafb5b3f6f5add755c62" category="inline-link">『 VMware Compatibility Guide 』を参照してください</block>
  <block id="f0c67c4d38f07e6eb4bead0202260ddb" category="list-text"><block ref="a9846c61dcf62d503a7738adf47f11be" category="inline-link-rx"></block>。『 VMware Compatibility Guide 』には、システム、 I/O 、ストレージ /SAN 、およびバックアップと VMware Infrastructure およびソフトウェア製品との互換性が記載されています</block>
  <block id="0f0b69f9725d17d0a8d3ceebcf33f72f" category="inline-link">VMware 向け NetApp ONTAP ツール</block>
  <block id="2be6bbf4ea543b07ab3b9a218eb509cc" category="list-text"><block ref="d1284fbca35bc1b47ead37f18b1c3ba2" category="inline-link-rx"></block>。VMware vSphere 用の ONTAP ツールは、 VSC 、 VASA Provider 、 Storage Replication Adapter （ SRA ）の拡張機能を含む vCenter Server プラグインです。</block>
  <block id="f2a03b032017931383878c3ef48cdb0a" category="list-text">ホスト、ターゲット、 SVM 、および LUN の情報の ONTAP WWPN</block>
  <block id="6c2e28f86b2049d110f0e73e9bb78709" category="list-text">接続された ONTAP FC データポートと vSphere ホスト</block>
  <block id="acd7065eaa19f6ad949216b6dcca52b6" category="list-text">VMware vSphere 向け ONTAP ツールの導入、設定、利用可能な状態</block>
  <block id="94dafc85e46c3bc0d374c052b1075890" category="list-text">との互換性を確認します<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="0b3f75b021ef6bdc0a532e2d9b2a9d74" category="inline-link-macro">FCP の ONTAP ライセンスがあることを確認します。</block>
  <block id="3c56f50608e95955ed2e1a3fb8b1dad1" category="list-text"><block ref="3c56f50608e95955ed2e1a3fb8b1dad1" category="inline-link-macro-rx"></block></block>
  <block id="f8aa00b1a94d3290ba6ac653b792dd8a" category="list-text">ライセンスを追加するには 'license add-license-code &lt;license code&gt; を使用します</block>
  <block id="25d85157bcfdbb601bbda056cd3a5bc6" category="list-text">HBA ドライバがインストールされていることを確認します。VMware がサポートする HBA には、すぐに使用できるドライバが導入されています に表示されます <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block>。</block>
  <block id="2093983846bbd6cd7e3d486531259f7d" category="summary">このページでは、 ONTAP と VMware vSphere で利用できるハイブリッドクラウド機能について説明します。</block>
  <block id="df94231e8c7a2b7372365ba3eb8ad621" category="doc">ONTAP と vSphere を使用したハイブリッドクラウド</block>
  <block id="c689fcb3c54ae34ac006a005e03aad07" category="section-title">ハイブリッドクラウドについて</block>
  <block id="cc81a55aaf5bd2bdf603a2aea92a875a" category="paragraph">ONTAP ソリューションは、オンプレミスのプライベートクラウド、パブリッククラウドインフラ、またはその両方のメリットを組み合わせたハイブリッドクラウドのいずれに使用しても、データ管理を合理化し、最適化するためのデータファブリックの構築を支援します。まずハイパフォーマンスのオールフラッシュシステムを導入し、データ保護とクラウドコンピューティングのためにディスクストレージシステムとクラウドストレージシステムのどちらかと組み合わせます。</block>
  <block id="9afb01441ce427bb3863eaccd46b9b5d" category="paragraph">Azure 、 AWS 、 IBM 、 Google のクラウドから選択して、コストを最適化し、ロックインを回避できます。必要に応じて、 OpenStack とコンテナテクノロジの高度なサポートを活用できます。</block>
  <block id="8a61dac106bf2a7f3b869c8ff58c4ce5" category="paragraph">多くの場合、お客様はクラウドへの移行を開始する際に最初に試すのがデータ保護です。保護は、キーデータの非同期レプリケーションと同様に簡単に行うことも、完全なホットバックアップサイトとして複雑にすることもできます。データ保護は、主に NetApp SnapMirror テクノロジに基づいています。</block>
  <block id="d059ff0a497ad1427248dbb8f770b1d5" category="paragraph">ワークロード全体をクラウドに移行することを選択しているお客様もいます。これは、単にクラウドをデータ保護に使用するだけではなく、クラウドベースのストレージを使用するようにアプリケーションを書き換える必要がないため、 ONTAP の移動が簡単になります。クラウドの ONTAP は、オンプレミスの ONTAP と同様に機能します。オンプレミスの ONTAP システムは、より少ない物理スペースに多くのデータを格納し、ほとんど使用されないデータを階層化して低コストのストレージに格納できるデータ効率化機能を備えています。ONTAP は、ハイブリッドクラウド構成を使用する場合でも、ワークロード全体をクラウドに移行する場合でも、ストレージのパフォーマンスと効率を最大限に高めます。</block>
  <block id="ad622d292f56f20b32a61fe1b8bd2f56" category="paragraph">ネットアップ ONTAP では、クラウドベースのバックアップ（ SnapMirror クラウド、 Cloud Backup Service 、 Cloud Sync ）やストレージ階層化 / アーカイブツール（ FabricPool ）も提供しており、運用コストの削減とクラウドの幅広いリーチの活用を支援します。</block>
  <block id="49c437176039e1c910728eac1f332689" category="paragraph">次の図は、ハイブリッドクラウドのユースケースの例を示しています。</block>
  <block id="e61ead4102c89a9758572df81301a1d2" category="inline-image-macro">ハイブリッドクラウド</block>
  <block id="9188eeccf6b5386d9573cea87cf05102" category="paragraph"><block ref="9188eeccf6b5386d9573cea87cf05102" category="inline-image-macro-rx" type="image"></block></block>
  <block id="293f510d2162f186910d817d97121159" category="inline-link">ONTAP とクラウド</block>
  <block id="3963100a9d31ca50911a23ac5c87aca1" category="admonition">ONTAP とハイブリッドクラウドの詳細については、を参照してください<block ref="92883b1d8840f28e1ad4810811bf56b5" category="inline-link-rx"></block> ONTAP 9 ドキュメントセンターを参照してください。</block>
  <block id="980e76f4fd03b06bfe740133284e92a9" category="list-text">ONTAP システムのネットワークデータポートと接続された vSphere ホストで使用</block>
  <block id="1bc0e04873be7c6291aef492ff2785cc" category="list-text"><block ref="d503e168b9096ac416caa1c8f13ab28a" category="inline-link-macro-rx"></block> default-data-blocks サービスポリシーを使用できます。</block>
  <block id="c436a9a899f5e1cfacf8828c90931ca9" category="list-text"><block ref="24788d985e181b3194881517c2ec7650" category="inline-link-macro-rx"></block> 確認には、「 network interface service-policy show 」を使用できます。</block>
  <block id="c49b54ab60508b16176724eeb8118049" category="list-text"><block ref="3a73ce9b9237c3e09863bf7b049ce423" category="inline-link-macro-rx"></block> VMware vSphere 用の ONTAP ツールを使用する場合は、この手順を省略してください。LUN ごとにこの手順を繰り返します。</block>
  <block id="536d7ac288972152b209e6f004917285" category="list-text"><block ref="95a6e2e5fae04247474cdc6a729342fc" category="inline-link-macro-rx"></block> 一般的なユースケースとしては、ソフトウェア iSCSI イニシエータがあります。</block>
  <block id="f5852a230bef6cf666f848c5a2137db2" category="doc">ONTAP ユニファイドストレージ</block>
  <block id="0dc14c0a294efec0c8cab98ebffa39f0" category="section-title">ユニファイドストレージについて</block>
  <block id="d00516b816f266ee64e7b1de5af59ff2" category="paragraph">ONTAP ソフトウェアを実行するシステムは、いくつかの重要な方法で統合されます。本来、このアプローチは、 1 つのストレージシステムで NAS プロトコルと SAN プロトコルの両方をサポートすることを指していました。 ONTAP は、 NAS における従来の強みと同様に、業界をリードする SAN 向けプラットフォームとして継続されています。Storage Virtual Machine （ SVM ）は、 ONTAP ソフトウェアを実行しているシステムにクライアントからアクセスできるようにする、論理的な構成要素です。SVM は、論理インターフェイス（ LIF ）を介して複数のデータアクセスプロトコルを使用して同時にデータをやり取りできます。SVM は、 CIFS や NFS などの NAS プロトコルでファイルレベルのデータアクセスを提供し、 iSCSI 、 FC / FCoE 、 NVMe などの SAN プロトコルでブロックレベルのデータアクセスを提供します。SVM は、 SAN クライアントと NAS クライアントそれぞれに同時にデータを提供できます。</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="inline-image-macro">ユニファイドストレージ</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d59082aeee25c59b01266eaef6cb14" category="paragraph">vSphere 環境では、このアプローチは仮想デスクトップインフラ（ VDI ）向けのユニファイドシステムと仮想サーバインフラ（ VSI ）の組み合わせを意味する場合もあります。ONTAP ソフトウェアを実行するシステムは一般に、従来のエンタープライズアレイに比べて VSI の方が安価ですが、同じシステムで VDI を処理するための高度な Storage Efficiency 機能も備えています。また、 ONTAP は、 SSD から SATA までさまざまなストレージメディアを統合し、クラウドへの拡張を容易にします。パフォーマンスのためにフラッシュアレイを 1 台、アーカイブ用の SATA アレイ、クラウド用のシステムを 1 台購入する必要はありません。ONTAP は、これらすべてを 1 つにまとめます。</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">ストレージ仮想化</block>
  <block id="54c9439ad8fb4842a5a86c34d2401e36" category="admonition">SVM 、ユニファイドストレージ、クライアントアクセスの詳細については、を参照してください<block ref="2843f934dec816d79f9c394ad0533c28" category="inline-link-rx"></block> ONTAP 9 ドキュメントセンターを参照してください。</block>
  <block id="fa7b524ea902bff51145e4279b653d84" category="summary">このページでは、ビデオとチュートリアルについて説明します。</block>
  <block id="246bb366fee5c7eda4fcd280728ec465" category="doc">ハイブリッドクラウド、デスクトップ仮想化、コンテナのビデオとデモ</block>
  <block id="d04d1afcb2d01179846658f678623306" category="paragraph">ハイブリッドクラウド、デスクトップ仮想化、およびコンテナソリューションの特定の機能を紹介するビデオとデモをご覧ください。</block>
  <block id="4267881eb271396086a3cc1387da9a3a" category="section-title">VMware Tanzu ネットアップソリューション</block>
  <block id="2dd739333b022cfeccd93e19c8c39d83" category="paragraph">VMware Tanzu を使用すると、お客様は vSphere または VMware Cloud Foundation を通じて Kubernetes 環境を導入、管理、および管理できます。VMware のこの製品ポートフォリオでは、お客様のニーズに最適な VMware Tanzu エディションを選択することで、関連するすべての Kubernetes クラスタを単一のコントロールプレーンから管理できます。</block>
  <block id="f8d0723a562ed498a977795477b75cb0" category="inline-link">VMware Tanzu の概要</block>
  <block id="2d3e9ef8ae693e8ff80c4d6e70f0a876" category="paragraph">VMware Tanzu の詳細については、を参照してください<block ref="1951d4038519ab642a1c0f8898cecfe0" category="inline-link-rx"></block>。このレビューでは、 VMware Tanzu のユースケース、利用可能な追加機能などについて説明します。</block>
  <block id="f90851c66bcfaa6ba091b34fe8a7428b" category="section-title">ネットアップと VMware Tanzu ビデオシリーズ</block>
  <block id="31c49b154032d3d6039542b651e0f3d4" category="list-text"><block ref="31c49b154032d3d6039542b651e0f3d4" category="inline-link-rx"></block></block>
  <block id="fcf1189eaf4e4e32d27ee5174d63ae3c" category="list-text"><block ref="fcf1189eaf4e4e32d27ee5174d63ae3c" category="inline-link-rx"></block></block>
  <block id="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="list-text"><block ref="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="inline-link-rx"></block></block>
  <block id="20cf4402cce1622d010e58ef54b0c753" category="section-title">ネットアップは Red Hat OpenShift を採用しています</block>
  <block id="0454c59b86dfb678c92c2c7480958d1c" category="paragraph">エンタープライズ向け Kubernetes プラットフォームである Red Hat OpenShift を使用すると、オープンなハイブリッドクラウド戦略でコンテナベースのアプリケーションを実行できます。Red Hat OpenShift は、主要なパブリッククラウド上でクラウドサービスとして、または自己管理ソフトウェアとして利用でき、コンテナベースの解決策を設計する際に必要な柔軟性をお客様に提供します。</block>
  <block id="2426b725f5be26f50931584ae804c2eb" category="inline-link">Red Hat OpenShift の概要</block>
  <block id="ad973740d0b3378d367abba8a74a610e" category="paragraph">Red Hat OpenShift の詳細については、こちらを参照してください<block ref="dc6de73076240cafa99651f2d6acfef4" category="inline-link-rx"></block>。また、製品ドキュメントや導入オプションを確認して、 Red Hat OpenShift の詳細を確認することもできます。</block>
  <block id="282b81467c1dda139fb97c67a904cdcb" category="section-title">Red Hat OpenShift を搭載したネットアップのビデオ</block>
  <block id="ade88b04ec62ed28eb857e48bc32cef5" category="list-text"><block ref="ade88b04ec62ed28eb857e48bc32cef5" category="inline-link-rx"></block></block>
  <block id="a2f2cd3053597e34724347a57620122b" category="list-text"><block ref="a2f2cd3053597e34724347a57620122b" category="inline-link-rx"></block></block>
  <block id="e1ad6e34a69720808e091316ea5e105f" category="inline-link-macro">行 = 21..38</block>
  <block id="24988a51cebf36bd40a4e4df7f9199a1" category="paragraph"><block ref="24988a51cebf36bd40a4e4df7f9199a1" category="inline-link-macro-rx"></block></block>
  <block id="46f04290f169589dff914e050d1a987b" category="list-text">GUI を使用して SVM を作成する場合、論理インターフェイスはそのプロセスの一部です。</block>
  <block id="6af0e7a38739ed6e2658342101a7b51e" category="list-text">vSphere 環境と ONTAP を管理するために必要な基本的なスキル</block>
  <block id="5422bc00db54a341b2c538f4cea614c0" category="list-text">｛ ONTAP_version ｝ を実行している ONTAP ストレージシステム（ FAS/AFF/CVO/ONTAP Select / ASA ）</block>
  <block id="2ec64af43682ffa45eeaf33a86950347" category="list-text">ホスト、ターゲット、および ONTAP と LUN の情報用の WWPN</block>
  <block id="60ce38e4967c52c316eff771b7a3c4ec" category="list-text">ONTAP の FC データポートと vSphere ホストを接続。</block>
  <block id="32086766e64ae646fcadddc3e16b203b" category="list-text">N_Port ID Virtualization （ NPIV ）機能が有効になっている場合</block>
  <block id="b6e0bd021536c90aa87cfea18d73d453" category="list-text">単一のイニシエータターゲットゾーンを作成します。</block>
  <block id="f386e9f209710f55d41a97e9502d1c7c" category="list-text">各ゾーンに、 SVM の ONTAP FC 論理インターフェイス（ WWPN ）であるターゲットを含めます。SVM ごとに、ノードごとに少なくとも 2 つの論理インターフェイスが必要です。物理ポートの WWPN は使用しないでください。</block>
  <block id="9d17f91ad987b7e7cf2fa7249cd97343" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block>「 system license show 」コマンドを使用して、 NVMe-oF が表示されているかどうかを確認します。ライセンスを追加するには 'license add-license-code &lt;license code&gt; を使用します</block>
  <block id="7193bed15c5b4f7c80f1f19630b57e1e" category="list-text">SVM で NVMe プロトコルが有効になっていることを確認します。</block>
  <block id="5eabd2d7390fc49cb61f882324bdcac0" category="inline-link-macro">NVMe 用の SVM を設定する</block>
  <block id="3838b8ad26ea53cc8ddea76f2a58b20a" category="list-text"><block ref="3838b8ad26ea53cc8ddea76f2a58b20a" category="inline-link-macro-rx"></block></block>
  <block id="f2fd2de931ce484e947c89ae8207346a" category="list-text">SVM で NVMe/FC 論理インターフェイスが使用可能になっていることを確認してください。</block>
  <block id="978583cfbb47e2700c599c43b7949a53" category="list-text">GUI を使用して SVM を作成する場合、論理インターフェイスはそのプロセスの一部です。</block>
  <block id="3866119a70b69102c1584c0baa386190" category="list-text">ネットワーク・インターフェイスの名前を変更するには ' Network Interface modify コマンドを使用します</block>
  <block id="c6613394adcc7526a48f6e92b61ee067" category="list-text">HBA ドライバがインストールされていることを確認しますVMware がサポートする HBA には、すぐに使用できるドライバが含まれており、に表示されます <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block></block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="sidebar">NetApp DataOps ツールキット</block>
  <block id="2a643eb4634917213492cef085506d45" category="sidebar">ネットアップと VMware のソリューションを今すぐご利用ください</block>
  <block id="cadc483b04d069f993431e3ac64341bf" category="sidebar">Virtual Volume and Storage Policy Based Management の略</block>
  <block id="c4f0254bef611d7217287539f6e00feb" category="sidebar">VMware vSphere の自動化</block>
  <block id="86fbb5b9292be9b680987addfa410586" category="sidebar">従来のブロックストレージプロビジョニング</block>
  <block id="805a0828a65bce146a58e3556113b017" category="sidebar">VMFS-Fibre Channel （ VMFS - ファイバチャネル）</block>
  <block id="26e113624e0cc32cbe2a26e1cde1da24" category="sidebar">VMFS- Fibre Channel over Ethernet （ Fibre Channel over Ethernet ）</block>
  <block id="8237af9088e8905784b1cb373e3a080d" category="sidebar">VMFS-5 - iSCSI</block>
  <block id="94cab344ef7124917167bd5415b137cf" category="sidebar">VMFS-5 - NVMe over Fabric</block>
  <block id="348ee034e8868e5211a6501c09d4b0f0" category="sidebar">従来のファイルストレージプロビジョニング</block>
  <block id="614b997c0fb5abcd68fda0ab9ca05d69" category="sidebar">NFS-v3</block>
  <block id="912655e9dd57ab01b86691021957e61e" category="sidebar">v4.1 に対応しています</block>
  <block id="eaf99c5ef6885367fbd51d3ed4d278a9" category="sidebar">ONTAP for VMware vSphere の新機能</block>
  <block id="ce006038ddc2a04747fe5a2c9c43b8f5" category="sidebar">デモとチュートリアル</block>
  <block id="7cc3c71ee2fdbff1fd2efbfcded89f90" category="inline-link-macro">さまざまな分析戦略に対応するさまざまなソリューション</block>
  <block id="478906eb475a111b93606dc484113cdc" category="list-text"><block ref="478906eb475a111b93606dc484113cdc" category="inline-link-macro-rx"></block></block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">さまざまな分析戦略に対応する各種ソリューション解決策 Brief</block>
  <block id="2dc95f2080ad2dba9a9207db808106e5" category="cell">* Oracle データベース *</block>
  <block id="71e4dd221a9f0c3610e81f8ebab870ea" category="cell">* SAP HANA *</block>
  <block id="03bd539868199e3d2eb12809418e0815" category="cell">* Microsoft SQL Server *</block>
  <block id="153fbde949ec10e69bae256a4114f480" category="cell">* 解決策自動化の開始 *</block>
  <block id="e7760fa86ac312b359215e15113fde9b" category="cell">* ハイブリッド・クラウドで Oracle データベース・インフラを自動化 *</block>
  <block id="3c48757505a122bf371d1bf0105b6871" category="paragraph">doccomments@netapp.com に送信し、件名に TR-4597 を含めてください。</block>
  <block id="c1e392a90896851b3319d6075402fd4d" category="cell">* ハイブリッド / プライベートクラウド *</block>
  <block id="8ef4e9c7260e8d314760329e07c618ae" category="cell">* 仮想化 *</block>
  <block id="236122c6ab4c764632437a76fa95e5c0" category="cell">* デスクトップ仮想化 *</block>
  <block id="1ebfe0d8e53e3f7f2c37e8b3835c2adf" category="cell">* コンテナ *</block>
  <block id="b16e2e1566ba0fc14f6e0eb77d99cf93" category="cell">* NVIDIA DGX A100 システムを搭載した NetApp ONTAP AI *</block>
  <block id="70163cee23a15a309e4f1ec48b6928a8" category="cell">* NVIDIA DGX A100 システムと Mellanox Spectrum Ethernet スイッチを搭載した NetApp ONTAP AI *</block>
  <block id="0c70e09b2805fac4fb509aee9132fa97" category="cell">* NetApp DataOps ツールキット *</block>
  <block id="4810ca62a9687605d0a9c7471e75ec69" category="cell">* データ分析に関する解決策の概要 *</block>
  <block id="1e1fe2d30ed5bb9c5276dddb65f4ce65" category="cell">* セキュリティ *</block>
  <block id="bdca592f24222e5064192bb9e2f9af6e" category="sidebar">FlexPod - ネットアップの Cisco 解決策</block>
  <block id="0da8a1ebf94a3a1e650dbfbd01c69dd9" category="sidebar">FlexPod ソリューションのテクニカルコンテンツ</block>
  <block id="32591d046a055939af0d128133dc8606" category="sidebar">FlexPod のセールスページ</block>
  <block id="9e5a59ca9aef030e74a725dab3fb6dcf" category="paragraph">Astra Trident と Red Hat OpenShift を使用すると、ユーザは、プロビジョニングされたストレージクラス上の永続的ボリュームのスナップショットを作成できます。この機能を使用すると、ボリュームのポイントインタイムコピーを作成して、そのコピーを使用して新しいボリュームを作成したり、同じボリュームを以前の状態にリストアしたりできます。これにより、ロールバックからクローン、データリストアまで、さまざまなユースケースを実現またはサポートできます。</block>
  <block id="05cd0cf0962d29806df78d956f772deb" category="summary">Astra Trident は、コンテナや Kubernetes ディストリビューション向けの、 Red Hat OpenShift などのオープンソースで完全にサポートされているストレージオーケストレーションツールです。</block>
  <block id="0626021388a8dcc9b1e26b1209550b8d" category="paragraph">Astra Trident は、 Kubernetes と同様、迅速な開発サイクルを 1 年に 4 回リリースしています。</block>
  <block id="4281e618126caa3d322e78eafddba1b2" category="section-title">Astra Trident をダウンロード</block>
  <block id="f71051465199267cbb540658a51e2957" category="paragraph">Astra Trident Operator のインストールが完了したら、使用するネットアップストレージプラットフォームに合わせてバックエンドを設定する必要があります。Astra Trident のセットアップと設定を続行するには、次のリンクを参照してください。</block>
  <block id="7eba670f1ea5a6e2fba9cff6b6399064" category="summary">このページでは、 MetalLB ロードバランサのインストールおよび設定手順について説明します。</block>
  <block id="79a2d2fa50d2b47d02c0e9dbdfadc07f" category="doc">MetalLB ロードバランサのインストール：ネットアップでの Red Hat OpenShift</block>
  <block id="0b2da9b5fe81e13e88c9a05981a95a9e" category="paragraph">このページでは、 MetalLB ロードバランサのインストールおよび設定手順を示します。</block>
  <block id="28a4ce0a0514d0f6a6596fc7a9c5e725" category="section-title">MetalLB 設定オプション</block>
  <block id="04c22d763ca95631f9c8789eb2c6e68f" category="paragraph">MetalLB が OpenShift クラスタの外部でロードバランササービスに割り当てられた IP アドレスをどのようにアナウンスするかに基づいて、次の 2 つのモードで動作します。</block>
  <block id="92f98c10e5e0c86bcae2e9cb58b700e3" category="list-text">* レイヤ 2 モード。 * このモードでは、 OpenShift クラスタ内の 1 つのノードがサービスの所有権を取得し、その IP の ARP 要求に応答して、 OpenShift クラスタ外で到達可能にします。IP をアドバタイズするのはノードだけなので、帯域幅のボトルネックと低速フェールオーバーの制限があります。詳細については、のドキュメントを参照してください <block ref="4a1d14cac7ed68a2326a050e0f1fed80" category="inline-link-macro-rx"></block>。</block>
  <block id="32333b5f74abf17bffedb6e7abeb7b5f" category="section-title">MetalLB ロードバランサをインストールします</block>
  <block id="70bd399edc6825961c98dc29c2a49299" category="list-text">MetalLB リソースをダウンロードします。</block>
  <block id="d95ae9e4bae10f240e5577110ccbd7e6" category="list-text">ファイル「 metallb.yaml 」を編集し、「 pec.template.spec.securityContext` 」をコントローラ展開とスピーカー DemonSet から削除します。</block>
  <block id="39bb715a16a6f4c1ab16bc3ad3654f0b" category="paragraph">* 削除する行数： *</block>
  <block id="803519c541b237245faa09039c50dcaa" category="list-text">「 metallb-system' 」ネームスペースを作成します。</block>
  <block id="980aff973ca30f65ec180530f40def06" category="list-text">MetalLB CR を作成します。</block>
  <block id="f87be5542b64a7f94a807699fd549479" category="list-text">MetalLB スピーカを設定する前に、スピーカ DemonSet の昇格特権を与えて、ロードバランサを動作させるために必要なネットワーク設定を実行できるようにします。</block>
  <block id="53747915d8e79873876b08edb1ce3671" category="list-text">「 metalLB - システム」ネームスペースに「 ConfigMap 」を作成して、 MetalLB を設定します。</block>
  <block id="2b1e829362de1a86eeb131cdc4619908" category="list-text">これで、ロードバランササービスが作成されると、 MetalLB は外部 IP をサービスに割り当て、 ARP 要求に応答して IP アドレスをアドバタイズします。</block>
  <block id="234ce2b9b198f2acf2193cbd06120ff2" category="admonition">BGP モードで MetalLB を設定する場合は、上記の手順 6 を省略し、 MetalLB マニュアルの手順に従います <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>。</block>
  <block id="0f07e63979900ab2abf6d2d578850a47" category="inline-link-macro">次：解決策の検証 / ユースケース：ネットアップを使用した Red Hat OpenShift 。</block>
  <block id="3a29a96f08f4066b544db012326464ed" category="paragraph"><block ref="3a29a96f08f4066b544db012326464ed" category="inline-link-macro-rx"></block></block>
  <block id="dc7ec0964c3d39892e26bbe1593a79e2" category="list-text">OpenShift クラスタに Trident の Astra をインストール</block>
  <block id="e909486a42368b2659780687c3b4a31b" category="list-text">OpenShift クラスタ上でストレージクラスを構成し、 Astra Trident をプロビジョニングツールとして提供</block>
  <block id="a5369d9ec76321542413da21642ecc74" category="inline-link-macro">次のセクション：ネットアップストレージ統合の概要</block>
  <block id="1a9b0bf11ebe49684776b9ffad6b4022" category="paragraph"><block ref="1a9b0bf11ebe49684776b9ffad6b4022" category="inline-link-macro-rx"></block></block>
  <block id="7df52e0f8b2cb2af1e107fde51d06945" category="paragraph">ライブマイグレーションは、 OpenShift クラスタ内の 1 つのノードから別のノードに VM インスタンスをダウンタイムなしで移行するプロセスです。OpenShift クラスタでライブマイグレーションを実行するには、 VM を共有 ReadWriteAny アクセスモードの PVC にバインドする必要があります。NFS プロトコルが有効になっている NetApp ONTAP クラスタで SVM を使用して設定された Astra Trident バックエンドは、 PVC に対する共有 ReadWriteAny アクセスをサポートします。そのため、 NFS 対応の SVM から Trident によってプロビジョニングされた StorageClasses から要求された PVC を持つ VM をダウンタイムなしで移行できます。</block>
  <block id="a0c55f3c40b8bb2d3e26f8d11ca73cbc" category="summary">このリファレンスドキュメントでは、ネットアップによって検証済みの複数の異なるデータセンター環境に Installer Provisioned Infrastructure （ IPI ）を通じて導入された Red Hat OpenShift 解決策の導入を検証します。また、ネットアップストレージシステムとの統合についても、 Astra Trident ストレージオーケストレーションツールを使用して永続的ストレージを管理することで詳しく説明します。最後に、解決策検証と実際の使用事例をいくつか確認して文書化します。</block>
  <block id="a2ac5b8f3de7c17418af38c828121a15" category="list-text">ネットアップストレージと Kubernetes 向けオープンソースストレージオーケストレーションツールである Astra Trident とともに使用される Red Hat OpenShift の機能を紹介する実際の構成とユースケース。</block>
  <block id="d3d8eb53a347d6ffc9fb157d9ac8398b" category="paragraph">NetApp 解決策を使用した Red Hat OpenShift は、次の主要コンポーネントで構成されています。</block>
  <block id="2b8932b35916e8cecb6216546111322e" category="paragraph">Red Hat OpenShift Container Platform は、完全にサポートされているエンタープライズ向け Kubernetes プラットフォームです。Red Hat は、オープンソースの Kubernetes をいくつか強化して、コンテナ化されたアプリケーションの構築、導入、管理を完全に統合したすべてのコンポーネントを備えたアプリケーションプラットフォームを提供します。</block>
  <block id="9480fd8950471a46e6b29b165ba7ae41" category="paragraph">NetApp Astra Control Center は、 NetApp の信頼できるデータ保護テクノロジを基盤とするオンプレミス環境に導入された、ステートフル Kubernetes ワークロード向けの豊富なストレージおよびアプリケーション対応データ管理サービスを提供します。</block>
  <block id="12c17259bf3f3b36e970c9e3abbc6b43" category="cell">ネットアップアストラコントロールセンター</block>
  <block id="8d96276332b02a2ef892828c1d4fbab4" category="cell">アプリケーション対応データ管理</block>
  <block id="8de59ec369b10820d0dd336b9765c79b" category="cell">ネットアップアストラト Trident</block>
  <block id="824bd84e05db30b27e73f839dae3b8e5" category="list-text">Astra Trident のドキュメント</block>
  <block id="fe549ebd8a3f0fea1803cbaa947ef198" category="list-text">NetApp Astra Control Center のドキュメント</block>
  <block id="ad837604b59ea6a89754d8e75f595c7b" category="inline-link"><block ref="ad837604b59ea6a89754d8e75f595c7b" category="inline-link-rx"></block></block>
  <block id="4af69e66dd3d513168080d177919dd21" category="paragraph"><block ref="4af69e66dd3d513168080d177919dd21" category="inline-link-rx"></block></block>
  <block id="68dc46cb39cdfc93e4593bbdd5c218cf" category="paragraph">ほとんどの場合、 IPI インストール方法が推奨されます。これは、開発、テスト、および本番環境用の OCP クラスタを迅速に導入できるためです。</block>
  <block id="3dbb1adfd571e8b44af1259f287d723f" category="paragraph">ネットアップには、 Red Hat OpenShift に導入されたアプリケーション用のストレージをプロビジョニングするための、ネットアップの Astra Trident ストレージオーケストレーションツールで認定されているストレージプラットフォームが複数あります。</block>
  <block id="0d1d64b47559f0c28c883e7e790b8363" category="summary">このセクションは、実環境のユーザがこの解決策を本番環境に導入するときに実行する必要があるカスタマイズ（専用のイメージレジストリの作成やカスタムロードバランサインスタンスの導入など）に特化したものです。</block>
  <block id="2642cf401e87de575eae139953f87134" category="admonition">このセクションでは、サードパーティ製のロードバランサを使用するか、カスタマイズしたコンテナイメージをホストするプライベートレジストリを作成するなど、いくつかの高度な設定オプションについて説明しました。どちらも NetApp Astra Control Center をインストールするための前提条件です。</block>
  <block id="02b655f637212514780af2795fd74fc4" category="paragraph">以下のページでは、解決策追加情報を使用した Red Hat OpenShift で検証済みの高度な構成オプションについて説明します。</block>
  <block id="becc5334b7f3d2f4f57fc42cd287fd54" category="inline-link-macro">ロードバランサオプションの確認</block>
  <block id="22651dd64b4cd4c6d2742d1f8b126ae6" category="list-text"><block ref="22651dd64b4cd4c6d2742d1f8b126ae6" category="inline-link-macro-rx"></block></block>
  <block id="261bdcc1d2c24d15c43c5947e69ea9e6" category="inline-link-macro">プライベートイメージレジストリを設定しています</block>
  <block id="c8db11b008075455562a8b598b31753c" category="list-text"><block ref="c8db11b008075455562a8b598b31753c" category="inline-link-macro-rx"></block></block>
  <block id="c4a7756da710a87248298a14bd0c21e6" category="paragraph"><block ref="c4a7756da710a87248298a14bd0c21e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7a6c3c568d213db46836511343c4965" category="list-text">ONTAP 9.5 以降を実行している NetApp ONTAP ストレージシステムが 1 つ以上必要です。</block>
  <block id="c927c560df09d5ca001f99cd07b14700" category="list-text">Trident ストレージバックエンドは、 ONTAP クラスタがサポートする SVM を含む各 OpenShift クラスタで設定する必要があります。</block>
  <block id="67a56d728807272d2a01df50c6548f4f" category="list-text">ストレージプロビジョニングツールとして Astra Trident を使用し、各 OpenShift クラスタに設定されたデフォルトのストレージクラス。</block>
  <block id="dda5c1363ac68168c83f72fc2645f51f" category="list-text">ロードバランシングや OpenShift Services の公開のために、各 OpenShift クラスタにロードバランサをインストールして構成する必要があります。</block>
  <block id="7dbcc72cc3a693b8f89b064e38ed7a23" category="list-text">NetApp アストラ Control Center イメージをホストするには、プライベートイメージのレジストリを設定する必要があります。</block>
  <block id="537f97bbcef0e2e67d6840aa5845aa65" category="list-text">NetApp ONTAP クラスタへの管理者アクセスが必要です。</block>
  <block id="0507b40de1fbd59b7a77b9054689e92b" category="list-text">Docker または podman 、 tridentctl 、 OC または kubectl ツールがインストールされ、 $path に追加された管理ワークステーション。</block>
  <block id="8c7c70cb991e0295e289054b79308c5d" category="section-title">Astra Control Center をインストールします</block>
  <block id="ccab5cf8842d06d8d4e2f7f778657c4b" category="list-text">tar ボールを開梱し、作業ディレクトリを作成されたフォルダに変更します。</block>
  <block id="abe31bcfb59f2265c2fb97dde407366c" category="open-title">ポッドマン</block>
  <block id="e83d8437c3befea11906e730883605bf" category="list-text">レジストリ FQDN を、組織 / 名前空間 / プロジェクト名とともに環境変数「管理」としてエクスポートします。</block>
  <block id="9acf317cba8637e151b8daae04e3e998" category="list-text">レジストリにログインします。</block>
  <block id="326c4e96ff06709dede5c03038f00e78" category="list-text">ファイルを実行可能にします</block>
  <block id="ed85c18933b4b240788294af279f8624" category="list-text">シェルスクリプトを実行します。</block>
  <block id="05b6053c41a2130afd6fc3b158bda4e6" category="open-title">Docker です</block>
  <block id="a27cc132b2f3001f3e9df9c40dad4bfb" category="list-text">次のコマンドを実行して演算子を作成します。</block>
  <block id="685fe82295261a8902e709081b6c9599" category="list-text">すべての Astra Control Center リソースをインストールするための専用のネームスペースを作成します。</block>
  <block id="d689979a6af0f5660231db187d212950" category="list-text">Astra Control Center CRD を作成した名前空間に作成します。</block>
  <block id="9904a774f242f31a5ae37c8f75bda92b" category="list-text">「 acc-operator-controller-manager 」ログをチェックし、インストールが完了したことを確認します。</block>
  <block id="cc2ba6bb5620162b64bafdca9f089718" category="inline-image-macro">Astra Control Center ログイン</block>
  <block id="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="paragraph"><block ref="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90fbead2d113af1a2680805778908d98" category="inline-image-macro">Astra Control Center の必須パスワード変更</block>
  <block id="247e9fd0170ec4d9550de59ebd54787b" category="paragraph"><block ref="247e9fd0170ec4d9550de59ebd54787b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0dd5915bd7ca0f5d34df18bf7a183d50" category="inline-image-macro">Astra Control Center でユーザを作成</block>
  <block id="0ea309ed2f56bdc52dd6184b9043e683" category="paragraph"><block ref="0ea309ed2f56bdc52dd6184b9043e683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54936e9fda3da1e56a25c0056f054bce" category="inline-image-macro">Astra Control Center 追加ライセンス</block>
  <block id="02fd0244de299d20dfbaf9113b883030" category="paragraph"><block ref="02fd0244de299d20dfbaf9113b883030" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2044ecf5033cd4a7b9530b83075af99e" category="admonition">NetApp Astra Control Center のインストールまたは設定で問題が発生した場合は、既知の問題のナレッジベースを利用できます<block ref="d775d2705bd260971e4d33c3d1094402" category="inline-link-rx"></block>。</block>
  <block id="9204faa817ce36107d052d3cd7c886c7" category="inline-link-macro">次のページ： Red Hat OpenShift クラスタの登録：ネットアップでの Red Hat OpenShift 。</block>
  <block id="8d167505bef11e381036abf56e79f457" category="paragraph"><block ref="8d167505bef11e381036abf56e79f457" category="inline-link-macro-rx"></block></block>
  <block id="8b14fb34f5313442bf2fdc4d80edc389" category="summary">このセクションでは、ネットアップ環境で Red Hat OpenShift をカスタマイズするユーザ向けのロードバランサオプションについて説明します。</block>
  <block id="87beaa6eff6159cd7270b2a4e71c10a4" category="doc">ロードバランサのオプションの確認：ネットアップを使用した Red Hat OpenShift</block>
  <block id="0aa971b4d33bdc82c500a35166e588c8" category="paragraph">ただし、アプリケーションでは、適切なサービスを公開するために、カスタマイズしたロードバランサの導入と設定が必要になる場合があります。その一例が、ネットアップアストラコントロールセンターです。このニーズを満たすために、いくつかのカスタムロードバランサオプションを評価しました。このセクションでは、これらのインストールと設定について説明します。</block>
  <block id="6914d9014ff3e2cb99cabff26b55a0bc" category="paragraph">以下のページでは、解決策追加情報を搭載した Red Hat OpenShift で検証済みのロードバランサオプションについて説明します。</block>
  <block id="2b545f7c547a71eaeda9dcb451aea0c5" category="inline-link-macro">MetalLB</block>
  <block id="eaefba36e93c0d0177c3de1143bd08dd" category="list-text"><block ref="eaefba36e93c0d0177c3de1143bd08dd" category="inline-link-macro-rx"></block></block>
  <block id="16dcf1808fc3c9a6f8342f97305d2ad6" category="doc">アプリケーションを保護</block>
  <block id="58c0d00b6ee4c263f1fbe431b41eebf4" category="paragraph">アプリケーションワークロードを Astra Control Center で管理した後、それらのワークロードの保護設定を構成できます。</block>
  <block id="59af79c7ab060b4cca322301a4729f0c" category="section-title">アプリケーションスナップショットを作成しています</block>
  <block id="c0cf3c0162d106c6ee24b7afa9b79575" category="paragraph">アプリケーションの Snapshot コピーを作成すると、 ONTAP Snapshot コピーが作成されます。 Snapshot コピーに基づいて、アプリケーションを特定の時点にリストアまたはクローニングできます。</block>
  <block id="9101281f33d55e682b1a47a44251fa0e" category="list-text">アプリケーションのスナップショットを作成するには、 [ アプリ ] &gt; [ 管理 ] タブに移動し、 Snapshot コピーを作成するアプリケーションをクリックします。アプリケーション名の横にあるドロップダウンメニューをクリックし、 Snapshot をクリックします。</block>
  <block id="c01290a8a623e36f9bcae85b910a3410" category="inline-image-macro">Astra Control Center のスナップショットボタン</block>
  <block id="f40e241f10f15eb6887acbc81fec81b0" category="inline-image-macro">Astra Control Center でスナップショットを作成</block>
  <block id="1853746a915bea325b8b576237c24427" category="section-title">アプリケーションのバックアップを作成しています</block>
  <block id="91796648d42dbd448c6cbb2044cb92ba" category="paragraph">アプリケーションのバックアップは、アプリケーションのアクティブな状態とそのリソースの設定をキャプチャしてファイルに変換し、リモートのオブジェクトストレージバケットに格納します。</block>
  <block id="72e328bb06195897c7a644970c61d3a2" category="paragraph">Astra Control Center で管理対象アプリケーションのバックアップとリストアを行うには、バッキング ONTAP システムのスーパーユーザ設定を前提条件として設定する必要があります。そのためには、次のコマンドを入力します。</block>
  <block id="6db82a24b17137378420e9fc7961d961" category="list-text">Astra Control Center で管理対象アプリケーションのバックアップを作成するには、 [ アプリ ] &gt; [ 管理 ] タブに移動し、バックアップを作成するアプリケーションをクリックします。アプリケーション名の横にあるドロップダウンメニューをクリックし、 [ バックアップ ] をクリックします。</block>
  <block id="bc230776554b8a63af328cf9f01124e1" category="inline-image-macro">Astra Control Center のバックアップボタン</block>
  <block id="e10781941ccd98298d2856b437b3fb4b" category="inline-image-macro">Astra Control Center でバックアップを作成</block>
  <block id="92955527b375720b2a586155a776c0ac" category="inline-image-macro">Astra Control Center のクローンボタン</block>
  <block id="c4293ef1955d52694e7d2288b637df1a" category="inline-image-macro">Astra Control Center の復元</block>
  <block id="c501040965cb5ca97cc675347e9ebfdf" category="list-text">新しいアプリケーションは Discovering 状態になり、 Astra Control Center は選択したクラスタにアプリケーションを作成します。アプリケーションのすべてのリソースが Astra によってインストールおよび検出されると、アプリケーションは Available 状態になります。</block>
  <block id="9ff3c5458e4a8facc6e7c25656a3baf7" category="inline-image-macro">Astra Control Center の新しいアプリが検出されました</block>
  <block id="d19de154f02438c6d6918a4e016c7c62" category="doc">保護するアプリケーションを選択します</block>
  <block id="501195b19cb60bfec4c2e4899a2a460c" category="paragraph">Red Hat OpenShift クラスタを登録したら、 Astra Control Center を使用して導入および管理するアプリケーションを検出できます。</block>
  <block id="a022d74e2b8b62dd9f1caa37a51aa3f3" category="section-title">アプリケーションを管理します</block>
  <block id="d8c780951f3271e7d72b116e5f41d46b" category="list-text">OpenShift クラスタと ONTAP バックエンドが Astra Control Center に登録されると、コントロールセンターは、指定した ONTAP バックエンドで構成されたストレージクラスを使用するすべてのネームスペース内のアプリケーションを自動的に検出します。</block>
  <block id="3b5963749d054f288f27dfb2f20d0370" category="inline-image-macro">Astra Control Center アプリケーションが検出されました</block>
  <block id="a78e618a70881e5c5dda311aaa61c250" category="paragraph"><block ref="a78e618a70881e5c5dda311aaa61c250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c46442de8c982973aeee99a9441b746" category="list-text">[ アプリケーション ]&gt;[ 検出済み ] の順に移動し、 Astra を使用して管理するアプリケーションの横にあるドロップダウンメニューをクリックします。[ 管理 ] をクリックします。</block>
  <block id="22d84cdf10d4c1059d68b1ab7da5b375" category="inline-image-macro">Astra Control Center がアプリケーションを管理</block>
  <block id="4afca1ab36db499d54b08ff38dff8a5c" category="paragraph"><block ref="4afca1ab36db499d54b08ff38dff8a5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d694cfe5907a4790ea939388a8cfd25" category="list-text">アプリケーションが [ 使用可能（ Available ） ] 状態になり、 [ アプリケーション（ Apps ） ] セクションの [ 管理（ Managed ） ] タブで表示できます。</block>
  <block id="dc496d6799e0c6ab3bdfdbdc6a086b48" category="inline-image-macro">Astra Control Center アプリケーションを利用可能</block>
  <block id="872adedc4ac847cec0aa8fb9299d32e5" category="paragraph"><block ref="872adedc4ac847cec0aa8fb9299d32e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="472d13eb415cd6107aeef3a1ae6cd705" category="summary">ネットアップは、 Red Hat OpenShift などのコンテナベースの環境における永続的データのオーケストレーションや管理を支援する、さまざまな製品を提供しています。</block>
  <block id="ebfc0e639726a366f8eb5ac86bb7cc43" category="paragraph"><block ref="ebfc0e639726a366f8eb5ac86bb7cc43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd351007d4a671a321b6881f730d0dc3" category="paragraph">以下のページには、解決策追加情報に実装された Red Hat OpenShift でアプリケーションおよび永続的ストレージ管理のために検証されたネットアップ製品に関する があります。</block>
  <block id="afa49872fb8ae001174e4c8f2cc47208" category="inline-link-macro">次のセクションでは、ネットアップ Astra Control Center の概要について説明します</block>
  <block id="22fd530ae76b4bbe50669b9a4d5b72d7" category="paragraph"><block ref="22fd530ae76b4bbe50669b9a4d5b72d7" category="inline-link-macro-rx"></block></block>
  <block id="810a039d1a8524388b75a0fe8d837afc" category="summary">Astra Control Center でワークロードを管理できるようにするには、まず Red Hat OpenShift クラスタを登録する必要があります。</block>
  <block id="3557f7a93216446476c40d54e0426c40" category="doc">Red Hat OpenShift クラスタを Astra Control Center に登録します</block>
  <block id="349c99fe6f384da92e5b8289b828791c" category="section-title">Red Hat OpenShift クラスタを登録します</block>
  <block id="c179429ab818c9d0cca3d1db55f788bf" category="list-text">最初のステップでは、 OpenShift クラスタを Astra Control Center に追加して管理します。クラスタに移動してクラスタの追加をクリックし、 OpenShift クラスタの kubeconfig ファイルをアップロードして、ストレージの選択をクリックします。</block>
  <block id="8dfc7d6b819f8c17b51391e3b3159add" category="inline-image-macro">Astra Control Center でクラスタを作成</block>
  <block id="7470624615914e8e3d5fdf4ea1aa31de" category="paragraph"><block ref="7470624615914e8e3d5fdf4ea1aa31de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7d9a690231a2d896f69e9b45c9ff4a1" category="admonition">ユーザ名とパスワードまたはトークンを使用して認証するために kubeconfig ファイルを生成できます。トークンが期限切れになるまでの時間は制限されており、登録されたクラスタに到達できなくなる可能性があります。ネットアップでは、 OpenShift クラスタを Astra Control Center に登録するために、ユーザ名とパスワードを付けた kubeconfig ファイルを使用することを推奨します。</block>
  <block id="cab7d2cb072914c0a5a89baab41d38e8" category="inline-image-macro">Astra Control Center でクラスタ選択ストレージを作成</block>
  <block id="68ac91074dd3b4e5514e5f56a6c9c756" category="paragraph"><block ref="68ac91074dd3b4e5514e5f56a6c9c756" category="inline-image-macro-rx" type="image"></block></block>
  <block id="420b9c40f78cc4825914319af51801b9" category="inline-image-macro">Astra Control Center クラスタを使用可能</block>
  <block id="1b017a62213661e1ed3c5c581fcf74a2" category="paragraph"><block ref="1b017a62213661e1ed3c5c581fcf74a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d01de34ef9b9b934d18009a1e3273a9" category="list-text">ONTAP クラスタをストレージリソースとして Astra Control Center でバックエンドとして管理するようにインポートします。ストレージクラスが設定されている Astra に OpenShift クラスタが追加されると、ストレージクラスをサポートする ONTAP クラスタが自動的に検出されて検査されますが、 Astra コントロールセンターにインポートされて管理されません。</block>
  <block id="781ffd1df517a65b302412f53de974da" category="inline-image-macro">Astra Control Center バックエンド検出</block>
  <block id="1fcc7977dffdc8fd8fc53582c67da895" category="paragraph"><block ref="1fcc7977dffdc8fd8fc53582c67da895" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4da0c23c38cf0da34e1e6660ff74542b" category="inline-image-macro">Astra Control Center でバックエンドを作成</block>
  <block id="69dbaffc2661024ee0b5095bc3674f60" category="paragraph"><block ref="69dbaffc2661024ee0b5095bc3674f60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edb4425c04926a17b6ff9a4a2ecdc669" category="list-text">バックエンドを追加すると、ステータスが Available に変わります。このバックエンドには、 OpenShift クラスタ内の永続ボリュームと ONTAP システム上の対応するボリュームに関する情報が含まれます。</block>
  <block id="92c130f9be24925c7dee36f7580ea347" category="inline-image-macro">Astra Control Center バックエンドも利用可能</block>
  <block id="e9f487b0aad6779edbf50c6092477bd5" category="paragraph"><block ref="e9f487b0aad6779edbf50c6092477bd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2d10d92dc9d83e3cf3514e8e883e5cb" category="list-text">Astra Control Center を使用して OpenShift クラスタ間でバックアップとリストアを行うには、 S3 プロトコルをサポートするオブジェクトストレージバケットをプロビジョニングする必要があります。現在サポートされているオプションは、 ONTAP S3 、 StorageGRID 、および AWS S3 です。このインストールのために、 AWS S3 バケットを設定します。バケットに移動し、バケットの追加をクリックして、汎用 S3 を選択します。S3 バケットの詳細とアクセスするためのクレデンシャルを入力し、「 Make this bucket the default bucket for the cloud 」のチェックボックスをオンにして、 Add をクリックします。</block>
  <block id="6910cb9051734be0129cb1e7dd84ce5c" category="inline-image-macro">Astra Control Center バケットの作成</block>
  <block id="2786d0b632389f7cbd6c4e67fba0061f" category="paragraph"><block ref="2786d0b632389f7cbd6c4e67fba0061f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2ed5156911e542a4d3d64a6e160f6446" category="image-alt">ネットアップ ONTAP を基盤とする Astra Trident を使用した Red Hat OpenShift クラスタのマルチテナンシー</block>
  <block id="086e6c16e3fe8e13c336612ef636aa02" category="list-text">Astra Trident</block>
  <block id="bf4e72937ad57bd2f780561c81d25d53" category="paragraph">NetApp ONTAP をベースにした OpenShift Virtualization では、ライブ VM 移行、 VM ディスククローニング、 VM スナップショットなどの一部の機能がサポートされており、 Astra Trident の支援を受けています。それぞれのセクションで、このドキュメントの後半で各ワークフローの例について説明します。</block>
  <block id="d55adbfc40b7bcdb0606eb0bd4d88cae" category="summary">このセクションでは、 Astra Trident が提供する永続的ストレージを使用して、プライベートイメージレジストリを作成および設定します。</block>
  <block id="9c864113b9e4202e111b818a53d4f506" category="inline-link">キー・ IO</block>
  <block id="4b4141875f954447d204e6f73d93e2a0" category="inline-link">DockerHub</block>
  <block id="508888fd9f92f35e5edd97bd8083e289" category="paragraph">Red Hat OpenShift の導入では、のようなパブリックレジストリを使用します<block ref="b9eeebbe4a68a648d570ea2173e5ef99" category="inline-link-rx"></block> または<block ref="0252a6b70cc5017fa1445a78532155b6" category="inline-link-rx"></block> お客様のほとんどのニーズに対応ただし、お客様が独自のプライベートイメージまたはカスタマイズされたイメージをホストしたい場合があります。</block>
  <block id="00a3f196d7f27a1f41f5d6a7f48759d0" category="paragraph">この手順ドキュメントでは、 Astra Trident と NetApp ONTAP が提供する永続的ボリュームを使用して作成された、プライベートイメージレジストリを作成しています。</block>
  <block id="d9d5e29b1b83dd9c215f5ea158ca2475" category="admonition">Astra Control Center では、 Astra コンテナに必要なイメージをホストするためにレジストリが必要です。次のセクションでは、 Red Hat OpenShift クラスタにプライベートレジストリをセットアップし、 Astra Control Center のインストールをサポートするために必要なイメージをプッシュする手順について説明します。</block>
  <block id="86e93d266c168d718105c402f43fc91e" category="list-text">このプルシークレットは、サービスアカウントにパッチを適用するか、対応するポッド定義で参照できます。</block>
  <block id="18f8bf05a7a278e63d921de74d2a5966" category="list-text">TLS 証明書を Docker クライアントに追加します。</block>
  <block id="fe70522102670f75ed2fff361701d056" category="paragraph">このリファレンスドキュメントでは、ネットアップによって検証済みの複数の異なるデータセンター環境に Installer Provisioned Infrastructure （ IPI ）を通じて導入された Red Hat OpenShift 解決策の導入を検証します。また、ネットアップストレージシステムとのストレージ統合についても、永続的ストレージの管理には Astra Trident ストレージオーケストレーションツールを、ステートフルアプリケーションの管理と保護には NetApp Astra Control Center を活用して詳しく説明しています。最後に、解決策検証と実際の使用事例をいくつか確認して文書化します。</block>
  <block id="4a56de086437c8a56c22bccd4e7ed9ba" category="paragraph">OpenShift で既存の VM をクローニングするには、 Astra Trident の Volume CSI クローニング機能をサポートします。CSI ボリュームクローニングでは、 PV を複製することによって、既存の PVC をデータソースとして使用して新しい PVC を作成できます。新しい PVC が作成されると、その PVC は独立したエンティティとして機能し、送信元 PVC へのリンクや依存関係はありません。</block>
  <block id="9057e692817874e4c563dec1fa8c1700" category="paragraph">VM をシャットダウンして既存の VM をクローニングすることは、 Astra Trident のサポートとともに実装されるネイティブの OpenShift 機能です。VM をクローニングするには、次の手順を実行します。</block>
  <block id="306a916d056a0d0a4b898b9dca9692ee" category="inline-link-macro">Red Hat OpenShift を基盤とした NetApp Astra コントロールセンター</block>
  <block id="20c49a9a4d903fa259d4f8820b3755d2" category="cell"><block ref="20c49a9a4d903fa259d4f8820b3755d2" category="inline-link-macro-rx"></block></block>
  <block id="82ebdc178ed6bd9adb7b66c2edfb70d0" category="sidebar">ネットアップストレージシステムの概要</block>
  <block id="aef2d8db139dd41c9ae6c878ab92ae75" category="sidebar">ネットアップとストレージの統合の概要</block>
  <block id="5f6fc3deb668cb75e9e6c8932620df6a" category="sidebar">NetApp Astra Control Center の概要</block>
  <block id="846665f4ec19bffa9d9a8c3937c2f9fd" category="sidebar">Red Hat OpenShift クラスタを登録します</block>
  <block id="b1dbcb80c89b000949ef64c6d6d6c42b" category="sidebar">保護するアプリケーションを選択します</block>
  <block id="2913361a2ab3fddb4242f1761d4a6e38" category="sidebar">アプリケーションを保護</block>
  <block id="b066abadb76f5e6776aa1e7cfdf56b38" category="sidebar">NetApp Astra Trident の概要</block>
  <block id="938033783443233af5517c828deb6d1e" category="sidebar">OpenShift の高度な構成オプション</block>
  <block id="8252479af4b1df9b77ceaf67fa8cd07d" category="sidebar">プライベートイメージレジストリを作成しています</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="summary">著作権に関する声明、商標、特許などにアクセスできます。</block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">法的通知</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">著作権</block>
  <block id="09e95b77ffe81fe465a83ba99efad5c8" category="paragraph"><block ref="09e95b77ffe81fe465a83ba99efad5c8" category="inline-link-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">商標</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp 、 NetApp のロゴ、および NetApp の商標ページに記載されているマークは、 NetApp, Inc. の商標です。その他の会社名および製品名は、それぞれの所有者の商標である場合があります。</block>
  <block id="7aa531e9acfe2b98e34d2c92fe9846ff" category="paragraph"><block ref="7aa531e9acfe2b98e34d2c92fe9846ff" category="inline-link-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">特許</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">ネットアップが所有する特許の最新リストは、次のサイトで入手できます。</block>
  <block id="d7f1fbcf9ce4e42f705add574d262b2c" category="paragraph"><block ref="d7f1fbcf9ce4e42f705add574d262b2c" category="inline-link-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">プライバシーポリシー</block>
  <block id="fc248f74f5e36542f7f5627b8610e9a3" category="paragraph"><block ref="fc248f74f5e36542f7f5627b8610e9a3" category="inline-link-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">オープンソース</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">通知ファイルには、ネットアップソフトウェアで使用されるサードパーティの著作権およびライセンスに関する情報が記載されています。</block>
  <block id="d648f2a68a54fd1b3329efc3cf24d29c" category="sidebar">法的通知</block>
  <block id="5328ed3b5c6e4726166e04c16c2e5581" category="summary">このセクションでは、 Pandas で Crito Click Logs Day 15 をロードし、 scikit learn ランダムフォレストモデルをトレーニングする方法について説明します。この例では、 Dask cuDF を使用して DataFrame のロードを実行し、 Dask cuML でランダムなフォレストモデルのトレーニングを行いました。</block>
  <block id="a0432b74d7d4d2ad68e93e947654c865" category="doc">Dask の 15 日目をロードし、 Dask cuML ランダムフォレストモデルをトレーニングします</block>
  <block id="7c784438423fe1bee9ab4f91a8fd7559" category="inline-link-macro">前の手順： Pandas で Logs Day 15 をクリックし、 scikit に学習したランダムなフォレストモデルをトレーニングします。</block>
  <block id="5d5b75a952d74a7d4520c521956b9d7e" category="paragraph"><block ref="5d5b75a952d74a7d4520c521956b9d7e" category="inline-link-macro-rx"></block></block>
  <block id="78dc33cd9d496e2466a0c1e2ba09ab3f" category="inline-link-macro">「トレーニング時間の比較」</block>
  <block id="4a2764258721dd882c9ec28454963797" category="paragraph">前のセクションと同様に、 Pandas の Logs Day 15 をロードして、 scikit に学習したランダムフォレストモデルをトレーニングします。この例では、 Dask cuDF を使用して DataFrame のロードを実行し、 Dask cuML でランダムなフォレストモデルのトレーニングを行いました。セクションのトレーニング時間と規模の違いを比較しました <block ref="8d6c01ed5b9db5301efeb6183c858b76" category="inline-link-macro-rx"></block></block>
  <block id="356d8553da3749641cb731d318c85b0c" category="section-title">Crito_dASK_RF.ipynb</block>
  <block id="2f4f1a139be92d2b17647025ff8630ab" category="paragraph">このノートブックは、次の例に示すように、「 numpy`, cuml` 」、および必要な「 Ask 」ライブラリをインポートします。</block>
  <block id="7b871613dade772ae668d694698383bf" category="paragraph">Dask Client() を開始します。</block>
  <block id="3e9277d3d0f0519292426b933e52f232" category="paragraph">クラスタが正しく設定されていれば、ワーカーノードのステータスを確認できます。</block>
  <block id="d6b257c355ced1525e4967c96b62b83e" category="paragraph">AKS クラスタでは、次のステータスが表示されます。</block>
  <block id="d94a77691c281e8bf418635fea6ca580" category="paragraph"><block ref="d94a77691c281e8bf418635fea6ca580" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073b2194006d8da73b5f74f3d7224d76" category="paragraph">Dask は遅延実行パラダイムを採用しています。処理コードを瞬時に実行するのではなく、 Dask は Directed Acyclic Graph （ DAG ）を実行します。DAG には、各ワーカーが実行する必要のある一連のタスクとそのやり取りが含まれています。このレイアウトは、ユーザーが Dask に一方の方法または別の方法で実行するように指示するまで、タスクが実行されないことを意味します。Dask を使用すると、 3 つの主なオプションがあります。</block>
  <block id="a40049c3d7270ce955d2023f8e2015dc" category="list-text">* DataFrame 上のコールコンピュート () 。 * このコールはすべてのパーティションを処理し、結果をスケジューラに返して最終的な集約を行い、 cuDF DataFrame に変換します。このオプションは慎重に使用してください。スケジューラノードのメモリが不足しないかぎり、結果が大幅に低下する場合にのみ使用してください。</block>
  <block id="30e170dbe1dd223491e1a822605da52d" category="list-text">* DataFrame 上で Persist() を呼び出します。 * この呼び出しはグラフを実行しますが、スケジューラノードに結果を返すのではなく、クラスタ内で結果をメモリに保持するため、ユーザは同じ処理を再実行することなくパイプライン内で中間結果を再利用できます。</block>
  <block id="ca013764f3f6faeab137d2d529dba598" category="list-text">* DataFrame 上のコールヘッド () 。 * cuDF と同様に、この呼び出しは 10 件のレコードをスケジューラノードに返します。このオプションを使用すると、 DataFrame に目的の出力形式が含まれているかどうか、または処理と計算に応じてレコード自体が適切かどうかをすばやく確認できます。</block>
  <block id="7ac60f98a199ceae63010c7802a9aefa" category="paragraph">したがって、ユーザがこれらのアクションのいずれかをコールしない限り、スケジューラが処理を開始するのを待機するアイドル状態になります。この遅延実行パラダイムは、 Apache Spark などの最新の並列および分散コンピューティングフレームワークで一般的です。</block>
  <block id="d887d6a29f39f14cec0f83c5b02c42f8" category="paragraph">次の段落では、 Dask cuML を使用して、 GPU アクセラレーションによる分散コンピューティングを行い、モデル予測精度を計算することにより、ランダムなフォレストモデルのトレーニングを行います。</block>
  <block id="de76ff3258bd3001f89804efae30da38" category="inline-link-macro">次の手順：ネイティブタスクストリームダッシュボードを使用して Dask を監視します。</block>
  <block id="5db30f2a693de098d03dec622875beec" category="paragraph"><block ref="5db30f2a693de098d03dec622875beec" category="inline-link-macro-rx"></block></block>
  <block id="2e240897109c5037e05afe0bf035d177" category="inline-link-macro">前へ：終わりに。</block>
  <block id="d3202b7eec66185e032fcad76b4c2aa3" category="paragraph"><block ref="d3202b7eec66185e032fcad76b4c2aa3" category="inline-link-macro-rx"></block></block>
  <block id="27a5a0a02525fbb66788e119b829fe28" category="list-text">Azure NetApp Files の特長</block>
  <block id="45bd81d391ee3bd9831a237bff32b2c1" category="list-text">Azure NetApp Files のソリューションアーキテクチャのページです</block>
  <block id="57b815cb2da0c842a09d5ef586792c0a" category="inline-link"><block ref="57b815cb2da0c842a09d5ef586792c0a" category="inline-link-rx"></block></block>
  <block id="02508d077a7c6fbe1035568c37610d22" category="paragraph"><block ref="02508d077a7c6fbe1035568c37610d22" category="inline-link-rx"></block></block>
  <block id="f42fced7b7a9bfef49a209632add6f80" category="list-text">コンテナ向けの Trident 永続的ストレージ：</block>
  <block id="158e66cfa121c58b072656402170ca60" category="list-text">Azure NetApp Files と Trident</block>
  <block id="d9fe72ef646d82c8372b45ff009726a2" category="inline-link"><block ref="d9fe72ef646d82c8372b45ff009726a2" category="inline-link-rx"></block></block>
  <block id="e3c781df174a80c19c70a938b96db93a" category="paragraph"><block ref="e3c781df174a80c19c70a938b96db93a" category="inline-link-rx"></block></block>
  <block id="145f2a04d99fdbd7a450ef83e82d471b" category="list-text">Dask および Rapids ：</block>
  <block id="df5eb1591e808e358e02221e1e0111e6" category="list-text">Dask</block>
  <block id="7db6639777894f081a3d7c055b97900a" category="inline-link"><block ref="7db6639777894f081a3d7c055b97900a" category="inline-link-rx"></block></block>
  <block id="4846c68fb34aec3b1b7b7de96d27e71f" category="paragraph"><block ref="4846c68fb34aec3b1b7b7de96d27e71f" category="inline-link-rx"></block></block>
  <block id="41563f9620e92fbfd1e105e32ac297e4" category="list-text">Dask をインストールします</block>
  <block id="8659b02378fc9b47aac4428f69411abc" category="inline-link"><block ref="8659b02378fc9b47aac4428f69411abc" category="inline-link-rx"></block></block>
  <block id="972dffc891589785367dd3581a5abcef" category="paragraph"><block ref="972dffc891589785367dd3581a5abcef" category="inline-link-rx"></block></block>
  <block id="3ba7abeba4fd0f5d5ca9072155319afd" category="list-text">Dask API</block>
  <block id="f7673aa4f6b36ba9952cef7c98115776" category="inline-link"><block ref="f7673aa4f6b36ba9952cef7c98115776" category="inline-link-rx"></block></block>
  <block id="d43a23bd530cae7ba37a2e0ed6513bad" category="paragraph"><block ref="d43a23bd530cae7ba37a2e0ed6513bad" category="inline-link-rx"></block></block>
  <block id="1bfabf7fb7bf05567331dfc3d20c4921" category="list-text">Dask Machine Learning の略</block>
  <block id="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link"><block ref="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link-rx"></block></block>
  <block id="d05f63d77306100c615132f350f3fafe" category="paragraph"><block ref="d05f63d77306100c615132f350f3fafe" category="inline-link-rx"></block></block>
  <block id="90223e93e145939c9954970520e1767a" category="list-text">Dask Distributed Diagnostics の実行</block>
  <block id="e7252fe9d67234e05be7dc251c48cf74" category="inline-link"><block ref="e7252fe9d67234e05be7dc251c48cf74" category="inline-link-rx"></block></block>
  <block id="925c8b588cf5ae5fc486494a21fba8ac" category="paragraph"><block ref="925c8b588cf5ae5fc486494a21fba8ac" category="inline-link-rx"></block></block>
  <block id="d97adf46c9b097cad5eff54e3b65a21f" category="paragraph"><block ref="d97adf46c9b097cad5eff54e3b65a21f" category="inline-link-rx"></block></block>
  <block id="528d52adf23d34a248f0b9bf684c1832" category="paragraph"><block ref="528d52adf23d34a248f0b9bf684c1832" category="inline-link-rx"></block></block>
  <block id="a43c7ca8f7e6a4a034f6a940ec7566f5" category="inline-link-macro">次へ：バージョン履歴。</block>
  <block id="5f751f93279ebf35ea83b9aa80ef02df" category="paragraph"><block ref="5f751f93279ebf35ea83b9aa80ef02df" category="inline-link-macro-rx"></block></block>
  <block id="7580f940c2b73a449943bf14cfdb743e" category="summary">このページでは、 Azure NetApp Files のクラウドリソースの設定について説明します。</block>
  <block id="9ab9ef31301ca94d2090a6ac7e5141f0" category="doc">クラウドリソースの要件</block>
  <block id="1cee510209f529b7ddd8911bbc6e3ee2" category="inline-link-macro">Previous ：ソフトウェア要件。</block>
  <block id="abab2b04b3822b72d0eeb7b61dd84730" category="paragraph"><block ref="abab2b04b3822b72d0eeb7b61dd84730" category="inline-link-macro-rx"></block></block>
  <block id="00130c4c20e30be7264c0ff0d085261b" category="section-title">Azure NetApp Files を設定します</block>
  <block id="d696f60435e09b1c41d1db77b458999b" category="inline-link">クイックスタート： Azure NetApp Files をセットアップし、 NFS ボリュームを作成します</block>
  <block id="b955f251da04c8c868b22cbe7663a4f5" category="paragraph">の説明に従って、 Azure NetApp Files を設定します<block ref="f8525997ced72f3cfd70e1aecf287af9" category="inline-link-rx"></block>。</block>
  <block id="4ee734214d7dd4e522f2aab3d8e3d349" category="paragraph">「 Azure NetApp Files 用 NFS ボリュームの作成」のセクションを過ぎても、 Trident を使用してボリュームを作成できます。続行する前に、次の手順を実行します。</block>
  <block id="2a304a1348456ccd2234cd71a81bd338" category="inline-link">リンク</block>
  <block id="b1d13ce152415787185b9f596f9635e1" category="list-text">Azure NetApp Files とネットアップのリソースプロバイダに（ Azure Shell を使用）登録します<block ref="7a85c4f09a460b2978e2b516b5474576" category="inline-link-rx"></block>）。</block>
  <block id="4c21364a09ae3c9dab758e383fcae62d" category="list-text">Azure NetApp Files でアカウントを作成します（<block ref="27e1abf4e17aeb1c0d418f5fee2f2b5f" category="inline-link-rx"></block>）。</block>
  <block id="97f203356061531d1acaf022df0d4c3c" category="list-text">容量プール（必要に応じて、 4TB 以上の Standard または Premium ）をセットアップします（<block ref="16f1daa909eef5f1fe1f552d6b28d086" category="inline-link-rx"></block>）。次の表に、クラウドでのセットアップに必要なネットワーク構成を示します。Dask クラスタと Azure NetApp Files は同じ Azure Virtual Network （ VNet ）またはピア関係にある VNet に配置されている必要があります。</block>
  <block id="ddcf50c29294d4414f3f7c1bbc892cb5" category="cell">リソース</block>
  <block id="3e19b1ddc4033d0c6c439dad720f730d" category="cell">「 /version 」と入力します</block>
  <block id="21b6b0c072968b7235d21d8ec72be5dc" category="cell">エージェントノード</block>
  <block id="e5262abb96ddec17ecbca3557e70ea26" category="cell">3x Standard_DS2_v2</block>
  <block id="c64f4eaffc33134095fd3105b3d63832" category="cell">GPU ノード</block>
  <block id="11fed615c3da90add7abe544e965fa14" category="cell">3x Standard_NC6s_v3</block>
  <block id="238f4027146f2469c7d1209e594471e4" category="cell">標準的な容量のプールがある</block>
  <block id="9163995275052e5abd777ae389b15dfd" category="cell">容量（ TB ）</block>
  <block id="a6a0cae93cb8ecdef629c6de5f05989c" category="inline-link-macro">次の例：クリックスルー率予測ユースケースの概要</block>
  <block id="a5efee0d52d97830d344cded6ac0bf5c" category="paragraph"><block ref="a5efee0d52d97830d344cded6ac0bf5c" category="inline-link-macro-rx"></block></block>
  <block id="53ffd6a9e0049c8cbf7f940c2b8bc793" category="inline-link-macro">前： NetApp DataOps ツールキットを使用したデータセットとモデルのバージョニング。</block>
  <block id="01643859d7e5dff013d2acd6a02af35e" category="paragraph"><block ref="01643859d7e5dff013d2acd6a02af35e" category="inline-link-macro-rx"></block></block>
  <block id="eee817389517c17ec810d52f22a8222d" category="paragraph"><block ref="eee817389517c17ec810d52f22a8222d" category="inline-link-macro-rx"></block></block>
  <block id="4b022a47bb6a38cb1b05a5cbec618ccd" category="inline-link-macro">前の例：ピア AKS の VNet と Azure NetApp Files VNet</block>
  <block id="fec5fee1adce318e5e2f9ce6a66ccc02" category="paragraph"><block ref="fec5fee1adce318e5e2f9ce6a66ccc02" category="inline-link-macro-rx"></block></block>
  <block id="999aa3cd55c654beafcfa7653b65d339" category="paragraph">Helm を使用して Trident をインストールするには、次の手順を実行します。</block>
  <block id="36cd38f49b9afa08222c0dc9ebfe35eb" category="inline-link">ソース</block>
  <block id="9c5f8711af47a869d4ef82db9e55eda5" category="list-text">Install Helm （インストール手順については、を参照してください）<block ref="adf15389dc6d5fe4bd9024075437080f" category="inline-link-rx"></block>）。</block>
  <block id="f7c078ec85c617d77dfa95c309e4df1b" category="list-text">Trident 20.01.1 インストーラをダウンロードして展開します。</block>
  <block id="5729bb69ffc852a2e2757d743b7cb833" category="list-text">tridentctl' をシステム「 $PATH 」のディレクトリにコピーします。</block>
  <block id="d7fc4d1537e4623fdcebe9b8ba333cbb" category="list-text">Kubernetes （ Kubernetes ）クラスタに Trident をインストールし、 Helm （を参照<block ref="cbc920955683fc4acb62f9ea7099333f" category="inline-link-rx"></block>）：</block>
  <block id="f515d7de4d597c284ba8042f699a0eab" category="list-text">ディレクトリを 'helm' ディレクトリに変更します</block>
  <block id="6ee4094e2c3617e3e298ec79f9dc2898" category="list-text">Trident ポッドのステータスを確認</block>
  <block id="30f93734da9765d3bc7d49ca89932736" category="paragraph">すべてのポッドが稼働中の場合は、 Trident がインストールされてから次のポッドに移動できます。</block>
  <block id="cde865911fa15995bc83db30d852300b" category="list-text">AKS の Azure NetApp Files バックエンドとストレージクラスをセットアップします。</block>
  <block id="476fdb61358f28988640245a33bd9199" category="list-text">Azure サービスプリンシパルを作成します。</block>
  <block id="5cdfb88cd634d9d0eb47237e3251d4bd" category="paragraph">サービスプリンシパルは、 Trident が Azure と通信して Azure NetApp Files リソースを操作する方法を示します。</block>
  <block id="253a9ccb0f0696ed79c174b388867829" category="list-text">Trident バックエンド JSON ファイルを作成します。例：「 anf-backend.json 」</block>
  <block id="c17b83e07524acc467ac01e42fa0ebdb" category="list-text">任意のテキストエディタを使用して 'anf-backend.json ファイル内の次のフィールドに値を入力します</block>
  <block id="1197f8dc56b70115d87008dd2ecd3fca" category="list-text">次のフィールドを置き換えます。</block>
  <block id="b0b2134849d44712e969d6872e7245e5" category="list-text">' スクリプト ID' 。お客様の Azure サブスクリプション ID</block>
  <block id="7b42dbe86adeab0d66f36221b33bb0f4" category="list-text">「 tenantID 」。前の手順で「 AZ AD SP 」の出力から取得した Azure テナント ID 。</block>
  <block id="5a8bb8e509b4a424a1df50ef0bb41d89" category="list-text">「 clientID 」。前のステップで 'AZ ad sp' の出力からのあなたの appID 。</block>
  <block id="6334b606a5807346a083767eaab3934f" category="list-text">「 clientSecret 」を入力します。前の手順で「 AZ ad sp 」の出力から得たパスワード。</block>
  <block id="12104fe8975b3ce95324ec3cab160ffc" category="list-text">構成ファイルとして 'anf-backend.json を使用して 'trident'namespace に Azure NetApp Files バックエンドを作成するように Trident に指示します</block>
  <block id="d6d34c355bcd6b2efe2795a2aeedd247" category="paragraph"><block ref="d6d34c355bcd6b2efe2795a2aeedd247" category="inline-image-macro-rx" type="image"></block></block>
  <block id="004530c3d3b3f442f56243625372db1d" category="list-text">ストレージクラスを作成する。Kubernetes ユーザは、名前でストレージクラスを指定する PVC を使用してボリュームをプロビジョニングします。前の手順で作成した Trident バックエンドを参照するストレージクラス「 azurenetappfiles 」を作成するよう、 Kubernetes に指示します。</block>
  <block id="e777b114d6f12bc1190a60eaf8498e37" category="list-text">ストレージクラスおよびコピー用の YAML （ 'anf-storage-class.yaml ）ファイルを作成します。</block>
  <block id="01d45e8c6af153b1a477537e02466b5c" category="list-text">ストレージクラスが作成されたことを確認します。</block>
  <block id="445895be8456b7de5e864fc09994551a" category="paragraph"><block ref="445895be8456b7de5e864fc09994551a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d3fec4cfe088bc80c2c2930f051b60b" category="inline-link-macro">次の手順： Helm を使用して AKS に Rapids を導入して Dask をセットアップします。</block>
  <block id="f2d1f2f412dd744c26a147e39bfa708f" category="paragraph"><block ref="f2d1f2f412dd744c26a147e39bfa708f" category="inline-link-macro-rx"></block></block>
  <block id="4b737f96f31f513a87adcf43b83ec3a1" category="summary">このページでは、 AKS クラスタをセットアップするために必要な手順について説明します。</block>
  <block id="a81532d943508d42466c22d8d87bb4b8" category="doc">AKS クラスタをインストールしてセットアップします</block>
  <block id="ce3e1770b7ff86cfbc3a30a3e3ea87da" category="inline-link-macro">前：クリックスルー率予測ユースケースの概要。</block>
  <block id="80bf56f9bff31f7459309b983fbf8116" category="paragraph"><block ref="80bf56f9bff31f7459309b983fbf8116" category="inline-link-macro-rx"></block></block>
  <block id="40e1cc9f8d9321cbe9c1ef090f926a2b" category="paragraph">AKS クラスタをインストールしてセットアップする方法については、 Web ページを参照してください<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block> 次に、次の手順を実行します。</block>
  <block id="ad4af0825dd4979b7f48ae5ba031b23a" category="list-text">ノードのタイプ（ system [CPU] ノードまたは worker[GPU] ノード）を選択するときは、次のいずれかを選択します。</block>
  <block id="5a244a81080ee9fc08696fcbd45284e5" category="list-text">プライマリ・システム・ノードは ' 標準 DS2v2 （デフォルトでは 3 ノード）である必要があります</block>
  <block id="f3449ebebbf547282aa0562015bd360d" category="list-text">次に 'gpupool' という名前のユーザ・グループ（ GPU ノードの場合）のワーカー・ノード Standard_NC6s_v3 プール（最小 3 ノード）を追加します</block>
  <block id="d3d648c68589ef99efb6ad3ec15d1beb" category="paragraph"><block ref="d3d648c68589ef99efb6ad3ec15d1beb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2efc2b95642d4bcc76c710a3826225c" category="list-text">導入には 5 ～ 10 分かかります。完了したら、 Connect to Cluster （クラスタへの接続）をクリックします。</block>
  <block id="31797d7013400422e5d589ae3d91c79a" category="list-text">新しく作成した AKS クラスタに接続するには、ローカル環境（ラップトップ / PC ）から次のものをインストールします。</block>
  <block id="87e009e80a344ecb598be4c4bbe01c79" category="inline-link">使用している OS に応じた手順が表示されます</block>
  <block id="13a6d4f4230d0a1569b719c15884d447" category="list-text">を使用した Kubernetes コマンドラインツール<block ref="ad2337a31b7d16867fc954b03de661bd" category="inline-link-rx"></block></block>
  <block id="24a109d7bba4f8808eeb0bcf64d4357b" category="inline-link">Azure CLI をインストールします</block>
  <block id="7feed8a8a6c680e7beeca052b9fc9ed0" category="list-text">本ドキュメントに記載されている Azure CLI を使用して、<block ref="8e2043d81b680dba324c5a2abbee7b3f" category="inline-link-rx"></block></block>
  <block id="d33a4b8acf4001a4b35a2186fd020432" category="list-text">端末から AKS クラスタにアクセスするには、「 AZ login 」と入力し、クレデンシャルを入力します。</block>
  <block id="402ff6cff3671c1f49dc4af765835c14" category="list-text">「 Azure CLI ： kubectl get nodes 」と入力します。</block>
  <block id="4e5d89028ffbf65df6693ef1affd6573" category="list-text">次の例に示すように、 6 つのノードがすべて稼働していれば、 AKS クラスタをローカル環境に接続することができます</block>
  <block id="6b935f22371497abfe5378d4446df0da" category="paragraph"><block ref="6b935f22371497abfe5378d4446df0da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e57b7e32f49f0297d6c7524d1da1b3c0" category="inline-link-macro">次の例： Azure NetApp Files の委任されたサブネットを作成します。</block>
  <block id="46b5942a33ef6a130ca5fee3f6017bec" category="paragraph"><block ref="46b5942a33ef6a130ca5fee3f6017bec" category="inline-link-macro-rx"></block></block>
  <block id="e1490a61359279998443f8eab1c0483e" category="summary">このページでは、分散型または大規模なトレーニングにおける Azure NetApp Files の利点をまとめています。</block>
  <block id="b0de8e85db65da6381bb71646929daa6" category="doc">クリックスルー率予測ユースケースの概要</block>
  <block id="d7550d336c660c27c3f1aa9ffdbc1e08" category="inline-link-macro">Previous ：クラウドリソースの要件</block>
  <block id="6a4fb77bb2a725598588e7db128b749b" category="paragraph"><block ref="6a4fb77bb2a725598588e7db128b749b" category="inline-link-macro-rx"></block></block>
  <block id="3f504d5ee520c44b83e5875afd3f2831" category="inline-link">[ ログ ] をクリックします</block>
  <block id="ce2803fd5e9b90b62d0792d13e715d11" category="inline-link">Crito AI Lab の略</block>
  <block id="67ccf3c7c1e67c90000dfee83bab38ec" category="list-text">分散型または大規模なトレーニングにおける Azure NetApp Files の利点</block>
  <block id="e15bc9f9b7a013d672cb689660ab9f9f" category="list-text">CUDA 対応のデータ処理（ cDF 、 cuPy など）と ML アルゴリズム（ cuML ）をラピッズで表示</block>
  <block id="3876b7e4b6a608a0b9001ae2e65c91b1" category="inline-link-macro">次の手順： AK クラスタをインストールしてセットアップします。</block>
  <block id="2f0a1a89887d5c4f057724084bfdb718" category="paragraph"><block ref="2f0a1a89887d5c4f057724084bfdb718" category="inline-link-macro-rx"></block></block>
  <block id="17a9b27c376a8a5f5e184b2ebce41164" category="summary">すべてのデータを導入したら、新しいデータに対して推論を実行します。このモデルは、ユーザーが閲覧アクティビティに基づいて広告をクリックするかどうかを予測します。予測の結果は Dask cuDF に格納されます。Prometheus で結果を監視し、 Grafana ダッシュボードで視覚化できます。</block>
  <block id="af4d0cbb3c6dcf4f3a5e831b08e40ace" category="doc">Prometheus と Grafana で Dask と Rapids を監視します</block>
  <block id="a5d741c60ca9280a87382bcc2667207c" category="inline-link-macro">前：トレーニング時間の比較。</block>
  <block id="8162cd02e2793715a1b14265f2bfb54b" category="paragraph"><block ref="8162cd02e2793715a1b14265f2bfb54b" category="inline-link-macro-rx"></block></block>
  <block id="23c1612202d19b502b3701f893fb2557" category="inline-link">Rapids AI 培地ポスト</block>
  <block id="9fed5c9f0dab5b88ba96d45cf450079f" category="paragraph">詳細については、を参照してください<block ref="47200b727ab2088d205d11a973529202" category="inline-link-rx"></block>。</block>
  <block id="a5705f3e27851573a7eafd2a00a523b5" category="inline-link-macro">次のセクション： NetApp DataOps ツールキットを使用したデータセットとモデルのバージョニング</block>
  <block id="db75fb5c1fef47405a8df61e726e3c66" category="paragraph"><block ref="db75fb5c1fef47405a8df61e726e3c66" category="inline-link-macro-rx"></block></block>
  <block id="adb2100439d02c2978c4a5670cda87b8" category="summary">このページには、このタスクの構築に使用されたライブラリとフレームワークが一覧表示されます。これらのコンポーネントはすべて、 Azure の役割ベースのアクセスおよびセキュリティ制御と完全に統合されています。</block>
  <block id="235ff38f40d20846e27b4c64e964ce28" category="doc">データ処理およびモデルトレーニング用のライブラリ</block>
  <block id="542e61809d35e9c83a99b29c87aa40fb" category="inline-link-macro">前のバージョン： Azure NetApp Files のパフォーマンス階層</block>
  <block id="b7fe935ab4f924b870ae1983e3f3a271" category="paragraph"><block ref="b7fe935ab4f924b870ae1983e3f3a271" category="inline-link-macro-rx"></block></block>
  <block id="c4e831049faaa8b89e89eebd0a105dab" category="paragraph">次の表に、このタスクの構築に使用されたライブラリとフレームワークを示します。これらのコンポーネントはすべて、 Azure の役割ベースのアクセスおよびセキュリティ制御と完全に統合されています。</block>
  <block id="faeae27c134f5193efb923d2492daa47" category="cell">ライブラリ / フレームワーク</block>
  <block id="b540cdb28de9a6c72ef1a92504e69423" category="cell">Dask cuML</block>
  <block id="1fc1b4b6567949aab2cb7e6fecb1e68f" category="inline-link">cuML ライブラリ</block>
  <block id="efe85bbaa5690074ea98a2bfef62d930" category="cell">ML を GPU で動作させるには、を使用します<block ref="514c908f6fc3f426a00e1dabdf37831f" category="inline-link-rx"></block> Dask を使用して Rapids cuML パッケージにアクセスできます。Rapids cuML は、クラスタリング、寸法縮小、回帰アプローチなどの一般的な ML アルゴリズムを高性能 GPU ベースの実装で実装し、 CPU ベースのアプローチで最大 100 倍のスピードアップを実現します。</block>
  <block id="ede0db3d6c9043439d0762ee99543654" category="cell">Dask cuDF</block>
  <block id="a9c380d6e09cc11f858b53d56cf69da4" category="inline-link">dask -cudf ライブラリ</block>
  <block id="13a7d0199f9797a3533ff335da46b446" category="cell">cuDF には、データのサブ設定、変換、ワンホットエンコーディングなど、 GPU アクセラレーションによる抽出、変換、読み込み（ ETL ）をサポートするその他のさまざまな機能があります。Rapids チームはを維持する<block ref="836818db4e43067816d31d2b73198787" category="inline-link-rx"></block> これには、 Dask および cuDF を使用するためのヘルパーメソッドが含まれています。</block>
  <block id="0c9c2e873df681f1ab5b13053be78af7" category="cell">Scikit learn</block>
  <block id="cd1235fc9b090edba051d73dbc6f66bf" category="inline-link">エスティメータ</block>
  <block id="1977c9daa1d67de51a4651abdb160c09" category="inline-link">フィット</block>
  <block id="4f54da5a2c4a796e8215f20eb95fddcc" category="cell">Scikit-Learn には、数十の機械学習アルゴリズムとモデルが組み込まれています。これらは、試算ツールと呼ばれます。各<block ref="855747fa3f470c1754852d09071dd101" category="inline-link-rx"></block> は、を使用して一部のデータに装着できます<block ref="e52e604a9dbe357e0fb9bc58f4b62add" category="inline-link-rx"></block> メソッド</block>
  <block id="0dd4d530afb3c99ab869350770d7bebd" category="paragraph">2 つのノートブックを使用して、比較のための ML パイプラインを構築しました。 1 つは従来の Pandas の坐骨坐骨学習アプローチで、もう 1 つは Rapids および Dask との分散トレーニングです。各ノートブックを個別にテストして、パフォーマンスを時間と規模の観点から確認できます。各ノートブックについて個別に説明し、 Rapids および Dask を使用した分散型トレーニングの利点を示します。</block>
  <block id="7dd297826f91c438fab12307224d2c40" category="inline-link-macro">次に、 Pandas で Logs Day 15 をクリックし、 scikit に学習したランダムな森林モデルをトレーニングします。</block>
  <block id="ade9906123700a8bf734457510b6b3c8" category="paragraph"><block ref="ade9906123700a8bf734457510b6b3c8" category="inline-link-macro-rx"></block></block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="doc">バージョン履歴</block>
  <block id="3993b517d983222c5b766976180367f0" category="inline-link-macro">前へ（ Previous ）：追加情報を検索する場所。</block>
  <block id="7d5fc90090e6ef28f1b090f458e3bb91" category="paragraph"><block ref="7d5fc90090e6ef28f1b090f458e3bb91" category="inline-link-macro-rx"></block></block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">日付</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">ドキュメントのバージョン履歴</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">バージョン 1.0 以降</block>
  <block id="248f830b158797f9c038ea35ea266b89" category="cell">2021年8月</block>
  <block id="ea9349a37bfee247df0f87cbcacca796" category="cell">初版リリース</block>
  <block id="dfcb1d1644aa3be367d0ca7761be62ad" category="summary">このページでは、 Azure NetApp Files の委任サブネットを作成するために必要な手順について説明します。</block>
  <block id="d991c79e9311d59d4e38f3115d9c5b24" category="inline-link-macro">前へ： AKS クラスタをインストールしてセットアップします。</block>
  <block id="5dd65debe44935eb5866a15b9a62237e" category="paragraph"><block ref="5dd65debe44935eb5866a15b9a62237e" category="inline-link-macro-rx"></block></block>
  <block id="8bffe528b31ee595be868b5a4af3d25a" category="paragraph">Azure NetApp Files の委任されたサブネットを作成するには、次の手順を実行します。</block>
  <block id="1aa0034de6393efa24703b8a479a5aa6" category="list-text">Azure ポータル内の仮想ネットワークに移動します。新しく作成した仮想ネットワークを検索します。「 AKs-vnet 」などのプレフィックスが必要です。</block>
  <block id="f1621549bc319674bb9e859babb2a671" category="list-text">VNet の名前をクリックします。</block>
  <block id="c536871a8fac3a4390226f6e485cf662" category="paragraph"><block ref="c536871a8fac3a4390226f6e485cf662" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5025fbb3995af8640cab85f4f91126b" category="list-text">[ サブネット ] をクリックし、上部のツールバーの [ サブネット ] をクリックします。</block>
  <block id="22307856839205c5209cc8ce1f4ed0df" category="paragraph"><block ref="22307856839205c5209cc8ce1f4ed0df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e45b350630c9a3b31bf0c1a1f03dffb0" category="list-text">サブネットに「 ANF 」などの名前を付け、「サブネットの委任」見出しの下にある「 M icrosoft.Netapp/volumes` 」を選択します。他のものは変更しないでください。[OK] をクリックします。</block>
  <block id="3621b1bf0075cb659f152966504dfc0d" category="paragraph"><block ref="3621b1bf0075cb659f152966504dfc0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8034fc216ae23edc69bb75430f3de2f" category="paragraph">Azure NetApp Files ボリュームはアプリケーションクラスタに割り当てられ、 Kubernetes で永続ボリューム要求（ PVC ）として使用されます。その結果、 Jupyter ノートブック、サーバーレス関数などのさまざまなサービスに柔軟にマップできます。</block>
  <block id="ac3654eb11c3b0cfc94c6c1abdc6767a" category="paragraph">サービスのユーザは、プラットフォームのストレージをさまざまな方法で消費できます。このテクニカルレポートでは NFS について説明しているため、 Azure NetApp Files の主なメリットは次のとおりです。</block>
  <block id="42ba8b77b788a422a7e4ba2d8bb2d45e" category="list-text">ユーザに Snapshot コピーを使用できるようにする。</block>
  <block id="a51448debe1bbe5bb229b849d4057e09" category="list-text">ユーザが Azure NetApp Files ボリュームに大量のデータを格納できるようにする。</block>
  <block id="b7c10d399d058ef3538882e444459ba5" category="list-text">大容量のファイルセットでモデルを実行する場合、 Azure NetApp Files のパフォーマンスが向上します。</block>
  <block id="4b15c9979e20dd7eb0c0263e9d5ab1db" category="inline-link-macro">次の例：ピア AKS の VNet と Azure NetApp Files VNet</block>
  <block id="a9f725be439e4752193d45f7e7f41851" category="paragraph"><block ref="a9f725be439e4752193d45f7e7f41851" category="inline-link-macro-rx"></block></block>
  <block id="74b3e84bf9817092a6f26ddf10a2f3f8" category="summary">このページでは、この解決策で使用されているテクノロジの概要を説明します。</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">テクノロジの概要</block>
  <block id="5231f9fa4d08024f4620b759f83d0e97" category="inline-link-macro">前へ：はじめに。</block>
  <block id="dd5a70c15c985f455edb59eebf8d3eaa" category="paragraph"><block ref="dd5a70c15c985f455edb59eebf8d3eaa" category="inline-link-macro-rx"></block></block>
  <block id="4b2eedb67d8fb9da01af759e6e722a13" category="section-title">Microsoft とネットアップ</block>
  <block id="09e4ef7b38fea4a7bdf4341b588176d6" category="paragraph">2019 年 5 月より、 Microsoft は Azure ネイティブのファーストパーティポータルサービスを提供し、 NetApp ONTAP テクノロジをベースとしたエンタープライズ NFS および SMB ファイルサービスを提供しています。この開発は、 Microsoft とネットアップの戦略的パートナーシップによって推進されており、ワールドクラスの ONTAP データサービスの Azure への対応範囲がさらに拡大しています。</block>
  <block id="851e5baafa3bd23201e65e29f2fdf06a" category="paragraph">Azure NetApp Files サービスは、エンタープライズクラスの高パフォーマンスな従量課金制のファイルストレージサービスです。Azure NetApp Files は、あらゆる種類のワークロードに対応し、デフォルトで高可用性を実現します。サービスレベルとパフォーマンスレベルを選択し、サービスを使用して Snapshot コピーをセットアップできます。Azure NetApp Files は Azure ファーストパーティサービスで、コードを変更することなく、データベース、 SAP 、ハイパフォーマンスコンピューティングアプリケーションなど、クラウドで最も要件の厳しいエンタープライズファイルワークロードを移行して実行します。</block>
  <block id="f014a6e06480ef33e3f1ab027f7065ca" category="paragraph">このリファレンスアーキテクチャには、 IT 組織に次のようなメリットがあります。</block>
  <block id="5e6e9a1ee378cf26b50e61d8bd46d54d" category="list-text">さまざまなパフォーマンスとコストを考慮して、幅広いストレージ階層を提供します</block>
  <block id="295f4f6daaf50c87d2639d407c47f357" category="section-title">Dask と NVIDIA Rapids の概要</block>
  <block id="a9dcf931a9aad845de3c5b908d562955" category="paragraph">Dask は、 Python ライブラリを複数のマシン上で拡張し、大量のデータを高速処理する、オープンソースの並列コンピューティングツールです。これは、 Pandas 、 numpy 、 scikit learn などのシングルスレッド従来の Python ライブラリに類似した API を提供します。その結果、ネイティブの Python ユーザは、クラスタ全体でリソースを使用するために既存のコードを大幅に変更する必要がなくなります。</block>
  <block id="955647f3573b932f8596ba04ed80b7b6" category="paragraph">NVIDIA Rapids はオープンソースライブラリのスイートで、 GPU 上でエンドツーエンドの ML ワークフローとデータ分析ワークフローを完全に実行できます。Dask と組み合わせることで、 GPU ワークステーション（スケールアップ）からマルチノードのマルチ GPU クラスタ（スケールアウト）へ簡単に拡張できます。</block>
  <block id="7a9ece70a2d60d73203e927718fd8454" category="paragraph">クラスタに Dask を導入するには、 Kubernetes を使用してリソースのオーケストレーションを行います。次の図に示すように、ワーカーノードをプロセス要件に従ってスケールアップまたはスケールダウンすることもできます。これは、クラスタのリソース消費を最適化するのに役立ちます。</block>
  <block id="b3951b803e4010ed575c9238d2803949" category="paragraph"><block ref="b3951b803e4010ed575c9238d2803949" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2e194dd3ce5b4d001a02991ef567211" category="inline-link-macro">次の手順：ソフトウェア要件</block>
  <block id="23704e1baeed350311b18c3583ad89e9" category="paragraph"><block ref="23704e1baeed350311b18c3583ad89e9" category="inline-link-macro-rx"></block></block>
  <block id="0dff6955889d5634f0212efb574ef815" category="doc">クリックスルー率予測データの処理とモデルトレーニング</block>
  <block id="19075a93ccd90f3ea7019f0572778b2a" category="summary">このページには、この解決策に必要なソフトウェア要件が一覧表示されます。</block>
  <block id="b0167c15bc26c48af07aea36aba706fa" category="inline-link-macro">前のページ：テクノロジの概要</block>
  <block id="440b940924209e1d417ef7c4ef9bce34" category="paragraph"><block ref="440b940924209e1d417ef7c4ef9bce34" category="inline-link-macro-rx"></block></block>
  <block id="793d18702a236e0e3b768917638f0ba2" category="paragraph">次の表に、この解決策に必要なソフトウェア要件を示します。</block>
  <block id="8ab697a4168b5fb33603a98d6bc9a436" category="cell">Rapids および Dask の容器のイメージ</block>
  <block id="9ab6289633c326d69a377cbb29bd81a3" category="cell">リポジトリ : "rapidsai/rapidsai" タグ :0.17-cudda11.1-runtime-ubuntu18.04</block>
  <block id="6e1b77cc3b83d87aaee751e2eaed5044" category="inline-link-macro">次：クラウドリソースの要件</block>
  <block id="58bc7690a5a3a5a1aa5dc70739fd0b53" category="paragraph"><block ref="58bc7690a5a3a5a1aa5dc70739fd0b53" category="inline-link-macro-rx"></block></block>
  <block id="9e59f01034d2c132fac901b9c14a5d88" category="summary">NetApp DataOps Toolkit for Kubernetes は、ストレージリソースと Kubernetes ワークロードをデータサイエンスのワークスペースレベルまで抽象化します。これらの機能は、データサイエンティストとデータエンジニア向けに設計された、使いやすいシンプルなインターフェイスにパッケージ化されています。</block>
  <block id="7aee811c7e891ab94bb5be40b333faaf" category="doc">NetApp DataOps ツールキットを使用したデータセットとモデルのバージョン管理</block>
  <block id="f7136197d3b16131979b9319c4acce63" category="inline-link-macro">以前： Prometheus と Grafana を使用して Dask と Rapids を監視していました。</block>
  <block id="402dae1972461d7e7ba986ab6728df6c" category="paragraph"><block ref="402dae1972461d7e7ba986ab6728df6c" category="inline-link-macro-rx"></block></block>
  <block id="fd2d048a9ec0f96d89493b98f72cbe34" category="paragraph">NetApp DataOps Toolkit for Kubernetes は、ストレージリソースと Kubernetes ワークロードをデータサイエンスのワークスペースレベルまで抽象化します。これらの機能は、データサイエンティストとデータエンジニア向けに設計された、使いやすいシンプルなインターフェイスにパッケージ化されています。使い慣れた Python プログラムを使用しており、データサイエンティストやエンジニアは JupyterLab ワークスペースをわずか数秒でプロビジョニングおよび削除できます。これらのワークスペースには、テラバイト、あるいはペタバイト規模のストレージ容量が含まれることがあり、データサイエンティストは、すべてのトレーニングデータセットをプロジェクトのワークスペースに直接格納できます。ワークスペースとデータボリュームを個別に管理する時代は終わりました。</block>
  <block id="4a6c7893abd7ef92fb09d3359e17324d" category="inline-link">GitHub リポジトリ</block>
  <block id="eb0d40310a9cc0432fac66dc97652c39" category="paragraph">詳細については、ツールキットを参照してください<block ref="64134ca6239d4056f34489b42f2baeed" category="inline-link-rx"></block>。</block>
  <block id="1d1983037d4fd7beac963697b84f82bd" category="paragraph"><block ref="1d1983037d4fd7beac963697b84f82bd" category="inline-link-macro-rx"></block></block>
  <block id="cff4cbb413623685c446a2632974cf62" category="summary">このページでは、従来の Pandas を使用したモデルのトレーニング時間を Dask と比較します。Pandas では、メモリオーバーフローを回避するために、処理時間が遅くなるため、より少量のデータをロードしました。そのため、結果を補間して公平な比較を行いました。</block>
  <block id="014020acc8f97c1da58961d44b6301eb" category="doc">トレーニング時間の比較</block>
  <block id="76c5145913d13d6c3105c4265a78047e" category="inline-link-macro">前の手順：ネイティブタスクストリームダッシュボードを使用して Dask を監視します。</block>
  <block id="a871e4d194e2df9c65b061a5fc7cb154" category="paragraph"><block ref="a871e4d194e2df9c65b061a5fc7cb154" category="inline-link-macro-rx"></block></block>
  <block id="c8ed0bb49061765f5f30ba006ea7c5c0" category="paragraph">このセクションでは、従来の Pandas を使用したモデルのトレーニング時間を Dask と比較します。Pandas では、メモリオーバーフローを回避するために、処理時間が遅くなるため、より少量のデータをロードしました。そのため、結果を補間して公平な比較を行いました。</block>
  <block id="5b5214524edbd74fb721da08e61c8a41" category="paragraph">次の表は、 Pandas ランダムフォレストモデルに使用されるデータが大幅に少ない場合の、生のトレーニング時間の比較を示しています ( データセットの 1 日あたりの 2000 億行のうち、 5,000 万行 ) 。このサンプルでは、使用可能なすべてのデータの 0.25% 未満しか使用されていません。DASK cuML の場合は '20 億行すべての使用可能なローについてランダムフォレストモデルをトレーニングしましたこの 2 つのアプローチでは、同等のトレーニング時間が得られました</block>
  <block id="40a68b5da4b9b224764558bb02ecd028" category="cell">アプローチ</block>
  <block id="0e90ab0d7d04d2a878961f8d40071c83" category="cell">トレーニング時間</block>
  <block id="24cc88af022e13431f8005b38f74e0fd" category="cell">Scikit - Learn ：トレーニングデータとして day15 の 50 M 行のみを使用します</block>
  <block id="26e394f0b8009246698f4844db682015" category="cell">47 分 21 秒</block>
  <block id="ed536b2798ed9f16a79fb8f772601548" category="cell">Rapids-DASK ：トレーニングデータとして、 Day15 のすべての 20B 行を使用します</block>
  <block id="8809f6d1a4b5cbd872b52f83e378e527" category="cell">1 時間 12 分 11 秒</block>
  <block id="57093fade268287629c2720356ecac57" category="paragraph">次の表に示すように、トレーニング時間の結果を直線的に補間する場合、 Dask を使用した分散型トレーニングを使用すると大きな利点があります。従来の Pandas の scikit 学習アプローチでは、クリックログ 1 日あたり 45 GB のデータを処理してトレーニングするのに 13 日かかりますが、 Rapids-Dask アプローチでは同じ量のデータを処理するのにかかる時間は 262.39 倍になります。</block>
  <block id="36ebc33745cb5ac06238c615c8aaebdc" category="cell">Scikit - Learn ：トレーニングデータとして day15 のすべての 20B 行を使用します</block>
  <block id="b2ab615236e8c7812b0ab7dff59c552f" category="cell">13 日、 3 時間、 40 分、 11 秒</block>
  <block id="0d7cda3e89555f27bf26cf0c0c4f4fed" category="paragraph">前の表では、 Dask と Rapids を使用してデータ処理とモデルトレーニングを複数の GPU インスタンスに分散することで、従来の Pandas DataFrame 処理と比較して、 scikit 学習モデルトレーニングでの実行時間が大幅に短縮されたことを確認できます。このフレームワークを使用すると、マルチノードのマルチ GPU クラスタ内だけでなく、クラウド内でもオンプレミスでのスケールアップとスケールアウトが可能です。</block>
  <block id="fbd52cffa97d6ec5e0230516fc61f14c" category="inline-link-macro">次の例： Prometheus と Grafana で Dask と Rapids を監視します。</block>
  <block id="78117011d88a8971f2eadbeee6ac6474" category="paragraph"><block ref="78117011d88a8971f2eadbeee6ac6474" category="inline-link-macro-rx"></block></block>
  <block id="57a499fcdd85136edfd1ee55dedd9675" category="summary">この解決策は、 AI / ML アプリケーションのライフサイクルに従います。まず、データサイエンティストの仕事から始めて、データの準備やモデルのトレーニングに必要なさまざまなステップを定義します。Dask のラピッズを活用することで、 Azure Kubernetes Service （ AKS ）クラスタ全体で分散トレーニングを実施し、従来の Python の坐骨神経痛手法に比べてトレーニング時間を大幅に短縮しました。完全なサイクルを完了するには、パイプラインと Azure NetApp Files を統合します。</block>
  <block id="e6fab630e7da86a500e1e3c51fa61a00" category="paragraph">ネットアップ、 Verron Martina 、 Muneer Ahmad 、 Rick Huang 氏</block>
  <block id="4c3816ce69205bc811aa89dbe9d09a1a" category="paragraph">データサイエンティストの仕事は、機械学習（ ML ）モデルと人工知能（ AI ）モデルのトレーニングと調整に集中する必要があります。しかし、 Google の調査によると、データサイエンティストは、モデルをエンタープライズアプリケーションと連携させ、大規模に運用する方法を検討する時間の約 80% を費やしています。</block>
  <block id="a1451f6988178ae140f8da836d63a157" category="paragraph">エンドツーエンドの AI / ML プロジェクトを管理するには、エンタープライズコンポーネントについてより広範な理解が必要です。DevOps がその定義、統合、導入を引き継ぎましたが、 ML の運用では、 AI や ML プロジェクトを含む同様のフローがターゲットとなります。エンドツーエンドの AI / ML パイプラインが企業内でどのように影響するかを知るには、次の必要なコンポーネントのリストを参照してください。</block>
  <block id="24bea3d677b34d6aea9ff01417fd9d06" category="list-text">統合開発環境（ IDE ）</block>
  <block id="e6a53478c3fc5682c6f851672b3e7bc9" category="paragraph">データサイエンスの世界は、 IT とビジネスのさまざまな分野に影響をもたらしています。</block>
  <block id="9ca78187997ba2a23a73c094256ae63f" category="list-text">クラウド管理者とアーキテクトは、 Azure リソースをセットアップおよび管理できる必要があります。</block>
  <block id="060bc2911862b1ab8f6b4b77542434a2" category="paragraph">このテクニカルレポートでは、 Azure NetApp Files 、 Rapids AI 、 Dask 、 Azure が、これらの各役割がビジネスにもたらす価値について説明します。</block>
  <block id="ed8b6e047f5d4e844fe3e870c3fda4a3" category="paragraph">Azure NetApp Files は、さまざまなパフォーマンス階層を提供します。お客様はまず Standard 階層から始めて、データを移動することなく、スケールアウトしてハイパフォーマンス階層まで無停止でスケールアップできます。この機能により、データサイエンティストは、次の図に示すように、パフォーマンスの問題を発生させることなく、大規模なモデルのトレーニングを実施できます。クラスタ全体にデータサイロが発生することはありません。</block>
  <block id="d4dc9019b6000fd12d9dc6b091fe3e26" category="paragraph"><block ref="d4dc9019b6000fd12d9dc6b091fe3e26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b320345f652aacf7148c76dff24e2f68" category="inline-link-macro">次のステップ：テクノロジの概要</block>
  <block id="a20978df09e58f39953eb81f9368c2f2" category="paragraph"><block ref="a20978df09e58f39953eb81f9368c2f2" category="inline-link-macro-rx"></block></block>
  <block id="d577549f9b3a229c338e203a433489f6" category="summary">ここでは、 Azure NetApp Files VNet に AKS VNet をピアリングする方法について説明します。</block>
  <block id="e61e6d340ad05dc2e1ad0982f6857d7d" category="doc">ピア AKS の VNet と Azure NetApp Files VNet</block>
  <block id="1c45d541f316a23589217be5991b1545" category="inline-link-macro">前の処理： Azure NetApp Files の委譲されたサブネットを作成します。</block>
  <block id="786730f8769009abf0bf6400157dd16b" category="paragraph"><block ref="786730f8769009abf0bf6400157dd16b" category="inline-link-macro-rx"></block></block>
  <block id="e6ef5f0946a89d073a8f360de1038061" category="paragraph">AKS VNet を Azure NetApp Files VNet にピアリングするには、次の手順を実行します。</block>
  <block id="87c2d6c506d0bf65d2c5d773474f9c0f" category="list-text">検索フィールドに Virtual Networks と入力します。</block>
  <block id="7680f3bc49a836c67a8b0e7d2d9ccb44" category="list-text">「 vnet AK - vnet-name 」を選択します クリックして、検索フィールドに peerings と入力します。</block>
  <block id="fc3bb6a018a8f599cab21678959f92b0" category="list-text">+ Add をクリックします。</block>
  <block id="1991ef5bd8e165e42c56ccaefa2f640f" category="list-text">次の記述子を入力します。</block>
  <block id="51e5b9c0a583a9afbc2f998e622fd30d" category="list-text">ピアリングリンク名は 'AKs-vnet-name_-to-anf' です</block>
  <block id="14ac6521e2758ba95fe7be9ca6a82cd1" category="list-text">VNet ピアリングパートナーとしての SubscriptionID および Azure NetApp Files VNet</block>
  <block id="70b58cb057d859d4da9f17e43ffd238c" category="list-text">アスタリスク以外のすべてのセクションは、デフォルト値のままにします。</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">追加をクリックします。</block>
  <block id="50e3209c871e4867931ef51a9344a921" category="paragraph">詳細については、を参照してください<block ref="f81943721c88f7efe9b8252470f9ea43" category="inline-link-rx"></block>。</block>
  <block id="fd3c95528aa9718948de8d4e38b2fa2c" category="inline-link-macro">次の手順： Trident をインストール</block>
  <block id="18337fe57049583a9c04a79f64a2088f" category="paragraph"><block ref="18337fe57049583a9c04a79f64a2088f" category="inline-link-macro-rx"></block></block>
  <block id="dcfa517bb68d187d11e580baf2ecf588" category="summary">このページでは、 Helm を使用して AKS に Dask with Rapids deployment を設定する方法について説明します。</block>
  <block id="fd22fb1626b987fa7b72743fa9698ec6" category="doc">Helm を使用して、 AKS で Rapids デプロイメントを使用して Dask をセットアップします</block>
  <block id="d74bb88aa6e4b1c540be703fda33923e" category="inline-link-macro">前のページ： Trident をインストール</block>
  <block id="6020c64d2124fc0caa426123bfc5ba38" category="paragraph"><block ref="6020c64d2124fc0caa426123bfc5ba38" category="inline-link-macro-rx"></block></block>
  <block id="d81f517b6ad0d9702be81a8199a2246f" category="paragraph">Helm を使用して AKS で Rapids を使用して Dask をセットアップするには、次の手順を実行します。</block>
  <block id="549c839f491ec7099a895dd1cfea7534" category="list-text">Dask with Rapids をインストールするための名前空間を作成します。</block>
  <block id="74d041e68ac2a21a636ab14ae78f279d" category="list-text">クリックスルーレートデータセットを保存する PVC を作成します。</block>
  <block id="f5008aa6b27cdcaadbe27960383c8ff6" category="list-text">次の YAML コンテンツをファイルに保存して PVC を作成します。</block>
  <block id="67d464c36bcc48173c964a780459dbfd" category="list-text">YAML ファイルを Kubernetes クラスタに適用します。</block>
  <block id="be0ca76aafd92c18792693b8f05d01ce" category="inline-link"><block ref="be0ca76aafd92c18792693b8f05d01ce" category="inline-link-rx"></block></block>
  <block id="dc7ba914646428512334728c1f0ebd7d" category="list-text">rapidsai git リポジトリを複製します (<block ref="4f08c7c28c19e75f4d8607fc65d40067" category="inline-link-rx"></block>）。</block>
  <block id="50aef45ee39d958bc589f422bfb6d1bf" category="list-text">値 .yaml を変更し、作業者および Jupyter ワークスペース用に前に作成した PVC を含めます。</block>
  <block id="06867e85b141bb9d17f8ed6b4b685c46" category="list-text">リポジトリの 'rapidsai' ディレクトリに移動します</block>
  <block id="1a985ac965074fab9cfcee28ef954755" category="list-text">「 values] .yaml ファイルを更新し、 PVC を使用してボリュームをマウントします。</block>
  <block id="52076eb1fec3929530258335052328b3" category="list-text">リポジトリのホーム・ディレクトリに移動し 'Helm を使用して AKS 上に 3 つのワーカー・ノードを持つ Dask を展開します</block>
  <block id="bd4e74749939dd3c9f80ff138c18af53" category="inline-link-macro">次： Azure NetApp Files のパフォーマンス階層</block>
  <block id="52d5e0adb69809963ce4f94104a75b5e" category="paragraph"><block ref="52d5e0adb69809963ce4f94104a75b5e" category="inline-link-macro-rx"></block></block>
  <block id="1a17b23dd49d997677e18c9b9fe29935" category="summary">このページでは、ネイティブの Task Stream ダッシュボードを使用して Dask を監視する方法について説明します。</block>
  <block id="3268570ddd540695f3e92ff79d8f4684" category="doc">ネイティブタスクストリームダッシュボードを使用して Dask を監視します</block>
  <block id="1e80a6d70a902d1dae25d26917a5b490" category="inline-link-macro">前のページ : Dask の 15 日目をロードし、 Dask cuML ランダムフォレストモデルをトレーニングします。</block>
  <block id="3898f5ae37dfd830af10cdc128236b50" category="paragraph"><block ref="3898f5ae37dfd830af10cdc128236b50" category="inline-link-macro-rx"></block></block>
  <block id="9eeb55820f49a600fa229f23cfe9e5b5" category="inline-link">Dask 分散スケジューラ</block>
  <block id="99b248c7005783fe2682ad82217e9a24" category="paragraph">。<block ref="7df0d90bf997a373bfe85bbe10a2d2c8" category="inline-link-rx"></block> ライブフィードバックは、次の 2 つの形式で提供します。</block>
  <block id="d8516bf5d94a38a1fa1d7a8c3b92dee7" category="list-text">ライブ情報を含む多数のプロットやテーブルを含むインタラクティブなダッシュボード</block>
  <block id="d22ebe91c5dc1499387785da997fbe7d" category="list-text">コンソールやノートブックでの対話型の使用に適したプログレスバーです</block>
  <block id="6e35e4c1cc9332ebc8028df451bc4f06" category="paragraph">この場合、次の図は、保存されたバイト数、ストリーム数の詳細な内訳を示すタスクストリーム、実行された関連機能を持つタスク名ごとの進捗状況を監視する方法を示しています。この例では、ワーカーノードが 3 つあるため、ストリームには 3 つの主要なチャンクがあり、各ストリーム内で異なるタスクを示すカラーコードがあります。</block>
  <block id="5743e70224503025dacaa77fae253c4f" category="paragraph"><block ref="5743e70224503025dacaa77fae253c4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a5c7a858f05434bf6637c3995959f49" category="paragraph">個々のタスクを分析し、実行時間をミリ秒単位で調査するか、障害や障害を特定することができます。たとえば、次の図は、ランダムフォレストモデルフィッティングステージのタスクストリームを示しています。実行される関数は、 DataFrame 処理用の一意のチャンク、ランダムフォレストをフィッティングするための _construct_RF など、はるかに多くあります。Criteo のクリックログに含まれる 1 日分のデータのサイズ（ 45GB ）が大きいため、 DataFrame の処理にほとんどの時間が費やされていました。</block>
  <block id="816ff133aaa3d2f46ca0c7842f5fdaab" category="paragraph"><block ref="816ff133aaa3d2f46ca0c7842f5fdaab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5eca1492a19a4c24071ed91262666cf" category="inline-link-macro">次：トレーニング時間の比較。</block>
  <block id="d5d929f175d4a2062c661e45b9656f32" category="paragraph"><block ref="d5d929f175d4a2062c661e45b9656f32" category="inline-link-macro-rx"></block></block>
  <block id="d68d11ee3f69a45d681f78c744cae498" category="summary">既存のボリュームのサービスレベルを変更するには、そのボリュームに必要なサービスレベルを使用する別の容量プールにボリュームを移動します。この解決策を使用することで、お客様は、まず小規模なデータセットと少数の GPU を標準階層に配置し、データ量と GPU の増加に合わせてスケールアウトまたは Premium Tier へのスケールアップを行うことができます。</block>
  <block id="2fe5665064f07acc8afc830f911c09a5" category="doc">Azure NetApp Files のパフォーマンス階層</block>
  <block id="d84e339c1d1265f11e2f217f8d04354a" category="inline-link-macro">前の手順： Helm を使用して AKS に Rapids デプロイメントで Dask をセットアップしました。</block>
  <block id="1be55e0d10ba600a3d66b1f73f978b9f" category="paragraph"><block ref="1be55e0d10ba600a3d66b1f73f978b9f" category="inline-link-macro-rx"></block></block>
  <block id="de524ca3fc83ef426bc329e1a8b712ea" category="paragraph">既存のボリュームのサービスレベルを変更するには、そのボリュームに必要なサービスレベルを使用する別の容量プールにボリュームを移動します。この解決策を使用することで、お客様は、まず小規模なデータセットと少数の GPU を標準階層に配置し、データ量と GPU の増加に合わせてスケールアウトまたは Premium Tier へのスケールアップを行うことができます。Premium Tier は、 Standard 階層のテラバイトあたりスループットの 4 倍を提供し、ボリュームのサービスレベルを変更するためにデータを移動することなくスケールアップを実行できます。</block>
  <block id="5f92df8a2ac38644ed8ba20e16791602" category="paragraph">ボリュームのサービスレベルを動的に変更するには、次の手順を実行します。</block>
  <block id="8c83c4957baac2f6fea18f9d77767e3a" category="paragraph"><block ref="8c83c4957baac2f6fea18f9d77767e3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21ec2eabbe87e02cad1b0d4279ea00a7" category="list-text">プールの変更ウィンドウで、ボリュームの移動先となる容量プールを選択します。</block>
  <block id="ef3a0105bad35ad4c385d92daf6496a6" category="paragraph"><block ref="ef3a0105bad35ad4c385d92daf6496a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">[OK] をクリックします。</block>
  <block id="32ae33eea9c6b04002778d814c344fb5" category="section-title">パフォーマンス階層の変更を自動化</block>
  <block id="1c9506694c5a6fe83d1a0389d1d24564" category="paragraph">パフォーマンス階層の変更を自動化するには、次のオプションを使用できます。</block>
  <block id="54a3bcd89041e8f96766dcb598b15511" category="list-text">現在も動的サービスレベルの変更はパブリックプレビューで有効になっており、デフォルトでは有効になっていません。Azure サブスクリプションでこの機能を有効にする方法については、このドキュメントを参照してください<block ref="773d4c9e90e7325c5fcf35857900af6e" category="inline-link-rx"></block>。</block>
  <block id="0b01c5f61940e864222c5b29615a7eeb" category="inline-link">ボリュームプールの変更に関するドキュメント</block>
  <block id="265eed4df59633a830c9da49505786fc" category="list-text">Azure CLI の volume pool change コマンドについては、を参照してください<block ref="db78b725076ccf0203288c6620e52eb9" category="inline-link-rx"></block> 次に例を示します。</block>
  <block id="4455e376dc005ca0a99be0491b917ce7" category="inline-link">set-AzNetAppFilesVolumePool コマンドレット</block>
  <block id="a5bce2f378011f6036711869a5e8073b" category="list-text">PowerShell<block ref="45dc9ea5ce8eabd60a14674d792889e0" category="inline-link-rx"></block> Azure NetApp Files ボリュームのプールを変更し、次の例に示すようにします。</block>
  <block id="b79b50d5bff47e3a668f266c7b9dbc7b" category="inline-link-macro">次の例：データ処理とモデルトレーニング用のライブラリ。</block>
  <block id="edd770dcbb857ec8f0871955fb2f7d5d" category="paragraph"><block ref="edd770dcbb857ec8f0871955fb2f7d5d" category="inline-link-macro-rx"></block></block>
  <block id="60f89129c6220bfb3de5a84b4f6471ca" category="summary">このページでは、 Pandas と Dask DataFrames を使用して、 Criteo Terabyte データセットから Click Logs データをロードする方法について説明します。このユースケースは、広告交換のためのデジタル広告において、広告がクリックされるかどうかを予測したり、交換品が自動化されたパイプラインで正確なモデルを使用していないかどうかを予測したりすることで、ユーザーのプロファイルを作成する場合に適しています。</block>
  <block id="efdbc2f24f0a87c559175250c645b26b" category="doc">Pandas で Logs Day 15 をクリックして、 scikit に学習したランダムフォレストモデルをトレーニングします</block>
  <block id="2979440f06f7cfcab78b9a92ca964f28" category="inline-link-macro">Previous ：データ処理とモデルトレーニング用のライブラリ。</block>
  <block id="f2982e3861753bd206faa379a769d904" category="paragraph"><block ref="f2982e3861753bd206faa379a769d904" category="inline-link-macro-rx"></block></block>
  <block id="f82859e215621220b9aae984f796ef24" category="paragraph">このセクションでは、 Pandas と Dask DataFrames を使用して、 Criteo Terabyte データセットから Click Logs データをロードする方法について説明します。このユースケースは、広告交換のためのデジタル広告において、広告がクリックされるかどうかを予測したり、交換品が自動化されたパイプラインで正確なモデルを使用していないかどうかを予測したりすることで、ユーザーのプロファイルを作成する場合に適しています。</block>
  <block id="f08833dbbe310e84a1ba564838776db2" category="paragraph">Click Logs データセットから 15 日目のデータをロードし、合計 45GB にしました。Jupyter ノートブックの ctr-pandasrf-colated で次のセルを実行すると、最初の 5,000 万行を含む Pandas DataFrame が作成され、 scikit 学習ランダムフォレストモデルが生成されます。</block>
  <block id="f9964b2f8f54a1422ac46bab70fd1216" category="inline-link">公式の坐骨神経痛 - 学習文書</block>
  <block id="5646953e1414498e1ddf2eb3ab488e27" category="paragraph">トレーニングされたランダムフォレストモデルを使用して予測を実行するには、このノートブックで次の段落を実行します。重複を避けるために、 15 日目から最後の 100 万行をテストセットとして使用しました。セルはまた、モデルの発生率として定義された予測精度を計算し、ユーザーが広告をクリックするかどうかを正確に予測します。このノートブックの構成部品を確認するには、を参照してください<block ref="27e4d9ca2442a6439517a3ec2c7a4e73" category="inline-link-rx"></block>。</block>
  <block id="4e5653c75e720212b79703e8083de2a8" category="inline-link-macro">次は、 Dask の 15 日目をロードし、 Dask cuML ランダムフォレストモデルをトレーニングします。</block>
  <block id="8c9976282cff1b15934d937349911c30" category="paragraph"><block ref="8c9976282cff1b15934d937349911c30" category="inline-link-macro-rx"></block></block>
  <block id="7f39827ac712fa5b76b27ff0b267373c" category="sidebar">NetApp DataOps ツールキットを使用したデータセットとモデルのバージョン管理</block>
  <block id="6589da0279dd02b9b1d177e0ff5f457b" category="list-text">Astra Control Center Operator をインストールするための名前空間 NetApp-acc-operator を作成します。</block>
  <block id="e3990b0b892faaf03261a0a1bcd00b9b" category="list-text">NetApp-acc-operator ネームスペースのイメージレジストリにログインするためのクレデンシャルを含むシークレットを作成します。</block>
  <block id="8b6327b93d10679b1f412976af9d3bba" category="summary">Azure NetApp Files 、 Rapids 、 Dask は、 Docker や Kubernetes などのオーケストレーションツールと統合された大規模な ML 処理とトレーニングの導入を高速化し、簡易化します。エンドツーエンドのデータパイプラインを統合する解決策ことで、多くの高度なコンピューティングワークロードに特有のレイテンシと複雑さを軽減し、開発と運用のギャップを効果的に解消します。</block>
  <block id="5dc14d36063086387d2eb7cf012544aa" category="list-text">ボリューム Snapshot を作成するために使用できるボリューム Snapshot クラスを作成します。Storage &gt; VolumeSnapshotClasses の順に移動し、 Create VolumeSnapshotClass をクリックします。</block>
  <block id="3ffbaa72c8e63f0ec3ced08d8ebf9f72" category="list-text">最初に、スナップショットを新しい PVC に復元します。Storage &gt; VolumeSnapshots と進み、リストアする Snapshot の横にある省略記号をクリックして、 Restore as new PVC （新しい PVC として復元）をクリックします。</block>
  <block id="8a4d1acf8df9931b5c42b3253f943d79" category="list-text">次に、この PVC から新しい VM を作成します。[Workloads （ワークロード） ] &gt; [Virtualization （仮想化） ] &gt; [Virtual Machines （仮想マシン） ] に移動し、 [Create （作成）</block>
  <block id="91b9a57ab88a6942f692f9f393549f6e" category="list-text">spec&gt;template&gt;spec&gt;volumes セクションで、コンテナディスクからではなく、スナップショットから作成された新しい PVC を指定します。新しい VM について、要件に応じてその他の詳細をすべて指定します。</block>
  <block id="78c43863df60a7808264e8659cfa6b54" category="paragraph">Astra Trident は、コンテナや Kubernetes ディストリビューション向けの、 Red Hat OpenShift などのオープンソースで完全にサポートされているストレージオーケストレーションツールです。Trident は、 NetApp ONTAP や Element ストレージシステムを含むネットアップストレージポートフォリオ全体と連携し、 NFS 接続と iSCSI 接続もサポートします。Trident を使用すると、ストレージ管理者の手を煩わせることなく、エンドユーザがネットアップストレージシステムからストレージをプロビジョニングして管理できるため、 DevOps ワークフローが高速化されます。</block>
  <block id="d719c733d0cd8753c048c8c3a025fd51" category="paragraph">MetalLB は、 OpenShift クラスタにインストールされた自己ホスト型ネットワークロードバランサであり、クラウドプロバイダで実行されないクラスタでタイプロードバランサの OpenShift サービスを作成できます。LoadBalancer サービスをサポートするために連携する MetalLB の 2 つの主な機能は、アドレス割り当てと外部アナウンスメントです。</block>
  <block id="13f78a1c753a58b3786e5664e7b01344" category="list-text">* このモードでは、 OpenShift クラスタ内のすべてのノードがルータとの BGP ピアリングセッションを確立し、トラフィックをサービス IP に転送するためにルートをアドバタイズします。このための前提条件は、 MetalLB をそのネットワーク内のルータと統合することです。BGP のハッシュメカニズムにより、サービスの IP-to-Node マッピングが変更されることがあります。詳細については、のドキュメントを参照してください <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>。</block>
  <block id="5fe238de20fea7c5ec86dde0a98c5841" category="admonition">このマニュアルでは、レイヤ 2 モードで MetalLB を設定します。</block>
  <block id="0ef06ef8df800cf71fb95c66e0e08f1a" category="list-text">最初に、 [ インフラストラクチャの自動化 ] 、 [ クラスタ ] の順に移動</block>
  <block id="e056bb6efa17796fc810edad8410280d" category="list-text">プロバイダ接続の作成： [ プロバイダ接続 ] に移動して [ 接続の追加 ] をクリックし、選択したプロバイダタイプに対応するすべての詳細を入力して [ 追加 ] をクリックします。</block>
  <block id="401b252566122602a82ff66bc7ed3e6c" category="list-text">新しいクラスタを作成するには、クラスタに移動し、クラスタの追加 &gt; クラスタの作成をクリックします。クラスタと対応するプロバイダの詳細を指定し、 Create をクリックします。</block>
  <block id="2da6eeb34cf16de43ab8fa2f939d81c7" category="list-text">作成されたクラスタは、クラスタのリストに Ready ステータスで表示されます。</block>
  <block id="f52ae06380cfd00cae7839562f550e87" category="list-text">クラスタに移動し、クラスタの追加 &gt; 既存クラスタのインポートをクリックします。</block>
  <block id="63b7276dd1b569babc28304e786e2041" category="list-text">クラスタの名前を入力し、 [ インポートしてコードを生成して保存 ] をクリックします。既存のクラスタを追加するコマンドが表示されます。</block>
  <block id="be87809a27ab2944f89ccaebd89b7596" category="list-text">Copy コマンドをクリックし、ハブクラスタに追加するクラスタ上でコマンドを実行します。これにより、必要なエージェントのクラスタへのインストールが開始され、このプロセスが完了すると、クラスタがクラスタリストに「 Ready 」と表示されます。</block>
  <block id="627fd2c5e0310dc7409ea377e5d13045" category="section-title">割り当てられたプロジェクトで PVC またはポッドを作成するためのアクセスを検証します</block>
  <block id="8c9885c86a67cc4c47a30d7e8d14badb" category="section-title">アクセスを検証して別のプロジェクトに PVC またはポッドを作成するか、別のプロジェクト専用のリソースを使用します</block>
  <block id="83aa0a39007c30e71adde6fbf8180d9f" category="section-title">アクセス権を検証して、プロジェクト、リソースクォータ、ストレージクラスを表示および編集します</block>
  <block id="53c583e55a36ad49234df678a2dbcf45" category="paragraph">NetApp Element ソフトウェアは、拡張性に優れたモジュラ型のパフォーマンスを提供し、ストレージノードごとに容量とスループットを保証します。NetApp Element システムは、 1 つのクラスタで 4~100 ノードまで拡張でき、高度なストレージ管理機能も多数備えています。</block>
  <block id="28bbba0205a8bfd9f8f2da8b73522dc7" category="inline-link-macro">次のセクション：ネットアップストレージ統合の概要</block>
  <block id="d61c98dcb4bec6f3e1213776ebb1e6c3" category="paragraph"><block ref="d61c98dcb4bec6f3e1213776ebb1e6c3" category="inline-link-macro-rx"></block></block>
  <block id="1c01b62cc887329b006a88e9f959b5d4" category="list-text">IdP に project-3 のユーザグループが作成され、 OpenShift クラスタと同期されていることを確認してください。</block>
  <block id="e98511d60f9850de86f096614f447322" category="paragraph">Kubernetes 向けの高度なクラスタ管理機能を使用すると、ノード、ポッド、およびすべてのクラスタのアプリケーションとワークロードを監視できます。</block>
  <block id="36aff44ed429ca86d182dc7ee3dfdbb1" category="list-text">[ 環境の監視 ]&gt;[ 概要 ] に移動します。</block>
  <block id="c9904a9276a489fc238c999d2ddd633f" category="list-text">すべてのクラスタのすべてのポッドとワークロードが監視され、さまざまなフィルタに基づいてソートされます。ポッドをクリックすると、対応するデータが表示されます。</block>
  <block id="7cd1c61051d3647bc47d839e0efee222" category="list-text">クラスタ内のすべてのノードが、さまざまなデータポイントに基づいて監視および分析されます。ノードをクリックすると、対応する詳細が表示されます。</block>
  <block id="4e7f54a0ebc5cd69209a17181d477e4c" category="list-text">クラスタはすべて、クラスタのリソースとパラメータに基づいて監視および整理されます。クラスタをクリックしてクラスタの詳細を表示します。</block>
  <block id="842f7d4793f116332f5b12b648dfd539" category="list-text">ワークロード &gt; 仮想化 &gt; 仮想マシンと進み、作成 &gt; ウィザードを使用してをクリックします。</block>
  <block id="ae024d48dbfaaf4badad7bf9c812a98f" category="list-text">rootdisk の横にある省略記号をクリックし、 Trident を使用してプロビジョニングされたストレージクラスが選択されていることを確認します。[ 詳細設定 ] を展開し、 [ アクセスモード ] で [ 共有アクセス (RWX) ] を選択します。[ 保存 ] をクリックします。</block>
  <block id="289f346dbeb0185de2648a24955ca887" category="list-text">ワークロード &gt; 仮想化 &gt; 仮想マシンと進みます。</block>
  <block id="a542faac65568ba146d392d835d7fb33" category="list-text">* VMware vCenter Server* 。 VMware vCenter Server は、 1 つのコンソールからすべてのホストと VM を統合管理し、クラスタ、ホスト、 VM のパフォーマンス監視を集約します。</block>
  <block id="413563ec6c2672beb7df15f465cb4a48" category="list-text">* VMware vSphere vMotion 。 * VMware vCenter では、要求に応じて、無停止でクラスタ内のノード間で VM をホット移行できます。</block>
  <block id="e6583703b8777be27f8db85d741711b4" category="list-text">* vSphere High Availability 。 * ホスト障害時のシステム停止を避けるため、 VMware vSphere を使用すると、ホストをクラスタ化して High Availability に構成することができます。ホストの障害によってシステムが停止した VM は、クラスタ内の他のホストでまもなくリブートされ、サービスがリストアされます。</block>
  <block id="46b35ead34118cb2c50327c71e4aa640" category="list-text">* DRS （ Distributed Resource Scheduler ）。 * VMware vSphere クラスタは、ホストしている VM のリソースニーズを負荷分散するように構成できます。リソース競合のある VM は、十分なリソースを使用できるように、クラスタ内の他のノードにホット移行できます。</block>
  <block id="5c6371faa8d72dee8337811921707a4b" category="paragraph">NetApp 解決策上の Red Hat OpenShift では、 2 つのデータスイッチを使用して 25Gbps でプライマリデータ接続を提供します。また、ストレージノードのインバンド管理用に 1Gbps で接続を提供する管理スイッチをさらに 2 台使用し、 IPMI 機能のアウトオブバンド管理も行います。OCP のクラスタ管理には、 VMware vSphere 上の VM 論理ネットワークが使用されます。このセクションでは、解決策で使用される各仮想ネットワークセグメントの配置と目的について説明し、解決策を導入するための前提条件について説明します。</block>
  <block id="f33bd5bca507f2b59fc0a43383ade71b" category="cell">仮想ゲストネットワークアクセス</block>
  <block id="3500f2194985ef1b586c649fbe519d8d" category="paragraph">本ドキュメントで説明する検証済みのアーキテクチャには、 VMware vSphere HA と VMware vMotion を有効にして、 2 つの ESXi ハイパーバイザーノードを導入し、フォールトトレラント構成を確保することで、 HA 処理に適した最小限のハードウェア環境が示されています。この構成では、導入した VM を 2 つのハイパーバイザー間で移行し、 1 つのホストが使用できなくなった場合にリブートすることができます。</block>
  <block id="e79fa01ec6b411cfda4f8baad9f95cb0" category="paragraph">Red Hat OpenShift では最初に 3 つのマスターノードを導入するため、 2 ノード構成の少なくとも 2 つのマスターが同じノードを占有することがあります。その場合、特定のノードが使用できなくなったときに OpenShift が停止する可能性があります。そのため、 Red Hat のベストプラクティスでは、 OpenShift マスターを均等に分散してフォールトトレランスを高めるために、少なくとも 3 つの ESXi ハイパーバイザーノードを導入する必要があります。</block>
  <block id="f5428382aa8b44d7ef6ca71195afc8ca" category="paragraph">VM とホストのアフィニティを有効にすることで、複数のハイパーバイザーノードに OpenShift マスターを確実に分散させることができます。</block>
  <block id="c23c2371397ad3490af42526283948a4" category="paragraph">アフィニティまたは非アフィニティは、 VM やホストのセットに対してルールを定義する方法で、グループ内の同じホストまたはホスト上で VM を一緒に実行するか、別のホスト上で実行するかを決定します。VM とホストで構成されるアフィニティグループを作成することで、 VM に適用されます。このアフィニティグループには同じパラメータと条件が設定されます。アフィニティグループ内の VM がグループ内の同じホストで実行されているのか、または別々のホストで実行されているのかに応じて、アフィニティグループのパラメータでは正のアフィニティまたは負のアフィニティを定義できます。</block>
  <block id="5e059b05dcf86db414d6b8cdd66bcf0f" category="paragraph">IPI を使用すると、このドキュメントで前述した対話型ウィザードを使用して、 OpenShift クラスタを簡単に導入できます。ただし、クラスタ導入の一環として、一部のデフォルト値の変更が必要になる場合があります。</block>
  <block id="6e7315bf45cda77f0a1477ed6f712eb6" category="paragraph">このような場合は、クラスタをすぐに導入せずにウィザードを実行してタスクを実行できますが、代わりに、あとでクラスタを導入できる構成ファイルが作成されます。これは、 IPI のデフォルトを変更する必要がある場合や、マルチテナンシーなどの他の用途のために環境内に同一のクラスタを複数導入する場合に非常に便利です。OpenShift 用にカスタマイズされたインストール構成の作成の詳細については、を参照してください<block ref="fc4239653f75b84dd3ca03fe8b28dd64" category="inline-link-rx"></block>。</block>
  <block id="2a3b399798aa16ecfbc1425cc560bfad" category="section-title">ユースケース</block>
  <block id="f08561bbd831bfa1923e6acf045ef13a" category="section-title">ビジネスバリュー</block>
  <block id="81f74b2a02db97d708bd7cbf08d2463a" category="section-title">ネットアップストレージシステム</block>
  <block id="660d073f0987fac312dc40bd5dc868bd" category="paragraph">ネットアップには、エンタープライズデータセンターやハイブリッドクラウド環境に最適なストレージシステムが複数あります。ネットアップのポートフォリオには、コンテナ化されたアプリケーションに永続的ストレージを提供できる NetApp ONTAP 、 NetApp Element 、および NetApp E シリーズストレージシステムが含まれています。</block>
  <block id="069b087e8e1e69cc928f18a85f683523" category="section-title">ネットアップとストレージの統合</block>
  <block id="b4186621511a622be24ad982b0a8ec32" category="paragraph">NetApp Astra Control Center は、信頼性の高いネットアップのデータ保護テクノロジを基盤とするオンプレミス環境に導入された、ステートフル Kubernetes ワークロード向けの充実したストレージおよびアプリケーション対応のデータ管理サービスを提供します。</block>
  <block id="947496ade2e4a2c8e929d9aa9f00be04" category="paragraph">詳細については、 NetApp Astra の Web サイトをご覧ください<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>。</block>
  <block id="0bc570c518e7c4f356ebceb14fa8372f" category="section-title">Advanced Configuration Options （詳細設定オプション）</block>
  <block id="aa44798f04a58b33c3699abd02a59c57" category="paragraph">このセクションは、実環境のユーザがこの解決策を本番環境に導入するときに実行する必要があるカスタマイズ（専用のプライベートイメージレジストリの作成やカスタムロードバランサインスタンスの導入など）に特化したものです。</block>
  <block id="382742bb5fff6a719c144a0a01cd17e3" category="section-title">検証済みリリースの現在のサポートマトリックスです</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">ソフトウェアのバージョン</block>
  <block id="e3024b13494086daa1b9813a799ba41a" category="cell">データセンターの仮想化</block>
  <block id="35be109b995061abd3392d1b01fd0e9a" category="summary">Red Hat OpenStack Platform は、セキュアで信頼性の高いプライベート OpenStack クラウドの構築、導入、拡張を行うための統合基盤を提供します。</block>
  <block id="dc34aa9761794ceabad79dc29944976e" category="paragraph">OpenStack プロジェクトは、短期間で開発されたコミュニティプロジェクトで、 6 カ月ごとに更新リリースを提供します。最初の Red Hat OpenStack Platform は、すべてのアップストリームリリースに加えて新しいリリースを公開することで、このリリースサイクルのペースを維持していました。また、 3 回目のリリースごとに長期的なサポートを提供します。最近、 OpenStack Train をベースとした OSP リリース 16.0 ではリリース番号に対応しないことが選択されましたが、新しい機能はサブリリースにバックポートされています。最新のリリースは Red Hat OpenStack Platform 16.1 です。これには、アップストリームの Usuri および Victoria リリースからバックポートされた高度な機能が含まれています。</block>
  <block id="ffd7a6889e6ea6965969472250235082" category="paragraph">OpenStack Platform サービスはコンテナとして導入されます。コンテナはサービスを分離するため、アップグレードも簡単です。OpenStack Platform は、 Kolla によって構築、管理された一連のコンテナを使用します。サービスの導入は、 Red Hat Custom Portal からコンテナイメージを取得することによって行われます。これらのサービスコンテナは、 Podman コマンドを使用して管理され、 Red Hat OpenStack Director で導入、設定、および管理されます。</block>
  <block id="7adea0d9c77aabccd8bb67ae0a832d59" category="cell">プロジェクト名</block>
  <block id="e7a39f4cb0dd0ffaaffe8fb0319dec67" category="cell">OpenStack ネットワーク</block>
  <block id="4f0550f066ae72bb8c24fc3f59c323bf" category="cell">ブロックストレージ</block>
  <block id="670aaecb1a526fbed439dad3ec353a96" category="cell">オブジェクトストレージ</block>
  <block id="b81a67bf2ab52e16a62a9c71454c90ee" category="paragraph">Red Hat OpenStack Director では、皮肉なベアメタルプロビジョニングサービスを使用して Red Hat OpenStack Platform を導入するために、 IPMI 機能が必要です。</block>
  <block id="567f5ee3e60ecdd5338b39cab0006510" category="cell">ストレージインフラ</block>
  <block id="ea414c629935302b115bf3dabf5f827c" category="cell">Neutron は、 VXLAN を介したトンネリングによって、各テナントに独自のネットワークを提供します。ネットワークトラフィックは、各テナントネットワーク内で分離されます。各テナントネットワークには IP サブネットが関連付けられており、ネットワークネームスペースとは、複数のテナントネットワークで同じアドレス範囲を使用しても競合が発生することを意味します</block>
  <block id="f2feccaa3f5d086f0b16010ff463e369" category="cell">OpenStack Dashboard （ Horizon ）をグラフィカルに管理するためにホストする、公開されているネットワーク。 OpenStack サービスを管理するためのパブリック API 呼び出しが可能です。</block>
  <block id="493fd05bc58266bcd8394072cbe81748" category="paragraph">このドキュメントで説明する検証済みのアーキテクチャでは、 3 つの OSP コントローラノードと 2 つの OSP コンピューティングノードを導入して、 HA 運用に適した最小限のハードウェアを導入します。このアーキテクチャにより、耐障害性を備えた構成が実現し、両方のコンピューティングノードで仮想インスタンスを起動し、導入した VM を 2 つのハイパーバイザー間で移行できます。</block>
  <block id="ebe803a768c48af52bca59e6ab7df9bf" category="paragraph">Red Hat OpenShift 原因では最初に 3 つのマスターノードを導入するため、 2 ノード構成では少なくとも 2 つのマスターが同じノードを占有する可能性があり、その特定のノードが使用できなくなった場合には OpenShift が停止する可能性があります。そのため、 Red Hat では、少なくとも 3 つの OSP コンピューティングノードを導入して、 OpenShift マスターを均等に分散させ、解決策にフォールトトレランスを強化することをベストプラクティスとして推奨します。</block>
  <block id="bbfdc160550acbcdb4791a961a165d5d" category="paragraph">仮想マシンとホストのアフィニティを有効にすると、複数のハイパーバイザーノードに OpenShift マスターを分散できます。</block>
  <block id="cb346122cae28dfb1fcf0811f46296a2" category="paragraph">アフィニティとは、 VM やホストのセットに対してルールを定義する方法で、グループ内の同じホストで複数の VM が実行されるか、別々のホストで実行されるかを決定します。VM とホストで構成されるアフィニティグループを作成することで、 VM に適用されます。このアフィニティグループには同じパラメータと条件が設定されます。アフィニティグループ内の VM がグループ内の同じホストで実行されているのか、または別々のホストで実行されているのかに応じて、アフィニティグループのパラメータでは正のアフィニティまたは負のアフィニティを定義できます。Red Hat OpenStack Platform では、サーバグループを作成し、 Nova で導入されたインスタンスが異なるコンピューティングノードに導入されるようにフィルタを設定することで、ホストアフィニティルールと非アフィニティルールを作成して適用することができます。</block>
  <block id="de5bd213c3df23736df75636241f96de" category="admonition">OSP サーバグループには、特定のハードアフィニティや非アフィニティの制限があります。ノードを共有するために十分なリソースが別々のノードに導入できない場合や、リソースが不足している場合は、 VM をブートできません。</block>
  <block id="42bb5e38e5b1c611bdce679410b24d67" category="paragraph">このような場合は、クラスタをすぐに導入せずにウィザードを実行してタスクを実行できます。代わりに、あとでクラスタを導入できる構成ファイルを作成します。これは、 IPI のデフォルト値を変更する必要がある場合や、マルチテナンシーなどの他の用途のために環境内に同一のクラスタを複数導入する必要がある場合に非常に便利です。OpenShift 用にカスタマイズされたインストール構成の作成の詳細については、を参照してください<block ref="05810b34cd92ddfe8fd049160cb24f72" category="inline-link-rx"></block>。</block>
  <block id="dc5fa659e0452a77d6006f5b72f8b334" category="paragraph">Trident を NetApp Element ストレージシステムと統合するには、 iSCSI プロトコルを使用してストレージシステムと通信できるバックエンドを作成する必要があります。</block>
  <block id="05ca7295321cb9b417a251e75557c6c5" category="list-text">ダウンロードしたインストールアーカイブのサンプルバックエンドファイルは、「 sample -input 」フォルダ階層にあります。iSCSI を提供している NetApp Element システムの場合、「 backend-solidfire.json 」ファイルを作業ディレクトリにコピーし、ファイルを編集します。</block>
  <block id="b73d05719d0ea2964c963f6f83a34d3d" category="admonition">このファイルに定義されているオプションのフィールド「 fsType 」があります。iSCSI バックエンドでは、この値を特定の Linux ファイルシステムタイプ（ XFS 、 ext4 など）に設定するか、 OpenShift で使用するファイルシステムを決定できるようにするためにこの値を削除できます。</block>
  <block id="90dc29cb8c225faef816aefeaad3027d" category="inline-link-macro">次：解決策の検証 / ユースケース</block>
  <block id="99632a9c8a0d8380e77d9d11f96edfdc" category="paragraph"><block ref="99632a9c8a0d8380e77d9d11f96edfdc" category="inline-link-macro-rx"></block></block>
  <block id="920db239cf01c8ded4b7f364194ab540" category="list-text">サイドバーから Manage Applications に移動し、 Create Application をクリックします。作成するアプリケーションの詳細を入力し、 [ 保存 ] をクリックします。</block>
  <block id="f4fc33973424c12639f93790b1c6f370" category="paragraph">ネットアップは、堅牢なオールフラッシュ（ AFF ）およびスケールアウトハイブリッド（ FAS ）ストレージプラットフォームを提供し、低レイテンシのパフォーマンス、統合データプロテクション、マルチプロトコルのサポートのそれぞれに合わせてカスタマイズします。</block>
  <block id="c48db988cd283c11f89d4dd85803ec0a" category="doc">ネットアップを使用した Red Hat OpenShift でのマルチテナンシーの構成</block>
  <block id="6d72da55d82cdd434045ba5df1a959b6" category="paragraph">コンテナで複数のアプリケーションやワークロードを実行する多くの組織は、アプリケーションやワークロードごとに 1 つの Red Hat OpenShift クラスタを導入する傾向にあります。これにより、アプリケーションやワークロードを厳密に分離し、パフォーマンスを最適化し、セキュリティの脆弱性を軽減できます。ただし、アプリケーションごとに独立した Red Hat OpenShift クラスタを導入するには、独自の問題が発生します。これにより、各クラスタを個別に監視および管理する必要がある運用上のオーバーヘッドが増大し、さまざまなアプリケーションに専用リソースを使用することでコストが増大し、効率的な拡張性が妨げられます。</block>
  <block id="332dcd535fa9ce865f462efb80829a35" category="paragraph">この問題を解決するには、すべてのアプリケーションまたはワークロードを 1 つの Red Hat OpenShift クラスタで実行することを検討します。しかし、このようなアーキテクチャでは、リソースの分離とアプリケーションセキュリティの脆弱性が大きな課題の 1 つとなっています。あるワークロードのセキュリティの脆弱性は、自然に別のワークロードにオーバーフローする可能性があるため、影響ゾーンが増加します。また、あるアプリケーションによる突然の制御されないリソース使用率は、デフォルトではリソース割り当てポリシーがないため、別のアプリケーションのパフォーマンスに影響を与える可能性があります。</block>
  <block id="73c1b26ace2fc5fca6e6e78c00a61837" category="paragraph">このように効果的な解決策の 1 つは、 Red Hat OpenShift でマルチテナンシーを構成することです。マルチテナンシーは、複数のテナントを同じクラスタ上に共存させ、リソースやセキュリティなどを適切に分離できるアーキテクチャです。この場合、テナントは、特定のユーザグループが専用として使用するように設定されたクラスタリソースのサブセットとみなすことができます。Red Hat OpenShift クラスタでマルチテナンシーを設定する利点は次のとおりです。</block>
  <block id="f3ff3f5b3c67fb47bb8ec0f2f688b97d" category="paragraph">マルチテナント OpenShift クラスタを完全に実現するには、コンピューティング、ストレージ、ネットワーク、セキュリティなど、異なるリソースバケットに属するクラスタリソースにクォータと制限を設定する必要があります。この解決策のすべてのリソースバケットの特定の側面について説明しますが、 ネットアップでは、 NetApp ONTAP を基盤とする Astra Trident によって動的に割り当てられるストレージリソースにマルチテナンシーを設定することで、複数のワークロードで提供または消費されるデータを分離し、保護するためのベストプラクティスに焦点を当てています。</block>
  <block id="1cf7b9db4d7fe091bd1bbb685e5beea8" category="paragraph">Kubernetes 向けの Red Hat Advanced Cluster Management では、次のタスクを実行できます。</block>
  <block id="808c579683377aa7bd89b8e4d76ba220" category="list-text">複数のデータセンターとパブリッククラウドにわたって、複数のクラスタを作成、インポート、管理できます。</block>
  <block id="7fe0555145a586e3fb769f86902ccc72" category="list-text">1 つのコンソールから複数のクラスタにアプリケーションやワークロードを導入して管理</block>
  <block id="416434625b0f2158d99a4af37f233805" category="list-text">さまざまなクラスタリソースの健常性とステータスを監視および分析できます</block>
  <block id="fed6fdd49a1e6adda0ea12a93e74ea2d" category="list-text">複数のクラスタにわたってセキュリティコンプライアンスを監視し、実施できます。</block>
  <block id="1630dbfdd4887ce201ea82c71cde3d11" category="doc">Kubernetes 向けの高度なクラスタ管理機能を導入</block>
  <block id="bc2ab7a7550cebeb52a08cf830b5ecf6" category="list-text">Operators &gt; Operators Hub に移動し、 Kubernetes の Advanced Cluster Management を検索します。</block>
  <block id="c4ab802b80978ba1c5de3922d546bdb7" category="list-text">Kubernetes の高度なクラスタ管理を選択し、インストールをクリックします。</block>
  <block id="c972585d6241c4f2ed2604bcc8706358" category="list-text">Install Operator 画面で、必要な詳細情報を入力し（デフォルトのパラメータをそのまま使用することを推奨）、 Install をクリックします。</block>
  <block id="7bf3d0678c48be5730f20005e6f88aa1" category="list-text">オペレータがインストールされたら、 Create MultiClusterHub （ MultiClusterHub の作成）をクリックします。</block>
  <block id="95f29f27e373a9759cf065e1fde23e28" category="list-text">Create MultiClusterHub （マルチクラスタハブの作成）画面で、詳細を提供した後に Create （作成）をクリックします。これにより、マルチクラスタハブのインストールが開始されます。</block>
  <block id="a50aa5e8249109d6f4902945e968ad7d" category="list-text">すべてのポッドがオープンクラスタ管理ネームスペースの running 状態に移行し、オペレータが Succeeded 状態に移行すると、 Kubernetes の Advanced Cluster Management がインストールされます。</block>
  <block id="391dd52c88201d377f1572062e22c43e" category="list-text">ハブのインストールが完了するまでにはしばらく時間がかかり、完了すると、マルチクラスタハブは running 状態に移行します。</block>
  <block id="eef36825efd5d2d40e4f833635cd19da" category="list-text">オープンクラスタ管理ネームスペースにルートが作成されます。ルートの URL に接続して、 Advanced Cluster Management コンソールにアクセスします。</block>
  <block id="f122078c68f20c36897fec8a7c4a23e8" category="doc">OpenShift の概要</block>
  <block id="8c2b388bd42b0b6bae19890633c98a8d" category="list-text">* セキュリティとコンテナカタログ。 * OpenShift はマルチテナンシーを提供し、 Security-Enhanced Linux （ SELinux ）、 cgroups 、 Secure Computing Mode （ seccomp ）との確立されたセキュリティを使用してコンテナを分離し、保護することにより、ユーザを有害なコードの実行から保護します。また、さまざまなサブシステム用の TLS 証明書による暗号化、およびエンドユーザーに認証済みの信頼できるセキュアなアプリケーションコンテナを提供するためにセキュリティを重視してスキャンおよび採点される Red Hat 認定コンテナ（ access.redhat.com/containers ）へのアクセスも提供します。</block>
  <block id="9c2dd02f13d452b4422ac6c864933f01" category="paragraph">Red Hat OpenShift 4 以降、 OpenShift の導入方法には、高度にカスタマイズされた導入に User Provisioned Infrastructure （ UPI ；ユーザプロビジョニングインフラ）を使用する手動導入、または Installer Provisioned Infrastructure （ IPI ）を使用した完全に自動化された導入が含まれます。</block>
  <block id="66f8ff89bd2c9146cb3273d416c60fd2" category="list-text">Red Hat OpenShift を導入する環境を選択します。</block>
  <block id="f5806bcee67fc8f13f0255068a186e42" category="list-text">次の画面で、インストーラ、独自のプルシークレット、および管理用の CLI ツールをダウンロードします。</block>
  <block id="d711fd24836980dd490f3c01dd3ee8de" category="paragraph">ネットアップでは、以下の各データセンター環境で Installer Provisioned Infrastructure （ IPI ）導入方法を使用して、 Red Hat OpenShift のラボへの導入をテストし、検証しています。</block>
  <block id="77caa49b32b4fc8ce3276158f57f9229" category="doc">ネットアップストレージの概要</block>
  <block id="50bc4bb14f0d89a22c593112574d0fb3" category="list-text">AFF システムと FAS システムは、 NetApp ONTAP を実行し、ファイルベース（ NFS ）とブロックベース（ iSCSI ）の両方のユースケースにストレージを提供します。</block>
  <block id="bf3bfadca5040d5a50a8703c7dbb7ef1" category="list-text">Cloud Volumes ONTAP と ONTAP Select は、それぞれクラウドと仮想スペースに同じメリットをもたらします。</block>
  <block id="cb050b8fb8c2102a0ab337119eb19f0f" category="admonition">ネットアップのポートフォリオに含まれる各ストレージシステムでは、オンプレミスサイトとクラウド間でのデータ管理と移動の両方を容易に行えるため、データがアプリケーションの配置場所にあることを保証できます。</block>
  <block id="b432301f7ba469598e6ea2eb86e4859a" category="paragraph">一般的には、最も簡単に導入できる解決策が最適ですが、場合によっては、特定のアプリケーションまたは解決策の導入先環境の要件または仕様を満たすために、高度なカスタマイズが必要になります。そのため、 NetApp 解決策を使用した Red Hat OpenShift では、これらのニーズに合わせて次のカスタマイズを行うことができます。</block>
  <block id="d31d340fd6b135cac2cfac7b04a34c10" category="list-text">左上隅で、ロールを Administrator から Developer に変更します。+ 追加をクリックし、カタログからを選択します。キーワードでフィルターバーで Jenkins を検索します。永続的ストレージを使用する Jenkins Service を選択します。</block>
  <block id="fb86f2dea9912af1bb1677c9cf33e619" category="list-text">Jenkins ポッドが「 Ready 」状態になるまでに約 10 ～ 12 分かかります。</block>
  <block id="d59d1324dea050a2c0ffc376de411aa0" category="list-text">Jenkins アプリケーションの作成時に OpenShift OAuth が使用されていたため、「 OpenShift でログイン」をクリックします。</block>
  <block id="70a742210f3e3599821b3a11b682144c" category="list-text">Jenkins サービスアカウントに OpenShift ユーザへのアクセスを許可します。</block>
  <block id="b07934b6023389a7e3e183b45e3b7448" category="list-text">Jenkins のようこそページが表示されます。Maven ビルドを使用しているので、まず Maven のインストールを完了します。Manage Jenkins &gt; Global Tool Configuration に移動し、 Maven サブヘッドで Add Maven をクリックします。任意の名前を入力し、 [ 自動的にインストール ] オプションが選択されていることを確認します。[ 保存 ] をクリックします .</block>
  <block id="8fd32305bf380bf893ef2407eae75f5d" category="list-text">CI / CD のワークフローを示すパイプラインを作成できるようになりました。ホームページで、左側のメニューから [ 新規ジョブの作成 ] または [ 新規アイテム ] をクリックします。</block>
  <block id="cd55d787cacfb25983e0a24b58ba6d48" category="list-text">パイプライン (Pipeline) タブを選択しますサンプルパイプラインを試すドロップダウンメニューから、 Github + Maven を選択します。コードが自動的に入力されます。[ 保存 ] をクリックします .</block>
  <block id="eaeef52618dbbd29ca52633c93abcbb4" category="list-text">目的の OS を選択し、 Next （次へ）をクリックします。</block>
  <block id="6befc3ce0d5cbd575434f0d5e1ec1125" category="list-text">選択したオペレーティングシステムにブートソースが設定されていない場合は、設定する必要があります。Boot Source （起動ソース）で、 URL またはレジストリから OS イメージをインポートするかどうかを選択し、対応する詳細を指定します。Advanced を展開し、 Trident から作成されたストレージクラスを選択します。[ 次へ ] をクリックします。</block>
  <block id="3d210170d7f07fe3c907e8ac619f003a" category="doc">NetApp Astra Control Center の概要</block>
  <block id="9b0d9ae1197ded2c7d52147e5056475d" category="paragraph">NetApp Astra Control Center は、オンプレミス環境に導入され、ネットアップのデータ保護テクノロジを基盤とするステートフル Kubernetes ワークロード向けの充実したストレージサービスとアプリケーション対応データ管理サービスを提供します。</block>
  <block id="f0358bd53d50b55aa0509189dd381ca9" category="paragraph">NetApp Astra Control Center は、 Astra Trident ストレージオーケストレーションツールを導入し、 NetApp ONTAP ストレージシステムにストレージクラスとストレージバックエンドを使用して構成した Red Hat OpenShift クラスタにインストールできます。</block>
  <block id="8cc4d72a7129322eb1f39ea9b9cfb2f6" category="inline-link-macro">このドキュメントはこちら</block>
  <block id="1c2ddd920580e1a7860afb96d7ac352e" category="paragraph">Astra Trident のインストールと設定を行い、 Astra Control Center をサポートするには、を参照してください <block ref="a581b27b235a239b8b186164c4dbebd1" category="inline-link-macro-rx"></block>。</block>
  <block id="876ae62d75901b9ef80277fd884aa5e9" category="paragraph">クラウド接続環境では、 Cloud Insights を使用して高度なモニタリングとテレメトリを提供します。Cloud Insights 接続がない場合は、限定的な監視と計測（ 7 日間相当の指標）を使用でき、オープン指標エンドポイントを介して Kubernetes の標準の監視ツール（ Prometheus および Grafana ）にエクスポートされます。</block>
  <block id="54a5ba4de846d3c3ba8c0322f5139893" category="paragraph">Astra Control Center は、ネットアップの AutoSupport と Active IQ のエコシステムに完全に統合されており、ユーザをサポートし、トラブルシューティングを支援し、使用状況の統計を表示します。</block>
  <block id="34610c3089a79a0b0e58bcc24da4c16c" category="paragraph">Astra Control Center の有料版に加え、 90 日間の評価ライセンスも提供されています。評価版は、 E メールとコミュニティ（ Slack チャンネル）を通じてサポートされています。お客様は、これらの記事やその他のナレッジベース記事、および製品サポートダッシュボードから入手可能なドキュメントにアクセスできます。</block>
  <block id="b3d5fa878980b3f5b771ced3fa94111a" category="inline-link-macro">Astra の Web サイト</block>
  <block id="83d307afe7b187cee5d096f65402182f" category="paragraph">ネットアップアストラコントロールセンターの利用を開始するには、にアクセスしてください <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>。</block>
  <block id="7f9648de128837be473a3b24e53ff823" category="section-title">Astra Control Center のインストールの前提条件</block>
  <block id="8ffc0d45ec909884b280603fd2556021" category="list-text">1 つ以上の Red Hat OpenShift クラスタ。バージョン 4.6 EUS および 4.7 が現在サポートされています。</block>
  <block id="526a5a0f546838d61791ded926113f71" category="list-text">各 Red Hat OpenShift クラスタに Astra Trident をインストールして設定しておく必要があります。</block>
  <block id="7433dd0f15704f71764248a0ca105fad" category="admonition">サイトに各 OpenShift インストールを実装し、永続的ストレージ専用の SVM を用意することがベストプラクティスです。マルチサイト環境では、追加のストレージシステムが必要です。</block>
  <block id="e32d2cb3312c2c7797ca52bd8d6ff26f" category="admonition">リンクを参照してください <block ref="0065297854ca0573913043e80b99a2d1" category="inline-link-macro-rx"></block> この目的で検証済みのロードバランサに関する情報。</block>
  <block id="aa32c16385a1b749687956188e4f0d9a" category="admonition">リンクを参照してください <block ref="9d2000c3bba4885fe5f36ed192264583" category="inline-link-macro-rx"></block> この目的のために OpenShift プライベートレジストリをインストールして構成します。</block>
  <block id="121c2592ea226f655d357a8ecd8caf2e" category="inline-link">Astra 登録サイト</block>
  <block id="ba6df9237a2774d7ca28cdf134cf9314" category="admonition">Astra Control の試用版ライセンスの使用を開始するには、にアクセスしてください<block ref="dd61f8f3fbfa8ca8b0a268b985d55b0e" category="inline-link-rx"></block>。</block>
  <block id="29fc4f6574f437e623e4eb9d47136931" category="list-text">インストールを開始する前に、 Astra Control Center イメージをイメージレジストリにプッシュします。</block>
  <block id="25b4e951c048e2ae39554f36af8824b9" category="admonition">この手順では、 Docker または Podman のいずれかを使用して実行します。両方の手順については、この手順で説明します。</block>
  <block id="a53846d7be2355a59af69a47e2cf4637" category="list-text">シェルスクリプトファイルを作成し、次の内容を貼り付けます。</block>
  <block id="ad3318a786149147666e961c291c6875" category="admonition">レジストリに信頼されていない証明書を使用している場合は、シェルスクリプトを編集し、 podman push コマンドに「 --tls-verify=false 」を使用します。「 podman push $registry/ $ 」（ echo $astraalImage | sed's /^[^\\/]\\/'/')--tls-verify=false 」）。</block>
  <block id="f39d61476380fc033f45c2d744596b00" category="list-text">次に、イメージレジストリ TLS 証明書を OpenShift ノードにアップロードします。そのためには、 TLS 証明書を使用して OpenShift -config ネームスペースに ConfigMap を作成し、クラスタイメージ構成にパッチを適用して証明書を信頼できるようにします。</block>
  <block id="508ca0ca5ae419c052d9a8487bb0b2d0" category="admonition">ルートとともに入力オペレータからのデフォルト TLS 証明書を含む OpenShift 内部レジストリを使用している場合は、前の手順に従って、ルートホスト名に証明書をパッチする必要があります。入力オペレータから証明書を抽出するには、コマンド「 oc extract secret/router-ca --keys=tls.crt-n OpenShift ingress-operator 」を使用します。</block>
  <block id="6d71c41a686bcfc0b0866044afd43f2b" category="list-text">その名前空間のイメージレジストリにアクセスするためのシークレットを作成します。</block>
  <block id="25eb68598d15a49d385089020950412c" category="list-text">Astra Control Center CRD ファイル 'Astra_control_center_min.yaml を編集し 'FQDN' イメージレジストリの詳細 ' 管理者の電子メールアドレスなどの詳細を入力します</block>
  <block id="42b9bde28896d6478a324770641ac301" category="admonition">前のファイル「 Astra_control_center_min YAML 」は、 Astra Control Center CRD の最小バージョンです。PVC 作成時のデフォルト以外のストレージクラスを定義したり、メール通知用の SMTP の詳細を提供したりするなど、より詳細な制御を伴う CRD を作成する場合は、ファイル「 Astra_control_center.yaml 」を編集して必要な詳細を入力し、それを使用して CRD を作成します。</block>
  <block id="e3cd33ca69b8e508c973939783f528db" category="list-text">インストールが完了するまでに数分かかることがあります。NetApp-AstrA-cc' ネームスペース内のすべてのポッドとサービスが稼働していることを確認します</block>
  <block id="c27deb19babf146e6377dce25b1e70e7" category="list-text">Astra Control Center にログインするためのユーザ名は、 CRD ファイルに提供された管理者の電子メールアドレスで、パスワードは Astra Control Center UUID に付加された文字列「 ACC-` 」です。次のコマンドを実行します。</block>
  <block id="57a7aa2eaf00ddaa73ef6b49299ade6e" category="admonition">この例では、パスワードは「 ACC-345c55a5 -bf2e-21f0 -84b8 -b6f2bce5e95f 」です。</block>
  <block id="19bae630567610f1955167595b8daae3" category="list-text">CRD で提供された管理者メールアドレスを使用して初めて Astra Control Center GUI にログインする場合は、パスワードを変更する必要があります。</block>
  <block id="0c62383e1115b208212b5a634214ae37" category="list-text">ユーザーを Astra Control Center に追加する場合は、 [ アカウント ]&gt;[ ユーザー ] の順に選択し、 [ 追加 ] をクリックしてユーザーの詳細を入力し、 [ 追加 ] をクリックします。</block>
  <block id="60423d24e49c8db4836be0abd09fb78d" category="doc">NetApp ONTAP iSCSI 構成</block>
  <block id="cbaa3aa588b8aa5c85dca443c15a0195" category="doc">NetApp ONTAP の NFS 構成</block>
  <block id="f897eefba2c59919d6493db4825e2db2" category="admonition">カスタムの backendName 値は、簡単に識別できるように NFS を提供するストレージ DriverName とデータ LIF を組み合わせて定義することを推奨します。</block>
  <block id="a802e9436bb9bcbfa2b88bb549e28503" category="paragraph">ほとんどの場合、 Red Hat OpenShift は、ルートを介してアプリケーションを外部で利用できるようにします。サービスは、外部からアクセス可能なホスト名を付与することで公開されます。定義されたルートおよびサービスによって識別されるエンドポイントは、 OpenShift ルータによって使用され、外部クライアントにこの名前付き接続を提供できます。</block>
  <block id="abd6754aa5a185ca83b3f00c5da68534" category="inline-link-macro">次は、解決策の検証 / ユースケースです。</block>
  <block id="8bfe62be82a77570753936203ee020ca" category="paragraph"><block ref="8bfe62be82a77570753936203ee020ca" category="inline-link-macro-rx"></block></block>
  <block id="445b72f2cbecd97022bb6636eda3cbc7" category="cell">さまざまなアプリケーションやワークロード用のプロジェクトを作成できます</block>
  <block id="bfc5fb8ef5464441bc8b3ca7eda2892d" category="cell">割り当てられたプロジェクトで PVC またはポッドを作成またはパッチするためのアクセスを検証します</block>
  <block id="9e95c94350b2b7b51176ad958deb1388" category="cell">アクセスを検証して、別のプロジェクトで PVC またはポッドを作成またはパッチします</block>
  <block id="8c0b7954d326b4bcf2f42a57ef00eead" category="cell">アクセス権を検証して、プロジェクト、リソースクォータ、ストレージクラスを表示または編集します</block>
  <block id="c2c2a82496277a88b32b0e8d27249d3d" category="inline-link-macro">次のステップ：アプリケーションを保護しましょう。</block>
  <block id="d5be948b8a7fea6618eb171c64927be2" category="paragraph"><block ref="d5be948b8a7fea6618eb171c64927be2" category="inline-link-macro-rx"></block></block>
  <block id="bbb49986c10d9b599ce8b72ea09d5261" category="list-text">Operators &gt; OperatorHub に移動して、 OpenShift Virtualization を検索します。</block>
  <block id="2515fbef39d57544723402c683215c64" category="doc">ネットアップストレージ統合の概要</block>
  <block id="689ca76b61ed9331405d36eb5ded709d" category="paragraph">ネットアップは、 Red Hat OpenShift などのコンテナベースの環境における永続的データのオーケストレーションと管理に役立つさまざまな製品を提供します。</block>
  <block id="bc2397695676d1a63e489d4c80c8cd91" category="paragraph">Kubernetes 向けの高度なクラスタ管理機能を使用すると、ユーザはコンソールから 1 つ以上の管理対象クラスタ上にリソースを同時に作成できます。たとえば、異なる NetApp ONTAP クラスタでサポートされている異なるサイトに OpenShift クラスタがあり、両方のサイトで PVC をプロビジョニングする場合は、上部バーの（ + ）記号をクリックします。次に、 PVC を作成するクラスタを選択し、リソース YAML を貼り付けて、 Create をクリックします。</block>
  <block id="2fb91f8695d5dc9db4bf5a7ef710ec73" category="list-text">Astra Control Center で、対象となるストレージクラスが検出される。次に、ストレージクラスが NetApp ONTAP 上の SVM がサポートする Trident を使用してボリュームをプロビジョニングする方法を選択し、 Review （確認）をクリックします。次のペインで詳細を確認し、 Add Cluster をクリックします。</block>
  <block id="3edb3c83eb1bede6778cc1960a651973" category="list-text">手順 1 の説明に従って、両方の OpenShift クラスタを登録します。追加すると、 Astra Control Center がクラスタを検査して必要なエージェントをインストールしながら、クラスタは Discovering ステータスに移行します。クラスタが登録されると、クラスタのステータスが「 Running 」に変わります。</block>
  <block id="ed5c1a60b8165b8bc691cbdf1b0d122c" category="admonition">Astra Control Center で管理するすべての Red Hat OpenShift クラスタは、管理対象クラスタにインストールされたエージェントとしてインストールに使用されたイメージレジストリにアクセスできる必要があります。このレジストリからイメージがプルされます。</block>
  <block id="feab1371530d1ef069d928e811bcb08b" category="list-text">ONTAP クラスタをインポートするには、バックエンドに移動し、ドロップダウンをクリックして、管理対象の ONTAP クラスタの横にある Manage を選択します。ONTAP クラスタの資格情報を入力し、 [ 情報の確認 ] をクリックして、 [ ストレージバックエンドのインポート ] をクリックします。</block>
  <block id="d5a9f831c51dc05a9b40eae2850329fc" category="inline-link-macro">次に、保護するアプリケーションを選択します。</block>
  <block id="74dd157086250792afa856d5a6c32777" category="paragraph"><block ref="74dd157086250792afa856d5a6c32777" category="inline-link-macro-rx"></block></block>
  <block id="a62e902f0d244d960eddf2f14d3afa6f" category="paragraph">ベアメタル上の OpenShift では、コモディティサーバ上に OpenShift Container Platform を自動で導入できます。</block>
  <block id="0e05c6235b67ae8e5b743c9ca77358fa" category="paragraph">ベアメタル上の OpenShift は、コンテナ化の準備ができていないアプリケーションの仮想ワークロードをサポートしながら、 OpenShift クラスタの導入、迅速なプロビジョニング、拡張を容易にする OpenShift の仮想導入に似ています。ベアメタルに導入することで、 OpenShift 環境に加えてホストハイパーバイザー環境の管理に必要な追加のオーバーヘッドを必要としません。ベアメタルサーバに直接導入することで、ホストと OpenShift 環境間でリソースを共有する必要がある物理的なオーバーヘッドの制限を軽減できます。</block>
  <block id="9a3c3034787ddbd4af974d73f795c75a" category="list-text">* IPI またはサポートされたインストーラーの展開。 * ベアメタルサーバー上でインストーラー・プロビジョニング・インフラストラクチャー（ IPI ）によって展開される OpenShift クラスターにより、ハイパーバイザー層を管理することなく、汎用性が高く、容易に拡張できる OpenShift 環境を汎用サーバーに直接展開できます。</block>
  <block id="bf995f5252e568d22b265ec62c16914c" category="list-text">* 小型クラスタ設計。 * ハードウェア要件を最小限に抑えるため、ベアメタル上の OpenShift では、 OpenShift コントロールプレーンノードをワーカーノードやホストコンテナとしても機能させることにより、わずか 3 ノードのクラスタを導入できます。</block>
  <block id="13442dfd439ae0a377b0a2d2d9df1709" category="list-text">* OpenShift 仮想化。 * OpenShift では、 OpenShift Virtualization を使用してコンテナ内で仮想マシンを実行できます。このコンテナネイティブの仮想化では、コンテナ内で KVM ハイパーバイザーを実行し、 VM ストレージ用の永続ボリュームを接続します。</block>
  <block id="6e6a5272d3c6f8eceb96e3c19f0faaf6" category="list-text">* AI / ML に最適化されたインフラ。 * GPU ベースのワーカーノードを OpenShift 環境に組み込み、 OpenShift Advanced Scheduling を活用して、マシンラーニングアプリケーション向けの Kubeflow のようなアプリケーションを導入します。</block>
  <block id="6bc136fcf409560a1029f6f323619bbf" category="paragraph">NetApp 解決策上の Red Hat OpenShift では、 2 つのデータスイッチを使用して 25Gbps でプライマリデータ接続を提供します。また、ストレージノードのインバンド管理用に 1Gbps で接続を提供する管理スイッチを 2 台使用し、 IPMI 機能のアウトオブバンド管理も使用します。</block>
  <block id="17fea9675576fc9c72deb9501a5fd16a" category="paragraph">OpenShift ベアメタル IPI 環境では、プロビジョニングノード、つまりネットワークインターフェイスが別々のネットワークに接続されている Red Hat Enterprise Linux 8 マシンを作成する必要があります。</block>
  <block id="2f42f99315e0171a6e5c61957ae4689c" category="list-text">* ネットワークのプロビジョニング。 * このネットワークは、ベアメタルノードをブートし、 OpenShift クラスタを導入するために必要なイメージとパッケージをインストールするために使用されます。</block>
  <block id="aba727a2dc3dd836a33a2022bb2a9c3f" category="list-text">* ベアメタルネットワーク。 * このネットワークは、導入後のクラスタのパブリック側通信に使用されます。</block>
  <block id="7633522f66aaba6bc4bb2c25d299d287" category="paragraph">プロビジョニングノードをセットアップするために、お客様は、トラフィックをノード自体と、導入用にプロビジョニングされたブートストラップ VM に適切にルーティングできるようにするブリッジインターフェイスを作成します。クラスタが導入されると、 API および入力 VIP アドレスがブートストラップノードから新しく導入されたクラスタに移行されます。</block>
  <block id="963d7d04e1f1692a7fc49ae899123dbd" category="paragraph">次の図は、 IPI の導入時と導入の完了後の環境を示しています。</block>
  <block id="f53272342c85041784b2d5136e6eaa7d" category="cell">ベアメタルネットワーク</block>
  <block id="11405696f0e53417a3847f430a7b8ed0" category="cell">プロビジョニングネットワーク</block>
  <block id="eb5f501445f81cb1f7f4cf290565f9c8" category="admonition">これらの各ネットワークは仮想的に VLAN で分離されますが、 PXE ブートシーケンス中に VLAN タグを渡す方法がないため、各物理ポートをプライマリ VLAN が割り当てられたアクセスモードで設定する必要があります。</block>
  <block id="3ab0ae61b5256f874297403903fd5afc" category="paragraph">OpenShift Container Platform を導入する前に、次のインフラを用意する必要があります。</block>
  <block id="06a9d12a76441fd395abeba7bf0d7b91" category="list-text">インバンド管理ネットワークと VM ネットワークからアクセス可能な完全なホスト名解決を提供する DNS サーバが少なくとも 1 台必要です。</block>
  <block id="b611590ed189a9cbc27648402168f00a" category="inline-link-macro">次：ネットアップストレージの概要</block>
  <block id="2be0276ec05c9b03a47573ad9795095a" category="paragraph"><block ref="2be0276ec05c9b03a47573ad9795095a" category="inline-link-macro-rx"></block></block>
  <block id="932e95da8a59703292a426466e703c7a" category="paragraph">Red Hat Virtualization （ RHV ）は、 Red Hat Enterprise Linux （ RHEL ）で実行され、 KVM ハイパーバイザーを使用するエンタープライズ仮想データセンタープラットフォームです。</block>
  <block id="c29d3f9be705e3dcf947c6d2464cb090" category="list-text">* 自己ホスト型エンジン。 * ハードウェア要件を最小限に抑えるため、 RHV マネージャ（ RHV-M ）を、ゲスト VM を実行するホスト上の VM として導入することができます。</block>
  <block id="e2545c34b3a35dbcd93423b539eae91a" category="list-text">* 高可用性。 * ホスト障害時のシステム停止を回避するため、 RHV を使用することで、 VM を高可用性に設定することができます。高可用性 VM は、耐障害性ポリシーを使用してクラスタレベルで制御されます。</block>
  <block id="8f91b3a5c6d176cad584bb5f06c53684" category="list-text">* 高い拡張性。 * 1 つの RHV クラスタで最大 200 台のハイパーバイザホストを持つことができ、 IT 部門は大量の VM で、大量のリソースを消費するエンタープライズクラスのワークロードをホストするための要件をサポートできます。</block>
  <block id="a175fea9b8830c0cdbe1b268cb114738" category="list-text">* セキュリティ強化。 *RHV 、セキュア仮想化（ sVirt ）、およびセキュリティ強化 Linux （ SELinux ）テクノロジーから継承されたものは、セキュリティの強化とホストおよび VM の強化を目的として RHV によって採用されています。これらの機能の主なメリットは、 VM とそれに関連するリソースを論理的に分離できることです。</block>
  <block id="cd4c83df745cf56330120fb3ac308da2" category="paragraph">NetApp 解決策上の Red Hat OpenShift では、 2 つのデータスイッチを使用して 25Gbps でプライマリデータ接続を提供します。また、ストレージノードのインバンド管理用に 1Gbps で接続を提供する管理スイッチを 2 台追加し、 IPMI 機能用にアウトオブバンド管理を使用します。OCP は、クラスタ管理に RHV 上の仮想マシン論理ネットワークを使用します。このセクションでは、解決策で使用される各仮想ネットワークセグメントの配置と目的について説明し、解決策を導入するための前提条件について説明します。</block>
  <block id="c347686b0750301dfca053b321126bcc" category="cell">RHV-H ノード、 RHV-Manager 、および ovirtmgmt ネットワークの管理</block>
  <block id="4a3fe6077a529bcbe033bbb7d13027d6" category="paragraph">Red Hat OpenShift は最初に 3 つのマスターノードで導入するため、 2 ノード構成で少なくとも 2 つのマスターが同じノードを占有します。そのため、特定のノードが使用できなくなった場合に OpenShift が停止する可能性があります。そのため、解決策の一部として少なくとも 3 つの RHV - H ハイパーバイザーノードを導入して、 OpenShift マスターを均等に分散できるようにし、解決策にさらにフォールトトレランスを追加することが Red Hat のベストプラクティスです。</block>
  <block id="02d7502b2b132a675665088322fde9b0" category="paragraph">パラメータに定義された条件は、強制またはソフト強制のいずれかです。強制をハードに行うことで、アフィニティグループ内の VM は、外部条件に関係なく常に正または負のアフィニティに従って配置されます。ソフトな適用では、可能なかぎり、アフィニティグループ内の VM に対して肯定的または否定的なアフィニティに従って高い優先度が設定されます。このドキュメントで説明する 2 つまたは 3 つのハイパーバイザー構成では、ソフトアフィニティが推奨される設定です。大規模なクラスタでは、ハードアフィニティによって OpenShift ノードを適切に分散できます。</block>
  <block id="2b083bcbbb2d2208e64c13cb183af44f" category="paragraph">IPI を使用すると、このドキュメントで前述した対話型ウィザードを使用して、 OpenShift クラスタを簡単に導入できます。ただし、一部のデフォルト値については、クラスタの導入時に変更が必要になる場合があります。</block>
  <block id="a5867d73fa54e5b850ff2642c45ade52" category="paragraph">このような場合は、クラスタをすぐに導入せずにウィザードを実行してタスクを実行できます。クラスタの導入に使用する構成ファイルが作成されます。これは、 IPI のデフォルト値を変更する場合や、マルチテナンシーなどの他の用途のために環境内に同一のクラスタを複数導入する場合に非常に便利です。OpenShift 用にカスタマイズされたインストール構成の作成の詳細については、を参照してください<block ref="15427a9f842d7a49b872cf64115f33bc" category="inline-link-rx"></block>。</block>
  <block id="1d45b25ba986072287aaf72b6cf94130" category="paragraph">ネットアップ ONTAP を基盤とする Red Hat OpenShift と Astra Trident は、デフォルトでワークロードを分離する機能を提供していませんが、マルチテナンシーの設定に使用できる幅広い機能を備えています。ネットアップ ONTAP を基盤とする Astra Trident を使用した Red Hat OpenShift クラスタでのマルチテナント解決策の設計について理解を深めるために、一連の要件を含む例を検討し、その構成について概説します。</block>
  <block id="385df0e95c28430fb792ec836529f371" category="paragraph">2 つの異なるチームが取り組んでいる 2 つのプロジェクトの一環として、組織が Red Hat OpenShift クラスタ上で 2 つのワークロードを実行するとします。こうしたワークロードのデータは、 NetApp ONTAP NAS バックエンドの Astra Trident によって動的にプロビジョニングされる PVC 上に存在します。組織では、この 2 つのワークロードに対応するマルチテナント解決策を設計し、これらのプロジェクトに使用されるリソースを分離して、セキュリティとパフォーマンスを維持することが求められています。主に、これらのアプリケーションを提供するデータに重点が置かれています。</block>
  <block id="9c965c0beb472bc9265925ebbc55507e" category="paragraph">次の図は、ネットアップ ONTAP を基盤とする Astra Trident を使用した Red Hat OpenShift クラスタ上のマルチテナント解決策を示しています。</block>
  <block id="72710b926f57dad99b29203c63f4e3fd" category="paragraph">Red Hat OpenShift クラスタの観点からは、最初に最上位のリソースがプロジェクトです。OpenShift プロジェクトは、 OpenShift クラスタ全体を複数の仮想クラスタに分割するクラスタリソースと見なすことができます。したがって、プロジェクトレベルでの分離によって、マルチテナンシーの設定の基盤が提供されます。</block>
  <block id="20e1834bb9396599a6dcf7d743aa1b36" category="paragraph">次に、クラスタで RBAC を設定します。ベストプラクティスとして、すべての開発者が 1 つのプロジェクトまたはワークロードを担当し、アイデンティティプロバイダ（ IdP ）内の単一のユーザグループに設定することを推奨します。Red Hat OpenShift では、 IdP の統合とユーザグループの同期が可能なため、 IdP のユーザとグループをクラスタにインポートできるようになります。これにより、クラスタ管理者は、プロジェクト専用のクラスタリソースへのアクセスをそのプロジェクトに使用するユーザグループまたはグループに分離して、クラスタリソースへの不正アクセスを制限できます。Red Hat OpenShift への IdP の統合の詳細については、のドキュメントを参照してください<block ref="213cff8958909b80a9514e0c8321d8ef" category="inline-link-rx"></block>。</block>
  <block id="6d4e96186b1f4267def393ec42bf2d9e" category="paragraph">Red Hat OpenShift クラスタの永続的ストレージプロバイダとして機能している共有ストレージを分離し、各プロジェクト用にストレージ上に作成されたボリュームが、別々のストレージ上に作成されたものと同じようにホストに表示されるようにすることが重要です。そのためには、プロジェクトやワークロードに応じて Storage Virtual Machine （ SVM ）を NetApp ONTAP 上に作成し、各 SVM をワークロード専用にします。</block>
  <block id="76245f392269db8492c3610e325b1963" category="paragraph">ストレージクラスにネームスペースリソースが含まれていないため、あるプロジェクトのストレージクラスに対するストレージ要求を別のネームスペースまたはプロジェクトのポッドで拒否するにはどうすればよいですか？回答では、 ResourceQuotas を使用します。ResourceQuotas は、プロジェクトごとのリソースの合計使用量を制御するオブジェクトです。プロジェクト内のオブジェクトで消費できるリソースの合計量だけでなく、リソースの数も制限できます。ほとんどの場合、 ResourceQuotas を使用してプロジェクトのリソースを制限することができます。この機能を効率的に使用することで、リソースのオーバープロビジョニングや過剰消費によるコストやシステム停止を削減できます。のドキュメントを参照してください<block ref="9b2bb9683c8f6144876bed616f252527" category="inline-link-rx"></block> を参照してください。</block>
  <block id="5402bb91006fe391aea122e11c3607db" category="paragraph">このユースケースでは、特定のプロジェクトのポッドが、プロジェクト専用ではないストレージクラスのストレージを要求しないように制限する必要があります。これを行うには '&lt;storage-class-name&gt;.storageeclass.storage0.k8sio/persistentvolumeclaims'0 を設定して ' 他のストレージ・クラスに対する永続的ボリューム要求を制限する必要がありますさらに、クラスタ管理者は、プロジェクト内の開発者が ResourceQuotas を変更するためのアクセス権を持っていないことを確認する必要があります。</block>
  <block id="b1a934cbded2602c4186fb43d7c8a986" category="paragraph">それぞれのユースケースに応じて、コンテナと仮想マシン（ VM ）はどちらも、さまざまなタイプのアプリケーションに最適なプラットフォームとして機能します。そのため、多くの組織では、ワークロードの一部をコンテナで実行し、一部を VM で実行しています。そのため多くの場合、 VM 用のハイパーバイザーとアプリケーション用のコンテナオーケストレーションツールという別々のプラットフォームを管理する必要があり、組織はさらに多くの課題に直面します。</block>
  <block id="14bd8c5f1032dd20f94d4434365c6530" category="admonition">ここで説明するロール定義は単なる例です。エンドユーザの要件に基づいて開発者の役割を定義する必要があります。</block>
  <block id="cf17c458ea3abaad557d7cfc69886dbe" category="list-text">クラスタ内のすべてのプロジェクトの ResourceQuotas を管理する役割を作成して、ストレージ管理者に割り当てます。</block>
  <block id="db99ab183aa8f56c951cf20e25e7465c" category="list-text">クラスタが組織のアイデンティティプロバイダと統合され、ユーザグループがクラスタグループと同期されていることを確認します。次の例は、アイデンティティプロバイダがクラスタに統合され、ユーザグループと同期されていることを示しています。</block>
  <block id="38f22acd9ae9c74099644738d613baaa" category="admonition">ストレージ管理者の場合は、 Trident オペレータとリソースクォータの 2 つのロールにバインドする必要があります。</block>
  <block id="3434f6853d017037506e47f83a18c3eb" category="section-title">プライベートイメージレジストリを作成しています</block>
  <block id="9b1c6f527a1a481b925397807f319e71" category="list-text">「 PEC 」セクションに以下の保管パラメータを入力して、 imagegeistry のオペレータを編集します。</block>
  <block id="9ef71cd5ccaeb28206cd64b1d184019c" category="list-text">カスタムホスト名を使用して OpenShift ルートを作成するには、「 PEC 」セクションに次のパラメータを入力します。保存して終了します。</block>
  <block id="e0b23bc469102cf89472e5734da92a23" category="admonition">上記のルート設定は、ルートのカスタムホスト名が必要な場合に使用されます。OpenShift でデフォルトのホスト名を持つルートを作成するには、「 PEC 」セクションに「 defaultRoute ： true 」というパラメータを追加します。</block>
  <block id="625bd6ae5e3ac822b187b90d50edb553" category="sidebar-title">カスタム TLS 証明書</block>
  <block id="08e414328e39f86009287c06a5f23d23" category="paragraph">ルートにカスタムホスト名を使用している場合、デフォルトでは、 OpenShift 入力オペレータのデフォルトの TLS 設定が使用されます。ただし、カスタム TLS 設定をルートに追加することはできます。これには、次の手順を実行します。</block>
  <block id="60d14675c3111738a4ed19528764a7b1" category="list-text">ルートの TLS 証明書とキーを使用して秘密を作成します。</block>
  <block id="47f7f890b5c1bcb52ae163771dbf35b0" category="list-text">imageregistry 演算子を編集して 'PEC' セクションに次のパラメータを追加します</block>
  <block id="9199ff34349c38138ad0275e447e6588" category="list-text">このような場合は、すべての管理者をもう一度編集し、管理状態を「管理状態」に変更してください。保存して終了します。</block>
  <block id="2bc42a1a9a963d9a3ff2118466e5db07" category="list-text">すべての前提条件を満たしている場合は、プライベートイメージレジストリに PVC 、ポッド、およびサービスが作成されます。数分後にレジストリが起動します。</block>
  <block id="1f3713e339193dd15865ca74785eaa2c" category="list-text">入力オペレータ OpenShift レジストリルートにデフォルトの TLS 証明書を使用している場合は、次のコマンドを使用して TLS 証明書を取得できます。</block>
  <block id="295132dd97e1047a7c09e6a48054c469" category="list-text">OpenShift ノードがレジストリにアクセスしてイメージをプルできるようにするには、 OpenShift ノード上の Docker クライアントに証明書を追加します。TLS 証明書を使用して「 OpenShift -config 」ネームスペースに ConfigMap を作成し、証明書を信頼できるようにクラスタイメージ設定にパッチします。</block>
  <block id="98f3e484001465a59149c551e8d88cf0" category="list-text">OpenShift の内部レジストリは認証によって制御されます。OpenShift ユーザはすべて OpenShift レジストリにアクセスできますが、ログインユーザが実行できる操作はユーザ権限によって異なります。</block>
  <block id="561d4c8140016564eee98ecbc20f9add" category="list-text">ユーザーまたはユーザーのグループがレジストリから画像をプルできるようにするには、ユーザーにレジストリビューアの役割が割り当てられている必要があります。</block>
  <block id="88167e36ea0f872788407d0e01fc1382" category="list-text">ユーザーまたはユーザーグループにイメージの書き込みまたはプッシュを許可するには、ユーザーにレジストリエディタの役割が割り当てられている必要があります。</block>
  <block id="5ba9e8f3c64be4c82249856cac87a071" category="list-text">OpenShift ノードがレジストリにアクセスし、イメージをプッシュまたはプルするには、プルシークレットを設定する必要があります。</block>
  <block id="fe2033a9e377624583baa802ffd9ce6d" category="list-text">サービスアカウントにパッチを適用するには、次のコマンドを実行します。</block>
  <block id="59bd1dbdd3278e23e67bcabffbc4d55a" category="list-text">ポッド定義でプルシークレットを参照するには、「 PEC 」セクションに次のパラメータを追加します。</block>
  <block id="c0c3b4069e9a2e249507f67a6a2a3b07" category="list-text">OpenShift ノードとは別にワークステーションからイメージをプッシュまたはプルするには、次の手順を実行します。</block>
  <block id="312eaa3acf94b813cfe857f63a602724" category="list-text">OC ログインコマンドを使用して OpenShift にログインします。</block>
  <block id="cb4744e00672fbf6eba33b1b86d23ae0" category="list-text">podman/docker コマンドで OpenShift ユーザクレデンシャルを使用してレジストリにログインします。</block>
  <block id="aa20d170f1ff336ec9079cf6dd1ccee3" category="list-text">画像を押したり引いたりします。</block>
  <block id="85ca996063b5ec233e56a20ba93c5f44" category="list-text">Storage &gt; Storage VMs と進み、 Add をクリックします。必要な詳細を指定して、プロジェクト 1 用とプロジェクト 2 用に 1 つずつ、 2 つの SVM を作成します。また、 SVM とそのリソースを管理するには vsadmin アカウントを作成します。</block>
  <block id="b436e7799d01413277e05983e509574a" category="list-text">ストレージ管理者として Red Hat OpenShift クラスタにログインします。</block>
  <block id="f934b433773b966e5ebe0c7172decda4" category="admonition">この例では ONTAP と NAS のドライバを使用しています。ユースケースに基づいてバックエンドを作成する場合は、適切なドライバを使用します。</block>
  <block id="4e92dab2ab2bbe684f09a2aca58c9e44" category="list-text">NetApp ONTAP クラスタ：</block>
  <block id="f675b3d5e1e137870f481a742a3ec0af" category="list-text">Trident がクラスタにインストールされている。</block>
  <block id="1db1a9d97c708824712706fc4267ec25" category="list-text">tridentctl および OC ツールがインストールされ、 $PATH に追加された管理ワークステーション。</block>
  <block id="7cf4175762acfbabf9178d34f2504b28" category="list-text">ONTAP への管理アクセス。</block>
  <block id="10a540d0ed57154e8676c5725af53935" category="list-text">OpenShift クラスタへのクラスタ管理者アクセス。</block>
  <block id="6340f6ab1111f349228595ebceb8f6db" category="list-text">クラスタがアイデンティティプロバイダに統合されました。</block>
  <block id="9e110c19bb79322a0b76199795550dea" category="list-text">アイデンティティプロバイダは、異なるチームのユーザを効率的に区別するように設定されています。</block>
  <block id="39d08ecbb9add7bd87659df206457a73" category="list-text">ハブクラスタには Red Hat OpenShift クラスタ（バージョン 4.5 以降）が必要です</block>
  <block id="d60c66eb778a488709534045787b6a26" category="list-text">Red Hat OpenShift クラスタへのクラスタ管理者アクセス</block>
  <block id="3fc5f6755312b7edeef9542bd55ef639" category="section-title">ガバナンスとリスク</block>
  <block id="87f4e127e0ecf99187b35830ca7e78aa" category="list-text">サイドバーから「ガバナンスとリスク」に移動します。</block>
  <block id="0ecc505d3375f8bb3bd959aaaf7e710a" category="list-text">コンプライアンスポリシーを作成するには、 Create Policy （ポリシーの作成）をクリックし、ポリシー標準の詳細を入力して、このポリシーに準拠するクラスタを選択します。このポリシーの違反を自動的に修正するには、 [ サポートされている場合に適用 ] チェックボックスをオンにして、 [ 作成 ] をクリックします。</block>
  <block id="ea1abad541ee7994705555d53c0281c3" category="list-text">[Workloads （ワークロード） ] &gt; [Virtualization （仮想化） ] &gt; [Virtual Machines （仮想マシン） ] に移動し、クローンを作成する仮想マシンの横にある省略記号をクリックします。</block>
  <block id="81ab8abf2317781c0eb6f4deeaeea5a5" category="list-text">Storage &gt; PersistentVolume要求 と進み、ソース VM に接続されている PVC の横にある省略記号をクリックします。</block>
  <block id="5ba8ff3c009683ee423b0884c25360d0" category="list-text">[Workloads （ワークロード） ] &gt; [Virtualization （仮想化） ] &gt; [Virtual Machines （仮想マシン） ] に移動し、 [Create （作成）</block>
  <block id="cd32f6b0aebb29494cbc9cc21a10c926" category="list-text">spec&gt; template&gt; spec&gt; volumes セクションで、コンテナディスクではなく、クローン PVC を接続します。新しい VM について、要件に応じてその他の詳細をすべて指定します。</block>
  <block id="f79c612e785ac74789a25e8dda9e8731" category="doc">Astra Trident の概要</block>
  <block id="bd4a2d19c5168aa8c2b89b4affba2402" category="cell">9.8 、 9.9.1</block>
  <block id="4af39dbe40f8a0467bbdd739a971f0ea" category="admonition">次のメッセージは、 Astra Control Center のインストールが正常に完了したことを示します。</block>
  <block id="5946314197ad84982efa6561d9da8302" category="list-text">traefik サービスのロードバランサ IP を取得します。</block>
  <block id="298a1e8781e536e60684ab1700c60962" category="list-text">Astra Control Center CRD ファイルに指定された FQDN を指す DNS サーバーのエントリを、 traefik サービスの「 external-IP 」に追加します。</block>
  <block id="0c64767e085896708adcbcc1c32c55fe" category="inline-image-macro">ACC GUI の DNS エントリを追加します</block>
  <block id="1c278e58c0255ae1f09fc4fa520160b6" category="paragraph"><block ref="1c278e58c0255ae1f09fc4fa520160b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a37ba7c36c036650f5e1e7ded5232245" category="list-text">Astra Control Center では、すべての機能が動作するためにライセンスが必要です。ライセンスを追加するには、 ［ アカウント ］ &gt; ［ ライセンス ］ の順に選択し、 ［ ライセンスの追加 ］ をクリックして、ライセンスファイルをアップロードします。</block>
  <block id="a003986254b5a6c136733113505348da" category="doc">F5 BIG-IP ロードバランサのインストール</block>
  <block id="048600e045fd4c5afe58ec9d65aa4b19" category="paragraph">F5 BIG-IP は、 L4-L7 ロードバランシング、 SSL/TLS オフロード、 DNS 、ファイアウォールなど、高度な運用レベルのトラフィック管理およびセキュリティサービスを幅広く提供する Application Delivery Controller （ ADC; アプリケーションデリバリコントローラ）です。これらのサービスにより、アプリケーションの可用性、セキュリティ、パフォーマンスが大幅に向上します。</block>
  <block id="5c47e8322efb7f77c0aa515fec29477e" category="paragraph">F5 BIG-IP は、専用ハードウェア、クラウド、またはオンプレミスの仮想アプライアンスに、さまざまな方法で導入、使用できます。要件に応じて F5 BIG-IP を調査し、導入するには、ここで説明しているドキュメントを参照してください。</block>
  <block id="16a275a8b38f9c5211732c331edb7135" category="paragraph">F5 BIG-IP サービスを Red Hat OpenShift と効率的に統合するために、 F5 は BIG-IP Container Ingress Service （ CIS ）を提供します。CI は、特定のカスタムリソース定義（ CRD ）の OpenShift API を監視し、 F5 BIG-IP システム構成を管理するコントローラポッドとしてインストールされます。F5 BIG-IP CIS は、 OpenShift でサービスタイプ Loadancers とルートを制御するように構成できます。</block>
  <block id="e3ce824a7aff01576faaac58df9e0b18" category="paragraph">さらに、タイプ LoadBalancer にサービスを提供するための自動 IP アドレス割り当てには、 F5 IPAM コントローラを使用できます。F5 IPAM コントローラは、 LoadBalancer サービスの OpenShift API を ipamLabel 注釈で監視し、事前構成済みプールから IP アドレスを割り当てるコントローラポッドとしてインストールされます。</block>
  <block id="3b08b142099d42d5280d7b493288bf63" category="paragraph">このページには、 F5 BIG-IP CIS および IPAM コントローラのインストールおよび設定手順がリストされています。前提条件として、 F5 BIG-IP システムを導入し、ライセンスを取得しておく必要があります。また、デフォルトでは BIG-IP VE 基本ライセンスに含まれている SDN サービスのライセンスも必要です。</block>
  <block id="5fb7b483d0c9fa099945579d826691b8" category="admonition">F5 BIG-IP は、スタンドアロンモードまたはクラスタモードで導入できます。この検証の目的上、 F5 BIG-IP はスタンドアロンモードで導入されましたが、本番環境では、単一点障害を避けるために、大量の IP で構成されたクラスタを使用することを推奨します。</block>
  <block id="0d3e8be481c0c23fd0a68da9a9340ef7" category="admonition">F5 BIG-IP システムは、専用のハードウェア、クラウド、またはオンプレミスの仮想アプライアンスとして、バージョンが 12.x よりも大きいオンプレミスに導入でき、 F5 CIS と統合できます。このドキュメントでは、 BIG-IP VE エディションなどを使用して、 F5 BIG-IP システムを仮想アプライアンスとして検証しました。</block>
  <block id="39bc153685f2a0c6d56db4227295a3b0" category="section-title">検証済みのリリース</block>
  <block id="00d0a06cc7c922b3bc62b22524723ff8" category="cell">F5 BIG-IP VE エディション</block>
  <block id="5bd03f916d1e7b0410d0d3b2d12c6366" category="cell">16.1.0</block>
  <block id="c6f7874f49f685ffdf1b5a8aad8875c4" category="cell">F5 Container Ingress Service の略</block>
  <block id="21f47a5b35d016c2f0f8f57704079407" category="cell">2.5.1</block>
  <block id="9635118f932e26e24f0ca315d3843379" category="cell">F5 IPAM コントローラ</block>
  <block id="5256eb2d6e3cf80e003a290e63843800" category="cell">0.1.4</block>
  <block id="088afeececf092d5a406e0f5022a9638" category="cell">F5 AS3</block>
  <block id="425b0ca2d1d9d5c75555116fcd1614bf" category="cell">3.30.0</block>
  <block id="7cd8fb6e31cc946c078d2740c76a9899" category="section-title">インストール</block>
  <block id="b9a4064fa117596b59fb18df84df74df" category="inline-link">F5 AS3 GitHub リポジトリ</block>
  <block id="6463cf716c052865ec9f4716ff0b5d3f" category="list-text">F5 Application Services 3 拡張機能をインストールして、 big-IP システムが命令コマンドではなく JSON で構成を受け入れるようにします。に進みます<block ref="0d4e47593b830323684cdec40cb60c71" category="inline-link-rx"></block>をクリックし、最新の RPM ファイルをダウンロードします。</block>
  <block id="4c0802ebd79a8c6e5ea4aed829f023c9" category="list-text">F5 BIG-IP システムにログインし、 iApps &gt; Package Management LX に移動して、 Import （インポート）をクリックします。</block>
  <block id="3536ed517a711f49cfe64071db031cf5" category="list-text">[ ファイルの選択 ] をクリックして、ダウンロードした AS3 RPM ファイルを選択し、 [OK] をクリックして、 [ アップロード ] をクリックします。</block>
  <block id="2a90f793207a5a0c028d8ccc45e943fd" category="inline-image-macro">iApps のアップロード</block>
  <block id="7a3eaac0605c201c339e116a475c0bf6" category="paragraph"><block ref="7a3eaac0605c201c339e116a475c0bf6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="caedd771b59d267eda8f88d329e8784f" category="list-text">AS3 拡張機能が正常にインストールされたことを確認します。</block>
  <block id="c434efeb83b6dc500ea7893f1ad4236b" category="inline-image-macro">AS3 インストールの検証です</block>
  <block id="eb52ccb2be126d28d17e4383ae6ea6cf" category="paragraph"><block ref="eb52ccb2be126d28d17e4383ae6ea6cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97e9e05bfde432cfa7291b1e55a52ba7" category="list-text">次に、 OpenShift システムと BIG-IP システム間の通信に必要なリソースを構成します。まず、 OpenShift SDN のための BIG-IP システムに VXLAN トンネルインターフェイスを作成し、 OpenShift と BIG-IP サーバ間にトンネルを作成します。Network &gt; Tunnels &gt; Profiles と進み、 Create をクリックして Parent Profile を VXLAN に設定し、フラッディング Type を Multicast に設定します。プロファイルの名前を入力し、 [ 完了 ] をクリックします。</block>
  <block id="faaca798da0468a250bf3c3bffc26681" category="inline-image-macro">VXLAN プロファイルを作成する</block>
  <block id="bddf6bed69a1a2234f15cefc27853c50" category="paragraph"><block ref="bddf6bed69a1a2234f15cefc27853c50" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45ae0c96657fdc5a20e83839c2386c1e" category="list-text">Network &gt; Tunnels &gt; Tunnel List と進み、 Create をクリックして、トンネルの名前とローカル IP アドレスを入力します。前の手順で作成したトンネルプロファイルを選択し、 [ 完了 ] をクリックします。</block>
  <block id="1497a4f92d416d6c80392ec3467ff140" category="inline-image-macro">VXLAN トンネルを作成します</block>
  <block id="53ce9cdf8cf7f6cb09991e817df94959" category="paragraph"><block ref="53ce9cdf8cf7f6cb09991e817df94959" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc5e5bc480b39177b8cb8c9c3a2266ae" category="list-text">クラスタ管理者権限で Red Hat OpenShift クラスタにログインします。</block>
  <block id="986e63a308b4bebd3f531e38fa5a06c7" category="list-text">F5 BIG-IP サーバの OpenShift にホストサブネットを作成します。このサブネットは、 OpenShift クラスタから F5 BIG-IP サーバに拡張します。ホストサブネット YAML 定義をダウンロードします。</block>
  <block id="fd4475e12938f5f51ba3f312b42cdd39" category="list-text">ホストサブネットファイルを編集し、 OpenShift SDN の BIG-IP VTEP （ VXLAN トンネル） IP を追加します。</block>
  <block id="2e6d8a8db3c4d4a2227ffa0571be2a86" category="admonition">ご使用の環境に応じて、 hostIP などの詳細情報を変更します。</block>
  <block id="7f9916ee1bc520d892dfbbb1e06e2732" category="list-text">HostSubnet リソースを作成します。</block>
  <block id="7a46b2d02d466dda0cc67b215cb80bff" category="list-text">F5 BIG-IP サーバ用に作成されたホストサブネットのクラスタ IP サブネット範囲を取得します。</block>
  <block id="4f6c1fea3654c07f1606c0c76509d0b0" category="list-text">F5 BIG-IP サーバに対応する OpenShift のホストサブネット範囲の IP を使用して、 VXLAN OpenShift 上に自己 IP を作成します。F5 BIG-IP システムにログインし、 [ ネットワーク ]&gt;[ 自己 IP ] の順に選択し、 [ 作成 ] をクリックします。F5 BIG-IP ホストサブネット用に作成されたクラスタ IP サブネットから IP を入力し、 VXLAN トンネルを選択して、その他の詳細を入力します。[ 完了 ] をクリックします。</block>
  <block id="5c241806c0dd5ebb7030904151cb78ef" category="inline-image-macro">VXLAN 用に自己 IP を作成する</block>
  <block id="ffad9e123d8b7013e7d4553570644879" category="paragraph"><block ref="ffad9e123d8b7013e7d4553570644879" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d094b7d82871afb601d2f30d416ba8d" category="list-text">CIS で設定および使用する F5 BIG-IP システムにパーティションを作成します。[ システム ]&gt;[ ユーザ ]&gt;[ パーティションリスト ] の順に選択し、 [ 作成 ] をクリックして詳細を入力します。[ 完了 ] をクリックします。</block>
  <block id="4d81871723233ec21ed69ab80e638779" category="inline-image-macro">BIG-IP パーティションを作成します</block>
  <block id="b83428617c6ed29213f89e68f142bd18" category="paragraph"><block ref="b83428617c6ed29213f89e68f142bd18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37397397fa66431e2fa681b97126c399" category="admonition">CIS で管理されるパーティションでは手動で設定しないことをお勧めします。</block>
  <block id="81e4a49e9dbe0b55256fe5abf1b94fa4" category="list-text">OperatorHub のオペレータを使用して F5 BIG-IP CIS をインストールします。cluster-admin 権限を持つ Red Hat OpenShift クラスタにログインし、 F5 BIG-IP システムログインクレデンシャルを使用してシークレットを作成します。これはオペレータの前提条件です。</block>
  <block id="5de4ac005898cabf55523098c40c549b" category="list-text">F5 CIS CRD をインストールします。</block>
  <block id="0eddace1b16ed738fe1be181481c71b6" category="list-text">[ 演算子 ]&gt;[ 演算子ハブ ] に移動し、キーワード F5 を検索して、 F5 Container Ingress Service タイルをクリックします。</block>
  <block id="07543409cb05595e273df71050b9a9c0" category="inline-image-macro">オペレータハブに F5 CIS を配置します</block>
  <block id="334a7bbf4711d93b48b93c2b81d84a71" category="paragraph"><block ref="334a7bbf4711d93b48b93c2b81d84a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c25b2a3d320d6d02584fde4190d05d91" category="list-text">オペレータ情報を読み、 [ インストール ] をクリックします。</block>
  <block id="60d3353ed1910ad5c7bd352d0c1bea85" category="inline-image-macro">OperatorHub の F5 CIS 情報タイル</block>
  <block id="1aa79507d413f19135716c8006afa423" category="paragraph"><block ref="1aa79507d413f19135716c8006afa423" category="inline-image-macro-rx" type="image"></block></block>
  <block id="637a1bc658defc200d903b27828aa8fb" category="list-text">Install Operator （オペレータのインストール）画面で、デフォルトのパラメータをすべてそのままにして、 Install （インストール）をクリックします。</block>
  <block id="ccf254d7c8b666c9c127ec12fe14804b" category="inline-image-macro">F5 CIS オペレータをインストールします</block>
  <block id="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="paragraph"><block ref="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="636d8318702bc67a1613ceadf7ce9d00" category="list-text">オペレータのインストールには時間がかかります。</block>
  <block id="dffa3077bcff43536afd75bd61b11c0c" category="inline-image-macro">F5 CIS オペレータインストールの進行状況</block>
  <block id="b1be0ed9469d2ced1f6283b49735f5c1" category="paragraph"><block ref="b1be0ed9469d2ced1f6283b49735f5c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="197a0a4cc4a45ec9a62fe2b7335d8dfc" category="list-text">オペレータがインストールされると、「 Installation Successful 」というメッセージが表示されます。</block>
  <block id="5bf83e99bfa132430d0b690181334933" category="list-text">[ 演算子 ]&gt;[ インストールされている演算子 ] に移動し、 [F5BigIpCtlr ] タイルの下にある [F5 Container Ingress Service] をクリックして、 [ インスタンスの作成 ] をクリックします。</block>
  <block id="a5f584f06c59c2cf4a4a4e8b42d495a2" category="inline-image-macro">F5BigIpCtlr を作成します</block>
  <block id="a2574a02e64888de32a5a277ed05f668" category="paragraph"><block ref="a2574a02e64888de32a5a277ed05f668" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5ce9a4ef68c16a3ab5d0dd555305872" category="list-text">YAML View をクリックし、必要なパラメータを更新した後で次の内容を貼り付けます。</block>
  <block id="2e2beb899f89156ed06287fe6f78e6cf" category="admonition">以下のパラメータ「 bigip_dpartition 」、「 OpenShift 」 SDN_NAME 」、「 bigip_url 」、「 bigip_login_secret 」を更新して、内容をコピーする前にセットアップの値を反映させます。</block>
  <block id="50a17348dc3f981a95001edcc80a428f" category="list-text">このコンテンツを貼り付けたら、 [ 作成 ] をクリックします。これにより、 CIS ポッドが kube-system 名前空間にインストールされます。</block>
  <block id="72003ce6faa67d172e943ddd74fab63b" category="inline-image-macro">F5 CIS ポッドを検証します</block>
  <block id="ef76b6b9f85ff0ec00e48f565e13eff9" category="paragraph"><block ref="ef76b6b9f85ff0ec00e48f565e13eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc8632c05e82ccafb395157ccae4f5c3" category="admonition">Red Hat OpenShift は、デフォルトで、 L7 ロードバランシングのルートを介してサービスを公開する方法を提供します。組み込みの OpenShift ルータは、これらのルートのトラフィックのアドバタイズと処理を行います。ただし、外部 F5 BIG-IP システムを介してルートをサポートするように F5 CIS を構成することもできます。このシステムは、補助ルータとして実行することも、自己ホスト型 OpenShift ルータに代わるものでもあります。CIS は、 OpenShift ルートのルータとして機能する BIG-IP システムに仮想サーバを作成し、 BIG-IP はアドバタイズメントとトラフィックルーティングを処理します。この機能を有効にするためのパラメータについては、次のドキュメントを参照してください。これらのパラメータは、 APPS/v1 API の OpenShift Deployment リソースに対して定義されています。したがって、 F5BigIpCtlr リソース cis.f5.com/v1 API でこれらを使用する場合は、パラメータ名にハイフン (-) をアンダースコア (_) に置き換えます。</block>
  <block id="a6e55fc1fe932b26a294a0f2880478aa" category="list-text">CIS リソースの作成に渡される引数には 'IPAM:true' と 'custom_resource_mode:true' がありますこれらのパラメータは 'IPAM コントローラとの CIS 統合を有効にするために必要ですF5 IPAM リソースを作成して 'CIS で IPAM 統合が有効になっていることを確認します</block>
  <block id="84ac0b78989fa6595723d5541b8ec470" category="list-text">F5 IPAM コントローラに必要なサービスアカウント、ロール、およびロールバインドを作成します。YAML ファイルを作成し、次の内容を貼り付けます。</block>
  <block id="670c1074ae74616731a63f6b9462b94e" category="list-text">リソースを作成します。</block>
  <block id="b7802bea6dc04d06b63232b6301621bb" category="list-text">YAML ファイルを作成し、下記の F5 IPAM 展開定義を貼り付けます。</block>
  <block id="6a1491ddca525bea3293eca6ea8019d0" category="admonition">以下の spec.template.spec.containers [0] の ip-range パラメータを更新して、設定に対応する ipamLabel と IP アドレス範囲を反映させます。</block>
  <block id="642252b62fe47e95caa77e3b06a7dbaf" category="admonition">IPAM コントローラが定義された範囲から IP アドレスを検出して割り当てるには 'ipamLabels[`range1' および range2` を以下の例に示します ] が 'LoadBalancer 型のサービスに注釈を付ける必要があります</block>
  <block id="8f253132259909c28624117b3476a672" category="list-text">F5 IPAM コントローラ配置を作成します。</block>
  <block id="43946dccec13f46420eb559911e4c526" category="list-text">F5 IPAM コントローラポッドが実行されていることを確認します。</block>
  <block id="1362b3e7985b4f24d6c2ef4438ee1f0e" category="list-text">F5 IPAM スキーマを作成します。</block>
  <block id="52b8ffce119fe77b28034f2fdd35eb5f" category="section-title">検証</block>
  <block id="32172ccfad6e7060b8f5e091e296f09c" category="list-text">LoadBalancer タイプのサービスを作成します</block>
  <block id="0847be44e618094bc81c848c7d131399" category="list-text">IPAM コントローラが外部 IP を割り当てるかどうかを確認します。</block>
  <block id="0e51a0606ba7833099aa57bd61c62ba6" category="list-text">導入環境を作成し、作成した LoadBalancer サービスを使用します。</block>
  <block id="5f905cb56a4d1b364cab7fc57f4de4e5" category="list-text">ポッドが実行されているかどうかを確認します。</block>
  <block id="51b4d723f0434284233dab97982b185d" category="list-text">対応する仮想サーバが、 OpenShift の LoadBalancer タイプのサービス用に BIG-IP システムに作成されているかどうかを確認します。Local Traffic &gt; Virtual Servers &gt; Virtual Server List の順に選択します。</block>
  <block id="91193cea3335c4666b7dc31ca767030c" category="inline-image-macro">対応するサービスタイプの LoadBalancer 用の BIG-IP 仮想サーバの作成を検証します</block>
  <block id="879dfaa1de924ed5e9ccb98da9ac95cd" category="paragraph"><block ref="879dfaa1de924ed5e9ccb98da9ac95cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="10a93051f49f4080568cecc5ec30cd99" category="inline-link-macro">F5 BIG-IP</block>
  <block id="886218e92c071e06819887a13189b4e6" category="list-text"><block ref="886218e92c071e06819887a13189b4e6" category="inline-link-macro-rx"></block></block>
  <block id="0c3fd18fbca2ec11aa1ef250cf79f2e5" category="paragraph">NetApp Astra Control は、ネットアップのデータ保護テクノロジを基盤とするステートフル Kubernetes ワークロード向けの充実したストレージサービスとアプリケーション対応データ管理サービスを提供します。Astra Control Service は、クラウドネイティブの Kubernetes 環境でステートフルワークロードをサポートするために利用できます。Astra Control Center は、 Red Hat OpenShift などのオンプレミス環境でステートフルワークロードをサポートするために使用できます。詳細については、 NetApp Astra Control の Web サイトをご覧ください<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>。</block>
  <block id="e6d792539f0b0370e43d76a3e05a211a" category="cell">仮想化コアソリューションの集合。ソリューションは、 [navy]#vmware Virtualization#[navy]#Demos and Tutorials#. に分類されています</block>
  <block id="1f23e5de73e650f12cbafec55d8a98cd" category="cell"><block ref="1f23e5de73e650f12cbafec55d8a98cd" category="inline-link-macro-rx"></block></block>
  <block id="69f55c7d7266874ad1ed57caf459c979" category="summary">この使用事例は、当社が実施した最も大規模な金融機関顧客向けコンセプトの実証（ CPOC ）に基づいています。ネットアップはこれまで、分析データを NetApp ONTAP AI に移動するためにネットアップの In-Place Analytics Module （ NIPAM ）を使用してきました。ただし、 NetApp XCP の最新の拡張機能とパフォーマンスの向上、および NetApp Data Mover 解決策独自のアプローチにより、 NetApp XCP を使用したデータ移行が再度行われます。</block>
  <block id="5084e1c3bd53b6115df08f4c40aadbe6" category="doc">データレイクから ONTAP NFS へ</block>
  <block id="ae8dcf06c5337995ca840fbd543188fc" category="inline-link-macro">Previous ：お客様のシナリオ</block>
  <block id="82f418da831bb7ca7897e30f8bc5525a" category="paragraph"><block ref="82f418da831bb7ca7897e30f8bc5525a" category="inline-link-macro-rx"></block></block>
  <block id="b1a11a01b3bdf3150e0240a1f037cdf5" category="section-title">お客様の課題と要件</block>
  <block id="9ed16d5ac47c336caaf9ca2b75930d78" category="paragraph">お客様が直面する課題と要件には、次のものがあります。</block>
  <block id="b6976e1a47e217f1a7c746e8f57e327c" category="list-text">構造化データ、非構造化データ、半構造化データ、ログ、 データレイク内のマシン間でデータを移動できます。AI システムでは、予測処理のために、これらすべてのタイプのデータを処理する必要があります。データがデータレイクネイティブファイルシステムにある場合、データを処理することは困難です。</block>
  <block id="d85cb5080a9e99841f0ff6c36abdadad" category="list-text">お客様の AI アーキテクチャは、 Hadoop Distributed File System （ HDFS ）および Hadoop Compatible File System （ HCFS ）からデータにアクセスできないため、データは AI 処理に利用できません。AI には、 NFS などのわかりやすいファイルシステム形式でデータが必要です。</block>
  <block id="982b6c87ace8f5b95c0523bd0557f4e2" category="list-text">データ量とスループットが多く、 AI システムにデータを移動するにはコスト効率の高い方法が必要であるため、データレイクからデータを移動するには特別なプロセスがいくつか必要になります。</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="section-title">Data Mover の解決策</block>
  <block id="b0a9a6f2387f2a23e13931f68fc509c1" category="paragraph">この解決策では、 MapR クラスタ内のローカルディスクから MapR ファイルシステム（ MapR - FS ）を作成します。MapR NFS Gateway は、仮想 IP を持つ各データノードに設定されています。ファイルサーバサービスは、 MapR - FS データを格納および管理します。NFS ゲートウェイを使用すると、仮想 IP を介して NFS クライアントからマップ FS データにアクセスできるようになります。Map NFS Gateway から NetApp ONTAP NFS にデータを転送するために、 MapR データノードごとに XCP インスタンスが実行されている。各 XCP インスタンスは、特定のソースフォルダのセットをデスティネーションの場所に転送します。</block>
  <block id="01e1c2900284f91d77ea71ffd32c6d18" category="paragraph">次の図は、 XCP を使用する MapR クラスタ用の NetApp Data Mover 解決策を示しています。</block>
  <block id="a7dcdfa2099e01480afb3c060c679f10" category="paragraph"><block ref="a7dcdfa2099e01480afb3c060c679f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="409f476aa8c516a92f8d6a42e21db5a0" category="inline-link">XCP を使用した、データレイクからハイパフォーマンスコンピューティング、 ONTAP NFS へのデータの移動</block>
  <block id="4084b5f9c9bab8db38eb6e04a3b3a4cc" category="paragraph">お客様の詳細なユースケース、デモの記録、テスト結果については、を参照してください<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> ブログ</block>
  <block id="6cef4abedb8153458ee404a47b193489" category="inline-link">TR-4732 ：『 Big Data Analytics Data to Artificial Intelligence 』</block>
  <block id="520ef13ea64298a652262e37756b6bd4" category="paragraph">NetApp XCP を使用して MapR FS データを ONTAP NFS に移動する手順の詳細については、の付録 B を参照してください<block ref="c952a09d2ff4403056a594c41db26c8d" category="inline-link-rx"></block>。</block>
  <block id="b4dd66db226c58dbbcc8455a7576d491" category="inline-link-macro">次に、 ONTAP NFS 向けのハイパフォーマンスコンピューティングを実現します。</block>
  <block id="9ebf542ce4a3a8a997eb85e5b6e086ed" category="paragraph"><block ref="9ebf542ce4a3a8a997eb85e5b6e086ed" category="inline-link-macro-rx"></block></block>
  <block id="89185de94c95d958df7a1d1f328c5d3d" category="summary">移行にはさまざまなフェーズがあり、移行の計画や完了に役立ちます。サードパーティ製 NAS ストレージまたは NetApp XCP を使用して直接接続された NAS エクスポートストレージからデータを移行する場合は、このセクションに記載されている移行のガイドラインに従ってください。</block>
  <block id="ee5b035493cdde88f6472904ffe00677" category="doc">データ移行ワークフロー</block>
  <block id="33af37ca0d75bc0783cc87782a94cb6e" category="inline-link-macro">以前のバージョン： NetApp XCP 。</block>
  <block id="c6f303d52bc03c848b2dde21f1b31f9d" category="paragraph"><block ref="c6f303d52bc03c848b2dde21f1b31f9d" category="inline-link-macro-rx"></block></block>
  <block id="5b312b66520bbb17746eeb5c9959e4ef" category="paragraph">次の図は、任意の NAS から NetApp NAS への移行ワークフローを示しています。</block>
  <block id="228d4a26c37192668bb7f7bf0d81ce40" category="paragraph"><block ref="228d4a26c37192668bb7f7bf0d81ce40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0e69ccbb7ad96f546f7924206944bfa" category="section-title">オンプレミス</block>
  <block id="8df17c51ab4a9817f3fe7cea57052110" category="paragraph">任意の NAS から NetApp NAS への移行ワークフローには、次の手順が含まれます。</block>
  <block id="3bd3dda9341b512ee536cc6e48d51a69" category="list-text">NAS 共有とデータを検出</block>
  <block id="7800ed0aa4aebf1d63fd7120c2bcf538" category="list-text">データをスキャンしてレポートを作成し、データのレイアウトを確認します。</block>
  <block id="8e9880476ad79e202d93a0a7d0bb5f5b" category="list-text">XCP Copy コマンドを実行してベースラインを作成します。移行を高速化するには、追加の XCP インスタンスを選択し、ワークロードをサブフォルダレベルで分割して、並行移行ジョブを開始します。</block>
  <block id="57324e972ea87c8e788d9831e510bc6d" category="list-text">差分更新の場合は、カットオーバー期間の変更率が低いまで XCP sync を使用します。</block>
  <block id="3812202d715addac73d7122672d3c8d0" category="list-text">移行を完了するには、 XCP sync コマンドを実行して、ソースを読み取り専用としてマークして最終同期を実行します。</block>
  <block id="2c1d8a91f274a7723f6ad2ffefc81b62" category="list-text">データが正しく転送されたことを確認するには 'XCP verify コマンドを実行して ' ソースとデスティネーションを比較します</block>
  <block id="8f4cde54f5af74d15d142ad98344aab6" category="paragraph">次の図は、オンプレミスからクラウドへの移行ワークフローを示しています。</block>
  <block id="9d1b3862e72bece8266c1c8b1098c696" category="paragraph"><block ref="9d1b3862e72bece8266c1c8b1098c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2fef7fa18bd688132425321b9188bb" category="paragraph">オンプレミスとクラウド間に直接インターネット接続がない場合は、トラックなどのオフラインデータ転送方式を使用して、オンプレミスからクラウドにデータを転送する必要があります。クラウドサービスプロバイダによって、データをデータセンターに移動するための用語が異なる手法が用意されています。</block>
  <block id="9e76bcaf48df4797c2e546f778fd72f8" category="paragraph">次の図は、 ExpressRoute を使用しないオンプレミスから Azure へのデータムーバーの解決策を示しています。</block>
  <block id="e13bab0261f71ca4765f8b68cea20a43" category="paragraph"><block ref="e13bab0261f71ca4765f8b68cea20a43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423066080659363cc444ec5dee611f48" category="paragraph">同様のアーキテクチャを各種クラウドサービスプロバイダの対応するコンポーネントと組み合わせて使用できます。</block>
  <block id="050572d01f21dded8086b49419066add" category="inline-link-macro">次のステップ：ファイル分析</block>
  <block id="ae292ee37a105844872f831698fb440f" category="paragraph"><block ref="ae292ee37a105844872f831698fb440f" category="inline-link-macro-rx"></block></block>
  <block id="c4e9391c8d60f1f326246cd6b6705492" category="summary">ネットアップは、 1 つまたは複数のボリュームから重複ファイルを検索する要求を受信しました。ネットアップは次の解決策を提供しました。</block>
  <block id="2e4e5fbe1f8f460b943ac3ed031c9dcf" category="doc">ファイルを複製します</block>
  <block id="f89d6874c6cf2c5de0dae9564728c7cf" category="inline-link-macro">前のバージョン： XCP Data Mover を使用して大容量ファイルを移行する。</block>
  <block id="6c8f161effcb72b9425f626e8733146b" category="paragraph"><block ref="6c8f161effcb72b9425f626e8733146b" category="inline-link-macro-rx"></block></block>
  <block id="dc4b36d55f5f1f0af63ed899a010c8f1" category="paragraph">単一のボリュームの場合は、次のコマンドを実行します。</block>
  <block id="2d2f31777cf3433071b9bcd33f39279a" category="paragraph">複数のボリュームの場合は、次のコマンドを実行します。</block>
  <block id="fdefb3eaaab41fef36db24700d399ef2" category="inline-link-macro">Next ：特定の日付ベースのスキャンとデータのコピー。</block>
  <block id="769f411db097d478d8d10a821946e501" category="paragraph"><block ref="769f411db097d478d8d10a821946e501" category="inline-link-macro-rx"></block></block>
  <block id="b25f76deff236f93a3afa73c8a5b2a2c" category="summary">このユースケースは、ネットアップが最も大規模な観光業界のお客様を対象に、クラウドへの小規模なオンプレミスファイルの移行を検討しています。</block>
  <block id="4b1739353c6d18cea69ed6a274b7135f" category="doc">XCP Data Mover を使用して、数百万個の小規模ファイルを柔軟なストレージに移行する</block>
  <block id="2b2142a0bf2476846ad59f7952380ca1" category="inline-link-macro">前のバージョン： ONTAP NFS へのハイパフォーマンスコンピューティング。</block>
  <block id="c81efa558deea51a126490ba8d09b59a" category="paragraph"><block ref="c81efa558deea51a126490ba8d09b59a" category="inline-link-macro-rx"></block></block>
  <block id="bb29cc4e9e4447f7bad1e81c1c5a9a1f" category="paragraph">このユースケースは、オンプレミスからクラウドへのデータ移行に関して、ネットアップの観光業界で最大のお客様を基準にしています。COVID-19 によって出張業界の需要が減少しているため、お客様は、オンプレミス環境のハイエンドストレージの設備投資を、需要に応じた価格設定アプリケーションで削減したいと考えています。このお客様は、数百万もの小規模ファイルをクラウドに移行するという厳しい SLA を持っています。</block>
  <block id="81ec900a5387f7a686d1451adaddf399" category="paragraph">次の図は、小規模ファイルを対象としたオンプレミスから Azure NetApp Files へのデータ移行を示しています。</block>
  <block id="214c5e9894032cde0e65b576e32294b9" category="paragraph"><block ref="214c5e9894032cde0e65b576e32294b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="099a60093e7de3795f557974125ce82b" category="inline-link">NetApp XCP Data Mover 解決策：オンプレミスからクラウドへ</block>
  <block id="50d4edabefc40ad9614b567197696a2e" category="paragraph">詳細については、を参照してください<block ref="2c0eb3741003532ef113837d4b882a9a" category="inline-link-rx"></block> ブログ</block>
  <block id="3242fe890cd89c89373a1bd576cef03a" category="inline-link-macro">次の手順： XCP Data Mover を使用して大容量ファイルを移行します。</block>
  <block id="c32441c7755c153b58450a597193448b" category="paragraph"><block ref="c32441c7755c153b58450a597193448b" category="inline-link-macro-rx"></block></block>
  <block id="485f9678c52b78d051ddff564d873eb9" category="summary">このセクションのコマンドでは、 CSV 形式でデータがダンプされます。サイズ列を合計してデータの合計サイズを確認できます。</block>
  <block id="92f6d6878e37105d20e75151b95d4e6a" category="doc">SMB / CIFS 共有からの CSV ファイルの作成</block>
  <block id="bab825782f37e3f0cd908b20bc8aa74c" category="inline-link-macro">Previous ：日付ベースの特定のスキャンとデータのコピー。</block>
  <block id="ad80673543d1d2744f55966060c4579b" category="paragraph"><block ref="ad80673543d1d2744f55966060c4579b" category="inline-link-macro-rx"></block></block>
  <block id="d122031c67144a65ca4721f8324ae0b3" category="paragraph">次に、 CSV 形式でデータをダンプするコマンドを示します。サイズ列を合計してデータの合計サイズを確認できます。</block>
  <block id="1bed902c0754e4abc7598b7f1a0450e0" category="paragraph">次のような出力が表示されます。</block>
  <block id="f7c322db5a6c805aed8a38858c7ba770" category="paragraph">3 つのサブディレクトリの深さまでスキャンし ' ソート順を指定するには 'XCP -du' コマンドを実行して ' 各ディレクトリ・レベルで 3 つのサブディレクトリの深さまでサイズをダンプします</block>
  <block id="7c12bd6fa64456eb3a61460a4bbb98e6" category="paragraph">ソートするには、情報を CSV ファイルにダンプして情報をソートします。</block>
  <block id="c2e9a8d6d376247b10a1ab4624bd2610" category="inline-link-macro">次のステップ： 7-Mode から ONTAP へのデータ移行</block>
  <block id="7155e60f207d105fa4db5d15efdce133" category="paragraph"><block ref="7155e60f207d105fa4db5d15efdce133" category="inline-link-macro-rx"></block></block>
  <block id="2246a929033f1d77a86efa97dda42849" category="inline-link-macro">前の手順：トラブルシューティング。</block>
  <block id="49c4600bab96ae4bda03f252b43985b4" category="paragraph"><block ref="49c4600bab96ae4bda03f252b43985b4" category="inline-link-macro-rx"></block></block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">このドキュメントに記載されている情報の詳細については、以下のドキュメントや Web サイトを参照してください。</block>
  <block id="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link"><block ref="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link-rx"></block></block>
  <block id="eba010943793fb5b647ad292a452b3ff" category="list-text">NetApp XCP ブログ<block ref="2639c38af267ba997fc1d85740cfc9a6" category="inline-link-rx"></block></block>
  <block id="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link"><block ref="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link-rx"></block></block>
  <block id="fb8d9f206204f9562c2a67c6b37a7d1b" category="list-text">NetApp XCP ユーザガイド<block ref="05f41a166d52148335e3a0df2eafec23" category="inline-link-rx"></block></block>
  <block id="e2c2bd378a3ae3740034d637754af7e2" category="inline-link"><block ref="e2c2bd378a3ae3740034d637754af7e2" category="inline-link-rx"></block></block>
  <block id="79b44e54a5eac82beac2de86249cd862" category="list-text">ビッグデータ分析から人工知能へ– Data Mover 解決策 for AI<block ref="79ced727b5c9638c0385a25671803fba" category="inline-link-rx"></block></block>
  <block id="9ebf058ce7a44ad4517e7033db8a90a7" category="paragraph"><block ref="9ebf058ce7a44ad4517e7033db8a90a7" category="inline-link-macro-rx"></block></block>
  <block id="0706a8a70e2892183b45c55ef1394714" category="summary">このセクションでは、 NFS 用にファイルサイズ 100 万個のファイルを使用して XCP コピー処理と XCP 同期処理を実行するおおよその時間を記載します。</block>
  <block id="137e4d3e0bc5586af6fc7ca9441511e1" category="doc">サイジングガイドライン</block>
  <block id="f688414f56f567909ca9a570f161016e" category="inline-link-macro">前の手順：導入手順</block>
  <block id="fb58e731328976afe8beac53cbe55ee7" category="paragraph"><block ref="fb58e731328976afe8beac53cbe55ee7" category="inline-link-macro-rx"></block></block>
  <block id="5224a4cb1d59edb5630ae27e640409e9" category="section-title">テストに基づく推定所要時間</block>
  <block id="1112334374c9149cc8ad8e80a76f2e56" category="paragraph">次の図に、 XCP コピー処理の結果を示します。</block>
  <block id="d6852faef2642951731c8d64e3009dbe" category="paragraph"><block ref="d6852faef2642951731c8d64e3009dbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58fe8c2d511caf443cb23313cb89181b" category="paragraph">次の図に、 XCP Sync の名前変更処理とリンク処理の結果を示します。</block>
  <block id="319b9e8dee4108359b7ef17af2fb492d" category="paragraph"><block ref="319b9e8dee4108359b7ef17af2fb492d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2186640ac8cac7be2b0f3940d871bf04" category="paragraph">ファイルのサイズは ' 名前を変更したソースファイルを転送するための XCP 同期完了時間とは一致しませんグラフは線形です</block>
  <block id="de54b82b6e27abb7d6f924e14d40a351" category="paragraph">リンクタイプは、ソフトリンク、ハードリンク、およびマルチリンクです。ソフトリンクは通常のファイルと見なされます。ファイルのサイズは、 XCP 同期処理を完了する時点とは関係ありません。</block>
  <block id="db3eb29ec347d79a716c6235063b1955" category="paragraph">次の図は、 XCP の同期アペンドおよび削除処理の結果を示しています。</block>
  <block id="feeff6134484088b1b404089dc5f92d9" category="paragraph"><block ref="feeff6134484088b1b404089dc5f92d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64c7d081568c95905b16364c19e1be1" category="paragraph">追加処理と削除処理では、小さなファイルサイズに比べて大きなファイルサイズの方が時間がかかります。処理の完了時間は、追加および削除の変更率と線形で表示されます。</block>
  <block id="ecc8d4faf16ec3b08a8badd1d71421d3" category="section-title">XCP 1.6.1 と XCP 1.5 を比較しています</block>
  <block id="ded6c17dda87ca50a7ecde2418543075" category="paragraph"><block ref="ded6c17dda87ca50a7ecde2418543075" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09a0804a78587affdd9192afd0f8c80c" category="paragraph">次の図は、 XCP 1.6.1 での XCP 同期パフォーマンスの結果と 1.5 の結果を示しています（ファイル数は 16K となります）。</block>
  <block id="b2733f54373c0149b19c3b37afbcb7da" category="paragraph"><block ref="b2733f54373c0149b19c3b37afbcb7da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7770abf0d9a0789407ea0a0e81cc5a6" category="paragraph"><block ref="e7770abf0d9a0789407ea0a0e81cc5a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71c6a3c1c59fc41b371a18011d1d5c9b" category="paragraph">XCP 1.7 のパフォーマンスは、平均して XCP 1.6.3 と同様で、「 XCP sync 」差分アップデートでは名前変更、追加、リンク、削除の各操作を 100 万ファイルの 1MB サイズで実行できます。</block>
  <block id="dd6275237d7504aabd0c206384365206" category="inline-link-macro">次の手順：パフォーマンスの調整。</block>
  <block id="cb619c90f7b537d24a1473acda746a47" category="paragraph"><block ref="cb619c90f7b537d24a1473acda746a47" category="inline-link-macro-rx"></block></block>
  <block id="a01ed8ff3f6e9e3ac0c0068a083281f2" category="summary">このセクションでは、 NetApp XCP を使用したデータ移行のトラブルシューティングについて説明します。</block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">トラブルシューティング</block>
  <block id="ae638a1049211e9956348a48a85bd359" category="inline-link-macro">Previous ：ベストプラクティスのガイドラインと推奨事項</block>
  <block id="e19cdddb31b62a88048cfee77eb96e9d" category="paragraph"><block ref="e19cdddb31b62a88048cfee77eb96e9d" category="inline-link-macro-rx"></block></block>
  <block id="95109c432d89e67182659615993ba75d" category="section-title">エラー 1 ： XCP Failed が NFS3 エラーで失敗しました。 70 ： stale filehandle Error in the xcp.log</block>
  <block id="99b1b0e3547443c29793187326a64dbc" category="paragraph">* 理由とガイダンス。 *</block>
  <block id="0774d3e8b775fcc34e680b302e85f3c1" category="paragraph">ソースフォルダをマウントし、フォルダが存在することを確認します。存在しない場合、または削除された場合は、「テールファイルハンドル」エラーが表示されます。この場合、エラーは無視してかまいません。</block>
  <block id="8fefb715a66a069c9e9318a58ecfdaee" category="section-title">エラー 2 ： NetApp NFS Destination Volume has Space 、 but XCP Failed with NFS3 error 28 ： no space left on device</block>
  <block id="bba52daa861e8093e201c3939f43057f" category="list-text">「 d f 」コマンドを実行するか、ストレージをチェックして、 NFS デスティネーション・ボリュームのスペースを確認します。</block>
  <block id="20183145becc54cc822a80107f92f13d" category="list-text">ストレージコントローラ内の inode を確認します。</block>
  <block id="fe3a96130e3ec3092026a84e4dd12e50" category="list-text">inode が使用されている場合は、次のコマンドを実行して inode の数を増やします。</block>
  <block id="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="paragraph"><block ref="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="inline-link-macro-rx"></block></block>
  <block id="3d5c39f585b0e679dbfe0855d556f0af" category="summary">NetApp XCP は、複数のスレッドとカスタマイズ可能な機能を使用してデータを転送します。データの移動や移行、ファイルシステム分析、ディレクトリツリーの高速削除という 3 つの主なユースケースに対応しています。</block>
  <block id="6416bf9c9c9445fbe2e15f69fa8371d2" category="paragraph">NetApp XCP は、複数のスレッドとカスタマイズ可能な機能を使用してデータを転送します。データの移動や移行、ファイルシステム分析、ディレクトリツリーの高速削除という 3 つの主なユースケースに対応しています。</block>
  <block id="7817bd783e8db0557909483f54288eae" category="section-title">データの移動または移行</block>
  <block id="a7786f240f16aadfd675c46be438f64e" category="paragraph">NetApp XCP は、任意の NAS から NetApp NAS にデータを転送します。このプロセスは、スキャン、コピー、同期、検証の 4 つの主要な処理で構成されます。データの監視と転送に役立つ追加の機能がいくつかあります。</block>
  <block id="59e4194e1b171063beeb99722a68e7af" category="list-text">* Copy. * はベースラインデータ転送を実行します。</block>
  <block id="a75ddee1308f2f19e478595122434544" category="list-text">* Sync. * は増分データ転送を実行します。</block>
  <block id="ae4ab572ec7de44b385c01df54f00d17" category="list-text">* 検証。 * ターゲットの完全な検証を実行します。</block>
  <block id="8ddbaa98ade9dcd56d4960b7abd22525" category="list-text">* Show （オプション）。 * NAS 共有を検出します。</block>
  <block id="4f4544fb0f8ed8f32e27a8b8651a46e6" category="paragraph">次の図は、 XCP データの移行とレプリケーションの処理を示しています。</block>
  <block id="6d97d3e510fc0fba449ece8ddd3f3d10" category="paragraph"><block ref="6d97d3e510fc0fba449ece8ddd3f3d10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="657bad21acd4ceb926477ced53a4ec55" category="section-title">ファイルシステム分析</block>
  <block id="65424b0dc0515cfa3b67e71712012db0" category="paragraph">NetApp XCP を使用すると、構造化されていないデータを標準で識別、精査、分析し、分析情報を向上させることができます。分析情報は、計画を改善し、価値の高いデジタル資産の運用を開始し、レポートと評価を通じてデータガバナンスを実現するために、企業のお客様に欠かせない重要な要件です。</block>
  <block id="03c5a03e8b03794f5fa193e72245496c" category="paragraph">機密データを扱うお客様は、 NetApp XCP を使用して、次のような回答の一般的な運用上の質問にお答えください。</block>
  <block id="6ad28c778baa08cff585599e160c12c8" category="list-text">データはどこにありますか？</block>
  <block id="5eccfafcfad0fb3dcd5f4f1036fed9f9" category="list-text">データの量とファイルの種類</block>
  <block id="b1c54971a6211d7b7e3d074bff16b4c9" category="list-text">どのようなデータがアクティブに使用され、休止状態になっているか？</block>
  <block id="81ff19b428c80049b09f8e1e6e55cfde" category="paragraph"><block ref="81ff19b428c80049b09f8e1e6e55cfde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a6c498fb90ee345d997f888fce3b18" category="section-title">削除</block>
  <block id="4125c56415a1c3b98b49ee7f8c2ebfc3" category="paragraph">ストレージ・チームや Electronic Design Automation （ EDA ）のワークロードでは、古いデータであっても、ストレージ・スペースを回復するためにクリーニングが必要なテスト・データであっても、大きなディレクトリをクリーンアップするのは非常に困難です。XCP は、ディレクトリツリー全体を削除できる高速削除機能を提供します。NetApp XCP Delete 機能は、特定の NAS パスからファイルとフォルダを削除します。一致フィルタを使用すると、特定のファイルおよびフォルダセットを削除できます。多数のファイルやフォルダに対しては、削除の確認を必要としない強制オプションを使用できます。</block>
  <block id="ecfd5328aaeaeb8ab72037598049a32c" category="section-title">ライブソース移行のサポート</block>
  <block id="286a0f56c729672b0709605c558d0008" category="paragraph">この機能では、ソースの変更はサポートされますが、デスティネーションに対する変更はサポートされません。移行中は、移行先をアクティブにしないでください。ライブソースマイグレーションは、 NFS マイグレーションでのみサポートされます。</block>
  <block id="2c346a482fcf83bd03d1d51f65d58b8d" category="admonition">ライブソース移行では、特別な設定は必要ありません。</block>
  <block id="ba41152bc4991a294ab26fbe691d52e3" category="section-title">XCP の前提条件</block>
  <block id="010e3e2a3d44100784dac368cdb601c0" category="paragraph">NetApp XCP を導入する前に、次の前提条件を満たしている必要があります。</block>
  <block id="b76760dcfae800f7180ec4e8c57a8e2f" category="list-text">次のコマンドを実行して、 NFS サーバで使用されている NFS ポートを確認します。</block>
  <block id="a9a9fca38da059af5a55e2fc58ef3851" category="list-text">オンプレミスインスタンスまたはクラウドインスタンス（ Azure 、 AWS 、 Google Virtual Machine [VM] インスタンスなど）の XCP 処理を実行する場所にアクセスするには、 NFS ポートのファイアウォールポートを開きます。</block>
  <block id="b22a57ce186f512ec584f5aac1d3de34" category="list-text">telnet コマンド '&lt; オンプレミスの NFS データ LIF IP または NAS ip&gt;2049 を使用して 'XCP サーバから NFS ポートにアクセスできることを確認しますデフォルトのポートは 2049. です。環境内のポートが異なる場合は、その IP を使用します。</block>
  <block id="e54a7adb3b7e28ed3d693d972fc48fd0" category="list-text">NFS の場合は、「 howmount -e &lt;NAS ip&gt;` コマンドを使用して、 XCP サーバから共有にアクセスできることを確認します。</block>
  <block id="da7f6a983e12f3b14b965ea651990ca9" category="list-text">デスティネーションボリュームの inode の数を、ソースファイルのファイル数（ファイル数）よりも多くします。</block>
  <block id="71858e85f290ec0f6955841bab9f3aef" category="inline-link">NetApp XCP ライセンスポータル</block>
  <block id="14324adbfb79ad4b6832f6a02a1275db" category="list-text">から XCP ライセンスをダウンロードします<block ref="eab886d42d2df7a710066e6d9bf6f5f5" category="inline-link-rx"></block>。</block>
  <block id="7481213bd7173438d06de418474e428b" category="list-text">mysupport.netapp.com にネットアップアカウントがあるか、または無償で登録できます。</block>
  <block id="d25e9f08475ddf6a2701e7cfbd67ff06" category="list-text">ライセンスをダウンロードしてご用意ください。</block>
  <block id="3d19c697861d11cce0f1d78d41cfea64" category="list-text">NAS ボリュームを作成し、データデスティネーションの共有を設定します。</block>
  <block id="4f2a304b9680876edc7cb61b5c4c7134" category="list-text">複数の XCP インスタンスがある場合、複数のソースフォルダまたはファイルからデスティネーションにデータを転送するには、サーバまたはクラウドインスタンスが 1 つ以上必要です。</block>
  <block id="adc4e34febc2f5919cfa03870630c2fc" category="list-text">maxdir サイズ（デフォルトは 308MB ）では、最大ファイル数（約 100 万）が 1 つのフォルダに定義されます。maxdir サイズ値を大きくして、ファイル数を増やします。値を増やすと、 CPU サイクルが増える。</block>
  <block id="a1552408599f6e2171495d55ae375802" category="list-text">クラウドでは、オンプレミスとクラウド間で ExpressRoute （ Azure ）、 Direct Connect （ AWS ）、または Cloud Interconnect （ GCP ）を使用することを推奨します。</block>
  <block id="fb41b0ab70237465636fc4267d1c00dd" category="inline-link-macro">次の手順：移行ワークフロー</block>
  <block id="7ed4381f9a10813d06ebeaf5c947c2c1" category="summary">NetApp XCP ファイル分析 GUI は、バックエンドで XCP を使用してファイルシステムスキャンを実行し、 NAS （ NFS 、 SMB ）ファイルシステムのグラフやビューなどの統計情報を表示するのに役立ちます。</block>
  <block id="250a5d043009990eb69a399d7c630462" category="doc">ファイル分析</block>
  <block id="47461303c8b8cbeb3e7558e2a9a1ca70" category="inline-link-macro">前のページ：移行ワークフロー</block>
  <block id="685a7e894721315c196897b76f95b8ce" category="paragraph"><block ref="685a7e894721315c196897b76f95b8ce" category="inline-link-macro-rx"></block></block>
  <block id="0f2604fbc18e6e91ba050460e6557361" category="paragraph">NetApp XCP ファイル分析 GUI は、バックエンドで XCP を使用してファイルシステムスキャンを実行し、 NAS （ NFS 、 SMB ）ファイルシステムのグラフやビューなどの統計情報を表示するのに役立ちます。1.6 以降では、構成オプションと systemctl オプションを使用して、簡単な導入手順で XCP をサービスとして実行できます。XCP Configure オプションでは、 Postgres と Web サーバのインストールと設定、およびクレデンシャルの収集が指示されます。systemctl オプションは、 GUI から REST API 通信のサービスとして XCP を実行します。</block>
  <block id="914cb171c700c273306e8265b56f4973" category="paragraph">次の図に、 XCP ファイルの分析フローを示します。</block>
  <block id="538e51b99e800ab65e133b5d57b2dc7f" category="paragraph"><block ref="538e51b99e800ab65e133b5d57b2dc7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bcdbf2b32a87f7efd13f706d43954d5" category="inline-link">NetApp XCP 1.6 が、オープンファイル分析とインフラストラクチャの向上を実現します</block>
  <block id="168c81694a3b19988d829a9baeda23fd" category="list-text">「 XCP scan 」と「 -match 」フィルタを使用して、消費されたスペースを使用して、 1 年を超えて変更されたファイルのリストを生成します。</block>
  <block id="de615506a73ca5960be54d36ba7fcd5b" category="list-text">1 年以上前のファイルで使用されているスペースを探します。</block>
  <block id="d2d1f03d5f19a1229103a85cc9224a61" category="list-text">1 年以上前に変更されたデータの合計サイズとグラフ表示を確認します。</block>
  <block id="d706f3d28ee3e74f9a6829c882169af8" category="paragraph">次のレポートは、 1 年以上前に変更されたファイルのカスタムスキャン例です。</block>
  <block id="4d614048a495643d1c641a86e53b78d3" category="paragraph"><block ref="4d614048a495643d1c641a86e53b78d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54e4262e01c029cac8932a431c7e3d3f" category="paragraph"><block ref="54e4262e01c029cac8932a431c7e3d3f" category="inline-link-macro-rx"></block></block>
  <block id="035fe4f74f99e66d6525774bf40236f9" category="summary">ここでは、 NetApp XCP を使用してデータを移行する際のベストプラクティス、ガイドライン、推奨事項について説明します。</block>
  <block id="52f7ac44cac2d8d1a3f005648d7521e3" category="doc">ベストプラクティスのガイドラインと推奨事項</block>
  <block id="b5a13e4f32bf69c6814808ff6a11eb9b" category="inline-link-macro">前のバージョン： ACL を使用した、ソースストレージボックスから ONTAP への CIFS データの移行。</block>
  <block id="a930ea4d6e07241178b9fe2f3c054fd2" category="paragraph"><block ref="a930ea4d6e07241178b9fe2f3c054fd2" category="inline-link-macro-rx"></block></block>
  <block id="1cce79308861dd86d5e56af13afefaf2" category="list-text">IMT でサポートされている XCP クライアントオペレーティングシステムを使用します。サポートされている IMT クライアントは、ネットアップで認定されています。</block>
  <block id="ec653488c4b3b9bb00702a4fb937f5b4" category="list-text">Linux オペレーティングシステムで root ユーザとして XCP を実行し、移行を実行します。sudo ユーザとして XCP コマンドを実行できますが、 XCP ではサポートされていません。</block>
  <block id="8c8f6415908fe0a235f0850d80a398a4" category="list-text">クライアントごとに 1 つの XCP インスタンスのみを実行します。技術的には、同じホスト上で異なる場所から複数のインスタンスの XCP を実行できますが、これはサポートされていません。実際、多数のインスタンスを実行すると、障害が発生する可能性があります。</block>
  <block id="cac486281cae3e805e89a64673c47eb3" category="list-text">現在の XCP バージョンでは、 Live Source はサポートされていません。ソースのネットアップボリュームがアクティブで、アプリケーションやユーザによって継続的に変更されている場合は、ソースボリュームの Snapshot を作成して移行を実行する必要があります。</block>
  <block id="c1f9797ffa66b762cf07348c6bc4a005" category="list-text">新しい Snapshot は、増分同期ごとに別の名前を使用して作成することを推奨します。これにより、障害発生時に Snapshot 名に基づいて差分移行パスを簡単に作成できます。</block>
  <block id="1309895bb5c78406c77a6cc2800160eb" category="list-text">Snapshot ベースのマイグレーションを実行する場合は、カットオーバーまで Snapshot ベースのマイグレーションを続行することを推奨します。</block>
  <block id="cc9954d8dc3e80c40af9d0a7ca3de005" category="list-text">ファイル数が 1 、 000 万を超え、増分データの変更率が 50% を超える場合は、インストールおよび管理ガイドでの最小推奨値よりもコア数とメモリ容量を増やすことを推奨します。</block>
  <block id="f6cb936ed9c08627956daed52c6c3323" category="inline-link-macro">次の手順：トラブルシューティング。</block>
  <block id="58c815a6f6adf3657aa40f96cb5f2d08" category="paragraph"><block ref="58c815a6f6adf3657aa40f96cb5f2d08" category="inline-link-macro-rx"></block></block>
  <block id="7776aec966d5a0c71bd4e8230f9470b8" category="summary">このユースケースは、テレビネットワークの顧客に基づいています。お客様は、 Oracle Recovery Manager （ RMAN ）のバックアップファイルをクラウドに移行し、 Azure NetApp Files と Pacemaker ソフトウェアを使用して Oracle E-Business Suite （ EBS ）アプリケーションを実行したいと考えていました。また、データベースバックアップファイルをオンデマンドのクラウドストレージに移行して、大容量ファイル（それぞれ 25GB から 50GB まで）を Azure に転送することも検討していました。</block>
  <block id="8108bac490ceb375198c578e8a439026" category="doc">XCP Data Mover を使用して大容量ファイルを移行する</block>
  <block id="adec666d077f4afe1b4f2b8720ed1247" category="inline-link-macro">前のバージョン： XCP Data Mover を使用して、数百万の小規模ファイルを柔軟なストレージに移行しています。</block>
  <block id="d6be3aed77745a993a24266eaf05084d" category="paragraph"><block ref="d6be3aed77745a993a24266eaf05084d" category="inline-link-macro-rx"></block></block>
  <block id="06470d7a09a56d555bad98bdf38a6cad" category="paragraph">次の図は、オンプレミスから大容量ファイルの Azure NetApp Files へのデータ移行を示しています。</block>
  <block id="1b95efe3eae02043da6528de3cf9caf8" category="inline-link-macro">次の手順：ファイルを複製します。</block>
  <block id="76fdb34470826293aaf52b30bf98fce0" category="paragraph"><block ref="76fdb34470826293aaf52b30bf98fce0" category="inline-link-macro-rx"></block></block>
  <block id="ddf97b6ffb913bd772848e3ebecfc8c1" category="summary">このセクションでは、 NetApp XCP でのデータ転送の導入手順について説明します。</block>
  <block id="8388066510b59c8d3387373b6969a7af" category="doc">導入手順</block>
  <block id="c6310b144c1666a29ec7cacf1c0dceab" category="inline-link-macro">前のページ：ファイル分析</block>
  <block id="57c4917a0617c8b675e6cc1dbad5c7fe" category="paragraph"><block ref="57c4917a0617c8b675e6cc1dbad5c7fe" category="inline-link-macro-rx"></block></block>
  <block id="8449c94058b7c2e686c3e19f7e772a65" category="section-title">ベッドの詳細をテストします</block>
  <block id="94cb70bde9d89f0b10ffdca34b0bec22" category="paragraph">次の表に、この導入およびパフォーマンス検証に使用したテストベッドの詳細を示します。</block>
  <block id="57419d904381619fcf00bc94e4ce26f1" category="cell">XCP バージョン 1.7</block>
  <block id="0bf2dca8ce9b94406660e58b59a3dbbd" category="list-text">Linux サーバ × 1 - Linux （ RHEL 7.9 または RHEL 8 ）</block>
  <block id="d85d793ce9fe1772209fa5e17fb29449" category="list-text">Windows サーバ × 1 – Windows Server 2019 標準</block>
  <block id="91ea491db15b6d672d79b23fb98eb089" category="cell">ソースボリュームの NetApp AFF ストレージアレイ HA ペア</block>
  <block id="23ec9249d03285a513eaaf182a7bcd49" category="list-text">AFF8080</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">NFS プロトコル</block>
  <block id="80fdc6d88149270be735269f2ff65645" category="cell">デスティネーションボリューム用の NetApp AFF ストレージアレイ HA ペア</block>
  <block id="203165a49e3a391bdbc44e3a05d54279" category="list-text">ONTAP 9</block>
  <block id="28712ee052ea500eba0cdbb1d847277f" category="cell">Fujitsu PRIMERGY RX2540 サーバ</block>
  <block id="539c5af1c2682685cd076697aaa6c700" category="cell">各装置には、 *48 CPU * Intel Xeon * 256GB 物理メモリ * 10GbE デュアルポートが搭載されています</block>
  <block id="0cc5c79089d6ca0752529568758efc4c" category="cell">10GbE</block>
  <block id="2879e817640f94636340918850eb6903" category="inline-link">NetApp XCP ユーザガイド</block>
  <block id="f2dd54ec57ec5464ee3aa191a48a8a43" category="paragraph">データ転送用に NetApp XCP を導入するには、まず移行先で XCP ソフトウェアをインストールしてアクティブ化します。詳細については、を参照してください<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>。これには、次の手順を実行します。</block>
  <block id="c58c8903e33903d2e630277aa3a78795" category="inline-link">NetApp XCP （ダウンロード）ページ</block>
  <block id="2d1acef34bb45f2c1878c6b576f3b400" category="list-text">から XCP ソフトウェアをダウンロードします<block ref="13844fc5dba1627d28169d2acfff11e2" category="inline-link-rx"></block>。</block>
  <block id="8319752fe43598ddb329e536217c1cb5" category="list-text">ダウンロードした XCP tar ファイルを XCP サーバにコピーします。</block>
  <block id="c9b8e059d1597eaead43d286e91c91e3" category="list-text">tar ファイルを解凍します。</block>
  <block id="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link"><block ref="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link-rx"></block></block>
  <block id="19f1deecf23a78878eb01c772b9233e0" category="list-text">からライセンスをダウンロードします<block ref="4da39fde529d1b69f60873c302229eed" category="inline-link-rx"></block> XCP サーバにコピーします。</block>
  <block id="3df11515e644382207c1430c36ea48bb" category="list-text">ライセンスをアクティブ化します。</block>
  <block id="ad7984249c2054b4da5fd3b57b1b91ef" category="list-text">ソース NFS ポートとデスティネーション NFS サーバを特定します。デフォルトのポートは 2049. です。</block>
  <block id="79fe861b8c719b1a534bdbcace1444a2" category="list-text">NFS の接続を確認します。NFS サーバのポートに Telnet を使用して、（ソースとデスティネーションの両方について） NFS サーバを確認します。</block>
  <block id="5e471de79dbe02105770bcf04bc501d5" category="list-text">カタログを設定する。</block>
  <block id="67005679d502da10622f2104421e894b" category="list-text">NFS ボリュームを作成し、 XCP カタログ用の NFS をエクスポートする。また、 XCP カタログにオペレーティングシステムの NFS エクスポートを利用することもできます。</block>
  <block id="d6f2a18783592d1858e3e5bdcabd4567" category="list-text">NFS エクスポートを確認します。</block>
  <block id="39b638480b201a7448774e8186012e4e" category="list-text">xcp.ini` を更新します</block>
  <block id="9d44d1309af47903754b16c403f68774" category="list-text">XCP show を使用して ' ソース NAS エクスポートを検索します検索：</block>
  <block id="fbff9a42f0ba33571594cb39da93ef4b" category="list-text">（オプション）ソース NAS データをスキャンします。</block>
  <block id="82d1938e7390e37babdea8d6fd359156" category="paragraph">ソース NAS データをスキャンすることで、データレイアウトを把握し、移行の潜在的な問題を特定するのに役立ちます。XCP スキャン処理時間は、ファイル数とディレクトリ深度に比例します。NAS データに精通している場合は、この手順を省略できます。</block>
  <block id="c6e94e11da5ba5bce0f27b8c782e4110" category="list-text">'XCP scan' が作成したレポートを確認します主に読み取り不能フォルダと読み取り不能ファイルを検索します。</block>
  <block id="6a6a10773cfc849f638ac0137a5f08d6" category="list-text">（任意） inode を変更します。inode の数を確認し、カタログボリュームとデスティネーションボリュームの両方で移行またはコピーするファイルの数に基づいて変更する（必要な場合）。</block>
  <block id="342779baf0b15fdf377f142c987e896a" category="list-text">デスティネーションボリュームをスキャン</block>
  <block id="a88831977a2b62e982b722f6fa6662b5" category="list-text">ソースボリュームとデスティネーションボリュームのスペースを確認します。</block>
  <block id="4b14d92fd07932987cf7416eb7f604ca" category="list-text">「 XCP copy 」を使用してソースからデスティネーションにデータをコピーし、概要を確認します。</block>
  <block id="506aae448569ed08125f41ed940eb00b" category="admonition">デフォルトでは、データをコピーするための 7 つの並行プロセスが XCP によって作成されます。これは調整可能です。</block>
  <block id="5c46a2da3e6e0423829946fe877c50b8" category="admonition">ソースボリュームは読み取り専用にすることを推奨します。ソースボリュームは、リアルタイムでアクティブなライブファイルシステムです。NetApp XCP はアプリケーションによって継続的に変更されるライブソースをサポートしていないため、「 XCP copy 」操作が失敗することがあります。</block>
  <block id="0f7dbc07af0b5c3ba51ff604b81ebe8a" category="paragraph">Linux では、 XCP Linux がカタログ化を実行するため、 XCP にインデックス ID が必要です。</block>
  <block id="764363dd147880ab6aca242a0417562e" category="list-text">（オプション）デスティネーションネットアップボリュームの inode を確認します。</block>
  <block id="ab3ba5fb62db279b7d07bac650a6c2d2" category="list-text">'XCP sync' を使用して差分更新を実行します</block>
  <block id="6cdfbe571ba2209e0a76f3bcabfee9f6" category="paragraph">このドキュメントでは、リアルタイムをシミュレートするために、ソースデータの 100 万個のファイルの名前が変更され、更新されたファイルは「 XCP sync 」を使用してデスティネーションにコピーされました。Windows の場合、 XCP にはソースパスとデスティネーションパスの両方が必要です。</block>
  <block id="13475b4ca9a916769b9d63f4fddfa18d" category="list-text">データ転送を検証送信元と宛先が同じデータであることを検証するには、「 XCP verify 」を使用します。</block>
  <block id="1cd06f171a5a99926a67bd673014f765" category="paragraph">XCP のマニュアルには 'CAN'copy''sync' および 've rify' オペレーション用の複数のオプション（例を含む）が用意されています詳細については、を参照してください<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>。</block>
  <block id="efa146517859e051c07fabac4c88d3e7" category="admonition">Windows のお客様は、アクセス制御リスト（ ACL ）を使用してデータをコピーする必要があります。ネットアップでは、コマンド XCP copy-acl-fallbackuser\&lt;username&gt;-fallbackgroup\&lt;username または groupname&gt; &lt;source&gt;&lt;destination&gt;` を使用することを推奨しています。パフォーマンスを最大限に高めるために、 ACL を備えた SMB データと NFS と SMB の両方からアクセスできるデータが格納されたソースボリュームを検討する場合、ターゲットは NTFS ボリュームである必要があります。XCP （ NFS バージョン）を使用して、 Linux サーバからデータをコピーし、 Windows サーバからの「 -acl 」および「 -nodata 」オプションを使用して XCP （ SMB バージョン）同期を実行し、ソースデータからターゲット SMB データに ACL をコピーします。</block>
  <block id="85760de676a9f74f28f26115c39c9a0b" category="inline-link">「監査とセキュリティログ」ポリシーを設定しています</block>
  <block id="a0251b301ad566d86ffa3916c5510295" category="paragraph">詳細な手順については、を参照してください<block ref="06fdba77988da3047baf401e4fdefca5" category="inline-link-rx"></block>。</block>
  <block id="d2bac014bbd39f6954893239102c5678" category="inline-link-macro">次：サイジングガイドライン</block>
  <block id="b49cd7fb5a227da1698c527804f31bbb" category="paragraph"><block ref="b49cd7fb5a227da1698c527804f31bbb" category="inline-link-macro-rx"></block></block>
  <block id="24992328317a5b7b3c00507eb27776df" category="paragraph"><block ref="24992328317a5b7b3c00507eb27776df" category="inline-link-macro-rx"></block></block>
  <block id="d4f4c40bd169a262676284f5da7a191a" category="cell">2020年10月</block>
  <block id="945407c0c602d0c34ead1ebb5427a84b" category="summary">GPU がデータを処理できるように、 GPFS から NFS にデータを移行するために NetApp XCP を使用しました。AI は通常、ネットワークファイルシステムのデータを処理します。</block>
  <block id="1f797a3a419cdffd442fc4b662974908" category="doc">ONTAP NFS へのハイパフォーマンスコンピューティング</block>
  <block id="95160fc4cfa09139af600f92561c7ef9" category="inline-link-macro">前のバージョン： ONTAP NFS へのデータレイク。</block>
  <block id="9d82d327cabd66bd4cccb55cb5ed28ec" category="paragraph"><block ref="9d82d327cabd66bd4cccb55cb5ed28ec" category="inline-link-macro-rx"></block></block>
  <block id="a4a4d9553ba807d3f28f8f25ea56cfec" category="paragraph">このユースケースは、フィールド組織からのリクエストに基づいています。ネットアップのお客様の中には、トレーニングモデルのデータ分析を可能にするハイパフォーマンスコンピューティング環境にデータを配置しているお客様もいらっしゃいます。この環境では、研究組織が大量のデジタルデータを分析して理解することができます。ネットアップのフィールドエンジニアは、 IBM の GPFS から NFS にデータを抽出するために、詳細な手順を必要としています。GPU がデータを処理できるように、 GPFS から NFS にデータを移行するために NetApp XCP を使用しました。AI は通常、ネットワークファイルシステムのデータを処理します。</block>
  <block id="0ce008ed1a75e69e9f21d1ad29ed23dd" category="paragraph">ONTAP NFS へのハイパフォーマンスコンピューティングのユースケース、デモの記録、およびテスト結果の詳細については、を参照してください<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> ブログ</block>
  <block id="fb64727a5df67d0ceff6f0a11b531ab5" category="paragraph">NetApp XCP を使用して MapR FS データを ONTAP NFS に移動する手順の詳細については、の「付録 A ： GPFS から NFS への移行」を参照してください<block ref="e760c508aca9c545c45aba81e95e5593" category="inline-link-rx"></block>。</block>
  <block id="1b5c563b4edac6a7e8566fac62f90b34" category="inline-link-macro">次の手順： XCP Data Mover を使用して、数百万の小規模ファイルを柔軟なストレージに移行します。</block>
  <block id="0461d449643091f3bbb27cfbb215c6f2" category="paragraph"><block ref="0461d449643091f3bbb27cfbb215c6f2" category="inline-link-macro-rx"></block></block>
  <block id="1357196e1dc18c4ad43fe26a6c1b30ad" category="inline-link-macro">Previous ：パフォーマンスの調整。</block>
  <block id="33672b776ede62bd1269689ea61e45aa" category="paragraph"><block ref="33672b776ede62bd1269689ea61e45aa" category="inline-link-macro-rx"></block></block>
  <block id="1ebf7a1cb4f3826913a58c19018c694e" category="paragraph">このセクションでは、お客様のシナリオとそのアーキテクチャについて説明します。</block>
  <block id="b58464d62b5399c457b8a1fcf6bbcd27" category="inline-link-macro">次の例は、 ONTAP NFS へのデータレイクです。</block>
  <block id="a24139c6a89df9b0694c3ea695639ace" category="paragraph"><block ref="a24139c6a89df9b0694c3ea695639ace" category="inline-link-macro-rx"></block></block>
  <block id="322bc614a8031f8c334d233f8221a4ab" category="summary">このセクションでは、 NetApp Data ONTAP 7-Mode から ONTAP にデータを移行する手順について詳しく説明します。</block>
  <block id="30ee25b2188724428e827e97bab504fe" category="doc">7-Mode から ONTAP へのデータマイグレーション</block>
  <block id="aecfc9b89f609bfde217a6cf8fc0b00a" category="inline-link-macro">前の手順： SMB / CIFS 共有からの CSV ファイルの作成</block>
  <block id="6da13b2cdb445320dc3e29759119f4e8" category="paragraph"><block ref="6da13b2cdb445320dc3e29759119f4e8" category="inline-link-macro-rx"></block></block>
  <block id="3ec8186e1900b95154cccf8ccea38023" category="section-title">7-Mode の NFSv3 ストレージを ONTAP for NFS データに移行する</block>
  <block id="e70a6b3d23d1e0da94c71a9ea26747d1" category="paragraph">このセクション ONTAP では、次の表に示す、手順システムへのソースの 7-Mode NFSv3 エクスポートの移行の手順を説明します。</block>
  <block id="cad365d13740342c8f6199feb7229137" category="paragraph">ソースの 7-Mode NFSv3 ボリュームがクライアントシステムにエクスポートされてマウントされ、 XCP が Linux システムにすでにインストールされていることを前提としています。</block>
  <block id="b40dbfa52a308abff927380b983cd868" category="list-text">ターゲット ONTAP システムが正常であることを確認します。</block>
  <block id="39745ae9472f91abcd9e844389157858" category="list-text">ターゲットシステムにルートではないアグリゲートが少なくとも 1 つ存在することを確認します。アグリゲートは正常な状態です。</block>
  <block id="47e01226b4fdf549d938eb5c6196970d" category="paragraph">データアグリゲートがない場合は、「 storage aggr create 」コマンドを使用して新しいアグリゲートを作成します。</block>
  <block id="5c52d0e31e44663ee633be681387faa1" category="list-text">ターゲットクラスタシステムに Storage Virtual Machine （ SVM ）を作成します。</block>
  <block id="426b5839edbb7a7772be396e7eaceace" category="list-text">ターゲット SVM から FCP 、 iSCSI 、 NDMP 、 CIDS の各プロトコルを削除します。</block>
  <block id="d03930721e424cdac105ccd0172f7dbe" category="paragraph">この SVM で許可されているプロトコルが NFS であることを確認してください。</block>
  <block id="4d6b5eb9160c3c34e9ff5535c403cea9" category="list-text">デスティネーション SVM に読み書き可能な新しいデータボリュームを作成します。セキュリティ形式、言語設定、容量の要件がソースボリュームと同じであることを確認します。</block>
  <block id="a2cebf1e91b2a266a58458873c8980fd" category="list-text">データ LIF を作成して NFS クライアントの要求に対応します。</block>
  <block id="6817d90b89495074e679248b56128378" category="paragraph">LIF が正常に作成されたことを確認します。</block>
  <block id="3a014fae7f5d70cc01c593a8401140ee" category="list-text">必要に応じて、 SVM で静的ルートを作成します。</block>
  <block id="84bb87c2987a4b39ea23430f38570808" category="paragraph">ルートが正常に作成されたことを確認します。</block>
  <block id="54b19b8b3b6de7bce018de598a1645ea" category="list-text">ターゲットの NFS データボリュームを SVM ネームスペースにマウントします。</block>
  <block id="6365adb4324221d944bc90c4663dfe5a" category="paragraph">ボリュームが正常にマウントされたことを確認します。</block>
  <block id="991398c32a43bcf95d7fa14129a6fcb0" category="paragraph">volume create コマンドを使用して ' ボリューム・マウント・オプション（ジャンクション・パス）を指定することもできます</block>
  <block id="6c02d24a81dd4d9b1ad7a15079b4f122" category="list-text">ターゲット SVM で NFS サービスを開始します。</block>
  <block id="e210fe657c5d46e3e11ca263d1a18af7" category="paragraph">サービスが開始され、実行されていることを確認します。</block>
  <block id="304683b37151feda067e3acfde300057" category="list-text">デフォルトの NFS エクスポートポリシーがターゲット SVM に適用されていることを確認します。</block>
  <block id="353fde8a37910716dc00dec81475c0d5" category="list-text">必要に応じて、ターゲット SVM 用の新しいカスタムエクスポートポリシーを作成します。</block>
  <block id="174608facfdad6448222d6d46c87fba5" category="paragraph">新しいカスタムエクスポートポリシーが作成されたことを確認します。</block>
  <block id="4007cf260b496d35ba0e925f1e7a183d" category="list-text">NFS クライアントへのアクセスを許可するようにエクスポートポリシールールを変更します。</block>
  <block id="5f249df749512e129505d18fd47d7010" category="list-text">クライアントがボリュームへのアクセスを許可されていることを確認します。</block>
  <block id="94a80f56f92334f07fd30337692ca889" category="list-text">Linux NFS サーバに接続します。NFS エクスポートボリュームのマウントポイントを作成します。</block>
  <block id="725ae014e8d8f66f0f2d477fa656ba32" category="list-text">このマウントポイントに、ターゲットの NFSv3 エクスポートボリュームをマウントします。</block>
  <block id="a345b19bdd483ecd745a2e643b756bc6" category="admonition">NFSv3 ボリュームはエクスポートする必要がありますが、 NFS サーバでマウントする必要はありません。マウント可能な場合は、 XCP Linux ホストクライアントでこれらのボリュームをマウントします。</block>
  <block id="b5b2af7fb88c03cfd258cdd77fc6fbe1" category="paragraph">マウントポイントが正常に作成されたことを確認します。</block>
  <block id="8d3ac4d5ea9c5d5c45d7322512d7b778" category="list-text">NFS エクスポートマウントポイントにテストファイルを作成して、読み取り / 書き込みアクセスを有効にします。</block>
  <block id="07e483b5917b8a9e91a22b2ebc20961a" category="admonition">読み取り / 書き込みテストが完了したら、ターゲットの NFS マウントポイントからファイルを削除します。</block>
  <block id="09280cd628b820e696b87163b3fe0fde" category="list-text">XCP がインストールされている Linux クライアントシステムに接続します。XCP のインストールパスを参照します。</block>
  <block id="86de6eeea329a50737c7056637f43e49" category="list-text">XCP Linux クライアントホストシステムで「 XCP show 」コマンドを実行して、ソースの 7-Mode NFSv3 エクスポートを照会します。</block>
  <block id="080173849f5fec049b214897a2882295" category="list-text">ソースの NFSv3 エクスポートパスをスキャンし、ファイル構造の統計を出力します。</block>
  <block id="df86b239e412ba3ba7192b581381b444" category="paragraph">XCP では、ソースの NFSv3 エクスポートは「 can 」、「 copy 」、「 sync 」の各処理で読み取り専用モードにすることを推奨します。</block>
  <block id="695efe20ffcfc7c261e44cbb1b62cc78" category="list-text">ソースの 7-Mode NFSv3 エクスポートを、ターゲット ONTAP システムの NFSv3 エクスポートにコピーします。</block>
  <block id="50515e001679292835a498c6bd3f3c31" category="list-text">コピーが完了したら、ソースとデスティネーションの NFSv3 エクスポートに同一のデータがあることを確認します。「 XCP verify 」コマンドを実行します。</block>
  <block id="70d6a53ca7c3c592cb4099e2988c226c" category="paragraph">送信元データと宛先データの間に相違がある場合 'XCP verify' はサマリーにエラー NO such file or directory を報告しますこの問題を修正するには、「 XCP sync 」コマンドを実行して、ソースの変更を宛先にコピーします。</block>
  <block id="505d73172f49d62bd99779ab53aa5eeb" category="list-text">カットオーバーの前後に、もう一度「ライフル」を実行します。ソースに新規または更新されたデータがある場合は、差分更新を実行します。「 XCP sync 」コマンドを実行します。</block>
  <block id="887abb0b5917a0a6b0c47f5ef3eca1ce" category="list-text">以前に中断されたコピー操作を再開するには 'XCP RESUME コマンドを実行します</block>
  <block id="f807709818ec3fbc508863a00ea17044" category="paragraph">「ファイルのコピーが完了したら、「グリフィ」を再度実行して、ソースストレージとデスティネーションストレージのデータが同一になるようにします。</block>
  <block id="d78900410b9203071958256c3d6a7701" category="list-text">NFSv3 クライアントホストは、 7-Mode ストレージからプロビジョニングされたソースの NFSv3 エクスポートをアンマウントし、ターゲットの NFSv3 エクスポートを ONTAP からマウントする必要があります。カットオーバーには停止が必要です。</block>
  <block id="6bd42ffcfd349b793e9f6c6f00c18cd8" category="section-title">7-Mode ボリュームの Snapshot コピーを ONTAP に移行する</block>
  <block id="fefac3d628a2abc2d1677e073a0688e7" category="paragraph">このセクションでは、ソースの 7-Mode ボリュームの NetApp Snapshot コピーを ONTAP に移行する手順について説明します。</block>
  <block id="721e28a3edb434ca3d7f37307126504c" category="admonition">ソースの 7-Mode ボリュームがクライアントシステムにエクスポートされてマウントされ、 XCP が Linux システムにすでにインストールされていることを前提としています。Snapshot コピーはボリュームのポイントインタイムイメージであり、前回の Snapshot コピー作成後の差分変更を記録します。7-Mode システムをソースとして「 snap 」オプションを使用します。</block>
  <block id="e18566c8fe02de3e35e48df30daa5189" category="paragraph">* 警告： * ベースの Snapshot コピーを保持します。ベースラインコピーが完了したあとにベース Snapshot コピーを削除しないでください。以降の同期処理にはベースの Snapshot コピーが必要です。</block>
  <block id="50bdf0eaa7b3716343ae0345a98e1a5f" category="list-text">ターゲットクラスタシステムに SVM を作成します。</block>
  <block id="2e4b636c74015de6d92a2eb874c15a88" category="list-text">ターゲット SVM から FCP 、 iSCSI 、 NDMP 、および CIFS の各プロトコルを削除します。</block>
  <block id="c45e0bc468a9249c2954fa84c21f833e" category="list-text">必要に応じて、 SVM を使用して静的ルートを作成します。</block>
  <block id="f35ea333881cef53fcd944d5a052be9d" category="paragraph">ボリュームが正常にマウントされたことを確認します。</block>
  <block id="71c0d546c4569fd9a5798bdbc9729ab6" category="paragraph">volume create コマンドを使用して ' ボリューム・マウント・オプション（ジャンクション・パス）を指定することもできます</block>
  <block id="7ec3f8d8dd165416936305e1ca1530f0" category="list-text">デフォルトの NFS エクスポートポリシーがターゲット SVM に適用されていることを確認します。</block>
  <block id="f69801ea46df8aed1b26399a9330f459" category="list-text">エクスポートポリシールールを変更して、ターゲットシステム上の NFS クライアントへのアクセスを許可します。</block>
  <block id="9fee35c8bded36b1931a6addb7635a81" category="list-text">クライアントがターゲットボリュームにアクセスできることを確認します。</block>
  <block id="7633c6765c7399ce0f1ecbca891fb11c" category="paragraph">ソースの NFSv3 エクスポートは、 XCP スキャン、「 copy 」、および「 sync 」処理の間に読み取り専用モードにすることを推奨します。'sync' 操作では '-snap' オプションに対応する値を渡す必要があります</block>
  <block id="486e9eb5a73ed3d87e070761d3ceeefe" category="list-text">ソースの 7-Mode NFSv3 Snapshot （ベース）をターゲット ONTAP システムの NFSv3 エクスポートにコピーします。</block>
  <block id="160bb3a75d27ad175143123df09bce76" category="admonition">このベース Snapshot は今後の同期処理用に保持します。</block>
  <block id="97ba1a5f7ee8f9243390e46469b6e8f3" category="list-text">コピーが完了したら、ソースとデスティネーションの NFSv3 エクスポートに同一のデータがあることを確認します。「 XCP verify 」コマンドを実行します。</block>
  <block id="44842ca325a3ba46b3b4703a79fab171" category="paragraph">「 ve rify 」でソース・データとデスティネーション・データの違いが検出された場合、「 No such file or directory 」というエラーが要約に報告されます。この問題を修正するには、「 XCP sync 」コマンドを実行して、ソースの変更を宛先にコピーします。</block>
  <block id="030bc6fe403e876e1c932987ece73d61" category="list-text">カットオーバーの前後に、もう一度「ライフル」を実行します。ソースに新規または更新されたデータがある場合は、差分更新を実行します。増分変更がある場合は、これらの変更の新しい Snapshot コピーを作成し、そのスナップショットパスを sync 操作のための「 -snap' 」オプションで渡します。</block>
  <block id="b29cfae254be5e3cfc339ed594ea9378" category="paragraph">--snap オプションとスナップショット・パスを指定して 'XCP sync コマンドを実行します</block>
  <block id="2885d0e1370007423656773743ce189b" category="admonition">この処理にはベース Snapshot が必要です。</block>
  <block id="121dba07a28112a093b812991271c895" category="list-text">NFSv3 クライアントホストは、 7-Mode ストレージからプロビジョニングされたソースの NFSv3 エクスポートをアンマウントし、ターゲットの NFSv3 エクスポートを ONTAP からマウントする必要があります。このカットオーバーには停止が必要です。</block>
  <block id="6db55966f4a2b44c31ed7672f14d023e" category="section-title">ACLv4 を NetApp 7-Mode からネットアップストレージシステムに移行する</block>
  <block id="8f81754856c547fbd3e5295b9da06cc7" category="paragraph">このセクションでは、ソースの NFSv4 エクスポートを ONTAP システムに移行するためのステップバイステップの手順について説明します。</block>
  <block id="fd58e84bd534e0ff49a00942e9ee2002" category="admonition">ソースの NFSv4 ボリュームがクライアントシステムにエクスポートされてマウントされ、 XCP が Linux システムにすでにインストールされていることを前提としています。ソースは、 ACL をサポートする NetApp 7-Mode システムである必要があります。ACL の移行はネットアップからネットアップへのみサポートされます。名前に特殊文字を含むファイルをコピーするには、ソースとデスティネーションが UTF-8 エンコード言語をサポートしていることを確認します。</block>
  <block id="88464fae780b488ca9d39f305a3b3777" category="section-title">ソースの NFSv4 エクスポートを ONTAP に移行するための前提条件</block>
  <block id="078b760bc7ad8cae447a095cc53029af" category="paragraph">ソースの NFSv4 エクスポートを ONTAP に移行する前に、次の前提条件を満たしている必要があります。</block>
  <block id="abb629da0d811e197b383d473d19f265" category="list-text">デスティネーションシステムで NFSv4 を設定しておく必要があります。</block>
  <block id="09e4d7a665b5df121af76a08951028cf" category="list-text">NFSv4 のソースとターゲットが XCP ホストにマウントされている必要があります。NFS v4.0 を選択してソースストレージとターゲットストレージを照合し、ソースシステムとターゲットシステムで ACL が有効になっていることを確認します。</block>
  <block id="c36e1764174e8e6a7791e7afd73f3294" category="list-text">XCP は、 ACL 処理のために、 XCP ホストにソース / ターゲットパスをマウントする必要があります。次の例では、「 vol1 (10.63.5.56:/vol1) 」が「 /mnt/vol1 」パスにマウントされています。</block>
  <block id="baa4716341f52ff4d0642ca1398e16f1" category="section-title">サブディレクトリオプション</block>
  <block id="66f63b7de79aaf05b47a1b63467b2a84" category="paragraph">サブディレクトリを操作するには、次の 2 つのオプションがあります。</block>
  <block id="5d1498ef6a2ee01cb9031bbf8a8dadc4" category="list-text">サブディレクトリ（ /vol1/dir1/DIR11` ）で XCP を動作させるには、 XCP ホストに完全なパス（「 10.63.5.56 ： /vol1/dir1/DIR11` ）をマウントします。</block>
  <block id="39b3225d42725e9616ca3fee7aa7cbb6" category="paragraph">完全なパスがマウントされていない場合、 XCP で次のエラーが報告されます。</block>
  <block id="84274fa575b6d9b0177512a818215d91" category="list-text">次の例に示すように、サブディレクトリ構文 (`m ount: subdirectory/qtree/.snapshot ') を使用します。</block>
  <block id="8dd9bb3f47ac0b27a42761c265b0c720" category="paragraph">ACL v4 を NetApp 7-Mode からネットアップストレージシステムに移行するには、次の手順を実行します。</block>
  <block id="b2f12804e995a318c2272527efb05774" category="paragraph">SVM が正常に作成されたことを確認します。</block>
  <block id="b887d08ec971525ffbfec7f19d01d72d" category="list-text">デフォルトの NFS エクスポートポリシーがターゲット SVM に適用されていることを確認します。</block>
  <block id="1c94e1638450716cd57f55bafd07e60f" category="paragraph">ポリシールールが変更されたことを確認します。</block>
  <block id="132fa7c123291d5007311a22ff8f5654" category="list-text">ターゲットの NFSv4 エクスポートボリュームをこのマウントポイントにマウントします。</block>
  <block id="c686c09824f51c6e681d87d1deb44c71" category="admonition">NFSv4 ボリュームはエクスポートする必要がありますが、 NFS サーバでマウントする必要はありません。マウント可能な場合は、 XCP Linux ホストクライアントでこれらのボリュームをマウントします。</block>
  <block id="e943b6ad310412b689f42adec28acf3a" category="paragraph">ファイルが作成されたことを確認します。</block>
  <block id="35ce5d99ee6b9bb871da972e459e7259" category="list-text">XCP Linux クライアント・ホスト・システムで XCP show コマンドを実行して、ソース NFSv4 エクスポートを照会します。</block>
  <block id="97cc35dcdaf8c5c5fa0e936cd31e9907" category="list-text">ソースの NFSv4 エクスポートパスをスキャンし、ファイル構造の統計を出力します。</block>
  <block id="5073080976611febfcee79295d42232e" category="paragraph">ネットアップでは、「 XCP scan 」、「 copy 」、および「 sync 」の処理中に、ソースの NFSv4 エクスポートを読み取り専用モードにすることを推奨しています。</block>
  <block id="f120bcab91519def54b7b66ee0fbecfe" category="list-text">ソースの NFSv4 エクスポートをターゲット ONTAP システムの NFSv4 エクスポートにコピーします。</block>
  <block id="39ff9cab7c62e62bf182a632271eb700" category="list-text">「 copy 」が完了したら、ソースおよびデスティネーションの NFSv4 エクスポートに同一のデータがあることを確認します。「 XCP verify 」コマンドを実行します。</block>
  <block id="977c8a5f0f7f70041a1c6359c72cb1cd" category="paragraph">「 ve rify 」でソース・データとデスティネーション・データの違いが検出された場合、「 No such file or directory 」というエラーが要約に報告されます。この問題を修正するには、「 XCP sync 」コマンドを実行して、ソースの変更を宛先にコピーします。</block>
  <block id="29aee025cf0bcad3c355bd0aad4516e6" category="admonition">この処理を実行するには、前のコピーインデックス名またはインデックス番号が必要です。</block>
  <block id="ee0fd4f8758695ad7502bee81363478a" category="list-text">以前に中断された「 copy 」操作を再開するには、「 XCP resume 」コマンドを実行します。</block>
  <block id="cdc35fb8de987dae3f48c142ffcb0686" category="section-title">7-Mode の SMB ストレージを ONTAP for CIFS データに移行する</block>
  <block id="74efc43b80fa7a84f709780789176e0d" category="paragraph">このセクションでは、ソースの 7-Mode SMB 共有を ONTAP システムに移行するためのステップバイステップの手順について説明します。</block>
  <block id="f6f758220d5d00061aaa03b99e14785b" category="admonition">7-Mode システムと ONTAP システムに SMB のライセンスが設定されていることを前提としています。デスティネーション SVM が作成され、ソースとデスティネーションの SMB 共有がエクスポートされます。 XCP がインストールされてライセンスが付与されます。</block>
  <block id="281c766457d5499048f9440f61957421" category="list-text">ファイルとディレクトリを含む SMB 共有をスキャンします。</block>
  <block id="95c490ed8cb5d13c961fc2c50c372940" category="list-text">ソースからデスティネーション SMB 共有にファイル（ ACL の有無に関係なく）をコピーします。次に、 ACL を含むコピーの例を示します。</block>
  <block id="dc056263ce0a29568cee559ae8ec35dc" category="admonition">データ・アグリゲートが存在しない場合は 'storage 'aggr create ' コマンドを使用して新しいアグリゲートを作成します</block>
  <block id="7c34f7c35c71ba790649c5563408e77e" category="list-text">ソースとデスティネーションのファイルを同期します。</block>
  <block id="974c1ef10ec8fef5b3ff19989555d061" category="list-text">ファイルが正しくコピーされたことを確認します。</block>
  <block id="8ae319b52e88ea41e78a01efdaab2143" category="inline-link-macro">次の例： ACL を使用した、ソースストレージボックスから ONTAP への CIFS データの移行</block>
  <block id="b6ea874ca7f1192a99c58fa3ff1199ba" category="paragraph"><block ref="b6ea874ca7f1192a99c58fa3ff1199ba" category="inline-link-macro-rx"></block></block>
  <block id="5dc302565fd7f552e134618ee18d2be2" category="summary">この解決策は、特定の日付に基づいてデータをコピーする必要があるお客様を対象としています。</block>
  <block id="07f04efd2f421076b9aa06c4fee83be5" category="doc">データの特定の日付ベースのスキャンおよびコピー</block>
  <block id="7af90e46070dd59c121e31e1525d4af2" category="inline-link-macro">前へ：ファイルを複製します。</block>
  <block id="7f58802ce1d6245244bb449cd961f0f3" category="paragraph"><block ref="7f58802ce1d6245244bb449cd961f0f3" category="inline-link-macro-rx"></block></block>
  <block id="e0b5216bc931e3e5fd7efb74ad10b1d3" category="paragraph">この解決策は、特定の日付に基づいてデータをコピーする必要があるお客様を対象としています。次の情報を確認します。</block>
  <block id="c277b447e2e86b92f26c7dbcf8fecdf2" category="inline-link-macro">次の手順： SMB / CIFS 共有からの CSV ファイルの作成</block>
  <block id="7a9653d25343b8ddab24257e57b5be7a" category="paragraph"><block ref="7a9653d25343b8ddab24257e57b5be7a" category="inline-link-macro-rx"></block></block>
  <block id="89bddd14a9f02aeace6d5ffadf25e4f3" category="summary">このドキュメントでは、 NetApp XCP のベストプラクティスのガイドラインとテストシナリオベースの解決策について説明します。これらのベストプラクティスは、オンプレミス向けの移行ワークフローと、クラウド、ファイルシステム分析、トラブルシューティング、および XCP のパフォーマンス調整を対象としています。</block>
  <block id="e7b1326bcbbf0b5513213b2373b5721a" category="doc">TR-4863 ：『 Best Practice Guidelines for NetApp XCP - Data Mover 、 File Migration 、 and Analytics 』</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">ネットアップ Karthikeyan Nagalingam</block>
  <block id="88d20f11fbf1788b5271fcc5d5297a41" category="paragraph">このドキュメントでは、 NetApp XCP のベストプラクティスのガイドラインとテストシナリオベースの解決策について説明します。これらのベストプラクティスは、オンプレミスの移行ワークフローと、クラウド、ファイルシステム分析、トラブルシューティング、および XCP のパフォーマンス調整を対象としています。テストシナリオのセクションでは、お客様のユースケースとその要件、 XCP を使用した NetApp 解決策、およびお客様へのメリットについて説明します。</block>
  <block id="842b5068483a5cd5b058644a5d000f1c" category="inline-link-macro">次： NetApp XCP 。</block>
  <block id="10dbc4bbbec11552354dca73bcd59c78" category="paragraph"><block ref="10dbc4bbbec11552354dca73bcd59c78" category="inline-link-macro-rx"></block></block>
  <block id="7e0710b4cb48030b7a4c065128b88194" category="summary">このセクションでは、セキュリティ情報を含む CIFS データをソース ONTAP システムからターゲット CIFS システムに移行するためのステップバイステップ形式の手順について説明します。</block>
  <block id="82f0875c37eacadc40a7a7fb2a6b6313" category="doc">ACL を使用した、ソースストレージボックスから ONTAP への CIFS データの移行</block>
  <block id="0f17f55a868185c28a66d0817a780f53" category="inline-link-macro">Previous ： 7-Mode から ONTAP へのデータマイグレーションを示します。</block>
  <block id="99b2c0d3f328317650f8748e47c7bedb" category="paragraph"><block ref="99b2c0d3f328317650f8748e47c7bedb" category="inline-link-macro-rx"></block></block>
  <block id="c55bb6c3381ca2d8a4016e387cc62883" category="list-text">SMB クライアント要求を処理するデータ LIF を作成します。</block>
  <block id="5368b7f480b92b4a2a9b475e6e9cf953" category="list-text">ターゲットのデータボリュームを SVM ネームスペースにマウントします。</block>
  <block id="18f8848c17d02fd34b293885d5d3a215" category="list-text">ターゲット SVM で CIFS サービスを開始します。</block>
  <block id="cf1269d629dc2110f2ae65edf8662b79" category="list-text">デフォルトのエクスポートポリシーがターゲット SVM に適用されていることを確認します。</block>
  <block id="74e1ca9e0b551a7349207f3d546b9f51" category="list-text">CIFS クライアントへのアクセスを許可するようにエクスポートポリシールールを変更します。</block>
  <block id="3c19a2ac394a25f9ace05db18ad86c8b" category="paragraph">ポリシールールが変更されたことを確認します。</block>
  <block id="876afc73f4771f46cfc9dba7fb687744" category="list-text">XCP がインストールされている Windows クライアントシステムに接続します。XCP のインストールパスを参照します。</block>
  <block id="e73a44af938fa16a4816d3639d2f3b69" category="list-text">XCP Windows クライアント・ホスト・システムで XCP show コマンドを実行して、ソース・ノードの SMB エクスポートを照会します。</block>
  <block id="7132ef955ec5e0151ccd0790da2551d7" category="list-text">コピーのために 'help' コマンドを実行します</block>
  <block id="268b71a144890a49d97f8ca062fd48f9" category="list-text">ターゲット ONTAP システムで、「 fallback-user 」および「 fallback-group 」引数パスの値として指定する必要があるローカルユーザおよびローカルグループ名のリストを取得します。</block>
  <block id="ac9ad1198db0fb6f730a1f3aa97c35ab" category="list-text">ACL を持つ CIFS データをソースからターゲットに移行するには 'acl' および– fallback-user/group' オプションを指定して 'XCP copy' コマンドを実行します</block>
  <block id="a53e836d6264ad1778a4e1a7ae34f58c" category="paragraph">「 fallback-user/group 」オプションには、 Active Directory またはローカルユーザ / グループ内のターゲットシステムに存在する任意のユーザまたはグループを指定します。</block>
  <block id="9aa080e55cad2c9968cc50de60a3f88e" category="list-text">「 XCP copy 」で「 error failed to obfallback security principal 」 ( フォールバックセキュリティプリンシパルの取得に失敗しました ) というエラーメッセージが表示された場合は、 hosts ファイルに宛先ボックスを追加します (C:\Windows\System32\drivers\etc\hosts) 。</block>
  <block id="b7ceaa0e08e9de5bf76572a50529f752" category="paragraph">ネットアップストレージのデスティネーションボックスのエントリには、次の形式を使用します。</block>
  <block id="569ccf25ad533b79cf2f639f0326d943" category="list-text">hosts ファイルに destination box エントリを追加した後にエラーメッセージ「 error failed to get fallback security principal 」が表示される場合は、ターゲットシステムにユーザ / グループが存在しません。</block>
  <block id="4a909d1b3a171fdcddc8da070e839ecc" category="list-text">ACL を持つ CIFS データを移行するには 'XCP copy' を使用します（ルート・フォルダを使用するかどうかは関係ありません）</block>
  <block id="a4ebb620bc1fbff4f93249967cd47f4b" category="paragraph">ルートフォルダを使用せずに、次のコマンドを実行します。</block>
  <block id="f6c1a65a9150853333bf43b4a6dc9e5b" category="paragraph">ルートフォルダを使用して、次のコマンドを実行します。</block>
  <block id="154ef40d43f003733406aef6be0ada62" category="inline-link-macro">次のステップ：ベストプラクティスのガイドラインと推奨事項</block>
  <block id="7fd167e59284838d9e36c5c99e4d2943" category="paragraph"><block ref="7fd167e59284838d9e36c5c99e4d2943" category="inline-link-macro-rx"></block></block>
  <block id="dc0b758a04bbb9e380300887d831e4e1" category="summary">ここでは、 XCP 処理のパフォーマンス向上に役立つチューニングパラメータをいくつか紹介します。</block>
  <block id="9db3ca538820d0cfb7b44ef80f16ca98" category="doc">パフォーマンスの調整</block>
  <block id="7931b9aae255139b42cb605b3b62a6db" category="inline-link-macro">前のバージョン：サイジングのガイドライン</block>
  <block id="0ff4824165c6661bc016402e35d2a9fe" category="paragraph"><block ref="0ff4824165c6661bc016402e35d2a9fe" category="inline-link-macro-rx"></block></block>
  <block id="ec6136417c258c9b7f95c39765c5ca51" category="paragraph">このセクションでは、 XCP 処理のパフォーマンスを向上させるために役立つチューニングパラメータをいくつか説明します。</block>
  <block id="dd10b781bf6dd686a8631401ce0fba96" category="list-text">拡張性を高め、ワークロードを複数の XCP インスタンスに分散させるには、移行とデータ転送用に各 XCP インスタンスのサブフォルダを分割します。</block>
  <block id="37e9b10f81fe31cb6b80609f724b34f8" category="list-text">XCP では最大 CPU リソースを使用できます。 CPU コア数が多いほど、パフォーマンスが向上します。そのため、 XCP サーバに追加の CPU が必要です。テストでは 128GB の RAM と 48 個のコア CPU を使用し、 8 倍の CPU と 8 GB の RAM に比べてパフォーマンスが向上しました。</block>
  <block id="a174d00dcd4849e0653429de84c71cde" category="list-text">Azure NetApp Files の場合、パフォーマンスはサービスレベルによって異なります。詳細については、次の表を参照してください。この表には、 Azure NetApp Files のサービスレベルとパフォーマンスの詳細が表示されます。</block>
  <block id="6d59be48f566a73e053e12167b279be5" category="cell">サービスレベル</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">標準</block>
  <block id="8d5e7e72f12067991186cdf3cb7d5d9d" category="cell">Premium サービス</block>
  <block id="7057376a419b3334cc7b8b7a9f064abb" category="cell">ウルトラ</block>
  <block id="0b85467ebafa7ca3c47e82dc38184484" category="cell">スループット</block>
  <block id="adcda45ec4de9aeb48e1893272b078d1" category="cell">1 テラバイトあたり 16mbps</block>
  <block id="93209d2e9d1ed8d87a279cef886b5021" category="cell">TB あたり 64MBps</block>
  <block id="f646efbbd60d091e92b32611965c4f1c" category="cell">TB あたり 128MBps</block>
  <block id="4a9cc851fc41c5762618832386fa4937" category="cell">ワークロードのタイプ</block>
  <block id="11969136028e1ffaeed70de5e59bde33" category="cell">汎用ファイル共有、 E メール、 Web</block>
  <block id="76ab8c335a6bb24396ea1953bac75705" category="cell">BMS 、データベース、およびアプリケーション</block>
  <block id="9dab8e594b90062c0612cbb1676234ba" category="cell">レイテンシの影響を受けやすいアプリケーション</block>
  <block id="0a568304277380e4cfb0f2d2abbd99b4" category="cell">パフォーマンスの説明</block>
  <block id="c55268b956eecd1d58f60723a410c808" category="cell">標準パフォーマンス： 1TB あたり 1 、 000 IOPS （ 16K I/O ）と TB あたり 16mbps</block>
  <block id="536d2154a9035458ae8efd38b24f3ea7" category="cell">優れたパフォーマンス– TB あたり 4 、 000 IOPS （ 16 、 000 I/O ）、 TB あたり 64MBps</block>
  <block id="91ff77656b0dc231fcbe8f488a15a253" category="cell">卓越したパフォーマンス： TB あたり 8 、 000 IOPS （ 16 、 000 I/O ）、 128MBps / TB</block>
  <block id="121bc30e927e8a3d918fc90c0ec18fee" category="paragraph">スループットとワークロードのタイプに基づいて適切なサービスレベルを選択する必要があります。ほとんどのお客様は Premium レベルから始めて、ワークロードに基づいてサービスレベルを変更します。</block>
  <block id="f44706d8f59ec82b48b083fb246a4fc7" category="inline-link-macro">次のステップ：お客様のシナリオ</block>
  <block id="bb0eaaf9fa62e9175efd3145f00946ea" category="paragraph"><block ref="bb0eaaf9fa62e9175efd3145f00946ea" category="inline-link-macro-rx"></block></block>
  <block id="4b1c76979225b75a8e5f476356ed17e8" category="paragraph">ネットアップで VMware を利用するには：まずはここから</block>
  <block id="d7b056332bb039010d62c71ede534471" category="paragraph">VMware 環境の変革を開始する準備ができたら、最新の解決策の概要をご覧ください。また、最新のテクニカルソリューションと製品デモもご覧いただけます。次のステップに進む準備が整ったら、ネットアップや VMware のエキスパートコミュニティと連携して、データセンターの最新化、ハイブリッドクラウド、コンテナ化されたアプリケーションへの取り組みの計画と実行を支援します。</block>
  <block id="be52ccc9c4dbcee449a6257062c0bcda" category="paragraph">どこから始めるべきかわからない場合は、 <block ref="dcd7ec98fb935d9a5fd8ade723a47456" category="inline-link-macro-rx"></block> ネットアップの VMware エキスパートのメンバーです。</block>
  <block id="27b7a196b8196df4eeee9d21ade20a45" category="inline-link-macro">PDF 形式</block>
  <block id="e2fd99d21fbe7a1b2ed6388c40d48b0f" category="admonition">このページに表示されるコンテンツは、からもダウンロードできます <block ref="a182addaadbc8a97de909268c8dc9bf0" category="inline-link-macro-rx"></block>。</block>
  <block id="9d0be07780aeb437025d4b3420d12540" category="sidebar">NetApp XCP データ移行</block>
  <block id="68dfe5056c735db544868f482f9f1d6f" category="sidebar">NetApp XCP のベストプラクティスガイドライン</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="sidebar">お客様のシナリオ</block>
  <block id="c5071cdf8081474104ef1eee5ec6d784" category="sidebar">ACL を使用した、ソースストレージボックスから ONTAP への CIFS データの移行</block>
  <block id="211c181ce8e8cb0472af3095c66dc5eb" category="paragraph"><block ref="211c181ce8e8cb0472af3095c66dc5eb" category="inline-link-macro-rx"></block></block>
  <block id="7480aca6b5f94dc27cc94b015284d5e9" category="paragraph"><block ref="7480aca6b5f94dc27cc94b015284d5e9" category="inline-link-macro-rx"></block></block>
  <block id="6be5bc354916244292cf704d8a451541" category="inline-link-macro">ビデオ： Workload Migration Using Astra Control Center - Red Hat OpenShift with NetApp</block>
  <block id="b0fd8947f538fb2988e86d35bac6d6fa" category="list-text"><block ref="b0fd8947f538fb2988e86d35bac6d6fa" category="inline-link-macro-rx"></block></block>
  <block id="c0a8420c339dd9d57d40448c30a749df" category="inline-link-macro">ビデオ： Workload Migration Using Astra Trident and SnapMirror - Red Hat OpenShift with NetApp</block>
  <block id="a43d8fe0429e313d082e6919f1fd2b75" category="list-text"><block ref="a43d8fe0429e313d082e6919f1fd2b75" category="inline-link-macro-rx"></block></block>
  <block id="344aeea955e7674b99b8e8db2354133d" category="doc">Astra Control Center を使用したワークロードの移行：ネットアップを使用した Red Hat OpenShift</block>
  <block id="7527b11aa1f9aa169a9d6103e9c4c417" category="paragraph">Azure NetApp Files 、 Rapids 、 Dask は、 Docker や Kubernetes などのオーケストレーションツールと統合することで、大規模な ML 処理とトレーニングの導入を高速化し、簡易化します。エンドツーエンドのデータパイプラインを統合する解決策ことで、多くの高度なコンピューティングワークロードに特有のレイテンシと複雑さを軽減し、開発と運用のギャップを効果的に解消します。データサイエンティストは、大規模なデータセットでクエリを実行し、トレーニングフェーズ中にデータやアルゴリズムのモデルを他のユーザーと安全に共有できます。</block>
  <block id="a93fc9ba708498e20819f22e22ecfa5c" category="paragraph">クラウドにエンドツーエンドの分散トレーニングモデルとデータパイプラインを構築することで、 GPU によって高速化されたデータ処理フレームワークやコンピューティングフレームワークを活用していない従来のオープンソースアプローチと比較して、ワークフロー全体の完了時間が 2 桁向上することを実証しました。</block>
  <block id="fcceee9f9e65e4b0d089c6c433f6c191" category="paragraph">ネットアップ、 Microsoft 、オープンソースのオーケストレーションフレームワーク、 NVIDIA を組み合わせることで、最新テクノロジをマネージドサービスとして統合し、優れた柔軟性を実現してテクノロジの採用を促進し、新しい AI / ML アプリケーションの市場投入期間を短縮できます。これらの高度なサービスはクラウドネイティブ環境で提供され、オンプレミス環境やハイブリッド導入アーキテクチャで簡単に移行できます。</block>
  <block id="b622f3d3bde9c5202a2be0c23982e0b2" category="paragraph">このユースケースは、一般に公開されているに基づいています<block ref="f00b4c49198828625540594bcd2c0e57" category="inline-link-rx"></block> データセットの作成元<block ref="3ba217c046bd683ab55f300076736b4a" category="inline-link-rx"></block>。ML プラットフォームとアプリケーションの最近の進歩により、現在は大規模な学習が注目されています。クリックスルー率（ CTR ）は、オンライン広告インプレッション数 100 件あたりの平均クリックスルー数（パーセンテージ）と定義されています。デジタルマーケティング、小売、 E コマース、サービスプロバイダなど、さまざまな業界やユースケースで重要な指標として広く採用されています。CTR を潜在的な顧客トラフィックの重要な指標として使用する例を以下に示します。</block>
  <block id="d86cf69a8b82547a94ca3f6a307cf9a6" category="inline-link">Google アナリティクス</block>
  <block id="fe123d76ac9bec74ba2056b6a34fbf5d" category="inline-link">広告ランク</block>
  <block id="747d705222dc64c89cfadd75a9792b30" category="list-text">* デジタルマーケティング :* インチ<block ref="6c9e2e85af2f8f35c64de5000ebda91e" category="inline-link-rx"></block>、 CTR は、広告主または販売主のキーワード、広告、および無料リストがどの程度効果を発揮しているかを測定するために使用できます。クリック率が高いと、ユーザーは広告やリストを便利で関連性の高いものとして見つけることができます。CTR はまたあなたのキーワードの予想される CTR に貢献する、の構成要素である<block ref="428c3403a03510f9dc338448b285e764" category="inline-link-rx"></block>。</block>
  <block id="8a2e97f5a0cefdd4b76863bdd3773fb2" category="list-text">* e- コマース： * 活用に加えて<block ref="8785133d6074d4ab5f5345c36bc35a21" category="inline-link-rx"></block>E コマースバックエンドには、少なくともいくつかの訪問者統計情報があります。これらの統計情報は一目見すると有用ではないように見えますが、通常は読みやすく、他の情報よりも正確な情報になる可能性があります。このような統計で構成されるファーストパーティデータセットは独占的なものであり、 E コマースの販売者、購買担当者、プラットフォームに最も関連性があります。これらのデータセットは、ベンチマークの設定に使用でき、過去 1 年と過去 1 日の間に結果を比較するために、さらに詳細な分析を行うための時系列を作成します。</block>
  <block id="5737cd832bf93fd33459cf0a04787441" category="list-text">* 小売： * 実店舗の小売業者は、訪問者数と顧客数を CTR に関連付けることができます。お客様の数は、販売時点の履歴から確認できます。小売業者のウェブサイトや広告トラフィックの CTR が、前述の売上につながる可能性があります。ロイヤルティプログラムは、オンライン広告や他の Web サイトからリダイレクトされたお客様が報奨を獲得するために参加する可能性があるため、別のユースケースです。小売業者は、ロイヤルティプログラムを通じて顧客を獲得し、販売履歴から行動を記録することで、さまざまなカテゴリーで消費者の購買行動を予測するだけでなく、クーポンをパーソナライズし、チャーンを減らす推奨システムを構築できます。</block>
  <block id="32c14bcab423a033bf540425e236d3e6" category="list-text">* 通信事業者とインターネット・サービス・プロバイダーは、豊富なデータを提供するファーストパーティのユーザー・テレメトリ・データを使用して、洞察に富んだ AI 、 ML 、分析のユースケースを実現しています。たとえば、携帯電話会社の Web 閲覧のトップレベルのドメイン履歴ログを毎日活用して、既存のモデルを微調整して最新のオーディエンスセグメンテーションを作成したり、顧客の行動を予測したり、リアルタイム広告を配置してオンライン体験を向上させることができます。このようなデータ主導のマーケティングワークフローでは、 CTR はコンバージョンを反映する重要な指標です。</block>
  <block id="78ae79f63f58a3ac75e77e3a075fd19e" category="inline-link">Crito Terabyte のログをクリックします</block>
  <block id="deb698cbe7918324e2e1564708266732" category="paragraph">デジタルマーケティングの文脈では、<block ref="cc065865c19a3af4babfdf02c1c6b55d" category="inline-link-rx"></block> 現在は、 ML プラットフォームとアルゴリズムのスケーラビリティを評価する際の参考データセットとなっています。広告主は、クリックスルーレートを予測することで、広告に対応する可能性が最も高い訪問者を選択し、閲覧履歴を分析し、ユーザーの関心に基づいて最も関連性の高い広告を表示できます。</block>
  <block id="5f326be91a09bc93ca87444e834df2a6" category="paragraph">このテクニカルレポートで紹介する解決策には、次のようなメリットがあります。</block>
  <block id="e150c8d445e71cda899957943e39b75f" category="list-text">分散型トレーニング用 Dask 並列コンピューティングフレームワーク</block>
  <block id="ec61531814ab09c5338813eecc764692" category="paragraph">Rapids AI と Azure NetApp Files をベースに構築されたエンドツーエンドのワークフローでは、ランダムフォレストモデルのトレーニング時間が 2 桁単位で大幅に短縮されたことが示されています。この点は、構造化された表形式データが 45 GB （平均）の実世界のクリックログを毎日処理する場合の従来の Pandas アプローチと比べて大幅に改善されています。これは、約 20 億行を含む DataFrame に相当します。このテクニカルレポートでは、クラスタ環境のセットアップ、フレームワークとライブラリのインストール、データのロードと処理、従来型のトレーニングと分散型のトレーニング、可視化と監視について説明し、重要なエンドツーエンドのランタイム結果を比較します。</block>
  <block id="0359d40b3d1a900a1841f1e8bd783cd5" category="doc">TR-4904 ：『 Distributed Training in Azure - Click Through Rate Prediction 』</block>
  <block id="1863627f5be51826024a24014fce26ff" category="sidebar">Azure での分散トレーニング - クリックスルー率予測</block>
  <block id="458df51beb3b33cfa61bdc8725403f5b" category="sidebar">Jupyter ノートブック ( リファレンス用 )</block>
  <block id="8d7efa937e97b1a8187ff8f122d9732a" category="sidebar">クラウドベースの VMware 環境向けにストレージを最適化</block>
  <block id="5a6bd3a9e0048284caf2b5f521d90959" category="list-text"><block ref="5a6bd3a9e0048284caf2b5f521d90959" category="inline-link-macro-rx"></block></block>
  <block id="2625fb6375d503af481868caf90606c9" category="summary">このセクションでは、本テクニカルレポートに関連する 2 つの Jupyter ノートブックへのリンクを示します。</block>
  <block id="91409fc3ebd20becb4eb816cbcceb02e" category="doc">Jupyter ノートブックを参考にしてください</block>
  <block id="cdd5560e07964d04d88721f16446a3b6" category="paragraph">このテクニカルレポートには、 Jupyter ノートブックが 2 つ関連付けられています。</block>
  <block id="1490d9a5ddbc6bcbe6cedaa01eb50f99" category="inline-link-macro">*CTR - PandasRF - 照合済み。 ipynb. *</block>
  <block id="562c7333f0fea5590cfeb818a55e6557" category="list-text"><block ref="6f686a9606ae64621340ea0a5e72dfde" category="inline-link-macro-rx"></block> このノートブックは Crito Terabyte Logs データセットから 15 日目を読み込み、データを Pandas DataFrame に処理してフォーマットし、 Scikit-learn ランダムフォレストモデルのトレーニングを行い、予測を実行し、精度を計算します。</block>
  <block id="c0cb1f1199ae4e4bdfa626e26a5a25cd" category="inline-link-macro">* Crito_dAsk _RF.ipynb.*</block>
  <block id="fa93cb17bf7778768ccae778487bf90d" category="list-text"><block ref="01d86d8522c2722466fcbda71181d3ff" category="inline-link-macro-rx"></block> このノートブックは Crito Terabyte Logs データセットから 15 日目をロードし、データを Dask cuDF に処理してフォーマットし、 Dask cuML ランダムフォレストモデルのトレーニングを行い、予測を実行し、精度を計算します。GPU を搭載した複数のワーカーノードを活用することで、この分散データとモデルの処理とトレーニングのアプローチを非常に効率的に行うことができます。処理するデータが多いほど、従来の ML アプローチに比べて時間を大幅に節約できます。このノートブックは、ネットワークセットアップによってデータやモデルの配布が自由に移動できる限り、クラウド、オンプレミス、または Kubernetes クラスタにコンピューティングとストレージが異なる場所に配置されているハイブリッド環境に導入できます。</block>
  <block id="95e5ff389c2796a171f904ad5b9322f6" category="list-text">ネットアップと VMware Cloud Foundation （ VCF ）</block>
  <block id="81cd1d42ffdb75544144e24cf0f8dc54" category="inline-link-macro">パート 1 ：はじめに</block>
  <block id="837bbffc16dc6e344470df1114a13c87" category="list-text"><block ref="837bbffc16dc6e344470df1114a13c87" category="inline-link-macro-rx"></block></block>
  <block id="0437c596200f9be8466a3200f5cf2438" category="inline-link-macro">パート 2 ： VCF および ONTAP プリンシパルストレージ</block>
  <block id="e361fc9a6477c5857207bca25b3d797f" category="list-text"><block ref="e361fc9a6477c5857207bca25b3d797f" category="inline-link-macro-rx"></block></block>
  <block id="14c9e898417d6b3caceb9c60335c4bb3" category="inline-link-macro">パート 3 ： VCF およびエレメントプリンシパルストレージ</block>
  <block id="aa37de763ea804c1fb3fe637fb6ee5ef" category="list-text"><block ref="aa37de763ea804c1fb3fe637fb6ee5ef" category="inline-link-macro-rx"></block></block>
  <block id="fbbcbe8b70235742e3e6aa656c7815d9" category="inline-link-macro">パート 4 ： VMware 用の ONTAP ツールと追加ストレージ</block>
  <block id="de8f12d6d2f85119918d1bbb774d43c8" category="list-text"><block ref="de8f12d6d2f85119918d1bbb774d43c8" category="inline-link-macro-rx"></block></block>
  <block id="00d07ce14f227693b9dabba2f52b53a5" category="inline-link-macro">ネットアップベースのクラウドサービスで Azure VMware 解決策を使い始めましょう</block>
  <block id="ac66988ead29ba5f4ed32ec3894527e7" category="list-text"><block ref="ac66988ead29ba5f4ed32ec3894527e7" category="inline-link-macro-rx"></block></block>
  <block id="3123a26626e19f387157faf3a8e35e86" category="list-text">Red Hat OpenShift クラスタにクラスタ管理者アクセス権限が必要です。</block>
  <block id="abfe00e88b26a267771078e0295b1573" category="admonition">Docker をインストールする場合は、 20.10 よりも前のバージョンの Docker 、 Podman をインストールする場合は、バージョン 3.0 よりも前の podman が必要です。</block>
  <block id="e2f745ac603721ed9903b0acea00d059" category="admonition">「 kubeadmin 」ユーザを使用してプライベートレジストリにログインしている場合は、「 podman login -u OCP -user -p token --tls-verify=false astra-registry.apps.ocp-vmw.cie.netapp.com` 」の代わりにトークンを使用します。</block>
  <block id="e4b91f5b748fa6ef8813d2871257b134" category="admonition">または、サービスアカウントのトークンを使用して、サービスアカウントを作成し、（プッシュアクセスまたはプルアクセスが必要かどうかに応じて）レジストリエディタまたはレジストリビューアロールを割り当て、レジストリにログインすることもできます。</block>
  <block id="ad533c54cadd80fbf8f60e58b7d3abd6" category="admonition">「 kubeadmin 」ユーザを使用してプライベートレジストリにログインする場合は、「 password - `d Occker login -u OCP-user-p token astra-registry.apps.ocp-vmw.cie.netapp.com` 」の代わりにトークンを使用します。</block>
  <block id="4324c8f0a70a221bdde33868774e5a76" category="list-text">Astra Control Center Operator CR 'Astra_control_center_deployment.yaml ' を編集します Astra Control Center は ' すべてのリソースを配備しますオペレータ CR で 'acc-operator-controller-managor' の配備定義を検索し ' イメージをレジストリにプッシュする際に指定した組織名とともに ' レジストリの FQDN を入力します ( この例では astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra` ) テキスト 'Astra_image_registry' を置き換えて 'imagePullSecret' セクションで作成したシークレットの名前を指定しますオペレータのその他の詳細を確認し、保存して閉じます。</block>
  <block id="0f436b7e192eae471d7abf1265bb4c02" category="list-text">Astra Control Center GUI に、 FQDN を参照してログインします。</block>
  <block id="8b2aacc194c3dc4c36ce93a57e31685c" category="list-text">現在のデフォルトストレージクラスからデフォルトのアノテーションを削除し、 OpenShift クラスタの Trident バック対象ストレージクラスをデフォルトとしてアノテートします。</block>
  <block id="53557215e4d209eda16495dbe5f7c505" category="paragraph">+ 注 : 「 kubeadmin 」ユーザを使用してプライベートレジストリにログインする場合は、パスワードの代わりにトークンを使用します。</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">このセクションでは、この AI 解決策の技術基盤について説明します。</block>
  <block id="42b507999e258502c07acce91c03de9f" category="paragraph"><block ref="42b507999e258502c07acce91c03de9f" category="inline-link-macro-rx"></block></block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">最先端の NetApp AFF ストレージシステムにより、 AI 推論をエッジで導入することで、業界をリードするパフォーマンス、卓越した柔軟性、クラウド統合、業界最高クラスのデータ管理機能を備えたエンタープライズストレージの要件を満たすことができます。ネットアップの AFF システムはフラッシュに特化して設計されており、ビジネスクリティカルなデータの高速化、管理、保護に役立ちます。</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">エントリレベルの NetApp AFF ストレージシステムは、 FAS2750 のハードウェアと SSD フラッシュメディアに基づいています</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">HA 構成の場合は 2 台のコントローラ</block>
  <block id="7df12cd193e8452ed6fc45ca8bcd3771" category="paragraph"><block ref="7df12cd193e8452ed6fc45ca8bcd3771" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">ネットアップのエントリレベルの AFF C190 ストレージシステムは、次の機能をサポートしています。</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">960GB SSD を最大で 24 本搭載できます</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">次の 2 つの構成が可能です</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">イーサネット（ 10GbE ）： 10GBASE-T （ RJ-45 ）ポート × 4</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">ユニファイド（ 16Gb FC または 10GbE ）：ユニファイドターゲットアダプタ 2 （ UTA2 ）ポート × 4</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">最大 50.5TB の実効容量</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">NAS ワークロードの場合、エントリレベルの AFF C190 システム 1 台で、シーケンシャルリードの場合は 4.4GBps 、スモールランダムリードの場合は 230K IOPS が 1 ミリ秒以下のレイテンシでサポートされます。</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">ネットアップは、他のエントリレベルストレージシステムも提供しています。このシステムは、大規模な環境にも対応できる優れたパフォーマンスと拡張性を提供します。NAS ワークロードの場合、 1 つのエントリレベルの AFF A220 システムで次のことがサポートされます。</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">シーケンシャルリードのスループットは 6.2GBps です</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">1 ミリ秒以下のレイテンシでスモールランダムリードの IOPS 値 375K</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">960GB 、 3.8TB 、 7.6TB の SSD の最大ドライブ数： 144x</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220 は、 1PB を超える実効容量にまで拡張できます</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">最大実効容量は 35PB で、最大スケールアウト構成は 2~24 ノード（ HA ペア × 12 ）</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">AFF A220 と比較して、パフォーマンスが 45% 以上向上します</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440 万 IOPS のランダムリード： 1 ミリ秒</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">最新のネットアップ ONTAP リリース ONTAP 9.8 を基盤としています</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">HA とクラスタインターコネクトに 25GB のイーサネットを利用しています</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">NetApp E シリーズ EF システム</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">EF シリーズは、エントリレベルとミッドレンジのオールフラッシュ SAN ストレージアレイファミリーです。データへのアクセスを高速化し、 NetApp SANtricity ソフトウェアを使用してデータから迅速に価値を引き出すことができます。SAS と NVMe の両方のフラッシュストレージを搭載し、低コストで卓越した IOPS 、 100 マイクロ秒未満の応答時間、最大 44GBps の帯域幅を実現します。これらのシステムは、混在ワークロードや、 AI 推論やハイパフォーマンスコンピューティング（ HPC ）などの要件の厳しいアプリケーションに最適です。</block>
  <block id="51ffc2dfd09bb521be00106f197d1009" category="paragraph"><block ref="51ffc2dfd09bb521be00106f197d1009" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">32Gb / 16Gb FC 、 25Gb / 10Gb iSCSI 、 12Gb SAS に対応しています</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">最大実効容量は 96 本のドライブで合計 1.5PB です</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">10Gbps のスループット（シーケンシャルリード）</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">30 万 IOPS （ランダムリード）</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">NetApp EF280 は、ネットアップポートフォリオの中で最も低コストのオールフラッシュアレイ（ AFA ）です</block>
  <block id="44114b1635cead15f56735bad0467251" category="section-title">NetApp EF300</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">合計容量 367TB の NVMe SSD を 24 本搭載</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">拡張オプションは合計で 240x NL-SAS HDD 、 96x SAS SSD 、またはその組み合わせです</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100Gb NVMe/IB 、 NVMe/RoCE 、 iSER/IB 、および SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32Gb NVMe/FC 、 FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">25Gb iSCSI です</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20GBps （シーケンシャルリード）</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670K IOPS （ランダムリード）</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">NetApp EF シリーズ NetApp EF シリーズオールフラッシュアレイ EF600 、 F300 、 EF570 、 EF280 のデータシート</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">詳細については、を参照してください<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block>。</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">データ管理を簡易化</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">データ管理は、アプリケーションやデータセットに適切なリソースを使用できるようにするために、エンタープライズ IT 運用にとって非常に重要です。ONTAP には、運用を合理化および簡易化し、総運用コストを削減するための次の機能が含まれています。</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">* インラインデータコンパクションと重複排除の強化。 * データコンパクションはストレージブロック内の無駄なスペースを削減し、重複排除は実効容量を大幅に増やします。この環境データはローカルに格納され、データはクラウドに階層化されます。</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">* 最小、最大、アダプティブの Quality of Service （ AQoS ）。 * きめ細かいサービス品質（ QoS ）管理機能により、高度に共有された環境で重要なアプリケーションのパフォーマンスレベルを維持できます。</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool 。 * この機能は、 Amazon Web Services （ AWS ）、 Azure 、 NetApp StorageGRID ストレージ解決策などのパブリックおよびプライベートクラウドストレージオプションへのコールドデータの自動階層化を提供します。FabricPool の詳細については、を参照してください <block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block>。</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">データの高速化と保護</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 は、卓越したパフォーマンスとデータ保護を実現し、以下の方法でこれらの機能を拡張します。</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">* パフォーマンスと低レイテンシ。 * ONTAP は、可能な限り低いレイテンシで最高のスループットを提供します。</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* NetApp Volume Encryption （ NVE ）。 * ONTAP は、オンボードと外部キー管理の両方をサポートし、ボリュームレベルでのネイティブな暗号化を実現します。</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">* マルチテナンシーと多要素認証。 * ONTAP により、インフラリソースを最高レベルのセキュリティで共有できます。</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">将来のニーズにも対応できるインフラ</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 には次の機能が搭載されており、要件が厳しく、絶えず変化するビジネスニーズに対応できます。</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">* シームレスな拡張とノンストップオペレーション。 * ONTAP は、既存のコントローラとスケールアウトクラスタに無停止で容量を追加できます。NVMe や 32Gb FC などの最新テクノロジへのアップグレードも、コストのかかるデータ移行やシステム停止を行わずに実行できます。</block>
  <block id="0cee26e8172666a9085f957269fc4b64" category="list-text">* クラウドへの接続。 * ONTAP は、すべてのパブリッククラウドで Software-Defined Storage （ ONTAP Select ）とクラウドネイティブインスタンス（ NetApp Cloud Volumes Service ）を選択できる、最もクラウドに接続されたストレージ管理ソフトウェアです。</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">* 新しいアプリケーションとの統合。 * ONTAP は、既存のエンタープライズアプリケーションをサポートする同じインフラストラクチャを使用して、自律走行車、スマートシティ、インダストリー 4.0 などの次世代プラットフォームやアプリケーションにエンタープライズクラスのデータサービスを提供します。</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">NetApp E シリーズ SANtricity ソフトウェアのデータシート</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity は、 E シリーズハイブリッドフラッシュと EF シリーズオールフラッシュアレイに業界をリードするパフォーマンス、信頼性、シンプルさを提供するように設計されています。E シリーズハイブリッドフラッシュアレイと EF シリーズオールフラッシュアレイのパフォーマンスと利用率を最大限に高め、データ分析、ビデオ監視、バックアップとリカバリなどの高負荷のアプリケーションに対応します。SANtricity を使用すると、ストレージをオンラインにしたまま、設定の調整、メンテナンス、容量の拡張などのタスクを実行できます。SANtricity は、優れたデータ保護、プロアクティブな監視、認定済みのセキュリティも提供します。いずれも使いやすい標準搭載の System Manager インターフェイスからアクセスできます。詳細については、を参照してください<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block>。</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">パフォーマンスの最適化</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">パフォーマンスが最適化された SANtricity ソフトウェアは、データ分析、ビデオ監視、バックアップのすべてのアプリケーションに、高い IOPS 、高いスループット、低レイテンシを実現します。高 IOPS 、低レイテンシのアプリケーション、広帯域幅、高スループットのアプリケーションのパフォーマンスを向上</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">アップタイムを最大限に向上</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">ストレージをオンラインにしたまま、すべての管理タスクを実行できます。構成の調整、メンテナンス、容量の拡張を、 I/O を中断せずに実行できます自動化機能、オンライン構成、最先端の Dynamic Disk Pools （ DPP ）テクノロジなどにより、業界最高の信頼性を実現します。</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">お休みください</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">SANtricity ソフトウェアは、使いやすい標準搭載の System Manager インターフェイスを通じて、優れたデータ保護、プロアクティブな監視、認定済みのセキュリティを実現します。ストレージ管理業務を簡易化E シリーズストレージシステムの高度な調整に必要な柔軟性を実現します。NetApp E シリーズシステムをいつでも、どこからでも管理可能標準搭載されている Web ベースのインターフェイスにより、管理ワークフローが合理化されます。</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block> ネットアップは、 Docker と Kubernetes 向けのオープンソースの動的ストレージオーケストレーションツールであり、永続的ストレージの作成、管理、使用を簡易化します。Kubernetes ネイティブアプリケーションである Trident は、 Kubernetes クラスタ内で直接実行されます。Trident を使用すると、 DL コンテナイメージをネットアップストレージにシームレスに導入し、エンタープライズクラスの AI コンテナ環境を実現できます。Kubernetes ユーザ（ ML 開発者やデータサイエンティストなど）は、オーケストレーションとクローニングを作成、管理、自動化し、ネットアップテクノロジを基盤とするネットアップの高度なデータ管理機能を活用できます。</block>
  <block id="e367efbc26bd12c0d6ae37dd6a55ef9b" category="inline-link">Cloud Sync</block>
  <block id="2d76806bea2175a1c575d37015a3621b" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> 迅速かつセキュアなデータ同期を実現するネットアップのサービスです。オンプレミスの NFS または SMB ファイル共有、 NetApp StorageGRID 、 NetApp ONTAP S3 、 NetApp Cloud Volumes Service 、 Azure NetApp Files 、 Amazon Simple Storage Service （ Amazon S3 ）、 Amazon Elastic File System （ Amazon EFS ）、 Azure Blob 、 Google Cloud Storage 間でファイルを転送する必要があるかどうか または、 IBM Cloud Object Storage を使用すると、 Cloud Sync で必要な場所に迅速かつ安全にファイルを移動できます。転送されたデータは、ソースとターゲットの両方で完全に使用できます。Cloud Sync は、事前定義されたスケジュールに基づいてデータを継続的に同期し、差分のみを移動するため、データレプリケーションにかかる時間とコストを最小限に抑えることができます。Cloud Sync は、セットアップや使用がきわめて簡単なソフトウェアサービス（ SaaS ）ツールです。Cloud Sync によって実行されるデータ転送は、データブローカーによって実行されます。Cloud Sync データブローカーは、 AWS 、 Azure 、 Google Cloud Platform 、オンプレミスに導入できます。</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="section-title">Lenovo ThinkSystem サーバ</block>
  <block id="e76fa728781968dd4a707e2d3b1d8108" category="paragraph">Lenovo ThinkSystem サーバは、革新的なハードウェア、ソフトウェア、サービスを搭載しており、お客様の現在の課題を解決し、将来の課題に対処するための、進化した、用途に合わせたモジュラー設計アプローチを提供します。これらのサーバは、クラス最高の業界標準テクノロジーと、差別化された Lenovo の革新技術を組み合わせて、 x86 サーバで可能な限り高い柔軟性を提供します。</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">Lenovo ThinkSystem サーバを導入する主なメリットは次のとおりです。</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">ビジネスの成長に合わせて拡張性に優れたモジュラ設計</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">業界をリードする耐障害性により、計画外停止にかかるコストを時間単位で削減します</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">高速フラッシュテクノロジにより、レイテンシを低減し、応答時間を短縮し、リアルタイムでのデータ管理をスマートに実現します</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">Lenovo は、 AI 分野において、企業がワークロードに ML と AI のメリットを理解し、採用できるようにするための実践的なアプローチをとっています。Lenovo のお客様は、 Lenovo AI Innovation Center で Lenovo AI 製品を調査および評価し、特定のユースケースの価値を十分に理解することができます。価値実現までの時間を短縮するために、このお客様中心のアプローチでは、 AI に最適化された、すぐに使用できる解決策開発プラットフォームのコンセプトの実証をお客様に提供しています。</block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="section-title">Lenovo ThinkSystem SE350 Edge Server</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">エッジコンピューティングにより、 IoT デバイスからのデータをネットワークのエッジで分析してから、データセンターやクラウドに送信できます。下の図に示す Lenovo ThinkSystem SE350 は、柔軟性、接続性、セキュリティ、およびリモート管理性を重視した、耐久性と環境を強化したコンパクトなフォームファクタのエッジでの導入に固有の要件を満たすように設計されています。</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">SE350 は、エッジ AI ワークロードの高速化をサポートする柔軟性を備えたインテル Xeon D プロセッサーを搭載しており、データセンター外のさまざまな環境でのサーバー導入の課題に対応できるように設計されています。</block>
  <block id="b739a166d96ffd72ac4d456012bfbe21" category="paragraph"><block ref="b739a166d96ffd72ac4d456012bfbe21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="paragraph"><block ref="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="section-title">MLPerf</block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">MLPerf 推論 v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf は、 AI のパフォーマンスを評価するための業界をリードするベンチマークスイートです。画像分類、オブジェクト検出、医療画像処理、自然言語処理（ NLP ）など、応用 AI の多くの分野をカバーしています。この検証では、推論 v0.7 ワークロードを使用しました。これは、この検証の完了時に MLPerf 推論の最新の反復処理です。。<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> Suite には、データセンターとエッジシステムのための 4 つの新しいベンチマークが含まれています。</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">* BERT * Transformers （ BERT ）の双方向エンコーダリプレゼンテーションは、チームデータセットを使用して質問に答えるように微調整されています。</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">* DLRM.* ディープラーニング・レコメンド・モデル（ DLRM ）は、クリックスルー・レート（ CTR ）を最適化するためのトレーニングを受けた、パーソナライズされた推奨モデルです。</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*3D U-Net. * 3D U-Net アーキテクチャは、 Brain Tumor Segmentation （ BRT ）データセットについてトレーニングされています。</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T* 再帰型ニューラルネットワークトランスデューサ (RNN-T) は、 LibriSpeech のサブセットについてトレーニングを受けた自動音声認識 (ASR) モデルです。MLPerf 推論の結果とコードは、 Apache ライセンスに基づいて公開およびリリースされます。MLPerf Inference にはエッジがあり、次のシナリオをサポートします。</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">* 単一ストリーム * このシナリオは、スマートフォンで実行されるオフライン AI クエリなど、応答性が重要な要因となるシステムを模倣しています。個々のクエリがシステムに送信され、応答時間が記録されます。すべての応答の 90 パーセンタイルレイテンシが結果として報告されます。</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">* マルチストリーム * このベンチマークは、複数のセンサーからの入力を処理するシステム用です。テスト中は、一定の間隔でクエリが送信されます。QoS の制約（許容される最大レイテンシ）が発生する。テストでは、 QoS の制約を満たしている間にシステムが処理できるストリーム数が報告されます。</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">* オフライン。 * これはバッチ処理アプリケーションを対象とした最も簡単なシナリオで、メトリックは 1 秒あたりのサンプル数でスループットです。すべてのデータをシステムで使用でき、ベンチマークはすべてのサンプルの処理にかかる時間を測定します。</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="c953c121914b99f83398f20ab2160ed1" category="paragraph">Lenovo は、本ドキュメントで使用されているサーバである T4 で SE350 の MLPerf Inference スコアを発表しました。の結果を参照してください<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> エントリ #0.7~145 の「 Edge 、 Closed Division 」セクションに記載されています。</block>
  <block id="26cb2cd90a9e0e03f63323eab13f117d" category="inline-link-macro">次の手順：テスト計画</block>
  <block id="91666b8460dc62d134fe80c31f05d28b" category="paragraph"><block ref="91666b8460dc62d134fe80c31f05d28b" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">AI 主導の自動化とエッジコンピューティングは、ビジネス組織がデジタル変革を実現し、運用効率と安全性を最大限に高めるための、業界をリードするアプローチです。エッジコンピューティングでは、データセンターとの間を移動する必要がないため、データの処理速度が大幅に向上します。そのため、データセンターやクラウドへのデータの送受信に関連するコストが削減されます。</block>
  <block id="1490b4526090ba1052ae7d989d2f44df" category="inline-link-macro">前のバージョン：アーキテクチャのサイジングオプション</block>
  <block id="9d58af74dd11a7bf0a907e66af94ae03" category="paragraph"><block ref="9d58af74dd11a7bf0a907e66af94ae03" category="inline-link-macro-rx"></block></block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">AI 主導の自動化とエッジコンピューティングは、ビジネス組織がデジタル変革を実現し、運用効率と安全性を最大限に高めるための、業界をリードするアプローチです。エッジコンピューティングでは、データセンターとの間を移動する必要がないため、データの処理速度が大幅に向上します。そのため、データセンターやクラウドへのデータの送受信に関連するコストが削減されます。エッジに導入された AI 推論モデルを使用してほぼリアルタイムで意思決定を行う必要がある場合は、レイテンシの低減とスピードの向上が効果的です。</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">ネットアップのストレージシステムは、ローカル SSD ストレージと同等以上のパフォーマンスを発揮し、データサイエンティスト、データエンジニア、 AI / ML 開発者、ビジネスや IT の意思決定者に次のようなメリットをもたらします。</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">AI システム、分析などの重要なビジネスシステム間でデータを容易に共有できます。このようなデータ共有により、インフラのオーバーヘッドを削減し、パフォーマンスを向上させ、企業全体のデータ管理を合理化できます。</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">個別に拡張可能なコンピューティングとストレージにより、コストを最小限に抑え、リソース使用率を向上させます。</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">統合された Snapshot コピーとクローンを使用して開発と導入のワークフローを合理化し、ユーザのワークスペースを瞬時にスペース効率よく利用できるほか、バージョン管理機能も統合され、導入も自動化されています。</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">ディザスタリカバリとビジネス継続性を実現するエンタープライズクラスのデータ保護本ドキュメントで紹介するネットアップと Lenovo の解決策は、柔軟性に優れたスケールアウトアーキテクチャを備えており、エッジでのエンタープライズクラスの AI 推論導入に最適です。</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">J. J. J.Falkanger 、 Sr.Lenovo 、 HPC &amp; AI ソリューション担当マネージャー</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">ネットアップ、テクニカルマーケティングエンジニア、 Dave Arnette 氏</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell 、 Tech Lead E シリーズ AI Solutions 、ネットアップ</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">ネットアップ、 QA エンジニア、 Cody Harryman 氏</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">NetApp AFF A シリーズアレイの製品ページ</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">NetApp ONTAP データ管理ソフトウェア— ONTAP 9 情報ライブラリ</block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727 ：『 NetApp EF Series Introduction 』</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">NetApp E シリーズ SANtricity ソフトウェアのデータシート</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">コンテナ向け NetApp 永続的ストレージ— NetApp Trident</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">TensorFlow ベンチマーク</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Lenovo ThinkSystem DM5100F ユニファイドフラッシュストレージアレイ</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="f8287e56c1a5982e49b792d1116aa372" category="paragraph"><block ref="f8287e56c1a5982e49b792d1116aa372" category="inline-link-rx"></block></block>
  <block id="5e79a20254a28ffdb604f6cba5216c75" category="cell">2021年3月</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">初版リリース</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">バージョン 2.0 以降</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">2021年10月</block>
  <block id="71b3f2dc39aa770e58cd3fad98b76c37" category="cell">EF および MLPerf Inference v1.1 で更新</block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">検証に使用する設定は、他のユースケースに合わせて調整できます。</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">アーキテクチャのサイジングオプション</block>
  <block id="ac0ec60d36dfa69ed9c33bff90080b23" category="inline-link-macro">前へ：テスト結果。</block>
  <block id="389a3124af7d4b9dc7165b05fd96a378" category="paragraph"><block ref="389a3124af7d4b9dc7165b05fd96a378" category="inline-link-macro-rx"></block></block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">コンピューティングサーバ</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">SE350 でサポートされている最小レベルの CPU である Intel Xeon D-2123IT CPU を使用し、 4 つの物理コアと 60W TDP を使用しました。サーバは CPU の交換をサポートしていませんが、より強力な CPU で発注することもできます。サポートされている CPU の上位は、 16 コアを搭載した Intel Xeon D-2183IT 、 2.20GHz で動作する 100W です。これにより、 CPU の計算能力が大幅に向上します。CPU は推論ワークロード自体を実行するためのボトルネックではありませんでしたが、データ処理や推論に関連するその他のタスクに役立ちます。現時点では、 NVIDIA T4 がエッジで唯一の GPU です。そのため、 GPU のアップグレードやダウングレードは行えません。</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">共有ストレージ</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">テストと検証には、ストレージ容量が最大 50.5TB の NetApp AFF C190 システムが使用されています。シーケンシャルリードの場合は 4.4GBps のスループット、スモールランダムリードの場合は 230K の IOPS が、このドキュメントではエッジ推論ワークロードに適していることが実証されています。</block>
  <block id="bb33c803e43b816786d862bbbbf2c824" category="paragraph">ただし、より多くのストレージ容量を必要としたり、より高速なネットワーク速度を必要とする場合は、 NetApp AFF A220 またはを使用してください<block ref="03f94a30ec5c979321fdd9a1ba99a1c6" category="inline-link-rx"></block> ストレージシステムまた、最大容量が 1.5PB の NetApp EF280 システムでは、この解決策検証に、帯域幅も 10Gbps 使用しました。より多くのストレージ容量をより多くの帯域幅で使用する場合は、<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> を使用できます。</block>
  <block id="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="paragraph"><block ref="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="inline-link-macro-rx"></block></block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">このセクションでは、この解決策の検証に使用するテスト手順について説明します。</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">手順をテストします</block>
  <block id="e46c1f341c1cea1321f4c00d15e90b0d" category="inline-link-macro">前の手順：設定をテストします。</block>
  <block id="ed760d2dffd7d011a7870619f7884005" category="paragraph"><block ref="ed760d2dffd7d011a7870619f7884005" category="inline-link-macro-rx"></block></block>
  <block id="bff816e8e8ddbe2a3b705d92abba6627" category="paragraph">この検証では次のテスト手順を使用しました。</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">オペレーティングシステムと AI 推論のセットアップ</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">コード</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">AFF C190 には、 NVIDIA ドライバと Docker を搭載した Ubuntu 18.04 を使用し、 NVIDIA GPU をサポートし、 MLPerf を使用しました<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> Lenovo から MLPerf Inference v0.7 への提出書類の一部として提供されます。</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">EF280 には、 NVIDIA ドライバと Docker を搭載した Ubuntu 20.04 を使用し、 NVIDIA GPU と MLPerf をサポートしました<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> Lenovo から MLPerf Inference v1.1 への提出の一部として提供されています。</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">AI 推論をセットアップするには、次の手順を実行します。</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">このディレクトリは、ネットワークストレージのユースケース用に共有ストレージ上で共有するか、またはローカルデータでテストする際にローカルディスク上で共有する必要があります。</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">実行中の Docker コンテナ内から次のコマンドがすべて実行されます。</block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">推論ワークロードを実行するには、次のコマンドを実行します（ 1 つのコマンド）。</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">AI 推論の実行</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">実行された実行のタイプは次の 3 つです。</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">ローカルストレージを使用した単一サーバの AI 推論</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">ネットワークストレージを使用した単一サーバの AI 推論</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">ネットワークストレージを使用したマルチサーバ AI 推論</block>
  <block id="7dc96590f7bab3379a7a79986056d22a" category="inline-link-macro">次の手順：テスト結果</block>
  <block id="697d202c2969580ba0434be04d39a929" category="paragraph"><block ref="697d202c2969580ba0434be04d39a929" category="inline-link-macro-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">このセクションでは、テスト構成、ネットワークインフラストラクチャ、 SE350 サーバ、およびストレージプロビジョニングの詳細について説明します。</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">設定をテストします</block>
  <block id="b1ee26c1917a17c30b17d7cd6b01e2cd" category="inline-link-macro">前の手順：テスト計画</block>
  <block id="7dffe110836fe412eac19d0f63cf5b5b" category="paragraph"><block ref="7dffe110836fe412eac19d0f63cf5b5b" category="inline-link-macro-rx"></block></block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">次の図に、テスト構成を示します。NetApp AFF C190 ストレージシステムと、 Lenovo ThinkSystem SE350 サーバを 2 台（それぞれ NVIDIA T4 アクセラレータを 1 台搭載）使用しました。これらのコンポーネントは、 10GbE ネットワークスイッチを介して接続されます。ネットワークストレージには、検証 / テスト用のデータセットと事前トレーニング済みのモデルが格納されます。サーバはコンピューティング機能を提供し、ストレージに NFS プロトコル経由でアクセスします。</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">このセクションでは、テスト構成、ネットワークインフラストラクチャ、 SE350 サーバ、およびストレージプロビジョニングの詳細について説明します。次の表に、解決策アーキテクチャの基本コンポーネントを示します。</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">SE350 サーバ x 2 （それぞれ NVIDIA T4 GPU カード 1 枚）</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">各サーバには Intel Xeon D-2123IT CPU が 1 つ搭載され、物理コアは 2.20GHz と 128GB の RAM で動作します</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">エントリレベルの NetApp AFF ストレージシステム（ HA ペア）</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">NetApp ONTAP 9 ソフトウェア</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">960GB SSD × 24</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">コントローラごとに 1 つのインターフェイスグループ。マウントポイント用に 4 つの論理 IP アドレスが割り当てられます</block>
  <block id="1a538c197da3186f1eba50d82572dc34" category="paragraph"><block ref="1a538c197da3186f1eba50d82572dc34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">次の表に、 AFF C190 と 2RU 、 24 ドライブスロットのストレージ構成を示します。</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">コントローラ</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">アグリゲート</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">FlexGroup ボリューム</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">Aggregatesize を実行します</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">ボリュームサイズ</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">オペレーティングシステムのマウントポイント</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">コントローラ 1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">aggr1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netappleenov_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/NetApp_Lenovo _ fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">コントローラ 2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">aggr2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">/netappLenovo_AI_fg フォルダには、モデルの検証に使用するデータセットが含まれています。</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">次の図は、テスト構成を示しています。NetApp EF280 ストレージシステムを 2 台、 Lenovo ThinkSystem SE350 サーバを 2 台（それぞれ NVIDIA T4 アクセラレータを 1 台搭載）使用しました。これらのコンポーネントは、 10GbE ネットワークスイッチを介して接続されます。ネットワークストレージには、検証 / テスト用のデータセットと事前トレーニング済みのモデルが格納されます。サーバはコンピューティング機能を提供し、ストレージに NFS プロトコル経由でアクセスします。</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">次の表に、 EF280 のストレージ構成を示します。</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">ボリュームグループ</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">ボリューム</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDPsize</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">接続方法</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">ボリューム 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 から iSCSI LUN 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">ボリューム 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 から iSCSI LUN 1 へ</block>
  <block id="43fa57e4031b0f759153c9c9fa49e6ed" category="paragraph"><block ref="43fa57e4031b0f759153c9c9fa49e6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0fccd40a3886a1e5dc539059407586a0" category="inline-link-macro">次の手順：手順をテストします。</block>
  <block id="3bee5237e36a9a0dc60fd351ce904544" category="paragraph"><block ref="3bee5237e36a9a0dc60fd351ce904544" category="inline-link-macro-rx"></block></block>
  <block id="290612199861c31d1036b185b4e69b75" category="doc">まとめ</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">先進的なドライバーアシスタンスシステム（ ADAS ）、インダストリー 4.0 、スマートシティ、モノのインターネット（ IoT ）など、いくつかの新しいアプリケーションシナリオでは、ほぼゼロのレイテンシで継続的なデータストリームを処理する必要があります。このドキュメントでは、こうした要件を満たすエッジ環境のネットアップストレージコントローラと Lenovo ThinkSystem サーバに GPU ベースの人工知能（ AI ）推論を導入するためのコンピューティングとストレージのアーキテクチャについて説明します。また、このドキュメントでは、業界標準の MLPerf Inference ベンチマークのパフォーマンスデータも提供し、 NVIDIA T4 GPU を搭載したエッジサーバ上のさまざまな推論タスクを評価します。オフライン、単一ストリーム、マルチストリームの推論のシナリオのパフォーマンスを調査し、コスト効率の高い共有ネットワークストレージシステムを使用したアーキテクチャはハイパフォーマンスであり、複数のエッジサーバのデータとモデルを一元的に管理できることを示します。</block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">提案するアーキテクチャのパフォーマンスを評価するために、多数のテストを実施しました。6 種類のワークロードがあります（画像分類、オブジェクト検出 [ 小規模 ] 、オブジェクト検出 [ 大規模 ] 、医療画像処理、音声テキスト変換、 また、ナチュラル言語処理（ NLP ）もサポートされており、オフライン、シングルストリーム、マルチストリームという 3 つのシナリオで実行できます。</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">テスト結果</block>
  <block id="5e2777e1d5ba6adfeabc55064de508f5" category="inline-link-macro">前へ：手順のテスト。</block>
  <block id="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="paragraph"><block ref="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="inline-link-macro-rx"></block></block>
  <block id="507b481f4f0fb36b82f97222c73fb91d" category="section-title">AFF のテスト結果</block>
  <block id="817fbb6103e6cb6855c19a5c1b25f817" category="paragraph">提案するアーキテクチャのパフォーマンスを評価するために、多数のテストを実施しました。6 種類のワークロードがあります（画像分類、オブジェクト検出 [ 小規模 ] 、オブジェクト検出 [ 大規模 ] 、医療画像処理、音声テキスト変換、 また、ナチュラル言語処理（ NLP ）もサポートされており、オフライン、シングルストリーム、マルチストリームの 3 つのシナリオで実行できます。</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">最後のシナリオは、画像分類とオブジェクト検出の場合にのみ実装されます。</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">その結果、次の 3 種類のセットアップですべてテストされた 15 のワークロードが生成されます。</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">単一のサーバ / ローカルストレージ</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">単一のサーバ / ネットワークストレージ</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">マルチサーバ / ネットワークストレージ</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">結果については、以降のセクションで説明します。</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">AFF のオフラインシナリオにおける AI 推論</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">このシナリオでは、すべてのデータがサーバで使用可能であり、すべてのサンプルの処理にかかった時間が測定されました。テストの結果として、帯域幅が 1 秒あたりのサンプル数で報告されます。複数のコンピューティングサーバを使用した場合、すべてのサーバの合計帯域幅がレポートされます。3 つのユースケースすべての結果を次の図に示します。2 サーバの場合は、両方のサーバからの帯域幅の合計を報告します。</block>
  <block id="d39bc80b598327ae50c15f64c44bb6ea" category="paragraph"><block ref="d39bc80b598327ae50c15f64c44bb6ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">結果から、ネットワークストレージがパフォーマンスに悪影響を与えていないことがわかります。変更は最小限で、一部のタスクでは何も検出されません。2 台目のサーバを追加する場合、合計帯域幅は正確に 2 倍になるか、最悪の場合は 1 % 未満になります。</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">AFF 向けの単一ストリームのシナリオでの AI 推論</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">このベンチマークではレイテンシを測定します。複数のコンピューティングサーバの場合は、平均レイテンシが報告されます。一連のタスクの結果を次の図に示します。2 台のサーバの場合は、両方のサーバの平均レイテンシが報告されます。</block>
  <block id="01f3906715186988e276bc34ebc661c0" category="paragraph"><block ref="01f3906715186988e276bc34ebc661c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">結果からも、タスクを処理するのに十分なネットワークストレージがあることがわかります。1 つのサーバケースにおけるローカルストレージとネットワークストレージの違いは、最小またはなしです。同様に、 2 台のサーバが同じストレージを使用している場合、両方のサーバの遅延は同じままであるか、非常に小さい値で変化します。</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">AFF のマルチストリームシナリオにおける AI 推論</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">この場合、 QoS の制約を満たしながらシステムで処理可能なストリーム数が返されます。したがって、結果は常に整数になります。複数のサーバについて ' すべてのサーバの合計ストリーム数を報告しますすべてのワークロードがこのシナリオをサポートしているわけではありませんが、そのシナリオを実行してきました。テストの結果を次の図にまとめます。2 サーバの場合は、両方のサーバからのストリームの合計数を報告します。</block>
  <block id="758b60f43cbc650fded1dcf9be428fa5" category="paragraph"><block ref="758b60f43cbc650fded1dcf9be428fa5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">この結果は、ローカルストレージとネットワーキングストレージでセットアップのパフォーマンスが完璧に向上し、 2 台目のサーバを追加すると、提案されたセットアップで処理できるストリーム数が 2 倍になります。</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">EF シリーズのテスト結果</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">提案するアーキテクチャのパフォーマンスを評価するために、多数のテストを実施しました。6 種類のワークロードがあります（画像分類、オブジェクト検出 [ 小規模 ] 、オブジェクト検出 [ 大規模 ] 、医療画像処理、音声テキスト変換、 とナチュラル言語処理（ NLP ）は、オフラインとシングルストリームの 2 つの異なるシナリオで実行されました。結果については、以降のセクションで説明します。</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">EF 向けのオフラインシナリオでの AI 推論</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">このシナリオでは、すべてのデータがサーバで使用可能であり、すべてのサンプルの処理にかかった時間が測定されました。テストの結果として、帯域幅が 1 秒あたりのサンプル数で報告されます。1 つのノードの実行については両方のサーバからの平均をレポートし、 2 つのサーバの実行については、すべてのサーバに合計された合計帯域幅をレポートします。ユースケースの結果を次の図に示します。</block>
  <block id="8e793f971410e2b57df427d1305ee0a2" category="paragraph"><block ref="8e793f971410e2b57df427d1305ee0a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">EF 向けの単一ストリームのシナリオでの AI 推論</block>
  <block id="5656e3a262dfb3d6e1cba96551717de0" category="paragraph"><block ref="5656e3a262dfb3d6e1cba96551717de0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="516a608926718d1a912cf9404f1a63ac" category="inline-link-macro">次：アーキテクチャのサイジングオプション</block>
  <block id="9cedf0fb8faddf365d88f523ae482015" category="paragraph"><block ref="9cedf0fb8faddf365d88f523ae482015" category="inline-link-macro-rx"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">このドキュメントでは、最新のアプリケーションシナリオを満たすエッジ環境のネットアップストレージコントローラと Lenovo ThinkSystem サーバに GPU ベースの人工知能（ AI ）推論を導入するためのコンピューティングとストレージのアーキテクチャについて説明します。</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886 ： Lenovo ThinkSystem-解決策 Design を使用したエッジネットアップでの AI 推論</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Lenovo 、 Miroslav Hodak 、 Sathish Thyagarajan 氏</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">企業は、ネットワークエッジで大量のデータを生成するケースが増えています。スマートセンサーや IoT データから最大限の価値を引き出すために、企業はエッジコンピューティングを可能にするリアルタイムのイベントストリーミング解決策を求めています。そのため、データセンターの外部にあるエッジでは、処理能力の高い作業がますます実行されるようになっています。AI 推論は、この傾向の推進要因の 1 つです。特にアクセラレータを使用する場合は、エッジサーバがこれらのワークロードに十分な処理能力を発揮しますが、ストレージが制限されることが多いのは、特にマルチサーバ環境では問題です。このドキュメントでは、共有ストレージシステムをエッジ環境に導入する方法と、パフォーマンスに影響を与えずに AI 推論ワークロードにどのようなメリットがあるかを説明します。</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">このドキュメントでは、エッジでの AI 推論向けのリファレンスアーキテクチャについて説明します。複数の Lenovo ThinkSystem エッジサーバとネットアップストレージシステムを組み合わせることで、導入と管理が容易な解決策を構築これは、複数のカメラと産業用センサーを備えた工場フロア、小売取引における POS システム、自律走行車の視覚的な異常を識別するフル・セルフ・ドライビング（ FSD ）システムなど、さまざまな状況での実践的な展開のための基本ガイドとなることを目的としています。</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">本ドキュメントでは、 Lenovo ThinkSystem SE350 Edge Server とエントリレベルの NetApp AFF および EF シリーズストレージシステムで構成された、コンピューティングとストレージの構成のテストと検証について説明します。リファレンスアーキテクチャは、 AI 導入向けの効率的でコスト効率に優れた解決策を提供すると同時に、 NetApp ONTAP と NetApp SANtricity データ管理ソフトウェアを使用して、包括的なデータサービス、統合データプロテクション、シームレスな拡張性、クラウド対応データストレージを提供します。</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">本ドキュメントは、次のような方を対象としています。</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">エッジで AI を生産するビジネスリーダーやエンタープライズアーキテクト。</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">データサイエンティスト、データエンジニア、 AI / 機械学習（ ML ）研究者、 AI システムの開発者</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">AI / ML モデルとアプリケーションの開発のためのソリューションを設計するエンタープライズアーキテクト。</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">ディープラーニング（ DL ）モデルや ML モデルを効率的に導入する方法を探しているデータサイエンティストと AI エンジニア。</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">エッジ推論モデルの導入と管理を担当するエッジデバイスマネージャとエッジサーバ管理者。</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">解決策アーキテクチャ</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">カメラやセンサーなどから受信したデータを推論しているエッジコンピューティングデバイス。</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">複数の用途に使用できる共有ストレージ要素：</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">推論モデルや推論の実行に必要なその他のデータを一元的に格納できます。コンピューティングサーバはストレージに直接アクセスし、ネットワーク全体で推論モデルを使用します。ローカルにコピーする必要はありません。</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">更新されたモデルはここにプッシュされます。</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">エッジサーバーが受信する入力データをアーカイブして、後で分析します。たとえば、エッジデバイスがカメラに接続されている場合、ストレージエレメントはカメラでキャプチャされたビデオを保持します。</block>
  <block id="45d9a14c8d568ce70d22acbde8373657" category="paragraph"><block ref="45d9a14c8d568ce70d22acbde8373657" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">赤</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">青</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Lenovo コンピューティングシステム</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">NetApp AFF ストレージシステム</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">カメラやセンサーなどからの入力で推論を実行するエッジデバイス。</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">推論モデルとエッジデバイスからのデータを保持する共有ストレージを使用して、後から分析することができます。</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">このネットアップと Lenovo 解決策は、主に次のようなメリットをもたらします。</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">エッジでの GPU アクセラレーションコンピューティング。</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">共有ストレージからバックアップおよび管理される複数のエッジサーバの導入。</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">堅牢なデータ保護により、データ損失ゼロで目標復旧時点（ RPO ）と目標復旧時間（ RTO ）を達成</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">NetApp Snapshot コピーとクローンでデータ管理を最適化し、開発ワークフローを合理化</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">このアーキテクチャの使用方法</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">本ドキュメントでは、提案アーキテクチャの設計とパフォーマンスを検証します。ただし、ネットアップでは、コンテナ、ワークロード、モデル管理、クラウドやデータセンターとのデータ同期など、特定のソフトウェアレベルの要素は導入シナリオに固有のものであるため、テストは実施していません。ここには複数の選択肢があります。</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">解決策エリア</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">AI 推論とエッジコンピューティングの主なメリットは、デバイスがレイテンシなしで高品質のデータを計算、処理、分析できることです。このドキュメントで説明するエッジコンピューティングのユースケースの例は非常に多くありますが、ここではいくつかの重要な例を示します。</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">自動車：自律走行車</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">従来のエッジコンピューティングの図は、自律走行車（ AV ）の先進ドライバーアシスタンスシステム（ ADAS ）にあります。ドライバーのいない自動車の AI は、カメラやセンサーからの大量のデータを迅速に処理して、安全性を強化する必要があります。物体と人間の間を解釈するのに時間がかかりすぎると、生命や死亡を意味することがあります。そのため、可能な限り車両の近くでそのデータを処理できることが重要です。この場合、 1 つ以上のエッジコンピュートサーバがカメラ、レーダー、 LiDAR などのセンサーからの入力を処理し、共有ストレージには推論モデルが保持されてセンサーからの入力データが格納されます。</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">ヘルスケア：患者のモニタリング</block>
  <block id="a5031cd8ea18cb91370c532194ecd58e" category="paragraph">AI とエッジコンピューティングがもたらす最大の影響の 1 つは、在宅ケアと集中治療ユニット（ ICU ）の両方において、慢性疾患の患者の継続的なモニタリングを強化できることです。インスリンレベル、呼吸、神経学的活性、心リズム、および消化管機能をモニターするエッジデバイスからのデータは、患者の生命を救うための時間が限られているため、ただちに作用する必要のあるデータを瞬時に分析する必要があります。</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">小売：現金払い</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">エッジコンピューティングは AI と ML を強化することで、小売企業はチェックアウト時間を短縮し、足のトラフィックを増加させることができます。キャッシュレスシステムは、次のようなさまざまなコンポーネントをサポートします。</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">認証とアクセス：物理的な買い物客を検証済みのアカウントに接続し、小売店のスペースへのアクセスを許可する。</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">インベントリの監視：センサー、 RFID タグ、コンピューター・ビジョン・システムを使用して、買い物客による商品の選択や選択解除を確認できます。</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">ここで ' 各エッジ・サーバが各チェックアウト・カウンタを処理し ' 共有ストレージ・システムが中央の同期ポイントとして機能します</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">金融サービス：キオスクでの人間の安全と不正防止</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">銀行業界では、 AI とエッジコンピューティングを活用して、パーソナライズされた銀行業務を革新し、創出しています。リアルタイムのデータ分析と AI 推論を使用したインタラクティブなキオスクにより、 ATM は顧客がお金を引き出すのを支援できるだけでなく、カメラからキャプチャされた画像を介してキオスクをプロアクティブに監視し、人間の安全や不正行為に対するリスクを特定できるようになりました。このシナリオでは、エッジコンピューティングサーバと共有ストレージシステムが対話型のキオスクやカメラに接続されて、銀行が AI 推論モデルでデータを収集して処理できるようにします。</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">製造： Industry 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">産業革命の 4 つ目（インダストリー 4.0 ）は、スマートファクトリーや 3D プリントなどの新たなトレンドとともに始まっています。データ主導の未来に備えるために、大規模な機械間（ M2M ）通信と IoT が統合されており、人間の介入なしに自動化を強化します。製造はすでに高度に自動化されており、 AI 機能の追加は長期的なトレンドの自然な流れを続けています。AI により、コンピュータビジョンやその他の AI 機能を活用して自動化できる運用を自動化できます。品質管理や、人間のビジョンや意思決定に依存するタスクを自動化して、工場の現場で組み立てライン上の材料を迅速に分析し、製造工場が必要とする ISO 規格の安全性と品質管理に適合できるようにすることができます。ここでは、各コンピュートエッジサーバが、製造プロセスを監視する一連のセンサーと、更新された推論モデルに必要に応じて共有ストレージにプッシュされます。</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">通信：地殻検出、タワー検査、およびネットワーク最適化</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">電気通信業界は、コンピュータビジョンと AI 技術を使用して、錆を自動的に検出し、腐食を含む基地局を特定する画像を処理しているため、さらなる検査が必要です。最近では、ドローン画像と AI モデルを使用して、塔の異なる領域を特定し、錆、表面の亀裂、腐食を分析しています。通信インフラやセルタワーを効率的に検査し、定期的に劣化を評価し、必要に応じて迅速に修復できる AI テクノロジの需要は高まり続けています。</block>
  <block id="50dba7db75064ae2e0beea487226ed46" category="paragraph">さらに、通信業界で新たに登場したユースケースとして、 AI と ML のアルゴリズムを使用して、データトラフィックパターンの予測、 5G 対応デバイスの検出、 MIMO （複数入力 / 複数出力）エネルギー管理の自動化と強化が挙げられます。MIMO ハードウェアは、ネットワーク容量を増やすために無線タワーで使用されていますが、これには追加のエネルギーコストが伴います。セルサイトに導入された「 MIMO スリープモード」用の ML モデルは、無線機の効率的な使用を予測し、モバイルネットワークオペレータ（ MNO ）のエネルギー消費コストを削減するのに役立ちます。AI 推論とエッジコンピューティングのソリューションは、 MNO がデータセンターにやり取りするデータ量を削減し、 TCO を削減し、ネットワーク運用を最適化し、エンドユーザの全体的なパフォーマンスを向上させるのに役立ちます。</block>
  <block id="f45c430b02aac052aef8d958c80ff351" category="paragraph"><block ref="f45c430b02aac052aef8d958c80ff351" category="inline-link-macro-rx"></block></block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">このドキュメントは、 MLPerf Inference v0.7 コード、 MLPerf Inference v1.1 コード、およびルールに準拠しています。このセクションで説明する表で定義されているように、エッジで推論用に設計されたベンチマークを実行しました。</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">テスト計画</block>
  <block id="35e08a3e7b357a4284ef29b287063ae5" category="paragraph"><block ref="35e08a3e7b357a4284ef29b287063ae5" category="inline-link-macro-rx"></block></block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">ルール</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">面積（ Area ）</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">タスク</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">QSL サイズ</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">品質</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">マルチストリーム遅延制約</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">ビジョン</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">画像分類</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNet (224x224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">FP32 の 99%</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50 ミリ秒</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">物体検出（大）</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD リネット 34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">ココ (1200x1200)</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66 ミリ秒</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">物体検出（小）</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">ssd - MobileNetsv1 を参照してください</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">ココ (300 x 300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">医療画像のセグメンテーション</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">2019 年 BRT （ 224x224x160 ）</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">FP32 の 99% および 99.9%</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">該当なし</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">スピーチ</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">音声テキスト</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">ライブラリキーテック開発 - クリーン</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">言語</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">言語処理</block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="cell">BERT</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">分隊 v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">シナリオ</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">画像分類</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">シングルストリーム、オフライン、マルチストリーム</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">単一ストリーム、オフライン</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">音声テキスト</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">この検証で開発されたネットワーク・ストレージ・アーキテクチャを使用してこれらのベンチマークを実行し、 MLPerf に送信されたエッジ・サーバ上のローカル実行の結果と比較しました。この比較は、共有ストレージが推論パフォーマンスに与える影響を判断するためのものです。</block>
  <block id="a53c037982ff4e0cd4a61ba90c4c21d3" category="inline-link-macro">次の手順：設定をテストします。</block>
  <block id="50cbf9a915ce97c432035077add8a92f" category="paragraph"><block ref="50cbf9a915ce97c432035077add8a92f" category="inline-link-macro-rx"></block></block>
  <block id="012b603d852affe4779f095a5c59f0c5" category="summary">パブリッククラウドの即応性、価値実現までの時間、コスト削減はすべて、データベースアプリケーションの開発とテストのためにパブリッククラウドを採用する企業にとって有益な価値提案です。このような状況を早急に実現するには、 SnapCenter より優れたツールはありません。SnapCenter では、オンプレミスで本番環境のデータベースを保護できるだけでなく、パブリッククラウドでアプリケーションの開発やコードのテスト用にコピーをすばやくクローニングして、余分なストレージの消費量を最小限に抑えることができます。以下に、ツールを使用したステップバイステッププロセスの詳細を示します。</block>
  <block id="38da6679588aeb2754e14dd58994685e" category="doc">クラウドへの開発 / テストバースト対応ワークフロー</block>
  <block id="5b9681a3caf5db6230c17718122074d3" category="inline-link-macro">前のセクション： AWS パブリッククラウドの導入を開始しました。</block>
  <block id="e9e59a2a982f81f5f964248f351b2446" category="paragraph"><block ref="e9e59a2a982f81f5f964248f351b2446" category="inline-link-macro-rx"></block></block>
  <block id="4d8a5b6bc9c43ab79e376d1aa4d83217" category="paragraph">パブリッククラウドの即応性、価値実現までの時間、コスト削減はすべて、データベースアプリケーションの開発とテストのためにパブリッククラウドを採用する企業にとって有益な価値提案です。このような状況を実現するためのツールは、 SnapCenter よりも優れています。SnapCenter では、オンプレミスで本番環境のデータベースを保護できるだけでなく、パブリッククラウドでのアプリケーション開発やコードテスト用にコピーをすばやくクローニングして、余分なストレージの消費量を最小限に抑えることもできます。以下に、このツールを使用するためのステップバイステッププロセスの詳細を示します。</block>
  <block id="b47b42841be2e173707ab5884714970b" category="section-title">レプリケートされた Snapshot バックアップから、開発 / テスト用の Oracle データベースをクローニングします</block>
  <block id="8d90529d1117b8d3781bd6781acf4e91" category="list-text">Oracle 用のデータベース管理ユーザ ID で SnapCenter にログインします。リソースタブに移動します。このタブには、 SnapCenter で保護されている Oracle データベースが表示されます。</block>
  <block id="a95ff2a2ae2905b0bb3bd0efa211a040" category="paragraph"><block ref="a95ff2a2ae2905b0bb3bd0efa211a040" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d539d2e9659870aa79747206fac4769" category="list-text">バックアップトポロジと詳細表示に使用するオンプレミスデータベースの名前をクリックします。セカンダリでレプリケートされた場所が有効になっている場合は、リンクされたミラーバックアップが表示されます。</block>
  <block id="20111f4a74a9c065157aa13379000a73" category="paragraph"><block ref="20111f4a74a9c065157aa13379000a73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4a9c1f33e524696d6f3adebf89947bb" category="list-text">ミラーバックアップをクリックして、ミラーバックアップビューに切り替えました。その後、セカンダリミラーバックアップが表示されます。</block>
  <block id="e1cbaea95bcc154ccf9e8aece7fc73b3" category="paragraph"><block ref="e1cbaea95bcc154ccf9e8aece7fc73b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4726a244c3941457e8f62b49c83d35d1" category="list-text">クローニングするミラーされたセカンダリデータベースバックアップコピーを選択し、時間およびシステムの変更番号または SCN でリカバリポイントを決定します。通常は、クローニングするフルデータベースバックアップ時間または SCN の末尾にリカバリポイントを設定します。リカバリポイントを決定したら、必要なログファイルのバックアップをリカバリ用にマウントする必要があります。ログファイルのバックアップは、クローンデータベースをホストする対象の DB サーバにマウントする必要があります。</block>
  <block id="81d132cd1ae26e007bb608e5f8609288" category="paragraph"><block ref="81d132cd1ae26e007bb608e5f8609288" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2dc441031605bf54d78fde13b3efc3c" category="paragraph"><block ref="b2dc441031605bf54d78fde13b3efc3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22a17e5abcfc4b5e70ebdea098cd1891" category="admonition">ログの削除が有効で、リカバリポイントが最後のログの削除よりも長くなっている場合は、複数のアーカイブログのバックアップのマウントが必要になることがあります。</block>
  <block id="e9606676533bbe916f4b4b6824eac195" category="list-text">クローニングするフルデータベースバックアップコピーを選択し、クローンボタンをクリックして DB クローンワークフローを開始します。</block>
  <block id="48493c19ee97a291cd320501daf5c721" category="paragraph"><block ref="48493c19ee97a291cd320501daf5c721" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c06d82b497809fcc0fd06d00c6d91a5" category="list-text">完全なコンテナデータベースまたは CDB クローンに適したクローン DB SID を選択してください。</block>
  <block id="f6ee6a459784097119ec1eee6224152e" category="paragraph"><block ref="f6ee6a459784097119ec1eee6224152e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2c50a030b1c5313fca09568edf8c0f9" category="list-text">クラウド内のターゲットクローンホストを選択すると、クローンワークフローによってデータファイル、制御ファイル、および REDO ログディレクトリが作成されます。</block>
  <block id="323554a005f5e77dfaa765ea81e645be" category="paragraph"><block ref="323554a005f5e77dfaa765ea81e645be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="701f017aeafb71656cf2bc3a9bd34862" category="list-text">なしクレデンシャル名は OS ベースの認証に使用され、データベースポートは無関係になります。ターゲットのクローン DB サーバで設定した Oracle Home 、 Oracle OS User 、 Oracle OS Group を適切な値に設定します。</block>
  <block id="c5237b674d4a9cd38d44c5e546cc51d4" category="paragraph"><block ref="c5237b674d4a9cd38d44c5e546cc51d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26a911f3c85fc3c73d79253e65bf30e3" category="list-text">クローニング処理の前に実行するスクリプトを指定します。さらに重要な点は、ここでデータベースインスタンスのパラメータを調整または定義できることです。</block>
  <block id="56774e452bc62021e52de3e3fea844a2" category="paragraph"><block ref="56774e452bc62021e52de3e3fea844a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09d7240367714707474d63a3a574222b" category="list-text">日時または SCN でリカバリポイントを指定します。Cancel を実行するまで ' データベースは使用可能なアーカイブ・ログまでリカバリされますアーカイブログボリュームをマウントするターゲットホストから、外部アーカイブログの場所を指定します。ターゲットサーバの Oracle 所有者がオンプレミスの本番サーバと異なる場合は、アーカイブログディレクトリがターゲットサーバの Oracle 所有者によって読み取り可能であることを確認します。</block>
  <block id="6cb86841376102e5b8924f9909b8f570" category="paragraph"><block ref="6cb86841376102e5b8924f9909b8f570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70b171a9c984de6358afb3557fe84586" category="paragraph"><block ref="70b171a9c984de6358afb3557fe84586" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a752afaf144d06159ca3eec8bb23455f" category="list-text">必要に応じて、 SMTP サーバに E メール通知を設定します。</block>
  <block id="b30b70196320d22207ea0d5d95d2c841" category="paragraph"><block ref="b30b70196320d22207ea0d5d95d2c841" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0421be6f676ac1ddace9e39eeeb54f0f" category="list-text">クローンの概要：</block>
  <block id="a930a442bf914f516109fbb28bf2fbd1" category="paragraph"><block ref="a930a442bf914f516109fbb28bf2fbd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d929881b22cd699e243e2343bd707d" category="list-text">クローニング後に検証して、クローンデータベースが正常に動作することを確認する必要があります。開発 / テストデータベースでは、リスナーの起動や DB ログアーカイブモードのオフなどのいくつかの追加タスクを実行できます。</block>
  <block id="9991775de6f914e5a41601ba523e3193" category="paragraph"><block ref="9991775de6f914e5a41601ba523e3193" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58732c8d9b1293bb6666ef2284840fd3" category="section-title">レプリケートされた Snapshot バックアップから、開発 / テスト用の SQL データベースをクローニングします</block>
  <block id="605f2bb9d099f78e26260848db117df7" category="list-text">SQL Server 用のデータベース管理ユーザ ID で SnapCenter にログインします。[ リソース ] タブに移動します。このタブには、 SnapCenter によって保護されている SQL Server ユーザーデータベースとパブリッククラウド内のターゲットスタンバイ SQL インスタンスが表示されます。</block>
  <block id="d238acd8e02d4df70c9b55828a4b8801" category="paragraph"><block ref="d238acd8e02d4df70c9b55828a4b8801" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39c34a717e197c67b1fc8d678db5815b" category="list-text">バックアップトポロジおよび詳細ビューで使用するオンプレミス SQL Server ユーザデータベース名をクリックします。セカンダリでレプリケートされた場所が有効になっている場合は、リンクされたミラーバックアップが表示されます。</block>
  <block id="8c57a9d29ca9640330e03e6edca2b6e5" category="paragraph"><block ref="8c57a9d29ca9640330e03e6edca2b6e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a5910fa5df5b6482c00b15ae683eef0f" category="list-text">ミラーバックアップをクリックして、ミラーバックアップビューに切り替えます。セカンダリミラーバックアップが表示されます。SnapCenter では SQL Server トランザクションログがリカバリ専用のドライブにバックアップされるため、ここにはフルデータベースバックアップのみが表示されます。</block>
  <block id="f8d3ed6786c765a87cec8464a574076a" category="paragraph"><block ref="f8d3ed6786c765a87cec8464a574076a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="368014bae8201ab49d2207a53c907069" category="list-text">バックアップコピーを選択し、 [ クローン ] ボタンをクリックして、 [ バックアップからクローン ] ワークフローを起動します。</block>
  <block id="87dbbaf733c71b9d4e0027ad4a85e709" category="paragraph"><block ref="87dbbaf733c71b9d4e0027ad4a85e709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75c22c861d423e3f3450da18d56f0599" category="paragraph"><block ref="75c22c861d423e3f3450da18d56f0599" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44258030a87117191bde6d62511ddb9a" category="list-text">ターゲットクローンサーバとしてクラウドサーバを選択し、クローンインスタンス名を指定し、クローンデータベース名を指定します。自動割り当てマウントポイントまたはユーザ定義のマウントポイントパスを選択します。</block>
  <block id="7841eed97c9a860bcb6a46b08ea08c11" category="paragraph"><block ref="7841eed97c9a860bcb6a46b08ea08c11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18145dc97ae06034ae9aafa8b98cb36e" category="list-text">リカバリポイントは、ログのバックアップ時刻または特定の日時を基準に決定します。</block>
  <block id="b2798123b4d42e447362355b510a424c" category="paragraph"><block ref="b2798123b4d42e447362355b510a424c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b9becceddf802cada91d9e2aa84ac5a" category="list-text">クローニング処理の前後に実行するオプションのスクリプトを指定します。</block>
  <block id="adee0219db450497bd0f545df8d862c7" category="paragraph"><block ref="adee0219db450497bd0f545df8d862c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e41b01ffd717fd3d0b5788e608e50b52" category="list-text">E メール通知が必要な場合は、 SMTP サーバを設定します。</block>
  <block id="9b758c550d5da3ecb44f04ae804293d4" category="paragraph"><block ref="9b758c550d5da3ecb44f04ae804293d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc89ae2ec0203249b8e60785a63ca258" category="list-text">クローンの概要。</block>
  <block id="ab74d2d908acf5c3e01544cd4b871b73" category="paragraph"><block ref="ab74d2d908acf5c3e01544cd4b871b73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28725828580a55d904e8b2a39f377eb9" category="list-text">ジョブステータスを監視し、目的のユーザデータベースがクラウドクローンサーバのターゲット SQL インスタンスに接続されていることを確認します。</block>
  <block id="766259946fc034002a24d5f23655c73e" category="paragraph"><block ref="766259946fc034002a24d5f23655c73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d512bf68b17268adfe539f9722d869b4" category="section-title">クローン後の設定</block>
  <block id="50d9180ea26c89fbe6506d71d81d3fb1" category="list-text">通常、オンプレミスの Oracle 本番データベースはログアーカイブモードで実行されます。このモードは、開発データベースやテストデータベースには必要ありません。ログアーカイブモードをオフにするには、 Oracle DB に sysdba でログインし、ログモード変更コマンドを実行して、データベースにアクセスできるようにします。</block>
  <block id="b205237d51ff9525496f4b2252942213" category="list-text">Oracle リスナーを設定するか、新しくクローニングされた DB をユーザアクセス用の既存のリスナーに登録します。</block>
  <block id="800699a04cdaa75b2219988799b0a048" category="list-text">SQL Server の場合は、ログボリュームがいっぱいになったときに SQL Server 開発 / テストログファイルを簡単に縮小できるように、ログモードを「 Full 」から「 Easy 」に変更します。</block>
  <block id="89e018d207fd292a4926870904035c18" category="section-title">クローンデータベースをリフレッシュします</block>
  <block id="d84550ba9a340ebf4fa6698dff5ba344" category="list-text">クローニングされたデータベースを削除し、クラウド DB サーバ環境をクリーンアップします。次に、前の手順に従って、新しいデータで新しい DB のクローンを作成します。新しいデータベースのクローニングには数分しかかかりません。</block>
  <block id="1170d6f09309cb8dc382034a34680937" category="inline-link-macro">クローンをリフレッシュします</block>
  <block id="fef062eeb7771b01e620bb2460b1bf9a" category="list-text">クローンデータベースをシャットダウンし、 CLI を使用してクローン更新コマンドを実行します。詳細については、次の SnapCenter のドキュメントを参照してください。 <block ref="1e4035dee07650c706f8f0714c384872" category="inline-link-macro-rx"></block>。</block>
  <block id="2d6962c20ba37b34437afc30e6838e0d" category="inline-link-macro">ネットアップの解決策自動化コミュニティでは、余裕期間のチャネルがサポートさ</block>
  <block id="7b88d7d11804db6b079e226a6f043ea7" category="paragraph">この解決策やユースケースに関するサポートが必要な場合は、に参加してください <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> また、ソリューション自動化チャネルを検索して、質問や問い合わせを投稿しましょう。</block>
  <block id="e2a76301a4117f21d6192304aa650018" category="inline-link-macro">次：ディザスタリカバリのワークフロー</block>
  <block id="28a87ee64d4675e6c24cd960fe71d9bf" category="paragraph"><block ref="28a87ee64d4675e6c24cd960fe71d9bf" category="inline-link-macro-rx"></block></block>
  <block id="d83342bb55cac062a4841a3b7a62a7fd" category="summary">ここでは、前のセクションで概説した前提条件を満たすために完了しておく必要がある作業の概要を示します。次のセクションでは、オンプレミスとパブリッククラウドの両方の運用に関するタスクの概要を説明します。関連リンクをクリックすると、詳細なプロセスと手順にアクセスできます。</block>
  <block id="21475c5fe4cf73cfbf7756ed71e43375" category="doc">概要の確認</block>
  <block id="fa952e93a2f3bc19270cbedd1510f523" category="inline-link-macro">前のバージョン：パブリッククラウドの前提条件</block>
  <block id="f50eb88fd106752cf99e25d4a7259bb7" category="paragraph"><block ref="f50eb88fd106752cf99e25d4a7259bb7" category="inline-link-macro-rx"></block></block>
  <block id="b2e7ae8381268c9d97dc3576aa67da04" category="list-text">SnapCenter でデータベース管理ユーザを設定します</block>
  <block id="e1c4efcd7b5b155c8a6e57d348b6c071" category="list-text">SnapCenter プラグインのインストールの前提条件</block>
  <block id="cf69df8da81eda7b468d606f3e9aff06" category="list-text">SnapCenter ホストプラグインのインストール</block>
  <block id="2a6faa57bc6cc0f7a4c90cebd5e63344" category="list-text">DB リソースの検出</block>
  <block id="2a36af746a3cc41f6964edac717b5206" category="list-text">ストレージクラスタピアリングと DB ボリュームレプリケーションをセットアップします</block>
  <block id="a227a5da83d0a04e6e8e7e76a89eba09" category="list-text">CVO データベースストレージの SVM を SnapCenter に追加してください</block>
  <block id="c615eed91e2ab578525394d0ff0138d9" category="list-text">SnapCenter でデータベースバックアップポリシーを設定する</block>
  <block id="8ecb914dad4186dafb38268be6fc8a1f" category="list-text">データベースを保護するためのバックアップポリシーを実装する</block>
  <block id="3041fe5faf49efefd030e278790b4faf" category="list-text">バックアップを検証</block>
  <block id="8a3f037eef48de78bfe13d14e3d7cdfa" category="section-title">AWS パブリッククラウド</block>
  <block id="0bcf61b20ebca1ef90cb7982284867a6" category="list-text">フライト前チェック</block>
  <block id="c27b238e54d27696cafed4684c6f1335" category="list-text">AWS に Cloud Manager と Cloud Volumes ONTAP を導入する手順</block>
  <block id="2bb50575568fc6429e2c1cef751d40f4" category="list-text">データベースワークロードの EC2 コンピューティングインスタンスを導入します</block>
  <block id="bc2dcb446bec0ecd131a2e612dbd1ecd" category="paragraph">詳細については、次のリンクをクリックしてください。</block>
  <block id="7146594a919f2b006b1b0911c7b6d7da" category="inline-link-macro">オンプレミス</block>
  <block id="21aa279d0a145dcaab5feaa02df2c02a" category="inline-link-macro">パブリッククラウド - AWS</block>
  <block id="fd0476c0c92270df2d75402a67cfe0f4" category="paragraph"><block ref="8f0e2d08c6bad9ef491c2061921b9d90" category="inline-link-macro-rx"></block>、 <block ref="11145243f1982fd305768240bff5daad" category="inline-link-macro-rx"></block></block>
  <block id="ff9d8653752bd48bb6b73cf97f207af1" category="summary">SnapCenter DR ワークフローによるハイブリッドクラウドデータベースソリューション</block>
  <block id="ac2e8778240cb518ee14b1defbf55765" category="doc">ディザスタリカバリワークフロー</block>
  <block id="461887ca64f2d60da58c130a00656a96" category="inline-link-macro">前の手順：クラウドへの開発 / テストバーストのワークフロー</block>
  <block id="b8499237e1a42a05b5306219f80b35ba" category="paragraph"><block ref="b8499237e1a42a05b5306219f80b35ba" category="inline-link-macro-rx"></block></block>
  <block id="8e84608bd62584b2f262d60fd734714f" category="paragraph">企業はパブリッククラウドを、ディザスタリカバリの実現可能なリソースとして活用してきました。SnapCenter は、このプロセスを可能な限りシームレスに実行します。このディザスタリカバリワークフローはクローニングワークフローと非常によく似ていますが、データベースリカバリは、クラウドにレプリケートされた最後の使用可能なログまで実行され、可能なすべてのビジネストランザクションをリカバリします。ただし、ディザスタリカバリに固有の、設定前の手順と設定後の手順がほかにもあります。</block>
  <block id="e230d95c57c5534b3e90b93fddbcb1c9" category="section-title">オンプレミスの Oracle 本番 DB を、 DR 用にクラウドへクローニング</block>
  <block id="db9517755259859dbae095126c803544" category="list-text">クローンリカバリが最後に使用可能なログで実行されるかどうかを検証するために、小さなテストテーブルを作成して行を挿入しました。テストデータは、使用可能な最後のログへの完全リカバリ後にリカバリされます。</block>
  <block id="39f00f2f1a95739a075844dcffac1441" category="paragraph"><block ref="39f00f2f1a95739a075844dcffac1441" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fd1337293be82f7472d90bc35f51e90" category="list-text">Oracle のデータベース管理ユーザ ID として SnapCenter にログインします。リソースタブに移動します。このタブには、 SnapCenter で保護されている Oracle データベースが表示されます。</block>
  <block id="1ddb1f7854ac534473544de627fc5289" category="paragraph"><block ref="1ddb1f7854ac534473544de627fc5289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e795ef17ab8e08159909afe558c32a1c" category="list-text">Oracle ログリソースグループを選択し、 Backup Now （今すぐバックアップ）をクリックして Oracle ログバックアップを手動で実行し、最新のトランザクションをクラウド内のデスティネーションにフラッシュします。実際の DR シナリオでは、最後にリカバリ可能なトランザクションはデータベースログボリュームからクラウドへのレプリケーション頻度によって異なり、クラウドへのレプリケーションは企業の RTO ポリシーまたは RPO ポリシーによって異なります。</block>
  <block id="e3ea77c81b6559a6984aee62074951ec" category="paragraph"><block ref="e3ea77c81b6559a6984aee62074951ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44d1c907c1d5302eb896d76cae9b5e7f" category="paragraph"><block ref="44d1c907c1d5302eb896d76cae9b5e7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d77575716b9cd49ab1453e367c405abe" category="admonition">非同期 SnapMirror では、ディザスタリカバリシナリオでクラウドデスティネーションにしていないデータは失われます。これは、データベースログのバックアップ間隔で行われます。データ損失を最小限に抑えるため、ログバックアップの頻度を増やすようにスケジュールを設定できます。ただし、技術的には、ログのバックアップ頻度に制限があります。</block>
  <block id="c684c2587fa959f3df40953faab1c1a1" category="list-text">セカンダリ・ミラー・バックアップで最後のログ・バックアップを選択し、ログ・バックアップをマウントします。</block>
  <block id="4d27921136b62a393650eec8f38c5a39" category="paragraph"><block ref="4d27921136b62a393650eec8f38c5a39" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6784de36878125b88feb4c3192d2aa3d" category="paragraph"><block ref="6784de36878125b88feb4c3192d2aa3d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fbfa0a2a63c1090863dedb14664d443c" category="list-text">最後のフルデータベースバックアップを選択し、 Clone をクリックしてクローンワークフローを開始します。</block>
  <block id="ecafa568fe2f36fee38130d0f80eeafc" category="paragraph"><block ref="ecafa568fe2f36fee38130d0f80eeafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3aa765536eeb5bd55823afbb43c9efdc" category="list-text">ホスト上で一意のクローン DB ID を選択します。</block>
  <block id="6d4d1ea488e25d46cd7824491f3f98fb" category="paragraph"><block ref="6d4d1ea488e25d46cd7824491f3f98fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d57d235b31b66e982ae6d433fa33948e" category="list-text">ログボリュームをプロビジョニングし、 Oracle フラッシュリカバリ領域とオンラインログのターゲット DR サーバにマウントします。</block>
  <block id="4ef6ef644cc7510226d8d150ce9cfe73" category="paragraph"><block ref="4ef6ef644cc7510226d8d150ce9cfe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d5730b3167534121e5ac4fcdf84cf1f" category="paragraph"><block ref="4d5730b3167534121e5ac4fcdf84cf1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6142419cbd2b279a240db52011ea3cab" category="admonition">Oracle クローン手順はログボリュームを作成しないため、クローニングを実行する前に DR サーバでプロビジョニングする必要があります。</block>
  <block id="b20da77a777ef0a84d95f447b254387c" category="list-text">ターゲットのクローンホストと、データファイル、制御ファイル、および REDO ログを配置する場所を選択します。</block>
  <block id="326062662ffdb461c61b5ddfc54974bc" category="paragraph"><block ref="326062662ffdb461c61b5ddfc54974bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b126b14adfdc04f12e6a00531155f4a" category="list-text">クローンのクレデンシャルを選択します。ターゲット・サーバの Oracle ホーム構成の詳細を入力します</block>
  <block id="ee4a9d80953ee6db29e5577ef13327ba" category="paragraph"><block ref="ee4a9d80953ee6db29e5577ef13327ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c76f59dc52686a71eb5917bbcabfa212" category="list-text">クローニングの前に実行するスクリプトを指定します。データベースパラメータは必要に応じて調整できます。</block>
  <block id="31b131b08153ae34a96d1e17fa891e1f" category="paragraph"><block ref="31b131b08153ae34a96d1e17fa891e1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7018f70f78c5e3154b2620e31167c12e" category="list-text">リカバリオプションとして Until Cancel を選択して、使用可能なすべてのアーカイブログをリカバリで実行し、セカンダリクラウドの場所に最後にレプリケートされたトランザクションをリカバリします。</block>
  <block id="57fa7fef5a8266470204775391a701d3" category="paragraph"><block ref="57fa7fef5a8266470204775391a701d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6233d74c8f9820a1029624d60ab66049" category="list-text">必要に応じて、 SMTP サーバで E メール通知を設定します。</block>
  <block id="a563132424d4d3d255697521a0446bc9" category="paragraph"><block ref="a563132424d4d3d255697521a0446bc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0cd00abfa258b121d480ce7d27e63" category="list-text">DR クローンの概要：</block>
  <block id="0f66818ccf8a8dd3d6491b9bcf74c02e" category="paragraph"><block ref="0f66818ccf8a8dd3d6491b9bcf74c02e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4ff014e6bff5ee06349d607c14fcf9e" category="list-text">クローニングされた DB は、クローンの完了直後に SnapCenter に登録され、バックアップ保護に使用できます。</block>
  <block id="18eac7477ab0c6038ec443444677a1eb" category="paragraph"><block ref="18eac7477ab0c6038ec443444677a1eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22d74aee547ad10d104f875521cfa6d7" category="section-title">Oracle の DR クローンの検証と設定後の POST コマンドです</block>
  <block id="9d58cce71d4c85948ccecfea105367ed" category="list-text">クラウドの DR サイトでフラッシュ、レプリケート、リカバリされた最後のテストトランザクションを検証します。</block>
  <block id="1db3ba1f62cbb82a66232de851bad3ce" category="paragraph"><block ref="1db3ba1f62cbb82a66232de851bad3ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61b3573abc722a493f53ed27503f7eff" category="list-text">フラッシュリカバリ領域を設定します。</block>
  <block id="71ca9fe67f8c3826e171fb227af4f666" category="paragraph"><block ref="71ca9fe67f8c3826e171fb227af4f666" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4005d553f013abc53c6a1a65aed1d65f" category="list-text">ユーザアクセス用に Oracle リスナーを設定します。</block>
  <block id="0c79c2a9e4fd1ea908a63d58f1f44917" category="list-text">レプリケートされたソースボリュームからクローンボリュームをスプリットします。</block>
  <block id="42e82bb35283d9f2e2b444419f518667" category="list-text">クラウドからオンプレミスへの逆レプリケーションを行い、障害が発生したオンプレミスデータベースサーバを再構築します。</block>
  <block id="4ce2420dd00dd0b543e2e51bf7c1c135" category="admonition">クローンスプリットでは、一時的にストレージスペースが利用され、通常の処理よりもはるかに高くなる場合があります。ただし、オンプレミスの DB サーバを再構築すると、追加スペースを解放できるようになります。</block>
  <block id="0e70133bb418f4025b82a6a35301e209" category="section-title">オンプレミスの SQL 本番 DB を DR 用のクラウドにクローニング</block>
  <block id="32bfa00a92b9f85d791a43f6d70a35cd" category="list-text">同様に、 SQL クローンリカバリが前回使用可能なログを通過したかどうかを検証するために、小さなテストテーブルを作成して行を挿入しました。テストデータは、使用可能な最後のログへのフルリカバリ後にリカバリされます。</block>
  <block id="321bd96e83b00fcd04bfcc72ec4564ff" category="paragraph"><block ref="321bd96e83b00fcd04bfcc72ec4564ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3b7f1fcf93afdd055ec19e230b54347" category="list-text">SQL Server 用のデータベース管理ユーザ ID で SnapCenter にログインします。[ リソース ] タブに移動します。このタブには、 SQL Server 保護リソースグループが表示されます。</block>
  <block id="c9673e38d22c239c3b46259620b7b190" category="paragraph"><block ref="c9673e38d22c239c3b46259620b7b190" category="inline-image-macro-rx" type="image"></block></block>
  <block id="608bfa3334f97023b71f6b7a04742bd6" category="list-text">パブリッククラウドのセカンダリストレージにレプリケートする最後のトランザクションをフラッシュするには、ログバックアップを手動で実行します。</block>
  <block id="94ca8d0daf1445cae1bbc5a13d7b0c42" category="paragraph"><block ref="94ca8d0daf1445cae1bbc5a13d7b0c42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b9ced1d8d8e91eb2606cb7d0932fa4" category="list-text">クローンに対して最後に実行した SQL Server のフルバックアップを選択します。</block>
  <block id="f93fa51d605a26ef233b6fb9c5489266" category="paragraph"><block ref="f93fa51d605a26ef233b6fb9c5489266" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82efcc579f2220a65dbe5cdd64f47253" category="list-text">クローンサーバ、クローンインスタンス、クローン名、マウントオプションなどのクローン設定を行います。クローニングが実行されるセカンダリストレージの場所が自動的に入力されます。</block>
  <block id="bb5bdefa03845f9483d1e3fcf8d3b40f" category="paragraph"><block ref="bb5bdefa03845f9483d1e3fcf8d3b40f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d84ecf0ed314694d6e3ad9b2a96a198" category="list-text">適用するすべてのログバックアップを選択します。</block>
  <block id="79284af3915a1bc3e4d4d3993acd9042" category="paragraph"><block ref="79284af3915a1bc3e4d4d3993acd9042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f68fbd76be71ebe267aa207f7bef25f" category="list-text">クローニングの前後に実行するオプションのスクリプトを指定します。</block>
  <block id="1f29cf99c49ef1910181e451424c3796" category="paragraph"><block ref="1f29cf99c49ef1910181e451424c3796" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ac43ede08a0b7154673a619b979f17d" category="list-text">E メール通知が必要な場合は、 SMTP サーバを指定します。</block>
  <block id="e8aa5b543b67c22f0a2a205562794787" category="paragraph"><block ref="e8aa5b543b67c22f0a2a205562794787" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7338d3af995c4a281de85493129cc18" category="list-text">DR クローンの概要：クローニングされたデータベースはただちに SnapCenter に登録され、バックアップ保護に使用できます。</block>
  <block id="332fb27e1cc349fc79252fbfc5de6ad0" category="paragraph"><block ref="332fb27e1cc349fc79252fbfc5de6ad0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8be7490bb89f986a83768e6a71d78ee8" category="paragraph"><block ref="8be7490bb89f986a83768e6a71d78ee8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f01a56e31a650c5bb83408b5238270e" category="section-title">DR による SQL のクローン検証後の構成</block>
  <block id="029640b7bf09578f05703e407e99b8d7" category="list-text">クローニングジョブのステータスを監視する。</block>
  <block id="d5f350d5580b71105a1718557ce88137" category="paragraph"><block ref="d5f350d5580b71105a1718557ce88137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68236fcee9bee8dbdc1c54b7b2d84b34" category="list-text">すべてのログファイルクローンとリカバリで、最後のトランザクションがレプリケートされてリカバリされたことを確認します。</block>
  <block id="3ebb58ab28579acf2742808bf95fc07e" category="paragraph"><block ref="3ebb58ab28579acf2742808bf95fc07e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50159c53d6f87eb33c314abd9f0bd28f" category="list-text">DR サーバで、 SQL Server ログバックアップ用の新しい SnapCenter ログディレクトリを設定します。</block>
  <block id="50f8c30e062c542679b96127a844db6a" category="paragraph">この解決策やユースケースに関するサポートが必要な場合は、にご参加ください <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> また、ソリューション自動化チャネルを検索して、質問や問い合わせを投稿しましょう。</block>
  <block id="467bda78c0e1adcc5ed650843fbfbdf5" category="summary">このセクションでは、 AWS に Cloud Manager と Cloud Volumes ONTAP を導入するプロセスについて説明します。</block>
  <block id="298a4809d5445df75b6c4a9fb94074a4" category="doc">AWS パブリッククラウドの導入</block>
  <block id="b8f5ff8c1ae69fa5befe459d3f34b68a" category="inline-link-macro">前の手順：オンプレミスでの作業の開始</block>
  <block id="19f84106226ff97c314f55dd621bbd98" category="paragraph"><block ref="19f84106226ff97c314f55dd621bbd98" category="inline-link-macro-rx"></block></block>
  <block id="87aa698992e009d04733c9906225592c" category="admonition">作業を簡単に進めるために、 AWS への導入に基づいて本ドキュメントを作成しました。ただし、 Azure と GCP の場合もプロセスはほぼ同じです。</block>
  <block id="39845311263ccad04c0d4f0b9aa9d4c6" category="section-title">1. 事前フライトチェック</block>
  <block id="12ed93944854c12caa37886d620f16db" category="paragraph">導入前に、次の段階で導入できるようにインフラが設置されていることを確認してください。これには次のものが含まれます。</block>
  <block id="c6368ae044df0f7bb26ed60afda5c591" category="list-text">AWS アカウント</block>
  <block id="4019c185756035c18c03fabfccd7d4b2" category="list-text">選択した地域の VPC</block>
  <block id="fca5d2fece6e360f78dff4573ba04a20" category="list-text">パブリックインターネットにアクセスできるサブネット</block>
  <block id="e3e5c3dadc3e70d536645a3be9744f79" category="list-text">AWS アカウントに IAM ロールを追加する権限</block>
  <block id="bd5c82fb0e0371a168f609848b11e92a" category="list-text">AWS ユーザのシークレットキーとアクセスキー</block>
  <block id="c3d1ff3c88148b2246bb0972916da82a" category="section-title">2. AWS に Cloud Manager と Cloud Volumes ONTAP を導入する手順</block>
  <block id="6d0eb695a99109617b806676e9610075" category="inline-link">ネットアップのクラウドに関するドキュメント</block>
  <block id="593581e466784760a050bceaea5e0c48" category="admonition">Cloud Manager と Cloud Volumes ONTAP を導入する方法は多数あります。最もシンプルですが、最も多くの権限が必要です。お使いの AWS 環境にこの方法が適していない場合は、を参照してください<block ref="97a20614f8c0e53f461a9353634e5e51" category="inline-link-rx"></block>。</block>
  <block id="bb3e779fdf877143137572122cf424e3" category="section-title">Cloud Manager Connector を導入します</block>
  <block id="4c6e32ff373dc3ce5b49202f92f01b08" category="list-text">に移動します<block ref="143fea272f01f72dbdc942451156df21" category="inline-link-rx"></block> ログインまたはサインアップします。</block>
  <block id="356cf5e12d635c19d987b1b195ff5a40" category="paragraph"><block ref="356cf5e12d635c19d987b1b195ff5a40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2300b8579a8761e452d89a2af6636b7d" category="list-text">ログイン後、キャンバスに移動します。</block>
  <block id="af93b0b88e1db5f3aa229d2336fedb3c" category="paragraph"><block ref="af93b0b88e1db5f3aa229d2336fedb3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3fbf2c408ce86ff3403990e7e32dcb3" category="list-text">「 Add Working Environment 」をクリックし、「 Cloud Volumes ONTAP in AWS 」を選択します。ここでは、シングルノードシステムとハイアベイラビリティペアのどちらを導入するかを選択することもできます。ハイアベイラビリティペアを導入することを選択しました。</block>
  <block id="bb18ff1ebac7ea2039aa297469c76b76" category="paragraph"><block ref="bb18ff1ebac7ea2039aa297469c76b76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="016aa0c0a7322975ec4b8eeac805f2c0" category="list-text">コネクタが作成されていない場合は、コネクタの作成を求めるポップアップが表示されます。</block>
  <block id="a05691eb0d806668c3796d3d6fe01157" category="paragraph"><block ref="a05691eb0d806668c3796d3d6fe01157" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fc3362a0d8ab63cc8fa21bbd0fb07db" category="list-text">[ 開始 ] をクリックし、 [AWS] を選択します。</block>
  <block id="55f5adc74d49945abd7798742f307124" category="paragraph"><block ref="55f5adc74d49945abd7798742f307124" category="inline-image-macro-rx" type="image"></block></block>
  <block id="deae4c054bb3102bbf634b14534da9bf" category="inline-link">ネットアップのポリシーのページ</block>
  <block id="651d429a2b6cfcd93f6adb1d4825a214" category="list-text">シークレットキーとアクセスキーを入力します。ユーザに、で概説されている正しい権限があることを確認します<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block>。</block>
  <block id="94497191b0b0c6d05a2df7d2175e87f5" category="paragraph"><block ref="94497191b0b0c6d05a2df7d2175e87f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d59b60a74630e45f83fd3c48207b47" category="list-text">コネクタに名前を付け、の説明に従って事前定義されたロールを使用する<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block> または、 Cloud Manager にロールの作成を依頼してください。</block>
  <block id="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="paragraph"><block ref="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02d395705fb063ad8d33d8c83c856e6f" category="list-text">コネクタの導入に必要なネットワーク情報を入力します。アウトバウンドインターネットアクセスが有効になっていることを確認します。</block>
  <block id="8215126360cbe5d8f5566c7ffc8cf224" category="list-text">コネクタにパブリック IP アドレスを割り当てます</block>
  <block id="22adb619c008bfd7495288573093ae44" category="list-text">コネクタにプロキシを与える</block>
  <block id="58a149795bbe86e4e0d4ab8f10413219" category="list-text">インターネットゲートウェイを経由してインターネットに接続するためのルートをコネクタに与える</block>
  <block id="5908ad1cf5bd748238e305dd5fc52fac" category="paragraph"><block ref="5908ad1cf5bd748238e305dd5fc52fac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c58ebc9f032dc8d2e5c4f522cedbe0b" category="list-text">セキュリティグループを提供するか、新しいセキュリティグループを作成して、 SSH 、 HTTP 、および HTTPS 経由でコネクタと通信する。IP アドレスからのみコネクタへのアクセスを有効にしました。</block>
  <block id="1d39d9c13f50dd25f7e54173c87c633a" category="paragraph"><block ref="1d39d9c13f50dd25f7e54173c87c633a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb444cfaba774437ecdbbb95856d94cd" category="list-text">概要ページの情報を確認し、追加をクリックしてコネクタを配置します。</block>
  <block id="5576df68e3720f55e585e7e091d5b9e3" category="paragraph"><block ref="5576df68e3720f55e585e7e091d5b9e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4255ace47c9ad7f2907c18df7512bb9f" category="list-text">コネクタがクラウド形成スタックを使用して導入されるようになりました。進捗状況は Cloud Manager または AWS から監視できます。</block>
  <block id="ff7fb4bedc0d09880f85d9745ec258a5" category="paragraph"><block ref="ff7fb4bedc0d09880f85d9745ec258a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca320cc147e2b9fac2dd7379e91012b6" category="list-text">導入が完了すると、成功ページが表示されます。</block>
  <block id="f5bbadf1ed57058e80e27764684e6314" category="paragraph"><block ref="f5bbadf1ed57058e80e27764684e6314" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6382283fd45b13b5c983745731fec990" category="section-title">Cloud Volumes ONTAP を導入します</block>
  <block id="5fe90897c7135ba3020c4a397f55adb6" category="list-text">AWS と、それぞれの要件に応じた導入タイプを選択します。</block>
  <block id="63b636f2002a2e7b7c2e2420cd64ff73" category="paragraph"><block ref="63b636f2002a2e7b7c2e2420cd64ff73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf1300c5621fdebe8c1a70fade44f3b" category="list-text">サブスクリプションが割り当てられておらず、 PAYGO で購入する場合は、資格情報の編集を選択します。</block>
  <block id="b893bded7e1bd3419a443758a8ef410f" category="paragraph"><block ref="b893bded7e1bd3419a443758a8ef410f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88eb84b1a8f0417c9de6e1202125df56" category="list-text">[Add Subscription] を選択します。</block>
  <block id="0b5d3e3d1a9347ff4a7395d09208a8f4" category="paragraph"><block ref="0b5d3e3d1a9347ff4a7395d09208a8f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="052208bafdfe08bc8f0735a78226e541" category="list-text">購読する契約のタイプを選択します。従量課金制を選択しました。</block>
  <block id="4d5ab1ed0682fe644e831558598d4638" category="paragraph"><block ref="4d5ab1ed0682fe644e831558598d4638" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65577508f7897e730adb501d0db73913" category="list-text">AWS にリダイレクトされます。 Continue to Subscribe を選択します。</block>
  <block id="ac33260d1e06f504f1dcac229aeb269c" category="paragraph"><block ref="ac33260d1e06f504f1dcac229aeb269c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="439c4fb23c120f0a99894c630cedaabd" category="list-text">登録すると、 NetApp Cloud Central にリダイレクトされます。すでに購読していてリダイレクトされていない場合は、「ここをクリック」リンクを選択します。</block>
  <block id="a90c8b1fc04a41aff490fd2b269f5932" category="paragraph"><block ref="a90c8b1fc04a41aff490fd2b269f5932" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14b9e98d2b57da92c29826ce7de32c32" category="list-text">Cloud Central にリダイレクトされます。ここで、サブスクリプションの名前を指定して、 Cloud Central アカウントに割り当てる必要があります。</block>
  <block id="c89376fd9624f6ebda7959df6176ef34" category="paragraph"><block ref="c89376fd9624f6ebda7959df6176ef34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4508f5994d1b34ff85cd1e8a1884d6c1" category="list-text">成功すると、チェックマークページが表示されます。Cloud Manager のタブに戻ります。</block>
  <block id="2b206bbd8f3b20e3282b660a356d90be" category="paragraph"><block ref="2b206bbd8f3b20e3282b660a356d90be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3294e5fb9ec1c42cde7ebf9b206c583" category="list-text">サブスクリプションが Cloud Central に表示されます。[ 適用 ] をクリックして続行します。</block>
  <block id="37ce5c33a55d907edabe632c39a2707c" category="paragraph"><block ref="37ce5c33a55d907edabe632c39a2707c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7927b068a5dddb4852b2e7dc256544" category="list-text">次のような作業環境の詳細を入力します。</block>
  <block id="0dbae4d42c7a0db53e2eb32adee12892" category="list-text">クラスタ名</block>
  <block id="0c191ee206a91460fd94e2ff976a38e7" category="list-text">クラスタのパスワード</block>
  <block id="53aa18427d1e2c7b7113c668561a62d2" category="list-text">AWS のタグ（オプション）</block>
  <block id="d3b6ff1e8c6317d132d3a5e974f1374c" category="paragraph"><block ref="d3b6ff1e8c6317d132d3a5e974f1374c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fb5b261ae3a3581304a283ef70a5246" category="inline-link">ネットアップクラウドのホームページ</block>
  <block id="e7b29c75e71a48483734401322ef6e92" category="list-text">導入する追加サービスを選択します。これらのサービスの詳細については、を参照してください<block ref="1bb1213784e04e4f47d06f252d1ba164" category="inline-link-rx"></block>。</block>
  <block id="88e71a2c19d98c79d2ed51a753c8a4c2" category="paragraph"><block ref="88e71a2c19d98c79d2ed51a753c8a4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0dffa77d5644a3816ba69e24ce813ff" category="list-text">複数のアベイラビリティゾーンに導入する（ 3 つのサブネットをそれぞれ異なる AZ に配置する）か、単一のアベイラビリティゾーンに導入するかを選択します。複数の AZ を選択しました。</block>
  <block id="6e4a3fe2b0629dae504d8e727147f709" category="paragraph"><block ref="6e4a3fe2b0629dae504d8e727147f709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b889b7255c34e7f230e392668605860" category="list-text">導入先のクラスタのリージョン、 VPC 、およびセキュリティグループを選択します。このセクションでは、ノード（およびメディエーター）ごとのアベイラビリティゾーンと、ゾーンが占有しているサブネットも割り当てます。</block>
  <block id="9ad68c9f72863557931a8569462bff52" category="paragraph"><block ref="9ad68c9f72863557931a8569462bff52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be43ebbf5380089f153e4f1b13e35e6f" category="list-text">メディエーターとともにノードの接続方法を選択します。</block>
  <block id="8bf6da8b537127466c4421c1ae3169be" category="paragraph"><block ref="8bf6da8b537127466c4421c1ae3169be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="204bd52e1d13052712299779cf041df6" category="admonition">メディエーターは AWS API との通信を必要とします。メディエーター EC2 インスタンスを導入したあとで API にアクセスできる場合は、パブリック IP アドレスは必要ありません。</block>
  <block id="52fade87431f9acc43b7bf6e4c5fd2f1" category="inline-link">ネットアップのクラウドに関するドキュメント</block>
  <block id="0c79e4a46253eeb94ba6b8218928aa99" category="list-text">フローティング IP アドレスは、クラスタ管理 IP やデータサービス IP など、 Cloud Volumes ONTAP で使用されるさまざまな IP アドレスへのアクセスを許可するために使用されます。これらのアドレスは、ネットワーク内でルーティングされていないアドレスである必要があり、 AWS 環境のルーティングテーブルに追加されます。これらのアドレスは、フェイルオーバー時に HA ペアの一貫した IP アドレスを有効にするために必要です。フローティング IP アドレスの詳細については、を参照してください<block ref="72cde540b4f97efa19e071f729439801" category="inline-link-rx"></block>。</block>
  <block id="fd4a46ceddfb2402b7e37177af575e04" category="paragraph"><block ref="fd4a46ceddfb2402b7e37177af575e04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ca6b5e9b64aed9132a6be07d061f3b" category="list-text">フローティング IP アドレスが追加されるルーティングテーブルを選択します。これらのルーティングテーブルは、クライアントが Cloud Volumes ONTAP と通信するために使用します。</block>
  <block id="3453ab81a2f04d5c39ae750fb79ece2a" category="paragraph"><block ref="3453ab81a2f04d5c39ae750fb79ece2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af918e519f9c0db1ed5ab4fd4b6e9e05" category="list-text">AWS で管理する暗号化を有効にするか、 AWS KMS を有効にして ONTAP ルートディスク、ブートディスク、データディスクを暗号化するかを選択します。</block>
  <block id="058eaefa711702bd45c5f6650cf01e4c" category="paragraph"><block ref="058eaefa711702bd45c5f6650cf01e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01bd54fa77587425fca4a6c352309b5c" category="list-text">ライセンスモデルを選択します。選択する項目がわからない場合は、ネットアップの担当者にお問い合わせください。</block>
  <block id="e5e49184799594a9fa690c9122eb883e" category="paragraph"><block ref="e5e49184799594a9fa690c9122eb883e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04110b24d1459a6e21e35ad976a8f10e" category="list-text">ユースケースに最も適した構成を選択してください。これは、前提条件のページに記載されているサイジングに関する考慮事項に関連したものです。</block>
  <block id="e19584159c9c3791a9e3c462cb0aa451" category="paragraph"><block ref="e19584159c9c3791a9e3c462cb0aa451" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ed47788a525c6d08246bfa2f90922da" category="list-text">必要に応じて、ボリュームを作成します。次の手順では SnapMirror を使用してボリュームを作成するため、この作業は必要ありません。</block>
  <block id="01da9401385484b72ba9c016ac6c19ab" category="paragraph"><block ref="01da9401385484b72ba9c016ac6c19ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76011f95c4e1b3f68fa5829dab0fb786" category="list-text">選択内容を確認し、チェックボックスをオンにして、 Cloud Manager によって AWS 環境にリソースが導入されることを確認します。準備ができたら、 [ 移動 ] をクリックします。</block>
  <block id="7b78e746aa55ffe6fee1f3e0b65b8cca" category="paragraph"><block ref="7b78e746aa55ffe6fee1f3e0b65b8cca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13b7f009673a469e5482a96832be1473" category="list-text">Cloud Volumes ONTAP による導入プロセスが開始されます。Cloud Manager は、 AWS API とクラウド形成スタックを使用して Cloud Volumes ONTAP を導入します。次に、お客様の仕様に合わせてシステムを構成し、すぐに利用できるすぐに使えるシステムを提供します。このプロセスのタイミングは、選択内容によって異なります。</block>
  <block id="11d15d8a4bb9195b48d5010fa30fa547" category="paragraph"><block ref="11d15d8a4bb9195b48d5010fa30fa547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e63d2329924bb302fb012e7916b3614" category="list-text">タイムラインに移動することで進行状況を監視できます。</block>
  <block id="77405312cc4c1e96d3f7f796e838bf89" category="paragraph"><block ref="77405312cc4c1e96d3f7f796e838bf89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b4df7cc92b3ee31f5d95082a78c7903" category="list-text">タイムラインは、 Cloud Manager で実行されるすべてのアクションの監査として機能します。Cloud Manager のセットアップ時に AWS と ONTAP クラスタの両方に対して行われたすべての API 呼び出しを表示できます。これは、直面している問題のトラブルシューティングにも効果的に使用できます。</block>
  <block id="8c17e020c76595308d57605fa71dc7af" category="paragraph"><block ref="8c17e020c76595308d57605fa71dc7af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c5674ad1910f0a25455fdeb0f3f097a" category="list-text">導入が完了すると、現在の容量である Canvas に CVO クラスタが表示されます。現在の状態の ONTAP クラスタは、設定なしで真のエクスペリエンスを提供できるように完全に設定されています。</block>
  <block id="db044bc640be9fc8227b7ada891f279d" category="paragraph"><block ref="db044bc640be9fc8227b7ada891f279d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28d2e01957d5845ff59688f17bd34339" category="section-title">オンプレミスからクラウドへ SnapMirror を設定</block>
  <block id="081494b1a178710486921a42e2bdfa87" category="paragraph">ソース ONTAP システムとデスティネーション ONTAP システムが導入されたので、データベースデータを含むボリュームをクラウドにレプリケートできます。</block>
  <block id="cb3269c2496a99fb03bebe82b6a3e4bc" category="inline-link">SnapMirror Compatibility Matrix を参照してください</block>
  <block id="46aad6288d89ba29f38b4742bf018aca" category="paragraph">互換性のある SnapMirror の ONTAP バージョンに関するガイドについては、を参照してください<block ref="f75a4f2138bf92eb17ef87cad85a9e34" category="inline-link-rx"></block>。</block>
  <block id="36c5350a8474f2212fecc811eb77df57" category="list-text">ソース ONTAP システム（オンプレミス）をクリックし、宛先にドラッグアンドドロップするか、 Replication （レプリケーション） &gt; Enable （有効）を選択するか、 Replication （レプリケーション） &gt; Menu （メニュー） &gt; Replicate （複製）を選択します。</block>
  <block id="5dbe69ec28d70286f46385336e96d003" category="paragraph"><block ref="5dbe69ec28d70286f46385336e96d003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8771a8fdaa9e84a7eef7540edcca5f40" category="paragraph">Enable を選択します。</block>
  <block id="ac21962f3f0ae9f9c17b26196452f903" category="paragraph"><block ref="ac21962f3f0ae9f9c17b26196452f903" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6a8dc55f6f333187a100f6ed328bdc0" category="paragraph">または [ オプション ] を選択し</block>
  <block id="949fa0a5e194cf44c9e08903cb914566" category="paragraph"><block ref="949fa0a5e194cf44c9e08903cb914566" category="inline-image-macro-rx" type="image"></block></block>
  <block id="066bf779660ad446aa9b0d4021c4bf40" category="paragraph">レプリケート：</block>
  <block id="deafbb4908c633cb93a7f7e76b31da08" category="paragraph"><block ref="deafbb4908c633cb93a7f7e76b31da08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a803b2a55429f981d25fbb8da94aef7" category="list-text">ドラッグアンドドロップしなかった場合は、レプリケート先のクラスタを選択します。</block>
  <block id="630e74180bc1b6c0c0c866d5478ff029" category="paragraph"><block ref="630e74180bc1b6c0c0c866d5478ff029" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761124dc5e0730086556a7d33d43418c" category="list-text">レプリケートするボリュームを選択します。データとすべてのログボリュームをレプリケートしました。</block>
  <block id="7bec2596a51a0d4a808a37dec9e6c540" category="paragraph"><block ref="7bec2596a51a0d4a808a37dec9e6c540" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bde4e8497f5ecaef866c0f049aada776" category="list-text">デスティネーションのディスクタイプと階層化ポリシーを選択します。ディザスタリカバリには、ディスクタイプとして SSD を使用し、データの階層化を維持することを推奨します。データを階層化することで、ミラーリングされたデータを低コストのオブジェクトストレージに階層化し、ローカルディスクにコストを削減できます。関係を解除するかボリュームのクローンを作成すると、高速なローカルストレージがデータに使用されます。</block>
  <block id="a7d9908d0f610b3db167c894d109d1ec" category="paragraph"><block ref="a7d9908d0f610b3db167c894d109d1ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f06f2f09c024b69ef3944a8cd78ad9" category="list-text">デスティネーション・ボリューム名を選択します [source_volume_name] _dr] を選択します</block>
  <block id="6f8ba85bc89d216799431f124e48b25f" category="paragraph"><block ref="6f8ba85bc89d216799431f124e48b25f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2882a0dbc1a6ad74198ac2cb6316870d" category="list-text">レプリケーションの最大転送速度を選択します。これにより、 VPN などのクラウドへの低帯域幅接続がある場合に帯域幅を節約できます。</block>
  <block id="041263f562a9058ae414685962469951" category="paragraph"><block ref="041263f562a9058ae414685962469951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f81dd66e0f0847d4cb1d2d12fadcc2f3" category="list-text">レプリケーションポリシーを定義ミラーを選択したところ、最新のデータセットがデスティネーションボリュームにレプリケートされます。また、要件に応じて別のポリシーを選択することもできます。</block>
  <block id="d0b86e2934c870915aaa77674d1d79d7" category="paragraph"><block ref="d0b86e2934c870915aaa77674d1d79d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4db5384e8d04b01ff24a9178b3efaf6a" category="list-text">レプリケーションを開始するスケジュールを選択します。要件に応じて変更することもできますが、ネットアップでは、データボリュームの「毎日」のスケジュールとログボリュームの「時間単位」のスケジュールを設定することを推奨します。</block>
  <block id="c6715d4de4d68a1f8eb9cb8acb63b097" category="paragraph"><block ref="c6715d4de4d68a1f8eb9cb8acb63b097" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02e3a269661e3c96a86a075872a1b269" category="list-text">入力した情報を確認し、 Go をクリックしてクラスタピアと SVM ピアをトリガーし（ 2 つのクラスタ間のレプリケーションを初めて行う場合）、 SnapMirror 関係を実装して初期化します。</block>
  <block id="75c2d297cd7282b30ce0400170110307" category="paragraph"><block ref="75c2d297cd7282b30ce0400170110307" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c160366cab97ee8f1a35416d1294ddb" category="list-text">データボリュームとログボリュームについては、このプロセスを続行してください。</block>
  <block id="64853c47f4f907262466c1e5ad154c8c" category="list-text">すべての関係を確認するには、 Cloud Manager の Replication （レプリケーション）タブに移動します。ここでは、関係を管理し、その状態を確認できます。</block>
  <block id="641e620fe8c714d7381775d20a707726" category="paragraph"><block ref="641e620fe8c714d7381775d20a707726" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c88bec52f9e24233a78b6a90efa32ec6" category="list-text">すべてのボリュームがレプリケートされたあと、安定した状態になり、ディザスタリカバリと開発 / テストのワークフローに進むことができます。</block>
  <block id="86fb3ee49ae2f8c0ee121c551a8f08c2" category="section-title">3. データベースワークロードの EC2 コンピューティングインスタンスを導入します</block>
  <block id="91ba52045df2b9244f28270482f749c9" category="inline-link">EC2 インスタンスタイプ</block>
  <block id="33aaa72e62140af9cecb2c48f836b84b" category="paragraph">AWS では、さまざまなワークロードに対して EC2 コンピューティングインスタンスが事前に設定されていますインスタンスタイプの選択によって、 CPU コア数、メモリ容量、ストレージタイプと容量、およびネットワークパフォーマンスが決まります。OS パーティションを除き、データベースワークロードを実行するメインストレージは、 CVO または FSX ONTAP ストレージエンジンから割り当てられます。したがって、考慮すべき主な要因は、 CPU コア、メモリ、およびネットワークパフォーマンスレベルの選択です。一般的な AWS EC2 インスタンスタイプは次のとおりです。<block ref="9334d5b9e602c5921b4f295f6041489b" category="inline-link-rx"></block>。</block>
  <block id="0af43c3d809d6e56a6a7a0d1ed039bbc" category="section-title">コンピューティングインスタンスのサイズを決定します</block>
  <block id="0b6e77aedd6bd733f979314fef2a98d7" category="list-text">必要なワークロードに基づいて適切なインスタンスタイプを選択します。考慮すべき要因としては、サポートされるビジネストランザクションの数、同時ユーザの数、データセットのサイジングなどがあります。</block>
  <block id="c421d122321bec48d6b30858f4e7b515" category="inline-link">Amazon EC2</block>
  <block id="ed4b68006572e288530a2152f7fbe5fe" category="list-text">EC2 インスタンスの導入は、 EC2 ダッシュボードから実行できます。具体的な導入手順については、この解決策では説明していません。を参照してください<block ref="3a5862dd365e3998013717e9cf118a9a" category="inline-link-rx"></block> を参照してください。</block>
  <block id="708991723f71fa1bd7b8081be442552c" category="section-title">Oracle ワークロード向けの Linux インスタンス構成</block>
  <block id="5c17b7d75ff16063f772234e1ea8eeb1" category="paragraph">このセクションでは、 EC2 Linux インスタンスを導入したあとの追加の設定手順について説明します。</block>
  <block id="39d786446455bb2b3017b793805fc902" category="list-text">SnapCenter 管理ドメイン内で名前解決のために、 Oracle スタンバイインスタンスを DNS サーバに追加します。</block>
  <block id="385a2a4f5305fe5ce8017f18fb7eabd4" category="list-text">パスワードなしの sudo 権限で SnapCenter OS のクレデンシャルとして Linux 管理ユーザ ID を追加します。EC2 インスタンスで SSH パスワード認証を使用する ID を有効にします。（デフォルトでは、 EC2 インスタンスで SSH パスワード認証とパスワードなしの sudo は無効になっています）。</block>
  <block id="a2b4677d7a72840a78373c600441681a" category="list-text">OS パッチ、 Oracle のバージョン、パッチなど、オンプレミスの Oracle インストールと一致するように Oracle インストールを設定します。</block>
  <block id="66b65364302a847feb2630bfd7974256" category="inline-link">Oracle 19C 自動導入</block>
  <block id="fa470598a181c1ed905bace243e46aa3" category="list-text">NetApp Ansible DB 自動化ロールを使用して、データベースの開発 / テストとディザスタリカバリのユースケース用に EC2 インスタンスを設定できます。自動化コードは、 NetApp パブリックの GitHub サイトからダウンロードできます。<block ref="437f8b44ff65600fb5697e9d369a0c54" category="inline-link-rx"></block>。目的は、データベースソフトウェアスタックを EC2 インスタンスにインストールして設定し、オンプレミスの OS とデータベースの設定を一致させることです。</block>
  <block id="97875b4799caf4c948118e7b4776c9fb" category="section-title">SQL Server ワークロード用の Windows インスタンス構成</block>
  <block id="c63751cfdcf8c0b4e26635a47c7f0d97" category="paragraph">このセクションでは、 EC2 Windows インスタンスを最初に導入したあとの追加の設定手順を示します。</block>
  <block id="5f44e6a78874f9f49acae3caa71cc14d" category="list-text">RDP を使用してインスタンスにログインするには、 Windows 管理者パスワードを取得します。</block>
  <block id="eabafc642b0901afd6622ab0f19d9ef0" category="list-text">Windows ファイアウォールを無効にし、ホストを Windows SnapCenter ドメインに追加し、名前解決のために DNS サーバにインスタンスを追加します。</block>
  <block id="08bf2d7ff3ac9ab37cfa8dc449b3c8da" category="list-text">SQL Server ログファイルを格納する SnapCenter ログボリュームをプロビジョニングします。</block>
  <block id="f97ac9d1946c873247af15165559b47a" category="list-text">Windows ホストで iSCSI を構成し、ボリュームをマウントしてディスクドライブをフォーマットします。</block>
  <block id="6c2a9c611f48cae767f6ebea6fca0457" category="inline-link">NetApp の自動化</block>
  <block id="6dea6226167bd38268de4c4d948d72de" category="list-text">繰り返しになりますが、これまでのタスクの多くは、 NetApp Automation 解決策 for SQL Server を使用して自動化することができます。NetApp Automation のパブリック GitHub サイトで、新たに公開されたロールとソリューションを確認できます。<block ref="8cafb3a3b1222d318fcd262791229701" category="inline-link-rx"></block>。</block>
  <block id="752c08adf364adb2721c9a373759f8f6" category="inline-link-macro">次：クラウドへの開発 / テストバーストのワークフロー</block>
  <block id="4e3fc3c2eb04754fcac9e4e23b6de054" category="paragraph"><block ref="4e3fc3c2eb04754fcac9e4e23b6de054" category="inline-link-macro-rx"></block></block>
  <block id="ac9bef0f960e3a46befd2d06b223b61d" category="summary">このセクションでは、開発とテスト、および DR の運用に使用される一般的なハイブリッドクラウドアーキテクチャについて説明します。</block>
  <block id="fece52c505c48f2979e3fa0c8b6bd8bc" category="paragraph"><block ref="fece52c505c48f2979e3fa0c8b6bd8bc" category="inline-link-macro-rx"></block></block>
  <block id="4085a97aa705c0122bbcec0c84dd97d3" category="paragraph">次のアーキテクチャ図は、開発 / テスト運用とディザスタリカバリ処理のためのエンタープライズデータベース運用をハイブリッドクラウドで実装する一般的な方法を示しています。</block>
  <block id="acb339f710a626679c374df5b90c5416" category="paragraph"><block ref="acb339f710a626679c374df5b90c5416" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cdc302c6d83b60c8ec7ad0b550e55a8" category="paragraph">通常のビジネス運用では、クラウド内の同期されたデータベースボリュームをクローニングし、アプリケーションの開発 / テスト用データベースインスタンスにマウントできます。障害が発生した場合は、クラウド内の同期されたデータベースボリュームをディザスタリカバリ用にアクティブ化できます。</block>
  <block id="fbfd3304757c668454a7bdd10f9de200" category="inline-link-macro">次のステップ：ソリューションの要件</block>
  <block id="ae3b1bce66c4c75d8abf9828ec9f2608" category="paragraph"><block ref="ae3b1bce66c4c75d8abf9828ec9f2608" category="inline-link-macro-rx"></block></block>
  <block id="c94d29f1f4f8ef37e9d27f30b7d7c67d" category="summary">SnapCenter ハイブリッドクラウドデータベースワークロード環境を準備するには、このセクションで説明するタスクをオンプレミスで完了する必要があります。</block>
  <block id="f6a196d9d3a941e76765e4a9395630c4" category="doc">オンプレミスの前提条件</block>
  <block id="eac55cbc45bfe6b98b8847b3952de7d3" category="inline-link-macro">前のページ：前提条件の設定</block>
  <block id="e63a288cc25b5c4127d3021b339c9f20" category="paragraph"><block ref="e63a288cc25b5c4127d3021b339c9f20" category="inline-link-macro-rx"></block></block>
  <block id="40931dcd4d9132545ec0faf2c5fb1b64" category="paragraph">SnapCenter ハイブリッドクラウドデータベースワークロード環境を準備するには、オンプレミスで次のタスクを完了する必要があります。</block>
  <block id="79daf399b9626cde309801f41a1e2e14" category="section-title">SnapCenter のインストールと設定</block>
  <block id="2607530756fefa4173e12cfcd5fbfb01" category="paragraph">NetApp SnapCenter ツールは Windows ベースのアプリケーションで、通常は Windows ドメイン環境で実行されますが、ワークグループ導入も可能です。これは、集中管理サーバー（ SnapCenter サーバー）とデータベースワークロード用のデータベースサーバーホスト上の SnapCenter プラグインを含む多層アーキテクチャに基づいています。ここでは、ハイブリッドクラウドの導入に関する主な考慮事項をいくつか示します。</block>
  <block id="9f8c0bcd11d7afd1dd2ee818191cb914" category="list-text">* 単一インスタンスまたは HA 展開。 * HA 展開は、単一 SnapCenter インスタンスサーバーに障害が発生した場合に冗長性を提供します。</block>
  <block id="1bfa2867d5aa49106efbf3ac752f3084" category="list-text">* 名前解決。 * フォワードルックアップとリバースルックアップのためには、ストレージ SVM 上だけでなくすべてのデータベースホストを解決するために SnapCenter サーバ上で DNS を設定する必要があります。フォワードルックアップとリバースルックアップの両方で SnapCenter サーバとストレージ SVM を解決するためには、データベースサーバで DNS も設定する必要があります。</block>
  <block id="41f54308d86c1d7b525475d6ead22892" category="list-text">* ロールベースアクセス制御（ RBAC ）の設定。 * 混在データベースワークロードの場合は、 RBAC を使用して、 Oracle データベースの管理者や SQL Server の管理者など、異なる DB プラットフォーム用の管理責任を分離できます。DB 管理者ユーザには、必要な権限が付与されている必要があります。</block>
  <block id="5aee5dffd2e329652ec35995add763ae" category="list-text">* バックアップの一貫性と信頼性を確保するために、ポリシー・ベースのバックアップ戦略を有効にします。 *</block>
  <block id="dde4790e572aa9d01cd58fcfd8498766" category="list-text">* ファイアウォール上の必要なネットワーク・ポートを開きます。 * オンプレミスの SnapCenter サーバーが、クラウド DB ホストにインストールされたエージェントと通信できるようにします。</block>
  <block id="e2962676531ebdcf62cb2a7b96042e77" category="list-text">* ポートは、オンプレミスとパブリッククラウド間の SnapMirror トラフィックを許可するためにオープンである必要があります。 * SnapCenter サーバは、 ONTAP SnapMirror を使用して、オンサイトの Snapshot バックアップをクラウドの CVO ストレージ SVM にレプリケートします。</block>
  <block id="549762060d7242346fa79f39cba51791" category="inline-link-macro">SnapCenter の設置ワークフロー</block>
  <block id="aec875397d57826c45f7072636026a07" category="paragraph">インストール前の計画と考慮事項を慎重に検討したら、これをクリックしてください <block ref="f44e9d032441cc842cad02c3aab57d84" category="inline-link-macro-rx"></block> SnapCenter のインストールと設定の詳細については、を参照してください。</block>
  <block id="df3fb602185c77a88bab186791d02636" category="section-title">オンプレミスのデータベースサーバのストレージ構成</block>
  <block id="f7f3a649be867b87ccb26789453199db" category="paragraph">データベースとアプリケーションの全体的なパフォーマンスには、ストレージのパフォーマンスが重要な役割を果たします。適切に設計されたストレージレイアウトでは、 DB のパフォーマンスを向上させるだけでなく、データベースのバックアップとリカバリの管理も簡単に行えます。ストレージレイアウトを定義する際には、データベースのサイズ、データベースの予想されるデータ変更率、バックアップの実行頻度など、いくつかの要素を考慮する必要があります。</block>
  <block id="8481231881c8e64b34aa3c7e29510a25" category="paragraph">一般に、仮想データベースワークロード用に NFS または iSCSI でストレージ LUN をゲスト VM に直接接続すると、 VMDK 経由で割り当てられたストレージよりもパフォーマンスが向上します。次の図に示す LUN 上にある大規模な SQL Server データベースのストレージレイアウトを使用することを推奨します。</block>
  <block id="cc75f443d22e45e490468a8f20689d77" category="paragraph"><block ref="cc75f443d22e45e490468a8f20689d77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99aea05cf884bfdec230afa5250968b2" category="paragraph">次の図は、 LUN 上の小規模または中規模の SQL Server データベースに推奨されるストレージレイアウトを示しています。</block>
  <block id="9fc72535f1113895818f8aa60ef773e7" category="paragraph"><block ref="9fc72535f1113895818f8aa60ef773e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ecde8f778d0dd0676f392793ce4382" category="admonition">ログディレクトリは SnapCenter 専用で、データベースリカバリ用のトランザクションログロールアップを実行します。1 つのボリュームに複数の LUN を割り当てて、パフォーマンスを向上させることもできます。</block>
  <block id="ee9158729a15dbd90d166650ba285d0e" category="paragraph">Oracle データベースワークロードの場合、 SnapCenter は、 ONTAP ストレージを使用するデータベース環境をサポートします。この環境は、物理デバイスまたは仮想デバイスとしてホストにマウントされます。環境の重要度に基づいて、データベース全体を単一または複数のストレージデバイス上にホストすることができます。通常、専用ストレージにあるデータファイルは、制御ファイル、 REDO ファイル、アーカイブログファイルなどの他のすべてのファイルから分離されます。これにより、管理者は Snapshot テクノロジを使用して数秒から数分以内に（ ONTAP の単一ファイル SnapRestore ）を迅速にリストアしたり、大規模な重要データベース（ペタバイト規模）のクローンを作成したりできます。</block>
  <block id="b31fbb7e1a6e863315e431fdf9c00db9" category="paragraph"><block ref="b31fbb7e1a6e863315e431fdf9c00db9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="959a3405dfdfb0469534f5276ffb8e5e" category="paragraph">レイテンシの影響を受けやすいミッションクリティカルなワークロードに対しては、可能なかぎり最適なレイテンシを実現するために、異なる種類の Oracle ファイルに専用のストレージボリュームを導入する必要があります。大規模なデータベースの場合は、ボリュームごとに複数の LUN をデータファイルに割り当てる必要があります（最大 8 個まで推奨）。</block>
  <block id="ac111cbcae2e9eaedafe418acc3a2cab" category="paragraph"><block ref="ac111cbcae2e9eaedafe418acc3a2cab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2702ce3d59ec94853fa030462b309f2f" category="paragraph">小規模な Oracle データベースの場合、 SnapCenter は共有ストレージレイアウトをサポートしています。共有ストレージレイアウトでは、同じストレージボリュームまたは LUN 上で複数のデータベースまたはデータベースの一部をホストできます。このレイアウトの例として、 +DATA ASM ディスクグループまたはボリュームグループ上のすべてのデータベースのデータファイルをホストできます。それ以外のファイル（ REDO ファイル、アーカイブログファイル、および制御ファイル）は、別の専用ディスクグループまたはボリュームグループ（ LVM ）でホストすることができます。このような導入シナリオを次に示します。</block>
  <block id="6c12e98a6e201f55836390c2a6232e5a" category="paragraph"><block ref="6c12e98a6e201f55836390c2a6232e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93cf45b97655292e0536b810cb248828" category="paragraph">Oracle データベースの再配置を容易にするには、通常のバックアップポリシーに含まれている別の LUN に Oracle バイナリをインストールする必要があります。これにより、新しいサーバホストにデータベースを再配置する場合、 Oracle バイナリの同期が取れていないため、潜在的な問題が発生することなく、 Oracle スタックをリカバリ用に起動できます。</block>
  <block id="1e69a4a8adec0842d1e110e970112268" category="section-title">ライセンス要件</block>
  <block id="7f59934b2c0edd33f0d981f3bc4d12e7" category="paragraph">SnapCenter は、ネットアップが提供するライセンスソフトウェアです。これは通常、オンプレミスの ONTAP ライセンスに含まれています。ただし、ハイブリッドクラウドの導入の場合は、 SnapCenter に CVO をターゲットデータレプリケーションのデスティネーションとして追加するために、 SnapCenter のクラウドライセンスも必要です。詳細については、次のリンク先で SnapCenter の標準容量ベースのライセンスを確認してください。</block>
  <block id="9e86ae6c96041e3cb31e88116102ee35" category="inline-link-macro">SnapCenter の容量単位の標準ライセンスです</block>
  <block id="a1d51b5b5f3258b40cbe392146bc8868" category="paragraph"><block ref="a1d51b5b5f3258b40cbe392146bc8868" category="inline-link-macro-rx"></block></block>
  <block id="85db56d490cdd7a31d40697ad1c9be3c" category="section-title">ネットワークとセキュリティ</block>
  <block id="254215e6d18fb5582ba78464fa468553" category="paragraph">オンプレミスの本番データベースをオンプレミスで運用し、開発 / テストやディザスタリカバリのためにクラウドへの移行が非常に活発になるハイブリッドデータベースでは、環境をセットアップしてオンプレミスのデータセンターからパブリッククラウドに接続する際に、ネットワークとセキュリティを考慮することが重要です。</block>
  <block id="1e356fab450b44971b6cdbd1c25586b8" category="paragraph">パブリッククラウドでは、一般に仮想プライベートクラウド（ VPC ）を使用して、パブリッククラウドプラットフォーム内の異なるユーザを分離します。個々の VPC 内では、 VPC のロックダウンのユーザニーズに基づいて設定可能なセキュリティグループなどの手法を使用してセキュリティが制御されます。</block>
  <block id="5192a6d33c7a0127a67cbd7e07801735" category="paragraph">オンプレミスのデータセンターから VPC への接続は、 VPN トンネルを介して保護できます。VPN ゲートウェイでは、 NAT およびファイアウォールルールを使用してセキュリティを強化できます。このルールでは、インターネット上のホストから企業データセンター内のホストへのネットワーク接続の確立をブロックします。</block>
  <block id="04a3995237c020c6a587d8a7723af6a6" category="paragraph">ネットワークとセキュリティに関する考慮事項については、任意のパブリッククラウドに対する、関連するインバウンドおよびアウトバウンドの CVO ルールを確認してください。</block>
  <block id="d15513a147fbd525b88805bee9ea17ea" category="inline-link-macro">CVO-AWS のセキュリティグループルール</block>
  <block id="f8d1f085169118c4d407be16136389c6" category="list-text"><block ref="f8d1f085169118c4d407be16136389c6" category="inline-link-macro-rx"></block></block>
  <block id="39f48b44d100d16ed6e2b931111663b7" category="inline-link-macro">CVO-Azure のセキュリティグループルール</block>
  <block id="bcde746324630d82052a4fc9861cfea6" category="list-text"><block ref="bcde746324630d82052a4fc9861cfea6" category="inline-link-macro-rx"></block></block>
  <block id="7b20c547f2fd113499deaa3c0e418282" category="inline-link-macro">CVO-GCP のファイアウォールルール</block>
  <block id="acde731d82a437ab33cb200791f7a197" category="list-text"><block ref="acde731d82a437ab33cb200791f7a197" category="inline-link-macro-rx"></block></block>
  <block id="d9446a69434b7c7fdec5c9e35d222834" category="section-title">Ansible による自動化を使用して、オンプレミスとクラウドの間で DB インスタンスを同期することもできます。これはオプションです</block>
  <block id="1c7c9b49a62ea0dc765d1439120cfc8f" category="paragraph">ハイブリッドクラウドデータベース環境の管理を簡易化するために、ネットアップでは Ansible コントローラを導入して、コンピューティングインスタンスをオンプレミスやクラウドに同期させるなどの一部の管理タスクを自動化することを強く推奨していますが、必須ではありません。特に重要なのは、クラウド内の同期されていないコンピューティングインスタンスが原因で、カーネルパッケージやその他の問題が原因で、リカバリされたデータベースがクラウドエラーになる可能性があるためです。</block>
  <block id="7468552c7fc3a7ca377b7fc2405a9940" category="paragraph">Ansible コントローラの自動化機能を使用して、 SnapMirror インスタンスの解除などの特定のタスクで SnapCenter を補強し、本番環境で DR データコピーをアクティブ化することもできます。</block>
  <block id="6ac547919eb6ca11f5a8387eaf990843" category="inline-link-macro">RedHat / CentOS Ansible コントローラのセットアップ</block>
  <block id="c8e133fc33bbdb52f84b3532496f2ac8" category="inline-link-macro">Ubuntu / Debian Ansible のコントローラセットアップ</block>
  <block id="6f332c2f54a4d49478f9588c5cd6c57c" category="paragraph">以下の手順に従って、 RedHat または CentOS マシン用の Ansible コントロールノードをセットアップします。 <block ref="fedce547519117863322cfa54cc2ba7d" category="inline-link-macro-rx"></block>。Ubuntu または Debian マシン用の Ansible の制御ノードをセットアップするには、次の手順に従います。 <block ref="1c50818f5fe40dbc8b2e05138d554fa4" category="inline-link-macro-rx"></block>。</block>
  <block id="d5316785c089f90464e8e683aadd02e1" category="inline-link-macro">次のステップ：パブリッククラウド</block>
  <block id="d09f79a080b121cb1acc181711b5d02a" category="paragraph"><block ref="d09f79a080b121cb1acc181711b5d02a" category="inline-link-macro-rx"></block></block>
  <block id="d89002d36151bd13d2bba69f3533ee5f" category="summary">この解決策では、ネットアップの営業担当者やお客様に、 NetApp SnapCenter の GUI ベースのツールとパブリッククラウドのネットアップストレージサービス CVO を使用して、データベースをハイブリッドクラウド環境に設定、運用、移行するための手順とガイダンスを提供しています。</block>
  <block id="8269707c3930f3cbcd49193be33bc125" category="doc">TR-4908 ：『 Hybrid Cloud Database Solutions with SnapCenter Overview 』</block>
  <block id="7c4d94e1b484fb577b0aeafbec788ea1" category="paragraph">ネットアップ、 Felix Melligan 、 Alan Co 氏</block>
  <block id="268a30b4d0cad062acd42967ce0fab50" category="paragraph">この解決策では、次のユースケースについて、 NetApp SnapCenter の GUI ベースのツールとパブリッククラウドのネットアップストレージサービス CVO を使用して、データベースをハイブリッドクラウド環境に設定、運用、移行するための手順とガイダンスを、ネットアップの営業担当者やお客様に提供しています。</block>
  <block id="e88a2467c8ad8bf481854b1a745a875b" category="list-text">ハイブリッドクラウドでのデータベース開発 / テスト運用</block>
  <block id="3c9552536897a076f75b078a5e2a3703" category="list-text">ハイブリッドクラウドでのデータベースディザスタリカバリ</block>
  <block id="a1ac690c228caf22f3228d3a4d8b5cab" category="paragraph">現在でも、多くのエンタープライズデータベースは、パフォーマンスやセキュリティなどの理由から、プライベートな企業データセンターに配置されています。このハイブリッドクラウドデータベース解決策を使用すると、開発 / テストデータベースの運用にパブリッククラウドを使用しながら、企業はプライマリデータベースをオンサイトで運用できるようになります。ディザスタリカバリにも対応しているため、ライセンスコストと運用コストを削減できます。</block>
  <block id="d900d125b3be40bcb79452d624c38561" category="paragraph">Oracle 、 SQL Server 、 SAP HANA など、多数のエンタープライズデータベース 高いライセンスコストと運用コストを負担します。多くのお客様は、コアを開発、テスト、本番、ディザスタリカバリに使用するかどうかにかかわらず、データベース環境内のコンピューティングコアの数に基づいて 1 回限りのライセンス料金と年間サポートコストを負担しています。そのような環境の多くは、アプリケーションのライフサイクルを通じてフル活用されない場合があります。</block>
  <block id="1f49cc83c5c3735827e3353f320f5f7f" category="paragraph">このソリューションは、開発、テスト、ディザスタリカバリに特化したデータベース環境をクラウドに移行することで、ライセンス可能なコア数を潜在的に削減するためのオプションをお客様に提供します。パブリッククラウドの拡張性、冗長性、高可用性、使用量に応じた課金モデルを使用することで、ライセンスと運用のコストを大幅に削減できると同時に、アプリケーションの使用や可用性を損なうこともありません。</block>
  <block id="1a197dd926608052c7d43edfd09556fa" category="paragraph">ネットアップの容量ベースの CVO ライセンスモデルでは、潜在的なデータベースライセンスコストの削減に加えて、ストレージコストを GB 単位で削減すると同時に、競合するストレージサービスでは利用できない高レベルのデータベース管理機能を利用できるようにしています。次のグラフは、パブリッククラウドで利用できる一般的なストレージサービスのストレージコストの比較です。</block>
  <block id="810fba7bc9a3829eb522ebbc24326a08" category="paragraph"><block ref="810fba7bc9a3829eb522ebbc24326a08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e222eb27a0002f2960d1cf1e14bbf7d" category="paragraph">この解決策は、 SnapCenter の GUI ベースのソフトウェアツールと NetApp SnapMirror テクノロジを使用することで、ハイブリッドクラウドデータベースの運用を簡単にセットアップ、実装、運用できることを実証しています。</block>
  <block id="26cc8c416b5c9fd6bec3dc68e6f2f0c8" category="paragraph">次のビデオでは、 SnapCenter の実際の動作を紹介します。</block>
  <block id="edc6673fe24c4867029921bbe72f25cb" category="inline-link">SnapCenter を使用して、ハイブリッドクラウド全体で Oracle データベースをバックアップする</block>
  <block id="b10d6cd72b187359c3769fbf5ff10e4c" category="list-text"><block ref="0d160cec2141981b284cd9986321651e" category="inline-link-rx"></block></block>
  <block id="68d9033a95c0ed286c9b7e0e7454cd86" category="inline-link">SnapCenter - Oracle データベース用の AWS クラウドに開発 / テストをクローニング</block>
  <block id="da8d0116fa67f0499837675277668911" category="list-text"><block ref="da8d0116fa67f0499837675277668911" category="inline-link-rx"></block></block>
  <block id="3b04263461ad5a7b57aa872e093ec9fa" category="paragraph">特に、このドキュメントの図では、 CVO をパブリッククラウドのターゲットストレージインスタンスとして示していますが、 ONTAP は、 AWS 向け FSX 解決策ストレージエンジンの新しいリリースに対しても完全に検証されています。</block>
  <block id="c5a6d2f45fc4352f35e95d92c804b6f2" category="paragraph">解決策の動作やユースケースを自社でテストするために、ネットアップラボオンデマンドの SL10680 が次のリンクからリクエストできます： https://labondemand.netapp.com/lod3/labtest/request?nodeid=68761&amp;destination=lod3/testlabs[TL_AWS_004 HCD ： AWS-NW 、 SnapCenter （ OnPrem ） ^ ]</block>
  <block id="d31314285161c777a09609cc4fb2d07a" category="inline-link-macro">次は、ソリューションアーキテクチャです。</block>
  <block id="0830319fc7a6b051bbb0602c2778e67c" category="paragraph"><block ref="0830319fc7a6b051bbb0602c2778e67c" category="inline-link-macro-rx"></block></block>
  <block id="8f7280c86689be0a39cdf74aa673040d" category="summary">この解決策はハイブリッドクラウド環境で設計されており、開発 / テストやディザスタリカバリ処理の目的で一般的なすべてのパブリッククラウドにバーストできます。オンプレミスの本番データベースをサポートします。</block>
  <block id="132f2888eb2cfdeef2730212f50c53e3" category="doc">SnapCenter の要件</block>
  <block id="e2a7d0854ef572e10255339732bb005d" category="inline-link-macro">以前のバージョン：ソリューションアーキテクチャ。</block>
  <block id="b10927905ed5379ba0d73333abdbe06d" category="paragraph"><block ref="b10927905ed5379ba0d73333abdbe06d" category="inline-link-macro-rx"></block></block>
  <block id="185b108b21dccef917f415be6026c91c" category="paragraph">本番環境のデータベースサーバをオンプレミスでホストし、 ONTAP ストレージクラスタから DB ホストに DB ボリュームを提供するとします。SnapCenter ソフトウェアをオンプレミスにインストールし、データベースのバックアップとクラウドへのデータレプリケーションを行う。Ansible コントローラを推奨しますが、データベース導入の自動化や、 OS カーネル、およびデータベース構成の、パブリッククラウドのスタンバイ DR インスタンスや開発 / テストインスタンスとの同期には必要ありません。</block>
  <block id="47099d9ea153f8abfa5b6b70da253b3a" category="cell">* オンプレミス *</block>
  <block id="d36407241494bfc1e84614ad1b0dd6a4" category="cell">SnapCenter でサポートされるデータベースおよびバージョン</block>
  <block id="8c8c8ca7a4093a1210412a3a5e5ad55f" category="cell">SnapCenter v4.4 以降</block>
  <block id="9d9ebf67dab68c3c892de99e981039cf" category="cell">Ansible v2.09 以降</block>
  <block id="62dd4f48e99b13c8a00fbaba684f9592" category="cell">ONTAP クラスタ 9.x</block>
  <block id="d0fdc58e1e05d6cbc8b1beb072bfa235" category="cell">クラスタ間 LIF が設定されました</block>
  <block id="7135df562bcb25bfdf20e4317b923b88" category="cell">オンプレミスからクラウド VPC への接続（ VPN 、インターコネクトなど）</block>
  <block id="8c27863f5ffd0e66a9304eaca2e47fde" category="cell">ネットワークポートが開いています - ssh 22 - TCP 8145 、 8146 、 10000 、 11104 、 11105</block>
  <block id="bcb9f3419f724f768e30956a4427261d" category="cell">* クラウド - AWS *</block>
  <block id="61c90d44785278f980592f082ef500f1" category="inline-link">Cloud Manager Connector の略</block>
  <block id="97bc5062dceccb6827b1e3f0522035f0" category="cell"><block ref="97bc5062dceccb6827b1e3f0522035f0" category="inline-link-rx"></block></block>
  <block id="2f077494ceff1f33085c5b163c3673b3" category="cell"><block ref="2f077494ceff1f33085c5b163c3673b3" category="inline-link-rx"></block></block>
  <block id="59b2c9424963f98d73ec69c59dde54cb" category="cell">DB OS EC2 インスタンスとオンプレミスを一致させる必要があります</block>
  <block id="e26786a16da88ee829ab76c48fd3b003" category="cell">* クラウド - Azure *</block>
  <block id="c2f8674b07907f393b67a3f9e98d3d56" category="cell"><block ref="c2f8674b07907f393b67a3f9e98d3d56" category="inline-link-rx"></block></block>
  <block id="a8dd724647657a383eb37fd8775ec1a9" category="cell"><block ref="a8dd724647657a383eb37fd8775ec1a9" category="inline-link-rx"></block></block>
  <block id="8bede1f0e559918be01f0646b75b4257" category="cell">DB OS の Azure 仮想マシンをオンプレミスと一致させる</block>
  <block id="b2a454fb4ff03b84162c59d674fdae25" category="cell">* クラウド - GCP*</block>
  <block id="af072236983e991ab34e773871b10236" category="cell"><block ref="af072236983e991ab34e773871b10236" category="inline-link-rx"></block></block>
  <block id="499477cf7953707f63a1b1313c8c065a" category="cell"><block ref="499477cf7953707f63a1b1313c8c065a" category="inline-link-rx"></block></block>
  <block id="2900c5e1ee191606f20d007194e70edf" category="cell">DB OS の Google Compute Engine インスタンスをオンプレミスと一致させる</block>
  <block id="126b29c0beff0884077277115103a374" category="inline-link-macro">次の手順：前提条件の構成。</block>
  <block id="a6d027dea0e97ba248528210d36e5475" category="paragraph"><block ref="a6d027dea0e97ba248528210d36e5475" category="inline-link-macro-rx"></block></block>
  <block id="d0bb28dcc0cc1b523a41bbb46875db9e" category="summary">Cloud Manager Connector と Cloud Volumes ONTAP をインストールして SnapMirror を設定する前に、クラウド環境向けの準備を行う必要があります。このページでは、 Cloud Volumes ONTAP を導入する際に考慮すべき点と同様に、実行する必要がある作業について説明します。</block>
  <block id="8c6fb9ece3bad11d3e76d1344d9ed9ab" category="doc">パブリッククラウドの前提条件</block>
  <block id="ac7eeb8ecebe00daa1fdf4fd06cc46de" category="inline-link-macro">前：オンプレミスの前提条件</block>
  <block id="70ba5e430ac8eade85f8e01e51412fe4" category="paragraph"><block ref="70ba5e430ac8eade85f8e01e51412fe4" category="inline-link-macro-rx"></block></block>
  <block id="5a2798d22185b0e40ea502bbbb171d38" category="section-title">Cloud Manager と Cloud Volumes ONTAP の導入の前提条件チェックリスト</block>
  <block id="1e094e6477be231098329b0096c7221f" category="list-text">NetApp Cloud Central へのログイン</block>
  <block id="b59e275c4ece2430dff67db92845ab7f" category="list-text">Web ブラウザから複数のエンドポイントへのネットワークアクセス</block>
  <block id="d2ed5c7ede8a1ce9d218ec60b0f03935" category="list-text">コネクタのネットワーク上の場所</block>
  <block id="0d07862d67097acd517fe27c0de099d7" category="list-text">クラウドプロバイダの権限</block>
  <block id="203802866ac2835e79bd76c94a3761c2" category="list-text">個々のサービスのネットワーク</block>
  <block id="c4d5e1cbdfc47a0fdcb4a1a9dddd9e17" category="inline-link">クラウドのドキュメント</block>
  <block id="1a22a3f7b690b2ec8919c8806633fb26" category="paragraph">開始する必要がある項目の詳細については、を参照してください<block ref="247d95fa755d21bb8790cc6d7a2fc412" category="inline-link-rx"></block>。</block>
  <block id="ea61e2c2ff507048203824add1eb7c21" category="section-title">考慮事項</block>
  <block id="176ca67b83510a1281a4cfc749a3543a" category="section-title">1. Cloud Manager Connector とは</block>
  <block id="1681641037afae45bd6074dcde9eed00" category="paragraph">ほとんどの場合、 Cloud Central アカウント管理者はクラウドまたはオンプレミスネットワークにコネクタを導入する必要があります。Connector を使用すると、 Cloud Manager でパブリッククラウド環境内のリソースとプロセスを管理できます。</block>
  <block id="8a78be5d168f00b24bf1625de3d5409c" category="paragraph">コネクタの詳細については、を参照してください<block ref="f39c14bbbbdd46ca70a63fb06046c789" category="inline-link-rx"></block>。</block>
  <block id="fcc2bf38b8157a22b5fc6975b7054acc" category="section-title">2. Cloud Volumes ONTAP のサイジングとアーキテクチャ</block>
  <block id="1c09b5154aa1f43cb9ebcbd6fea5eadc" category="paragraph">Cloud Volumes ONTAP を導入する際には、事前定義されたパッケージを選択するか、独自の設定を作成するかを選択できます。これらの値の多くはあとで無停止で変更することができますが、クラウドに導入するワークロードに基づいていくつかの重要な決定を行う必要があります。</block>
  <block id="331ce28903aee0b30cd3c94e5483edf5" category="inline-link">CVO のサイジングツール</block>
  <block id="acaed5d74e38e1779b3831dcf51c7600" category="paragraph">クラウドプロバイダごとに導入オプションが異なり、ほぼすべてのワークロードに独自のプロパティがあります。ネットアップには、があります<block ref="6a71e7e42ab9335484c5530029f79b92" category="inline-link-rx"></block> これは、容量とパフォーマンスに基づいて導入の規模を正しく決定するのに役立ちますが、次の点を考慮していくつかの基本的な概念を中心に構築されています。</block>
  <block id="145c90afb7955854f2371e9decf3de9b" category="list-text">容量が必要です</block>
  <block id="f1521b662bf51f1af6c2d38bd610afae" category="list-text">クラウド仮想マシンのネットワーク機能</block>
  <block id="f75d8ba5edc8017382d5df68baf9e30f" category="list-text">クラウドストレージのパフォーマンス特性</block>
  <block id="af9d66ea3132fcfeb46b85557bc1af1b" category="paragraph">重要な点は、現在の容量とパフォーマンスの要件を満たすだけでなく、将来の拡張も考慮する構成を計画することです。これは、一般に容量ヘッドルームおよびパフォーマンスヘッドルームと呼ばれます。</block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="inline-link">AWS</block>
  <block id="3a580f142203677f1f0bc30898f63f53" category="inline-link">Azure</block>
  <block id="c731f72e1d22a7c5e01a7cb789a8885e" category="inline-link">GCP</block>
  <block id="180f0326dff3a03aecf5e184943d108a" category="paragraph">詳細については、の計画に関するドキュメントを参照してください<block ref="af5d70b69c3436f8bcf6f7b9579c4e83" category="inline-link-rx"></block>、<block ref="c2e85b51d3015b4c720388e64a3de23e" category="inline-link-rx"></block>および<block ref="b1068926334a08925797774f64291db4" category="inline-link-rx"></block>。</block>
  <block id="c50ea1f0c6dcf02fbdd39e1e6b5befc2" category="section-title">3. シングルノードとハイアベイラビリティのどちらか？</block>
  <block id="eadb13b9c72271dbf16967e78059fea4" category="paragraph">どのクラウドでも、 CVO を導入できるノードは 1 つだけです。 2 つのノードで構成されるクラスタハイアベイラビリティペアにもなります。ユースケースによっては、コストを削減するためにシングルノードを導入したり、可用性と冗長性を向上させるために HA ペアを導入したりすることができます。</block>
  <block id="9cbd119b18cd836b6020fcfd3bfbe37f" category="paragraph">DR のユースケースでは、開発とテストのために一時的なストレージをスピンアップする場合でも、突然のゾーンの停止やインフラの停止による影響が小さいため、シングルノードが一般的です。ただし、本番環境では、データが 1 箇所だけに格納されている場合や、データセットの冗長性と可用性を高める必要がある場合に、高可用性を推奨します。</block>
  <block id="83d2ad0cda1f71c52878284cc7c1f713" category="paragraph">各クラウドバージョンのハイアベイラビリティのアーキテクチャの詳細については、のドキュメントを参照してください<block ref="4344469628657b2a6a0d147e5e6fbc9a" category="inline-link-rx"></block>、<block ref="28a8305eced80cb5b1351f5cffb268ae" category="inline-link-rx"></block> および<block ref="1b945d178a8347e94e5c5456dc9e6db8" category="inline-link-rx"></block>。</block>
  <block id="f0d106c1997a933ecb53ee88e83670e7" category="inline-link-macro">次の手順：概要。</block>
  <block id="fd43d07d375b44f30fde6995279b9265" category="paragraph"><block ref="fd43d07d375b44f30fde6995279b9265" category="inline-link-macro-rx"></block></block>
  <block id="a10998cc3e1dc7f2a013754d935c4f26" category="summary">NetApp SnapCenter ツールでは、ロールベースアクセス制御（ RBAC ）を使用してユーザリソースのアクセスと権限付与を管理します。また、 SnapCenter のインストール時に、すでにデータを含むロールが作成されます。また、ニーズやアプリケーションに基づいてカスタムロールを作成することもできます。</block>
  <block id="7e3b07f9add4cd78ade3c795a52dfad2" category="doc">オンプレミスでの作業の開始</block>
  <block id="32229cff9e0b41c513b3e3b9e19cec88" category="inline-link-macro">前の手順：概要。</block>
  <block id="6be036b00e3db4159514171a989cacd6" category="paragraph"><block ref="6be036b00e3db4159514171a989cacd6" category="inline-link-macro-rx"></block></block>
  <block id="d30e54646ba482722332f48ddc22bde5" category="section-title">1. SnapCenter でデータベース管理者ユーザを設定します</block>
  <block id="72f706d19ed0d09889b4fbc7578cd1a3" category="paragraph">NetApp SnapCenter ツールでは、 Role-Based Access Control （ RBAC ；ロールベースアクセス制御）を使用してユーザリソースのアクセス権と権限付与を管理し、 SnapCenter のインストール時にすでにデータを含むロールが作成されます。また、ニーズやアプリケーションに基づいてカスタムロールを作成することもできます。データベースのバックアップ、リストア、ディザスタリカバリを行う場合は、 SnapCenter でサポートされているデータベースプラットフォームごとに専用の管理者ユーザ ID を使用することを推奨します。単一の ID を使用してすべてのデータベースを管理することもできます。テストケースとデモでは、それぞれ Oracle と SQL Server の両方に専用の管理者ユーザを作成しました。</block>
  <block id="27733e8f07432bb94ac7621b28d3b2c8" category="paragraph">特定の SnapCenter リソースは、 SnapCenterAdmin ロールでのみプロビジョニングできます。その後、リソースを他のユーザ ID に割り当ててアクセスできるようになります。</block>
  <block id="64784aa3cec13e83af6e941f8489cf06" category="paragraph">オンプレミスの SnapCenter 環境が事前にインストールおよび設定されている場合は、次のタスクがすでに完了している可能性があります。設定されていない場合は、次の手順でデータベース管理ユーザを作成します。</block>
  <block id="c8867eac833e7bb55520105b00139f1a" category="list-text">Windows Active Directory に管理者ユーザを追加します。</block>
  <block id="dd3e743eb52cbe7c2b6104573a9767e0" category="list-text">SnapCenterAdmin ロールで付与された ID を使用して SnapCenter にログインします。</block>
  <block id="a6bd76cb24271ba173d16f01bf4108d0" category="list-text">[ 設定とユーザー ] の下の [ アクセス ] タブに移動し、 [ 追加 ] をクリックして新しいユーザーを追加します。新しいユーザ ID は、手順 1 で Windows Active Directory に作成した管理者ユーザにリンクされます。。必要に応じて、適切なロールをユーザに割り当てます。必要に応じて、管理者ユーザにリソースを割り当てます。</block>
  <block id="6a67bb048bd14dd348cca7f81b62d699" category="paragraph"><block ref="6a67bb048bd14dd348cca7f81b62d699" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5d2c51e83f473f137861a132554d1916" category="section-title">2. SnapCenter プラグインのインストールの前提条件</block>
  <block id="7bd973d4d28d6fcf5f50379b33a49758" category="paragraph">SnapCenter は、 DB ホストで実行されているプラグインエージェントを使用して、バックアップ、リストア、クローニングなどの処理を実行します。プラグインのインストールやその他の管理機能の [ 設定と資格情報 ] タブで設定された資格情報を使用して、データベースホストとデータベースに接続します。Linux や Windows などのターゲットホストタイプとデータベースのタイプに基づいて、特定の権限要件があります。</block>
  <block id="c342f214098114b90cb67297a2ef5dc3" category="paragraph">SnapCenter プラグインをインストールする前に、 DB ホストのクレデンシャルを設定しておく必要が一般に、 DB ホスト上の管理者ユーザアカウントは、プラグインのインストールに使用するホスト接続クレデンシャルとして使用します。OS ベースの認証を使用して、データベースアクセスに同じユーザ ID を付与することもできます。一方、データベース管理アクセスには、異なるデータベースユーザ ID を使用したデータベース認証を使用することもできます。OS ベースの認証を使用する場合は、 OS 管理ユーザ ID に DB アクセス権を付与する必要があります。Windows ドメインベースの SQL Server をインストールする場合、ドメイン管理者アカウントを使用して、ドメイン内のすべての SQL Server を管理できます。</block>
  <block id="19df1192effefad83e57653fd3a47415" category="paragraph">SQL Server 用 Windows ホスト：</block>
  <block id="e1cc3ce53d7753e33588201db3d3b147" category="list-text">認証に Windows クレデンシャルを使用している場合は、プラグインをインストールする前にクレデンシャルを設定する必要があります。</block>
  <block id="a82f1290b72a26d654b93632a1ec50bb" category="list-text">認証に SQL Server インスタンスを使用している場合は、プラグインのインストール後にクレデンシャルを追加する必要があります。</block>
  <block id="63f74bef6650942c6795f96366a39e6a" category="list-text">クレデンシャルの設定時に SQL 認証を有効にすると、検出されたインスタンスやデータベースに赤いロックアイコンが表示されます。ロックアイコンが表示された場合、リソースグループに追加する際にそのインスタンスまたはデータベースのクレデンシャルを指定する必要があります。</block>
  <block id="b61dad3bbbf3270bf2dada5c2ac1f775" category="list-text">次の条件に該当する場合、 sysadmin アクセスがない RBAC ユーザにクレデンシャルを割り当てる必要があります。</block>
  <block id="34cefb5a19894e4f9b1b068544c0f591" category="list-text">SQL インスタンスに資格情報が割り当てられます。</block>
  <block id="6707464a5871a6aa26dcf785bea4052c" category="list-text">SQL インスタンスまたはホストが RBAC ユーザに割り当てられている。</block>
  <block id="4bc8aac02ff00d874ad8b4ccd4d745ed" category="list-text">RBAC DB 管理者ユーザには、リソースグループとバックアップ権限の両方が必要です。</block>
  <block id="9198b455aa67840c7a69c7a54e94301a" category="paragraph">Oracle 用 UNIX ホスト：</block>
  <block id="71d53e54a48cfe7de69347bcd854ef30" category="list-text">sshd.conf を編集して sshd サービスを再起動して、 root または root 以外のユーザのパスワードベースの SSH 接続を有効にしておく必要があります。AWS インスタンスでのパスワードベースの SSH 認証は、デフォルトではオフになっています。</block>
  <block id="efa873f0464a14d54b066f475ad74480" category="list-text">プラグインプロセスをインストールして開始できるように root 以外のユーザの sudo 権限を設定します。プラグインをインストールすると、プロセスは有効な root ユーザーとして実行されます。</block>
  <block id="82a2174029175f8fbc3f52fea4e18c84" category="list-text">インストールユーザの Linux 認証モードでクレデンシャルを作成します。</block>
  <block id="86b3cc44ebd8e0a9185e48c4f22e81e9" category="list-text">Java 1.8.x （ 64 ビット）は Linux ホストにインストールする必要があります。</block>
  <block id="c1e8851d10ecc615c47a47f704569d29" category="list-text">Oracle データベースプラグインをインストールすると、 UNIX 用 SnapCenter プラグインもインストールされます。</block>
  <block id="7efb27733d1fb21feae901a41580dced" category="section-title">3. SnapCenter ホストプラグインのインストール</block>
  <block id="37a5c714defad8175b81b4d49eb0544c" category="admonition">SnapCenter プラグインをクラウド DB サーバーインスタンスにインストールする前に、コンピューティングインスタンスの導入に関する該当するクラウドセクションに記載されているすべての設定手順が完了していることを確認してください。</block>
  <block id="283aa502c28fe1c9ff8dadd1700955fc" category="paragraph">次の手順は、 SnapCenter プラグインがホストにインストールされている状態で、データベースホストが SnapCenter に追加される方法を示しています。手順環境はオンプレミスホストとクラウドホストの両方を追加します。次のデモでは、 AWS に Windows または Linux ホストを追加します。</block>
  <block id="81ed46777c39c0d0618953601572fc27" category="section-title">SnapCenter の VMware グローバル設定を構成します</block>
  <block id="2aa8a40dbbfb6b52621408c81aa5373c" category="paragraph">[ 設定 ] &gt; [ グローバル設定 ] に移動します。ハイパーバイザー設定で、「 VM に iSCSI 直接接続ディスクまたはすべてのホスト用の NFS がある」を選択し、更新をクリックします。</block>
  <block id="4c120331c9eea223eee675b6588d76ee" category="paragraph"><block ref="4c120331c9eea223eee675b6588d76ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f63a469619859e4cfab52fd63523aca" category="section-title">Windows ホストおよびプラグインのインストールをホストに追加します</block>
  <block id="997da6deedab4436b559e3a8f7f05a2e" category="list-text">SnapCenterAdmin 権限でユーザ ID を使用して SnapCenter にログインします。</block>
  <block id="97e7f600216a2e9ae18423777e11ad9c" category="list-text">左側のメニューから [Hosts] タブをクリックし、 [Add] をクリックして [Add Host] ワークフローを開きます。</block>
  <block id="35314bae57d7ff62ab36156211c1cc71" category="list-text">ホストタイプとして Windows を選択しますホスト名には ' ホスト名または IP アドレスを指定できますホスト名を SnapCenter ホストから正しいホスト IP アドレスに解決する必要があります。手順 2 で作成したホストクレデンシャルを選択します。インストールするプラグインパッケージとして Microsoft Windows と Microsoft SQL Server を選択します。</block>
  <block id="b9740ae9eb2ef0fe27e4c541d06a961f" category="paragraph"><block ref="b9740ae9eb2ef0fe27e4c541d06a961f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31efcd689861354799bb539ab2571ebe" category="list-text">プラグインが Windows ホストにインストールされると、その全体的なステータスは「 Configure log directory 」と表示されます。</block>
  <block id="0e15e25c5ee21469698f72cf35caa7bf" category="paragraph"><block ref="0e15e25c5ee21469698f72cf35caa7bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2aeaa4503c6d72513c0dbe0f205ee3b" category="list-text">ホスト名をクリックして、 SQL Server ログディレクトリの設定を開きます。</block>
  <block id="6fc78660a180b747f815b878c89e3cb0" category="paragraph"><block ref="6fc78660a180b747f815b878c89e3cb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb2b40646a77b4f044e7fa04ea20306" category="list-text">[ ログディレクトリの設定 ] をクリックして、 [ Plug-in for SQL Server の設定 ] を開きます。</block>
  <block id="5e3bf9ddacfcad12c5cf63614a869ad4" category="paragraph"><block ref="5e3bf9ddacfcad12c5cf63614a869ad4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7143b5d162d385dfb1af07f61c59f65" category="list-text">[ 参照 ] をクリックしてネットアップストレージを検出し、ログディレクトリを設定できるようにします。 SnapCenter はこのログディレクトリを使用して、 SQL Server トランザクションログファイルをロールアップします。[ 保存 ] をクリックします。</block>
  <block id="50eb49de485da684ac1556947ac46aba" category="paragraph"><block ref="50eb49de485da684ac1556947ac46aba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0d88588bdb07dd412a4ba1d08348b29" category="admonition">DB ホストにプロビジョニングされたネットアップストレージを検出するには、 CVO の手順 6 に示すように、ストレージ（オンプレミスまたは CVO ）を SnapCenter に追加する必要があります。</block>
  <block id="d744af12906d55ab51aa932b3ffcd121" category="list-text">ログディレクトリを構成すると、 Windows ホストプラグインの [ 全般的なステータス ] が [ 実行中 ] に変更されます。</block>
  <block id="3f7bfffdbb76fd620b0a31d300415528" category="paragraph"><block ref="3f7bfffdbb76fd620b0a31d300415528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41517f2e270a138f4ae92988a4cbdd2" category="list-text">ホストをデータベース管理ユーザー ID に割り当てるには、 [ 設定とユーザー ] の [ アクセス ] タブに移動し、データベース管理ユーザー ID ( この場合はホストを割り当てる必要がある sqldba ) をクリックして、 [ 保存 ] をクリックしてホストリソースの割り当てを完了します。</block>
  <block id="b21f826d2ea15e58b9c8aadccb566cfe" category="paragraph"><block ref="b21f826d2ea15e58b9c8aadccb566cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021de72edbb0f174ffe954c5e5367b80" category="paragraph"><block ref="021de72edbb0f174ffe954c5e5367b80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2fe19c733a6342990513e02264db163" category="section-title">UNIX ホストを追加し、プラグインをホストにインストールします</block>
  <block id="6a0f36be9f208d20c3c1145c3a09b876" category="list-text">左側のメニューから [Hosts] タブをクリックし、 [Add] をクリックして [Add Host] ワークフローを開きます。</block>
  <block id="dd8c6d773e31c4254eb58b4b5e2ae1be" category="list-text">ホストタイプとして Linux を選択します。ホスト名には、ホスト名または IP アドレスを使用できます。ただし、ホスト名を解決して、 SnapCenter ホストから正しいホスト IP アドレスを取得する必要があります。手順 2 で作成したホストクレデンシャルを選択します。ホストのクレデンシャルには sudo 権限が必要です。Oracle Database をインストールするプラグインとしてチェックし、 Oracle と Linux の両方のホストプラグインをインストールします。</block>
  <block id="7d4cdef2144fd1466fae298bd27476d1" category="paragraph"><block ref="7d4cdef2144fd1466fae298bd27476d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="711730391561a228d41f7fede13ca6e8" category="list-text">[ その他のオプション ] をクリックし、 [ インストール前のチェックをスキップ ] を選択します。 インストール前のチェックを省略するかどうかを確認するプロンプトが表示されます。[ はい ] をクリックし、 [ 保存 ] をクリック</block>
  <block id="3511b18d059f3f300b5fbe827f7273ac" category="paragraph"><block ref="3511b18d059f3f300b5fbe827f7273ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e095a093138c6b1968d313d5f799255a" category="list-text">Submit をクリックして、プラグインのインストールを開始します。次のように指紋の確認を求められます。</block>
  <block id="146c4805beb9310e4554842f776cb88b" category="paragraph"><block ref="146c4805beb9310e4554842f776cb88b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53dcda6f2c03efbe73ae5eb311852a8d" category="list-text">SnapCenter はホストの検証と登録を実行し、プラグインを Linux ホストにインストールします。ステータスは、プラグインのインストールから実行に変わります。</block>
  <block id="2636403a6c50748422736d9d84a3e4be" category="paragraph"><block ref="2636403a6c50748422736d9d84a3e4be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="33ea9d9313933c68d640ebb655ec43dc" category="list-text">新しく追加したホストに、適切なデータベース管理ユーザ ID （この場合は oradba ）を割り当てます。</block>
  <block id="2815d2f5e3b49d9332a320ec997271dd" category="paragraph"><block ref="2815d2f5e3b49d9332a320ec997271dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb6a9566891a97e0f8fbaefbd4878bdd" category="paragraph"><block ref="eb6a9566891a97e0f8fbaefbd4878bdd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b4c839521fd41e845e6e8c3158b809b" category="section-title">4. データベースリソースの検出</block>
  <block id="45e46a9524f23884445bf542bf464b93" category="paragraph">プラグインのインストールが正常に完了すると、ホスト上のデータベースリソースがすぐに検出されます。左側のメニューの [ リソース ] タブをクリックします。データベースプラットフォームのタイプに応じて、データベース、リソースグループなどのさまざまなビューを使用できます。ホスト上のリソースが検出されて表示されない場合は、 Refresh Resources タブをクリックする必要があります。</block>
  <block id="79fca6395972f8079320d3229822e491" category="paragraph"><block ref="79fca6395972f8079320d3229822e491" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66789731e61fd3d4b6024e5fcb0945e1" category="paragraph">データベースが最初に検出されると、全体的なステータスは「 Not protected 」と表示されます。 前のスクリーンショットは、バックアップポリシーでまだ保護されていない Oracle データベースを示しています。</block>
  <block id="68148a1249ca9110d03c698ae152932a" category="paragraph">バックアップの設定またはポリシーが設定されていて、バックアップが実行された場合、データベースの全体的なステータスには、バックアップのステータスが「 Backup succeeded 」と表示され、最後のバックアップのタイムスタンプが表示されます。次のスクリーンショットは、 SQL Server ユーザデータベースのバックアップステータスを示しています。</block>
  <block id="2cdfb74ac3aabfde7e1fae347ed5afc7" category="paragraph"><block ref="2cdfb74ac3aabfde7e1fae347ed5afc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c9616324bc00808729d46fba94ad75" category="paragraph">データベースアクセスクレデンシャルが適切に設定されていない場合は、赤いロックボタンが表示され、データベースにアクセスできないことが示されます。たとえば、 Windows クレデンシャルにデータベースインスタンスへの sysadmin アクセスがない場合、赤いロックを解除するためにデータベースクレデンシャルを再設定する必要があります。</block>
  <block id="dd4606e87689c86d82a694412c5654a5" category="paragraph"><block ref="dd4606e87689c86d82a694412c5654a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="884f07ad394b89553e7d6d1f90fae584" category="paragraph"><block ref="884f07ad394b89553e7d6d1f90fae584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0024854a814ddd68bcf3907357c46bc2" category="paragraph">Windows レベルまたはデータベースレベルのいずれかで適切なクレデンシャルを設定すると、赤いロックは消え、 SQL Server Type の情報が収集および確認されます。</block>
  <block id="95c88e08b2fd416b4514ce2454af2038" category="paragraph"><block ref="95c88e08b2fd416b4514ce2454af2038" category="inline-image-macro-rx" type="image"></block></block>
  <block id="864f4d2595d06e5e8b46b08edb3899e6" category="section-title">5. ストレージクラスタピアリングと DB ボリュームレプリケーションの設定</block>
  <block id="785196ec55a9e713ad1a4f962baa31dd" category="paragraph">パブリッククラウドをターゲットとするデスティネーションとしてオンプレミスのデータベースデータを保護するために、オンプレミスの ONTAP クラスタデータベースボリュームは、 NetApp SnapMirror テクノロジを使用してクラウドの CVO にレプリケートされます。レプリケートされたターゲットボリュームを、開発 / OPS またはディザスタリカバリ用にクローニングできます。以下に、クラスタピアリングと DB ボリュームレプリケーションの設定手順の概要を示します。</block>
  <block id="1f1927293f04e4cf0fc91a7e389612eb" category="list-text">オンプレミスクラスタと CVO クラスタインスタンスの両方で、クラスタピアリング用のクラスタ間 LIF を設定できます。この手順は、 ONTAP システムマネージャを使用して実行できます。CVO のデフォルトの導入では、クラスタ間 LIF が自動的に設定されます。</block>
  <block id="9547803d96e78bbc38305e6300f7a800" category="paragraph">オンプレミスクラスタ：</block>
  <block id="2ef6da9ba547bc5361495650ac3fc992" category="paragraph"><block ref="2ef6da9ba547bc5361495650ac3fc992" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3c5b3e342f57b792e2263e69e41677a" category="paragraph">ターゲットの CVO クラスタ：</block>
  <block id="d94586e4cd285619a4f1ef0e06636dd1" category="paragraph"><block ref="d94586e4cd285619a4f1ef0e06636dd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79d372933b80ed2ca8ca14d8458828af" category="inline-link-macro">はじめに - AWS パブリッククラウド</block>
  <block id="6a87ea28950f9209121872c9d2690049" category="list-text">クラスタ間 LIF を設定した場合、 NetApp Cloud Manager でドラッグアンドドロップを使用してクラスタピアリングとボリュームレプリケーションを設定できます。を参照してください <block ref="28783e162df4af496939d6f9f6f31d5f" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="d1567c6c8f0752cbc7deb6d9f639ba12" category="paragraph">または、 ONTAP System Manager を使用して、クラスタピアリングと DB ボリュームレプリケーションを次のように実行することもできます。</block>
  <block id="494c0b53ff31502c0c1105881e2e389a" category="list-text">ONTAP システムマネージャにログインします。クラスタ &gt; 設定に移動し、ピアクラスタをクリックして、クラウド内の CVO インスタンスとのクラスタピアリングをセットアップします。</block>
  <block id="ba770272a0f634af47a5788634e80d54" category="paragraph"><block ref="ba770272a0f634af47a5788634e80d54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54de72c782c4b4ccc7f2914a858d5356" category="list-text">Volumes （ボリューム）タブに移動します。レプリケートするデータベースボリュームを選択し、 Protect （保護）をクリックします。</block>
  <block id="32588f46a47679329b03194fd2e9084f" category="paragraph"><block ref="32588f46a47679329b03194fd2e9084f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0aace069b478e8b2b0753f855f2be94" category="list-text">保護ポリシーを非同期に設定します。デスティネーションクラスタと Storage SVM を選択してください。</block>
  <block id="7dbec53b432ae53f7e454836ad0dad00" category="paragraph"><block ref="7dbec53b432ae53f7e454836ad0dad00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a2a64fe8af0790615a9344069794e2e" category="list-text">ソースとターゲットの間でボリュームが同期されていること、およびレプリケーション関係が正常な状態であることを確認します。</block>
  <block id="97edcd79a5e90d9caafde40fcb586185" category="paragraph"><block ref="97edcd79a5e90d9caafde40fcb586185" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36097c4ad6058de288de8992f89adbb8" category="section-title">6. CVO データベースストレージの SVM を SnapCenter に追加する</block>
  <block id="ebcf85d67af3f672ade8bd7b224a8a2b" category="list-text">メニューからストレージシステムタブをクリックし、新規をクリックして、レプリケートされたターゲットデータベースボリュームをホストする CVO ストレージ SVM を SnapCenter に追加します。Storage System フィールドにクラスタ管理 IP を入力し、適切なユーザ名とパスワードを入力します。</block>
  <block id="41e9c94a0c8cb108959099b8f87adb82" category="paragraph"><block ref="41e9c94a0c8cb108959099b8f87adb82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a27406b63f99780f65572b95f2f72348" category="list-text">[ その他のオプション ] をクリックして、追加のストレージ構成オプションを開きます。[ プラットフォーム Cloud Volumes ONTAP ] フィールドで、 [ 保存 ] をクリックし、 [ セカンダリ ] をオンにします。</block>
  <block id="8a60464ab91cb2499a03c722639c3aee" category="paragraph"><block ref="8a60464ab91cb2499a03c722639c3aee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b474a0a2de59b8e3013112beb48af7b7" category="list-text">に示すように、ストレージシステムを SnapCenter データベース管理ユーザ ID に割り当てます <block ref="8a46cbc3838a53b9205abb25a577bbc8" category="inline-xref-macro-rx"></block>。</block>
  <block id="8691f91a1fe977fd76aa5e53b0f71034" category="paragraph"><block ref="8691f91a1fe977fd76aa5e53b0f71034" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39ec95149453e7bb6b73f1c03228e85c" category="section-title">7. SnapCenter でデータベースバックアップポリシーを設定します</block>
  <block id="37d9f685e375f77a2231e13c88ccc606" category="paragraph">次に、フルデータベースバックアップポリシーまたはログファイルバックアップポリシーを作成する手順を示します。このポリシーを実装することで、データベースリソースを保護できます。データベースバックアップやログバックアップの頻度は、 Recovery Point Objective （ RPO ；目標復旧時点）または Recovery Time Objective （ RTO ；目標復旧時間）によって決まります。</block>
  <block id="739184f368f13e142dd034fcdc853594" category="section-title">Oracle のフルデータベースバックアップポリシーを作成します</block>
  <block id="94b39254a7aba068b68fec64f6331b0b" category="list-text">データベース管理ユーザ ID として SnapCenter にログインし、 [ 設定 ] をクリックして、 [ ポリシー ] をクリックします。</block>
  <block id="90affc4ffbb767a3d1272be5e1ad8f0c" category="paragraph"><block ref="90affc4ffbb767a3d1272be5e1ad8f0c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1d144b8c78fc8541b57aa9f0ca863a6" category="list-text">新規をクリックして新しいバックアップポリシー作成ワークフローを開始するか、変更する既存のポリシーを選択します。</block>
  <block id="29618ae8465c694d23d68e171fe9d905" category="paragraph"><block ref="29618ae8465c694d23d68e171fe9d905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c9dac29c26006ce512153a9bdabcc95" category="list-text">バックアップタイプとスケジュール頻度を選択します。</block>
  <block id="10e2791563a2891fd7e4e68c5673671b" category="paragraph"><block ref="10e2791563a2891fd7e4e68c5673671b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4df94ad44381c9fb7fe2f8d01dcd16d8" category="list-text">バックアップ保持を設定します。これにより、保持するフルデータベースバックアップコピーの数が定義されます。</block>
  <block id="6dcc4aa023085480846059b6b1d5e5b3" category="paragraph"><block ref="6dcc4aa023085480846059b6b1d5e5b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd634020906b35a41e0ba633eddeb96a" category="list-text">セカンダリレプリケーションのオプションを選択して、クラウドのセカンダリサイトにレプリケートするローカルプライマリ Snapshot バックアップをプッシュします。</block>
  <block id="25ef9e4c73a2da8519e8d232b6a95fcb" category="paragraph"><block ref="25ef9e4c73a2da8519e8d232b6a95fcb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2e3af55a4355bc46e91425ac5701174" category="list-text">バックアップの実行前と実行後に実行するオプションのスクリプトを指定します。</block>
  <block id="326d50fae4f713cebe97d0f6bb23a2d9" category="paragraph"><block ref="326d50fae4f713cebe97d0f6bb23a2d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd009bc210e371d36d466b592179e883" category="list-text">必要に応じてバックアップ検証を実行</block>
  <block id="0b132e3438f5cf31e90f45e79710f0b9" category="paragraph"><block ref="0b132e3438f5cf31e90f45e79710f0b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba73d3ec3f929ff18665087076291ac" category="list-text">まとめ</block>
  <block id="4f92fa99421beeb9f74ee7613de52706" category="paragraph"><block ref="4f92fa99421beeb9f74ee7613de52706" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3594f2789840eda9633139ca530384a" category="section-title">Oracle のデータベースログバックアップポリシーを作成します</block>
  <block id="be763ec2afcb0358426bb0abcae4dd60" category="list-text">データベース管理ユーザ ID で SnapCenter にログインし、 [ 設定 ] をクリックして、 [ ポリシー ] をクリックします。</block>
  <block id="b0e663a3d363868d6c71ab9ec37940c6" category="list-text">新規をクリックして新しいバックアップポリシー作成ワークフローを開始するか、既存のポリシーを選択して変更します。</block>
  <block id="fa2687f5a5fbedb43745f649a2e11950" category="paragraph"><block ref="fa2687f5a5fbedb43745f649a2e11950" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0938f6574b189bdac27cdd92abc521c5" category="paragraph"><block ref="0938f6574b189bdac27cdd92abc521c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59480846ec23463481d361bf3026235e" category="list-text">ログの保持期間を設定します。</block>
  <block id="c8df578fbf71151edda735bc81e8511c" category="paragraph"><block ref="c8df578fbf71151edda735bc81e8511c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04ba33c0584145006ca637b4556aa919" category="list-text">パブリッククラウド内のセカンダリサイトへのレプリケーションを有効にします。</block>
  <block id="fdbe42a8484a3e984e4aacb6a31cccef" category="paragraph"><block ref="fdbe42a8484a3e984e4aacb6a31cccef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab9406cbd3a8f082700523fdac8a0c1d" category="list-text">ログバックアップの前後に実行するオプションのスクリプトを指定します。</block>
  <block id="5b04423521e56720f1f5d0291db584ef" category="paragraph"><block ref="5b04423521e56720f1f5d0291db584ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4b55e05a9ae89fe14377b98bc8a8166" category="list-text">バックアップ検証スクリプトを指定します。</block>
  <block id="c4dc219fd9466ab86c22ac8e859384ea" category="paragraph"><block ref="c4dc219fd9466ab86c22ac8e859384ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2564f2d008c62044da1b7f7397252edf" category="paragraph"><block ref="2564f2d008c62044da1b7f7397252edf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe147647227dfec6603bc76daf30463e" category="section-title">SQL のフルデータベースバックアップポリシーを作成します</block>
  <block id="fa726a7e85857bee77ace96dcf7e5316" category="paragraph"><block ref="fa726a7e85857bee77ace96dcf7e5316" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce2168daff0c9b1a74e59d999d6ead44" category="paragraph"><block ref="ce2168daff0c9b1a74e59d999d6ead44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30637cfd5a5cc820d6bc4116fccfff7e" category="list-text">バックアップオプションとスケジュール頻度を定義します。可用性グループが設定された SQL Server の場合は、優先バックアップレプリカを設定できます。</block>
  <block id="b520dcfd25c4b29395bb9b12ac643bb2" category="paragraph"><block ref="b520dcfd25c4b29395bb9b12ac643bb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f74ada8393aecd40e892de04b5b30f8" category="list-text">バックアップの保持期間を設定します。</block>
  <block id="4ade95d8122243cda1455b04504d3367" category="paragraph"><block ref="4ade95d8122243cda1455b04504d3367" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1a67a80a7ad9403781b210983ea778d" category="list-text">クラウドのセカンダリサイトへのバックアップコピーレプリケーションを有効にする。</block>
  <block id="caf8324e53d9bb41b3ecb64f3e3b7dda" category="paragraph"><block ref="caf8324e53d9bb41b3ecb64f3e3b7dda" category="inline-image-macro-rx" type="image"></block></block>
  <block id="17b7b360fc2163537795a34cd8d14d6a" category="list-text">バックアップジョブの前後に実行するオプションのスクリプトを指定します。</block>
  <block id="abbc7de57d2b0d5d1c462b7513199253" category="paragraph"><block ref="abbc7de57d2b0d5d1c462b7513199253" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb836d972496d965dd2170ed1480917b" category="list-text">バックアップ検証を実行するオプションを指定します。</block>
  <block id="b4dd01df6b310e6b0814328a86bd6ed6" category="paragraph"><block ref="b4dd01df6b310e6b0814328a86bd6ed6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67cfb8548ccb78172db31d7af494fa02" category="paragraph"><block ref="67cfb8548ccb78172db31d7af494fa02" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b67ed2348002e614d5a35151577632" category="section-title">SQL のデータベースログバックアップポリシーを作成します。</block>
  <block id="b405195aec7cf62440373fcdc490dec6" category="list-text">データベース管理ユーザ ID で SnapCenter にログインし、 [ 設定 ] 、 [ ポリシー ] 、 [ 新規 ] の順にクリックして、新しいポリシー作成ワークフローを開始します。</block>
  <block id="c236030076b67936a7c1c11d49408838" category="paragraph"><block ref="c236030076b67936a7c1c11d49408838" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acdaf46fc90606d68f3f2b52cca5e95b" category="list-text">ログバックアップオプションとスケジュール頻度を定義します。可用性グループが設定された SQL Server の場合は、優先バックアップレプリカを設定できます。</block>
  <block id="19ab604707a9384fa4883cedd5a525f9" category="paragraph"><block ref="19ab604707a9384fa4883cedd5a525f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da00d968a5d810d846ddc815b8f405a4" category="list-text">SQL Server データバックアップポリシーでログバックアップの保持を定義します。デフォルトをここで受け入れます。</block>
  <block id="783828e5ae6dcfd713966e7301831296" category="paragraph"><block ref="783828e5ae6dcfd713966e7301831296" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d04d89062d3ed67bbc9c4aee35bdba7f" category="list-text">クラウドのセカンダリへのログバックアップのレプリケーションを有効にします。</block>
  <block id="b1968bd01bc5c402dcd27c99ce6326cc" category="paragraph"><block ref="b1968bd01bc5c402dcd27c99ce6326cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30c50cf9d6726341a29a3caf97dc84e8" category="paragraph"><block ref="30c50cf9d6726341a29a3caf97dc84e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4d9b291b4ffaddb50c99313e530077f" category="paragraph"><block ref="c4d9b291b4ffaddb50c99313e530077f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f28f6c36698b3a4cd47cbeead15eddf2" category="section-title">8. データベースを保護するためのバックアップポリシーを実装します</block>
  <block id="37b889cc1b57f66ae9018b6eacb891ba" category="paragraph">SnapCenter では、リソースグループを使用して、サーバでホストされている複数のデータベース、同じストレージボリュームを共有しているデータベース、ビジネスアプリケーションをサポートしている複数のデータベースなど、データベースリソースを論理的にグループ化してデータベースをバックアップします。1 つのデータベースを保護すると、そのデータベース専用のリソースグループが作成されます。次の手順は、セクション 7 で作成したバックアップポリシーを実装して、 Oracle データベースと SQL Server データベースを保護する方法を示しています。</block>
  <block id="0603dbbe978e4cd3ee1c45ba96a1aa6f" category="section-title">Oracle のフルバックアップ用のリソースグループを作成する</block>
  <block id="5f4e02f34bcd7993867c4b3297a171d0" category="list-text">データベース管理ユーザ ID で SnapCenter にログインし、 Resources タブに移動します。[ 表示 ] ドロップダウンリストで、 [ データベース ] または [ リソースグループ ] を選択して、リソースグループ作成ワークフローを起動します。</block>
  <block id="6eac6f96ac8d968dfec8184d16a73d43" category="paragraph"><block ref="6eac6f96ac8d968dfec8184d16a73d43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="98dcf41bcde9cb6c4235a6a7dfe69346" category="list-text">リソースグループの名前とタグを指定します。Snapshot コピーの命名形式を定義し、冗長なアーカイブログデスティネーションが設定されている場合は省略できます。</block>
  <block id="a75ba82042ae54dd2e68cf6c7a26614c" category="paragraph"><block ref="a75ba82042ae54dd2e68cf6c7a26614c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0cd85a82e6f02b779006b158b9c5f828" category="list-text">リソースグループにデータベースリソースを追加する。</block>
  <block id="3836a8be1f86b6658a7fa6b180e4a72d" category="paragraph"><block ref="3836a8be1f86b6658a7fa6b180e4a72d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cee52cb6702e7590fbef45eccc8fb2df" category="list-text">ドロップダウンリストから、セクション 7 で作成したフルバックアップポリシーを選択します。</block>
  <block id="af900bffdda986bc1db955ae78832742" category="paragraph"><block ref="af900bffdda986bc1db955ae78832742" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fe872cd84ea2e9051770379e63f9caf" category="list-text">（ + ）記号をクリックして、目的のバックアップスケジュールを設定します。</block>
  <block id="9da504fd8ab60cfcc873608530cf5d56" category="paragraph"><block ref="9da504fd8ab60cfcc873608530cf5d56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdc27a4c5d48dbfc04f81ecac85acd64" category="list-text">Load Locators （ロケータのロード）をクリックして、ソースボリュームとデスティネーションボリュームをロードします。</block>
  <block id="7242164857e43688f8a7bec97559c36e" category="paragraph"><block ref="7242164857e43688f8a7bec97559c36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b612dc8868902cf8fbf2b1024ad94e65" category="paragraph"><block ref="b612dc8868902cf8fbf2b1024ad94e65" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95633243861715786b64e1554b629435" category="paragraph"><block ref="95633243861715786b64e1554b629435" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f7192b9766e6f09c261f3ca3d3bddc8" category="section-title">Oracle のログバックアップ用のリソースグループを作成します</block>
  <block id="1a0cd5de7c84ddbf632838dd9f510d37" category="paragraph"><block ref="1a0cd5de7c84ddbf632838dd9f510d37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0ad3d9537c50952c04b71be3f9d4579" category="paragraph"><block ref="f0ad3d9537c50952c04b71be3f9d4579" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c33c31714f671e112fbe52b660d3e7a4" category="paragraph"><block ref="c33c31714f671e112fbe52b660d3e7a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03955b73285eab0d68e90c627da9726d" category="list-text">ドロップダウンリストから、セクション 7 で作成したログバックアップポリシーを選択します。</block>
  <block id="6286629570d2ca91cf6860e7da6e9073" category="paragraph"><block ref="6286629570d2ca91cf6860e7da6e9073" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88c73129e9a418955658ce5c48d9d8b5" category="list-text">（ + ）記号をクリックして、目的のバックアップスケジュールを設定します。</block>
  <block id="8cdd30063d988671ffa9240fe171b1ce" category="paragraph"><block ref="8cdd30063d988671ffa9240fe171b1ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eacfd6f10777b8dfb41199e4d4dfa915" category="list-text">バックアップ検証が設定されている場合は、ここに表示されます。</block>
  <block id="69911c1794125b768effca94c8153987" category="paragraph"><block ref="69911c1794125b768effca94c8153987" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a27fac4b1d49d5468930a56c3a6de56" category="list-text">必要に応じて、 E メール通知用の SMTP サーバを設定します。</block>
  <block id="fd540644538dcedf1f6543455447728f" category="paragraph"><block ref="fd540644538dcedf1f6543455447728f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="554dbe35f6afa38e8232497f5d05d1c1" category="paragraph"><block ref="554dbe35f6afa38e8232497f5d05d1c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf688c7a95f421447e84a47fd03f3aa2" category="section-title">SQL Server のフルバックアップ用のリソースグループを作成する</block>
  <block id="d08ef097ee33c4a3506183adeb51c5e7" category="list-text">データベース管理ユーザ ID で SnapCenter にログインし、 Resources タブに移動します。[ 表示 ] ドロップダウンリストで、 [ データベース ] または [ リソースグループ ] を選択して、リソースグループ作成ワークフローを起動します。リソースグループの名前とタグを指定します。Snapshot コピーの命名形式を定義できます。</block>
  <block id="87d2630813d214672697efc01974d64e" category="paragraph"><block ref="87d2630813d214672697efc01974d64e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ace5324d60cb3faa1863efd675149" category="list-text">バックアップするデータベースリソースを選択します。</block>
  <block id="15330fe5b8f32032bd3b30c091d7dc4b" category="paragraph"><block ref="15330fe5b8f32032bd3b30c091d7dc4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2fc1974f486effa4a60bf216e63a88d5" category="list-text">セクション 7 で作成したフル SQL バックアップポリシーを選択します。</block>
  <block id="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="paragraph"><block ref="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b70beeb570488ba753a620378cacd8" category="list-text">バックアップの正確なタイミングおよび頻度を追加します。</block>
  <block id="8fa0a3897bc03e9b1653d17308464031" category="paragraph"><block ref="8fa0a3897bc03e9b1653d17308464031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49252579bd8140847f4bbac20ef89b07" category="list-text">バックアップ検証を実行する場合は、セカンダリ上のバックアップ用の検証サーバを選択します。Load Locator （ロケータのロード）をクリックしてセカンダリストレージの場所を入力します。</block>
  <block id="355e5eb56524b7365674014ea5868ee6" category="paragraph"><block ref="355e5eb56524b7365674014ea5868ee6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19e819eadb96ee5769ff4c6309352a62" category="paragraph"><block ref="19e819eadb96ee5769ff4c6309352a62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0be278d93ec2e64895e31bf440c54b98" category="paragraph"><block ref="0be278d93ec2e64895e31bf440c54b98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4dd921984d3a8a89e7df5c97875b923" category="section-title">SQL Server のログバックアップ用のリソースグループを作成します</block>
  <block id="4e94ca9b995e68691b4e67b82b9f5bce" category="list-text">データベース管理ユーザ ID で SnapCenter にログインし、 Resources タブに移動します。[ 表示 ] ドロップダウンリストで、 [ データベース ] または [ リソースグループ ] を選択して、リソースグループ作成ワークフローを起動します。リソースグループの名前とタグを指定します。Snapshot コピーの命名形式を定義できます。</block>
  <block id="4e71263f0aec815017fd21a22ddb87d6" category="paragraph"><block ref="4e71263f0aec815017fd21a22ddb87d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="013faf9f6cde83814469c6d583e10702" category="paragraph"><block ref="013faf9f6cde83814469c6d583e10702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23e15d7c127e66b1da1d72072a29e9eb" category="list-text">セクション 7 で作成した SQL ログバックアップポリシーを選択します。</block>
  <block id="52a8553e4c33eb8353d56286d3845b28" category="paragraph"><block ref="52a8553e4c33eb8353d56286d3845b28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e7cac98c16b45d7e4ebec8786b8fda1" category="list-text">バックアップの正確なタイミングと頻度を追加します。</block>
  <block id="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="paragraph"><block ref="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68398b6746dde91649e96505d97acc40" category="list-text">バックアップ検証を実行する場合は、セカンダリ上のバックアップ用の検証サーバを選択します。Load Locator をクリックしてセカンダリストレージの場所を入力します。</block>
  <block id="3bde998a2436b40589b20d91a713d3ee" category="paragraph"><block ref="3bde998a2436b40589b20d91a713d3ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80000e8cb7742af4686df786fdf38249" category="paragraph"><block ref="80000e8cb7742af4686df786fdf38249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d32fb038efa6b409f8dedd0e02a10f26" category="paragraph"><block ref="d32fb038efa6b409f8dedd0e02a10f26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c72629a46c2e88cf7f6a012167bb16" category="section-title">9. バックアップを検証する</block>
  <block id="d1c55c296cbdaa8d88eda765a6158b62" category="paragraph">データベースリソースを保護するためにデータベースバックアップリソースグループを作成すると、定義済みのスケジュールに従ってバックアップジョブが実行されます。[ モニタ ] タブでジョブの実行ステータスを確認します。</block>
  <block id="5f9af2a4e435e2b39c27f43b580d6d20" category="paragraph"><block ref="5f9af2a4e435e2b39c27f43b580d6d20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57882e224a8cbe8f694da9b1d8fa503e" category="paragraph">リソースタブでデータベース名をクリックしてデータベースバックアップの詳細を表示し、ローカルコピーとミラーコピーを切り替えて、 Snapshot バックアップがパブリッククラウドのセカンダリサイトにレプリケートされていることを確認します。</block>
  <block id="f9b40afbdb387dd32b8523c95080a898" category="paragraph"><block ref="f9b40afbdb387dd32b8523c95080a898" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28268d417882b5cf7a3d3ee3a15834c8" category="paragraph">この時点で、クラウド内のデータベースバックアップコピーをクローニングして、開発 / テストプロセスを実行したり、プライマリに障害が発生した場合にディザスタリカバリを実行したりできます。</block>
  <block id="78b29bbf3f07a44b62307ce90b34904e" category="inline-link-macro">次は、 AWS パブリッククラウドの導入を開始するにあたり、</block>
  <block id="7d32c0298884bcc4c0211357748d0e6e" category="paragraph"><block ref="7d32c0298884bcc4c0211357748d0e6e" category="inline-link-macro-rx"></block></block>
  <block id="0f22160e43c900ef7426d8a19e9f482d" category="summary">ハイブリッドクラウドデータベースワークロードを実行する前に、オンプレミスとクラウドの両方で特定の前提条件を設定する必要があります。ここでは、このプロセスの概要を示し、必要なシステム構成の詳細については次のリンクを参照してください。</block>
  <block id="1dad826770c4d2c619351c974f725b36" category="doc">前提条件の設定</block>
  <block id="ce38f65c711e7e3047c9350abe42c0c3" category="inline-link-macro">以前のバージョン：ソリューションの要件。</block>
  <block id="d3fe0eebddd46d46399cb319c7219427" category="paragraph"><block ref="d3fe0eebddd46d46399cb319c7219427" category="inline-link-macro-rx"></block></block>
  <block id="4df40e141b0559f15db8f84f78aed013" category="section-title">オンプレミス</block>
  <block id="caea8340e2d186a540518d08602aa065" category="list-text">自動化</block>
  <block id="761883c0d5c55fba5b200ac8ac0d86e5" category="section-title">パブリッククラウド</block>
  <block id="37aa83a33297d9d16b4423be342598bb" category="list-text">コネクタのネットワーク上の場所</block>
  <block id="74c043a4451dd260729a23ce96aa1550" category="paragraph">重要な考慮事項：</block>
  <block id="7aee27c83b5e3622c1d8cbd5c2098c60" category="list-text">Cloud Manager Connector の導入場所</block>
  <block id="43fd5c6fa3d9ba8a215c31f3bf0a9859" category="list-text">Cloud Volumes ONTAP のサイジングとアーキテクチャ</block>
  <block id="7a0e00d70e3b0ff06476a52565f923c4" category="list-text">シングルノードとハイアベイラビリティのどちらか？</block>
  <block id="2d0b46fff3ae203a435b167c7111b389" category="paragraph">詳細については、次のリンクを参照してください。</block>
  <block id="cfd98f49422c4fba755a2ff74c55a4a0" category="paragraph"><block ref="cfd98f49422c4fba755a2ff74c55a4a0" category="inline-link-macro-rx"></block></block>
  <block id="704849d56e695ab8f9df0b106e0d7e33" category="inline-link-macro">パブリッククラウド</block>
  <block id="96e41b2b281ca4b71edf4ed16e46a2be" category="paragraph"><block ref="96e41b2b281ca4b71edf4ed16e46a2be" category="inline-link-macro-rx"></block></block>
  <block id="7c12725837ee75c4c0a9bbc14f99934d" category="inline-link-macro">次のステップ：オンプレミスでの前提条件</block>
  <block id="bc57dd30a9059d494c9d76e4b0a9ce8f" category="paragraph"><block ref="bc57dd30a9059d494c9d76e4b0a9ce8f" category="inline-link-macro-rx"></block></block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">Lenovo ThinkSystem-解決策 Design を使用したエッジネットアップでの AI 推論</block>
  <block id="30b22b544972f5adb280ca2975099846" category="sidebar">SnapCenter を使用したハイブリッドクラウドデータベースソリューション</block>
  <block id="59f8ae0d5c4ba13dee4828e2727c8859" category="sidebar">オンプレミスでの作業の開始</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">次の図は、 NetApp EF280 ストレージシステムを示しています。</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1 は、ネットアップの最新世代のストレージ管理ソフトウェアです。インフラを最新化し、クラウド対応データセンターに移行することができます。ONTAP は、業界をリードするデータ管理機能を活用して、データの格納場所に関係なく、単一のツールセットでデータの管理と保護を実現します。エッジ、コア、クラウドなど、必要な場所に自由にデータを移動することもできます。ONTAP 9.8.1 には、データ管理を簡易化し、重要なデータの高速化と保護を実現し、ハイブリッドクラウドアーキテクチャ全体で次世代インフラ機能を実現する、多数の機能が搭載されています。</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">登録が必要なデータセット、 ImageNet 2012 Validation set 、 Crito Terabyte データセット、および BRT 2019 Training セットをダウンロードし、ファイルを解凍します。</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">1TB 以上の作業ディレクトリを作成し、ディレクトリを参照する環境変数「 M LPERF_scratch_path 」を定義します。</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">make 「 prebuild 」コマンドを実行します。このコマンドは、必要な推論タスク用の Docker コンテナを構築して起動します。</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">MLPerf Inference タスク用のトレーニング済み AI モデル「 make download_model 」をダウンロードしてください</block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">無料でダウンロードできる追加のデータセット「 make download_data 」をダウンロードしてください</block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">データをプリプロセスします。「 preprocess_data 」にします</block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">「 make build 」を実行します。</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">コンピューティングサーバの GPU に最適化された推論エンジン「 generate_engines 」を構築します</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">このベンチマークではレイテンシを測定します。いずれの場合も、実行に関連するすべてのサーバの平均レイテンシを報告します。一連のタスクの結果が表示されます。</block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">結果から、このタスクを処理するのに十分なネットワークストレージがあることが再びわかります。1 つのサーバケースにおけるローカルストレージとネットワークストレージの違いは、最小またはなしです。同様に、 2 台のサーバが同じストレージを使用している場合、両方のサーバの遅延は同じままであるか、非常に小さい値で変化します。</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">この Lenovo ThinkSystem サーバと NetApp ONTAP または NetApp SANtricity ストレージ解決策は、従来の CPU に加えて GPU の処理能力を使用して大規模なデータセットで AI 推論を処理するように設計されています。この検証では、次の 2 つの図に示すように、単一または複数の Lenovo SR350 エッジサーバを 1 つの NetApp AFF ストレージシステムと相互接続したアーキテクチャを使用して、パフォーマンスと最適なデータ管理を実現します。</block>
  <block id="aacb24ff7918ccc37aea66f8c9548b68" category="paragraph"><block ref="aacb24ff7918ccc37aea66f8c9548b68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">次の図の論理アーキテクチャの概要は、このアーキテクチャのコンピューティング要素とストレージ要素の役割を示しています。具体的には、次の情報が表示されます。</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">このドキュメントは MLPerf 推論 v0.7 に準拠しています<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block>、 MLPerf Inference v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block>および<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block>。次の表に示すように、エッジでの推論向けに設計された MLPerf ベンチマークを実行しました。</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">次の表に、 Edge ベンチマークのシナリオを示します。</block>
  <block id="5174c42549c4dd0407a40298a4d9e362" category="paragraph"><block ref="5174c42549c4dd0407a40298a4d9e362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8a1e11a906a27bd156606bf4717e8e8" category="summary">このサポートセンターの解決策のアーキテクチャは、 NVIDIA が構築したツールと NetApp DataOps ツールキットを中心にしています。NVIDIA のツールを使用すると、構築済みのモデルとパイプラインを使用して、ハイパフォーマンスな AI ソリューションを迅速に導入できます。NetApp DataOps ツールキットにより、さまざまなデータ管理タスクが簡易化され、開発期間が短縮されます。</block>
  <block id="d51083e81cbf0ec7828af24692206315" category="inline-link-macro">以前のバージョン：ユースケース</block>
  <block id="beff34f173af198016bee889c9f9ed7a" category="paragraph"><block ref="beff34f173af198016bee889c9f9ed7a" category="inline-link-macro-rx"></block></block>
  <block id="c779b37f861deb44744634dea201514f" category="inline-link-macro">NVIDIA RIVA</block>
  <block id="ccfdc9ae99a97b7a6b8ad83a329bcdc8" category="paragraph"><block ref="eb3a0fd60dc608626ce6d809beb18359" category="inline-link-macro-rx"></block> GPU でリアルタイムのパフォーマンスを実現する、マルチモーダルな会話型 AI アプリケーションを構築するための GPU アクセラレーション対応 SDK です。NVIDIA Train 、 Adapt 、 Optimize （ TAO ）ツールキットは、トレーニングを高速化し、高精度で高性能なドメイン固有の AI モデルをすばやく簡単に作成する方法を提供します。</block>
  <block id="600ff5755ecd6aa4213eb806162b679e" category="paragraph">NetApp DataOps ツールキットは Python ライブラリで、開発者、データサイエンティスト、 DevOps エンジニア、データエンジニアはさまざまなデータ管理タスクを簡単に実行できます。これには、新しいデータボリュームまたは JupyterLab ワークスペースのほぼ瞬時のプロビジョニング、データボリュームまたは JupyterLab ワークスペースのほぼ瞬時のクローニング、データボリュームまたは JupyterLab ワークスペースのほぼ瞬時の Snapshot コピーによるトレーサビリティとベースライン設定が含まれます。</block>
  <block id="1c8bd88c9d2cb845c6c27915f4a3fe8e" category="paragraph">次の図は、解決策のアーキテクチャを示しています。環境には、クラウド、コア、エッジの 3 つのカテゴリがあります。各カテゴリは地理的に分散させることができます。たとえば、クラウドにはバケット内の音声ファイルを含むオブジェクトストアがあり、コアには高速ネットワークまたは NetApp Cloud Sync 経由でリンクされたデータセンターが含まれる場合があります。エッジノードは、ヒューマンエージェントの日常的な作業プラットフォームを表しています。このプラットフォームでは、対話型ダッシュボードツールとマイクを使用して感情を視覚化したり、顧客との会話から音声データを収集したりできます。</block>
  <block id="5d103a663d28ddc9aa2af5f7b958e52c" category="inline-link">リバ</block>
  <block id="cc7a5a83afae781789c3a002465500b5" category="inline-link">Tao ツールキット</block>
  <block id="9595827147dc1170c44979ae1fcabaa6" category="paragraph">GPU によって高速化されたデータセンターでは、 NVIDIA を使用できます<block ref="cfd3aefe24e0725c1b0424dd8b503dc1" category="inline-link-rx"></block> 会話型 AI アプリケーションを構築するためのフレームワーク。それには、があります<block ref="ccdd6931e40e98163a0ae3c3c3bfb185" category="inline-link-rx"></block> Transfer L ラーニング技術を使用して、モデルのフィニッチニングと再トレーニングを接続します。これらのコンピューティングアプリケーションとワークフローは、を基盤としています<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>ONTAP が提供する最高のデータ管理機能を実現します。このツールキットを使用すると、企業のデータチームは、スナップショットやクローンを使用して、構造化データと非構造化データでモデルのプロトタイプを迅速に作成できるため、トレーサビリティ、バージョン管理、 A/B テストを実現し、セキュリティ、ガバナンス、 コンプライアンスを実現できます。を参照してください <block ref="3f1432f6921bc0c51d34759cb0d748ab" category="inline-link-macro-rx"></block> 詳細：</block>
  <block id="816c3453eeba98af344f96d7eefe8834" category="paragraph">この解決策では、オーディオファイル処理、 NLP モデルトレーニング、トランスファーラーニング、およびデータ管理の詳細な手順について説明します。最終的なパイプラインが生成され、ヒューマンサポートエージェントのダッシュボードにリアルタイムで表示されるセンチメントの概要が生成されます。</block>
  <block id="b6fb1598d37d2537eed4160a485b790e" category="paragraph"><block ref="b6fb1598d37d2537eed4160a485b790e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62519b55e4debcf57caf02c89620de61" category="cell">応答遅延テスト</block>
  <block id="b763dc0a5ffab97a986c74098214cae6" category="cell">時間（ミリ秒）</block>
  <block id="08fa9c0a2e18301dd14e18c393fb4280" category="cell">データ処理</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10.</block>
  <block id="08db96f19d3c99c2b42fd180d9d81580" category="cell">推論</block>
  <block id="212e6da10eee5f14935bd37b84fe9684" category="paragraph">この応答時間テストは、 560 の会話で 50,000 以上のオーディオファイルで実行されました。各オーディオファイルのサイズは、 MP3 の場合は約 100 KB 、 WAV の場合は約 1 MB でした。データ処理手順では、 MP3 を WAV ファイルに変換します。推論の手順では、オーディオファイルをテキストに変換し、テキストから感情を抽出します。これらのステップは互いに独立しており、並列化することでプロセスを高速化できます。</block>
  <block id="c18e24981c583441c6975f2116288cb7" category="paragraph">ストア間でのデータ転送の遅延を考慮すると、マネージャは、文章の最後の 2 番目の時間内にリアルタイムの感情分析の更新を確認できるようになります。</block>
  <block id="1c4968697a5851a64ad0fbf1b594e919" category="section-title">NVIDIA Riva ハードウェア</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">OS</block>
  <block id="4c8be35e5fe3d8471f378a69f74c0ab6" category="cell">Linux x86_64</block>
  <block id="4d240f00b5a82cfaaf594cdc72f552f3" category="cell">GPU メモリ（ ASR ）</block>
  <block id="3fa503e0bb3bf46423ef9176821a1f6c" category="cell">ストリーミングモデル：最大 5600 MB の非ストリーミングモデル：約 3100 MB</block>
  <block id="6345afe417f42d9e0cf6a269bff00b4c" category="cell">GPU メモリ（ NLP ）</block>
  <block id="217941fb2e441b0bae1b5fec0b454c31" category="cell">1 つの BERT モデルで最大 500MB</block>
  <block id="7e04ebd38c78635d1f8aa53de0dde49b" category="section-title">NVIDIA TAO ツールキットハードウェア</block>
  <block id="03282e46abfd7449ab38bb851caf2c8d" category="cell">システム RAM</block>
  <block id="edaf98e5dae9931cbd74a93b3dd93849" category="cell">32 GB</block>
  <block id="6ddfc451ef4f9a7613468cd288d2ab3e" category="cell">GPU RAM</block>
  <block id="2b55387dd066c5bac646ac61543d152d" category="cell">CPU</block>
  <block id="04911a799cc8712b473ed5a3cb2b8904" category="cell">8 コア</block>
  <block id="fceec3562665d08f1dd24689f68f0f29" category="cell">NVIDIA （ A100 、 V100 、 RTX 30x0 ）</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD の場合</block>
  <block id="2f9289dfcac06a2ba95650d7e24ea9e8" category="cell">100GB</block>
  <block id="19aa61315132dbea1d19c7aeeef5f5b2" category="section-title">フラッシュストレージシステム</block>
  <block id="fd5487a1e906d6cd514dbbc16f17a489" category="paragraph">ネットアップの最新世代のストレージ管理ソフトウェア ONTAP 9.9 は、インフラの刷新とクラウド対応データセンターへの移行を可能にします。ONTAP は、業界をリードするデータ管理機能を活用して、データの格納場所に関係なく、単一のツールセットでデータの管理と保護を実現します。エッジ、コア、クラウドなど、必要な場所に自由にデータを移動することもできます。ONTAP 9.9 には、データ管理を簡素化し、重要なデータを高速化および保護し、ハイブリッドクラウドアーキテクチャ全体で次世代のインフラ機能を実現する、多数の機能が含まれています。</block>
  <block id="78a2efe59d4ad6ad51556ea77f5fdec3" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> は、高速でセキュアなデータ同期を実現するネットアップのサービスです。オンプレミスの NFS または SMB ファイル共有間で、次のいずれかのターゲットにファイルを転送できます。</block>
  <block id="df2c24964ca3e99761acc48b2c8a75c9" category="list-text">NetApp ONTAP S3</block>
  <block id="1a4c7c9b6e3157ccd0101fd0836c0bfc" category="list-text">NetApp Cloud Volumes Service の略</block>
  <block id="ddcf3699b41cd4c4ee5be4b9dd95c1e6" category="list-text">Amazon Simple Storage Service （ Amazon S3 ）</block>
  <block id="8224436b00c48149c863f4b17219a19d" category="list-text">Amazon Elastic File System （ Amazon EFS ）</block>
  <block id="52745271323ee9ea30e3a37d0338d118" category="list-text">Azure Blob の略</block>
  <block id="833c2c211a541e50ad94433664e4b5c1" category="list-text">Google クラウドストレージ</block>
  <block id="5446a6bee3301e1f52824fc0affa6299" category="list-text">IBM クラウドオブジェクトストレージ</block>
  <block id="1b238365e840da0711b49e8f646e2fdf" category="paragraph">Cloud Sync は、必要な場所に迅速かつ安全にファイルを移動します。転送されたデータは、ソースとターゲットの両方で完全に使用できます。Cloud Sync は、事前定義されたスケジュールに基づいてデータを継続的に同期し、差分のみを移動するため、データレプリケーションにかかる時間とコストを最小限に抑えることができます。Cloud Sync は、セットアップや使用が簡単なソフトウェアサービス（ SaaS ）ツールです。Cloud Sync によって実行されるデータ転送は、データブローカーによって実行されます。Cloud Sync データブローカーは、 AWS 、 Azure 、 Google Cloud Platform 、オンプレミスに導入できます。</block>
  <block id="a5c952f5be43013a024d778712474fbc" category="paragraph">StorageGRID の Software-Defined オブジェクトストレージスイートは、パブリッククラウド、プライベートクラウド、ハイブリッドマルチクラウド環境のすべてをシームレスにサポートし、幅広いユースケースに対応しています。業界をリードするイノベーションにより、 NetApp StorageGRID は、非構造化データを長期にわたって自動化されたライフサイクル管理などの多目的に保管、保護、保管します。詳細については、を参照してください<block ref="7660f0463c83c682b9f091117b07c3b3" category="inline-link-rx"></block> サイト</block>
  <block id="6ffce2da93d4b296032f30d7b2adea01" category="paragraph">次の表に、この解決策を実装するために必要なソフトウェアコンポーネントを示します。解決策の特定の実装で使用されるソフトウェアコンポーネントは、お客様の要件に応じて異なる場合があります。</block>
  <block id="d20072ce64f4d9efd57e036d2b7c30ec" category="cell">ホストマシン</block>
  <block id="7915eebeca25d928212b5d457786a549" category="cell">Riva ( 以前の開発コード名 Jarv)</block>
  <block id="1bf6e69c18341244d990250bf5aa3ce0" category="cell">1.4.0</block>
  <block id="7a2cd4790985cbbb0b362dfe8e59d991" category="cell">Tao ツールキット ( 以前の Transfer Learning Toolkit)</block>
  <block id="55c82b601deae028c1c5e87fd820923d" category="cell">3.0</block>
  <block id="67c6ecbcd91c613e8659b3f0c4b01510" category="cell">9.9.1</block>
  <block id="8bec4fb7fbc1430e393d3f41063748e7" category="cell">DGX OS</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="1b13fe3d4acac980a061d9efb92000d5" category="cell">DTK</block>
  <block id="d233662f9c26d1a06118c93ef2fd1de9" category="cell">2.0.0</block>
  <block id="76e535c7d7533499b0d86f60a0d15b84" category="section-title">NVIDIA Riva ソフトウェア</block>
  <block id="5d7bf724a19463b3251c61a94a446c4c" category="cell">&gt;19.02 （ NVIDIA - Docker をインストール済み） &gt;=19.03 （ DGX を使用していない場合</block>
  <block id="3ff6010d41ffb33d6f0971a202e76ad7" category="cell">NVIDIA ドライバ</block>
  <block id="616120c1963dd46f2321dd37e823f8a0" category="cell">465.19.01 + 418.40 + 、 440.33 + 、 450.51 + 、 460.27 + （データセンターの GPU の場合</block>
  <block id="88f8128d405513d54a3e9831c73f87a0" category="cell">コンテナ OS</block>
  <block id="73611f9a837b7a25dad3a9c5d1a98658" category="cell">Ubuntu 20.04</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="cell">CUDA （ CUDA</block>
  <block id="a26b47ba45087eadbeaa7c4802b3a8c8" category="cell">11.3.0</block>
  <block id="d92ef06e9564a9db573d075b4220057e" category="cell">cuBLAS</block>
  <block id="a8a364c27ce7406b7be591b4f973d5bb" category="cell">11.5.1.101</block>
  <block id="9bfd6cd63a5597c998aa2d96564f5c34" category="cell">cuDNN</block>
  <block id="15daa8f1432fd7e2b07f63097623dfab" category="cell">8.2.0.41</block>
  <block id="1ed15cc4178fd8ec4d845042a8f1ead0" category="cell">NCCL</block>
  <block id="f10585a0c5c8f535143471006baef867" category="cell">2.9.6</block>
  <block id="61918500e2bc645b2aea3f447086a8a5" category="cell">TensorRT</block>
  <block id="086934e5e95d3c797fc75f38fb3d086c" category="cell">7.2.3.4.</block>
  <block id="d024876954df77538311467564f00917" category="cell">Triton Inference サーバ</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="2efc85a476098fde0ecbf8d81505b612" category="section-title">NVIDIA TAO ツールキットソフトウェア</block>
  <block id="cb6c22f673a55391483c7f040d8cf637" category="cell">Ubuntu 18.04 LTS</block>
  <block id="23eeeb4347bdd26bfc6b7ee9a3b755dd" category="cell">Python</block>
  <block id="c80362c25c18981fcf433e78dda5de78" category="cell">3.6.9 以上</block>
  <block id="aec7ff22e2f74b581cffbfa59e63f347" category="cell">Docker - CE</block>
  <block id="21ca3af3ea5e6a282911a64dbf5ced7a" category="cell">19.03.5</block>
  <block id="0cf76d9b00333f4396d0424ae164dd07" category="cell">Docker - API</block>
  <block id="ca2b7e7213f7ba5d4b3923e807af27df" category="cell">1.40</block>
  <block id="ad2f80b0463af47fcb7430e0e1789841" category="cell">nvidia -container-toolkit</block>
  <block id="12b58130c1d9383cf3bf63391bd04721" category="cell">&gt;1.3.0-1</block>
  <block id="cec57b9746d41fd1c1749d591dbd7baf" category="cell">nvidia Container - ランタイム</block>
  <block id="68b90d96e3d934d65890ff695d37f354" category="cell">3.4.0 -1</block>
  <block id="f235b98dbe494fca328354abf0b52858" category="cell">nvidia - docker2</block>
  <block id="10439f6f665bce43173e2871a0b7bfc6" category="cell">2.5.0-1</block>
  <block id="fd3811d814e856dc6a43152673bb6753" category="cell">nVidia ドライバ</block>
  <block id="06c61cdd8c93e750b3e0d4e2537416ea" category="cell">&gt; 455</block>
  <block id="b6da1806d8ccb5327c3d80bbcfea4737" category="cell">python-pip</block>
  <block id="7b043cb99d00fe56df3fead569b1a4de" category="cell">&gt;21.06</block>
  <block id="3bdf92e45d10e51e2bdc2b16cf33f345" category="cell">nvidia -pyindex</block>
  <block id="9ca445b9db010a99239196af5ac3a8b9" category="cell">最新バージョン</block>
  <block id="cf87f69879c53ebf670ee8bd793ad7ba" category="section-title">ユースケースの詳細</block>
  <block id="7cb906d40b2e5bad2205a60ef8b6a019" category="list-text">感情分析</block>
  <block id="52a38da70697d6c80e3b6a204f64263f" category="paragraph"><block ref="52a38da70697d6c80e3b6a204f64263f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8ff4a485cc084b2a4b5bb829cf18055" category="paragraph">音声テキスト変換のユースケースは、まずサポートセンターの音声ファイルを取り込むことから始まります。このオーディオは、 Riva が必要とする構造に合わせて処理されます。オーディオファイルが解析単位に分割されていない場合は、オーディオを Riva に渡す前にこれを行う必要があります。オーディオファイルが処理されると、 API 呼び出しとして Riva サーバーに渡されます。サーバは、ホスティングしている多くのモデルの 1 つを採用し、応答を返します。この音声 / テキスト（自動音声認識の一部）は、音声のテキスト表現を返します。そこから、パイプラインはセンチメント分析部分に切り替わります。</block>
  <block id="230007c23660d290efdea5586b1716aa" category="paragraph">感情分析では、自動音声認識からのテキスト出力がテキスト分類への入力として機能します。Text Classification は、任意の数のカテゴリにテキストを分類するための NVIDIA コンポーネントです。サポートセンターとの会話では、感情のカテゴリがプラスからマイナスになります。モデルのパフォーマンスは、ホールドアウトセットを使用して、微調整ステップの成功を判断することができます。</block>
  <block id="3390cebd79348bc76a1e5eb5f169bedf" category="paragraph"><block ref="3390cebd79348bc76a1e5eb5f169bedf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="952b3f5758e644ef2558d59d3aace0b1" category="inline-link">NVIDIA NGC カタログ</block>
  <block id="4fa0a0d712258621946173068bf4f7e0" category="paragraph">TAO ツールキット内の音声テキスト分析と感情分析にも、同様のパイプラインが使用されています。主な違いは、モデルの微調整に必要なラベルの使用です。TAO ツールキットパイプラインは、データファイルの処理から始まります。次に、事前にトレーニングされたモデル（から入手可能<block ref="aaddb3bb47bcb0ca6e2a55cdce808e9b" category="inline-link-rx"></block>）は、サポートセンターのデータを使用して微調整されます。微調整されたモデルは、対応するパフォーマンス指標に基づいて評価され、事前トレーニングされたモデルよりもパフォーマンスが高い場合は、 Riva サーバに導入されます。</block>
  <block id="587796d49571c1c4d5c89993d7ed01dd" category="inline-link-macro">次：設計上の考慮事項</block>
  <block id="1165e49145cd3a7ebc2b75e325d8797a" category="paragraph"><block ref="1165e49145cd3a7ebc2b75e325d8797a" category="inline-link-macro-rx"></block></block>
  <block id="431db7b0dc79bb29f07c20c6060c3338" category="summary">このセクションでは、この解決策に役立つ Jupyter ノートブックとその他のリソースを示します。</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="doc">ビデオとデモ</block>
  <block id="eeb22c31d24f52a9b8225da48c32dd15" category="inline-link-macro">Previous ：検証結果</block>
  <block id="234bbb7420397102b6a782bcaafff71a" category="paragraph"><block ref="234bbb7420397102b6a782bcaafff71a" category="inline-link-macro-rx"></block></block>
  <block id="4b8db041d93aa27fd0cc94a261e224ca" category="inline-link-macro">「サポート - センタ - センチメント - 分析 - パイプライン .ipynb 」</block>
  <block id="4e336784d7218f9fd7024470cba6b522" category="inline-link">「サポート - センター - モデル - 転送 - 学習と微調整 .ipynb 」</block>
  <block id="46e3dcdd2c6c30a1d9fcf40d37f0deb3" category="paragraph">センチメント分析パイプラインを含むノートブックが 2 つあります。<block ref="8ed620ac9482ce00db4c0f6de7250148" category="inline-link-rx"></block> および <block ref="ff8619e3bd3fbeea07c38337a7b773f7" category="inline-link-macro-rx"></block>。これらのノートブックは、ユーザーのデータに微調整された最先端のディープラーニングモデルを使用して、サポートセンターのデータを取り込み、各文から感情を抽出するパイプラインを開発する方法を示しています。</block>
  <block id="fa8c0b2056c13341c1455ad44cc91889" category="section-title">サポートセンター - 感情分析パイプライン .ipynb</block>
  <block id="6b3450c2b921c398bbf90a1aee0b016c" category="paragraph">このノートブックには、オーディオの取り込み、テキストへの変換、外部ダッシュボードで使用するための感情の抽出を行う推論 Riva パイプラインが含まれています。データセットは、まだダウンロードされていない場合は自動的にダウンロードされて処理されます。ノートブックの最初のセクションは、音声ファイルからテキストへの変換を処理する Speech to Text です。続いて、各テキスト文の感情を抽出し、それらの結果を提案されたダッシュボードと同様の形式で表示する感情分析セクションが表示されます。</block>
  <block id="63abda3d2c420172da9a3a20c7f64dda" category="admonition">MP3 データセットをダウンロードして正しい形式に変換する必要があるため、このノートブックはモデルのトレーニングや微調整の前に実行する必要があります。</block>
  <block id="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="paragraph"><block ref="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="295c2feb943bbe2efca238849828084e" category="section-title">サポートセンター - モデルトレーニングと微調整 .ipynb</block>
  <block id="6efbeb8cfc7e387edbf91bad41170349" category="paragraph">ノートブックを実行する前に、 TAO Toolkit 仮想環境を設定する必要があります ( インストール手順については、『 Commands Overview 』の TAO Toolkit の項を参照してください ) 。</block>
  <block id="a9d805c9ddfdf62e60632a9754e29404" category="paragraph">このノートブックは、 TAIO ツールキットを使用して、お客様のデータに基づいてディープラーニングモデルを微調整します。前のノートブックと同様に、この 2 つのセクションに分かれて、 Speech to Text コンポーネントと、センチメント分析コンポーネントが表示されます。各セクションでは、データ処理、モデルトレーニング、微調整、結果の評価、およびモデルのエクスポートについて説明します。最後に、 Riva で使用するために、両方の微調整済みモデルを導入するための最終セクションがあります。</block>
  <block id="b40454c57dd60f999f3243514cd90ede" category="paragraph"><block ref="b40454c57dd60f999f3243514cd90ede" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f89bf51287609a0c0cf7563b31265c06" category="paragraph"><block ref="f89bf51287609a0c0cf7563b31265c06" category="inline-link-macro-rx"></block></block>
  <block id="00a9f41b5383bf6bcb5b7f6540d427b4" category="summary">NVIDIA 、 AWS 、 Google などが公開している最新のトレーニング済みモデリングツールを使用することで、複雑なモデルを含むエンドツーエンドのパイプラインを容易に構築してカスタマイズできるようになりました。</block>
  <block id="14e5cae1e8e56eca8add5bdcedfe2335" category="inline-link-macro">前のバージョン：データセンター分析をサポート</block>
  <block id="d39a6e05d58eb4f71cae7257dc52a1d0" category="paragraph"><block ref="d39a6e05d58eb4f71cae7257dc52a1d0" category="inline-link-macro-rx"></block></block>
  <block id="710217ef02bea8d1d76bc6fc0e7bc056" category="paragraph">これらのサポートセンターで処理されるコールの数が原因で、手動で実行した場合はコールパフォーマンスの評価にかなりの時間がかかる可能性があります。BAG of Words カウンティングなどの従来のメソッドは、いくつかの自動化を実現できますが、これらのメソッドは、ダイナミック言語の微妙な側面や意味をキャプチャしません。AI モデリング手法を使用すると、このように詳細な分析を自動化された方法で実行できます。さらに、 NVIDIA 、 AWS 、 Google などが公開している最新のトレーニング済みモデリングツールを使用することで、複雑なモデルを含むエンドツーエンドのパイプラインを容易に構築し、カスタマイズできるようになりました。</block>
  <block id="dd4541bcdb4728a1a380e825494f08e2" category="paragraph">サポートセンターの感情分析のためのエンドツーエンドのパイプラインは、従業員が発信者と会話するときに、音声ファイルをリアルタイムで取り込みます。次に、これらのオーディオファイルは音声テキストコンポーネントで使用するために処理され、テキスト形式に変換されます。会話中の各文は、感情（肯定的、否定的、または中立的）を示すラベルを受け取ります。</block>
  <block id="cfc9b6a29659e2208f66d876bd355200" category="paragraph">感情分析は、コールパフォーマンスを評価するための会話の重要な側面を提供することができます。これらの感情は、従業員と発信者間のやり取りにさらに深いレベルを追加します。AI を活用した感情ダッシュボードは、マネージャーが会話内の感情をリアルタイムに追跡し、従業員の過去の問い合わせを過去に分析します。</block>
  <block id="2357d01362feabb1716e49b27d23f9cf" category="inline-link">NVIDIA Maxine の 2 つのポートが</block>
  <block id="a2415fcdba82ba111e08286b17d98943" category="paragraph">この問題を解決するエンドツーエンドの AI パイプラインを迅速に構築するための強力な方法が用意されています。この場合、 NVIDIA Riva ライブラリを使用して、音声変換と感情分析の 2 つの直列タスクを実行できます。1 つ目は教師あり学習信号処理アルゴリズムで、 2 つ目は教師あり学習 NLP 分類アルゴリズムです。NVIDIA TAO Toolkit を使用すれば、ビジネス関連のデータを使用して、関連するあらゆるユースケースに合わせてアルゴリズムを微調整できます。その結果、コストとリソースの数分の 1 に過ぎず、より正確で強力なソリューションを構築できます。お客様はを組み込むことができます<block ref="2aa9e1b3ec0ddf7f0bf09cdb2976222a" category="inline-link-rx"></block> サポートセンター設計における GPU アクセラレーションビデオ会議アプリケーションのフレームワーク。</block>
  <block id="076dd41fe8ba902e5439b5ba07f330ee" category="paragraph">この解決策の中核をなすのは、次のユースケースです。どちらのユースケースでも、 TAIO ツールキットを使用してモデルの微調整を行い、 Rivea を使用してモデルを展開します。</block>
  <block id="bc176e8f914533ec222bba678e13955f" category="paragraph">従業員と顧客の間のサポートセンターのやり取りを分析するために、音声コールの形式で各顧客との会話をパイプラインを通じて実行し、文レベルの感情を抽出できます。そのような感情は、人間が感情を正当化するか、必要に応じて調整することができます。次に、ラベル付けされたデータが微調整ステップに渡され、感情の予測が改善されます。ラベル付きの感情データがすでに存在する場合は、モデルの微調整を迅速に行うことができます。どちらの場合も、パイプラインは音声の取り込みと文章の分類を必要とする他のソリューションに対して一般化可能です。</block>
  <block id="91fa9ce0e0cb723f35d6cc55f796be7e" category="paragraph"><block ref="91fa9ce0e0cb723f35d6cc55f796be7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8836d456396ee0865c317994c018a24b" category="paragraph">AI の感情に関するアウトプットは、外部クラウドデータベースまたは企業が管理するストレージシステムにアップロードされます。この大規模なデータベースからローカルストレージにセンチメント出力が転送され ' 管理者のセンチメント分析を表示するダッシュボード内で使用されますダッシュボードの主な機能は、カスタマーサービスのスタッフとリアルタイムで連携することです。マネージャは、コール中の従業員に関する評価やフィードバックを行い、各文章の感情を最新の状態に更新したり、従業員の過去のパフォーマンスや顧客からの反応を履歴的に確認したりすることができます。</block>
  <block id="586779135ffb596b1f1844ada64164b6" category="paragraph"><block ref="586779135ffb596b1f1844ada64164b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="539788a6fdaffc74393f282739bdd3e2" category="paragraph">。 <block ref="95472f01c3cd86dddef6619dbb9af815" category="inline-link-macro-rx"></block> Riva 推論パイプラインが感情ラベルを生成した後も、データストレージシステムの管理を継続できます。これらの AI 分析結果は、 NetApp DataOps ツールキットで管理するデータストレージシステムにアップロードできます。データストレージシステムは、数百ものインサートを管理し、毎分選択できる能力を備えている必要があります。ローカルデバイスストレージシステムは、大容量のデータストレージをリアルタイムで照会して抽出します。大規模なデータストレージインスタンスを照会して履歴データを照会することで、ダッシュボードのエクスペリエンスを強化することもできます。NetApp DataOps ツールキットを使用すると、データを迅速にクローニングし、データを使用するすべてのダッシュボードにデータを分散できるため、この 2 つの方法を簡単に使用できます。</block>
  <block id="679db67ee98260ef471da732862ed356" category="list-text">従業員のマネージャー</block>
  <block id="7e6beec614d536589c47de8f77fa1b1a" category="list-text">データエンジニア / データサイエンティスト</block>
  <block id="a2ce7e25564bee3c78076bcff87d1329" category="list-text">IT 管理者（オンプレミス、クラウド、ハイブリッド）</block>
  <block id="8dcd09ac05ad9012a6ff01f7b5fc337b" category="paragraph">会話中に感情を追跡することは、従業員のパフォーマンスを評価するための貴重なツールです。AI ダッシュボードを使用することで、マネージャーは従業員と発信者が自分の感情をリアルタイムでどのように変化させるかを確認できるため、ライブ評価やガイダンスセッションが可能になります。さらに、音声会話、テキストチャットボット、ビデオ会議に参加しているお客様から、価値ある顧客インサイトを得ることができます。このような顧客分析では、最新の AI モデルとワークフローを使用して、大規模なマルチモーダル処理の機能を活用しています。</block>
  <block id="b7c29e65097b6ed45e464f6492ff670d" category="paragraph">データ側では、多数のオーディオファイルがサポートセンターによって毎日処理されます。NetApp DataOps ツールキットを使用すると、モデルの定期的な微調整と感情分析用ダッシュボードの両方で、このデータ処理タスクを容易に行うことができます。</block>
  <block id="1da289b166db713f9283c5be78ef5b96" category="paragraph">IT 管理者は、 NetApp DataOps ツールキットを利用して、導入環境と本番環境の間でデータを迅速に移動することもできます。また、リアルタイム推論のためには、 NVIDIA 環境とサーバも管理、分散する必要があります。</block>
  <block id="7179915e029316714169ac136027ef31" category="paragraph"><block ref="7179915e029316714169ac136027ef31" category="inline-link-macro-rx"></block></block>
  <block id="c1579c333c7c7a4e52136c7f58a7efc6" category="summary">このテクニカルレポートで提案している解決策は、こうした優れたカスタマーエクスペリエンスの提供を支援することを実証しています。課題は、企業が AI インフラとワークフローを最新化するためのアクションを取ることです。</block>
  <block id="9c5e72cb1709251063c12e4bddb1ba12" category="inline-link-macro">Previous （前）：ビデオとデモ。</block>
  <block id="2f6461cd01fcb0c2d85704a563bd7c19" category="paragraph"><block ref="2f6461cd01fcb0c2d85704a563bd7c19" category="inline-link-macro-rx"></block></block>
  <block id="50d6e8cef34560d1d68c6688a12b1cb8" category="paragraph">顧客体験が競争上の重要な戦場と見なされるようになった今、 AI を強化したグローバルサポートセンターは、ほぼすべての業界の企業が無視することができない重要な要素となっています。このテクニカルレポートで提案している解決策は、こうした優れたカスタマーエクスペリエンスの提供を支援することを実証しています。課題は、企業が AI インフラとワークフローを最新化するためのアクションを取ることです。</block>
  <block id="f6e349295b2165b25a412793116b8675" category="paragraph">顧客サービスにおける AI の最適な実装は、人事担当者の代わりになるものではありません。AI は、リアルタイムの感情分析、紛争のエスカレーション、マルチモーダルの感情コンピューティングを通じて、優れた顧客体験を生み出す力を発揮します。これにより、包括的な AI モデルが大規模に推奨事項を提示し、個々のヒューマンエージェントが欠けている可能性のある点を補足する、言葉、言葉以外の顔の手がかりを検出できます。AI は、特定のお客様と現在対応可能なエージェントをよりよくマッチさせることもできます。AI を活用することで、企業は、プロバイダの製品、サービス、ブランドイメージに対する顧客の考えや印象に関する価値ある感情を引き出すことができます。</block>
  <block id="eb5cb6f03236a80f7ddd5085afa95729" category="paragraph">解決策を使用して、客観的なパフォーマンス評価指標として機能するように、サポートエージェントの時系列データを作成することもできます。従来の顧客満足度調査では、十分な回答が得られないことが雇用者は、長期的な従業員や顧客の感情を収集することで、サポートエージェントのパフォーマンスに関して十分な情報に基づいた判断を下すことができます。</block>
  <block id="aa20fc291fbb8ceda8651d8d8ee9dba6" category="paragraph">ネットアップ、 SFL Scientific 、オープンソースのオーケストレーションフレームワーク、 NVIDIA を組み合わせることで、最新テクノロジをマネージドサービスとして統合し、優れた柔軟性を提供することで、テクノロジの採用を促進し、新しい AI / ML アプリケーションの市場投入期間を短縮できます。これらの高度なサービスはオンプレミスで提供され、クラウドネイティブ環境やハイブリッド導入アーキテクチャへの移植が容易です。</block>
  <block id="71fd14327d5bf7e725ab97e00192b238" category="paragraph"><block ref="71fd14327d5bf7e725ab97e00192b238" category="inline-link-macro-rx"></block></block>
  <block id="9c08a0abcced906f3225e86f61dd598c" category="paragraph"><block ref="9c08a0abcced906f3225e86f61dd598c" category="inline-link-macro-rx"></block></block>
  <block id="c5648cc9e6e76ab4aa041d71661d0288" category="list-text">3D 対話型デモ</block>
  <block id="26e071d5769be8e940617a0c8dd5c22d" category="inline-link">www.netapp.com/ai</block>
  <block id="9e22db1b830d668e86d5dc1b5c204555" category="paragraph"><block ref="9e22db1b830d668e86d5dc1b5c204555" category="inline-link-rx"></block></block>
  <block id="1fa584a3d1190f1a7fdded0c91412cac" category="list-text">ネットアップの AI スペシャリストと直接つながる</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="488d7301e5d1a52040c33186d7e11657" category="paragraph"><block ref="488d7301e5d1a52040c33186d7e11657" category="inline-link-rx"></block></block>
  <block id="787dd83fbbc162f0279e320ada1f7c0b" category="list-text">ネットアップ解決策が実現する NVDIA 基本コマンドプラットフォームの概要</block>
  <block id="5541299dd0999c42fcd24fd754001e38" category="inline-link"><block ref="5541299dd0999c42fcd24fd754001e38" category="inline-link-rx"></block></block>
  <block id="ac527e3c2b2d8a080840aa28c13b127b" category="paragraph"><block ref="ac527e3c2b2d8a080840aa28c13b127b" category="inline-link-rx"></block></block>
  <block id="465b9c508fba1d27d188eb21e0655293" category="list-text">AI 向けネットアップ 10 の理由を解説したインフォグラフィック</block>
  <block id="75048e22ffd1c45ce07e6cae3170780a" category="inline-link"><block ref="75048e22ffd1c45ce07e6cae3170780a" category="inline-link-rx"></block></block>
  <block id="e2435a6f01dee5a11f6cd698a292183d" category="paragraph"><block ref="e2435a6f01dee5a11f6cd698a292183d" category="inline-link-rx"></block></block>
  <block id="66d4373905c5c7c0a3f51e5480d443b2" category="list-text">ヘルスケア分野の AI ：『 Deep learning to identify COVID-19 nscions in lung CT scans 』ホワイトペーパーを参照してください</block>
  <block id="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link"><block ref="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link-rx"></block></block>
  <block id="d1e9d43080e6c2364ee86ac930ae1341" category="paragraph"><block ref="d1e9d43080e6c2364ee86ac930ae1341" category="inline-link-rx"></block></block>
  <block id="2ece031fbb30496ba2ec244a07557107" category="list-text">ヘルスケア分野の AI ：ヘルスケア設定におけるフェイスマスクの使用状況を監視するホワイトペーパーです</block>
  <block id="aa895997d9bc7e84d90779885cb936b7" category="inline-link"><block ref="aa895997d9bc7e84d90779885cb936b7" category="inline-link-rx"></block></block>
  <block id="4ac3d75f4e132824f0fe3a418d42a9f9" category="paragraph"><block ref="4ac3d75f4e132824f0fe3a418d42a9f9" category="inline-link-rx"></block></block>
  <block id="ff11da2c36a9883c6eb658395f3de353" category="list-text">医療分野の AI ：診断画像診断テクニカルレポート</block>
  <block id="41575d740e0d837694e2fa66ce618124" category="inline-link"><block ref="41575d740e0d837694e2fa66ce618124" category="inline-link-rx"></block></block>
  <block id="61a15cd6b61d637fb54ae6ae99ae39d5" category="paragraph"><block ref="61a15cd6b61d637fb54ae6ae99ae39d5" category="inline-link-rx"></block></block>
  <block id="1527888e6b729290296c51cf9c3aeeec" category="list-text">小売業向け AI ：ネットアップの会話型 AI で NVIDIA Riva を使用</block>
  <block id="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link"><block ref="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link-rx"></block></block>
  <block id="dc1f6c62d8de3b68ec946b66d053f5a7" category="paragraph"><block ref="dc1f6c62d8de3b68ec946b66d053f5a7" category="inline-link-rx"></block></block>
  <block id="2281741ceb773b1efc91b48b4e5e04fe" category="list-text">NetApp ONTAP AI 解決策の概要</block>
  <block id="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link"><block ref="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link-rx"></block></block>
  <block id="a32cc63ad53dc74caf680b96a921ad3b" category="paragraph"><block ref="a32cc63ad53dc74caf680b96a921ad3b" category="inline-link-rx"></block></block>
  <block id="c6b4ec978259e83d537f6a179912448a" category="list-text">NetApp DataOps ツールキットの解決策概要</block>
  <block id="c50b3ec30c711b6233dd7753f12165d4" category="inline-link"><block ref="c50b3ec30c711b6233dd7753f12165d4" category="inline-link-rx"></block></block>
  <block id="a045bf4eb32fbbf6c351d4c3cbd5932c" category="paragraph"><block ref="a045bf4eb32fbbf6c351d4c3cbd5932c" category="inline-link-rx"></block></block>
  <block id="9399af78c2a9b2a197612e42bf8b8f79" category="list-text">ネットアップの AI コントロールプレーン解決策の概要</block>
  <block id="c771257beb97f479ebb6d342d91b61bd" category="inline-link"><block ref="c771257beb97f479ebb6d342d91b61bd" category="inline-link-rx"></block></block>
  <block id="ce6060d7bc79a57fdb337f6364f0e8a9" category="paragraph"><block ref="ce6060d7bc79a57fdb337f6364f0e8a9" category="inline-link-rx"></block></block>
  <block id="b6e1af8dc83073dfa46f061507b15586" category="list-text">『データの活用で業界を変革』の E ブック</block>
  <block id="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link"><block ref="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link-rx"></block></block>
  <block id="195010aa6331d4b94de36f6aa5cf3fc7" category="paragraph"><block ref="195010aa6331d4b94de36f6aa5cf3fc7" category="inline-link-rx"></block></block>
  <block id="4dcaafba5ac7511b65c0f3a3688f8d81" category="list-text">NetApp EF シリーズ AI 解決策の概要</block>
  <block id="385bae1ac9580238d4ef22dad99878c3" category="inline-link"><block ref="385bae1ac9580238d4ef22dad99878c3" category="inline-link-rx"></block></block>
  <block id="5bbcd3b785c7ecb740b1302ea68fb4ff" category="paragraph"><block ref="5bbcd3b785c7ecb740b1302ea68fb4ff" category="inline-link-rx"></block></block>
  <block id="e72de1f0850154df8bf93fae76b2276d" category="list-text">AI 推論向けのネットアップの AI と Lenovo ThinkSystem 解決策の概要</block>
  <block id="883d1d69b62bc20ea26446649b6c95b0" category="inline-link"><block ref="883d1d69b62bc20ea26446649b6c95b0" category="inline-link-rx"></block></block>
  <block id="74686a12110c0c39ad22ac2252bcb1a1" category="paragraph"><block ref="74686a12110c0c39ad22ac2252bcb1a1" category="inline-link-rx"></block></block>
  <block id="8954bee2812529847e7f3108185fc57d" category="list-text">エンタープライズ AI および ML 向けのネットアップ AI と Lenovo ThinkSystem の解決策概要</block>
  <block id="f877ccffca68b901c2c61513c04dbf37" category="inline-link"><block ref="f877ccffca68b901c2c61513c04dbf37" category="inline-link-rx"></block></block>
  <block id="214ebd5c8513ce31087d4bf0cd12af76" category="paragraph"><block ref="214ebd5c8513ce31087d4bf0cd12af76" category="inline-link-rx"></block></block>
  <block id="7cbca96fc14ecadf4054303e98a81787" category="list-text">ネットアップと NVIDIA – AI ビデオで可能なことを再定義</block>
  <block id="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link"><block ref="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link-rx"></block></block>
  <block id="c7531fbb829ae07f04aab76de6fad46c" category="paragraph"><block ref="c7531fbb829ae07f04aab76de6fad46c" category="inline-link-rx"></block></block>
  <block id="f521e3eae9fd2145ce8aeede6602641d" category="summary">このセクションでは、この解決策のさまざまなコンポーネントの設計上の考慮事項について説明します。</block>
  <block id="5b1c62f1e35074e19185d9341b492c54" category="inline-link-macro">前のバージョン：アーキテクチャ</block>
  <block id="b180067c966e23ba80c92f3bb1bf6745" category="paragraph"><block ref="b180067c966e23ba80c92f3bb1bf6745" category="inline-link-macro-rx"></block></block>
  <block id="35ff22a5291df56d5075c29d8dc65044" category="section-title">ネットワークとコンピューティングの設計</block>
  <block id="49d41bdb2234e0a4330f0c9d7d03853a" category="paragraph">データセキュリティの制限に応じて、すべてのデータはお客様のインフラストラクチャまたはセキュアな環境内に保持されている必要があります。</block>
  <block id="5a20c2b759137410d60f5ce368ca45d2" category="paragraph"><block ref="5a20c2b759137410d60f5ce368ca45d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d6e133bd239a98d559f693ee2ff5ecc" category="section-title">ストレージ設計</block>
  <block id="3051d856c7b26f6d385279d67a8a532b" category="paragraph">NetApp DataOps ツールキットは、ストレージシステムを管理するための主要なサービスです。DataOps ツールキットは Python ライブラリで、開発者、データサイエンティスト、 DevOps エンジニア、データエンジニアは、新しいデータボリュームや JupyterLab ワークスペースのほぼ瞬時のプロビジョニング、データボリュームや JupyterLab ワークスペースのほぼ瞬時のクローニングなど、さまざまなデータ管理タスクを簡単に実行できます。 トレーサビリティやベースライン設定のためのデータボリュームまたは JupyterLab ワークスペースのほぼ瞬時のスナップショット作成。この Python ライブラリは、任意の Python プログラムまたは Jupyter Notebook にインポートできるコマンドラインユーティリティまたは関数ライブラリとして機能します。</block>
  <block id="6f9e8585e5f750b8ceb149639b1e25e6" category="section-title">RIVA のベストプラクティス</block>
  <block id="7ecab6bd65c2f169e987be2f59219357" category="inline-link">ベストプラクティスに基づくデータ保護</block>
  <block id="f51b8fa6c731ea53318149e50e826ddb" category="paragraph">NVIDIA はいくつかの一般的な機能を提供<block ref="f6aee1daf7f2fd9cd207fcd26f08d8be" category="inline-link-rx"></block> リベットを使用する場合：</block>
  <block id="20430e77ba2ecbe15261761c8f4fa2c4" category="list-text">* 可能であれば、ロスレスのオーディオフォーマットを使用します。 * MP3 などの損失のあるコーデックを使用すると、品質が低下する可能性があります。</block>
  <block id="8b3e389f067f32da1e1ab7df2b8d8155" category="list-text">* トレーニングデータの増加。 * 音声トレーニングデータにバックグラウンドノイズを追加することで、当初は精度を低下させながら堅牢性を高めることができます。</block>
  <block id="b37d69a795b4d7bb6e0f28a42c3ef8ae" category="list-text">* スクラップテキストを使用すれば語彙のサイズを制限しなさい。 * 多くのオンライン源にタイプミスまたは補助発音および珍しい単語を含んでいる。これらを削除すると、言語モデルが改善されます。</block>
  <block id="6afe4c71ada39a70da349380efbad345" category="list-text">* 可能であれば、最小サンプリングレート 16kHz を使用します。 * ただし、オーディオ品質が低下するため、リサンプルしないようにしてください。</block>
  <block id="cab3977e4ad163e19ab6245a9b09f541" category="paragraph">これらのベストプラクティスに加えて、パイプラインの各ステップで正確なラベルを持つ代表的なサンプルデータセットの収集に優先順位を付ける必要があります。つまり、サンプルデータセットには、ターゲットデータセットに典型的な指定された特性を比例的に反映させる必要があります。同様に、データセットの注釈には、データの品質と量を最大化するために、正確性とラベル付けの速度のバランスをとる責任があります。たとえば、このサポートセンターの解決策には、音声ファイル、ラベル付きテキスト、および感情ラベルが必要です。この解決策は、シーケンシャルなので、パイプラインの開始時に発生したエラーが最後まで伝播されます音声ファイルの品質が悪い場合は、テキスト文字変換と感情ラベルも同様になります。</block>
  <block id="0b6b65c9613285433178682e3550355c" category="paragraph">このエラーの伝播も同様に、環境 the models Trained on this data です。感情の予測が 100% 正確であるにもかかわらず、音声テキスト変換モデルのパフォーマンスが低い場合、最終的なパイプラインは最初の音声テキスト変換によって制限されます。開発者は、各モデルのパフォーマンスを個別に、また大きなパイプラインのコンポーネントとして考慮する必要があります。この場合、最終目標は、感情を正確に予測できるパイプラインを開発することです。そのため、パイプラインを評価する全体的な指標は感情の精度であり、音声からテキストへの変換は直接影響を与えます。</block>
  <block id="f3b552e561f520013398b3be885a4420" category="paragraph"><block ref="f3b552e561f520013398b3be885a4420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1ce31a9f2a1a3a478bb69589e180bd" category="paragraph">NetApp DataOps ツールキットは、ほぼ瞬時のデータクローニングテクノロジを使用して、データ品質チェックパイプラインを補完します。各ラベル付きファイルを評価し、既存のラベル付きファイルと比較する必要があります。これらの品質チェックをさまざまなデータストレージシステムに分散させることで、これらのチェックを迅速かつ効率的に実行できます。</block>
  <block id="6d61a746e66a6545c5c9faf68668e013" category="inline-link-macro">次は、サポートセンターの感情分析の展開です。</block>
  <block id="58a113e09ecc7941870d9bcc2d2ee3df" category="paragraph"><block ref="58a113e09ecc7941870d9bcc2d2ee3df" category="inline-link-macro-rx"></block></block>
  <block id="34d110ef6b6b3684adfe9c791fce2f95" category="summary">このセクションでは、この解決策を導入するために必要な詳細な手順について説明します。</block>
  <block id="e0673e67d0ae2470ff4a9a3a926792b0" category="doc">サポートセンターのセンチメント分析の導入</block>
  <block id="0c7ee1e6d81ae421558f2979d46adb5d" category="inline-link-macro">前の手順：設計上の考慮事項。</block>
  <block id="2e4639bc721df1da69c19fe5c10f5764" category="paragraph"><block ref="2e4639bc721df1da69c19fe5c10f5764" category="inline-link-macro-rx"></block></block>
  <block id="b23f4e3eb5ff4f900ba54c824bf7a676" category="paragraph">解決策の導入には、次のコンポーネントが含まれます。</block>
  <block id="1b497bff4e1d2dff7f8855237612936b" category="list-text">NGC の設定</block>
  <block id="2dcf1afb8ed1445e4b167ef91fdd8a1b" category="list-text">NVIDIA Rivea サーバ</block>
  <block id="6894a1e922948fc0bc9cc96291183448" category="list-text">NVIDIA TAO ツールキット</block>
  <block id="3b498dd8feee94c2dbcb419be10d3b70" category="list-text">TAO モデルを Riva にエクスポートします</block>
  <block id="534b37206d500ff97473ada660fb69d3" category="paragraph">導入を実行するには、次の手順を実行します。</block>
  <block id="2f6c7bd50828792593b3aa4deff875cc" category="section-title">NetApp DataOps ツールキット：センターのセンチメント分析をサポート</block>
  <block id="3b84de14b99e2695fdfd099f56b254be" category="paragraph">を使用します<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>、次の手順を実行します。</block>
  <block id="d19523f192f664c9e34bf949d6f084c3" category="list-text">PIP でツールキットをインストールします。</block>
  <block id="1fe6ae43439f5ccecf9883686d6b3784" category="list-text">データ管理を設定</block>
  <block id="36b413e2c45a91e66db4aac6abd67ba1" category="section-title">NGC 構成：センターの感情分析をサポート</block>
  <block id="e3ab64bcab09d9eb8219520405242267" category="inline-link">NVIDIA NGC</block>
  <block id="f526ba073cf7bc97c2b0d3bfe091e293" category="paragraph">セットアップするには<block ref="5b4e29c9d8254a25bb1abc36cd17ca4c" category="inline-link-rx"></block>、次の手順を実行します。</block>
  <block id="a485a457c113aa9f2f8096ac1ca500d7" category="list-text">NGC をダウンロード</block>
  <block id="7438544460c4a4fdf0b70bb65bb03a92" category="list-text">現在のディレクトリをパスに追加します。</block>
  <block id="4f1208b2473595e5f4c3118c13de0fcc" category="list-text">コマンドを実行できるように、 NGC CLI を設定する必要があります。次のコマンドを入力します。プロンプトが表示されたら、 API キーも入力します。</block>
  <block id="5307692c5f99e57b8002a6a87f08c240" category="paragraph">Linux ベースではないオペレーティングシステムについては、を参照してください<block ref="481e32faa0c657434738f6f0a550651b" category="inline-link-rx"></block>。</block>
  <block id="326419ec6a380f68d7d15a373452bf35" category="section-title">NVIDIA Rivea サーバ：センタ心理分析をサポートします</block>
  <block id="92ed82a726e834b50a6863c8c4e9db4e" category="paragraph">セットアップするには<block ref="fb85035785391c7c4b815d01de952f38" category="inline-link-rx"></block>、次の手順を実行します。</block>
  <block id="a4fc5fd3d1cea05f031d5adc045dc1e0" category="list-text">NGC から Riva ファイルをダウンロード</block>
  <block id="5f2573d8cf9e274560d9a9b3eb2e1aaa" category="list-text">Riva セットアップを初期化します (`Riva_init.sh`)</block>
  <block id="3b570ac682cfeffcdb2c7243afdbf285" category="list-text">Riva サーバ (`Riva_start.sh`) を起動します</block>
  <block id="d44d4e10378cce2928c99a4b49e45cea" category="list-text">Riva クライアント (`Riva_start_client.sh`) を起動します</block>
  <block id="6846c1a17ddaf84e01f26ec51c151e78" category="inline-link">FFmpeg</block>
  <block id="22c9c751571566e0566c448194d9d64f" category="list-text">Riva クライアント内で、オーディオ処理ライブラリをインストールします（<block ref="3e294dfc4ee3a49adac5a070482274ce" category="inline-link-rx"></block>)</block>
  <block id="8637711b2ee1b94fe789bb28e88c4b61" category="list-text">を起動します<block ref="37a4c4b3ad3c3851ac5717bfd3104346" category="inline-link-rx"></block> サーバ</block>
  <block id="b57a5203a9fd3e877aacee6cba6bc9c8" category="list-text">Riva Inference Pipeline Notebook を実行します。</block>
  <block id="5dceab25ae38dae0d7ed3167abd32377" category="section-title">NVIDIA TAO Toolkit ：センターの感情分析をサポートします</block>
  <block id="2418d4c7f6be40d5c9a50e4aecab1b27" category="paragraph">NVIDIA TAO Toolkit をセットアップするには、次の手順を実行します。</block>
  <block id="630eef78d15fd844ba4a38ea7f7a9c79" category="inline-link">仮想環境</block>
  <block id="35fb58d5f90347e4f0c445b4968db5f6" category="list-text">を準備してアクティブ化します<block ref="3d97a4392c0af686650645d1371fa8ef" category="inline-link-rx"></block> TAO ツールキット用。</block>
  <block id="0a80b2068950d6e04f34c0142a10e719" category="inline-link">必須パッケージ</block>
  <block id="40eb0bd8a87ab1b39e8f2ee5ea287a22" category="list-text">をインストールします<block ref="3646357cb54591ae95dd3b8f0889f0c2" category="inline-link-rx"></block>。</block>
  <block id="c0e95a7dacbc170e387c4e1a0fe41a0b" category="list-text">トレーニング中および微調整中に使用したイメージを手動で引き出します。</block>
  <block id="b5a6ae7c1df936b55910309efc466f01" category="list-text">TAO 微調整ノートブックを実行します。</block>
  <block id="e6dda626093691f78b3127a8faa82b6e" category="section-title">TAO モデルを Riva にエクスポート：センターの感情分析をサポートします</block>
  <block id="6a358d81cb24a7e408b0339062f6bb92" category="inline-link">Rivea の Tao ツールキットモデル</block>
  <block id="53ace4ba305859107cead3e5b0b53b8b" category="paragraph">を使用してください<block ref="ce50a5bf8eb35af9ad9bb322336ee3af" category="inline-link-rx"></block>、次の手順を実行します。</block>
  <block id="08c3be8307b7659c6ad67ee4d9659d58" category="list-text">TAO 微調整ノートブックにモデルを保存します。</block>
  <block id="ac711bb6af28947dfa8b29512acb36e8" category="list-text">TAO トレーニング済みモデルを Riva モデルディレクトリにコピーします。</block>
  <block id="1317e1d8d20d5c44c680825aba2196e6" category="section-title">導入の障害です</block>
  <block id="6e3da39922ebbd1a8a1a5a7238a89168" category="paragraph">独自の解決策を開発する際に留意すべき点をいくつかご紹介します。</block>
  <block id="47c0613abd5b97b67a94c2355692cf08" category="list-text">最初に NetApp DataOps ツールキットをインストールし、データストレージシステムが最適に動作するようにします。</block>
  <block id="943f803f8c6b4c6508bc97536a6d7b2b" category="list-text">NVIDIA NGC は、イメージとモデルのダウンロードを認証するため、それ以外のコンポーネントよりも先にインストールする必要があります。</block>
  <block id="70367b72bfd96b5608a7c72ac3f983bf" category="list-text">Rivea は、 TAO ツールキットの前にインストールする必要があります。Riva インストールでは、必要に応じてイメージをプルするように Docker デーモンが設定されます。</block>
  <block id="1ed7124aa68792cb6ce3049f6f1d4f7b" category="list-text">DGX および Docker でモデルをダウンロードするには、インターネットアクセスが必要です。</block>
  <block id="de9b04ca3177b736c9f3cc74d62f5088" category="inline-link-macro">次の例は、検証結果です</block>
  <block id="3556370bb03d018998375ff0476db59a" category="paragraph"><block ref="3556370bb03d018998375ff0476db59a" category="inline-link-macro-rx"></block></block>
  <block id="0e85d8fd0ce7acdba87f57325a14b3fb" category="summary">前のセクションで説明したように、 2 つ以上の機械学習モデルが順番に実行されている場合は常に、エラーがパイプライン全体に伝播されます。この解決策では、企業の株価リスクレベルを測定する上で最も重要な要因は、文章の感情です。音声対テキストモデルは、パイプラインに不可欠ですが、感情を予測する前に前処理単位として機能します。</block>
  <block id="6700d3710d10e74d6e48f994b760d48b" category="doc">検証結果</block>
  <block id="ee4eec78ae095f539af53c130e976afa" category="inline-link-macro">前の内容：サポートセンターの感情分析の展開</block>
  <block id="ac96c8f3af95b93c2683c2124998e668" category="paragraph"><block ref="ac96c8f3af95b93c2683c2124998e668" category="inline-link-macro-rx"></block></block>
  <block id="2e10a4ae90aad11c07592a14fbf8c5c6" category="paragraph">前のセクションで説明したように、 2 つ以上の機械学習モデルが順番に実行されている場合は常に、エラーがパイプライン全体に伝播されます。この解決策では、企業の株価リスクレベルを測定する上で最も重要な要因は、文章の感情です。音声対テキストモデルは、パイプラインに不可欠ですが、感情を予測する前に前処理単位として機能します。実際に重要なのは、基本的な真実文と予測された文の感情の違いです。これは、ワードエラーレート（ WER ）のプロキシとして機能します。音声とテキストの正確さは重要ですが、 WER は最終的なパイプラインメトリックでは直接使用されません。</block>
  <block id="0fc4c7871adf5db8dd2b13fc4c381da8" category="paragraph">これらの感情指標は、 F1 スコア、リコール、各文章の精度について計算できます。結果は集約され、各メトリックの信頼間隔とともに混乱マトリックス内に表示されます。</block>
  <block id="66554c8f1474c5658d17e23710901f98" category="paragraph">転送学習を使用する利点は、データ要件、トレーニング時間、コストの数分の 1 でモデルのパフォーマンスが向上することです。また、微調整されたモデルをベースラインバージョンと比較して、転送学習がインペアリングではなくパフォーマンスを向上させるようにする必要があります。つまり、調整済みモデルの方が、サポートセンターのデータのパフォーマンスが事前トレーニング済みモデルよりも優れているはずです。</block>
  <block id="6e979ee914c9401fddd049d16cdef66a" category="section-title">パイプラインの評価</block>
  <block id="7f109f66c71a1fd15436d1c413354c41" category="cell">テストケース</block>
  <block id="e7f1ec3a5f35af805407a8a531eefb79" category="cell">テスト番号</block>
  <block id="6bf1af9a7f1b6dd6cca4b7434097ad94" category="cell">パイプラインのセンチメント指標</block>
  <block id="beed3529b961c63b785104d7a17cf5f4" category="cell">テストの前提条件</block>
  <block id="c7320b1f70fd8a9831e530d17a82f34d" category="cell">音声 / テキストおよび感情分析モデル向けに微調整されたモデル</block>
  <block id="9d5b1bc6dcdedf0c8750e543fab75738" category="cell">予想される結果</block>
  <block id="74015a89b882f01e94433a9c1f1c904c" category="cell">微調整されたモデルのセンチメント・メトリックは、元の事前トレーニング済みモデルよりも優れています。</block>
  <block id="68d279a19e31962e0ab0b648f25c07ee" category="list-text">ベースラインモデルのセンチメントメトリックを計算します。</block>
  <block id="b6168629c9e5a47b0637aa362112642d" category="list-text">微調整モデルのセンチメントメトリックを計算します。</block>
  <block id="97ae5da5f745d90cf815a206b3549e0a" category="list-text">これらの指標間の差異を計算します。</block>
  <block id="fc997f472d1b5e66aadb364e10c29f4f" category="list-text">すべての文の違いを平均化します。</block>
  <block id="c6b3b1378b2e31169a4a1cd4c20691c8" category="inline-link-macro">次は、ビデオとデモです</block>
  <block id="6016219a0b0ad0bb3594f964b5e6396d" category="paragraph"><block ref="6016219a0b0ad0bb3594f964b5e6396d" category="inline-link-macro-rx"></block></block>
  <block id="67d45a00257105f21f4427f31e0c9fa1" category="summary">このテクニカルレポートでは、転送学習と会話型 AI を使用して、ネットアップのデータ管理テクノロジと NVIDIA ソフトウェアフレームワークを使用して、エンタープライズレベルのグローバルサポートセンターで感情分析を行うための設計ガイダンスを提供します。</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="doc">TR-4910 ：『 NetApp AI と顧客コミュニケーションを組み合わせた感情分析』</block>
  <block id="22268d4ee4f32cda2f20141957aac961" category="paragraph">Sathish Thyagarajan 、 Rick Huang 氏、および SFL Scientific 、 Diego Sosa-coba 、 David Arnette 氏</block>
  <block id="0c450c48691e7a55b657f2cb7d18a0dd" category="paragraph">このテクニカルレポートでは、転送学習と会話型 AI を使用して、ネットアップのデータ管理テクノロジと NVIDIA ソフトウェアフレームワークを使用して、エンタープライズレベルのグローバルサポートセンターで感情分析を行うための設計ガイダンスを提供します。この解決策は、チャットログ、 E メール、およびその他のテキストまたは音声通信を表す録音された音声ファイルやテキストファイルから顧客の洞察を得たいと考えているあらゆる業界に適用されます。ネットアップはエンドツーエンドのパイプラインを実装して、ネットアップのクラウド対応オールフラッシュストレージを使用した GPU アクセラレーションコンピューティングクラスタで、自動音声認識、リアルタイムの感情分析、ディープラーニングの自然言語処理モデル再トレーニング機能をデモンストレーションしました。大規模で最先端の言語モデルのトレーニングと最適化により、世界規模のサポートセンターで推論を迅速に実行できるようになり、優れたカスタマーエクスペリエンスと目標を達成し、長期的な従業員パフォーマンス評価を実施できます。</block>
  <block id="549c85ede9b39be6ef0eec80db7e098c" category="paragraph">感情分析は、正、負、または中性感情がテキストから抽出される Natural Language Processing （ NLP ）内の研究分野です。会話型 AI システムは、より多くの人がコミュニケーションを行うようになったため、ほぼグローバルレベルの統合にまで成長しました。感情分析には、サポートセンターの従業員のパフォーマンスを発信者との会話で決定し、適切な自動チャットボット応答を提供し、四半期ごとの収益呼における企業の代表者と対象者間のやり取りに基づいて会社の株価を予測するなど、さまざまなユースケースがあります。さらに、感情分析を使用して、ブランドが提供する製品、サービス、サポートに関するお客様の見解を判断できます。</block>
  <block id="5855677156d63ad3c93a7b5382098060" category="paragraph">このエンドツーエンドの解決策は、 NLP モデルを使用して、サポートセンター分析フレームワークを可能にする高度なセンチメント分析を実行します。音声録音は文書化されたテキストに処理され、会話の各文から感情が抽出されます。結果はダッシュボードに集約され、会話の感情を分析するために、従来とリアルタイムの両方で巧妙に細工することができます。この解決策は、データモダリティと出力ニーズが似ている他のソリューションに汎用化できます。適切なデータを使用することで、他のユースケースにも対応できます。たとえば、企業収益の問い合わせを、同じエンドツーエンドパイプラインを使用して、センチメントについて分析することができます。また、パイプラインの柔軟性が高いため、トピックモデリングや Named Entity Recognition （ NER ）などの他の形式の NLP 解析も可能です。</block>
  <block id="ea4f750fd9fd89aeff4ca8d4162fb673" category="paragraph">これらの AI 実装は、 NVIDIA Rivea 、 NVIDIA TAO Toolkit 、 NetApp DataOps ツールキットが連携して実現しました。NVIDIA のツールを使用すると、あらかじめ組み込まれたモデルとパイプラインを使用して、ハイパフォーマンスな AI ソリューションを迅速に導入できます。NetApp DataOps ツールキットにより、さまざまなデータ管理タスクが簡易化され、開発期間が短縮されます。</block>
  <block id="7a7e97f7fcf4e2974d9a6feee2b056f8" category="section-title">お客様にもたらされる価値</block>
  <block id="3815ef30c3d6c6bdc3862cc9530d091e" category="paragraph">企業は、感情分析のためのテキスト、音声、ビデオの会話について、従業員評価および顧客対応ツールから価値を得ています。マネージャーは、ダッシュボードに表示される情報を活用して、会話の両側に基づいて従業員と顧客満足度を評価できます。</block>
  <block id="da210ea22d819ca26070a3795f9a14d4" category="paragraph">さらに、 NetApp DataOps ツールキットは、お客様のインフラストラクチャ内でのデータのバージョン管理と割り当てを管理します。その結果、ダッシュボードに表示される分析情報が頻繁に更新されるため、データストレージのコストを抑えることができません。</block>
  <block id="e5fcadecc4515efec9267b8ad57b28a5" category="inline-link-macro">次：ユースケース</block>
  <block id="93b7bce28e36a4eebec23c8fd4be315d" category="paragraph"><block ref="93b7bce28e36a4eebec23c8fd4be315d" category="inline-link-macro-rx"></block></block>
  <block id="4878d0f06c45c7f565e6545cccf18c88" category="inline-link-macro">SnapCenter を使用したハイブリッドクラウドデータベースソリューション</block>
  <block id="a07f396f8180d71ad8372bd51f3800d7" category="cell">* ハイブリッド・クラウド・データベース・ソリューション *<block ref="642bb53d1747dfdf3e6f0ebcbb604cfe" category="inline-link-macro-rx"></block></block>
  <block id="24743f8350683e7f1d7d5f6802de3aab" category="cell"><block ref="24743f8350683e7f1d7d5f6802de3aab" category="inline-link-macro-rx"></block></block>
  <block id="dcad2dec3906d4a902bdfb0b7093ce21" category="cell"><block ref="dcad2dec3906d4a902bdfb0b7093ce21" category="inline-link-macro-rx"></block></block>
  <block id="59fbb2b8017dcaa261a32ed33941a3bd" category="cell"><block ref="41f97968c03372ffce726ec89c54fc9a" category="inline-link-macro-rx"></block></block>
  <block id="8e7cb8af41001c3eeb84421bdf0bf30f" category="cell"><block ref="8e7cb8af41001c3eeb84421bdf0bf30f" category="inline-link-macro-rx"></block></block>
  <block id="5a6ed16cce1a08e1b3de84293a1c0a11" category="cell"><block ref="5a6ed16cce1a08e1b3de84293a1c0a11" category="inline-link-macro-rx"></block></block>
  <block id="7dffec91055830f84efb7bc18ab4f86d" category="cell"><block ref="7dffec91055830f84efb7bc18ab4f86d" category="inline-link-macro-rx"></block></block>
  <block id="cce65a4a66212b1b6a69449993338407" category="cell"><block ref="cce65a4a66212b1b6a69449993338407" category="inline-link-macro-rx"></block></block>
  <block id="de2b8e7716b57342938375941b7e521a" category="cell"><block ref="de2b8e7716b57342938375941b7e521a" category="inline-link-macro-rx"></block></block>
  <block id="c4ff33edf6e94fb434fb59e4ad2c286b" category="inline-link-macro">SnapCenter を使用したハイブリッドクラウドデータベースソリューション</block>
  <block id="dcf8c21fbb1d22c97f20ace5649e8918" category="list-text"><block ref="dcf8c21fbb1d22c97f20ace5649e8918" category="inline-link-macro-rx"></block></block>
  <block id="fc25c016a8fb35a621842044a8d4f2e7" category="inline-link-macro">ハイブリッドクラウドで Oracle データベースインフラを自動化</block>
  <block id="59a4cf9e5720080358e0622f3c948571" category="list-text"><block ref="59a4cf9e5720080358e0622f3c948571" category="inline-link-macro-rx"></block></block>
  <block id="ae270ffdc87820776fadfe121aa13143" category="sidebar">ネットアップの AI による地合い分析</block>
  <block id="f74720767a0bf20cfdb6bba5f215d795" category="sidebar">サポートセンターの感情分析の導入</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">このユースケースでは、 DevTest と Reporting の目的で同じデータセンターとリモートサイトに大量の分析データを格納した既存の Hadoop クラスタをベースに、新しい Hadoop / Spark クラスタを迅速かつ効率的に構築することがお客様の要件となります。</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">ユースケース 3 ：既存の Hadoop データに対して DevTest を有効化</block>
  <block id="aeab228f25b5fbe0b00f83117579246e" category="inline-link-macro">従来のユースケース 2 - クラウドからオンプレミスへのバックアップとディザスタリカバリ</block>
  <block id="cf44ed74ea7e07a8e4478e43d9537e07" category="paragraph"><block ref="cf44ed74ea7e07a8e4478e43d9537e07" category="inline-link-macro-rx"></block></block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">シナリオ（ Scenario ）</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">このシナリオでは、大規模な Hadoop データレイク実装をオンプレミスとディザスタリカバリサイトで使用して、複数の Spark / Hadoop クラスタを構築しています。</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="section-title">要件と課題</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">このユースケースの主な要件と課題は次のとおりです。</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">DevTest 、 QA 用など、同じ本番環境のデータへのアクセスを必要とする用途に複数の Hadoop クラスタを作成この課題は、非常に大規模な Hadoop クラスタを、スペース効率に優れた方法で何度も瞬時にクローニングすることです。</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">運用効率を高めるために、 Hadoop データを DevTest チームとレポートチームに同期します。</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">業務用クラスタと新規クラスタに同じクレデンシャルを使用して Hadoop データを分散します。</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">スケジュールされたポリシーを使用して、本番クラスタに影響を与えずに効率的に QA クラスタを作成</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">解決策</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">FlexClone テクノロジは、直前に説明した要件を回答に適用するために使用されます。FlexClone テクノロジは、 Snapshot コピーの読み取り / 書き込みコピーです。親 Snapshot コピーのデータを読み取り、新規または変更されたブロック用に追加のスペースのみを消費します。高速でスペース効率に優れています。</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">まず、ネットアップの整合グループを使用して既存のクラスタの Snapshot コピーを作成し、</block>
  <block id="4b481b20e942087b64c5bb7b07d9dca9" category="paragraph">NetApp System Manager またはストレージ管理プロンプト内の Snapshot コピー。整合グループ Snapshot コピーはアプリケーションと整合性のあるグループ Snapshot コピーであり、整合グループ Snapshot コピーに基づいて FlexClone ボリュームが作成されます。FlexClone ボリュームは親ボリュームの NFS エクスポートポリシーを継承することに留意する必要があります。Snapshot コピーの作成後、次の図に示すように、 DevTest および Reporting 用に新しい Hadoop クラスタをインストールする必要があります。インプレース分析モジュールは、 NFS データのインプレース分析モジュールユーザーおよびグループ許可を介して、新しい Hadoop クラスタからクローン NFS ボリュームにアクセスします。</block>
  <block id="4c490dfedbcc5a021b8a4c823e337d41" category="paragraph">適切なアクセス権を持つには、インプレース分析モジュールのユーザーとグループ構成で設定されたユーザーに対して、新しいクラスタに同じ UID と GUID が設定されている必要があります。</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">この図は、 DevTest 用の Hadoop クラスタを示しています。</block>
  <block id="4157075925c8c1518cc71d1d0abab403" category="paragraph"><block ref="4157075925c8c1518cc71d1d0abab403" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e10ad11fd299ee6f161f17d772a78a48" category="inline-link-macro">次のユースケース 4 - データ保護とマルチクラウド接続</block>
  <block id="8109e574f349ced8f667b9389c9189a4" category="paragraph"><block ref="8109e574f349ced8f667b9389c9189a4" category="inline-link-macro-rx"></block></block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">このセクションでは、ネットアップが提供するさまざまな Hadoop データ保護要件を満たすユースケースとソリューションの概要を説明します。</block>
  <block id="23496143e5ca83c13eb4d953786abdcd" category="inline-link-macro">前：ユースケース 5 - 分析ワークロードの高速化</block>
  <block id="09b7371b2ae3168a3c54b30e4966e86e" category="paragraph"><block ref="09b7371b2ae3168a3c54b30e4966e86e" category="inline-link-macro-rx"></block></block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">このセクションでは、ネットアップが提供するさまざまな Hadoop データ保護要件を満たすユースケースとソリューションの概要を説明します。ネットアップのデータファブリックを使用することで、お客様は次のことが可能になります。</block>
  <block id="ce0bf05854efb234905c751e40774ab5" category="list-text">ネットアップの充実したデータ管理機能と Hadoop ネイティブワークフローとの統合により、適切なデータ保護ソリューションを柔軟に選択できます。</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Hadoop クラスタのバックアップ時間を約 70% 短縮します。</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Hadoop クラスタのバックアップによるパフォーマンスへの影響を排除します。</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">異なるクラウドプロバイダからのマルチクラウドデータ保護とデータアクセスを、単一の分析データソースに同時に提供できます。</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">FlexClone テクノロジを使用すると、スペース効率に優れた高速な Hadoop クラスタコピーを作成できます。</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">このドキュメントに記載されている情報の詳細については、以下のドキュメントや Web サイトを参照してください。</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">ネットアップのビッグデータ分析ソリューション</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">ネットアップストレージを使用した Apache Spark ワークロード</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">ネットアップの Apache Spark 向けストレージソリューション</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">ネットアップが有効にしたデータファブリック上の Apache Hadoop</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="list-text">NetApp In-Place Analytics Module の略</block>
  <block id="1d669c79bffe95dd384dffb8309a0d40" category="inline-link"><block ref="1d669c79bffe95dd384dffb8309a0d40" category="inline-link-rx"></block></block>
  <block id="fde1cd76fa73f8065aeb8a97c77b40ec" category="paragraph"><block ref="fde1cd76fa73f8065aeb8a97c77b40ec" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">謝辞</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">ネットアップ、 ANZ 地域セールス担当、 Paul Burland 氏</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">ネットアップ、ビジネス開発マネージャー、 Hoseb Dermanilian 氏</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">ネットアップ、 MPSG ディレクター、 Lee Dorrior 氏</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">ネットアップ、 ANZ ビクトリア地区 SE 、システムエンジニア David Thiessen 氏</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">2018 年 1 月</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">ユースケース 5 ：分析ワークロードの高速化を更新</block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">このシナリオでは、大規模なオンプレミスの Hadoop リポジトリがあり、ディザスタリカバリのためにバックアップを作成したいと考えています。しかし、お客様の現在のバックアップ解決策はコストが高く、 24 時間以上のバックアップウィンドウに悩まされています。</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">使用事例 1 ： Hadoop データのバックアップ</block>
  <block id="8efec9e11b7742f59dbe1af079e1c1d0" category="inline-link-macro">以前： Hadoop のデータ保護のユースケースの概要。</block>
  <block id="259b434ecfae95df231c879645a98918" category="paragraph"><block ref="259b434ecfae95df231c879645a98918" category="inline-link-macro-rx"></block></block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">ソフトウェアの下位互換性：</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">提案する代替バックアップ解決策は、本番用 Hadoop クラスタで現在実行しているソフトウェアバージョンと互換性があることが必要です。</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">コミットされた SLA を満たすためには、代替の解決策で非常に低い RPO と RTO を達成することを推奨します。</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">ネットアップのバックアップ解決策で作成したバックアップは、データセンターのローカルに構築された Hadoop クラスタ、およびリモートサイトのディザスタリカバリロケーションで実行されている Hadoop クラスタで使用できます。</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">提案する解決策は対費用効果が高いものでなければなりません。</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">提案する解決策は、バックアップ処理中に実行中の本番環境の分析ジョブに与えるパフォーマンスへの影響を軽減する必要があります。</block>
  <block id="e3d4f6860e578b28733c41c2c852f821" category="section-title">お客様の既存のバックアップ解決策</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">次の図は、元の Hadoop ネイティブのバックアップ解決策を示しています。</block>
  <block id="2975218bd3c71a4ac4eac95d3529a9cb" category="paragraph"><block ref="2975218bd3c71a4ac4eac95d3529a9cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">本番環境のデータは、中間バックアップクラスタを通じてテープに保護されます。</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">hadoop distcp-update &lt;hdfs1 &gt;&lt;hdfs2&gt;` コマンドを実行することにより、 HDFS1 データが HDFS2 にコピーされます。</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">バックアップ・クラスタは NFS ゲートウェイとして機能し ' テープ・ライブラリを介して Linux'cp' コマンドを使用してデータを手動でテープにコピーします</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">元の Hadoop ネイティブバックアップ解決策には次のようなメリットがあります。</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">解決策は Hadoop ネイティブのコマンドをベースにしているため、新しい手順を習得する必要がなくなります。</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">解決策は、業界標準のアーキテクチャとハードウェアを活用しています。</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">元の Hadoop ネイティブバックアップ解決策には、次のような欠点があります。</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">バックアップ時間が長いと 24 時間を超えるため、本番環境のデータが脆弱になります。</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">バックアップ時間中にクラスタのパフォーマンスが大幅に低下します。</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">テープへのコピーは手動で行います。</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">バックアップ解決策は、必要なハードウェアと、手動プロセスに必要な人的時間の点でコストが高くなります。</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">バックアップソリューション</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">これらの課題と要件に基づいて、既存のバックアップシステムを検討し、 3 つのバックアップソリューションを提案しました。以降のサブセクションでは、解決策 A ～ 解決策 C というラベルの付いた 3 種類のバックアップソリューションについて説明します</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">解決策 A の略</block>
  <block id="8ee7b0fbb95cf5b1c98578a7ef03b9eb" category="paragraph">解決策 A は、バックアップ Hadoop クラスタにインプレース分析モジュールを追加し、次の図に示すように、ネットアップ NFS ストレージシステムへのセカンダリバックアップを可能にします。これにより、テープの要件がなくなります。</block>
  <block id="411ee6c684ee720eff303771433e41d6" category="paragraph"><block ref="411ee6c684ee720eff303771433e41d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">解決策 A の詳細なタスクは次のとおりです。</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">本番環境の Hadoop クラスタには、保護が必要な HDFS 内のお客様の分析データがあります。</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">HDFS を使用するバックアップ Hadoop クラスタは、データの中間的な場所として機能します。Just a Bunch of Disks （ JBOD ）は、本番環境の Hadoop クラスタとバックアップの Hadoop クラスタの両方で HDFS にストレージを提供する。</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">「 hadoop distcp – update – diff&lt;hdfs1 &gt;&lt;hdfs2&gt;` コマンド」を実行することで、 Hadoop 本番クラスタの HDFS からバックアップクラスタの HDFS へと Hadoop 本番データを保護します。</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Hadoop スナップショットは、本番環境からバックアップ Hadoop クラスタへデータを保護するために使用されます。</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">NetApp ONTAP ストレージコントローラは、バックアップ Hadoop クラスタにプロビジョニングされる NFS エクスポートボリュームを提供します。</block>
  <block id="b0e42779d51b21a745cae08f938ec60a" category="list-text">MapReduce と複数のマッパを利用して「 hadoop distcp 」コマンドを実行することで、分析データはインプレース分析モジュールを使用してバックアップ Hadoop クラスタから NFS に保護されます。</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">ネットアップストレージシステム上の NFS にデータを格納したあと、必要に応じて、ネットアップの Snapshot 、 SnapRestore 、および FlexClone テクノロジを使用して Hadoop データをバックアップ、リストア、および複製します。</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">Hadoop データは、 SnapMirror テクノロジを使用してクラウドやディザスタリカバリロケーションに保護できます。</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">解決策 A には、次のような利点があります。</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Hadoop の本番データはバックアップクラスタから保護されます。</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">HDFS データは NFS を通じて保護されるため、クラウドやディザスタリカバリの場所を保護できます。</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">バックアップ処理をバックアップクラスタにオフロードすることでパフォーマンスを向上します。</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">手動でのテープ操作が不要になります</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">ネットアップのツールを使用してエンタープライズ管理機能を利用できます。</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">既存の環境への変更は最小限で済みます。</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">対費用効果の高い解決策です。</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">この解決策の欠点は、パフォーマンスを向上させるためにバックアップクラスタと追加のマッパが必要であることです。</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">お客様は最近、解決策 A を導入しました。シンプルさ、コスト、全体的なパフォーマンスが理由です。</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">この解決策では、 JBOD の代わりに ONTAP の SAN ディスクを使用できます。このオプションを選択すると、バックアップクラスタのストレージ負荷が ONTAP にオフロードされますが、問題となるのは SAN ファブリックスイッチが必要な場合です。</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">解決策 B</block>
  <block id="304af2b0b47890c7db8f6097978fdede" category="paragraph">解決策 B は本番用 Hadoop クラスタにインプレース分析モジュールを追加するため、次の図に示すように、バックアップ Hadoop クラスタは不要です。</block>
  <block id="303388aba87d7dcff207a6cd098b0cfe" category="paragraph"><block ref="303388aba87d7dcff207a6cd098b0cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">解決策 B の詳細なタスクは次のとおりです。</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">NetApp ONTAP ストレージコントローラは、本番用 Hadoop クラスタに対して NFS エクスポートをプロビジョニングします。</block>
  <block id="3c321f811c173c1f133bdcc77fc81a33" category="paragraph">hadoop native 「 hadoop distcp 」コマンドは、実稼働クラスタ HDFS からインプレース分析モジュールを介して NFS へ Hadoop データを保護します。</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">ネットアップストレージシステム上の NFS にデータを格納したあと、 Snapshot 、 SnapRestore 、および FlexClone テクノロジを使用して、必要に応じて Hadoop データをバックアップ、リストア、および複製します。</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">解決策 B には次のような利点があります。</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">本番環境クラスタは、バックアップ解決策用に若干変更されるため、実装が簡単になり、インフラコストを削減できます。</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">バックアップ処理のためのバックアップクラスタは必要ありません。</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">HDFS の本番環境のデータは、 NFS データへの変換によって保護されます。</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">解決策では、ネットアップのツールを使用してエンタープライズ管理機能を実行できます。</block>
  <block id="02946730aaff0e3d8abfa986a2fe949d" category="paragraph">この解決策の欠点は、本番クラスタに実装されており、本番クラスタに管理者タスクを追加できることです。</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">解決策 C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">解決策 C では、次の図に示すように、 NetApp SAN ボリュームが HDFS ストレージの Hadoop 本番クラスタに直接プロビジョニングされます。</block>
  <block id="dc460b3501caf17186202576855a6d3c" category="paragraph"><block ref="dc460b3501caf17186202576855a6d3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">解決策 C の詳細な手順は次のとおりです。</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">NetApp ONTAP SAN ストレージは、 HDFS データストレージの本番用 Hadoop クラスタでプロビジョニングされます。</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">NetApp Snapshot テクノロジと SnapMirror テクノロジを使用して、本番用 Hadoop クラスタの HDFS データをバックアップします。</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">バックアップはストレージレイヤにあるため、 Snapshot コピーのバックアッププロセス中は Hadoop / Spark クラスタの本番環境でパフォーマンスが低下することはありません。</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">Snapshot テクノロジを使用すると、データのサイズに関係なく数秒で完了するバックアップを作成できます。</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">解決策 C には次のような利点があります。</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">スペース効率に優れたバックアップは、 Snapshot テクノロジを使用して作成できます。</block>
  <block id="5788267ffe4023e91b333de591766cca" category="inline-link-macro">次のユースケース 2 ：クラウドからオンプレミスへのバックアップとディザスタリカバリ</block>
  <block id="1619284091911820ebd1407554fb6da7" category="paragraph"><block ref="1619284091911820ebd1407554fb6da7" category="inline-link-macro-rx"></block></block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">このユースケースは、クラウドベースの分析データをオンプレミスのデータセンターにバックアップする必要がある放送局の顧客に基づいています。</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">ユースケース 2 ：クラウドからオンプレミスへのバックアップとディザスタリカバリ</block>
  <block id="d05b5b5452aa966fcd3c8947a172f44a" category="inline-link-macro">前：ユースケース 1 - Hadoop データのバックアップ</block>
  <block id="d6b3b64a2054103914910c4432cc9e18" category="paragraph"><block ref="d6b3b64a2054103914910c4432cc9e18" category="inline-link-macro-rx"></block></block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">このユースケースは、放送局のお客様がクラウドベースの分析データをオンプレミスのデータセンターにバックアップする必要がある場合を基準にしています。以下の図を参照してください。</block>
  <block id="063e138ba69a95a99bd2f908b540e210" category="paragraph"><block ref="063e138ba69a95a99bd2f908b540e210" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">このシナリオでは、 IoT センサーのデータがクラウドに取り込まれ、 AWS 内のオープンソースの Apache Spark クラスタを使用して分析されます。処理されたデータをクラウドからオンプレミスにバックアップすることが要件です。</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">データ保護を有効原因にしても、本番環境の Spark / Hadoop クラスタのパフォーマンスへの影響は一切ありません。</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">効率的かつ安全な方法で、クラウドセンサーデータをオンプレミスに移動して保護する必要があります。</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">オンデマンド、瞬時、クラスタの低負荷時など、さまざまな条件下でクラウドからオンプレミスにデータを柔軟に転送できます。</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">お客様は、 Spark クラスタの HDFS ストレージとして AWS Elastic Block Store （ EBS ）を使用して、 Kafka 経由でリモートセンサーからデータを受け取り、取り込むことになりました。そのため、 HDFS ストレージはバックアップデータのソースとして機能します。</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">これらの要件を満たすために、 NetApp ONTAP Cloud が AWS に導入され、 Spark / Hadoop クラスタのバックアップターゲットとして機能する NFS 共有が作成されます。</block>
  <block id="c260f0b6bfdb6eff1473aafbf5bd075a" category="paragraph">NFS 共有が作成されると、インプレース分析モジュールを使用して、 HDFS EBS ストレージから ONTAP NFS 共有にデータがコピーされます。データが ONTAP クラウド上の NFS に配置されると、 SnapMirror テクノロジを使用して、必要に応じてクラウドからオンプレミスのストレージにデータを安全かつ効率的にミラーリングできます。</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">この図は、クラウドからオンプレミスの解決策へのバックアップとディザスタリカバリを示しています。</block>
  <block id="94c7a6b63152038de5e8b2763cdef06c" category="paragraph"><block ref="94c7a6b63152038de5e8b2763cdef06c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bbd6a10b63926b84e9a28da6d4214925" category="inline-link-macro">次：ユースケース 3 - 既存の Hadoop データに対して DevTest を有効化</block>
  <block id="e0f915fb1893e398d54abc6f9d00ca57" category="paragraph"><block ref="e0f915fb1893e398d54abc6f9d00ca57" category="inline-link-macro-rx"></block></block>
  <block id="69efde21ccf40f1dda4d665f81bacefe" category="summary">このシナリオでは、 NetApp NFS ストレージ解決策を使用して大規模な金融サービスおよび投資銀行の分析プラットフォームを最新化し、資産管理および定量的ビジネスユニットの投資リスクおよび派生物の分析を大幅に改善しました。</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">ユースケース 5 ：分析ワークロードを高速化</block>
  <block id="c8ea1eda8e0ac121148ac86dee9649a7" category="inline-link-macro">前のステップ：ユースケース 4 - データ保護とマルチクラウド接続</block>
  <block id="87fb2a1eb3f12014af6e5dd36ba66e5e" category="paragraph"><block ref="87fb2a1eb3f12014af6e5dd36ba66e5e" category="inline-link-macro-rx"></block></block>
  <block id="24b0e878b8196875cd088397ac8312a9" category="paragraph">お客様の既存の環境では、分析プラットフォームに使用される Hadoop インフラストラクチャは、 Hadoop サーバの内部ストレージを活用しています。JBOD 環境の専有特性により、組織内の多くの社内顧客は、リアルタイムデータの繰り返しサンプルに依存するシミュレーションであるモンテカルロ定量モデルを利用できませんでした。市場動向の不確実性の影響を理解するのに最適な能力は、量的資産管理事業部門にとって好ましくないものとなっていました。</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">銀行の定量事業部門は、正確でタイムリーな予測を実現するための効率的な予測方法を求めていました。そのためには、インフラを刷新し、既存の I/O 待機時間を短縮し、 Hadoop や Spark などの分析アプリケーションのパフォーマンスを向上させて、投資モデルを効率的にシミュレートし、潜在的な利益を測定し、リスクを分析する必要性を認識しました。</block>
  <block id="5ff37557b096819452a25d129a312360" category="paragraph">お客様は、既存の Spark 解決策の JBOD を使用していました。その後、 NetApp ONTAP 、 NetApp StorageGRID 、 MinIO Gateway to NFS を活用して、銀行の定量的財務グループの I/O 待機時間を短縮し、潜在的な利益とリスクを評価する投資モデルのシミュレーションと分析を実行しました。この図は、 Spark の解決策とネットアップストレージを示しています。</block>
  <block id="095ba715431845442ef6bf2f4283ad1c" category="paragraph"><block ref="095ba715431845442ef6bf2f4283ad1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">上の図に示すように、 Spark 搭載の 6 ノード Hadoop クラスタで NFS プロトコルと S3 プロトコルを使用して寄木細工のファイルにアクセスするために AFF A800 、 A700 システム、 StorageGRID を導入し、データ分析処理用に糸と Hive のメタデータサービスを用意しました。</block>
  <block id="bc12facb8aa0a34db56b00fdbc21c351" category="paragraph">お客様の古い環境にある DAS （直接接続型ストレージ）解決策には、コンピューティングとストレージを個別に拡張するという欠点がありました。NetApp ONTAP 解決策 for Spark を使用することで、銀行の財務分析事業部門はストレージをコンピューティングから切り離し、必要に応じてインフラリソースをより効率的に提供することができました。</block>
  <block id="582c4aa65d1bd005ddc785db8b807fca" category="paragraph">NFS で ONTAP を使用することで、 Spark の SQL ジョブにはコンピュートサーバの CPU がほぼフルに活用され、 I/O 待機時間が 70% 近く削減されました。その結果、 Spark のワークロードの処理能力とパフォーマンスが向上しました。また、 CPU 利用率の向上により、お客様は GPUDirect などの GPU を活用してプラットフォームをさらに最新化できるようになりました。さらに、 StorageGRID は Spark のワークロードに低コストのストレージオプションを提供し、 MinIO Gateway は S3 プロトコル経由で NFS データへの安全なアクセスを提供します。クラウド内のデータには、 Cloud Volumes ONTAP 、 Azure NetApp Files 、 NetApp Cloud Volumes Service を推奨します。</block>
  <block id="6e362ed6e741056d737b93021ab2f3f9" category="paragraph"><block ref="6e362ed6e741056d737b93021ab2f3f9" category="inline-link-macro-rx"></block></block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop ディストリビュータは、大規模なクラスタ間コピーとクラスタ内コピーに使用されるネイティブツールです。Hadoop DistCp の基本的なプロセスは、 MapReduce などの Hadoop ネイティブツールを使用して Hadoop のデータを HDFS ソースから対応するターゲットにコピーする、一般的なバックアップワークフローです。</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Hadoop データ保護機能とネットアップ</block>
  <block id="9445444fbd9e863564ea85ad226c0e80" category="inline-link-macro">従来のソリューション：ネットアップのビッグデータアーキテクチャを基盤とするデータファブリック。</block>
  <block id="e30c587da81860e05b3f8ecfb5b9965b" category="paragraph"><block ref="e30c587da81860e05b3f8ecfb5b9965b" category="inline-link-macro-rx"></block></block>
  <block id="5f45c95989226891db648114a547a6bd" category="paragraph">Hadoop ディストリビュータは、大規模なクラスタ間コピーとクラスタ内コピーに使用されるネイティブツールです。次の図に示す Hadoop ディストリビュータの基本的なプロセスは、 MapReduce などの Hadoop ネイティブツールを使用した一般的なバックアップワークフローで、 HDFS ソースから対応するターゲットに Hadoop データをコピーします。NetApp NFS の直接アクセスを使用すると、 Hadoop DistCp ツールのターゲットデスティネーションとして NFS を設定し、 HDFS ソースから MapReduce 経由で NFS 共有にデータをコピーできます。NetApp NFS への直接アクセスは、 DistCp ツールの NFS ドライバとして機能します。</block>
  <block id="6369c8cb38b142174d2f84d12d2f0420" category="paragraph"><block ref="6369c8cb38b142174d2f84d12d2f0420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4849340a20db94ed712aca71c30b915" category="inline-link-macro">次： Hadoop のデータ保護のユースケースの概要。</block>
  <block id="817c6593a9a8efc031ec597b5d11d605" category="paragraph"><block ref="817c6593a9a8efc031ec597b5d11d605" category="inline-link-macro-rx"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">このユースケースは、お客様のビッグデータ分析データにマルチクラウド接続を提供するという課題を抱えるクラウドサービスパートナーに適しています。</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">ユースケース 4 ：データ保護とマルチクラウド接続</block>
  <block id="2c8eccdfa6390b1d09b2527f7d7d2cc5" category="inline-link-macro">前：ユースケース 3 - 既存の Hadoop データに対する DevTest の有効化</block>
  <block id="fda5cc5b496f5f7aa6de18740227bc15" category="paragraph"><block ref="fda5cc5b496f5f7aa6de18740227bc15" category="inline-link-macro-rx"></block></block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">このシナリオでは、さまざまなソースから AWS で受信した IoT データが NPS の中央の場所に保存されます。NPS ストレージは、 AWS と Azure 上にある Spark / Hadoop クラスタに接続されています。これにより、同じデータにアクセスする複数のクラウドで実行されるビッグデータ分析アプリケーションを実現できます。</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">お客様は、複数のクラウドを使用して、同じデータに対して分析ジョブを実行したいと考えています。</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">オンプレミスやクラウドなどのさまざまなソースから、さまざまなセンサーやハブを介してデータを受信する必要があります。</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">解決策は、効率性とコスト効率に優れている必要があります。</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">主な課題は、オンプレミスと異なるクラウドの間でハイブリッド分析サービスを提供する、対費用効果の高い効率的な解決策を構築することです。</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">この図は、データ保護とマルチクラウド接続解決策を示しています。</block>
  <block id="faaf8e6278dc7a68fd1dd98dfe7f525a" category="paragraph"><block ref="faaf8e6278dc7a68fd1dd98dfe7f525a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14c23633f1ab374f4c801386847ba2f8" category="paragraph">上の図に示すように、センサーからのデータはストリーミングされ、 Kafka を介して AWS Spark クラスタに取り込まれます。データは NPS 内の NFS 共有に格納されます。 NPS は、 Equinix データセンター内のクラウドプロバイダの外部にあります。NetApp NPS は、 Direct Connect 接続と Express Route 接続を通じて Amazon AWS と Microsoft Azure に接続されているため、お客様はインプレース分析モジュールを利用して、 Amazon と AWS 両方の分析クラスタからデータにアクセスできます。このアプローチは、複数のハイパースケーラにわたるクラウド分析の実現を解決します。</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">そのため、オンプレミスと NPS ストレージはどちらも ONTAP ソフトウェアを実行するため、 SnapMirror を使用して NPS データをオンプレミスクラスタにミラーリングし、オンプレミスと複数のクラウドにわたるハイブリッドクラウド分析を実現できます。</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">パフォーマンスを最大限に高めるために、通常は複数のネットワークインターフェイスと直接接続 / エクスプレスルートを使用してクラウドインスタンスからデータにアクセスすることを推奨します。</block>
  <block id="1ef541fe0fa79d247c0f1751629bb504" category="inline-link-macro">次：ユースケース 5 - 分析ワークロードの高速化</block>
  <block id="7dfabd0b120fe0403ff107668db4094a" category="paragraph"><block ref="7dfabd0b120fe0403ff107668db4094a" category="inline-link-macro-rx"></block></block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">このセクションでは、データ保護のユースケースの概要を概要で説明します。これが、本ドキュメントで重要となるのです。以降のセクションでは、それぞれのユースケースについて、お客様の問題（シナリオ）、要件と課題、ソリューションなどの詳細を説明します。</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Hadoop のデータ保護のユースケースの概要</block>
  <block id="d161097dc6596d3807b21a5635856d71" category="inline-link-macro">以前のバージョン： Hadoop データ保護機能とネットアップ。</block>
  <block id="1a5df0b83f496dc00b4a331caac0d5cd" category="paragraph"><block ref="1a5df0b83f496dc00b4a331caac0d5cd" category="inline-link-macro-rx"></block></block>
  <block id="385dae214dc9bab52698dc7cd42632ad" category="paragraph">このユースケースでは、大規模な金融機関がインプレース分析モジュールを使用して、バックアップ時間を 24 時間以上から数時間未満に短縮しました。</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">大規模な放送会社では、ネットアップのデータファブリックをビルディングブロックとして使用することで、オンデマンド、瞬時、データ転送などのさまざまなデータ転送モードに応じて、クラウドデータをオンプレミスのデータセンターにバックアップするという要件を満たすことができました。 または、 Hadoop / Spark のクラスタの負荷に基づいて計算されました。</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">ネットアップのソリューションは、オンラインの音楽配信企業が、スペース効率に優れた複数の Hadoop クラスタをさまざまなブランチオフィスに迅速に構築し、レポートを作成したり、定期的なポリシーを使用して日々の DevTest タスクを実行したりできるよう支援しました</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">ある大手サービスプロバイダは、ネットアップのデータファブリックを使用して、さまざまなクラウドインスタンスからお客様にマルチクラウド分析を提供していました。</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">最大規模の金融サービスおよび投資銀行の 1 つは、ネットアップのネットワーク接続型ストレージ解決策を使用して、 I/O 待ち時間を短縮し、定量的な金融分析プラットフォームを高速化しました。</block>
  <block id="2afe208a471bf6c54f0ccc97f4c6508d" category="inline-link-macro">次のユースケース 1 - Hadoop データのバックアップ</block>
  <block id="aac250a096aacf9aed26ebbd137818da" category="paragraph"><block ref="aac250a096aacf9aed26ebbd137818da" category="inline-link-macro-rx"></block></block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">ネットアップのデータファブリックは、クラウド環境とオンプレミス環境全体でデータ管理を簡易化、統合することで、デジタル変革を加速します。ネットアップのデータファブリックは、一貫した統合的データ管理サービスとアプリケーション（ビルディングブロック）を提供し、データの可視化と分析、データのアクセスと制御、データの保護とセキュリティを実現します。</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">ネットアップのデータファブリックを基盤としたビッグデータアーキテクチャ</block>
  <block id="32e0d2b797e6706a73e8146d103572c7" category="inline-link-macro">Previous ：解決策の概要を示します。</block>
  <block id="45af7a946606481f9e2b5f0434aa0484" category="paragraph"><block ref="45af7a946606481f9e2b5f0434aa0484" category="inline-link-macro-rx"></block></block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">ネットアップのデータファブリックは、クラウド環境とオンプレミス環境全体でデータ管理を簡易化、統合することで、デジタル変革を加速します。</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">ネットアップのデータファブリックは、一貫した統合的データ管理サービスとアプリケーション（ビルディングブロック）を提供し、データの可視性と分析、データのアクセスと制御、データの保護とセキュリティを実現します。以下の図を参照してください。</block>
  <block id="22313f8779f9135c9b421ac0d4b320fb" category="paragraph"><block ref="22313f8779f9135c9b421ac0d4b320fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">実績のあるデータファブリックのユースケース</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">ネットアップのデータファブリックは、以下の 9 つのユースケースをお客様に提供します。</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">分析ワークロードを高速化</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">DevOps 変革を加速</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">クラウドとホスティングのインフラ構築</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">クラウドデータサービスを統合</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">データの保護とセキュリティ</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">非構造化データを最適化</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">データセンターの効率化</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">データの分析と管理を実現</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">簡易化と自動化</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">このドキュメントでは、 9 つのユースケースのうち 2 つを取り上げ、それぞれのソリューションを紹介します。</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">NetApp NFS への直接アクセス</block>
  <block id="233060aa11b5715000c000e94576cca9" category="paragraph">NetApp NFS から直接アクセス（旧 NetApp In-Place Analytics Module ）を使用すると、データを移動したりコピーしたりすることなく、既存または新規の NFSv3 / NFSv4 データに対してビッグデータ分析ジョブを実行できます。データの複数のコピーが作成されるため、ソースとデータを同期する必要がありません。たとえば、金融機関では、ある場所から別の場所へデータを移動する際に法的義務を果たす必要がありますが、これは容易な作業ではありません。このシナリオでは、 NetApp NFS の直接アクセスによって、元の場所から財務データが分析されます。もう 1 つの主な利点は、 NetApp NFS 直接アクセスを使用すると、ネイティブの Hadoop コマンドを使用して Hadoop データを保護しやすくなることと、ネットアップの充実したデータ管理ポートフォリオを活用してデータ保護ワークフローを実現できることです。</block>
  <block id="96e1e6bac181280c42ba5de56a8ef4c2" category="paragraph"><block ref="96e1e6bac181280c42ba5de56a8ef4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">NetApp NFS 直接アクセスでは、 Hadoop クラスタと Spark クラスタに対して次の 2 種類の導入オプションを提供しています。</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">デフォルトでは、 Hadoop / Spark クラスタは、データストレージとデフォルトのファイルシステムに Hadoop Distributed File System （ HDFS ； Hadoop 分散ファイルシステム）を使用しています。NetApp NFS の直接アクセスを使用すると、デフォルトの HDFS をデフォルトのファイルシステムとして NFS ストレージに置き換えることができるため、 NFS データに対する直接分析処理が可能になります。</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">もう 1 つの導入オプションでは、 NetApp NFS 直接アクセスを使用して、 1 つの Hadoop / Spark クラスタ内に HDFS を追加のストレージとして構成することもできます。この場合、 NFS エクスポートを介してデータを共有し、 HDFS データと同じクラスタからデータにアクセスできます。</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">NetApp NFS 直接アクセスを使用する主な利点は次のとおりです。</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">現在の場所からデータを分析するため、分析データを HDFS などの Hadoop インフラに移動する時間とパフォーマンスのかかるタスクは発生しません。</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">レプリカの数を 3 つから 1 つに減らします。</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">ユーザはコンピューティングとストレージを切り離して個別に拡張できます。</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">ONTAP の豊富なデータ管理機能を活用して、エンタープライズデータを保護します。</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">Hortonworks データプラットフォームで認定されています。</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">ハイブリッドデータ分析環境を実現</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">動的なマルチスレッド機能を活用して、バックアップ時間を短縮します。</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">ビッグデータ向けのビルディングブロック</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">ネットアップのデータファブリックは、以下の図に示すように、データアクセス、制御、保護、セキュリティのためのデータ管理サービスとアプリケーション（ビルディングブロック）を統合しています。</block>
  <block id="f0a67f0f8f389fb239ce107f693a7e68" category="paragraph"><block ref="f0a67f0f8f389fb239ce107f693a7e68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">上の図の構成要素は次のとおりです。</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* NetApp NFS 直接アクセス。 * 最新の Hadoop クラスタと Spark クラスタを、ソフトウェアやドライバの追加の必要なしに NetApp NFS ボリュームに直接アクセスできます。</block>
  <block id="2867a490011894512662b9423698d0e0" category="list-text">* ネットアップの Cloud Volumes ONTAP とクラウドボリュームサービス。 * ソフトウェア定義型の接続ストレージ。 Amazon Web Services （ AWS ）で実行されている ONTAP または Microsoft Azure クラウドサービスで実行されている Azure NetApp Files （ ANF ）に基づいています。</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">* NetApp SnapMirror テクノロジ * 。オンプレミスと ONTAP クラウドインスタンスまたは NPS インスタンス間でデータ保護機能を提供します。</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">* クラウド・サービス・プロバイダー。 * これらのプロバイダーには、 AWS 、 Microsoft Azure 、 Google Cloud 、 IBM Cloud が含まれます。</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">* PaaS * AWS の Amazon Elastic MapReduce （ EMR ）や Databricks 、 Microsoft Azure HDInsight 、 Azure Databricks などのクラウドベースの分析サービスを利用できます。</block>
  <block id="35848dde21e4a5f344385ead6dec9a43" category="inline-link-macro">次のステップ： Hadoop データ保護とネットアップ。</block>
  <block id="149584f581a09d835c88f233c514412e" category="paragraph"><block ref="149584f581a09d835c88f233c514412e" category="inline-link-macro-rx"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">本ドキュメントでは、 NetApp AFF および FAS ストレージシステム、 NetApp Cloud Volumes ONTAP 、ネットアップ接続ストレージ、 Spark および Hadoop 向けの NetApp FlexClone テクノロジを使用したハイブリッドクラウドデータソリューションについて説明します。これらの解決策アーキテクチャを使用することで、お客様の環境に適したデータ保護解決策を選択できます。ネットアップは、お客様とのやり取りと、お客様のビジネスユースケースに基づいてこれらのソリューションを設計しました。</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="doc">TR-4657 ：ネットアップのハイブリッドクラウドデータソリューション - Spark と Hadoop はお客様のユースケースに基づいています</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">ネットアップ、 Karthikeyan Nagalingam と Sathish Thyagarajan</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">本ドキュメントでは、 NetApp AFF および FAS ストレージシステム、 NetApp Cloud Volumes ONTAP 、ネットアップ接続ストレージ、 Spark および Hadoop 向けの NetApp FlexClone テクノロジを使用したハイブリッドクラウドデータソリューションについて説明します。これらの解決策アーキテクチャを使用することで、お客様の環境に適したデータ保護解決策を選択できます。ネットアップは、お客様とのやり取りと、お客様のビジネスユースケースに基づいてこれらのソリューションを設計しました。このドキュメントでは、次の詳細情報を提供します。</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Spark 環境や Hadoop 環境、お客様の課題に対応するデータ保護が必要な理由</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">ネットアップのビジョンと、そのビルディングブロックとサービスを基盤とするデータファブリック。</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">これらのビルディングブロックを使用して、柔軟なデータ保護ワークフローを構築する方法</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">実際のお客様のユースケースに基づく、複数のアーキテクチャの長所と短所各ユースケースには、次のコンポーネントがあります。</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">解決策</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">ソリューションの概要</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Hadoop のデータ保護を選ぶ理由</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">Hadoop 環境と Spark 環境では、次の点に注意する必要があります。</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">* ソフトウェアや人為的なエラー。 * Hadoop データの処理中にソフトウェアを更新したときに人的エラーが発生すると、業務によって原因が予期せぬ結果を招く可能性がある動作不良になることがあります。このような場合は、障害や妥当でない結果が生じないように、データを保護する必要があります。たとえば、ソフトウェアアップデートの実行が不十分でトラフィック信号分析アプリケーションが実行されたため、トラフィック信号データをプレーンテキスト形式で適切に分析できない新機能があります。ソフトウェアは JSON やその他の非テキストファイル形式を分析して、リアルタイムトラフィック制御分析システムを生成し、データポイントが不足している予測結果を生成します。このような状況では、原因が出力不良の可能性があり、交通信号で事故につながるおそれがあります。データ保護機能を使用すると、以前の作業中のアプリケーションバージョンにすばやくロールバックできるため、この問題に対応できます。</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">* サイズと拡張性。 * 分析データのサイズは日々増え続けています。その理由は、データソースとボリュームの数が増え続けることにあります。現在のビッグデータ市場では、ソーシャルメディア、モバイルアプリ、データ分析、クラウドコンピューティングの各プラットフォームがデータの主要なソースとなっており、データは急速に増加しています。そのため、データを保護して、正確なデータ運用を確保する必要があります。</block>
  <block id="80908b4b31d37977701d3694fbc636ac" category="list-text">* Hadoop のネイティブデータ保護。 * Hadoop には、データを保護するためのネイティブコマンドがありますが、このコマンドはバックアップ中のデータの整合性を提供しません。ディレクトリレベルのバックアップのみをサポートします。Hadoop によって作成された Snapshot は読み取り専用であり、バックアップデータを直接再利用することはできません。</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Hadoop や Spark のお客様にとって、データ保護の課題が発生しています</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Hadoop と Spark のお客様にとってよくある課題は、データ保護の際に本番クラスタのパフォーマンスに悪影響を与えることなく、バックアップ時間を短縮し、バックアップの信頼性を向上させることです。</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">また、 RPO （目標復旧時点）と RTO （目標復旧時間）のダウンタイムを最小限に抑え、オンプレミスとクラウドベースのディザスタリカバリサイトを制御して、ビジネス継続性を最適化する必要もあります。この制御は、通常、エンタープライズレベルの管理ツールを使用して行われます。</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">データ量が膨大で増え続けているだけでなく、データの到着率も増加しているため、 Hadoop 環境と Spark 環境は複雑化しています。このようなシナリオでは、ソースデータから効率的で最新の DevTest 環境と QA 環境を迅速に構築することは困難です。ネットアップはこれらの課題を認識し、本ホワイトペーパーで紹介しているソリューションを提供しています。</block>
  <block id="1f60e9ce60971dc2129b30c8820ff343" category="inline-link-macro">次のステップ：ネットアップのビッグデータアーキテクチャを基盤とするデータファブリック。</block>
  <block id="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="paragraph"><block ref="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="inline-link-macro-rx"></block></block>
  <block id="ea490901c403ce2b2a89f80227d0fb90" category="paragraph">バイナリおよびデータベースのレプリケーションマニュアルのスケジュール</block>
  <block id="931ea399c80122517d9eeb617f1594a0" category="list-text">ジョブテンプレートを設定して起動します。</block>
  <block id="2c777d857235f251004d6d8d70c9751d" category="list-text">以前に作成したジョブテンプレートをコピーします。</block>
  <block id="1eb977b1f69b531db931e9c62c1a0de9" category="list-text">「 ONTAP/CVO Setup Template 」を探して、右端で「 Copy Template 」をクリックします</block>
  <block id="3c96e57d33780bedfb652def025f39de" category="list-text">コピーしたテンプレートで [ テンプレートの編集 ] をクリックし、名前を [ バイナリおよびデータベースのレプリケーションのマニュアル ] に変更します。</block>
  <block id="b07fb736e8c17cea7e9e3753e7a67fd1" category="list-text">テンプレートの同じインベントリ、プロジェクト、資格情報を保持します。</block>
  <block id="f42c6e71dcb07b403b8393d5ab7f7fe4" category="list-text">実行するプレイブックとして ora_replication_cg.yml を選択します。</block>
  <block id="69fa06239fd734936aac1af5250c7f57" category="list-text">変数は変更されませんが、 CVO クラスタの IP は変数 dst_cluster_ip に設定する必要があります。</block>
  <block id="ec7445bbcbadd1f11fe1bc3e5e56eef9" category="list-text">ジョブテンプレートをスケジュールします。</block>
  <block id="ce0d20e65f0354847807516cbcc696f6" category="list-text">バイナリおよびデータベースのレプリケーション用プレイブックテンプレートをクリックし、一番上のオプションセットにあるスケジュールをクリックします。</block>
  <block id="d9a6405dc4a6cd71f6d77c749070a5e6" category="list-text">[ 追加 ] をクリックし、 [ バイナリおよびデータベースレプリケーションの名前スケジュールの追加 ] をクリックし、時間の開始時に [ 開始日時 ] を選択し、 [ ローカルタイムゾーン ] を選択して、 [ 実行頻度 ] をクリックします。実行頻度は、多くの場合、 SnapMirror レプリケーションが更新されます。</block>
  <block id="2dc4dec75c83aeb010419dc2a02da40b" category="admonition">ログボリュームのレプリケーション用に別のスケジュールが作成されるため、より頻繁にレプリケートできます。</block>
  <block id="cc335cb73dc47f7a9b404288e3b4330f" category="paragraph">ONTAP と CVO のセットアップ</block>
  <block id="6bc14a28f101e9d80ecc643ef13ef7fb" category="list-text">「 ONTAP/CVO Setup 」という名前を入力します</block>
  <block id="a7244f663b97629084f004e6c89b4a75" category="list-text">ジョブタイプを選択します。 Run は、プレイブックに基づいてシステムを設定します。</block>
  <block id="57344b3bd58c0e451513e303e45d49b7" category="list-text">オンプレミス環境用の ONTAP_setup.yml プレイブックを選択するか、 CVO-setup.yml を選択して CVO インスタンスにレプリケーションします。</block>
  <block id="41c1d72990c270d0221458749497c3e6" category="admonition">このテンプレートを使用して、他のプレイブック用にコピーします。</block>
  <block id="63c0320f73b5f4e528bbe1488acc5103" category="section-title">Oracle データベースのデータ保護を自動化</block>
  <block id="d798c6a829fee4b3d8316144e8769e91" category="paragraph">組織は環境を自動化して、効率を高め、導入を高速化し、手動作業を削減しています。Ansible などの構成管理ツールを使用して、エンタープライズデータベースの運用を合理化しています。この解決策では、 Ansible を使用して NetApp ONTAP による Oracle のデータ保護を自動化する方法を紹介します。ストレージ管理者、システム管理者、 DBA は、オフサイトのデータセンターやパブリッククラウドへのデータレプリケーションを一貫して迅速にセットアップできるため、次のようなメリットがあります。</block>
  <block id="1d4694b7ed077df8b2c51d4ef956ce0c" category="list-text">クラスタ間レプリケーション、 CVO のインスタンス化、 Oracle データベースのリカバリの構成にかかる時間を短縮できます</block>
  <block id="60bcf8682ddc3583a74e6cd2d95e1ccb" category="list-text">データベースリカバリワークフローを使用して、 DR シナリオを簡単にテストできます。</block>
  <block id="7fa4d3428dbef9829f6325b288c071bc" category="section-title">オンプレミスからオンプレミスへのレプリケーション</block>
  <block id="911a9e8dd85bfeeba31c1ed049e41e1c" category="list-text">ソースとデスティネーションにクラスタ間 LIF を作成</block>
  <block id="2f4eb56dd9301fc33f559b4345b90eb3" category="list-text">クラスタと SVM のピア関係を確立</block>
  <block id="2b71f4136dce37491ef0f319f5d1fbd9" category="list-text">Oracle ボリュームの SnapMirror を作成して初期化</block>
  <block id="20f4a46f5b12b0533f7a2268c4c2bf41" category="list-text">AWX/Tower を使用して、 Oracle バイナリ、データベース、ログ用のレプリケーションスケジュールを作成します</block>
  <block id="6ef1c2ae7c9ca61a54d88de28349a772" category="list-text">デスティネーションで Oracle DB のリストアを行い、データベースをオンラインにします</block>
  <block id="f4ec61d9ffa147f621f854609523a0fb" category="section-title">オンプレミスから AWS の CVO へ</block>
  <block id="3f155aa6a9345b3e25f3bb44ecccfc0a" category="list-text">AWS コネクタを作成します</block>
  <block id="1531cb3c2d4db27dcd3bfa2ad4711ec5" category="list-text">AWS で CVO インスタンスを作成</block>
  <block id="2f159b717f78e9925b219e87cbd20f9a" category="list-text">オンプレミスのクラスタを Cloud Manager に追加</block>
  <block id="df16a1e23dbbcc2f19f07ab1af741617" category="list-text">ソースにクラスタ間 LIF を作成</block>
  <block id="d1f660bb2bff2f31a46c751115155999" category="list-text">パート 1 ：未定</block>
  <block id="1ee2253d8fe666dbea54ab3648a62511" category="list-text">パート 2 ：未定</block>
  <block id="0679a51ae3a4071a6bd3dedbe97fd329" category="summary">このページでは、 NetApp ONTAP ストレージに Oracle データ保護を導入するための自動化方法について説明します。</block>
  <block id="22e3bbd761fbb7ae69b8035eb12f222d" category="paragraph">この解決策は、 AWX/Tower 環境で動作するように設計されています。</block>
  <block id="ad5310e9dcd8f367be2b92490488d86d" category="list-text">解決策は、プライベートクラウドのシナリオ（オンプレミスからオンプレミス）およびハイブリッドクラウド（オンプレミスからパブリッククラウドへの Cloud Volumes ONTAP [CVO] ）で実行するように設計されています。</block>
  <block id="936c99ed52ca08a052ebf611285dd998" category="inline-link-macro">CVO の導入と Connector の導入の前提条件を収集</block>
  <block id="ec329a9106131eb9bf99b0f9e67b0564" category="list-text">CVO Data Protection に必要なキーとトークンの取得方法の詳細については、を参照してください <block ref="e21f73de51752f791cddc773d1f38740" category="inline-link-macro-rx"></block></block>
  <block id="13716f12996b882bb4c7e0bd84c7c128" category="open-title">&lt;strong class="big"&gt; オンプレミス &lt;/strong&gt;&lt;strong&gt;|&lt;/strong&gt;</block>
  <block id="72bd33cc372377848ab3bb360deb365e" category="cell">ONTAP バージョン 9.8+</block>
  <block id="3ca63226b942aff3abcf62934a91e382" category="cell">ソース上の既存の Oracle 環境と、デスティネーション（ DR サイトまたはパブリッククラウド）上の同等の Linux オペレーティングシステム</block>
  <block id="6114118ecf4e8d86a2e7c80bfab462f6" category="open-title">&lt;strong&gt; 「ビッグ」 &gt;CVO&lt;/strong&gt;</block>
  <block id="2f960df807c8ad51e74c447149eb2033" category="cell">* Cloud Manager / AWS *</block>
  <block id="571f37fae4494df03321c2abe1fcc053" category="cell">AWS のアクセス / シークレットキー</block>
  <block id="7a5be8c4513f3bd0696db24a6bd977f4" category="cell">NetApp Cloud Manager アカウント</block>
  <block id="99e55608ac5f1697eb6804aaf586af09" category="cell">NetApp Cloud Manager Refresh Token</block>
  <block id="3f9ec2a23fee1cafeb1a700de677caac" category="cell">Playbook</block>
  <block id="1f959110c5104b300b1a3d5fe3ee80dc" category="cell">* ONTAP_setup*</block>
  <block id="b7ed1e5c864a764f83f035d7f4f774ee" category="cell">ソースクラスタでのクラスタ間 LIF の作成（オプション）</block>
  <block id="73ddb5848c16203494697871a4e993cd" category="cell">デスティネーションクラスタでのクラスタ間 LIF の作成（オプション）</block>
  <block id="04a35ce053d611d390fc192544fa4899" category="cell">クラスタ / SVM ピアリングの作成</block>
  <block id="4605aea1d05aa2979e72d73dd2c51773" category="cell">SnapMirror デスティネーションの作成と、指定された Oracle ボリュームの初期化</block>
  <block id="0dd4c7b6672d8937b6eb899b454fb7fe" category="cell">* ora_replication_cg *</block>
  <block id="7187aaa97acef94360159347d76a84c9" category="cell">/etc/oratab 内の各データベースのバックアップモードを有効にします</block>
  <block id="f9198142d6e5690166713858ae8a0cdd" category="cell">Oracle バイナリボリュームとデータベースボリュームの Snapshot</block>
  <block id="23ba14a0a5cf33c38faec5b66fff712e" category="cell">SnapMirror を更新しました</block>
  <block id="114debcae141b96db77c72e8a1e8fadb" category="cell">/etc/oratab 内の各データベースのバックアップモードをオフにします</block>
  <block id="682094861a79bcba0e0ab2e193198762" category="cell">* ora_replication_log *</block>
  <block id="1d03ae98454d1c807318a1e29a4e2736" category="cell">/etc/oratab 内の各データベースの現在のログを切り替えます</block>
  <block id="47e4696811eedec695f727189503e8df" category="cell">Oracle ログボリュームの Snapshot</block>
  <block id="86836efae3e3d868a96ae69bcbc987ba" category="cell">* ora_recovery*</block>
  <block id="6ceab4515ef4144abed0f0ce5ed3038f" category="cell">SnapMirror を解除します</block>
  <block id="a6066c717f63ac99226b48abb4cf1d85" category="cell">デスティネーションで NFS を有効にし、 Oracle ボリュームのジャンクションパスを作成します</block>
  <block id="aa46cdc29b66725a1180f57d02f0cee3" category="cell">DR Oracle ホストを設定</block>
  <block id="dea9253f9b15f57a0c2161848a3c27a3" category="cell">Oracle ボリュームをマウントして確認</block>
  <block id="ee95819ff53983a149759d555a93ba4b" category="cell">Oracle データベースをリカバリして起動します</block>
  <block id="5a6b57bc1fdf2f0e1259ed22f1d027a4" category="cell">* CVF_setup*</block>
  <block id="331c87cd495ffdc9cd55d8b3935a75f5" category="cell">環境の事前チェック</block>
  <block id="5f17c8d8d95282db12506044ba4d6ab9" category="cell">AWS Configure / AWS Access Key ID / Secret Key / Default Region</block>
  <block id="cef449920fe163cdd74231266cbdf23d" category="cell">AWS ロールの作成</block>
  <block id="85a4bcbc96cde90931ad369de96535b2" category="cell">AWS での NetApp Cloud Manager Connector インスタンスの作成</block>
  <block id="abe14752834b641e86064c7214f6719c" category="cell">AWS での Cloud Volumes ONTAP （ CVO ）インスタンスの作成</block>
  <block id="c2a9449cd3b0ae879520f450b65b1621" category="cell">オンプレミスのソース ONTAP クラスタを NetApp Cloud Manager に追加</block>
  <block id="fbb54d6efa6ca64af90fbe2289812be8" category="cell">デスティネーション CVO で NFS を有効にし、 Oracle ボリュームのジャンクションパスを作成してください</block>
  <block id="3ef6389d9b9aacdce331793dd2a96ce8" category="paragraph">自動化を簡易化するために、必要な Oracle パラメータがデフォルト値で多数設定されています。通常、ほとんどの環境でデフォルトパラメータを変更する必要はありません。上級ユーザーは ' デフォルト・パラメータを変更する際に注意してくださいデフォルトのパラメータは、各ロールフォルダの defaults ディレクトリにあります。</block>
  <block id="a98d844e94ad28c8e0fb089e005d6b9f" category="inline-link-macro">AWX/Tower の詳細な手順については、こちらを参照してください</block>
  <block id="7e599865fd1cdad0e26add5715f65267" category="paragraph">準備ができたら、をクリックします <block ref="d28bc5520349bb0598caaa5132432326" category="inline-link-macro-rx"></block>。</block>
  <block id="47373f46adef617d17665b0b94be8f67" category="paragraph">ログ・レプリケーション・プレイブックのスケジュール</block>
  <block id="8e43fbf8e210fdbb3e1d59ca59cde628" category="list-text">コピーしたテンプレートで [ テンプレートの編集 ] をクリックし、名前を [ リストアとリカバリプレイブック ] に変更します。</block>
  <block id="42f2159b893bbf4b6bf098ba9a026a1c" category="list-text">実行するプレイブックとして ora_recoveryyml を選択します。</block>
  <block id="0a3fe9b740fe79971ae2379eaec4822c" category="admonition">このプレイブックは、リモートサイトでデータベースをリストアする準備ができるまでは実行されません。</block>
  <block id="40640c0c34d4427f5d18b9ca476e3158" category="summary">このページでは、 NetApp ONTAP ストレージ上の Oracle19c の自動データ保護について説明します。</block>
  <block id="261e91a1afdfe1123497b1b9ba5ab3e1" category="section-title">AWX/Tower Oracle データ保護</block>
  <block id="db2b28449b6d868d910cd53527934988" category="list-text">最初のグループの Oracle という名前を入力し、 [ 保存 ] をクリックします。</block>
  <block id="200e1fa09608b23de5cd04d22d3a5bdb" category="list-text">DR_Oracle という名前の 2 つ目のグループに対してこの手順を繰り返します。</block>
  <block id="1e29c17b60e9145858da82263315e402" category="list-text">作成した Oracle グループを選択し、 Hosts サブメニューに移動して、 Add New Host をクリックします。</block>
  <block id="250d5368537e295251f9ccf63f950087" category="list-text">ソース Oracle ホストの管理 IP の IP アドレスを入力し、 [ 保存 ] をクリックします。</block>
  <block id="22dcd973cf7a10ed9d03c5b959e65807" category="list-text">DR_Oracle グループに対してこの手順を繰り返し、 DR/Destination Oracle ホストの管理 IP / ホスト名を追加する必要があります。</block>
  <block id="1a4eca6a53be80f21117669b80a5dbc8" category="admonition">以下は、オンプレミスと ONTAP 、または AWS 上の CVO のクレデンシャルタイプとクレデンシャルを作成する手順です。</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="open-title">オンプレミス</block>
  <block id="50d33cb309a9ea4bacb0a5541498b670" category="list-text">クレデンシャルタイプの作成ONTAP を使用するソリューションでは、ユーザ名とパスワードのエントリを照合するようにクレデンシャルタイプを設定する必要があります。</block>
  <block id="c048e95ab07253cc1cb87bef130c410b" category="list-text">次の内容をインジェクタ設定に貼り付け、 [ 保存 ] をクリックします。</block>
  <block id="9302fe5c60a983a24bb8787c00db4862" category="list-text">ONTAP のクレデンシャルを作成します</block>
  <block id="0a0aab79fb5a20fa5f830947226ef87c" category="list-text">ONTAP クレデンシャルの名前と組織の詳細を入力します</block>
  <block id="81999e930ad44af27e84682c3ea1e750" category="list-text">前の手順で作成したクレデンシャルタイプを選択します。</block>
  <block id="1546222d368538c25b5704b5fcf160f5" category="list-text">タイプの詳細で、ソースクラスタとデスティネーションクラスタのユーザ名とパスワードを入力します。</block>
  <block id="c4be718383c8ca0aa17633d911fc38fd" category="list-text">[ 保存 ] をクリックします .</block>
  <block id="39f6f9fe82cbf0c0970d13b6a043ad84" category="list-text">Oracle のクレデンシャルを作成します</block>
  <block id="30d4be106e7fb63befec4c8c7c815ad0" category="list-text">Oracle の名前と組織の詳細を入力します。</block>
  <block id="61d6c643401e4a602f3c8b4b6fc0a93c" category="list-text">必要に応じて、 DR_Oracle ホストの別のクレデンシャルに対して同じ手順を繰り返します。</block>
  <block id="f7fc367b5de87581ac78fc80805439af" category="open-title">CVO を確認して</block>
  <block id="61efb6ce79debd57f1e5eb28b08f94ba" category="list-text">クレデンシャルタイプを作成する。ONTAP が関連するソリューションでは、ユーザ名とパスワードのエントリに一致するクレデンシャルタイプを設定する必要があります。また、 Cloud Central と AWS のエントリも追加します。</block>
  <block id="b95cd128bfca5d5c9181a46d0392c360" category="list-text">次の内容をインジェクタ構成に貼り付け、 [ 保存（ Save ） ] をクリックする。</block>
  <block id="75f3f97810b5eef177a5355b86dabfd0" category="list-text">ONTAP / CVO / AWS のクレデンシャルを作成</block>
  <block id="922922f515b0ac072e20128999512b50" category="list-text">Oracle のクレデンシャルの作成（ソース）</block>
  <block id="7ebca140d5dcaa006aeda44b19cfc52e" category="list-text">Oracle ホストの名前と組織の詳細を入力します</block>
  <block id="ca530facf78f2112c60ee838d85b9b5b" category="list-text">Oracle 保存先のクレデンシャルを作成します</block>
  <block id="063e8368b0de123266b00f2c88e317fb" category="list-text">DR Oracle ホストの名前と組織の詳細を入力します</block>
  <block id="0d28c8cc8415971cf2cd02507176bf94" category="list-text">Type Details に、ユーザ名（ ec2-user またはデフォルトの入力から変更した場合は、そのユーザ名）と SSH 秘密鍵を入力します</block>
  <block id="cb8f433dfb62a17f7a02f4d7a8839b1c" category="list-text">適切な特権昇格方式（ sudo ）を選択し、必要に応じてユーザ名とパスワードを入力します。</block>
  <block id="791ef966f9be349751448b9066bdd8fa" category="list-text">入力するコマンド <block ref="1881636a0f344e587cc2202e2db4c5ac" category="inline-link-rx"></block> をソース管理 URL として指定します。</block>
  <block id="07ecfe1ec895f624e5c5d082fb961d1c" category="section-title">3. グローバル変数を設定します</block>
  <block id="dad1349ef99312028aeda3703d53efdb" category="section-title">4. 自動化に関するハンドブック</block>
  <block id="285a3bb8fb6f692046facadb3c0984cf" category="paragraph">実行する必要があるプレイブックは 4 つあります。</block>
  <block id="37472723bc7712fedddee6d02e29228d" category="list-text">環境のセットアップに関するプレイブック：オンプレミス、 CVO</block>
  <block id="5138c89250c5086accf2d1a5961c9b17" category="list-text">Oracle バイナリとデータベースをスケジュールどおりにレプリケートする Playbook</block>
  <block id="3e552d6e5b2c316c63eb1fc2081d42a8" category="list-text">Oracle ログをスケジュールどおりにレプリケートするためのプレイブック</block>
  <block id="33f4f1514dc2ceb963af16685f4de58c" category="list-text">デスティネーションホストでのデータベースのリカバリに関するプレイブック</block>
  <block id="17ae7167fac3c2364c6ad7b58819a920" category="open-title">ONTAP/CVO セットアップ</block>
  <block id="16f928d0ebd67060f6b3b2abf0481928" category="open-title">バイナリおよびデータベースボリュームのレプリケーション</block>
  <block id="b723f9a72bec39ac17d89e51ff0ba336" category="open-title">ログボリュームのレプリケーション</block>
  <block id="048f2ee27b8617cb0e13b6a0b7da956f" category="list-text">コピーしたテンプレートで [ テンプレートの編集 ] をクリックし、名前を [ ログレプリケーションのプレイブック ] に変更します。</block>
  <block id="d4a86123c8e623e35eaa51ab9583e03b" category="list-text">実行するプレイブックとして ora_replication_loges.yml を選択します。</block>
  <block id="d6e504930da1d0732ea4162514a38e8e" category="list-text">Log Replication Playbook テンプレートをクリックし、一番上のオプションセットにある Schedules （スケジュール）をクリックします。</block>
  <block id="1c03188c731004905466903c2eb763c4" category="list-text">[ 追加 ] をクリックし、 [ ログ複製の名前スケジュールの追加 ] をクリックし、時間の開始時に開始日時を選択し、 [ ローカルタイムゾーン ] と [ 実行頻度 ] を選択します。実行頻度は、多くの場合、 SnapMirror レプリケーションが更新されます。</block>
  <block id="d23bfe090a9fd09613c7a6573f619c02" category="admonition">1 時間ごとの最新の更新に確実にリカバリできるように、ログスケジュールを 1 時間ごとに更新するように設定することを推奨します。</block>
  <block id="f76dbca531ab83300165aacf97e1b7ff" category="open-title">データベースのリストアとリカバリ</block>
  <block id="8cc6746c11a65da30c7d875819acecfe" category="section-title">5. Oracle データベースのリカバリ</block>
  <block id="b8a177e5fd059f33473cad4d1d073d38" category="list-text">オンプレミスの本番 Oracle データベースのデータボリュームは、 NetApp SnapMirror レプリケーションを使用して、セカンダリデータセンターの冗長 ONTAP クラスタまたはパブリッククラウドの Cloud Volume ONTAP に保護されます。完全に構成されたディザスタリカバリ環境では、セカンダリデータセンターまたはパブリッククラウドのリカバリコンピューティングインスタンスがスタンバイ状態になり、災害発生時に本番データベースをリカバリできます。スタンバイコンピューティングインスタンスは、 OS カーネルパッチで paraellel アップデートを実行するか、ロックステップでアップグレードすることで、オンプレミスインスタンスと同期したままになります。</block>
  <block id="57d8ad774cb4fef3d53ee8836bfee761" category="list-text">この解決策で実証されている Oracle バイナリ・ボリュームは、ターゲット・インスタンスに複製され、ターゲット・インスタンスにマウントされて、 Oracle ソフトウェア・スタックが起動されます。この Oracle リカバリアプローチには、災害発生時に Oracle を新規にインストールした場合よりも優れています。Oracle のインストールは、現在のオンプレミスの本番ソフトウェアのインストールレベルやパッチレベルと完全に同期されていることが保証されます。ただし、 Oracle でのソフトウェアライセンスの構成によっては、リカバリサイトで複製された Oracle バイナリボリュームにソフトウェアライセンスが影響する場合とそうでない場合があります。ユーザは、 Oracle のライセンス要件を評価するために、ソフトウェアライセンス担当者に確認してから、同じ方法を使用することを推奨します。</block>
  <block id="74eaa493ffed695592003e0844d93c46" category="list-text">デスティネーションのスタンバイ Oracle ホストには、 Oracle の前提条件となる構成が設定されています。</block>
  <block id="0be4357ac224d44b11800179b23eb202" category="list-text">SnapMirror が切断され、ボリュームが書き込み可能になり、スタンバイ Oracle ホストにマウントされます。</block>
  <block id="69504b415e8aad20e18beca0de96ab6a" category="list-text">すべての DB ボリュームがスタンバイコンピューティングインスタンスにマウントされたあと、 Oracle リカバリモジュールは以下のタスクを実行して、リカバリサイトで Oracle をリカバリおよび起動します。</block>
  <block id="5e52a9563e31960cdf02c7b83e6495e7" category="list-text">制御ファイルを同期します。重要なデータベース制御ファイルを保護するために、異なるデータベースボリュームに Oracle 制御ファイルを重複して配置しました。1 つはデータボリューム上にあり、もう 1 つはログボリューム上にあります。データボリュームとログボリュームは異なる頻度でレプリケートされるため、リカバリ時に同期されません。</block>
  <block id="26b9a788a0ef0527f25f68892b364d19" category="list-text">Oracle バイナリの再リンク： Oracle バイナリは新しいホストに再配置されるため、再リンクが必要です。</block>
  <block id="b66ad18a7982f7c233e9d0af2f867856" category="list-text">Oracle データベースのリカバリ：リカバリ・メカニズムは、 Oracle ログ・ボリューム内の最後に使用可能なアーカイブ・ログのシステム変更番号を制御ファイルから取得し、 Oracle データベースをリカバリして、障害発生時に DR サイトにレプリケートされたすべてのビジネス・トランザクションをリカバリします。次に、データベースが新しいインカネーションで起動され、リカバリサイトでユーザ接続とビジネストランザクションが実行されます。</block>
  <block id="b9b07f10c0ce1735548942e3abaa3447" category="summary">このページでは、 NetApp Cloud Manager を介して CVO および Cloud Manager Connector の導入に必要なリフレッシュトークンとアクセス / シークレットキーを収集するための詳細情報を提供します。</block>
  <block id="bcc03f70ea2e77a98ddb6e8267e4892f" category="paragraph">AWX/Ansible タワーを介した Ansible プレイブックを使用して、 CVO とコネクタの自動導入を設定するには、次の情報が必要です。</block>
  <block id="193fc1c355935356ecd5d07811792512" category="section-title">AWS からアクセスキーとシークレットキーを取得する</block>
  <block id="60b6439418495e0d1821d169b7d4b885" category="list-text">Cloud Manager に CVO と Connector を導入するには、 AWS Access/Secret Key が必要です。IAM --&gt; ユーザー --&gt; ユーザー名 --&gt; セキュリティ資格情報 --&gt; アクセスキーの作成を起動して、 AWS コンソールでキーを取得します。</block>
  <block id="ad1cc06192440312813c412c9cf08bc5" category="list-text">アクセスキーをコピーし、 Connector および CVO の導入で使用するためのセキュリティを確保しておきます。</block>
  <block id="4ba9f13f5b12512f3651d5ea2d3ffa05" category="admonition">キーが紛失した場合は、別のアクセスキーを作成し、失われたアクセスキーを削除できます</block>
  <block id="ad35fbaef240a8ec1f43e8a0d5e15099" category="image-alt">トークンを更新します</block>
  <block id="89d8fe92eb33da3c73df38422c3fa73e" category="section-title">NetApp Cloud Central から Refresh Token を取得しています</block>
  <block id="3d7e1d21530a3a98c74b0b7484c84516" category="list-text">のアカウントクレデンシャルを使用して、 Cloud Central アカウントにログインします<block ref="ddbd83acb6424bbb7fa6878eff0976a1" category="inline-link-rx"></block></block>
  <block id="a95c6d24569073e45c394bcbd6a2c0e4" category="list-text">更新トークンを生成し、展開用に保存します。</block>
  <block id="ecd636681b83fa2697020594594aea14" category="section-title">クライアント ID を取得しています</block>
  <block id="2a1ed6ca97aeb484a26d6e0d625af96b" category="list-text">API ページにアクセスして、クライアント ID をにコピーします<block ref="06324b77583872f7e211b3e7ec3f882f" category="inline-link-rx"></block>。</block>
  <block id="1093ef7993a1f3824edbf581bb54b571" category="list-text">右上にある [Learn how to Authenticate] をクリックします。</block>
  <block id="622dcb1fafb9f30d36b32341e23ae7a0" category="list-text">ユーザ名とパスワードを入力してログインする必要がある場合は、ポップアップ表示される [Authentication] ウィンドウから通常のアクセスからクライアント ID をコピーします。SSO を使用するフェデレーテッドユーザは、 [ トークンの更新 ] タブからクライアント ID をコピーする必要があります。</block>
  <block id="76525f0f34b48475e5ca33f71d296f3b" category="image-alt">クライアント ID</block>
  <block id="6090065e2462d5f96ebac132568bdf46" category="section-title">AWS からキーペアを取得しています</block>
  <block id="294b903c23e96b98876b04f51502cec4" category="list-text">AWS コンソールで、「キーペア」を検索し、「 PEM 」とのキーペアを作成します。ここでは、 key_pair の名前を覚えておいてください。この名前を使用してコネクタを配置します。</block>
  <block id="ddb20e807acdf5ddf189dd213ff6d0cf" category="image-alt">キーペア</block>
  <block id="3ce1d7d6e1b4509256dd2574b6b5d290" category="section-title">アカウント ID を取得しています</block>
  <block id="8f19980a36fbde35540547e8f630c9e5" category="list-text">Cloud Manager で、 Account – &gt; Manage Accounts の順にクリックし、 AWX の変数で使用するアカウント ID をコピーします。</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">ネットアップのハイブリッドクラウドデータソリューション - Spark と Hadoop はお客様のユースケースに基づいています</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">使用事例 1 - Hadoop データのバックアップ</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">ユースケース 2 - クラウドからオンプレミスへのバックアップとディザスタリカバリ</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">ユースケース 3 - 既存の Hadoop データに対する DevTest の有効化</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">ユースケース 4 - データ保護とマルチクラウド接続</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">ユースケース 5 - 分析ワークロードの高速化</block>
  <block id="12367669ba6a0b6e059b69b5a95f2902" category="sidebar">Oracle Database のデータ保護</block>
  <block id="3e9d3644ee18a66c51ddd16b668eaa5a" category="sidebar">Oracle データ保護の自動化</block>
  <block id="82be90bcfc8fd03855e030edaa25583a" category="sidebar">AWX/Tower 向け Oracle データ保護の自動化</block>
  <block id="c515da31cebf8cf63b394c59f3f5f2c0" category="inline-link-macro">次の例： ONTAP AI 導入向けハイパフォーマンスジョブの概要</block>
  <block id="5c11e6d83807487f2c41bd48dc524734" category="paragraph"><block ref="5c11e6d83807487f2c41bd48dc524734" category="inline-link-macro-rx"></block></block>
  <block id="68cba59815f152ec72363e2495bab8d2" category="paragraph"><block ref="68cba59815f152ec72363e2495bab8d2" category="inline-link-macro-rx"></block></block>
  <block id="e76934323b48d5421aa2271f7e9fbee2" category="inline-link-macro">次のセクションでは、 NetApp Trident の導入と構成の概要について説明します</block>
  <block id="4e3ff90ed271e98a6802a9063034ea76" category="paragraph"><block ref="4e3ff90ed271e98a6802a9063034ea76" category="inline-link-macro-rx"></block></block>
  <block id="c64f80d07d5c1623b7b2f34e40d7b46c" category="inline-link-macro">次の例：ノートブック PC とパイプライン</block>
  <block id="c3714374d558db5573b4ecd4261e206e" category="paragraph"><block ref="c3714374d558db5573b4ecd4261e206e" category="inline-link-macro-rx"></block></block>
  <block id="defd49beb1345ee37b446e866e8b3420" category="inline-link-macro">次の例： Kubeflow の操作とタスク</block>
  <block id="2ecf31480279823ef2aed30a0fc061f2" category="paragraph"><block ref="2ecf31480279823ef2aed30a0fc061f2" category="inline-link-macro-rx"></block></block>
  <block id="64b0abe7a29610e134041ed793101fce" category="inline-link-macro">次の例： Trident の処理</block>
  <block id="f6c488122d476f1d213cf78dc2ee84d2" category="paragraph"><block ref="f6c488122d476f1d213cf78dc2ee84d2" category="inline-link-macro-rx"></block></block>
  <block id="f8bc0cf277b3c4424978d08f10f9df70" category="inline-link-macro">次の例： ONTAP AI 導入向けの Kubernetes Stageclasses</block>
  <block id="a58ef634a291d01e3abec43e5619294a" category="paragraph"><block ref="a58ef634a291d01e3abec43e5619294a" category="inline-link-macro-rx"></block></block>
  <block id="52a739b78342bd0cef8801d4c5c193b6" category="inline-link-macro">次の例： Apache Airflow の導入</block>
  <block id="6564dd7688129caf4acb63587998eb65" category="paragraph"><block ref="6564dd7688129caf4acb63587998eb65" category="inline-link-macro-rx"></block></block>
  <block id="b7cd12d2dd9ac8e3414514a02e5df6f4" category="inline-link-macro">次のセクションでは、シングルノードの AI ワークロードを実行します</block>
  <block id="6ee8519e7493385361c9afcfd675c8d0" category="paragraph"><block ref="6ee8519e7493385361c9afcfd675c8d0" category="inline-link-macro-rx"></block></block>
  <block id="080e5221e660ab18a3746fe480956ebc" category="paragraph">コンテナ管理レベルでは、 Kubernetes コンテナ管理が最適な選択肢であり、エンタープライズ環境に適した完全アップストリームバージョン（ Canonical ）または変更バージョン（ Red Hat ）のどちらでも十分にサポートされています。。 <block ref="8ff9014ec7345470e1bb9286d28496e4" category="inline-link-macro-rx"></block> NetApp Trident と新たに追加された Trident を使用しています<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> トレーサビリティ、データ管理機能、インターフェイス、ツールが組み込まれており、データサイエンティストやデータエンジニアはネットアップストレージと統合できます。Kubernetes 向け ML ツールキットである Kubeflow は、 TensorFlow サービスや NVIDIA Triton Inference Server などの複数のプラットフォームで、モデルのバージョン管理と KFServing をサポートするほか、 AI 機能も追加します。もう 1 つの選択肢は NVIDIA EGX プラットフォームです。このプラットフォームは、 GPU 対応 AI 推論コンテナのカタログにアクセスしながら、ワークロード管理を提供します。ただし、これらのオプションを使用するには、本番環境に移行するための多大な労力と専門知識が必要になる場合があります。また、サードパーティの独立系ソフトウェアベンダー（ ISV ）やコンサルタントの支援が必要になる場合もあります。</block>
  <block id="bdbf5a5e65f2cf7435dfcea294400b35" category="inline-link-macro">次に、データサイエンティストや開発者が使用する Jupyter Notebook Workspace をプロビジョニングします</block>
  <block id="86e512bbf34bd396dd043a14ff2027ec" category="paragraph"><block ref="86e512bbf34bd396dd043a14ff2027ec" category="inline-link-macro-rx"></block></block>
  <block id="b569e24403ad128c09e2d0dbd0116463" category="inline-link-macro">次のセクションでは、 Kubeflow の導入の概要を説明します</block>
  <block id="66f5564ed29f37f0b81d2dde741b9c8f" category="paragraph"><block ref="66f5564ed29f37f0b81d2dde741b9c8f" category="inline-link-macro-rx"></block></block>
  <block id="fffa1b56750a0334993c90d5adc9912a" category="doc">TR-4798 ：『 NetApp AI Control Plane 』</block>
  <block id="6dd86945b1681007efc06cd445661f24" category="inline-link-macro">次の手順：概念とコンポーネント</block>
  <block id="742ed784bbf61aca3af793407a42b1f5" category="paragraph"><block ref="742ed784bbf61aca3af793407a42b1f5" category="inline-link-macro-rx"></block></block>
  <block id="4fe6ae61b2ccf0bd553bc2c0f15cf803" category="inline-link-macro">次の例： ONTAP AI 導入向けの Trident バックエンド</block>
  <block id="8de05380035e6d3c48105e0b80ca2e32" category="paragraph"><block ref="8de05380035e6d3c48105e0b80ca2e32" category="inline-link-macro-rx"></block></block>
  <block id="96e1c56a273105095d8b5e23e670f72f" category="inline-link-macro">次の手順：ハードウェアとソフトウェアの要件</block>
  <block id="1c3ce2e5bdbf1449bbeba4ecbd124676" category="paragraph"><block ref="1c3ce2e5bdbf1449bbeba4ecbd124676" category="inline-link-macro-rx"></block></block>
  <block id="7af76512b5f0f470c6a7a6db368a9818" category="inline-link-macro">次のステップ：同期分散 AI ワークロードを実行します</block>
  <block id="e79dd849e38d01ac3faa7090e83320b2" category="paragraph"><block ref="e79dd849e38d01ac3faa7090e83320b2" category="inline-link-macro-rx"></block></block>
  <block id="99c61a2c4480337fdf852f9dbe8a8863" category="inline-link-macro">次の例： Apache Airflow ワークフロー</block>
  <block id="d719776b249ed9e7109b922484d474a2" category="paragraph"><block ref="d719776b249ed9e7109b922484d474a2" category="inline-link-macro-rx"></block></block>
  <block id="26c21566450ecb01d82e6d0e3f7ef1a3" category="inline-link-macro">次： Kubernetes の導入</block>
  <block id="0635bed13bdc0ace58fec0264ac3d119" category="paragraph"><block ref="0635bed13bdc0ace58fec0264ac3d119" category="inline-link-macro-rx"></block></block>
  <block id="256fbc599203bd1bd63bfe25b7a5b9ad" category="inline-link-macro">次のステップ：パフォーマンステスト</block>
  <block id="35bb3345a07dfa439dd6936ea8f69faf" category="paragraph"><block ref="35bb3345a07dfa439dd6936ea8f69faf" category="inline-link-macro-rx"></block></block>
  <block id="68eff5f8d34b801d40ab55f098bc6478" category="inline-link-macro">解決策の使用を開始するには、こちらをクリックしてください</block>
  <block id="e5dec240e8be4a30564a7e8ddc0d568a" category="list-text">準備ができたら、をクリックします <block ref="a171481e1cde5211da297c03090cb7ce" category="inline-link-macro-rx"></block>。</block>
  <block id="4d0c05180ba83e5c8a9bbac094c365e2" category="list-text">自動化は、 Oracle バイナリのセットアップ、データベース、ログ、ログのレプリケーションスケジュール、ログのみのレプリケーションスケジュールの 3 つのフェーズと、 DR サイトでのデータベースリカバリのための 4 つのフェーズで実行されます。</block>
  <block id="675b1e5a01195fa5d419962701704b96" category="cell">Oracle EC2 インスタンスに適切なスワップスペースを設定します。デフォルトでは、一部の EC2 インスタンスは 0 スワップで導入されます</block>
  <block id="68085bee9e04417d4d9e74101a357a22" category="list-text">Type Details に、ソースクラスタと CVO クラスタ、 Cloud Central / Manager 、 AWS Access / Secret Key 、 Cloud Central Refresh Token のユーザ名とパスワードを入力します。</block>
  <block id="861503fb33ea04fecb13449e713e8ac6" category="admonition">Recovering Playbook を実行する前に、次の情報を確認してください。 /etc/oratab および /etc/oraInst.loc を介して、ソース Oracle ホストからデスティネーションホストにコピーしてください</block>
  <block id="72feee9e055adc523c4c9ca3c1453409" category="inline-link-macro">ビデオ： Astra Control を使用した CI / CD パイプラインでのデータ保護</block>
  <block id="3bf54df2b09b6352059075c261817bd0" category="cell"><block ref="3bf54df2b09b6352059075c261817bd0" category="inline-link-macro-rx"></block></block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">このドキュメントでは、 VMware vSphere 向け ONTAP ツールの製品セキュリティについて説明します。</block>
  <block id="289953e1dbd51c07cae2ecf1e6fb88a1" category="doc">WP-7353 ：『 ONTAP tools for VMware vSphere - Product Security 』</block>
  <block id="595319f89334a6a0b8edd4f81172fc71" category="paragraph">Chance Bingen 、 Dan Tulledge 、ネットアップ、 Jenn Schrie 氏</block>
  <block id="7ab9df3e4e38ca227c1b48b0f6740675" category="section-title">安全な開発活動</block>
  <block id="1a79eb278bc02ebdbd2ab32925e316f6" category="paragraph">NetApp ONTAP Tools for VMware vSphere のソフトウェアエンジニアリングでは、次の安全な開発作業を実施します。</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">* 脅威モデリング。 * 脅威モデリングの目的は、ソフトウェア開発ライフサイクルの早い段階で、機能、コンポーネント、または製品のセキュリティ上の欠陥を発見することです。脅威モデルとは、アプリケーションのセキュリティに影響するすべての情報を構造化したものです。本質的に、これはセキュリティの観点から見たアプリケーションとその環境です。</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">* Dynamic Application Security Testing （ DAST ）。 * このテクノロジーは、実行中のアプリケーションで脆弱な状態を検出するように設計されています。DAST は、 Web 対応アプリケーションの公開 HTTP および HTML インターフェイスをテストします。</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">* サードパーティーのコード通貨。 * オープンソース・ソフトウェア（ OSS ）を使用したソフトウェア開発の一環として、製品に組み込まれた OSS に関連するセキュリティ上の脆弱性に対処する必要があります。これは継続的な取り組みです。新しい OSS バージョンには、いつでも新たに検出された脆弱性が報告される可能性があります。</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">* 脆弱性スキャン。 * 脆弱性スキャンは、お客様にリリースされる前にネットアップ製品の一般的なセキュリティの脆弱性と既知のセキュリティの脆弱性を検出するためのものです。</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">* ペネトレーションテスト。 * ペネトレーションテストは、システム、 Web アプリケーション、またはネットワークを評価して、攻撃者によって悪用される可能性のあるセキュリティの脆弱性を検出するプロセスです。ネットアップでのペネトレーションテスト（ペンテスト）は、承認された信頼できる第三者企業のグループが実施します。テスト範囲には、高度な攻撃方法やツールを使用した悪意のある侵入者やハッカーと同様のアプリケーションまたはソフトウェアに対する攻撃の開始が含まれます。</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">製品のセキュリティ機能</block>
  <block id="85d61648687f15050da0b86741b90358" category="paragraph">NetApp ONTAP Tools for VMware vSphere には、各リリースに次のセキュリティ機能が含まれています。</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">* ログインバナー。 * SSH はデフォルトでは無効になっており、 VM コンソールから有効になっている場合は 1 回限りのログインしか許可されません。ユーザがログインプロンプトでユーザ名を入力すると、次のログインバナーが表示されます。</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">* 警告： * このシステムへの不正アクセスは禁止されており、法律で訴追されます。このシステムにアクセスすることで、不正な使用が疑われる場合に、ユーザーのアクションが監視される可能性があることに同意したものとみなされます。</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">ユーザが SSH チャネルを介したログインを完了すると、次のテキストが表示されます。</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">* ロールベースアクセス制御 (RBAC) 。 * ONTAP ツールには、次の 2 種類の RBAC 制御が関連付けられています。</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">vCenter Server 標準の権限</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">vCenter プラグインに固有の権限。詳細については、を参照してください<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>。</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">* 暗号化された通信チャネル。 * すべての外部通信は、バージョン 1.2 の TLS を使用して HTTPS 経由で行われます。</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">* 最小限のポート露出。 * 必要なポートのみがファイアウォールで開かれています。</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">次の表に、オープンポートの詳細を示します。</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">TCP v4 / V6 ポート番号</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">機能</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">REST API 用の HTTPS 接続</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">HTTPS 接続</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">HTTPS 接続で SOAP over https 接続に使用される HTTPS 接続このポートを開いて、クライアントが ONTAP ツール API サーバに接続できるようにする必要があります。</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH （デフォルトでは無効）</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">HTTPS 接続 - VP および SRA - ループバックからの内部接続のみ</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083 年</block>
  <block id="25a695aa0122683aad4828e2458bbba6" category="cell">HTTPS 接続 - VP および SRA</block>
  <block id="4b8384754c8b30050bb36e840394189b" category="cell">SOAP over https 接続に使用されます</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">VP SNMP トラップパケット</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Derby データベースポート。このコンピュータとそれ自体の間のみ、外部接続は許可されません -- 内部接続のみ</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">こちらの技術情報アーティクル</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">* 認証局（ CA ）署名証明書のサポート。 * VMware vSphere 用の ONTAP ツールは CA 署名証明書をサポートしています。を参照してください<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> を参照してください。</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">* 監査ログ。 * サポートバンドルはダウンロード可能で、非常に詳細です。ONTAP ツールは、すべてのユーザログインおよびログアウトアクティビティを個別のログファイルに記録します。VASA API 呼び出しは、専用の VASA 監査ログ（ローカルの cxf.log ）に記録されます。</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">* パスワードポリシー。 * 次のパスワードポリシーが適用されます。</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">パスワードはどのログファイルにも記録されません。</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">パスワードはプレーンテキストで伝達されません。</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">パスワードは、インストールプロセスで設定します。</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">パスワード履歴は設定可能なパラメータです。</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">パスワードの最小有効期間は 24 時間に設定されます。</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">パスワードフィールドの自動入力は無効です。</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">ONTAP ツールは、保存されているすべてのクレデンシャル情報を SHA256 ハッシュで暗号化し</block>
  <block id="62783f5d69cb5d3cb22b077c1d2b8777" category="cell">2021年11月</block>
  <block id="796fae61e057ed3cc6ad68fe313088d7" category="inline-link-macro">ビデオ： Workload Migration Using Astra Control - Red Hat OpenShift with NetApp</block>
  <block id="a38830c0aa781c889eeb5910f47be6ea" category="summary">Astra Control Center を使用して、 CI / CD パイプラインでデータ保護を実現</block>
  <block id="dc0365ad4c92bc3f8973ff5616cd6830" category="doc">Astra Control Center を使用した CI / CD パイプラインでのデータ保護</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">ティアストレージのテストを 3~4 ノードで実施し、生成されるワークロードと利用者のワークロードについては NetApp StorageGRID のセットアップを使用しました。</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">拡張性を備えたパフォーマンステスト</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">ストレージノードの数が増えると、農産物と消費者の処理を完了するまでの時間が直線的に短くなりました。</block>
  <block id="544baf869b5baa766e8839cd33697872" category="paragraph"><block ref="544baf869b5baa766e8839cd33697872" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">s3 読み出し処理のパフォーマンスは、 StorageGRID ノードの数に基づいてリニアに向上します。StorageGRID は、最大 200 個の StorgeGRID ノードをサポートします。</block>
  <block id="2cd319a657a7fccb8f747dab6f102dcc" category="paragraph"><block ref="2cd319a657a7fccb8f747dab6f102dcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">このセクションでは、この解決策で使用されるテクノロジーについて説明します。</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Grid Manager で管理を簡易化</block>
  <block id="a96dbd2aff4998074bc0ca48dc4817d5" category="paragraph"><block ref="a96dbd2aff4998074bc0ca48dc4817d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">イメージ、ビデオ、レコードなどのオブジェクトを収めた、グローバルに分散されたペタバイト規模のリポジトリを管理します。</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">グリッドノードとサービスを監視してオブジェクトの可用性を確保します。</block>
  <block id="52134209a1824af49cd06b67ca3aedc7" category="list-text">Information Lifecycle Management （ ILM ；情報ライフサイクル管理）ルールを使用してオブジェクトデータの配置を継続的に管理します。これらのルールによって、取り込まれたオブジェクトのデータの処理、損失から保護する方法、格納場所と保管期間が決まります。</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">システム内のトランザクション、パフォーマンス、処理を監視します。</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">情報ライフサイクル管理ポリシー</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">ロードバランサとエンドポイントの設定</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">StorageGRID の管理ノードは、 StorageGRID システムを表示、設定、管理するための Grid Manager UI （ユーザインターフェイス）エンドポイントと REST API エンドポイント、およびシステムアクティビティを追跡するための監査ログを提供します。そこで、 Conluent Kafka の階層化ストレージに可用性の高い S3 エンドポイントを提供するために、 StorageGRID ロードバランサを実装しました。このロードバランサは、管理ノードとゲートウェイノードでサービスとして実行されます。また、ロードバランサはローカルトラフィックを管理し、ディザスタリカバリに役立つ GSLB （グローバルサーバロードバランシング）と通信します。</block>
  <block id="ebe4bf9f44a65ad044fdede621409388" category="paragraph">エンドポイントの設定をさらに強化するために、 StorageGRID は管理ノードに組み込まれたトラフィック分類ポリシーを提供し、ワークロードトラフィックを監視し、さまざまな Quality of Service （ QoS ；サービス品質）制限をワークロードに適用できます。トラフィック分類ポリシーは、ゲートウェイノードおよび管理ノードの StorageGRID ロードバランササービス上のエンドポイントに適用されます。これらのポリシーは、トラフィックの制限と監視に役立ちます。</block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="section-title">Apache Kafka です</block>
  <block id="d1675da945892e06b2f84c42c32b7074" category="paragraph"><block ref="d1675da945892e06b2f84c42c32b7074" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka には、 Producer と呼ばれる任意の数のプロセスから生成されるキーと値のメッセージが格納されます。データは、異なるトピック内の異なるパーティションにパーティショニングできます。パーティション内では、メッセージはオフセット（パーティション内のメッセージの位置）によって厳密に順序付けされ、インデックスが作成され、タイムスタンプとともに格納されます。コンシューマと呼ばれる他のプロセスは、パーティションからメッセージを読み取ることができます。Kafka はストリーム処理用の API を提供しており、 Kafka からデータを利用する Java アプリケーションを作成して Kafka に結果を書き込むことができます。Apache Kafka は、 Apache Apex 、 Apache Flink 、 Apache Spark 、 Apache Storm 、 Apache NiFi などの外部ストリーム処理システムとも連携します。</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka は 1 つ以上のサーバで構成されたクラスタ（ブローカー）上で実行され、すべてのトピックのパーティションがクラスタノード全体に分散されます。さらに、パーティションは複数のブローカーにレプリケートされます。Kafka はこのアーキテクチャにより、フォールトトレラントな方法で大量のメッセージストリームを配信でき、 Java Message Service （ JMS ）や Advanced Message Queuing Protocol （ AMQP ）などの従来のメッセージングシステムの一部を置き換えることができます。0.11.0.0 リリース以降、 Kafka はトランザクション書き込みを提供しており、これは Streams API を使用して一度のストリーム処理を提供します。</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka では、 Regular とコンパクションの 2 種類のトピックをサポートしています。通常のトピックでは、保持期限またはスペースバインドを設定できます。指定した保持期限よりも古いレコードがある場合や、パーティションのスペースバインドを超過している場合、 Kafka では古いデータを削除してストレージスペースを解放することができます。デフォルトでは、トピックの保持期間は 7 日間に設定されていますが、データを無期限に保存することもできます。コンパクションの対象となるトピックについては、レコードの有効期限は時刻やスペースの上限に基づいて切れません。Kafka では、以降のメッセージを同じキーを持つ古いメッセージの更新として扱い、キーごとに最新のメッセージを削除しないことを保証しています。ユーザは、特定のキーのヌル値を持つ、いわゆる tombstone メッセージを書き込むことによって、メッセージを完全に削除できます。</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Kafka には 5 つの主要な API があります。</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">* Producer API. * は、アプリケーションがレコードのストリームをパブリッシュすることを許可します。</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*Consumer API. * は、アプリケーションがトピックを購読し、レコードのストリームを処理することを許可します。</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">* Connector API. * は、トピックを既存のアプリケーションにリンクできる再利用可能なプロデューサおよびコンシューマ API を実行します。</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*Streams API. * この API は入力ストリームを出力に変換し、結果を生成します。</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">* 管理者 API 。 Kafka のトピック、ブローカー、その他の Kafka のオブジェクトを管理するのに使用されます。</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">Kafka メッセージングプロトコルをベースに構築されたコンシューマ向け API とプロデューサー用 API は、 Java で Kafka コンシューマクライアントとプロデューサークライアント向けのリファレンス実装を提供します。基本的なメッセージングプロトコルは、開発者が任意のプログラミング言語で独自のコンシューマクライアントまたはプロデューサクライアントを作成するために使用できるバイナリプロトコルです。これにより、 Java Virtual Machine （ JVM ； Java 仮想マシン）エコシステムの Kafka のロックが解除されます。使用可能な Java 以外のクライアントの一覧は、 Apache Kafka wiki で管理されています。</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">流暢な理由</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">履歴データとリアルタイムデータを一元化された単一の情報源に統合することで、 Conluent は、まったく新しいカテゴリの最新のイベント駆動型アプリケーションを簡単に構築し、ユニバーサルデータパイプラインを取得し、拡張性、パフォーマンス、信頼性を備えた強力な新しいユースケースを開放します。</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">流暢なものは何のために使用されるか。</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Conflicent Platform を使用すると、データが異なるシステム間でどのように転送または統合されるかなど、基本的なメカニズムを気にすることなく、データからビジネス価値を引き出す方法に集中できます。具体的には、 Con裕福 なプラットフォームによって、 Kafka へのデータソースの接続やストリーミングアプリケーションの構築、 Kafka インフラの保護、監視、管理が簡易化されます。現在、 Conluent Platform は、金融サービス、オムニチャネル小売、自律走行車など、さまざまな業界のさまざまなユースケースに使用されています。 マイクロサービス、 IoT 。</block>
  <block id="a4eaf48584aaa7df975a9275a8b4ee24" category="paragraph"><block ref="a4eaf48584aaa7df975a9275a8b4ee24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0693822e07a3206c53912f33e3d67758" category="section-title">流暢なイベントストリーミング技術の概要</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">流暢なプラットフォームの中核はです<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block>最も人気の高いオープンソースの分散ストリーミングプラットフォームです。Kafka の主な機能は次のとおりです。</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">レコードのストリームをパブリッシュしてサブスクライブします。</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">レコードのストリームをフォールトトレラントな方法で保存します。</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">レコードのストリームを処理します。</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">Conluent Platform には Schema Registry 、 REST Proxy 、合計 100 以上の Kafka コネクタ、および ksqlDB も含まれています。</block>
  <block id="55be5d4d3f7143137050de9374d03f6f" category="section-title">流暢なプラットフォームのエンタープライズ機能の概要</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">* Conluent Control Center * Kafka を管理および監視するための GUI ベースのシステム。Kafka Connect の管理や、他のシステムとの接続の作成、編集、管理を簡単に行うことができます。</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">* Kubernetes には流暢な言葉があります。 * Kubernetes の流暢な言葉は Kubernetes のオペレータです。Kubernetes の運用担当者は、特定のプラットフォームアプリケーションに固有の機能と要件を提供することで、 Kubernetes のオーケストレーション機能を拡張します。Con裕福 なプラットフォームの場合は、 Kubernetes での Kafka の導入プロセスを大幅に簡易化し、一般的なインフラのライフサイクルタスクを自動化します。</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">* Kafka コネクタは、 Kafka Connect API を使用して、 Kafka をデータベース、キーバリューストア、検索インデックス、ファイルシステムなどの他のシステムに接続します。Confluent Hub には、一般的なデータソースおよびシンク用のダウンロード可能なコネクタがあります。これには、 Conluent Platform でこれらのコネクタの完全なテストとサポートされたバージョンが含まれます。詳細については、を参照してください<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>。</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">* セルフバランシングクラスタ。 * 自動ロードバランシング、障害検出、自己修復機能を提供します。必要に応じてブローカーの追加や運用停止をサポートし、手動での調整は不要です。</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">* クラスタを直接接続し、リンクブリッジを介して 1 つのクラスタから別のクラスタにトピックをミラーリングします。クラスタリンクにより、マルチデータセンター、マルチクラスタ、ハイブリッドクラウドの導入を簡易化できます。</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">* 流暢な自動データバランサ。 * ブローカーの数、パーティションのサイズ、パーティションの数、およびクラスタ内のリーダーの数について、クラスタを監視します。これにより、データを移動してクラスタ全体で均等なワークロードを作成しながら、トラフィックのリバランシングを調整して、リバランシング中の本番ワークロードへの影響を最小限に抑えることができます。</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">* 流暢なリプリケータ * により、複数のデータセンターで複数の Kafka クラスターを容易に保守できます。</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">* 階層化ストレージ。 * 任意のクラウドプロバイダを使用して大量の Kafka データを保存するオプションを提供し、運用上の負担とコストを削減します。階層型ストレージでは、コスト効率に優れたオブジェクトストレージにデータを格納し、ブローカーを拡張するために、必要なコンピューティングリソースが増えた場合のみデータを利用できます。</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">* Conluent JMS Client. * Conluent Platform には Kafka 用の JMS 対応クライアントが含まれています。Kafka クライアントは、 Kafka ブローカーをバックエンドとして使用して、 JMS 1.1 標準 API を実装しています。これは 'JMS を使用するレガシーアプリケーションがあり ' 既存の JMS メッセージブローカを Kafka に置き換える場合に便利です</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">* Coneluent MQTT プロキシ * を使用すると、 MQTT デバイスやゲートウェイから Kafka に直接データを公開できます。 MQTT ブローカーは必要ありません。</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">* 流暢なセキュリティプラグイン。 * 流暢なセキュリティプラグインは、各種の流暢なプラットフォームツールや製品にセキュリティ機能を追加するために使用されます。現在、 Conluent REST プロキシ用のプラグインが用意されており、受信要求の認証に役立ち、認証されたプリンシパルを要求に Kafka に伝播できます。これにより、 Con裕福 な REST プロキシクライアントでは、 Kafka ブローカーのマルチテナントセキュリティ機能を利用できます。</block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">このドキュメントでは、ネットアップのストレージコントローラで Kafka を使用する場合のベストプラクティスのガイドラインを説明しています。</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="doc">TR-4912 ：『 Best Practices guidelines for ConFluent Kafka Tiered Storage with NetApp 』</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">また、 NetApp StorageGRID の階層型ストレージとして Kafka を使用して、 ConFluent Platform の認定を受けています。</block>
  <block id="0a569fd987814c0464300156b2e26414" category="paragraph"><block ref="0a569fd987814c0464300156b2e26414" category="inline-link-macro-rx"></block></block>
  <block id="82dc8b1c8f1a6f08261f17b764e74bf4" category="paragraph"><block ref="82dc8b1c8f1a6f08261f17b764e74bf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">競合する階層型ストレージ構成</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">階層化ストレージの構成には、 Kafka に次のパラメータが必要です。</block>
  <block id="1ba0fc45020f864c62328d58df2351ef" category="paragraph"><block ref="1ba0fc45020f864c62328d58df2351ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">オブジェクトストアの正確性テスト</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">階層化機能の正確性テスト</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">ティアフェッチベンチマーク</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">このテストでは、階層型オブジェクトストレージの読み取りパフォーマンスを検証し、ベンチマークによって生成されたセグメントからの負荷が大きい範囲での読み取り要求のフェッチをチェックしました。このベンチマークでは、 Conluent 社は階層フェッチ要求に対応するカスタムクライアントを開発しました。</block>
  <block id="b2ce010f52b23eb40ba6b51b92837acb" category="inline-link-macro">次のステップ：拡張性を備えたパフォーマンステスト</block>
  <block id="4a94c930da0f9f0974ad6d4f2d17726b" category="paragraph"><block ref="4a94c930da0f9f0974ad6d4f2d17726b" category="inline-link-macro-rx"></block></block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">本ドキュメントでは、 ConFluent Kafka の認定テスト、パフォーマンスの結果、チューニング、 Kafka コネクタ、自己リバランシング機能など、ネットアップのストレージで Kafka を使用する場合のベストプラクティスを紹介します。</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">Apache Kafka とは何ですか</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">S3 シンクパラメータの詳細</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">このテストは自己バランシングクラスタ機能に基づいており、クラスタトポロジの変更や負荷の不均一に基づいてリバランシングを自動で実行します。</block>
  <block id="6dec1258fbcccbfaa7098758abb00055" category="inline-link-macro">これまでの Kafka s3 コネクタを使用しました。</block>
  <block id="6e3bea5fe8473b6e884edafaf7fcf1d4" category="paragraph"><block ref="6e3bea5fe8473b6e884edafaf7fcf1d4" category="inline-link-macro-rx"></block></block>
  <block id="cc87abc70119e2ad833c42a865a33659" category="inline-link-macro">次のステップ：ベストプラクティスのガイドライン</block>
  <block id="caf8da5a9482899a1495e1e052a4b287" category="paragraph"><block ref="caf8da5a9482899a1495e1e052a4b287" category="inline-link-macro-rx"></block></block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">このセクションでは、この認定資格から得られた教訓について説明します。</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">ベストプラクティスのガイドライン</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">オブジェクトストレージは、セグメントの方がパフォーマンスに優れています。バイト数が多い場合は 512 MB をテストしました。</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">Kafka では、トピックに対して生成される各レコードのキーまたは値の長さ（バイト単位）は、「 length.key.value 」パラメータによって制御されます。StorageGRID では、 S3 オブジェクトの取り込みと読み出しのパフォーマンスがより高い値に引き上げられました。たとえば、 512 バイトが 5.8GBps の読み出しを提供し、 1024 バイトが 7.5GBps の s3 読み出しを提供し、 2048 バイトが 10Gbps 近く提供します。</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">次の図に、「 length.key.value 」に基づいた S3 オブジェクトの取り込みと読み出しを示します。</block>
  <block id="b50ee24368ac624f2816b9e550167cb9" category="paragraph"><block ref="b50ee24368ac624f2816b9e550167cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4127d3e6d7b548701a1cf83ef1d7a922" category="paragraph"><block ref="4127d3e6d7b548701a1cf83ef1d7a922" category="inline-link-macro-rx"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">このセクションでは、流暢な認定に使用されるハードウェアおよびソフトウェアについて説明します。この情報は、ネットアップストレージで Kafka を導入する場合に該当します。</block>
  <block id="40328f8a932f8ae1964c73c1f2eca76b" category="paragraph"><block ref="40328f8a932f8ae1964c73c1f2eca76b" category="inline-link-macro-rx"></block></block>
  <block id="f4e981d58b1468737da82402b3cce7f1" category="paragraph"><block ref="f4e981d58b1468737da82402b3cce7f1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="section-title">解決策アーキテクチャの詳細</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Kafka バージョン 6.2 と競合します</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">ご主人の 3 人</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">5 台のブローカーサーバ</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">Grafana × 1</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">1 つのコントロールセンター</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux （ Ubuntu 18.04 ）</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">すべてのサーバ</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">SG1000 × 1 （ロードバランサ）</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">24 本、 800 本の SSD × 4</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">S3 プロトコル</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">Fujitsu Primergy RX2540 サーバ × 15</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">各モデルには、 CPU × 2 、物理コア × 16 、 Intel Xeon × 256GB 物理メモリ × 100GbE デュアルポートが搭載されています</block>
  <block id="c88aa001e26103d0ebe4894b3c9ab9f5" category="paragraph"><block ref="c88aa001e26103d0ebe4894b3c9ab9f5" category="inline-link-macro-rx"></block></block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">このセットアップでは、 Kafka s3 sink Connector を使用して、 Kafka のオブジェクトストレージのトピックの読み取りと書き込みを直接実行する方法を紹介します。このテストでは、スタンドアロンの流暢なクラスタを使用しましたが、このセットアップは分散クラスタに適用できます。</block>
  <block id="9b154eb37aabb62c75c78bd31457468f" category="inline-link-macro">Previous ：拡張性を備えたパフォーマンステスト。</block>
  <block id="aa4f22f43748e77c4fb71f8cb5333c25" category="paragraph"><block ref="aa4f22f43748e77c4fb71f8cb5333c25" category="inline-link-macro-rx"></block></block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Conluent Kafka の Web サイトからダウンロードできます。</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">パッケージをサーバー上のフォルダに展開します。</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">2 つの変数をエクスポートします。</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">スタンドアロンの ConFluent Kafka セットアップの場合、クラスタは「 /tmp 」に一時的なルートフォルダを作成します。Zookeeper 、 Kafka 、スキーマレジストリ、 connect 、 ksql-server 、 とコントロールセンターのフォルダを作成し、それぞれの構成ファイルを「 $confliclus_home 」からコピーします。次の例を参照してください。</block>
  <block id="fc1644d2d2819b87443b810d963409fa" category="list-text">Zookeeper を構成します。デフォルトのパラメータを使用する場合は、何も変更する必要はありません。</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">上記の設定では、サーバを更新しました。xxx ’プロパティ。デフォルトでは、 Kafka リーダーの選択に 3 名の Zookeepers が必要です。</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">myid ファイルを tmp/conflicluent .406980/zookeeper /data に一意の ID で作成しました。</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">myid ファイルの最後の数の IP アドレスを使用しました。Kafka 、 connect 、 control-ccenter、 Kafka 、 Kafkakarest 、 ksql-server 、およびスキーマレジストリ設定。</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Kafka サービスを開始します。</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">構成ごとにログフォルダがあり、問題のトラブルシューティングに役立ちます。場合によっては、サービスの開始に時間がかかることがあります。すべてのサービスが稼働中であることを確認します。</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">「 confliclue-hub 」を使用して Kafka connect をインストールします。</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">また、「 conflicluent -hub install conflicentinc / Kafka-connect-s3 ： 10.0.3` を使用して、特定のバージョンをインストールすることもできます。</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">デフォルトでは、「 confluentinc - Kafka-connect-s3 」は「 /data/luent confin/conflicluent - 6.2.0/conflicluent -huber-components/conflicentinc - Kafka-connect-s3 」にインストールされています。</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">新しい「 confluentinc - Kafka -connect-s3` でプラグインパスを更新します。</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">流暢なサービスを停止し、再起動します。</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">アクセス ID とシークレットキーを「 /root/.AWS/credentials 」ファイルに設定します。</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">バケットに到達できることを確認します。</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">s3 およびバケット設定用の s3-sink プロパティファイルを設定します。</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">s3 バケットに数件のレコードをインポートします。</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">S3 シンクコネクタを取り付けます。</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">s3-sink のステータスを確認します。</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">ログをチェックして、 s3-sink のトピックを受け入れる準備ができていることを確認します。</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Kafka のトピックを確認してください。</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">s3 バケット内のオブジェクトを確認します。</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">内容を確認するには、次のコマンドを実行して、 S3 からローカルファイルシステムに各ファイルをコピーします。</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Apache アーカイブ</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">レコードを印刷するには、 avro-tools-1.11.0.1.jar を使用します（『』で入手できます）<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block>）。</block>
  <block id="9f4b95975f14f6481a322f453e05049c" category="sidebar">VMware vSphere 向け ONTAP ツール - 製品セキュリティ</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">ConFluent Kafka のベストプラクティスをご確認ください</block>
  <block id="a712a0e553d0302aa27009e1ebc815ce" category="summary">エンタープライズハイブリッドクラウドソリューションに関する一連のビデオとデモ</block>
  <block id="a867425c6a29a742f3dc77c80f5adac8" category="doc">エンタープライズハイブリッドクラウドのビデオとデモ</block>
  <block id="02ca4b8a1f54adf2c0d931bc5bdb61f3" category="paragraph">以下のビデオとデモでは、主要な 3 つのクラウドプロバイダすべてのエンタープライズハイブリッドクラウドソリューションの特定の機能を紹介します。</block>
  <block id="04999f88dfbb06dc4f6a71901a7e9b18" category="paragraph">&lt; リード &gt;</block>
  <block id="2a172299398c31c1e2cd726175d3a270" category="paragraph">&lt;content&gt; の順にクリックします</block>
  <block id="0c138556fe4f10d4cdba4c61933afd91" category="doc">Google Cloud Virtualization Engine （ GCVE ）向けネットアップソリューション</block>
  <block id="dc740fd7aabd59b53cda21fc57a7c10c" category="paragraph">ワークフローの移行、クラウドへの拡張 / バースト、バックアップ / リストア、ディザスタリカバリなど、ネットアップが Google Cloud に提供するソリューションの詳細をご確認ください。</block>
  <block id="1d71c2a7928e8ff703779db43b80044f" category="section-title">GCVE のソリューション</block>
  <block id="ba32bd76ecebfdb42efa20b6de24b808" category="paragraph">&lt; 該当する項を参照してください &gt;</block>
  <block id="4177c39712dda5976b0ba657b24af234" category="doc">Cloud Volumes ONTAP を Google Cloud に導入（自分で導入）</block>
  <block id="2839d8571363b149cc3fd9db82a7183d" category="paragraph">Cloud Volumes ONTAP 共有と LUN は、 GCVE プライベートクラウド環境で作成された VM からマウントできます。Cloud Volumes ONTAP は iSCSI 、 SMB 、 NFS の各プロトコルをサポートしているため、 iSCSI 経由でマウントしたボリュームを Linux クライアントや Windows クライアントにマウントし、 LUN に Linux クライアントや Windows クライアントからブロックデバイスとしてアクセスすることもできます。Cloud Volumes ONTAP ボリュームは、いくつかの簡単な手順で設定できます。</block>
  <block id="3b020916a45973167bc70cb4517bd8c8" category="inline-link-macro">システム間のデータレプリケーションの設定</block>
  <block id="83f1904115d07e05de148ff5c69277db" category="paragraph">ディザスタリカバリや移行の目的でオンプレミス環境からクラウドにボリュームをレプリケートするには、サイト間 VPN または Cloud Interconnect を使用して Google Cloud へのネットワーク接続を確立します。オンプレミスから Cloud Volumes ONTAP へのデータのレプリケートについては、本ドキュメントでは扱いません。オンプレミスシステムと Cloud Volumes ONTAP システム間でデータをレプリケートする方法については、を参照してください <block ref="17b5522e2d467cfa8e1eed2f77bb1eff" category="inline-link-macro-rx"></block>。</block>
  <block id="9eb931a836eecf8e743b47b449c70bc5" category="inline-link-macro">Cloud Volumes ONTAP サイジングツール</block>
  <block id="165fc07e6910d8748be18ecaaab5392d" category="admonition">使用 <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Cloud Volumes ONTAP インスタンスのサイズを正確に設定します。また、オンプレミスのパフォーマンスを監視し、 Cloud Volumes ONTAP のサイジングツールの情報として使用できます。</block>
  <block id="a1d02afc571062ee1235156b645846f8" category="list-text">NetApp Cloud Central にログイン— Fabric View （ファブリックビュー）画面が表示されます。Cloud Volumes ONTAP タブを探し、 Go to Cloud Manager を選択します。ログインすると、キャンバス画面が表示されます。</block>
  <block id="52111b7d24cc23248fa9cf8138732943" category="paragraph"><block ref="52111b7d24cc23248fa9cf8138732943" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67b4a468763f61993484edb54b0d5eaa" category="list-text">Cloud Manager Canvas タブで、 Add a Working Environment をクリックし、クラウドとして Google Cloud Platform を選択し、システム構成のタイプを選択します。次に、 [ 次へ ] をクリックします。</block>
  <block id="da94c5003e26421e5282adb2dc7794bf" category="paragraph"><block ref="da94c5003e26421e5282adb2dc7794bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="956a76d4c71f02e39d36ada071ba66ca" category="list-text">環境名と admin クレデンシャルなど、作成する環境の詳細を指定します。完了したら、 [ 続行 ] をクリックします。</block>
  <block id="786bd072b9aad97a5bb9b71b8988a176" category="paragraph"><block ref="786bd072b9aad97a5bb9b71b8988a176" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f716cee2acaef077786ecfa7a3f8bfe7" category="list-text">データセンスとコンプライアンス、クラウドへのバックアップなど、 Cloud Volumes ONTAP 導入用のアドオンサービスを選択または選択解除します。次に、 [ 続行 ] をクリックします。</block>
  <block id="03e0c2afea8f7c3aff4a53d66784f843" category="paragraph">ヒント：アドオンサービスを無効にすると、確認のポップアップメッセージが表示されます。CVO の導入後にアドオンサービスを追加 / 削除できます。コストを回避するために、不要なサービスは最初から選択解除することを検討してください。</block>
  <block id="d784fbb10e1bdb60322e86126fe6b77a" category="paragraph"><block ref="d784fbb10e1bdb60322e86126fe6b77a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faa5bffdcdb67efcb08e91a60de40950" category="list-text">場所を選択し、ファイアウォールポリシーを選択し、チェックボックスを選択して Google Cloud ストレージへのネットワーク接続を確認します。</block>
  <block id="5eb45a43e8f46d401f435ef2b77fc946" category="paragraph"><block ref="5eb45a43e8f46d401f435ef2b77fc946" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f73472fc9b5e80548aa8910eb7b409d7" category="list-text">ライセンスオプションとして、「従量課金制」または「 BYOL for using existing license 」を選択します。この例では、 Freemium オプションが使用されています。次に、 [ 続行 ] をクリックします。</block>
  <block id="ef8c5ea172d5c008d091f693a2a4b4bd" category="paragraph"><block ref="ef8c5ea172d5c008d091f693a2a4b4bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e3f0304199574fcad7150c8cbc80cf" category="list-text">AWS SDDC 上の VMware クラウドで実行されている VM に導入されるワークロードのタイプに基づいて、複数の事前設定パッケージから選択できます。</block>
  <block id="1cd93d1b6baa56bdec898225ef3fea89" category="paragraph">ヒント：タイルの上にマウスを移動して詳細を表示したり、 [ 構成の変更 ] をクリックして CVO コンポーネントと ONTAP バージョンをカスタマイズしたりできます。</block>
  <block id="7498ab388fb0a7938d43af30f32657b5" category="paragraph"><block ref="7498ab388fb0a7938d43af30f32657b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="623ce055c6e7272198e998744efd8deb" category="list-text">[ 確認と承認 ] ページで、選択内容を確認して確定します。 Cloud Volumes ONTAP インスタンスを作成するには、 [ 移動 ] をクリックします。</block>
  <block id="fcf4e1533222260897c2613078eae18e" category="paragraph"><block ref="fcf4e1533222260897c2613078eae18e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b8217eede1f57c19d7d36c1501891b" category="list-text">Cloud Volumes ONTAP のプロビジョニングが完了すると、 [Canvas] ページの作業環境に表示されます。</block>
  <block id="37030c826a75013cff1396c6351d33c0" category="paragraph"><block ref="37030c826a75013cff1396c6351d33c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="962c53cd54b0b3876e054c2fea4c4ff8" category="section-title">SMB ボリューム用の追加の設定</block>
  <block id="9af22b589cfa398b9a704f786d96a90d" category="list-text">作業環境の準備ができたら、 CIFS サーバに適切な DNS および Active Directory 設定パラメータが設定されていることを確認します。この手順は、 SMB ボリュームを作成する前に実行する必要があります。</block>
  <block id="8f10b252acc74e058dc00a78e8c33250" category="paragraph">ヒント：メニューアイコン（ º ）をクリックし、詳細設定を選択してオプションを表示し、 CIFS のセットアップを選択します。</block>
  <block id="0cd857f422db3bb835695ca4400e7afb" category="paragraph"><block ref="0cd857f422db3bb835695ca4400e7afb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c2efcf3ec5fbe68c5a418d6b0d5ed94" category="list-text">SMB ボリュームの作成は簡単なプロセスです。キャンバスで、 Cloud Volumes ONTAP 作業環境をダブルクリックしてボリュームを作成および管理し、ボリュームの作成オプションをクリックします。適切なサイズを選択し、包含アグリゲートを選択するか、高度な割り当てメカニズムを使用して特定のアグリゲートに配置します。このデモでは、プロトコルとして CIFS/SMB が選択されます。</block>
  <block id="597899b3d186b1c50739aeb0a82a2094" category="paragraph"><block ref="597899b3d186b1c50739aeb0a82a2094" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e1a14aa082ec04534624b099e0a4bd9" category="list-text">ボリュームのプロビジョニングが完了すると、 Volumes （ボリューム）ペインにボリュームが表示されます。CIFS 共有はプロビジョニングされるため、ユーザまたはグループにファイルとフォルダに対する権限を付与し、ユーザが共有にアクセスしてファイルを作成できることを確認してください。ファイル権限とフォルダ権限はすべて SnapMirror レプリケーションの一部として保持されるため、オンプレミス環境からボリュームをレプリケートする場合はこの手順は必要ありません。</block>
  <block id="4cdd5a747f01838b94117ef6fb699278" category="paragraph">ヒント：ボリュームメニュー（ º ）をクリックすると、そのオプションが表示されます。</block>
  <block id="368cd84bdda136cebde14eea38e8a0f2" category="paragraph"><block ref="368cd84bdda136cebde14eea38e8a0f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7a0ccac4888fc1553dadeee03d7e99" category="list-text">ボリュームが作成されたら、 mount コマンドを使用してボリュームの接続手順を表示し、 Google Cloud VMware Engine 上の VM から共有に接続します。</block>
  <block id="92890420fd7a7668e3b04db90e8a2ff2" category="paragraph"><block ref="92890420fd7a7668e3b04db90e8a2ff2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5ee926d870d7b6e5ee68e0001a9db42" category="list-text">次のパスをコピーし、 Map Network Drive オプションを使用して、 Google Cloud VMware Engine で実行されている VM にボリュームをマウントします。</block>
  <block id="809f33612149b405423b98b77a13d18f" category="paragraph"><block ref="809f33612149b405423b98b77a13d18f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0895b43b6a4f7ded9ce501e420da7cae" category="paragraph">マッピングが完了すると、このマッピングに簡単にアクセスでき、 NTFS アクセス権を適切に設定できます。</block>
  <block id="2565b7a7d81a362c6b3fc5f32d83075b" category="paragraph"><block ref="2565b7a7d81a362c6b3fc5f32d83075b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="262a1d892164ab4100a969a952274934" category="section-title">Cloud Volumes ONTAP 上の LUN をホストに接続します</block>
  <block id="049f63d3d6479b8801f942e53b31cfd6" category="paragraph">Cloud Volumes ONTAP LUN をホストに接続するには、次の手順を実行します。</block>
  <block id="2fc81fae057994bbe703cb2892b727c9" category="list-text">キャンバスページで、 Cloud Volumes ONTAP 作業環境をダブルクリックしてボリュームを作成および管理します。</block>
  <block id="3a596dcd3d3dd43ed187aea6bea5842e" category="list-text">Add Volume （ボリュームの追加） &gt; New Volume （新しいボリューム）をクリックし、 iSCSI を選択して Create Initiator Group （イニシエータContinue をクリックします。 .</block>
  <block id="b5f2af2dc909b8d634ef7e8dd729c0bc" category="paragraph"><block ref="99dce170472373a603dcc6cab1306eea" category="inline-image-macro-rx" type="image"></block>
<block ref="99eed8d2ce50ff339d9bff41a9fe9a51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4296bb5afd2416d05f951e9d3380e5e4" category="list-text">ボリュームのプロビジョニングが完了したら、ボリュームメニュー（ º ）を選択し、ターゲット IQN をクリックします。iSCSI Qualified Name （ IQN ）をコピーするには、 Copy （コピー）をクリックします。ホストから LUN への iSCSI 接続をセットアップします。</block>
  <block id="5bbe705670fa05ddb0b508acf301a379" category="paragraph">Google Cloud VMware Engine 上のホストで同じ処理を実行するには、次の手順を実行します。</block>
  <block id="a730e43d2afac8730f77c3fab06bcdc0" category="list-text">Google Cloud VMware Engine でホストされている VM への RDP</block>
  <block id="c4b994ff6c03cf45471392a32ff9809b" category="list-text">［ iSCSI イニシエータのプロパティ ］ ダイアログ・ボックスを開きます ［ サーバーマネージャ ］ ＞ ［ ダッシュボード ］ ＞ ［ ツール ］ ＞ ［ iSCSI イニシエータ ］</block>
  <block id="beacd9a0aebca77f6cc20d5cab0fb37c" category="list-text">Discovery （検出）タブで、 Discover Portal （ポータルの検出）または Add Portal （ポータルの追加）をクリックし、 iSCSI ターゲットポートの IP アドレスを入力します。</block>
  <block id="c4ab0fc2a07f004fb45eacc91a07e22c" category="list-text">ターゲットタブで検出されたターゲットを選択し、ログオンまたは接続をクリックします。</block>
  <block id="4f04cc11e470becd190503a4cea0e217" category="list-text">[ マルチパスを有効にする ] を選択し、コンピュータの起動時に [ この接続を自動的に復元する ] または [ この接続をお気に入りターゲットのリストに追加する ] を選択します。Advanced （詳細設定）をクリック</block>
  <block id="ed010f49a5a1ad0895131daffcd73a3c" category="admonition">Windows ホストには、クラスタ内の各ノードへの iSCSI 接続が必要です。ネイティブ DSM では、使用する最適なパスが選択されます。</block>
  <block id="88c7456aa49f0bfe0258958c4c42a153" category="paragraph"><block ref="88c7456aa49f0bfe0258958c4c42a153" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f2340e83f93b283dd5fc7023e4e72a2" category="paragraph">Storage Virtual Machine （ SVM ）の LUN は、 Windows ホストではディスクとして表示されます。追加した新しいディスクは、ホストでは自動的に検出されません。手動の再スキャンをトリガーしてディスクを検出するには、次の手順を実行します。</block>
  <block id="d16c566049378cf49448803dfc6ab25d" category="list-text">Windows コンピュータの管理ユーティリティを開きます。 [ スタート ]&gt;[ 管理ツール ]&gt;[ コンピュータの管理 ] を選択します。</block>
  <block id="b1babb2780a260f54d7e9f21602773df" category="list-text">ナビゲーションツリーでストレージノードを展開します。</block>
  <block id="678149d88ae91abbb05c5df448a4e8af" category="list-text">[ ディスクの管理 ] をクリックします</block>
  <block id="35e2e6c4175353900be410088efcc1b9" category="list-text">［ アクション ］ &gt; ［ ディスクの再スキャン ］ の順にクリック</block>
  <block id="da663e5eac7f594bcac6564a22726142" category="paragraph"><block ref="da663e5eac7f594bcac6564a22726142" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8a056111a10f9e055d309c54e7ca2bb" category="paragraph">Windows ホストから初めてアクセスした時点では、新しい LUN にはパーティションやファイルシステムは設定されていません。LUN を初期化します。必要に応じて、次の手順を実行してファイルシステムで LUN をフォーマットします。</block>
  <block id="8db13bd6122ee1a2b04931073cb808d7" category="list-text">Windows ディスク管理を開始します。</block>
  <block id="18e601e3f0e159e918f7adb9fd89fb99" category="list-text">LUN を右クリックし、必要なディスクまたはパーティションのタイプを選択します。</block>
  <block id="605158a22ab35f7223fe6f37b0f761b7" category="list-text">ウィザードの指示に従います。この例では、ドライブ F ：がマウントされています。</block>
  <block id="74edf50412d8a6c920ebdf456ca74d6f" category="paragraph"><block ref="74edf50412d8a6c920ebdf456ca74d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8bce76f68494174fa21e44b39be75e7" category="paragraph">Linux クライアントで、 iSCSI デーモンが実行されていることを確認します。LUN のプロビジョニングが完了したら、以下の例として Ubuntu を使用した iSCSI 構成に関する詳細なガイダンスを参照してください。これを確認するには、シェルから lsblk cmd を実行します。</block>
  <block id="5800551032817b82a3780efc5c365b61" category="paragraph"><block ref="5d8610d622621cfaf5f5af9098efada8" category="inline-image-macro-rx" type="image"></block>
<block ref="0e5aea74b7dab4389459e8f03d7961e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b88883556cc41d9ed2a47bd0cfe1bb4" category="section-title">Cloud Volumes ONTAP NFS ボリュームを Linux クライアントにマウント</block>
  <block id="3a676f5d05c6d1f36341948d03289c3f" category="paragraph">Cloud Volumes ONTAP (DIY) ファイルシステムを Google Cloud VMware Engine 内の VM からマウントするには、次の手順に従います。</block>
  <block id="99ff74a348250b7148d219f224bc40b4" category="paragraph">以下の手順に従ってボリュームをプロビジョニングします</block>
  <block id="17d1d28660c0ff68f1ee26c3bc7c2e0d" category="list-text">Volumes （ボリューム）タブで、 Create New Volume （新規ボリュームの作成）をクリックします。</block>
  <block id="6fa266ccf8c1f303a7ed67b355770afb" category="list-text">[Create New Volume] ページで、ボリュームタイプを選択します。</block>
  <block id="8d7c2959a73ccf424e912497fa729dfa" category="paragraph"><block ref="8d7c2959a73ccf424e912497fa729dfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e89e2106ea79d032d48e99a6498e2584" category="list-text">ボリュームタブで、ボリューム上にマウスカーソルを置き、メニューアイコン（ º ）を選択してから、マウントコマンドをクリックします。</block>
  <block id="1367b1db6f5a641c16b673b4f75f02de" category="paragraph"><block ref="1367b1db6f5a641c16b673b4f75f02de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8a4175c7cb7e059193f8bdcafc1395b0" category="list-text">[ コピー ] をクリックします .</block>
  <block id="e059ff9407d5207f003eae103b4c7a3a" category="list-text">指定された Linux インスタンスに接続します。</block>
  <block id="b3bcde31f03d76e154f81e6b5221b007" category="list-text">Secure Shell （ SSH ）を使用してインスタンスの端末を開き、適切なクレデンシャルでログインします。</block>
  <block id="42d35ecc4606c7783372ab3953fb10d6" category="list-text">次のコマンドを使用して、ボリュームのマウントポイント用のディレクトリを作成します。</block>
  <block id="2432c695bbc97e5283e213ba846e86dc" category="paragraph"><block ref="2432c695bbc97e5283e213ba846e86dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5cbcad6705273d58a27b5b92fdc1700" category="list-text">前の手順で作成したディレクトリに Cloud Volumes ONTAP NFS ボリュームをマウントします。</block>
  <block id="f505f299a6f5e1e9f6b91adec6ef8f38" category="paragraph"><block ref="4aa22d1032194bb618fa2b2a8bbc5d82" category="inline-image-macro-rx" type="image"></block>
<block ref="73581b61100d82e506cc05faa5fc45c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f43b203ec7020e7ea0e408d9d67255fc" category="doc">Azure VMware 解決策（ AVS ）を使用した Azure NetApp Files の設定</block>
  <block id="f9a184882060f3e5a8b6045e2a53107f" category="paragraph">解決策共有は、 Azure VMware Azure NetApp Files SDDC 環境で作成された VM からマウントできます。Azure NetApp Files では SMB プロトコルと NFS プロトコルがサポートされているため、ボリュームを Linux クライアントにマウントして Windows クライアントにマッピングすることもできます。Azure NetApp Files ボリュームは、 5 つの簡単な手順で設定できます。</block>
  <block id="5bb6f16c69df9b9f54bddaaa5e32b415" category="paragraph">Azure NetApp Files と Azure VMware 解決策は、同じ Azure リージョンに配置する必要があります。</block>
  <block id="8c8b1c25fd4bcb4102a3a834f721ec3e" category="section-title">Azure NetApp Files ボリュームを作成してマウント</block>
  <block id="763b2af90e10e00124392e31d5792be5" category="paragraph">Azure NetApp Files ボリュームを作成してマウントするには、次の手順を実行します。</block>
  <block id="e56fb44cec3cde26b63f919055458c3a" category="list-text">Azure ポータルにログインし、 Azure NetApp Files にアクセスします。Azure NetApp Files サービスへのアクセスを確認し、 Azure NetApp Files リソースプロバイダを登録するには、 _az プロバイダ登録 -- namespace Microsoft.NetApp – wait_command を使用します。登録が完了したら、ネットアップアカウントを作成します。</block>
  <block id="792c2610bbb56b5803bae91a54f34f51" category="inline-link-macro">Azure NetApp Files 共有</block>
  <block id="a7ad1b2194256789e815facefa65206d" category="paragraph">詳細な手順については、を参照してください <block ref="8dd8f38a60f74263b1cf35e18285061e" category="inline-link-macro-rx"></block>。このページでは、ステップバイステップのプロセスについて説明します。</block>
  <block id="710954ec785b2a7f67c2ef1c3f2f9d19" category="paragraph"><block ref="710954ec785b2a7f67c2ef1c3f2f9d19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe57bd1c78e967b463574e3089a42968" category="list-text">ネットアップアカウントが作成されたら、必要なサービスレベルとサイズの容量プールを設定します。</block>
  <block id="3928a91ce2a9b26c809bec745d6b9daf" category="paragraph">詳細については、を参照してください <block ref="e7281cc99a6c9a39d5a16325a46f1f7c" category="inline-link-macro-rx"></block>。</block>
  <block id="7ffd44a691267afdf7cc1178ab6115f8" category="paragraph"><block ref="7ffd44a691267afdf7cc1178ab6115f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42e9b5ee697da49886fd18e89e6ab1af" category="inline-link-macro">サブネットを Azure NetApp Files に委譲します</block>
  <block id="ee13d45546639cd210b35ce3665b6885" category="list-text">Azure NetApp Files の委任されたサブネットを設定し、ボリュームを作成する際にこのサブネットを指定します。委任されたサブネットを作成する詳細な手順については、を参照してください <block ref="ad52de6b143679c946d36f9e4248f40c" category="inline-link-macro-rx"></block>。</block>
  <block id="70a08a2f18d96817bf63302571e62634" category="paragraph"><block ref="70a08a2f18d96817bf63302571e62634" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96501b128e8ffab4b107cd6ffa7da649" category="list-text">容量プールブレードの下のボリュームブレードを使用して、 SMB ボリュームを追加します。SMB ボリュームを作成する前に、 Active Directory Connector が設定されていることを確認してください。</block>
  <block id="f676bcdffa60a69ff49ba9ffdbb2b912" category="paragraph"><block ref="f676bcdffa60a69ff49ba9ffdbb2b912" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9095b4995e678294045e2a1501d1db3" category="list-text">[Review + Create] をクリックして、 SMB ボリュームを作成します。</block>
  <block id="e48925dc65abf32faa19c5d430cf6d6d" category="paragraph">アプリケーションが SQL Server の場合は、 SMB 継続的可用性を有効にします。</block>
  <block id="be1613efbff068fd23ee511fe4e6dc51" category="paragraph"><block ref="be1613efbff068fd23ee511fe4e6dc51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2b999c81e324f553ec9720c334325ee" category="paragraph"><block ref="b2b999c81e324f553ec9720c334325ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe5eed95829ff2b525461ee72a9f3f23" category="inline-link-macro">Azure NetApp Files のパフォーマンスに関する考慮事項</block>
  <block id="2c5ce17dd48f2551465b828065fd8300" category="paragraph">サイズまたはクォータ別の Azure NetApp Files ボリュームのパフォーマンスの詳細については、を参照してください <block ref="ffec162f488d413e68dfe18d328e177e" category="inline-link-macro-rx"></block>。</block>
  <block id="bef7cec065f33ededdd1b50d74800b72" category="list-text">接続が確立されると、ボリュームをマウントしてアプリケーションデータに使用できるようになります。</block>
  <block id="8b3c17098d0d024937d60849b3bd8edb" category="paragraph">これを行うには、 Azure ポータルで Volumes ブレードをクリックし、マウントするボリュームを選択して、マウント手順にアクセスします。パスをコピーし、ネットワークドライブのマッピングオプションを使用して、 Azure VMware 解決策 SDDC で実行されている VM にボリュームをマウントします。</block>
  <block id="413fcfe1d831f95cd95f8f3bb9030eec" category="paragraph"><block ref="413fcfe1d831f95cd95f8f3bb9030eec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e50c675280580c3249f58f2f3eefdb86" category="paragraph"><block ref="e50c675280580c3249f58f2f3eefdb86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13c8bc9575bbdc3a8a30021320abbd69" category="list-text">Azure VMware 解決策 SDDC で実行されている Linux VM に NFS ボリュームをマウントする場合も、同じ手順を使用します。ボリュームの形状変更機能または動的なサービスレベル機能を使用して、ワークロードの要件を満たします。</block>
  <block id="ff817c6ff423e680ddf0a8398efdfb5a" category="paragraph"><block ref="ff817c6ff423e680ddf0a8398efdfb5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da94ac228f6efdf07fe7e43b1441faf2" category="paragraph">詳細については、を参照してください <block ref="ea07f7f3cbdf3d62072fbe16546616d3" category="inline-link-macro-rx"></block>。</block>
  <block id="29f8b77f5f7c79b566706e0d55c9de8b" category="doc">Amazon VMware マネージドクラウド（ VMC ）向けネットアップソリューション</block>
  <block id="c24b87c4afee5d42310b2dd6144617af" category="paragraph">ワークフローの移行、クラウドへの拡張 / バースト対応、バックアップ / リストア、ディザスタリカバリなど、ネットアップが AWS に提供するソリューションの詳細をご確認ください。</block>
  <block id="7e0686a26bc7a91429819c2aeb7b414a" category="doc">Azure VMware 解決策（ AVS ）向けネットアップソリューション</block>
  <block id="7e868c580794349e459e166e04a5abcd" category="paragraph">ワークフローの移行、クラウドへの拡張 / バースト対応、バックアップ / リストア、ディザスタリカバリなど、ネットアップが Azure に提供するソリューションの詳細をご確認ください。</block>
  <block id="93d6c31a1f56cb2d2f25af1274c4abdd" category="section-title">AVS 向けソリューション</block>
  <block id="4859596b2360db2dac4c6a687efe10d2" category="doc">AWS に新しい Cloud Volumes ONTAP インスタンスを導入（自分で実行）</block>
  <block id="ddf355809a57f794eb4f9cff41a1ad86" category="paragraph">Cloud Volumes ONTAP 共有および LUN は、 AWS SDDC 環境の VMware クラウドで作成された VM からマウントできます。Cloud Volumes ONTAP では iSCSI 、 SMB 、 NFS の各プロトコルがサポートされているため、このボリュームをネイティブの AWS VM Linux Windows クライアントにマウントすることもでき、 iSCSI 経由でマウントする場合は、 Linux クライアントまたは Windows クライアントからブロックデバイスとして LUN にアクセスできます。Cloud Volumes ONTAP ボリュームは、いくつかの簡単な手順で設定できます。</block>
  <block id="091112e3dbffea1fef77b4b6bbcec4d3" category="paragraph">ディザスタリカバリや移行の目的でオンプレミス環境からクラウドにボリュームをレプリケートするには、サイト間 VPN または DirectConnect を使用して、 AWS へのネットワーク接続を確立します。オンプレミスから Cloud Volumes ONTAP へのデータのレプリケートについては、本ドキュメントでは扱いません。オンプレミスシステムと Cloud Volumes ONTAP システム間でデータをレプリケートする方法については、を参照してください <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>。</block>
  <block id="c4fab68ae07564acd6ecd9b911dfff79" category="admonition">を使用します <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Cloud Volumes ONTAP インスタンスのサイズを正確に設定します。また、オンプレミスのパフォーマンスを監視して、 Cloud Volumes ONTAP サイジングツールの入力として使用することもできます。</block>
  <block id="44ca838e7d04a1071dc78602ef005cb3" category="list-text">NetApp Cloud Central にログインします。 Fabric View 画面が表示されます。Cloud Volumes ONTAP タブを探し、 Go to Cloud Manager を選択します。ログインすると、キャンバス画面が表示されます。</block>
  <block id="6b0e3e8cb8d190a2310f526f49f7908f" category="paragraph"><block ref="6b0e3e8cb8d190a2310f526f49f7908f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="613b8a42b8ee051cdae0288a52604a55" category="list-text">Cloud Manager のホームページで、 Add a Working Environment をクリックし、 AWS をクラウドとして選択し、システム構成のタイプを選択します。</block>
  <block id="1ce9ef4a253b6301539d9cab4fca67b6" category="paragraph"><block ref="1ce9ef4a253b6301539d9cab4fca67b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1552a04c8237c4a2d938cca2db53683" category="list-text">環境名と admin クレデンシャルなど、作成する環境の詳細を指定します。Continue をクリックします。 .</block>
  <block id="525c0dbff313821edbeaa46a9b5d88dd" category="paragraph"><block ref="525c0dbff313821edbeaa46a9b5d88dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fdbae44a4deac52e923aa6480a3f1f2" category="list-text">クラウドデータセンス、クラウドバックアップ、 Cloud Insights など、 Cloud Volumes ONTAP 導入用のアドオンサービスを選択します。Continue をクリックします。 .</block>
  <block id="7191330ca38db1397356e7619c4baf63" category="paragraph"><block ref="7191330ca38db1397356e7619c4baf63" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5908a77615c1d6294f872ff6f0e9ec5c" category="list-text">HA Deployment Models ページで、 Multiple Availability Zones 設定を選択します。</block>
  <block id="e2dff93e99a18f3bbf601965a86556d3" category="paragraph"><block ref="e2dff93e99a18f3bbf601965a86556d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5eee77262911549d8a2fd262ee2a983d" category="list-text">Region &amp; VPC ページで、ネットワーク情報を入力し、 Continue をクリックします。</block>
  <block id="94a6592c275cad51dc739b4ab70338db" category="paragraph"><block ref="94a6592c275cad51dc739b4ab70338db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6f20610782706f69940c617f7154ffe" category="list-text">[Connectivity and SSH Authentication] ページで、 HA ペアとメディエータの接続方法を選択します。</block>
  <block id="d121b588f00dfd906d6291024c708f8d" category="paragraph"><block ref="d121b588f00dfd906d6291024c708f8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a012735965bc67df3b6e4c64b7b894f" category="list-text">フローティング IP アドレスを指定し、 Continue （続行）をクリックします。</block>
  <block id="bc0e2f9513cce33557343a1867d4bdfb" category="paragraph"><block ref="bc0e2f9513cce33557343a1867d4bdfb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b2221e159f51173ae2b52e02587cc42" category="list-text">フローティング IP アドレスへのルートを含める適切なルーティングテーブルを選択し、 Continue （続行）をクリックします。</block>
  <block id="5486a792746fe5fbf546c327f6be2773" category="paragraph"><block ref="5486a792746fe5fbf546c327f6be2773" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e18f42f3f9ea4d4f2e8df33f334d9939" category="list-text">Data Encryption ページで、 AWS で管理する暗号化を選択します。</block>
  <block id="143c5081e907e69e16f1df952eafae3e" category="paragraph"><block ref="143c5081e907e69e16f1df952eafae3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a25e3ac90ce2b5cc921531efdc5963e" category="list-text">ライセンスオプションとして、「従量課金制」または「 BYOL for using an existing license 」を選択します。この例では、 ［ 従量課金制 ］ オプションを使用します。</block>
  <block id="e3750564d3942e5c1d3cec322e411d5e" category="paragraph"><block ref="e3750564d3942e5c1d3cec322e411d5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df531dd5efab87543ed07d56595eca08" category="list-text">AWS SDDC 上の VMware クラウドで実行されている VM に導入するワークロードのタイプに基づいて、複数の事前設定パッケージから選択できます。</block>
  <block id="30e80bd4d8d23ac64059627389a8b348" category="paragraph"><block ref="30e80bd4d8d23ac64059627389a8b348" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce4ab7c38fc244e8d1e30dd47a1c578d" category="paragraph"><block ref="ce4ab7c38fc244e8d1e30dd47a1c578d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc498db1b5b048e74d02bcfa90076dfe" category="paragraph"><block ref="bc498db1b5b048e74d02bcfa90076dfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8427c8fe11e3a00ca10a2cf45a96dd90" category="paragraph"><block ref="8427c8fe11e3a00ca10a2cf45a96dd90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31574a22471145d2a1ea069062aa95ec" category="list-text">CVO インスタンスを選択してボリュームを作成し、 Create Volume （ボリュームの作成）オプションをクリックします。適切なサイズを選択し、包含アグリゲートを選択するか、高度な割り当てメカニズムを使用して特定のアグリゲートに配置します。このデモでは、 SMB がプロトコルとして選択されます。</block>
  <block id="d657856abbf9bb39436a3f6f849251ea" category="paragraph"><block ref="d657856abbf9bb39436a3f6f849251ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="976543d01a4b5d38482c487005aadc68" category="list-text">ボリュームのプロビジョニングが完了すると、 Volumes （ボリューム）ペインにボリュームが表示されます。CIFS 共有はプロビジョニングされるため、ユーザまたはグループにファイルおよびフォルダに対する権限を付与し、ユーザが共有にアクセスしてファイルを作成できることを確認する必要があります。</block>
  <block id="eac2d4365044c30420d99e4450f5b3da" category="paragraph"><block ref="eac2d4365044c30420d99e4450f5b3da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ea4081e5d5395a0dd61744757f9abb9" category="list-text">ボリュームが作成されたら、 mount コマンドを使用して、 AWS SDDC ホストの VMware Cloud で実行されている VM から共有に接続します。</block>
  <block id="7786302dcdbb8e27839c1d68acb8c3ba" category="list-text">次のパスをコピーし、 Map Network Drive オプションを使用して、 AWS SDDC の VMware Cloud で実行されている VM にボリュームをマウントします。</block>
  <block id="fff9636198d4c8106d5edeb1a72f789c" category="paragraph"><block ref="97606ae260ebd0d0acdf4aac70a2a0b5" category="inline-image-macro-rx" type="image"></block>
<block ref="b4382417b1dd50929cfd78b7e90bc2aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27c47ada1e7cb796a499ede048474b99" category="section-title">LUN をホストに接続します</block>
  <block id="70ac69b194f074f8b2ce79ee769a0c96" category="paragraph">Cloud Volumes ONTAP LUN をホストに接続するには、次の手順を実行します。</block>
  <block id="4a8c2e183609aa00cfce8401be26e193" category="list-text">Cloud Manager のキャンバスページで、 Cloud Volumes ONTAP 作業環境をダブルクリックしてボリュームを作成および管理します。</block>
  <block id="298c5ecf2fc7c7ab04d3ff27df17c420" category="list-text">Add Volume （ボリュームの追加） &gt; New Volume （新規ボリューム）をクリックし、 iSCSI を選択して Create Initiator Group （イニシエータグループのContinue をクリックします。 .</block>
  <block id="a3f6544e066d08b352bdd873e84efd9f" category="paragraph"><block ref="d08d8d37d464a0090209067a27ccf9bf" category="inline-image-macro-rx" type="image"></block>
<block ref="dd9a8ac9d2dee64126f68f4ab9b10f3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6297ccc26d99397b36875f005bb1b800" category="list-text">ボリュームのプロビジョニングが完了したら、ボリュームを選択し、ターゲット IQN をクリックします。iSCSI Qualified Name （ IQN ）をコピーするには、 Copy （コピー）をクリックします。ホストから LUN への iSCSI 接続をセットアップします。</block>
  <block id="c5a9ec38aba893e2a0d701ba2f45a50e" category="paragraph">AWS SDDC 上の VMware Cloud にあるホストでも同じ処理を実行するには、次の手順を実行します。</block>
  <block id="2cbe60394fdca23a31c3a05a49aba035" category="list-text">AWS の VMware クラウドでホストされる VM への RDP</block>
  <block id="213e827694caf7236290f845284dcc05" category="list-text">ターゲットタブで検出されたターゲットを選択し、ログオンまたは接続をクリックします。</block>
  <block id="04d63507299c2b866ddad09b32b37fb3" category="list-text">[ マルチパスを有効にする ] を選択し、コンピュータの起動時に [ この接続を自動的に復元する ] または [ この接続をお気に入りターゲットのリストに追加する ] を選択します。Advanced （詳細設定）をクリック</block>
  <block id="15c42f0d55e1a75b7606d8cd1d0f0840" category="paragraph">[+]<block ref="f87da6f2c46cbdbedc31faf67374f8f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11f54f9bd2797dc115ca9e98fb0116d" category="paragraph">SVM の LUN は、 Windows ホストではディスクとして表示されます。追加した新しいディスクは、ホストでは自動的に検出されません。手動の再スキャンをトリガーしてディスクを検出するには、次の手順を実行します。</block>
  <block id="733dc90ee8ecde5a3fe64fd837d0eec1" category="paragraph"><block ref="733dc90ee8ecde5a3fe64fd837d0eec1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b173d8aceed1850c1882fee5f7479d4" category="paragraph"><block ref="5b173d8aceed1850c1882fee5f7479d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1085f8441673a34397360c417066d18f" category="paragraph">Linux クライアントで、 iSCSI デーモンが実行されていることを確認します。LUN のプロビジョニングが完了したら、 Linux ディストリビューション向けの iSCSI 構成に関する詳しいガイダンスを参照してください。たとえば、 Ubuntu の iSCSI 構成が見つかります <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>。これを確認するには、シェルから lsblk cmd を実行します。</block>
  <block id="af16b968e0e3b3975cdcefb5cdd9858a" category="paragraph">Cloud Volumes ONTAP （ DIY ）ファイルシステムを VMC 内の VM から AWS SDDC にマウントするには、次の手順を実行します。</block>
  <block id="9e770ba792bd4db694940294a77cccee" category="list-text">前の手順で作成したディレクトリに、 NetApp ONTAP NFS ボリュームの Amazon FSX をマウントします。</block>
  <block id="2b9f5ac2397a7a0e82ca568de7f62512" category="paragraph"><block ref="c1b4b180fa34b46779c12a4e278fa487" category="inline-image-macro-rx" type="image"></block>
<block ref="cf487bf9f5a361811181e443893feb53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6120544c737d67dd31f47d101fe21a84" category="doc">クラウドプロバイダでの仮想化環境の設定</block>
  <block id="f4f7adb7cbe18f2cdd82be75a52b0417" category="paragraph">サポートされている各ハイパースケーラで仮想化環境を設定する方法については、こちらで詳しく説明しています。</block>
  <block id="e647d88b9bd859d2c3e943c24b4fef00" category="paragraph">オンプレミスと同様に、 VM と移行を作成する本番環境に適した VMware Cloud on AWS を計画することが重要です。</block>
  <block id="162e9e1fd4657b8d9588a5ae8c8e6e66" category="paragraph">このセクションでは、 AWS SDDC で VMware Cloud をセットアップおよび管理する方法と、ネットアップストレージの接続に使用できるオプションについて説明します。</block>
  <block id="e6719013bc5803c0da0d4bf78fc8c4a0" category="admonition">FSX ONTAP および Cloud Volumes ONTAP を AWS VMC に接続する方法としてサポートされているのは、ゲスト内ストレージだけです。</block>
  <block id="d6d7fade0a5d1cd7723c64125e595b08" category="paragraph">セットアッププロセスは、次の手順に分けることができます。</block>
  <block id="389544cc8199f2ddd936397695d0dbe9" category="inline-link-macro">VMware Cloud for AWS を導入して設定</block>
  <block id="b4f284d3b5bb40ee91901933b8f7ef5f" category="inline-link-macro">VMware Cloud を FSX ONTAP に接続します</block>
  <block id="00ce356ad004b72efc4b99389b52af63" category="paragraph">オンプレミスと同様に、 Azure VMware 解決策を計画することは、 VM と移行を作成する本番環境に欠かせません。</block>
  <block id="491aa8f554f95207a4b7d47f89777e13" category="paragraph">このセクションでは、 Azure VMware 解決策をセットアップおよび管理する方法と、ネットアップストレージの接続に使用できるオプションについて説明します。</block>
  <block id="cc887bc72eb6e7422bfa13437f902e54" category="admonition">Azure NetApp Files と Cloud Volumes ONTAP を Azure VMware 解決策に接続する方法としてサポートされているのは、ゲスト内ストレージだけです。</block>
  <block id="3d24cd3e433bf1992e011c9f92c3fab6" category="inline-link-macro">リソースプロバイダを登録し、プライベートクラウドを作成</block>
  <block id="a1123889b6465e93a2209c2a0ca667ef" category="inline-link-macro">新しい ExpressRoute 仮想ネットワークゲートウェイまたは既存の ExpressRoute 仮想ネットワークゲートウェイに接続します</block>
  <block id="ae1764c7cb70aed2d4548c424d7bf34a" category="inline-link-macro">ネットワーク接続を検証し、プライベートクラウドにアクセス</block>
  <block id="9883d049f97d69a9f2326d61585d8fbe" category="paragraph">オンプレミスと同様に、 VM と移行を作成する本番環境に成功するには、 Google Cloud VMware Engine （ GCVE ）の計画が不可欠です。</block>
  <block id="6ad49d2b544134f2192d1612a572bdd6" category="paragraph">このセクションでは、 GCVE のセットアップと管理方法、およびネットアップストレージの接続に使用できるオプションとの組み合わせについて説明します。</block>
  <block id="a74a86037d1564ce62843a1252f6ad37" category="admonition">Cloud Volume と Cloud Volumes ONTAP サービスを GCVE に接続する方法としてサポートされているのは、ゲスト内ストレージだけです。</block>
  <block id="11a31c6d83a723b3ea9c348c22e86238" category="inline-link-macro">GCVE を導入および設定します</block>
  <block id="3e5cc29621d2619be0d7b1569da6909c" category="inline-link-macro">GCVE へのプライベートアクセスを有効にします</block>
  <block id="4dab2f9796b0af6304d00e21e2b9dfb4" category="inline-link-macro">AWS 上の VMware Cloud</block>
  <block id="02b412692a538ee9dc2534f0f9c73dc1" category="paragraph"><block ref="560d5b2cd40977bd7b77b31d7088f657" category="inline-link-macro-rx"></block> AWS エコシステム内の VMware ベースのワークロードにクラウドネイティブのエクスペリエンスを提供します。各 VMware Software-Defined Data Center （ SDDC ）は Amazon Virtual Private Cloud （ VPC ）内で動作し、フル VMware スタック（ vCenter Server を含む）、 NSX ベースの Software-Defined Networking 、 VSAN ソフトウェア定義ストレージ、およびワークロードにコンピューティングリソースとストレージリソースを提供する 1 つ以上の ESXi ホストを提供します。</block>
  <block id="dc77b78f59a0c38a9a2e8927dc05e916" category="paragraph">このセクションでは、 AWS で VMware Cloud をセットアップおよび管理する方法について説明します。また、 AWS で NetApp ONTAP を使用する場合は Amazon FSX 、ゲスト内ストレージを使用する場合は Cloud Volumes ONTAP と組み合わせて使用する方法についても説明します。</block>
  <block id="1687622e662f209ef64e3a88de409466" category="admonition">Amazon FSX for NetApp ONTAP および Cloud Volumes ONTAP を AWS 上の VMware Cloud に接続する方法としてサポートされているのは、ゲスト内ストレージだけです。</block>
  <block id="3712f34e1b7039d6d9bfb255ecc54445" category="paragraph">セットアッププロセスは、次の 3 つの部分に分けることができます。</block>
  <block id="f54d8dbbc1cb20fd37a59a4563644ef8" category="inline-link-macro">Amazon Web Services アカウント</block>
  <block id="4ca1486cd3276884e41ad4b36080c10b" category="list-text">に登録します <block ref="ab3390028f6599a1b73b747febbf672d" category="inline-link-macro-rx"></block>。</block>
  <block id="020e995219c3fad42714462fc9368253" category="inline-link-macro">マイ VMware</block>
  <block id="4f87cd22b54abb602d4264ede77c75fd" category="list-text">に登録します <block ref="6fb1d438d7363efa930c55af527a6c23" category="inline-link-macro-rx"></block> アカウント：</block>
  <block id="969c176eb8515e73c2df6805bd09d5de" category="list-text">VMware Cloud で SDDC をプロビジョニングします。</block>
  <block id="28cefea59e6b78bfecc1439107469038" category="section-title">AWS アカウントに登録</block>
  <block id="252c0d3625c410f643362d13f1e35681" category="paragraph">まだ作成していない場合は、 AWS アカウントが必要です。新規または既存の手順では、多くの手順を実行するためにアカウント内で管理者権限が必要です。を参照してください <block ref="d01b332d778720bc2fe2a9a15e6ba01d" category="inline-link-macro-rx"></block> をクリックしてください。</block>
  <block id="ed463b922006aa54f2aceda63f25caed" category="section-title">My VMware アカウントに登録します</block>
  <block id="e1ed167660991d514f55d806a323f3b5" category="paragraph">VMware のクラウドポートフォリオ（ AWS 上の VMware Cloud を含む）にアクセスするには、 VMware の顧客アカウントまたは My VMware アカウントが必要です。VMware アカウントをまだ作成していない場合は作成します <block ref="aefb6f511cceca70505b3e5bf76155fe" category="inline-link-macro-rx"></block>。</block>
  <block id="60fa505f14fb504e941cbc61b74d644a" category="section-title">VMware Cloud で SDDC をプロビジョニングします</block>
  <block id="6d931b72d8efc3fd87b7fdd5127cbba7" category="paragraph">VMware アカウントを設定して適切なサイジングを実行したら、 AWS サービスで VMware Cloud を使用するための次の一歩として Software-Defined Data Center を導入します。SDDC を作成するには、そのホストとして AWS リージョンを選択し、 SDDC に名前を付け、 SDDC に含める ESXi ホストの数を指定します。AWS アカウントがない場合でも、単一の ESXi ホストを含むスターター構成の SDDC を作成できます。</block>
  <block id="7e70ad389301fa9d8936c18cefd85b53" category="list-text">既存または新規に作成した VMware クレデンシャルを使用して、 VMware Cloud Console にログインします。</block>
  <block id="28570a642842f2bfa7db5cc3679fd904" category="paragraph"><block ref="28570a642842f2bfa7db5cc3679fd904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53722f60844c899c63607413f74e8dd8" category="list-text">AWS のリージョン、導入環境、およびホストタイプと SDDC 名を設定します。</block>
  <block id="5ec07ba481e6291d3af5e3ca61f27f57" category="paragraph"><block ref="5ec07ba481e6291d3af5e3ca61f27f57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5c464b97b208b8c43e9fdd315c80793" category="list-text">目的の AWS アカウントに接続し、 AWS クラウド形成スタックを実行します。</block>
  <block id="b6822d593b3a1b683cb4e513b210c080" category="paragraph"><block ref="941b74b5e4d054f44fb05f89bfb30732" category="inline-image-macro-rx" type="image"></block>
<block ref="5ca301c5ba248bc9f9566d74470fcc6b" category="inline-image-macro-rx" type="image"></block>
<block ref="54108005ae53e37fa06b081374d6ea43" category="inline-image-macro-rx" type="image"></block>
<block ref="9f7f4a317cf9d46aa6a2aa8f441279ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59e9afc055ce73e7e6154ea7609eec59" category="admonition">この検証ではシングルホスト構成を使用します。</block>
  <block id="3f68cef60baccc27cfef6b618e56f809" category="list-text">VMC 環境を接続する AWS VPC を選択します。</block>
  <block id="49e131b27a342d4970e86a31a127d41c" category="paragraph"><block ref="49e131b27a342d4970e86a31a127d41c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="102a37b9412553c4ae6b25a174592fbb" category="list-text">VMC 管理サブネットを構成します。このサブネットには、 vCenter や NSX などの VMC 管理サービスが含まれます。SDDC 環境への接続が必要な他のネットワークと重複するアドレス空間を選択しないでください。最後に、以下に示す CIDR サイズの推奨事項に従います。</block>
  <block id="0e8db488f9554136a65dd18025db8cf0" category="paragraph"><block ref="0e8db488f9554136a65dd18025db8cf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a541610269aad8edaf8defd851246b08" category="list-text">SDDC 構成を確認して承認し、 [Deploy the SDDC] をクリックします。</block>
  <block id="a8246981b8dc3e6123523500b3b1371d" category="paragraph"><block ref="a8246981b8dc3e6123523500b3b1371d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bb7bef7f28887197cfca7059ef2d6d3" category="paragraph">導入プロセスの完了には、通常約 2 時間かかります。</block>
  <block id="e9dcc1b6680c77f105c83d040009d685" category="paragraph"><block ref="e9dcc1b6680c77f105c83d040009d685" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79b6ae1d041f5cd8b33d3f351b301275" category="list-text">完了すると、 SDDC を使用できるようになります。</block>
  <block id="9013490d3a116eed1c849197a6c8aac0" category="paragraph"><block ref="9013490d3a116eed1c849197a6c8aac0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e149dd16e33c6137fe08782e96c9b226" category="inline-link-macro">VMC コンソールから SDDC を展開します</block>
  <block id="086760513a416fbc6578703211523314" category="paragraph">SDDC の導入の詳細な手順については、を参照してください <block ref="7279ebe13e8b8c4ee89b8961f2bf1157" category="inline-link-macro-rx"></block>。</block>
  <block id="1d583a1a8ff1ca8ae3360c7e33ecd984" category="doc">Azure に新しい Cloud Volumes ONTAP を導入</block>
  <block id="ed1019c297fadb83e87437230788320c" category="paragraph">解決策共有および LUN は、 Azure VMware Cloud Volumes ONTAP SDDC 環境で作成された VM からマウントできます。Cloud Volumes ONTAP は iSCSI 、 SMB 、 NFS の各プロトコルをサポートしているため、このボリュームは Linux クライアントおよび Windows クライアントにもマウントできます。Cloud Volumes ONTAP ボリュームは、いくつかの簡単な手順で設定できます。</block>
  <block id="e9cac40069a313b824541cda06c18a06" category="paragraph">ディザスタリカバリや移行の目的でオンプレミス環境からクラウドにボリュームをレプリケートするには、サイト間 VPN または ExpressRoute を使用して、 Azure へのネットワーク接続を確立します。オンプレミスから Cloud Volumes ONTAP へのデータのレプリケートについては、本ドキュメントでは扱いません。オンプレミスシステムと Cloud Volumes ONTAP システム間でデータをレプリケートする方法については、を参照してください <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>。</block>
  <block id="1563f27024f7b2b0a96be687f878206d" category="paragraph"><block ref="1563f27024f7b2b0a96be687f878206d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f067fbf4a3196796318f7e878eaa2a3" category="list-text">Cloud Manager のホームページで、 Add a Working Environment をクリックし、クラウドとして Microsoft Azure を選択し、システム構成のタイプを選択します。</block>
  <block id="e59c8066b7736d6ede98e2b57d619b60" category="paragraph"><block ref="e59c8066b7736d6ede98e2b57d619b60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21568dd1e2a5acafeee9d119cd012876" category="list-text">Cloud Volumes ONTAP の最初の作業環境を作成する際、 Cloud Manager はコネクタの導入を求めます。</block>
  <block id="4c3665ca095a8a103c69fac1ac46fb59" category="paragraph"><block ref="4c3665ca095a8a103c69fac1ac46fb59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54ae357a0d5e74ebab86e52641490fc0" category="list-text">コネクタが作成されたら、 [ 詳細（ Details ） ] および [ 資格情報（ Credentials ） ] フィールドを更新します。</block>
  <block id="9b971596a6ee599483fd04c84d2ce18d" category="paragraph"><block ref="9b971596a6ee599483fd04c84d2ce18d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf5341803b0061ef190495343f39fa02" category="list-text">環境名と admin クレデンシャルなど、作成する環境の詳細を指定します。オプションのパラメータとして、 Azure 環境のリソースグループタグを追加します。完了したら、 [ 続行 ] をクリックします。</block>
  <block id="350a5c2219e5e14fd23dda8372344842" category="paragraph"><block ref="350a5c2219e5e14fd23dda8372344842" category="inline-image-macro-rx" type="image"></block></block>
  <block id="360a69a0b184770c2409949f2c7e1140" category="list-text">クラウドデータセンス、クラウドバックアップ、 Cloud Insights など、 Cloud Volumes ONTAP 導入用のアドオンサービスを選択します。サービスを選択し、 Continue （続行）をクリックします。</block>
  <block id="11728d9ffc9e6944adf4891d5543e154" category="paragraph"><block ref="11728d9ffc9e6944adf4891d5543e154" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ee060e03da823e605453fbfa27743d77" category="list-text">Azure の場所と接続を設定します。使用する Azure のリージョン、リソースグループ、 VNet 、およびサブネットを選択します。</block>
  <block id="4549d76a3daf0d322686b6d4f6fb1490" category="paragraph"><block ref="4549d76a3daf0d322686b6d4f6fb1490" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1c88093dde70f0165ade30b74c908ad" category="list-text">ライセンスオプションとして、「従量課金制」または「 BYOL for using existing license 」を選択します。この例では、 ［ 従量課金制 ］ オプションを使用します。</block>
  <block id="10085b1c84507f0da366d741a248d728" category="paragraph"><block ref="10085b1c84507f0da366d741a248d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2c782d387cdd1de07d0119c2794edc8" category="list-text">さまざまなタイプのワークロードに使用できる事前設定されたパッケージをいくつか選択できます。</block>
  <block id="942b902e3715b75e8e6257349bbe93ff" category="paragraph"><block ref="942b902e3715b75e8e6257349bbe93ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c7055bfbaac9b0236d0bedccfb616d0" category="list-text">サポートのアクティブ化と Azure リソースの割り当てに関する 2 つの契約に同意します。 Cloud Volumes ONTAP インスタンスを作成するには、 Go をクリックします。</block>
  <block id="c19dadb8117ac0d88e543accbb1c1096" category="paragraph"><block ref="c19dadb8117ac0d88e543accbb1c1096" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6bb322a7578acfb8670b3ce8bc96fc9" category="paragraph"><block ref="b6bb322a7578acfb8670b3ce8bc96fc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02cbbc24385dbe83fb42a1bd0c5668da" category="paragraph"><block ref="02cbbc24385dbe83fb42a1bd0c5668da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d923f79d8112841c7df8503e86f0af4a" category="list-text">SMB ボリュームの作成は簡単なプロセスです。CVO インスタンスを選択してボリュームを作成し、 Create Volume （ボリュームの作成）オプションをクリックします。適切なサイズを選択し、包含アグリゲートを選択するか、高度な割り当てメカニズムを使用して特定のアグリゲートに配置します。このデモでは、 SMB がプロトコルとして選択されます。</block>
  <block id="a74d409c32c4bc504768c6a7607fc409" category="paragraph"><block ref="a74d409c32c4bc504768c6a7607fc409" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8923d310a6b50c677ed6f68410181b46" category="paragraph"><block ref="8923d310a6b50c677ed6f68410181b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="776a8d832701253eb40b056e68086fcd" category="list-text">ボリュームが作成されたら、 mount コマンドを使用して、 Azure VMware 解決策 SDDC ホストで実行されている VM から共有に接続します。</block>
  <block id="70307f46aa9c37929516c971f3445caa" category="list-text">次のパスをコピーし、ネットワークドライブのマッピングオプションを使用して、 Azure VMware 解決策 SDDC で実行されている VM にボリュームをマウントします。</block>
  <block id="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="paragraph"><block ref="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d1f50043685559ea05d7c21ae5a6d8a" category="paragraph"><block ref="1d1f50043685559ea05d7c21ae5a6d8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e7b38e3108ed39835e616f3a8eef4d9" category="paragraph">LUN をホストに接続するには、次の手順を実行します。</block>
  <block id="06fcf6729491b5106094916e154fb565" category="paragraph"><block ref="06fcf6729491b5106094916e154fb565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7af0094f03c81886be499600b8563647" category="paragraph">Azure VMware 解決策 SDDC にあるホストでも同じ処理を実行するには、次の手順を実行します。</block>
  <block id="640e587a72f6b61dc8d20a6de477db96" category="list-text">Azure VMware 解決策 SDDC にホストされている VM への RDP</block>
  <block id="2d5b864b177738fa7a03f083ae03d2a3" category="paragraph">* 注： * Windows ホストからクラスタ内の各ノードへの iSCSI 接続が確立されている必要があります。ネイティブ DSM では、使用する最適なパスが選択されます。</block>
  <block id="829bd9f13853ee7a86f5805c316df650" category="paragraph"><block ref="829bd9f13853ee7a86f5805c316df650" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d378c726809748df2090ec116c7232b4" category="paragraph"><block ref="d378c726809748df2090ec116c7232b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b3a58a7b9961d5d214b65da735d2f89" category="list-text">ウィザードの指示に従います。この例では、ドライブ E ：がマウントされています</block>
  <block id="586f9ee0f7d5544a894ea05b9df312d7" category="paragraph"><block ref="586f9ee0f7d5544a894ea05b9df312d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ff716a75c3423262418c90aad971f10" category="paragraph"><block ref="6ff716a75c3423262418c90aad971f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e3fe132749fe21d23cf75f00317a6fe" category="doc">AWS で VMware Cloud を使用して、 NetApp ONTAP 用に Amazon FSX を設定します</block>
  <block id="5f19d821dc2e2e3a8e9418909df59733" category="paragraph">Amazon FSX for NetApp ONTAP ファイル共有および LUN は、 AWS の VMware クラウドにある VMware SDDC 環境内で作成された VM からマウントできます。また、このボリュームは、 Linux クライアントにマウントして NFS または SMB プロトコルを使用して Windows クライアントにマッピングすることもできます。また、 iSCSI 経由でマウントした場合、 Linux クライアントまたは Windows クライアントから LUN にブロックデバイスとしてアクセスできます。NetApp ONTAP ファイルシステム用の Amazon FSX は、次の手順ですばやく設定できます。</block>
  <block id="190b27040d3191ccf35bdb35221f0682" category="admonition">パフォーマンスを向上させ、アベイラビリティゾーン間でのデータ転送料金を回避するには、 NetApp ONTAP 向け Amazon FSX と AWS 上の VMware Cloud を同じアベイラビリティゾーンに配置する必要があります。</block>
  <block id="f8caa19e45e4a42ea7bc10cad5d49ae8" category="section-title">ONTAP ボリューム用に Amazon FSX を作成してマウントします</block>
  <block id="e765d7d83fde51af5391c87cc45dccf2" category="paragraph">NetApp ONTAP ファイルシステム用に Amazon FSX を作成してマウントするには、次の手順を実行します。</block>
  <block id="43935f267f64b4ca1a3f1803272df64b" category="inline-link-macro">Amazon FSX コンソール</block>
  <block id="4d33567207f0232b86c9bec4b4f38d45" category="list-text">を開きます <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block> ファイルシステムの作成を選択して ' ファイルシステム作成ウィザードを開始します</block>
  <block id="df08dda7dc18ddb7de0e9ad5001a9f04" category="list-text">[Select File System Type] ページで、 [Amazon FSX for NetApp ONTAP ] を選択し、 [Next] をクリックします。Create File System ページが表示されます。</block>
  <block id="c40ea60211b89b2179fe7a947527ff66" category="paragraph"><block ref="c40ea60211b89b2179fe7a947527ff66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f29804f0e866cb47ba2fa233a71a54fd" category="list-text">Virtual Private Cloud （ VPC ；仮想プライベートクラウド）のネットワークセクションで、ルーティングテーブルとともに適切な VPC と優先サブネットを選択します。この場合、ドロップダウンから vmcfsx2.vPC が選択されます。</block>
  <block id="628892e49fa967795d4d8d3269c5bb31" category="paragraph"><block ref="628892e49fa967795d4d8d3269c5bb31" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf9c04e1d81f05e344db236ac47ea588" category="list-text">作成方法として、標準作成を選択します。[ クイック作成 ] を選択することもできますが、このドキュメントでは [ 標準作成 ] オプションを使用します。</block>
  <block id="e3c13c0fe612a941f86617c0ad730fca" category="paragraph"><block ref="e3c13c0fe612a941f86617c0ad730fca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e47c53bc440aebf2328e497b46953118" category="paragraph"><block ref="e47c53bc440aebf2328e497b46953118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed02b1594feb57e5c5c1ca0678086dd" category="list-text">「セキュリティと暗号化」セクションの「暗号化キー」で、ファイルシステムの保存データを保護する AWS Key Management Service （ AWS KMS ）暗号化キーを選択します。File System Administrative Password に、 fsxadmin ユーザのセキュアなパスワードを入力します。</block>
  <block id="450514d9ec3a47df8e580605e80579b7" category="paragraph"><block ref="450514d9ec3a47df8e580605e80579b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b969656105cc9174e398fa5754382d5b" category="list-text">仮想マシンで、 vsadmin で REST API または CLI を使用して ONTAP を管理するために使用するパスワードを指定します。パスワードを指定しない場合は、 SVM の管理に fsxadmin ユーザを使用できます。Active Directory セクションで、 SMB 共有をプロビジョニングするために Active Directory を SVM に追加してください。Default Storage Virtual Machine Configuration セクションで、この検証でストレージの名前を指定します。 SMB 共有は自己管理 Active Directory ドメインを使用してプロビジョニングされます。</block>
  <block id="0b0a8d3b6da586b1c3d7ace81f086743" category="paragraph"><block ref="0b0a8d3b6da586b1c3d7ace81f086743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89a8b582feabb26f60740f7b0a57aaef" category="list-text">Default Volume Configuration セクションで、ボリュームの名前とサイズを指定します。これは NFS ボリュームです。Storage Efficiency の場合、 ONTAP の Storage Efficiency 機能（圧縮、重複排除、コンパクション）をオンにするには Enabled を、オフにするには Disabled を選択します。</block>
  <block id="2cfdc5814e94a8d05a802a6b639158b7" category="paragraph"><block ref="2cfdc5814e94a8d05a802a6b639158b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59ed30f46b9afae4f90b77ac3ed74f8e" category="list-text">Create File System ページに表示されるファイルシステム設定を確認します。</block>
  <block id="08ef5aaea85c8112d5d0e368443ee4fe" category="list-text">ファイルシステムの作成をクリックします。</block>
  <block id="d385818e8551a5f93e9591daf3cf7c22" category="paragraph"><block ref="aae4a315cf943820b378b71447a7994a" category="inline-image-macro-rx" type="image"></block>
<block ref="e34db9249abae41534adba1bed16b8d1" category="inline-image-macro-rx" type="image"></block>
<block ref="f1c6728d54b85d98dd49bf5dc91e4f97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f5cc47067a5c4b536ab91f1a843de82" category="inline-link-macro">Amazon FSX for NetApp ONTAP の利用を開始する</block>
  <block id="e37ec80b6a23f377fd957d8c83c7a7b5" category="paragraph">詳細については、を参照してください <block ref="01eec31289b39ab7b89a00515912c371" category="inline-link-macro-rx"></block>。</block>
  <block id="af62c8c40f4b51eaee5cfbcfdb7bffaa" category="paragraph">上記のようにファイルシステムを作成したら、必要なサイズとプロトコルでボリュームを作成します。</block>
  <block id="5eb9e90ab2c5435bcefd918c8c8a7304" category="list-text">を開きます <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block>。</block>
  <block id="4cdc643691b84580850903954cdca1d1" category="list-text">左側のナビゲーションペインで、 [ ファイルシステム ] を選択し、ボリュームを作成する ONTAP ファイルシステムを選択します。</block>
  <block id="05c0eed2abbd9c20871b6af0eb7b1e38" category="list-text">Volumes （ボリューム）タブを選択します。</block>
  <block id="511e546bcb3da3ea3db700200e857ebf" category="list-text">Create Volume （ボリュームの作成）タブを選択します。</block>
  <block id="328a4173ff8b40f0204a78c6a579b01e" category="list-text">Create Volume （ボリュームの作成）ダイアログボックスが表示されます。</block>
  <block id="b1734fefd5bf5fc9e481a277d683ca10" category="paragraph">デモ用として、このセクションで NFS ボリュームを作成します。このボリュームは、 AWS 上の VMware クラウドで実行されている VM に簡単にマウントできます。nfsdemovol01 は次のように作成されます。</block>
  <block id="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="paragraph"><block ref="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72e172d843c1baf9acb881337f0bb2cc" category="section-title">FSX ONTAP ボリュームを Linux クライアントにマウントします</block>
  <block id="682dccf32ec3d6c1e1ca2548a43c4245" category="paragraph">前の手順で作成した FSX ONTAP ボリュームをマウントします。AWS SDDC 上の VMC 内の Linux VM から、次の手順を実行します。</block>
  <block id="a8dc83c93fa2350d1419b44103864f2c" category="list-text">Secure Shell （ SSH ）を使用してインスタンスの端末を開き、適切なクレデンシャルを使用してログインします。</block>
  <block id="454d9d1fe6ad680e393543d5e7b11669" category="list-text">次のコマンドを使用して、ボリュームのマウントポイント用のディレクトリを作成します。</block>
  <block id="6631f82f4a955cf7fe5644adadf79e47" category="paragraph"><block ref="6631f82f4a955cf7fe5644adadf79e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2774f9046ee4873805e1f044fa12fe85" category="list-text">実行したら、 df コマンドを実行してマウントを検証します。</block>
  <block id="d06051412d6da4495ca1a69429ea4fdf" category="paragraph"><block ref="d06051412d6da4495ca1a69429ea4fdf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0927b028b8b35cb7421cd2d29ebac0ab" category="section-title">FSX ONTAP ボリュームを Microsoft Windows クライアントに接続します</block>
  <block id="49a305dd021166bf8a508fb51b3fce24" category="paragraph">Amazon FSX ファイルシステム上のファイル共有を管理およびマッピングするには、共有フォルダ GUI を使用する必要があります。</block>
  <block id="0f51d6ad9d95d24bf6d5b0e18d947382" category="list-text">[ スタート ] メニューを開き、 [ 管理者として実行 ] を使用して fsmgmt.msc を実行します。これにより、共有フォルダ GUI ツールが開きます。</block>
  <block id="0186f9c0fa21b0c8ab82fadf036afe8f" category="list-text">アクション &gt; すべてのタスクをクリックし、別のコンピュータに接続を選択します。</block>
  <block id="f5cf362d19da392bad46d1cb4bbea453" category="list-text">別のコンピュータの場合は、 Storage Virtual Machine （ SVM ）の DNS 名を入力します。たとえば、 FSXSMBTESTING01.FSXTESTING.LOCAL はこの例で使用されています。</block>
  <block id="882da317003fa80717e3939e41c5aa32" category="admonition">TP が Amazon FSX コンソールで SVM の DNS 名を検索し、 Storage Virtual Machines を選択してから、 endpoints までスクロールして SMB DNS 名を検索します。[OK] をクリックします。共有フォルダのリストに Amazon FSX ファイルシステムが表示されます。</block>
  <block id="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="paragraph"><block ref="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd517d0d40877562e2dae460910a5260" category="list-text">共有フォルダツールの左ペインで [ 共有 ] を選択すると、 Amazon FSX ファイルシステムのアクティブな共有が表示されます。</block>
  <block id="e4fb530e581118e4aa66166f33242547" category="paragraph"><block ref="e4fb530e581118e4aa66166f33242547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b994a2e22edf9cb0de792e6a494da514" category="list-text">新しい共有を選択し、共有フォルダの作成ウィザードを完了します。</block>
  <block id="9630a309cdca9ed17b688fe15c03a200" category="paragraph"><block ref="f821d910b54d4df166bfb6c9a0fbeac1" category="inline-image-macro-rx" type="image"></block>
<block ref="1456921fb33e6c835f2ea077607c478a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed3796b20dc1d1a4f1756d0cb0f45489" category="inline-link-macro">SMB 共有の作成</block>
  <block id="dc77f3b6074a456c2be3f16b862db081" category="paragraph">Amazon FSX ファイルシステムでの SMB 共有の作成と管理の詳細については、を参照してください <block ref="a85495f11ff3e696252abf798d30d57d" category="inline-link-macro-rx"></block>。</block>
  <block id="470140537c670eb8edb32bf6e8b2bad5" category="list-text">接続が確立されると、 SMB 共有を接続してアプリケーションデータに使用できるようになります。これを行うには、共有パスをコピーし、 Map Network Drive オプションを使用して、 AWS SDDC 上の VMware Cloud で実行されている VM にボリュームをマウントします。</block>
  <block id="0542af5401c04588abf9b665f31829b6" category="paragraph"><block ref="0542af5401c04588abf9b665f31829b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6c5856c2845517bb6408529fb90b57e" category="section-title">iSCSI を使用して、 NetApp ONTAP LUN の FSX をホストに接続します</block>
  <block id="716fd43b3bc7735b075d056d4ac18dc4" category="paragraph">FSX の iSCSI トラフィックは、前のセクションで説明したルートを介して、 VMware Transit Connect/AWS Transit Gateway を経由します。NetApp ONTAP 用に Amazon FSX 内の LUN を設定するには、該当するマニュアルを参照してください <block ref="70da71f7286decf7407c5db884b5344a" category="inline-link-macro-rx"></block>。</block>
  <block id="32139f76f200f13f9078d49f80c95815" category="paragraph">Linux クライアントでは、 iSCSI デーモンが実行されていることを確認します。LUN のプロビジョニングが完了したら、（例として） Ubuntu を使用した iSCSI 構成に関する詳細なガイダンスを参照してください。 <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>。</block>
  <block id="102b54837bec429c2bc9f3f9fee8a857" category="paragraph">このドキュメントでは、 iSCSI LUN を Windows ホストに接続する方法を示します。</block>
  <block id="29980d065df6792c6cf2015646e8744d" category="section-title">NetApp ONTAP の FSX で LUN をプロビジョニングします。</block>
  <block id="6da38655de350d44c878e17adb0fd12c" category="list-text">ONTAP ファイルシステムの FSX の管理ポートを使用して、 NetApp ONTAP CLI にアクセスします。</block>
  <block id="6f8dec9d607d68b3712504d90548dc7f" category="list-text">サイジング結果から得られるように、必要なサイズの LUN を作成します。</block>
  <block id="c31d63ac510efc7c433e07d70ef0a11a" category="paragraph">この例では、 5g （ 5368709120 ）の LUN を作成しました。</block>
  <block id="e3de6fee1eaf0d0777dc125d42255a4b" category="list-text">必要な igroup を作成して、どのホストが特定の LUN にアクセスできるかを制御します。</block>
  <block id="8c92602adf53776d90c46162f150dd3c" category="paragraph">2 つのエントリが表示されました。</block>
  <block id="e71def0bc16c2989d418764ced77c368" category="list-text">次のコマンドを使用して、 LUN を igroup にマッピングします。</block>
  <block id="fd29357379ec9a1916e7512ba9cba2d5" category="list-text">新しくプロビジョニングした LUN を Windows VM に接続します。</block>
  <block id="15bea41b01d7287439a04eb0c57a5ef5" category="paragraph">AWS SDDC 上の VMware クラウド上にある Windows ホストに新しい LUN の接続を行うには、次の手順を実行します。</block>
  <block id="eabaddae6242a6352bd11a6bdf29b55a" category="list-text">AWS SDDC 上の VMware Cloud でホストされる Windows VM への RDP</block>
  <block id="debd85c1c5da22a2c5e207ae0ad4b91a" category="list-text">サーバーマネージャ &gt; ダッシュボード &gt; ツール &gt; iSCSI イニシエータと進み、 iSCSI イニシエータのプロパティダイアログボックスを開きます。</block>
  <block id="43237019bec64292757878b08a9d1a63" category="list-text">[ マルチパスを有効にする ] を選択し、 [ コンピュータの起動時にこの接続を自動的に復元する ] または [ この接続をお気に入りターゲットのリストに追加する ] を選択します。Advanced （詳細設定）をクリック</block>
  <block id="6aa775ce454f9bfcd13c7e20b90531e7" category="paragraph"><block ref="6aa775ce454f9bfcd13c7e20b90531e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc2a4ed37392086accdd3db98b75509" category="paragraph">Storage Virtual Machine （ SVM ）の LUN は、 Windows ホストではディスクとして表示されます。追加した新しいディスクは、ホストでは自動的に検出されません。手動の再スキャンをトリガーしてディスクを検出するには、次の手順を実行します。</block>
  <block id="3ba2e4c8502f30b8e6d44fc88ebe784a" category="paragraph"><block ref="3ba2e4c8502f30b8e6d44fc88ebe784a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="405bdc4379d9776fbda741356a79c543" category="paragraph">Windows ホストから初めてアクセスした時点では、新しい LUN にはパーティションやファイルシステムは設定されていません。LUN を初期化し、必要に応じて、次の手順を実行してファイルシステムで LUN をフォーマットします。</block>
  <block id="848c01bbaad78639e22ba05626884091" category="paragraph"><block ref="848c01bbaad78639e22ba05626884091" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b2a691ebf81d334bb42112bb635d34d" category="doc">エンタープライズハイブリッドクラウド（ EHC ）でサポートされる構成</block>
  <block id="5e1c36a2c24e0aaf7844ec890c15e430" category="paragraph">主要なハイパースケーラにおけるネットアップストレージサポートの組み合わせを理解している。</block>
  <block id="aa1f7516e656fcf88a02be4feaa432c5" category="cell">* Azure AVS *</block>
  <block id="9acf96fea18557ec8c6d660d6503f3bf" category="cell">* AWS VMC *</block>
  <block id="66fbf46ae142d95c688698893879b8af" category="cell">* GCP GCVE *</block>
  <block id="990372eb325efff403b4117c31a055a8" category="cell">* Cloud Volumes ONTAP （ CVO ） *</block>
  <block id="b7c8d0420d929de49959aae6ce8ba3e4" category="inline-link-macro">ゲストが接続されました</block>
  <block id="33cc6e358d22c6f19d9b7924dc3cdc6d" category="cell">* Cloud Volumes Service (CVS)*</block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="53ece9afd987905da70066422fba9879" category="inline-link-macro">ネイティブデータストア ^1</block>
  <block id="df635045d1bc577d1f8f5b4da11409be" category="cell">* Azure NetApp Files （ ANF ） *</block>
  <block id="23b14f1282da64a4a69cef795c672d69" category="cell">* FSX ONTAP *</block>
  <block id="c567300e15e9f9b873771e56c72c938b" category="admonition">1- 現在プライベートプレビュー中です</block>
  <block id="6a3b9d31df0a58cc23207c2af925ef0f" category="paragraph">Azure VMware 解決策を使用するには、まず、特定されたサブスクリプションにリソースプロバイダを登録します。</block>
  <block id="58c59ab4d5d488609913efa7b1daaa31" category="list-text">Azure ポータルにサインインします。</block>
  <block id="5d704d400396fefbe3427ee665a0ec16" category="list-text">Azure ポータルのメニューで、すべてのサービスを選択します。</block>
  <block id="eff35df9bedc80337261af1399e526a2" category="list-text">[ すべてのサービス ] ダイアログボックスで、サブスクリプションを入力し、 [ サブスクリプション ] を選択します。</block>
  <block id="41825376d695df481d13f37e3e1587db" category="list-text">表示するには、サブスクリプションリストからサブスクリプションを選択します。</block>
  <block id="4d3e5a69b8f8c0bec64cf18db73fff95" category="list-text">[ リソースプロバイダ ] を選択し、検索結果に「 Microsoft.AVS 」と入力します。</block>
  <block id="2bf384915bc11a9360bdf9792dc43bf3" category="list-text">リソースプロバイダが登録されていない場合は、 [ 登録 ] を選択します。</block>
  <block id="0b4b8a7bf2e1e647f3be6dde423b9b79" category="paragraph"><block ref="0b4b8a7bf2e1e647f3be6dde423b9b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb08f4992bb541aec19da4c688d0239" category="paragraph"><block ref="bdb08f4992bb541aec19da4c688d0239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="382da60e8008eed186472cc1a3c3ca37" category="list-text">リソースプロバイダの登録が完了したら、 Azure ポータルを使用して Azure VMware 解決策プライベートクラウドを作成します。</block>
  <block id="397065cbdc87787d17122a18f5c5088d" category="list-text">新規リソースを作成を選択する。</block>
  <block id="39d2b5824a6dce05a74b5a60d5769656" category="list-text">[Search the Marketplace] テキストボックスに Azure VMware 解決策と入力し、検索結果から選択します。</block>
  <block id="d090262ac8690f612cbc8bd5fc83b11c" category="list-text">Azure VMware 解決策ページで、 Create を選択します。</block>
  <block id="4a62c7a4f3f3f4a3927621c33c12bb63" category="list-text">[ 基本設定 ] タブのフィールドに値を入力し、 [ レビュー ] 、 [ 作成 ] の順に選択します。</block>
  <block id="2a01d572b1447155c310cabafac3fae9" category="paragraph">注：</block>
  <block id="7c1ec568c35f8a03d9cfd64b465a4e4f" category="list-text">クイックスタートのために、計画フェーズで必要な情報を収集します。</block>
  <block id="d61ffacba4094067e86b90bcf3739fcf" category="list-text">既存のリソースグループを選択するか、プライベートクラウド用の新しいリソースグループを作成します。リソースグループは、 Azure リソースを導入および管理する論理コンテナです。</block>
  <block id="81d6141ddb9ac3b3888dce83fbf00cf6" category="list-text">CIDR アドレスが一意で、他の Azure Virtual Network やオンプレミスネットワークと重複しないことを確認してください。CIDR はプライベートクラウド管理ネットワークであり、 vCenter Server や NSX Manager などのクラスタ管理サービスに使用されます。ネットアップでは、 /22 アドレススペースを使用することを推奨します。この例では、 10.21.0.0/22 が使用されています。</block>
  <block id="266811324b3ca32d24624ba571c07de8" category="paragraph"><block ref="266811324b3ca32d24624ba571c07de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd710e77504d5568fd5079361107a7eb" category="paragraph">プロビジョニングプロセスには約 4~5 時間かかります。プロセスが完了したら、 Azure ポータルからプライベートクラウドにアクセスして、導入が成功したことを確認します。導入が完了すると、「成功しました」のステータスが表示されます。</block>
  <block id="411f20742da0d4f8cdc568d7aee8fab3" category="paragraph">Azure VMware 解決策プライベートクラウドには Azure Virtual Network が必要です。Azure VMware 解決策はオンプレミスの vCenter をサポートしていないため、既存のオンプレミス環境と統合するには追加の手順が必要です。ExpressRoute 回線および仮想ネットワークゲートウェイのセットアップも行う必要があります。クラスタのプロビジョニングが完了するのを待っている間に、新しい仮想ネットワークを作成するか、既存の仮想ネットワークを使用して Azure VMware 解決策に接続します。</block>
  <block id="aa86eba8b2b706f81a805eb35b834541" category="paragraph"><block ref="aa86eba8b2b706f81a805eb35b834541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7714bc43e9a27f2c98a38e6b6d7f3d8" category="doc">パブリッククラウドプロバイダ向けのネットアップストレージオプション</block>
  <block id="8db50e5729f7a5d770aaceef947a2982" category="paragraph">主要な 3 種類のハイパースケーラにおけるストレージとしてのネットアップのオプションをご確認ください。</block>
  <block id="60ce80493de8468bdfd597af1c219a9f" category="paragraph">AWS は、次の構成でネットアップストレージをサポートします。</block>
  <block id="703133f070dbe0ec953855a2291e151a" category="paragraph">* ゲスト接続ストレージ *</block>
  <block id="94f644afad50386ab13d527e1056ce71" category="paragraph">* ネイティブデータストア *</block>
  <block id="83c87929208a5770dfb09e33514193f4" category="inline-link-macro">ネイティブデータストアとしての FSX ONTAP ^1</block>
  <block id="ad476c4cac730935959743eb28c5ca66" category="list-text"><block ref="ad476c4cac730935959743eb28c5ca66" category="inline-link-macro-rx"></block></block>
  <block id="5f18b04dd7d7089a2177c4c930d8d57f" category="paragraph">Azure は、以下の構成でネットアップストレージをサポートします。</block>
  <block id="98ba63f921be22bb183a43d868521ce1" category="inline-link-macro">ネイティブデータストアとしての Azure NetApp Files （ ANF ） ^1</block>
  <block id="c054a58e4fcd496e4fa5c1b0c16dfa69" category="list-text"><block ref="c054a58e4fcd496e4fa5c1b0c16dfa69" category="inline-link-macro-rx"></block></block>
  <block id="74eb4c6138d4b8cd8399b01966c5af28" category="section-title">GCP のネットアップストレージオプション</block>
  <block id="8f08ff97ca555f50f0d05fdf950a0568" category="paragraph">Google Cloud は、次の構成でネットアップストレージをサポートします。</block>
  <block id="1234d67e696757e4666b0611f60b80d8" category="inline-link-macro">ネイティブデータストアとしての Cloud Volumes Service （ CVS ） ^1</block>
  <block id="a508a86f372584a11bee8d3d41e3afca" category="list-text"><block ref="a508a86f372584a11bee8d3d41e3afca" category="inline-link-macro-rx"></block></block>
  <block id="5c2d9a62bb25b00981f59e22e27bfd17" category="doc">ネットワーク接続を検証し、 Azure VMware 解決策プライベートクラウドにアクセスします</block>
  <block id="40228f700f5965975e4aff8c6c2ff4b3" category="paragraph">Azure VMware 解決策では、オンプレミスの VMware vCenter でプライベートクラウドを管理することはできません。代わりに、ジャンプホストが Azure VMware 解決策 vCenter インスタンスに接続する必要があります。指定したリソースグループにジャンプホストを作成し、 Azure VMware 解決策 vCenter にサインインします。このジャンプホストは、接続用に作成された同じ仮想ネットワーク上の Windows VM であり、 vCenter と NSX Manager の両方にアクセスできる必要があります。</block>
  <block id="d88c36b93ae5dcb2646d56c57f27bf0e" category="paragraph"><block ref="d88c36b93ae5dcb2646d56c57f27bf0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44f5524c6ac4144dbabf7a4d365b837b" category="paragraph">仮想マシンをプロビジョニングしたら、 Connect オプションを使用して RDP にアクセスします。</block>
  <block id="443f53614721177f7c44df93d426a919" category="paragraph"><block ref="443f53614721177f7c44df93d426a919" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36cb4e54805ffde727ffbc809183608e" category="paragraph">新しく作成したジャンプホスト仮想マシンから、クラウド管理者ユーザを使用して vCenter にサインインします。クレデンシャルにアクセスするには、 Azure ポータルにアクセスし、（プライベートクラウド内の管理オプションで） Identity に移動します。プライベートクラウド vCenter と NSX Manager の URL とユーザー資格情報は、ここからコピーできます。</block>
  <block id="9620acd59a8e7ad0f318754391c40c4e" category="paragraph"><block ref="9620acd59a8e7ad0f318754391c40c4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73d88630b730fa00c46338a0aef4c2d3" category="paragraph">Windows 仮想マシンでブラウザを開き、 vCenter Web Client の URL にアクセスします <block ref="2db127a24dc88638a76677b404bda5a4" category="inline-link-rx"></block> admin ユーザのユーザ名に「 * cloudadmin@vsphere.loca l * 」と入力し、コピーしたパスワードを貼り付けます。同様に、 Web クライアントの URL を使用して NSX Manager にアクセスすることもできます <block ref="bb142e18a679100de3817fcefaa25b07" category="inline-link-rx"></block> admin ユーザ名を使用し、コピーしたパスワードを貼り付けて新しいセグメントを作成したり、既存の階層ゲートウェイを変更したりできます。</block>
  <block id="4a6e0ba5b4d42fb0f658bdfdbbea32fc" category="admonition">Web クライアントの URL は、プロビジョニングされる SDDC ごとに異なります。</block>
  <block id="49848931415b32db238a2dd1daddf3a7" category="paragraph"><block ref="49848931415b32db238a2dd1daddf3a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f65f698ac6bac1ada03193e1cdabb8" category="paragraph"><block ref="87f65f698ac6bac1ada03193e1cdabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec3eeb836273dbc92b27ce718a90b212" category="inline-link-macro">オンプレミス環境から Azure VMware 解決策へのピアリング</block>
  <block id="097529edf2feb9ed1237427eaa3b2599" category="paragraph">これで、 Azure VMware 解決策 SDDC の導入と設定が完了しました。ExpressRoute グローバルリーチを活用して、オンプレミス環境を Azure VMware 解決策プライベートクラウドに接続します。詳細については、を参照してください <block ref="29749340a5d7bf5df1867a3f2d2723a1" category="inline-link-macro-rx"></block>。</block>
  <block id="ae6569fd64694b91a054cbdfdfef84d2" category="paragraph">新しい Azure Virtual Network （ VNet ）を作成するには、 Azure VNet Connect （ Azure VNet 接続）タブを選択します。または、 Create Virtual Network ウィザードを使用して、 Azure ポータルから手動で作成することもできます。</block>
  <block id="34b04201ae997eaabb6802b04d5c1708" category="list-text">Azure VMware 解決策プライベートクラウドに移動し、管理オプションで接続にアクセスします。</block>
  <block id="da40ae630b63a930be4e1230efc306e1" category="list-text">Azure VNet Connect を選択します。</block>
  <block id="40292c219898a1253befc6301234575a" category="list-text">新しい VNet を作成するには、 Create New オプションを選択します。</block>
  <block id="f98e10d9ba9ac83ac2adeacde774d051" category="paragraph">この機能により、 VNet を Azure VMware 解決策プライベートクラウドに接続できます。VNet は、 ExpressRoute 経由で Azure VMware 解決策で作成されたプライベートクラウドに必要なコンポーネント（ジャンプボックス、 Azure NetApp Files などの共有サービス、クラウドボリューム ONTAP など）を自動的に作成することで、この仮想ネットワークのワークロード間の通信を有効にします。</block>
  <block id="0314a97a9eb0aae73531717ef45ad195" category="paragraph">* 注： * VNet アドレス空間はプライベートクラウド CIDR と重複しないようにしてください。</block>
  <block id="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="paragraph"><block ref="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="inline-image-macro-rx" type="image"></block></block>
  <block id="206843027dd7ebe90f425f9ee4765a01" category="list-text">新しい VNet の情報を入力または更新し、 OK を選択します。</block>
  <block id="26c6d54522f3fd79684f463116e9634b" category="paragraph"><block ref="26c6d54522f3fd79684f463116e9634b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="027524e66bad6099279342bf8d8f6dd4" category="paragraph">指定したアドレス範囲とゲートウェイサブネットを使用した VNet は、指定したサブスクリプションとリソースグループに作成されます。</block>
  <block id="5ecf2fb7501138eaa14be97a59d2a773" category="inline-link-macro">Azure で VMware プライベートクラウド用のネットワークを設定します</block>
  <block id="5da6ff60860f48de7bb7f4467c28f26f" category="admonition">VNet を手動で作成する場合は、適切な SKU と ExpressRoute をゲートウェイタイプとして使用して仮想ネットワークゲートウェイを作成します。導入が完了したら、認証キーを使用して、 ExpressRoute 接続を、 Azure VMware 解決策プライベートクラウドを含む仮想ネットワークゲートウェイに接続します。詳細については、を参照してください <block ref="4807c1aea8c93bde3104bd4ecfa22a07" category="inline-link-macro-rx"></block>。</block>
  <block id="d77d7a022616e70a9987aa0974241779" category="paragraph">プライベートクラウドのプロビジョニングが完了したら、プライベートクラウドへのプライベートアクセスを設定して、高スループットで低レイテンシのデータパス接続を実現します。</block>
  <block id="256431e41a96deb49bcd86b1ca56393e" category="inline-link-macro">GCP ドキュメント</block>
  <block id="e4cf8d7f33a9dafc85be0439cd8fbc4d" category="paragraph">これにより、 Cloud Volumes ONTAP インスタンスが実行されている VPC ネットワークが、 GCVE プライベートクラウドと通信できるようになります。これを行うには、に従ってください <block ref="9cd64b8fb1b43e7f674c1b78b2a86f74" category="inline-link-macro-rx"></block>。クラウドボリュームサービスの場合は、テナントホストプロジェクト間で 1 回限りのピアリングを実行して、 VMware エンジンと Cloud Volumes Service 間の接続を確立します。詳細な手順については、次の手順を実行してください <block ref="04a9f04edfdd7b0a53da57f015378c5a" category="inline-link-macro-rx"></block>。</block>
  <block id="e6945148d9a888e52db99c5ebce86868" category="paragraph"><block ref="e6945148d9a888e52db99c5ebce86868" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3eb3a1c6330fe124fc0706cbdd91df" category="paragraph">CloudOwner@gve.loca ユーザを使用して vCenter にサインインします。クレデンシャルにアクセスするには、 VMware Engine ポータルにアクセスし、 Resources にアクセスして、適切なプライベートクラウドを選択します。[Basic info] セクションで、 vCenter ログイン情報（ vCenter Server 、 HCX Manager ）または NSX ログイン情報（ NSX Manager ）の [View] リンクをクリックします。</block>
  <block id="6f32389268763bedb9e6716b5f0973d0" category="paragraph"><block ref="6f32389268763bedb9e6716b5f0973d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ec2407381a4f65d228483b566b6907f" category="paragraph">Windows 仮想マシンでブラウザを開き、 vCenter Web Client の URL にアクセスします <block ref="d325f0342d122dda054a3ca8b0c44019" category="inline-link-rx"></block> admin ユーザのユーザ名として CloudOwner@gve.loca を使用し、コピーしたパスワードを貼り付けます。同様に、 Web クライアントの URL を使用して NSX Manager にアクセスすることもできます <block ref="c694eb5be92097a8fdea8cdda0ad5ea5" category="inline-link-rx"></block> admin ユーザ名を使用し、コピーしたパスワードを貼り付けて新しいセグメントを作成したり、既存の階層ゲートウェイを変更したりできます。</block>
  <block id="3a9cff0eb1abb119c1c264dbfff216f6" category="paragraph">オンプレミスネットワークから VMware Engine プライベートクラウドに接続する場合は、クラウド VPN または Cloud Interconnect を利用して適切な接続を行い、必要なポートが開いていることを確認します。詳細な手順については、次の手順を実行してください <block ref="6fe8ac83365e22e24c5c8eb9edc2d548" category="inline-link-macro-rx"></block>。</block>
  <block id="b433f901707e7fd0f6d64371dfca4af9" category="paragraph"><block ref="b433f901707e7fd0f6d64371dfca4af9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="989afab9e0dfcc6d523ddb1d23145834" category="paragraph"><block ref="989afab9e0dfcc6d523ddb1d23145834" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c0dd0de38e3c9e55ef5f52e46641376" category="doc">VMware Engine を使用して Cloud Volumes Service を設定します</block>
  <block id="8e12272d11d90cdb919c737591f398f6" category="paragraph">Cloud Volumes Service 共有は、 VMware エンジン環境で作成された VM からマウントできます。Cloud Volumes Service では SMB プロトコルと NFS プロトコルがサポートされているため、ボリュームを Linux クライアントにマウントして Windows クライアントにマッピングすることもできます。Cloud Volumes Service ボリュームは簡単な手順で設定できます。</block>
  <block id="992031e7435f44536a649bfc9de30683" category="paragraph">Cloud Volume Service と Google Cloud VMware Engine のプライベートクラウドは同じリージョンに配置する必要があります。</block>
  <block id="a0c391dc49c440fc9962168353cedde3" category="inline-link-macro">ガイド</block>
  <block id="e9676faeb0b33249abc3a47d95e55ed8" category="paragraph">Google Cloud Marketplace で NetApp Cloud Volumes Service for Google Cloud を購入、有効化、設定するには、次の手順を実行します <block ref="c9eb1a9870bc9f20357f50bf16ec5704" category="inline-link-macro-rx"></block>。</block>
  <block id="84c877bb77a313d307054a0824ffff03" category="section-title">CVS NFS ボリュームを GCVE プライベートクラウドに作成する</block>
  <block id="1ec5bbc38708de3f8cfad6d6ca608742" category="paragraph">NFS ボリュームを作成してマウントするには、次の手順を実行します。</block>
  <block id="ca5470246976d59ea6a32d3e2094059d" category="list-text">Google クラウドコンソール内のパートナーソリューションから Cloud Volume にアクセスします。</block>
  <block id="45ab48bbbad4380f09ef6b41f9eb8f8a" category="paragraph"><block ref="45ab48bbbad4380f09ef6b41f9eb8f8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46577653160772df2b1548b726d7c9ce" category="list-text">Cloud Volume コンソールで、 Volumes （ボリューム）ページに移動し、 Create （作成）をクリックします。</block>
  <block id="4a43547530a8ef079adc80160de3dde9" category="paragraph"><block ref="4a43547530a8ef079adc80160de3dde9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="825700271a3acfeaf96fa0bfb5f15b65" category="list-text">[Create File System] ページで、チャージバックメカニズムに必要なボリューム名と課金ラベルを指定します。</block>
  <block id="8a81559c79124aa1a1cd2093faed73ee" category="paragraph"><block ref="8a81559c79124aa1a1cd2093faed73ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4bbe773302576667095a132b75c48fc" category="list-text">適切なサービスを選択します。GCVE は、 CVS パフォーマンスと希望するサービスレベルを選択して、アプリケーションワークロードの要件に基づいてレイテンシの向上とパフォーマンスの向上を実現します。</block>
  <block id="184fe9f42c4d5eaab1cc6079778040c2" category="paragraph"><block ref="184fe9f42c4d5eaab1cc6079778040c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492d6cb3c36c984d9f52d9461c5b69b" category="list-text">ボリュームおよびボリュームパスに Google Cloud のリージョンを指定（プロジェクト内のすべての Cloud Volume でボリュームパスが一意である必要があります）</block>
  <block id="594c2b024401023acd7deae8f3cb8ceb" category="paragraph"><block ref="594c2b024401023acd7deae8f3cb8ceb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4b0697a6c38463b0b06d7dc66b16b74" category="list-text">ボリュームのパフォーマンスレベルを選択します。</block>
  <block id="aebc437f9bb3656c19ecebe1becc99fa" category="paragraph"><block ref="aebc437f9bb3656c19ecebe1becc99fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd9c26fe6b5f33ab2b0002050ff831d8" category="list-text">ボリュームのサイズとプロトコルのタイプを指定します。このテストでは、 NFSv3 が使用されています。</block>
  <block id="e5ba61d9c8c666d452e9e78256762019" category="paragraph"><block ref="e5ba61d9c8c666d452e9e78256762019" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3a8099bd03f7da2c641e049e354ea1" category="list-text">この手順では、ボリュームにアクセスできる VPC ネットワークを選択します。VPC ピアリングが実行されていることを確認します。</block>
  <block id="d3dba730ef6d3f046910d94696ca086d" category="paragraph">ヒント： VPC ピアリングが行われていない場合は、ピアリングコマンドの説明を示すポップアップボタンが表示されます。Cloud Shell セッションを開き、適切なコマンドを実行して、 Cloud Volumes Service プロデューサーと VPC をピアリングします。事前に VPC ピアリングを準備する場合は、以下の手順を参照してください。</block>
  <block id="ecf942f7df1f072f5910afb3fa45f36e" category="paragraph"><block ref="ecf942f7df1f072f5910afb3fa45f36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ed1352ea98f362074fa7855ec6bb89c" category="list-text">適切なルールを追加してエクスポートポリシールールを管理し、対応する NFS バージョンのチェックボックスを選択します。</block>
  <block id="3ae650d16c298e2f5dc9e005a2f8934a" category="paragraph">注：エクスポートポリシーを追加しないと、 NFS ボリュームへのアクセスは許可されません。</block>
  <block id="2f6d29a5c21fb51bb181c4b97241a955" category="paragraph"><block ref="2f6d29a5c21fb51bb181c4b97241a955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a194552e035de341a4a7c99a1c687956" category="list-text">[ 保存 ] をクリックしてボリュームを作成します。</block>
  <block id="fe18028768c2ffc16d5cb32aa5b70d5b" category="paragraph"><block ref="fe18028768c2ffc16d5cb32aa5b70d5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3588b0992732355d67655af9f6450c5d" category="section-title">VMware Engine で実行されている VM に NFS エクスポートをマウントする</block>
  <block id="87397baf86d56e19a3bdac712966da5d" category="paragraph">NFS ボリュームのマウントを準備する前に、プライベート接続のピアステータスが Active と表示されていることを確認してください。ステータスが Active になったら、 mount コマンドを使用します。</block>
  <block id="c9f09539bbf502703a4f5e2d480a5972" category="paragraph">NFS ボリュームをマウントするには、次の手順を実行します。</block>
  <block id="726f902a0b5536d71345114fb942d81b" category="list-text">クラウドコンソールで、 Cloud Volume &gt; Volumes に移動します。</block>
  <block id="1feaf778ab1cf141cf92a316d53e1365" category="list-text">Volumes （ボリューム）ページに移動します</block>
  <block id="76d2df71caae5e1ec3f81822829504f5" category="list-text">NFS エクスポートをマウントする NFS ボリュームをクリックします。</block>
  <block id="4fc82f44f951748bf462898e43d08054" category="list-text">右にスクロールし、 [ 詳細を表示 ] の下にある [ 指示のマウント ] をクリックします。</block>
  <block id="692afb2fddb72a6cfc89dd1df12945ab" category="paragraph">VMware VM のゲスト OS 内からマウントプロセスを実行するには、次の手順を実行します。</block>
  <block id="2c7df76595ada01b5b08659283021aa7" category="list-text">SSH クライアントと SSH を使用して仮想マシンに接続します。</block>
  <block id="2b64d099377e2935e786009804205feb" category="list-text">インスタンスに NFS クライアントをインストールします。</block>
  <block id="d8aa2b3304fc65e5fd1cae735194aef6" category="list-text">Red Hat Enterprise Linux または SUSE Linux インスタンスの場合：</block>
  <block id="d610fa6d370a8d35fb4c26359f086aa0" category="list-text">Ubuntu または Debian のインスタンスで次の手順を実行します。</block>
  <block id="9bc2e27c16ca55bfc1a7ba94b91a21dc" category="list-text">「 /nimCVSNFSol01 」などの新しいディレクトリをインスタンスに作成します。</block>
  <block id="9e21b9d85251decc0982b75506826828" category="paragraph"><block ref="9e21b9d85251decc0982b75506826828" category="inline-image-macro-rx" type="image"></block></block>
  <block id="174714918db1cc87ef113e3087cba5da" category="list-text">適切なコマンドを使用してボリュームをマウントします。ラボで使用するコマンドの例を次に示します。</block>
  <block id="1ec7767a139a3f95923511d7bf547a6c" category="paragraph"><block ref="811572ed35d4b134bc0d7769dd80ab6c" category="inline-image-macro-rx" type="image"></block>
<block ref="b780e126200cb608d0de968e965e9c71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3df234dd2e63d779a2d017bb1ef3375d" category="section-title">VMware Engine で実行されている VM に SMB 共有を作成してマウントします</block>
  <block id="400db805dd1f9fc929e5bf72fafb1661" category="paragraph">SMB ボリュームの場合は、 SMB ボリュームを作成する前に、 Active Directory 接続が設定されていることを確認してください。</block>
  <block id="94f9379544859ae4d8990b84731870aa" category="paragraph"><block ref="94f9379544859ae4d8990b84731870aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c62a73033a0e9f64b5b2b311ded0cc5" category="paragraph">AD 接続が確立されたら、必要なサービスレベルを指定してボリュームを作成します。適切なプロトコルを選択する以外に、 NFS ボリュームを作成する手順は同じです。</block>
  <block id="228ba1c797822b63cd7c6f54ca40b87e" category="paragraph"><block ref="228ba1c797822b63cd7c6f54ca40b87e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54cd15dd2d6121aa16f0b4b87b46ef2a" category="list-text">適切なサービスを選択します。GCVE として、 CVS パフォーマンスと希望するサービスレベルを選択し、ワークロード要件に基づいてレイテンシの向上とパフォーマンスの向上を実現します。</block>
  <block id="b8eb8307790a9b22c2f6997c097b344e" category="paragraph"><block ref="b8eb8307790a9b22c2f6997c097b344e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb91d5f8a608e41cd1f217e30a536437" category="paragraph"><block ref="cb91d5f8a608e41cd1f217e30a536437" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e5a0a3c08f102d8c49c1d811b71d97f" category="paragraph"><block ref="7e5a0a3c08f102d8c49c1d811b71d97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d1a06f98a1c133a8a0c74cc4222e23b" category="list-text">ボリュームのサイズとプロトコルのタイプを指定します。このテストでは、 SMB を使用します。</block>
  <block id="6eb5a9152f38c77efc6d14902aa7dec8" category="paragraph"><block ref="6eb5a9152f38c77efc6d14902aa7dec8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">手順</block>
  <block id="15adcf662b8b92c623f4256a65f605ed" category="paragraph">ヒント： VPC ピアリングが行われていない場合は、ピアリングコマンドの説明を示すポップアップボタンが表示されます。Cloud Shell セッションを開き、適切なコマンドを実行して、 Cloud Volumes Service プロデューサーと VPC をピアリングします。事前に VPC ピアリングを準備する場合は、こちらを参照してください <block ref="3b4469537a7b14dcfd28e3d301600ff6" category="inline-link-macro-rx"></block>。</block>
  <block id="7f88d48c3b0283642fe6b1f3f061d0fd" category="paragraph"><block ref="7f88d48c3b0283642fe6b1f3f061d0fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ac40323c41c29fb75f6e19c4c683e47" category="paragraph"><block ref="8ac40323c41c29fb75f6e19c4c683e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4990031dcfbd871d95ce4ae0321e7156" category="paragraph">SMB ボリュームをマウントするには、次の手順を実行します。</block>
  <block id="fd78728be3a82142558c815267b8daa0" category="list-text">SMB 共有をマッピングする SMB ボリュームをクリックします。</block>
  <block id="58dc78a5cd30078188f7c605e636a975" category="paragraph">VMware VM の Windows ゲスト OS からマウントプロセスを実行するには、次の手順を実行します。</block>
  <block id="3dcb4e26f80951bdb3beeb0a03a3ba83" category="list-text">[ スタート ] ボタンをクリックし、 [ コンピュータ ] をクリックします。</block>
  <block id="202bba1ab43a099f57e49b350eb2ad1a" category="list-text">[ ネットワークドライブの割り当て ] をクリックします。</block>
  <block id="7dea65bdd8e9fbcd8a5b7249c71e1f0b" category="list-text">[ ドライブ ] リストで、使用可能な任意のドライブ文字をクリックします。</block>
  <block id="695179e494f30a851f80409f824a80f8" category="list-text">フォルダボックスに、次のように入力します。</block>
  <block id="2653f3365feaf0a8bf80106cba1b9ad8" category="paragraph"><block ref="2653f3365feaf0a8bf80106cba1b9ad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cd95358048d9f5d18cf70f66126e1e7" category="paragraph">コンピュータにログオンするたびに接続するには、 [ サインイン時に再接続 ] チェックボックスをオンにします。</block>
  <block id="7968f043139de8ff0e5df4451c437426" category="list-text">完了をクリックします。</block>
  <block id="8902b5e2f0c169ccf7ad8b5c335531e5" category="paragraph"><block ref="8902b5e2f0c169ccf7ad8b5c335531e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="104948b3593a97ed92fc801aaf126581" category="doc">エンタープライズハイブリッドクラウド（ EHC ）の概要</block>
  <block id="415be703c228d9c6838b18850a1d9f31" category="paragraph">ほとんどの IT 組織は、ハイブリッドクラウドファーストアプローチに準拠しています。このような組織は変革の段階にあり、お客様は現在の IT 環境を評価してから、評価と調査の演習に基づいてワークロードをクラウドに移行しています。</block>
  <block id="346972233965e89cf5b17c3907b35f86" category="paragraph">クラウドに移行するお客様の要因には、柔軟性とバースト性、データセンターの終了、データセンターの統合、サポート終了シナリオ、合併、 買収など。この移行の理由は、各組織とそれぞれのビジネス上の優先事項によって異なります。ハイブリッドクラウドに移行する際は、クラウドの導入と柔軟性を最大限に活用するために、クラウドに最適なストレージを選択することがきわめて重要です。</block>
  <block id="0c4a16ed987359b14dc407a858d1a78e" category="section-title">パブリッククラウドの VMware Cloud オプション</block>
  <block id="9789f0612fda153726aa8ad87265e4b9" category="section-title">Azure VMware 解決策の略</block>
  <block id="d788a5499d320b05602a6a0805c81403" category="image-alt">AVS</block>
  <block id="c7b818b90803789a74058cfb4396383d" category="paragraph">Azure VMware 解決策は、 Microsoft Azure パブリッククラウド内で VMware データセンターを完全に機能させるハイブリッドクラウドサービスです。Azure VMware 解決策は、 Microsoft がフルマネージドでサポートし、 VMware が Azure インフラを活用して検証した、ファーストパーティ製解決策です。つまり、 Azure VMware 解決策を導入すると、お客様のコンピューティング仮想化向けに VMware の ESXi を、ハイパーコンバージドストレージ用に vSAN を、 さらに NSX は、ネットワークとセキュリティを実現するだけでなく、 Microsoft Azure のグローバルプレゼンス、クラスをリードするデータセンター施設を活用し、ネイティブの Azure サービスとソリューションの豊富なエコシステムに近接しています。</block>
  <block id="22b0614f106e2b7c956c60c8fc0d35c3" category="image-alt">VM C</block>
  <block id="8641a2440fc22db60ec877f3a8946fa2" category="paragraph">VMware Cloud on AWS は、 VMware のエンタープライズクラスの SDDC ソフトウェアを AWS クラウドに提供し、ネイティブ AWS サービスへのアクセスを最適化します。VMware Cloud Foundation を基盤とする VMware Cloud on AWS は、 VMware のコンピューティング、ストレージ、ネットワーク仮想化製品（ VMware vSphere 、 VMware vSAN 、 VMware NSX ）と VMware vCenter Server の管理を統合し、専用の柔軟性の高いベアメタル AWS インフラストラクチャ上で実行できるように最適化されています。</block>
  <block id="8cb69aa5b1609d0a39f0fcd576c07df6" category="section-title">Google Cloud VMware Engine</block>
  <block id="5292de1147a4b3a1d5c63d057c4b0096" category="image-alt">「 gcve 」</block>
  <block id="1ffd600a1d8e07fe3b4bca16ae02167c" category="paragraph">Google Cloud VMware Engine は、 Google Cloud の高性能で拡張性の高いインフラストラクチャと VMware Cloud Foundation スタック（ VMware vSphere 、 vCenter 、 VSAN 、 NSX ）を基盤とした IaaS （ Infrastructure-as-a-Service ）ですこのサービスにより、アプリケーションの再構築やツールの再構築にかかるコスト、労力、リスクを伴わずに、クラウドへの迅速な移行を実現し、既存の VMware ワークロードをオンプレミス環境から Google Cloud Platform にシームレスに移行または拡張できます。VMware と緊密に連携して Google が販売およびサポートするサービスです。</block>
  <block id="3310d189628fa6ef843aac57894a6db2" category="admonition">SDDC プライベートクラウドと NetApp Cloud Volume コロケーション施設は、最小限のネットワークレイテンシで最高のパフォーマンスを提供します。</block>
  <block id="c771fce16e2ba5df07df53cc5ab0748f" category="section-title">ご存知ですか？</block>
  <block id="8bba30129de0461b328be1e49f02b4d9" category="paragraph">VMware SDDC を導入する際、使用するクラウドに関係なく、最初のクラスタには次の製品が含まれます。</block>
  <block id="7110e7a8682a9bc1c7105b83fe0cd9ea" category="list-text">コンピューティングの仮想化に使用する VMware ESXi ホストと、管理用の vCenter Server アプライアンス</block>
  <block id="7d7a80e207de2136f4f19820758703fc" category="list-text">各 ESXi ホストの物理ストレージ資産を組み込んだ VMware vSAN ハイパーコンバージドストレージ</block>
  <block id="d2852e9d73c0ef81033c835719128b81" category="list-text">管理のために NSX Manager クラスタを使用した仮想ネットワークとセキュリティのための VMware NSX</block>
  <block id="afb91ca7e7763c77e44a41cb5ad0f78b" category="paragraph">ストレージを大量に消費するワークロードをホストし、クラウドホスト型の VMware 解決策でスケールアウトする場合、デフォルトのハイパーコンバージドインフラでは、コンピューティングリソースとストレージリソースの両方で拡張を行う必要があります。</block>
  <block id="fdb27bea654a8d874baecced2be84a1b" category="paragraph">Azure NetApp Files 、 NetApp ONTAP 向け Amazon FSX 、 Cloud Volumes ONTAP （ 3 つの主要ハイパースケーラすべてに対応）、 Cloud Volumes Service for Google Cloud などの NetApp Cloud Volume と統合することで、お客様はストレージを個別に拡張できるオプションを利用できるようになりました。 また、必要に応じてコンピューティングノードを SDDC クラスタに追加します。</block>
  <block id="a752c3529f0285d457f3b33b3c80d9a4" category="list-text">VMware では、アンバランスなクラスタ構成を推奨していません。そのため、ストレージを拡張するとホストが増え、 TCO が増加します。</block>
  <block id="c231690c8e9fabbd819ec1805becb157" category="list-text">アプリケーションの要件、パフォーマンス、コストに合わせて複数のパフォーマンス階層を提供するオプションはありません。</block>
  <block id="5d4c92ddd5fe9a6044b25c17d3368207" category="list-text">クラスタホスト上に構築された VSAN のストレージ容量の制限に非常に簡単に到達できます。NetApp Cloud Volume を使用して、アクティブなデータセットをホストするか、またはティアクーラデータを永続的ストレージにホストするかに応じてストレージを拡張できます。</block>
  <block id="c1cf68955de5fa20274b29fa4a2a863f" category="paragraph">Azure NetApp Files 、 NetApp ONTAP 向け Amazon FSX 、 Cloud Volumes ONTAP （ 3 つの主要なハイパースケーラすべてで利用可能）、および Cloud Volumes Service for Google Cloud は、ゲスト VM と組み合わせて使用できます。このハイブリッドストレージアーキテクチャは、ゲストオペレーティングシステムとアプリケーションバイナリデータを保持する VSAN データストアで構成されます。アプリケーションデータは、ゲストベースの iSCSI イニシエータを介して VM に接続されます。または、 Amazon FSX for NetApp ONTAP 、 Cloud Volume ONTAP 、 Azure NetApp Files 、 Cloud Volumes Service for Google Cloud と直接通信する NFS/SMB マウントを使用して VM に接続されます。この構成では、 VSAN と同様にストレージ容量の問題を簡単に解決できます。使用可能な空きスペースは、使用する余裕容量およびストレージポリシーによって異なります。</block>
  <block id="1a5208bfffc624ccf99dfcbbf2078050" category="paragraph">次に、 AWS 上の VMware Cloud 上の 3 ノード SDDC クラスタについて考えてみましょう。</block>
  <block id="fab7fb31baaec1ccac4fe688e1a4c5d4" category="list-text">3 ノード SDDC の合計物理容量は 31.1TB （各ノードのおおよその 10TB ）です。</block>
  <block id="ca189b47c3a1dfe1adbd1519688e4cc8" category="list-text">追加のホストが追加される前に保持されるスラックスペース = 25% = （ .25 x 31.1TB ） = 7.7TB 。</block>
  <block id="999b2c719df3f3e524bb10fb76521726" category="list-text">余裕期間を計算した後の使用可能な物理容量 = 23.4TB</block>
  <block id="2e1f3b31385d3304e1cda70b9cd8ed4c" category="list-text">使用可能な有効な空きスペースは、適用するストレージポリシーによって異なります。</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">例：</block>
  <block id="2f5e6d9b0a4708c4d137ba14ac704a7b" category="list-text">RAID 0 = 有効な空きスペース = 23.4TB （使用可能な物理容量 / 1 ）</block>
  <block id="df6b502d4d7283ef27d3821b69836c2d" category="list-text">RAID 1 = 有効な空きスペース = 11.7TB （使用可能な物理容量 / 2 ）</block>
  <block id="921c660c11d4880048f3ef723f079e17" category="list-text">RAID 5 = 有効な空きスペース = 17.5TB （使用可能な物理容量 / 1.33 ）</block>
  <block id="e3bdc3102c3de4f73860c229550bc6f4" category="paragraph">そのため、 NetApp Cloud Volume をゲスト接続ストレージとして使用すると、パフォーマンスとデータ保護の要件を満たしながら、ストレージを拡張して TCO を最適化できます。</block>
  <block id="571c0d425ce03c2532e7d9f34ca87cb1" category="section-title">覚えておいてください</block>
  <block id="8e6eaed3852a3b311ab6ed1b8b6fc239" category="list-text">ハイブリッドストレージモデルでは、ホスト自体にも近接しているため、特定のレイテンシ要件に対処するために、 VSAN データストアにティア 1 または高優先度のワークロードを配置します。トランザクションのレイテンシが許容されるワークロード VM には、ゲスト内メカニズムを使用します。</block>
  <block id="43ff7a71a2ea2fc47a29d410cd1e4944" category="list-text">NetApp SnapMirror ® テクノロジを使用して、オンプレミスの ONTAP システムから Cloud Volumes ONTAP または Amazon FSX for NetApp ONTAP にワークロードデータをレプリケートすることで、ブロックレベルのメカニズムによって移行を簡易化できます。これは、 Azure NetApp Files および Cloud Volume サービスには適用されません。Azure NetApp Files または Cloud Volume サービスにデータを移行するには、使用するファイルプロトコルに応じて、 NetApp XCP 、 Cloud Sync 、 rysnc 、 robocopy を使用してください。</block>
  <block id="d3c0fd4b510310b9bd00463208eade94" category="list-text">テストでは、該当する SDDC からストレージにアクセスする際のレイテンシが 2 ～ 4 ミリ秒増加しました。ストレージをマッピングする際には、このレイテンシをアプリケーション要件に考慮してください。</block>
  <block id="b83cf0bc9b65a0fcd5f49d4c96dceea8" category="list-text">テストフェイルオーバーおよび実際のフェイルオーバー時にゲスト接続ストレージをマウントする場合は、 iSCSI イニシエータが再設定されていること、 SMB 共有の DNS が更新されていること、および NFS マウントポイントが fstab で更新されていることを確認してください。</block>
  <block id="1b4048870ed334dbc2e7d6f09a814188" category="list-text">ゲスト内の Microsoft Multipath I/O （ MPIO ；マルチパス I/O ）、ファイアウォール、ディスクタイムアウトのレジストリ設定が VM 内で適切に設定されていることを確認します。</block>
  <block id="00b23e82efc2ec82b134496e575a934c" category="section-title">ネットアップのクラウドストレージのメリット</block>
  <block id="80def6ec4d999fc4d082800c8c33f6ec" category="paragraph">ネットアップのクラウドストレージには次のようなメリットがあります。</block>
  <block id="2e594db552f7cd9c7f02d87507dbb471" category="list-text">コンピューティングとストレージの別々にストレージを拡張できるため、コンピューティングとストレージの密度が向上します。</block>
  <block id="479f9f236fc4cffa74f2e94b654bbeeb" category="list-text">ホスト数を削減し、全体的な TCO を削減できます。</block>
  <block id="108dd736471686a2b8b87154d73cbc5b" category="list-text">コンピューティングノードの障害は、ストレージのパフォーマンスには影響しません。</block>
  <block id="a85e0a264279b851fbcec367c181932e" category="list-text">Azure NetApp Files のボリュームの形状変更と動的なサービスレベル機能を使用すると、安定状態のワークロードのサイジングによってコストを最適化し、オーバープロビジョニングを防止できます。</block>
  <block id="4e24ca7789e0b9320e302b8efa2caf9f" category="list-text">Cloud Volumes ONTAP の Storage Efficiency 、クラウド階層化、インスタンスタイプの変更機能を使用すると、ストレージの追加や拡張を最適な方法で行うことができます。</block>
  <block id="d7a87fa8fc914cf57f38eff05d53faa2" category="list-text">ストレージリソースのオーバープロビジョニングは、必要な場合にのみ発生します。</block>
  <block id="940eacbcb0faa8c3b1e0d995c154f693" category="list-text">効率的な Snapshot コピーとクローンにより、パフォーマンスに影響を与えることなく迅速にコピーを作成できます。</block>
  <block id="a9e4a9fcd1f9bf0a9d0d0b2c0f198db5" category="list-text">Snapshot コピーからの迅速なリカバリを使用して、ランサムウェア攻撃に対処できます。</block>
  <block id="caf9b805c37cab661d4e3a26b7f71109" category="list-text">複数のリージョン間で効率的なブロック転送ベースのリージョナルディザスタリカバリと統合されたバックアップブロックレベルを提供することで、 RPO と RTO が向上します。</block>
  <block id="658fb5ef00749e8af5a974f612adea9b" category="section-title">前提条件</block>
  <block id="a9e63f2a8549d717b777806268a0c0cb" category="list-text">SnapMirror テクノロジやその他の関連するデータ移行メカニズムが有効になっている。オンプレミスから任意のハイパースケーラクラウドまで、さまざまな接続オプションがあります。適切なパスを使用し、関連するネットワークチームと連携します。</block>
  <block id="c63dc0feeff939bc83ba1537a1e8ac9a" category="list-text">本ドキュメントの作成時点で使用可能な唯一のオプションは、ゲスト内ストレージでした。</block>
  <block id="478a13ed02b948c9cfd89a6197062012" category="admonition">ストレージの計画とサイジング、および必要なホスト数については、ネットアップの解決策アーキテクトと対応するハイパースケーラクラウドアーキテクトに相談してください。Cloud Volumes ONTAP サイジングツールを使用してストレージインスタンスのタイプや適切なサービスレベルを最終決定する前に、ストレージのパフォーマンス要件を特定することを推奨します。</block>
  <block id="c748546b5854ecb146d9caa41d781bdb" category="section-title">詳細なアーキテクチャ</block>
  <block id="2b6a2372968d8ec2639d784ce8aee350" category="paragraph">このアーキテクチャ（下の図を参照）では、 NetApp Cloud Volumes ONTAP 、 Azure NetApp Files for Google Cloud 、 Cloud Volumes Service を追加のゲスト内ストレージオプションとして使用して、複数のクラウドプロバイダ間でハイブリッドマルチクラウド接続とアプリケーションのモビリティを実現する方法について、全体的な観点から説明しています。</block>
  <block id="1a8ac44404b1e5888d83801ac116ff66" category="inline-image-macro">エンタープライズハイブリッドクラウドアーキテクチャ</block>
  <block id="855b05f645c80247a3f11392cab187c2" category="paragraph"><block ref="855b05f645c80247a3f11392cab187c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd558e50adcdcb0d667a4790f70f75a9" category="paragraph">GCP で GCVE 環境を設定するには、 GCP コンソールにログインし、 VMware Engine ポータルにアクセスします。</block>
  <block id="fb33f758c28f8ef8d56e41f74b4c47ab" category="paragraph">[New Private Cloud] ボタンをクリックして、 GCVE プライベートクラウドに必要な設定を入力します。「場所」で、 CV/CVO を導入するリージョン / ゾーンにプライベートクラウドを導入して、最高のパフォーマンスと最小のレイテンシを確保してください。</block>
  <block id="63b31ca49de01854f780d1e1722cd1c1" category="paragraph">前提条件</block>
  <block id="d79b0ab3cbae1dcd79007a97d26af5b1" category="list-text">VMware Engine Service Admin IAM ロールを設定します</block>
  <block id="72a7f08f840ab91a28a2558393971c47" category="inline-link-macro">VMware Engine API アクセスおよびノードクォータを有効にします</block>
  <block id="88e3e4c9b1c9efec399f7dda7a0c5887" category="list-text"><block ref="88e3e4c9b1c9efec399f7dda7a0c5887" category="inline-link-macro-rx"></block></block>
  <block id="a88d670b04af96a871dad56001e8f742" category="list-text">CIDR 範囲がオンプレミスサブネットやクラウドサブネットと重複しないようにしてください。CIDR 範囲は /27 以上である必要があります。</block>
  <block id="33d7d6c631c2d2cb3608445ef761fe16" category="paragraph"><block ref="33d7d6c631c2d2cb3608445ef761fe16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65bdc0673006b33d0c876e18a9a98787" category="paragraph">注：プライベートクラウドの作成には、 30 分から 2 時間かかります。</block>
  <block id="44f55a60cc8f70d1e10efc62b75eeddc" category="doc">ハイパースケーラにおける VMware 向けネットアップソリューション</block>
  <block id="ee5c3b650204d422e3d3e7bd725ec032" category="paragraph">ネットアップが提供する 3 つの主要ハイパースケーラ（ゲスト接続ストレージデバイスまたはネイティブデータストアとしてのネットアップのソリューションから、ワークフローの移行、クラウドへの拡張 / バースト対応、バックアップ / リストア、ディザスタリカバリ）の機能の詳細をご確認ください。</block>
  <block id="f21c97f5b239021bb3f13d148516abb4" category="paragraph">クラウドを選択して、ネットアップに任せてください。</block>
  <block id="c1304f98c6be845a236d7a27951ece4f" category="paragraph"><block ref="c1304f98c6be845a236d7a27951ece4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca4ac823f3f130f3c78d6ac26ba9f46b" category="admonition">特定のハイパースケーラの機能を確認するには、そのハイパースケーラに適したタブをクリックします。</block>
  <block id="addac5e706b2148d9c7b3bbe2d2fcdde" category="paragraph">次のオプションから選択して、目的のコンテンツのセクションに移動します。</block>
  <block id="06262015df4851b380189212274a0e3e" category="inline-link-macro">ハイパースケーラ構成における VMware</block>
  <block id="7f08237a127b62af444f720f15216cee" category="list-text"><block ref="7f08237a127b62af444f720f15216cee" category="inline-link-macro-rx"></block></block>
  <block id="c774c23e9a97e08bfa096f1cbf18cc17" category="inline-link-macro">ネットアップストレージオプション</block>
  <block id="d3fc27ff58dc3a0d839a16af858e7999" category="list-text"><block ref="d3fc27ff58dc3a0d839a16af858e7999" category="inline-link-macro-rx"></block></block>
  <block id="833413440fbbe13837d8b58256cfba65" category="paragraph">オンプレミスと同様に、 VM と移行を作成する本番環境に適したクラウドベースの仮想化環境を計画することが重要です。</block>
  <block id="ff264305bf70750f504c04f48ab02038" category="paragraph">ネットアップのストレージは、 3 つの主要なハイパースケーラそれぞれで、接続されているかネイティブのデータストアとして、いくつかの方法で利用できます。</block>
  <block id="94772ee4b241fe0706c3aaef6e3a4505" category="inline-link-macro">サポートされているネットアップストレージオプション</block>
  <block id="67b586cdf9703ba67abe711415768cc0" category="paragraph">にアクセスしてください <block ref="01a9bd21bfc714c8dec8aabc5b88eda7" category="inline-link-macro-rx"></block> を参照してください。</block>
  <block id="8a69f1bae52e494c6960f92a27390dcf" category="paragraph">VMware Cloud を FSX ONTAP に接続するには、次の手順を実行します。</block>
  <block id="7ca6fbd8bbb6725fab7413e4179738f6" category="list-text">VMware Cloud の導入が完了して AWS VPC に接続されているため、 Amazon FSX for NetApp ONTAP を、元の接続済み VPC ではなく新しい VPC に導入する必要があります（以下のスクリーンショットを参照）。接続された VPC に FSX （ NFS および SMB のフローティング IP ）が導入されている場合、これらの IP にはアクセスできません。Cloud Volumes ONTAP のような iSCSI エンドポイントは、接続された VPC からは正常に機能します。</block>
  <block id="da6646a18f048724eb432bf61285ca7f" category="paragraph"><block ref="da6646a18f048724eb432bf61285ca7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85dd65f7163e587c050ea8931a368ae" category="list-text">同じリージョンに別の VPC を導入し、その新しい VPC に Amazon FSX for NetApp ONTAP を導入します。</block>
  <block id="c78834afa7d24e921aa4d756d0a6409f" category="paragraph">VMware Cloud コンソールで SDDC グループを構成すると、 FSX が導入された新しい VPC に接続するために必要なネットワーク設定オプションが有効になります。手順 3 で、「グループ用の VMware トランジット接続の構成に添付ファイルおよびデータ転送ごとの料金が発生する」がチェックされていることを確認し、「グループの作成」を選択します。このプロセスが完了するまでに数分かかることがあります。</block>
  <block id="f91a2b452c63b5ccfcb4c39c2957c74e" category="paragraph"><block ref="ca83e0582a449c1b4399270025e1cc4a" category="inline-image-macro-rx" type="image"></block>
<block ref="9232dff72050e533bd1e173e5a0dd48c" category="inline-image-macro-rx" type="image"></block>
<block ref="5a108f597862e683ab9463f7c3ba6df6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fae60fbb10da5c3df46ec8ae03cd29b5" category="inline-link-macro">外部 VPC を接続する手順</block>
  <block id="784ad3266f853af20763bb78f5eec87a" category="list-text">新しく作成した VPC を作成した SDDC グループに接続します。[External VPC （外部 VPC ） ] タブを選択し、に従います <block ref="19928d01a63fe78e1303b296c2046666" category="inline-link-macro-rx"></block> をグループに追加します。このプロセスが完了するまでに 10~15 分かかることがあります。</block>
  <block id="14466a85376e8776f891db4cb3c38c6c" category="paragraph"><block ref="dd1eb585a08c833cec9544c048af36b6" category="inline-image-macro-rx" type="image"></block>
<block ref="38542de5661e382aba9345fe6e5a991b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8acea1c4fcca87631ca127e2bc757f13" category="inline-link-macro">AWS 転送ゲートウェイ</block>
  <block id="77508ef16874a250b66be2f90fc59918" category="list-text">外部 VPC プロセスの一環として、 AWS コンソールから Resource Access Manager を使用して新しい共有リソースにアクセスするように求められます。共有リソースはです <block ref="ccce2323414354d76e9cea0c1df9221b" category="inline-link-macro-rx"></block> VMware Transit Connect によって管理されます。</block>
  <block id="ac81300f843e6b91377e64a8edb819c2" category="paragraph"><block ref="63de05888c0a11205c33fd560dba3bc5" category="inline-image-macro-rx" type="image"></block>
<block ref="0455c56bd9863ddfae4079b5aabd42e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf415daee6d6f894a54f025534ba071" category="list-text">トランジットゲートウェイ添付ファイルを作成します。</block>
  <block id="e222d36183b455bb51f289144826c239" category="paragraph"><block ref="e222d36183b455bb51f289144826c239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b6693c4eff7f7923c59277702b441a9" category="list-text">VMC コンソールに戻り、 VPC 接続を受け入れます。この処理が完了するまでに約 10 分かかることがあります。</block>
  <block id="64d5d06ed03c085c4f5ce23ff6eeddac" category="paragraph"><block ref="64d5d06ed03c085c4f5ce23ff6eeddac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9b85dc0e557eb865bfa9ae84e251623" category="list-text">[External VPC （外部 VPC ） ] タブで、 [Routes] 列の編集アイコンをクリックし、次の必要なルートを追加します。</block>
  <block id="ae6434a5ebe0bad2f978fef8e0ed9efe" category="inline-link-macro">フローティング IP</block>
  <block id="06651ace1eab88d681ca9a8852bf26e2" category="list-text">NetApp ONTAP の Amazon FSX のフローティング IP 範囲のルート <block ref="14a98976d888daccbd07561411cfd6fa" category="inline-link-macro-rx"></block>。</block>
  <block id="5e16e681111a1a5b2dc805d69827532f" category="list-text">Cloud Volumes ONTAP のフローティング IP 範囲のルート（該当する場合）。</block>
  <block id="efffbab523616433e2c1ea67cbcaab53" category="list-text">新しく作成される外部 VPC アドレススペースのルート。</block>
  <block id="daa8a39ba75e8ac01fd26d579ce35fd9" category="paragraph"><block ref="daa8a39ba75e8ac01fd26d579ce35fd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="853349bb92eccb477b47eef3b8a5d9e2" category="inline-link-macro">ファイアウォールルール</block>
  <block id="499ca5dd26dbcc4c89a04ac771b316a6" category="inline-link-macro">詳細な手順</block>
  <block id="14c6314f2ae331d7f9a01ac04a75cd2b" category="list-text">最後に、双方向トラフィックを許可します <block ref="0756551700fd3215666355892b2f3692" category="inline-link-macro-rx"></block> FSX/CVO へのアクセスに必要です。以下の手順に従ってください <block ref="583f77470215de8611ddf3fba5fc6512" category="inline-link-macro-rx"></block> SDDC ワークロード接続用のコンピューティングゲートウェイファイアウォールルール用。</block>
  <block id="098b98cba4d6766e7de663adf0fdabb0" category="paragraph"><block ref="098b98cba4d6766e7de663adf0fdabb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f4480b9caed7d956fd6071b4cce03b9" category="list-text">管理ゲートウェイとコンピューティングゲートウェイの両方にファイアウォールグループを設定したら、次の手順で vCenter にアクセスできます。</block>
  <block id="f1c1b29fad3f2bdb9d8d054686b86542" category="paragraph"><block ref="f1c1b29fad3f2bdb9d8d054686b86542" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8b86f112029b19bf6451ba4624a4090" category="paragraph">次の手順では、 Amazon FSX ONTAP または Cloud Volumes ONTAP が要件に応じて設定されていること、およびストレージコンポーネントを VSAN からオフロードして導入を最適化するようにボリュームがプロビジョニングされていることを確認します。</block>
  <block id="76b7cf7d0f36f0986e2c7ef578303aab" category="doc">まとめ：エンタープライズハイブリッドクラウド（ EHC ）にネットアップが選ばれる理由</block>
  <block id="dd6f2ba05323a537582c1f232e8a2c60" category="paragraph">ネットアップの Cloud Volume と主要ハイパースケーラ向け VMware ソリューションは、ハイブリッドクラウドの活用を検討している組織に大きな可能性をもたらします。以降では、 NetApp Cloud Volume の統合による真のハイブリッドマルチクラウド機能のユースケースについて説明します。</block>
  <block id="e7441dbfabeaebba75ddd1bf2bcf25e9" category="section-title">ユースケース 1 ：ストレージの最適化</block>
  <block id="b9a8c3d27aa6638e02992c8b76fea769" category="paragraph">RVtools の出力を使用したサイジングの演習では、馬力（ vCPU / vMem ）のスケールがストレージと平行になっていることが常に明らかです。多くの場合、組織は、ストレージスペースを必要とするだけでなく、クラスタのサイズを十分に拡張して処理能力を必要とする状況に遭遇します。</block>
  <block id="cb575e0b8e023ca0a1789ea03bdb86fd" category="paragraph">NetApp Cloud Volume を統合することで、組織は vSphere ベースのクラウド解決策を簡単な移行アプローチで実現できます。再プラットフォーム化や IP の変更は不要で、アーキテクチャの変更も必要ありません。また、この最適化により、ホストの数を vSphere で必要な量以上に抑えながらストレージの設置面積を拡張できます。ただし、ストレージ階層、セキュリティ、ファイルは変更されません。これにより、導入を最適化し、全体的な TCO を 35 ～ 45% 削減できます。この統合により、ウォームストレージから本番環境レベルのパフォーマンスまで、ストレージを数秒で拡張できます。</block>
  <block id="9ae8084cfbf8c00bc50891fe51bb70b4" category="section-title">ユースケース 2 ：クラウドへの移行</block>
  <block id="40c30ee45ee11e766ec77dfd0d98cef0" category="paragraph">企業は、次のような理由から、オンプレミスのデータセンターからパブリッククラウドへのアプリケーション移行を迫られています。設備投資（ CAPEX ）から運用コスト（ OPEX ）に移行するための資金調達ディレクティブや、すべてをクラウドへ移行するというトップダウンの指示など、さまざまな理由があります。</block>
  <block id="4744ec437cce262edc7110652b69ab21" category="paragraph">スピードが重要な場合は、合理化された移行アプローチのみが可能です。これは、クラウド固有の IaaS プラットフォームに適応するためのアプリケーションの再プラットフォーム化とリファクタリングが低速でコストがかかるためですが、多くの場合、数か月かかることがあります。ネットアップの Cloud Volume とゲスト接続ストレージ用の帯域幅効率に優れた SnapMirror レプリケーションを組み合わせることで、アプリケーションと整合性のある Snapshot コピーと HCX 、クラウド固有の移行（例 Azure Migrate ）、または VM のレプリケーションに使用するサードパーティ製品）。この移行は、時間のかかる I/O フィルタメカニズムを使用する場合よりも簡単です。</block>
  <block id="d393e254c1adb8df50cfc41394c68645" category="section-title">ユースケース 3 ：データセンターの拡張</block>
  <block id="90c724dd3ba1ec0f533f7fb73a10323a" category="paragraph">季節によって変動する需要の急増や、わずかに変動する有機的な成長によってデータセンターの容量が上限に達し解決策た場合、 NetApp Cloud Volume と一緒にクラウドホスト型の VMware 環境に移行するのは簡単です。NetApp Cloud Volume を利用すると、アベイラビリティゾーン全体の高可用性と動的な拡張機能を提供することで、ストレージの作成、レプリケーション、拡張が非常に簡単に行えます。NetApp Cloud Volume を活用すると、ストレッチクラスタが不要になるため、ホストクラスタの容量を最小限に抑えることができます。</block>
  <block id="0b95336d0f31a3bd4775f96c750bb9bc" category="section-title">ユースケース 4 ：クラウドへのディザスタリカバリ</block>
  <block id="c2aee451a27e7cf3993f462ee5b760e9" category="paragraph">従来のアプローチでは、災害が発生した場合、クラウドに複製された VM は、クラウドに復元する前にクラウド独自のハイパーバイザプラットフォームに変換する必要があります。これは、危機的な状況では対処できません。</block>
  <block id="772dec0515d132f26bfa87cb31b5758d" category="paragraph">SnapCenter を使用してゲスト接続ストレージに NetApp Cloud Volume を使用し、オンプレミスからの SnapMirror レプリケーションとパブリッククラウド仮想化ソリューションを使用することで、ディザスタリカバリに対する優れたアプローチを考案できます。これにより、完全に一貫性のある VMware SDDC インフラ上で VM レプリカをリカバリできるようになり、クラウド固有のリカバリツールも利用できます Azure Site Recovery を参照）、または Veeam などの同等のサードパーティツールが必要です。また、このアプローチにより、ランサムウェアからのディザスタリカバリ訓練やリカバリも迅速に実行できます。また、テスト用や災害時に、ホストをオンデマンドで追加することで、フル本番環境に拡張することもできます。</block>
  <block id="24d0e6ab8003b406cf7e3f42363acbf5" category="section-title">ユースケース 5 ：アプリケーションの最新化</block>
  <block id="59e56fb67c730af04acf8a13665cadb3" category="paragraph">アプリケーションがパブリッククラウドに配置されたら、組織は数百もの強力なクラウドサービスを活用して最新化と拡張を実現したいと考えています。NetApp Cloud Volume を使用すると、アプリケーションデータが vSAN にロックされず、 Kubernetes などの幅広いユースケースでデータを移動できるため、最新化は簡単なプロセスです。</block>
  <block id="eea420abccd820355b4bddd3524ae083" category="paragraph">オールクラウドとハイブリッドクラウドのどちらをターゲットとしている場合でも、 NetApp Cloud Volume は、アプリケーションワークロードを導入、管理するための優れたオプションを提供し、ファイルサービスとブロックプロトコルに加えて、データ要件をアプリケーションレイヤとシームレスにすることで TCO を削減します。</block>
  <block id="cd51ff9774803e84c79e8ab19bb7ffd2" category="paragraph">どのようなユースケースでも、任意のクラウドやハイパースケーラを NetApp Cloud Volume と組み合わせることで、オンプレミスと複数のクラウドにわたるクラウドのメリット、一貫したインフラ、運用、ワークロードの双方向の移動、エンタープライズクラスの容量とパフォーマンスを迅速に実現できます。</block>
  <block id="2993778cba8ea9a69af4ff9dc7e18fb8" category="paragraph">ストレージの接続に使用する一般的なプロセスや手順は同じです。新しい名前で変更されたデータの位置にすぎません。ツールやプロセスはすべて変わらないので、 NetApp Cloud Volume を使用すれば導入全体を最適化できます。</block>
  <block id="2195b6c1bba772f631332c732395b829" category="doc">エンタープライズハイブリッドクラウド（ EHC ）のユースケース</block>
  <block id="5f1bd6ade489565bebba9a771b93fe70" category="paragraph">ハイブリッドクラウドまたはクラウドファーストの導入を計画する際に IT 組織にとって重要なユースケースの概要。</block>
  <block id="0812fc943ecbd9a54d88fb25729d0aa5" category="section-title">一般的なユースケース</block>
  <block id="f136615e6f2c1b330afb72bf4a45b4a4" category="paragraph">ユースケースには次のものがあり</block>
  <block id="3481fb80f122383c65ff8c6c8fd8c943" category="list-text">ディザスタリカバリ、 SVM</block>
  <block id="4127bac8297e2af8866315910651ce47" category="list-text">データセンターのメンテナンス時にワークロードをホストする。 * ローカルのデータセンターでプロビジョニングされたリソース以外に追加のリソースが必要になる、迅速なバースト。</block>
  <block id="20b1c73b5938d2d878aa1d96fee7f1b2" category="list-text">VMware サイトの拡張</block>
  <block id="5fe13b2b805496310dbaa281d7325877" category="list-text">クラウドへの迅速な移行</block>
  <block id="b278a6d011d590bb350b9cb81c21a732" category="list-text">開発 / テスト、および</block>
  <block id="2116d89ca4be9d5a23f758068a2225b2" category="list-text">クラウドネイティブなテクノロジを活用したアプリケーションの最新化。</block>
  <block id="bc262005b263505cc0464e05c4324687" category="section-title">IT の旅の中で</block>
  <block id="cfdb9aabb4aedf8cad2e330ba5a516a3" category="paragraph">ほとんどの組織は、変革と最新化への移行を進めています。このプロセスの一環として、企業は既存の VMware への投資を活用しながら、クラウドのメリットを活用し、移行プロセスをできるだけシームレスに実行する方法を模索しています。このアプローチでは、データがすでにクラウドにあるため、最新化への取り組みが非常に簡単になります。</block>
  <block id="9576824e6ccc9e436057f6d3bcd644d2" category="paragraph">このシナリオに最も簡単に使用できる回答は、各ハイパースケーラにおける VMware ソリューションです。ネットアップの Cloud Volume と同様に、 VMware はオンプレミスの VMware 環境を任意のクラウドに移行または拡張できるため、既存のオンプレミスの資産、スキル、ツールを保持しながら、ワークロードをクラウド内でネイティブに実行できます。これにより、サービスの中断や IP 変更の必要性がなくなり、 IT チームは既存のスキルやツールを使用してオンプレミスで行う方法を運用できるようになるため、リスクが軽減されます。これにより、クラウドへの移行が高速化され、ハイブリッドマルチクラウドアーキテクチャへの移行が大幅にスムーズになります。</block>
  <block id="ca0a16f344ac7703cf785163a8f07f5d" category="section-title">ネイティブストレージオプションの重要性を理解する</block>
  <block id="46da638bac867fb225c11e1d8504da00" category="paragraph">あらゆるクラウドで VMware が提供する独自のハイブリッド機能はすべてのお客様に提供されますが、ネイティブストレージの選択肢が限られているため、ストレージの負荷が高い組織での有用性が制限されています。ストレージはホストに直接関連付けられているため、ストレージを拡張する唯一の方法は、ホストを追加することです。これにより、ストレージを大量に消費するワークロードの場合、 35 ～ 40% 以上のコストがかかる可能性があります。このようなワークロードに必要なストレージ容量は増えても容量は増えません。つまり、追加のホストに料金を支払うことになります。</block>
  <block id="0362604333fcf179ebf8b873f8f8c0ec" category="paragraph">次のシナリオを考えてみましょう。</block>
  <block id="b401aa039e47ba98bfaca10532e40d08" category="paragraph">CPU とメモリ用にわずか 5 台のホストが必要ですが、ストレージには多くのニーズがあり、ストレージ要件を満たすために 12 台のホストが必要です。この要件は、ストレージを増設するだけで追加の処理能力を購入する必要があるため、財務面での拡張性に大きな転換を実現できます。</block>
  <block id="7c25e9d8a9748905f5d456e20a93b413" category="paragraph">クラウドの導入と移行を計画する場合は、最適なアプローチを評価し、投資の総削減に最も簡単な方法をとることが常に重要です。あらゆるアプリケーション移行で最も一般的かつ簡単なアプローチは、仮想マシン（ VM ）やデータ変換がない場所でリホスト（リフトアンドシフト）を行うことです。NetApp Cloud Volume と VMware の Software-Defined Data Center （ SDDC ）を併用し、 vSAN を補完することで、移行と切り替えが容易になります。</block>
  <block id="548bebbdb3ac596c6116cbd05e474fe0" category="summary">あらゆるパブリッククラウドプロバイダに対応したエンタープライズハイブリッドクラウドソリューションに関する一連のブログをご用意しています</block>
  <block id="b8136929c18b90d36d40eb475da80f06" category="doc">エンタープライズハイブリッドクラウドに関するブログ</block>
  <block id="27f22a085d12c1434c2027f4d64f9418" category="paragraph">ブログの概要では、主要な 3 つのクラウドプロバイダすべてのエンタープライズハイブリッドクラウドソリューションの特定の機能を紹介しています。</block>
  <block id="f8aacfa5c683858912c498f517c9b457" category="cell">データアクセス</block>
  <block id="c14336a2319ce73616b0fa898a883fe0" category="cell">データアクセスソリューションの集合体。ソリューションは次のいずれかのカテゴリに分類されます。 [navy]#Data Migration#[navy]#Data Protection#[navy]#Security#</block>
  <block id="4fdba571bc9e0ee81ec6ad364abe8141" category="sidebar">エンタープライズハイブリッドクラウド（ EHC ）</block>
  <block id="d1c8b02a1da8ed066c640468ff055a12" category="sidebar">EHC の概要</block>
  <block id="e673b6ab6c5649a4df8e874aaa9017b9" category="sidebar">サポートされる構成</block>
  <block id="bee43f00a445d11a7c2f9ef81ad0c045" category="sidebar">ハイパースケーラクラウドの VMware クラウド</block>
  <block id="70321856a2bf47570f50f25e43e23bdf" category="sidebar">仮想化、デスクトップ仮想化コンテナ</block>
  <block id="5d7b876a73a9025080fbf6dd921d1fdd" category="sidebar">データ移行とデータ保護</block>
  <block id="9b699c59be5ba510cd9c430a31843b23" category="sidebar">データ移行</block>
  <block id="ef55a9d1028eac237813e753d20134df" category="sidebar">パブリッククラウド向け VMware</block>
  <block id="27c378e12a7c59dc5aa13b13cc6cecff" category="sidebar">ハイパースケーラクラウド上の VMware クラウド</block>
  <block id="452b0b090c1c37a0d467a8df764fd81f" category="sidebar">ハイパースケーラクラウドにおけるネットアップストレージ</block>
  <block id="2190ab0d2f6281b2f3a73e0fc8e1f560" category="sidebar">まとめ</block>
  <block id="75fcfea0185575f935a7f5f149efd8ca" category="sidebar">VMware ハイブリッドクラウドのユースケース</block>
  <block id="e251010eb0cac5793d760ab2e5f51473" category="sidebar">ユースケースの概要</block>
  <block id="6f4bb0fa6fee4cf4ae1b8b1fc16e17cb" category="sidebar">レガシー NetApp HCI ソリューション</block>
  <block id="4a7272ea95323d5fef2e377b91b5f16d" category="inline-link-macro">ゲスト接続ストレージとしての FSX ONTAP</block>
  <block id="3017a9031d66c55b0258c102decfd1b9" category="inline-link-macro">Cloud Volumes ONTAP （ CVO ）をゲスト接続ストレージとして活用</block>
  <block id="1ffaf40c19facb6829b48b667d1dcaa3" category="inline-link-macro">ゲスト接続ストレージとしての Azure NetApp Files （ ANF</block>
  <block id="9bb210767ccb9c085c816c82f3b6b1cb" category="inline-link-macro">Cloud Volumes Service （ CVS ）をゲスト接続ストレージとして使用できるようになりました</block>
  <block id="712d83d9ce8f26363e9bfd1cba104b88" category="sidebar">NetApp E シリーズおよび Commvault Data Platform V11</block>
  <block id="aa8156dc9f7aa240e4f412f2f5fedaf5" category="sidebar">を使用した E シリーズおよび EF シリーズリファレンスアーキテクチャおよびストレージのベストプラクティス Veeam Backup Replication 9.5 のリリース</block>
  <block id="74e4bedcc2ff5b37a8770caa0ef72975" category="sidebar">NetApp E シリーズストレージを使用した Veritas NetBackup の導入</block>
  <block id="029f60716c50acd9acf9ce4a9394c91a" category="sidebar">HyTrust を使用したマルチテナントインフラストラクチャ向けの NIST セキュリティ制御</block>
  <block id="e63695c4dea40eefb2ef481c7b242192" category="open-title">すべての変更</block>
  <block id="b0522aa84a7257c47dd4b765cf173db9" category="open-title">AI / データ分析</block>
  <block id="6fb2815b4c371ee082a84cc14539d4cb" category="open-title">エンタープライズアプリケーション</block>
  <block id="19751bc7a2f01e4ee4762945c90c0130" category="open-title">データ保護と移行</block>
  <block id="fb0ad99371abb3d02d60add8160c6dd9" category="section-title">NetApp Cloud Manager を使用した CVO と Connector の AWS 認証の要件</block>
  <block id="5edbe8c55546db896b55871b44a39263" category="cell">* 日付 *</block>
  <block id="12cd1425f32ad289dba28e35ae9096fb" category="cell">* 解決策エリア *</block>
  <block id="b96941ac46daa357b1782f017746a57b" category="cell">* 変更の概要 *</block>
  <block id="f63616bb6a8255ed08089231c746f285" category="cell">12/062021</block>
  <block id="3f2c1d118f7bc861eb20da58f81a2d0d" category="cell">ハイブリッドクラウド / 仮想化</block>
  <block id="040fc8ca9c1b1eb9d408c7ae5e202acb" category="cell">仮想化環境およびゲスト接続ストレージオプション向けの Enterprise Hybrid Cloud （ EHC ）コンテンツの作成</block>
  <block id="16784caec2e047ddf59bd5a51bd35a73" category="cell">2021年11月15日</block>
  <block id="1c20ad7a11d1c2856906d55171b50126" category="cell">新しいビデオデモ「 Astra Control を使用した CI / CD パイプラインでのデータ保護」を NVA-1160 に追加</block>
  <block id="5cdb842b21b9f980df2b3ab63ee9a9e6" category="cell">新しいコンテンツ： ConFluent Kafka のベストプラクティス</block>
  <block id="38562890365e144b467ec2813a6377f2" category="cell">2021 年 11 月 2 日</block>
  <block id="dfd39862c9cc158ad7b0e4e1e9a3024a" category="cell">2021 年 10 月 29 日</block>
  <block id="e7c456cd85cc15bd3faf7b65c0833d3e" category="cell">新しいコンテンツ： TR-4657 - ネットアップのハイブリッドクラウドデータソリューション： Spark と Hadoop</block>
  <block id="815425a7766095190649a3f9ecbc1828" category="cell">2021年10月26日</block>
  <block id="7a81532ad3c2274f22bc7665e02f162f" category="cell">ネットアップのソリューションタイルに、エンタープライズアプリケーションとデータベースに関するブログセクションを追加しました。エンタープライズデータベースのブログに 2 つのブログを追加。</block>
  <block id="8493c4f1797303a6de2524a60adcf058" category="cell">2021年10月18日</block>
  <block id="ade15f89ccc27958a743a992cea8c574" category="cell">TR-4908 - 『 Hybrid Cloud Database Solutions with SnapCenter 』</block>
  <block id="622eda32248f1c4d1fc31dd78ec74c4a" category="cell">2021年10月14日</block>
  <block id="f6ecd264493db5fac4b21f19be4eb69d" category="cell">VMware VCF ブログシリーズに、ネットアップのパート 1~4 を追加</block>
  <block id="83a11da06ed8a3e338b5e8d2991cae0c" category="cell">2021年10月4日</block>
  <block id="c95696f6146a5b8b56c74d4349687ec6" category="cell">新しいビデオデモ「 Astra Control Center を使用したワークロードの移行」を NVA-1160 に追加</block>
  <block id="4f41bdb2ec81835b66ffbbd18feea656" category="cell">2021 年 9 月 23 日</block>
  <block id="32ff1e0d02ec482c64fdac1af2a49372" category="cell">新しいコンテンツ： NetApp XCP 向けのネットアップのベストプラクティス</block>
  <block id="42246d8ef9280d19cf1326197310630a" category="cell">2021 年 9 月 21 日</block>
  <block id="10c87c454d38afc0644c8c1fb75fa524" category="cell">VMware vSphere 管理者、 VMware vSphere 自動化向けの新しいコンテンツまたは ONTAP</block>
  <block id="faaef04f2f0bb7bed9504fc3d357ba59" category="cell">2021年9月9日</block>
  <block id="80245b1f322b07a9fcd385bb375d8182" category="cell">NVA-1160 に、 OpenShift で F5 BIG-IP ロードバランサを統合</block>
  <block id="023cd4d7ed373df0d803d414e2e452bf" category="cell">2021年8月5日</block>
  <block id="afb6b7f715f1bf6492efb8f3c279ddd7" category="cell">NVA-1160 - NetApp Astra Control Center on Red Hat OpenShift に新しいテクノロジ統合を追加</block>
  <block id="2cd99fd0d69d62395a72dc7d4684299c" category="cell">2021 年 7 月 21 日</block>
  <block id="e88b179e97a156d13d1c9c4163513205" category="cell">07/02/2021</block>
  <block id="9f99e3ea14c0a44dde0fd7db13fa3bef" category="cell">TR-487- 『 SQL Server on Azure NetApp Files ： Real Deployment View 』</block>
  <block id="83d39ff0c36403ca3e183af9ca091a71" category="cell">2021年6月16日</block>
  <block id="2891cb0fe31606ff172d0be4ec81732f" category="cell">新しいビデオデモ「 OpenShift Virtualization のインストール：ネットアップでの Red Hat OpenShift 」を追加しました</block>
  <block id="77d29c989f99997794df55b2d9053ae8" category="cell">新しいビデオデモ「 OpenShift による仮想マシンの導入： NetAppp を使用した Red Hat OpenShift 」を追加しました</block>
  <block id="fab25e19f7e186358ed7f1268e7af3b4" category="cell">2021年6月14日</block>
  <block id="96da300b5faf4ae3a5ca09afabba4273" category="cell">解決策に Azure NetApp Files ： Microsoft SQL Server を追加</block>
  <block id="67c877d4abd9acdbb0fa62c3720b6d60" category="cell">2021年6月11日</block>
  <block id="a14851e0e2cb4c8e9176cdea01500288" category="cell">新しいビデオデモ「 Astra Trident を使用したワークロードの移行」と NVA-1160 に SnapMirror を追加</block>
  <block id="c5d2015481e39976c67e40778a449a2d" category="cell">2021年6月9日</block>
  <block id="c4aad26d0bd9fb92610a1b5b3390bd46" category="cell">ネットアップを使用した Red Hat OpenShift での Kubernetes の高度なクラスタ管理に関する NVA-1160 に新しいユースケースを追加しました</block>
  <block id="53977250e4a69cab3688fcbede8fb73a" category="cell">2021年5月28日</block>
  <block id="9c23aa040a3dc51dbbf59463247f4fec" category="cell">NVA-11460 の OpenShift Virtualization に新しいユースケースを追加しました NetApp ONTAP の略</block>
  <block id="c02e5ac689072495b8af780302105253" category="cell">2021年5月27日</block>
  <block id="f5abcac882b8caa17d3af1c14144f503" category="cell">NetApp ONTAP を使用した OpenShift で、 NVA-1160 マルチテナンシーに新しいユースケースを追加しました</block>
  <block id="3202abe9084b2d9ec5b0b162721978e7" category="cell">2021年5月26日</block>
  <block id="d58aa75910c54a80c6ba4de7e7f6949f" category="cell">ネットアップで NVA-1160 Red Hat OpenShift を追加</block>
  <block id="a0be3ecb819e8e7215f946964346f547" category="cell">2021年5月25日</block>
  <block id="95a74db23b085df59ef6412199e9e791" category="cell">ブログ「 Installing NetApp Trident on Red Hat OpenShift – How to Solve the Docker ‘ toomanyrequests ’問題！」を追加</block>
  <block id="2dec0489948dbe7f63f68743a085e98c" category="cell">2021年5月19日</block>
  <block id="0db377921f4ce762c62526131097968f" category="cell">全般</block>
  <block id="9045bfbeff51b83f9752fe549021a181" category="cell">FlexPod ソリューションへのリンクを追加</block>
  <block id="0a40e3c91a3a55c9a37428c6d194d0e5" category="cell">AI</block>
  <block id="af3192eaae3cb09641db4adcc45ed625" category="cell">AI コントロールプレーン解決策を PDF から HTML に変換しました</block>
  <block id="8ff5be8d16e86e5284f8ba8a3428459a" category="cell">2021年5月17日</block>
  <block id="a88789a4f83f213b256b57eb0884fd1d" category="cell">解決策フィードバックタイルをメインページに追加しました</block>
  <block id="027fb9451c491d9dcfb7db05f552788d" category="cell">2021年5月11日</block>
  <block id="3e62d5f1a7f1b6907ad1ecaf11282dac" category="cell">NFS への Oracle 19C for ONTAP の自動導入が追加されました</block>
  <block id="d2422eca0ff6f19afb6e1206b15fbe01" category="cell">2021年5月10日</block>
  <block id="85c96a5f13e6dea61e003704f8d456e2" category="cell">新しいビデオ： How to use VVOLs with NetApp and VMware Tanzu Basic 、パート 3</block>
  <block id="29e9b684dbbdf5cc1828da82a146781d" category="cell">2021年5月6日</block>
  <block id="508db167da7d74fc86c3f8024ce04558" category="cell">FlexPod データセンター上の Oracle 19C RAC データベースへのリンクを追加しました FC 経由で Cisco UCS と NetApp AFF A800 を使用</block>
  <block id="85fbf94a3ecf9a3af4a93f80a3681fe1" category="cell">2021年5月5日</block>
  <block id="608f33919f16e9a23bd532ad6bcf480a" category="cell">FlexPod Oracle NVA （ 1155 ）と Automation のビデオを追加しました</block>
  <block id="4dc6e14d2ad9dafd2cd72f8c77d22bea" category="cell">2021年5月3日</block>
  <block id="3d21a9c32818fc58b044121ce91e053c" category="cell">デスクトップ仮想化</block>
  <block id="4174d4c17e4b11e07d8dd581e16ba56c" category="cell">FlexPod デスクトップ仮想化ソリューションへのリンクを追加</block>
  <block id="b3cae16f1f895f4f9ceae98617a3bf0d" category="cell">2021年4月30日</block>
  <block id="2764512d2fc00264d149a6142151aa1a" category="cell">ビデオ： How to use VVOLs with NetApp and VMware Tanzu Basic 、パート 2</block>
  <block id="4996fa0acf5cc54e889a50e9bdd2e56b" category="cell">2021年4月26日</block>
  <block id="9c5316849ca2429400f8979f0ee0d963" category="cell">ブログ「 Using VMware Tanzu with ONTAP to Accelerate Your Kubernetes Journey. 」を追加</block>
  <block id="911da11d01e00e9aa94c5b03b2e6e2cc" category="cell">2021年4月6日</block>
  <block id="06cfdb63e0660d09f203a21e28520a1e" category="cell">「このリポジトリについて」を追加</block>
  <block id="32edd80de3642c58e1a05df5f3e458e1" category="cell">2021年3月31日</block>
  <block id="bbb1c8f8182403001f2e1f69085ca2ad" category="cell">エッジでの TR-4886 - AI 推論の項「 NetApp ONTAP with Lenovo ThinkSystem 解決策 Design 」を追加</block>
  <block id="d61c9a3748e1dd56535fbdaaa3e39eab" category="cell">2021年3月29日</block>
  <block id="8575a367028bec3e86e25b102a8dced1" category="cell">NetApp Storage 解決策で NVA-1157 - Apache Spark ワークロードを追加しました</block>
  <block id="8f10e64b04f6cc56cf66fd4f4eb0f4d9" category="cell">2021年3月23日</block>
  <block id="7998f8ad3cabe02af607385cae780ce1" category="cell">ビデオ： How to use VVOLs with NetApp and VMware Tanzu Basic 、パート 1</block>
  <block id="f86fe8ec70f2003923e4000589747208" category="cell">2021年3月9日</block>
  <block id="eea51e9c0dffabdea48ada8f53bbf0f5" category="cell">E シリーズの内容を追加し、 AI の内容を分類</block>
  <block id="0b218fa381bfd1c86fff15d165ab23a0" category="cell">2021年3月4日</block>
  <block id="932af944058a758da919ca59d1af640b" category="cell">新しいコンテンツ： NetApp 解決策の自動化の導入</block>
  <block id="4be9c930c1a8a198115d499cb3223d9e" category="cell">2021年2月18日</block>
  <block id="0c560038af98c5401dd10202e7937acd" category="cell">TR-4597 VMware vSphere for ONTAP を追加しました</block>
  <block id="aa1c3ec5e6dcfb94555ff987f061f1a0" category="cell">2021年2月16日</block>
  <block id="3ecf1285a084b58473a7873e3f33e74a" category="cell">AI Edge 推論の自動導入手順が追加されました</block>
  <block id="8138d0c3e613508050b6fec12c4322c7" category="cell">2021年2月3日</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="cell">SAP</block>
  <block id="91171755730ad15e6d79b5cb6682a8f1" category="cell">SAP と SAP HANA のすべてのコンテンツのランディングページを追加</block>
  <block id="e5099bd65458f8a8556c830ac4759296" category="cell">2021年2月1日</block>
  <block id="09689218a7f330554f4e28a18e9e14a6" category="cell">ネットアップ VDS を使用した VDI で、 GPU ノードのコンテンツを追加</block>
  <block id="c487c48f1528e49e3cb129fdbdd79990" category="cell">2021年1月6日</block>
  <block id="868f7f9e78f90bcf0597030ffefd449b" category="cell">新しい解決策： NVIDIA DGX A100 システムと Mellanox Spectrum イーサネットスイッチを搭載した NetApp ONTAP AI （設計と導入）</block>
  <block id="0663765430d1ca93138f13429aef7c37" category="cell">2020年12月22日</block>
  <block id="a4aae8f8849c453c6c67080c5d013301" category="cell">ネットアップソリューションリポジトリの初版リリース</block>
  <block id="18a2eb3f7faf7c44e3062e78cbeff089" category="inline-link-macro">SAP ソリューションリポジトリ</block>
  <block id="412b2ee09f2fbaf8cddb69ee6fe43a2e" category="admonition">SAP および SAP HANA の更新の詳細については、の各ソリューションに表示される「更新履歴」のコンテンツを参照してください <block ref="c4ed54a973fb1aa472c2443732d93c13" category="inline-link-macro-rx"></block>。</block>
  <block id="5a2d7e3c6d0ab5aa27c06042f28c3198" category="open-title">拡張 / バースト</block>
  <block id="8553825f2c93feb7d32c670401e5f338" category="open-title">データセンターのメンテナンス</block>
  <block id="b98a6acc7ef428f1ae11e5177447df8c" category="paragraph">クラウドの場合は、オンプレミスとクラウドの間の接続が直接接続（ AWS ）、 ExpressRoute （ Azure ）、クラウドインターコネクト（ GCP ）の場合にも、同様のオンプレミス移行ワークフローに従うことができます。</block>
  <block id="76e3e2a4e56301dafc50613d96fd624e" category="section-title">導入手順 - NAS</block>
  <block id="62e9f0426675b856daf874c75830c213" category="inline-link-macro">「 XCP の前提条件」</block>
  <block id="4f6583b152ef684b4492414bcdcdf877" category="list-text">のセクションで説明した前提条件を満たしていること <block ref="958d961a425946e5195ca036cea97fab" category="inline-link-macro-rx"></block></block>
  <block id="0957326f089aaf98a5b7b9110a2675cd" category="section-title">導入手順 - hdfs/MapRFS のデータ移行</block>
  <block id="1f43fc63f63aad0b707e06b0753182a1" category="paragraph">このセクションでは、 Hadoop ファイルシステムの NAS へのデータ転送という新しい XCP 機能について説明します。この機能は、 HDFS / MapRFS から NFS にデータを移行するか、その逆を行います。</block>
  <block id="368666825ffae5710ab122fb63937cee" category="paragraph">MapRFS/HDFS 機能の場合は、ルート以外のユーザ環境で次の手順を実行する必要があります。通常、 root 以外のユーザは HDFS 、 MapR 、または HDFS および MapRFS ファイルシステムを変更する権限を持つユーザです。</block>
  <block id="9adbc05b1436b3e8962253577f1e6441" category="list-text">CLI またはユーザの .bashrc ファイルと 'XCP コマンドを使用して 'CLASSPATH 'hadoop home ' Nhdfsa_libjvm_path ' lm_library_path ' および Nhdfsa_LIBhdfsa_path 変数を設定します</block>
  <block id="2a0eda7a7937e303f9e18a57a033fcb8" category="list-text">Nhdfsa_lidbhdfs_path は、 libhdfs.so ファイルを指しています。このファイルは、 Hadoop ディストリビューションの一部として HDFS / MapRFS ファイルとファイルシステムを操作し操作するための HDFS API を提供します。</block>
  <block id="13682a0461e750a2dfb4e86c2ddc1165" category="list-text">Nhdfs_libjvm_path は、 libjvm.so ファイルを指しています。これは JRE の場所にある共有 Java 仮想マシンライブラリです。</block>
  <block id="60ce276a5dde3f2d2e92b1986a2eb339" category="list-text">クラスパスは、 Hadoop クラスパス– glob 値を使用してすべての jar ファイルを指します。</block>
  <block id="84cbf778b2572cae5eba01d0ca330078" category="list-text">LD_LIBRARY_PATH は、 Hadoop のネイティブライブラリフォルダの場所を指しています。</block>
  <block id="68207eb9f168add2309e88b5223d57c6" category="paragraph">Cloudera クラスタに基づいて、次のサンプルを参照してください。</block>
  <block id="91328810a5559a740f522f4c5a1da5f1" category="paragraph">このリリースでは、 HDFS から NFS への XCP スキャン、コピー、および検証処理とデータ移行がサポートされます。データレイククラスタの 1 つのワーカーノードと複数のワーカーノードからデータを転送できます。1.8 リリースでは、 root ユーザと root 以外のユーザがデータを移行できるようになりました。</block>
  <block id="dee4c2c7e685015e9f3cc1ad197f3ab5" category="section-title">導入手順 - root 以外のユーザが HDFS / MaprFS データを NetApp NFS に移行します</block>
  <block id="5983f77acc016b8138698b32b0ab0405" category="list-text">導入の手順から 1 ～ 9 の手順を実行します。</block>
  <block id="c2765e27844a39bfc897cb964eec8711" category="list-text">次の例では、 HDFS から NFS にデータを移行します。</block>
  <block id="e6f549e8013d1f24b8756cd11ff3083e" category="list-text">HDFS 内に（「 hadoop fs -copyFromLocal 」を使用して）フォルダとファイルを作成します。</block>
  <block id="2433ce85404dd68893a2e4abb99843e4" category="list-text">HDFS フォルダで権限をチェックします。</block>
  <block id="befab6065ddb441f0b260ac75a8e84c8" category="list-text">NFS でフォルダを作成し、権限を確認します。</block>
  <block id="02341ea695e862c3a2d89461b1b8bf37" category="list-text">XCP を使用して HDFS から NFS にファイルをコピーし、権限を確認します。</block>
  <block id="46742b2c1e11cf6a3e230ec3da7e6800" category="admonition">XCP ファイル分析のアーキテクチャの概要、統計情報ビューなどの GUI ベースのダッシュボードビュー、およびファイル配布ビューの詳細については、ブログの投稿を参照してください<block ref="924a0428223d35821b584a5368c0e3e5" category="inline-link-rx"></block>。</block>
  <block id="21bd6427119f8d9a06a7c5bce95d28ac" category="paragraph">XCP 1.6 では、カスタマイズされたグラフを作成するための GUI に制限があります。必要なグラフを作成するには、 CLI を使用して対応するフィルタを指定して XCP スキャンコマンドを実行します。次の例を参照してください。</block>
  <block id="7e9b65699b01d35aeff9dc16008da7a5" category="paragraph">XCP コピーと同期のテストでは、導入時に使用したのと同じテストベッドを使用しました。8K 、 16K 、 1MB の 3 セットのファイルを 100 万個作成し、変更をリアルタイムで実行しました。XCP sync 関数は、ソースからターゲットへの差分増分更新をファイルレベルで実行します。増分更新操作には、既存のファイルとフォルダの名前変更、既存のファイルへのデータの追加、ファイルとフォルダの削除、ハードリンク、ソフトリンク、マルチリンクの追加の 4 つの操作があります。テスト目的では、名前変更、追加、削除、およびリンク操作に注目しました。つまり、 100 万ファイルに対して、名前変更、追加、削除などの変更処理が 10% から 90% の変更率で実行されたことになります。</block>
  <block id="f599c9e924e3b854abd0ab58126fed43" category="paragraph">以前のバージョンと比較して、 XCP 1.6.3 および 1.7 でパフォーマンスが向上しています。次のセクションでは、 XCP 1.6.3 と 1.7 の間での 8K 、 16K 、 1MB の各ファイルの同期パフォーマンスの比較を示します。</block>
  <block id="b53776fdc2fd9fc721aaa6f03fd3d6a0" category="paragraph">次の図は、 XCP 1.6.3 での XCP 同期パフォーマンスと 1.7 （ 8K サイズが 100 万ファイルの場合）の結果を示しています。</block>
  <block id="5b201508f1de849d630f98c0001fdc29" category="paragraph">次の図は、 XCP 1.6.1 での XCP 同期パフォーマンスの結果を示しています。 1MB のファイルサイズが 100 万ファイルの 1.5 です。</block>
  <block id="61b90da0c91ea6cb7c16bfaca41b4920" category="paragraph">このパフォーマンス検証に基づいて、オンプレミスとクラウドでのデータ移行には XCP 1.7 を使用することを推奨します。</block>
  <block id="d0ecdc77c2c944d380e9fef0e01eb119" category="paragraph">これは '-fmt' コマンドを使用するカスタム・レポートですすべてのディレクトリがスキャンされ、ディレクトリの名前、パス、およびサイズが CSV ファイルにダンプされます。サイズ列は、スプレッドシートアプリケーションでソートできます。</block>
  <block id="1c026a57d7676d346dd0d44a2f595c1d" category="list-text">* スキャン * NAS および MapR / HDFS データのレイアウトの概要を提供します。</block>
  <block id="6b2c974b2ada5fba492b8dcda598b1f9" category="paragraph">次の図は、 GUI からの NetApp XCP ファイル分析通信を示しています。</block>
  <block id="2d3aa3941d30870beb3abde613ce14b1" category="paragraph">XCP 1.7 に含まれるライブソース移行のサポートにより、使用中のデータソースからの移行（読み取りおよび書き込みアクティビティ）が可能になります。移行ジョブで使用されているファイル（ copy や sync running など）は XCP によって除外され、スキップされたファイルの情報は XCP ログにキャプチャされます。</block>
  <block id="b9611b870758eac97bd0c3bcb3fc8026" category="list-text">Azure NetApp ボリュームごと、またはクラウドの Cloud Volume Service （プレミアムサービスレベル）用に、 XCP カタログ用にオンプレミスで NFS 共有を 1 つ作成します。</block>
  <block id="7d131526ee2a04107bbc50d52a29a7d7" category="cell">2021 年 12 月 21/2021 年です</block>
  <block id="c65463900a520919b522c30b6256e475" category="cell">新しいビデオデモ「 NetApp Astra Control を活用した、事後分析の実施とアプリケーションの NVA-1160 へのリストア」を追加しました</block>
  <block id="5df9589990c71ed42c69a8bcc053d0d4" category="inline-link-macro">ビデオ： NetApp Astra Control を活用して、事後分析とアプリケーションのリストアを実行</block>
  <block id="51d1589966ca772274944bc0cd6b15bc" category="cell"><block ref="51d1589966ca772274944bc0cd6b15bc" category="inline-link-macro-rx"></block></block>
  <block id="fb12e7f50899cc1254f9a6f1e0341423" category="summary">アプリケーションのクローンを作成して事後分析を行い、 Astra Control Center を使用して CI / CD パイプラインでアプリケーションを復元します</block>
  <block id="bc42bbaf219349a2ba37dfd4709b2003" category="doc">NetApp Astra Control を活用して、事後分析とアプリケーションのリストアを実行</block>
  <block id="ceba75f5c6f0a0eed497aaa1cc4f30ad" category="cell">仮想化とエンタープライズハイブリッドクラウド向けのコンテンツをより効率的に整理するためのランディングページを作成しました</block>
  <block id="10b5b21ed1ee90eca305b558caf7d03b" category="open-title">移動</block>
  <block id="72b05a5f0a9b1e3f2eded42f0dbdd848" category="open-title">バックアップ / リストア</block>
  <block id="e413eba49b15917b0c9dbf2620f3e66e" category="open-title">ディザスタリカバリ</block>
  <block id="37cbb75112a68116251619ab33efe24a" category="section-title">VMC 向けネットアップソリューション</block>
  <block id="07b0eade4402d209b5dbe587a8ad3f6f" category="doc">AWS に仮想化環境を導入して設定</block>
  <block id="35dcee3fd9faac08f48b3df2e8e0e63c" category="admonition">現在、 FSX ONTAP と Cloud Volumes ONTAP を AWS VMC に接続する方法としてサポートされているのは、ゲスト内ストレージだけです。</block>
  <block id="fc6ca296e478de217b1d91ca6a51669e" category="list-text"><block ref="fc6ca296e478de217b1d91ca6a51669e" category="inline-link-macro-rx"></block></block>
  <block id="0e488e496c84968dd373c3acab443dd7" category="list-text"><block ref="0e488e496c84968dd373c3acab443dd7" category="inline-link-macro-rx"></block></block>
  <block id="a724b4fc4c5f79672a5c572466d5e001" category="doc">Azure 向けネットアップゲスト接続ストレージオプション</block>
  <block id="ca0f2c52a62624ee3babda4927666866" category="list-text"><block ref="ca0f2c52a62624ee3babda4927666866" category="inline-link-macro-rx"></block></block>
  <block id="426cc154d20d2e0075b81fa214c4d27d" category="list-text"><block ref="426cc154d20d2e0075b81fa214c4d27d" category="inline-link-macro-rx"></block></block>
  <block id="9eaed1d83e18be57bbead8a1f4bf4abe" category="doc">GCP 向けのネットアップネイティブデータストアオプションです</block>
  <block id="ae295ef15cb155f8a1af7d255e34298d" category="doc">AWS 用のネットアップゲスト接続ストレージオプション</block>
  <block id="0d349db2638a92fd70bcc7d2f31663ab" category="paragraph">AWS は、ゲスト接続ネットアップストレージを次の構成でサポートします。</block>
  <block id="ac68b9acaa4ad0b0a4dc57efbda279fc" category="list-text"><block ref="ac68b9acaa4ad0b0a4dc57efbda279fc" category="inline-link-macro-rx"></block></block>
  <block id="ade1814101b0113034e0f446307b3db3" category="doc">Google Cloud Platform GCVE のネットアップ機能</block>
  <block id="e8650e82200d7cca856f3795833c4382" category="paragraph">ネットアップが Google Cloud Platform （ GCP ）で提供する Google Cloud Virtualization Ending （ GCVE ）の機能については、ネットアップがゲスト接続ストレージデバイスまたはネイティブデータストアとして提供しているものを参照してください。また、ワークフローの移行、クラウドへの拡張 / バースト対応、バックアップ / リストア、ディザスタリカバリにも対応しています。</block>
  <block id="6eb516b97eae0ab93b8d6aab35fbb764" category="section-title">GCVE のネットアップストレージオプション</block>
  <block id="50b53922d656bce75f35201b661fc378" category="paragraph">ネットアップストレージは、 GCP GCVE 内で、推測接続またはネイティブデータストアとして、複数の方法で利用できます。</block>
  <block id="e3a2a8e4a74a67a9514c2aec5e4fac69" category="doc">ネットアップの Azure ネイティブデータストアオプション</block>
  <block id="99d04ce0dcd35b869d3c86120b76a443" category="summary">ネットアップのエンタープライズハイブリッドクラウドソリューションは、主要なパブリッククラウドハイパースケーラに含まれるネットアップストレージの機能を実証する、一連の戦略的機能とテクノロジ機能です。</block>
  <block id="3cce9a9057a6d96d9ac2ddab52d477fe" category="doc">ネットアップのエンタープライズハイブリッドクラウドソリューション</block>
  <block id="8811a4f5d0046113ac94b851ec1b1990" category="list-text"><block ref="8811a4f5d0046113ac94b851ec1b1990" category="inline-link-macro-rx"></block></block>
  <block id="1d8249c60cae81d82fc5bfb80167babc" category="list-text">1 つの VSAN 環境のみが可能です。そのため、すべてのストレージトラフィックが本番環境のワークロードと直接競合します。</block>
  <block id="63b9fbe67e7dd9b9f7623683244cb7f8" category="doc">Azure AVS 向けのネットアップの機能</block>
  <block id="ea7f7b3af23a2abea8816902269875f9" category="paragraph">ネットアップが Azure VMware 解決策（ AVS ）に提供する機能の詳細をご確認ください。ネットアップがゲスト接続ストレージデバイスまたはネイティブデータストアとして提供する機能から、ワークフローの移行、クラウドへの拡張 / バースト対応、バックアップ / リストア、ディザスタリカバリに至るまで、さまざまなメリットがあります。</block>
  <block id="1f0a2077c33b91b3daaaea05c7fadc07" category="section-title">Azure で AVS を設定する</block>
  <block id="cdac9a2e7f1dc52240712d4a191378e8" category="section-title">AVS 向けのネットアップストレージオプション</block>
  <block id="a69a7b9e874f9f6e0703191e7825cc4f" category="paragraph">ネットアップストレージは、 Azure AVS 内で数通りの方法で利用できます。接続されているか、ネイティブデータストアとして利用できます。</block>
  <block id="cf3ac5a0dae3780b356e57c121b3eab0" category="doc">Google Cloud Platform （ GCP ）への仮想化環境の導入と構成</block>
  <block id="8514045c5551663f28246e665ca2f189" category="list-text"><block ref="8514045c5551663f28246e665ca2f189" category="inline-link-macro-rx"></block></block>
  <block id="3cef16671ee166d12c5fd192fa419358" category="list-text"><block ref="3cef16671ee166d12c5fd192fa419358" category="inline-link-macro-rx"></block></block>
  <block id="b23824e61fecb77e1ae6d9f739a9fb83" category="doc">ネットアップの AWS 向けネイティブデータストアオプション</block>
  <block id="ba756c1a2b93ad97a639914aae828a16" category="doc">ネットアップの AWS VMC 向け機能</block>
  <block id="c31fafd8fe5f702d3722404547cc8cb5" category="paragraph">ネットアップが AWS VMware Cloud （ VMC ）にもたらす機能の詳細をご確認ください。ネットアップがゲスト接続ストレージデバイスまたはネイティブデータストアとして提供している機能から、ワークフローの移行、クラウドへの拡張 / バースト対応、バックアップ / リストア、ディザスタリカバリに利用できます。</block>
  <block id="8658ccb747e94ac624861f5761a34716" category="section-title">AWS で VMC を設定しています</block>
  <block id="e9f84da32eb512bd768458a738ed8aa6" category="section-title">VMC のネットアップストレージオプション</block>
  <block id="cd5a564d709538be5df5e7167600498d" category="paragraph">ネットアップのストレージは、 AWS VMC 内で、接続されているかネイティブのデータストアとして、いくつかの方法で利用できます。</block>
  <block id="bb01fec2870d3f698517f8471454637b" category="doc">Azure に仮想化環境を導入して設定</block>
  <block id="c33cce5b25d7b62b8be123136ad64ae1" category="list-text"><block ref="c33cce5b25d7b62b8be123136ad64ae1" category="inline-link-macro-rx"></block></block>
  <block id="d47c67e14996fb3c08deb5311a358578" category="list-text"><block ref="d47c67e14996fb3c08deb5311a358578" category="inline-link-macro-rx"></block></block>
  <block id="5a8521e0e0ab0935654c959eba47d6a0" category="list-text"><block ref="5a8521e0e0ab0935654c959eba47d6a0" category="inline-link-macro-rx"></block></block>
  <block id="c9b6ad26821d78c27282a65584d5f485" category="summary">ネットアップは、堅牢な仮想化環境向けに、オンプレミスとクラウドの両方で、多数のベストプラクティスとソリューションを提供しています。</block>
  <block id="ba64ee63cc4950b57bfb868fabec0db3" category="doc">ネットアップの仮想化ソリューション</block>
  <block id="c775b248c55d253008c58d1ecd60e66f" category="doc">エンドユーザコンピューティング（ EUC ） / 仮想デスクトップインフラ（ VDI ）ソリューション</block>
  <block id="599725d881295777d3740ac33e953ced" category="paragraph">仮想デスクトップをオンプレミスとクラウドのどちらに導入する場合でも、ネットアップにはニーズに対応するためのさまざまな EUC / VDI ソリューションが用意されています。</block>
  <block id="75fc33fcc3ef968fd3bf30c8da19bf9b" category="section-title">ネットアップの仮想デスクトップサービス（ VDS ）</block>
  <block id="0593c3151fa252cdb4e997dd1255c608" category="paragraph">ネットアップの仮想デスクトップサービス（ VDS ）は、主要なパブリッククラウドとプライベートクラウドで Remote Desktop Services （ RDS ）のオーケストレーションを実現します。</block>
  <block id="3b96d802308faf1d6ff7e5563ea3d29b" category="paragraph">VDS で利用できるソリューション：</block>
  <block id="2ccf8775db4706ac42c0a600eca82163" category="list-text"><block ref="2ccf8775db4706ac42c0a600eca82163" category="inline-link-macro-rx"></block></block>
  <block id="d4a0768ddf4ac449658ace06000fa76e" category="section-title">VMware Horizon を使用したエンドユーザコンピューティング</block>
  <block id="959f3d9cc20e0e9bfbc01c2d36cdc894" category="paragraph">ネットアップでは、複数のコンピューティング構成にまたがる VMware Horizon の検証済みアーキテクチャを提供しています。利用可能なソリューションは次のとおりです。</block>
  <block id="01606c27121f18cf231b4700ddf252e1" category="list-text"><block ref="01606c27121f18cf231b4700ddf252e1" category="inline-link-macro-rx"></block></block>
  <block id="4e5b466ff852e362d888b555cdcf62b7" category="list-text"><block ref="4e5b466ff852e362d888b555cdcf62b7" category="inline-link-macro-rx"></block></block>
  <block id="06e0780100d16763670aed1df8526b2e" category="list-text"><block ref="06e0780100d16763670aed1df8526b2e" category="inline-link-macro-rx"></block></block>
  <block id="128fc080215971e783f68c8be31bd85d" category="list-text"><block ref="128fc080215971e783f68c8be31bd85d" category="inline-link-macro-rx"></block></block>
  <block id="bf647454e36069fd16f1a7a35cf6a865" category="sidebar">はじめに</block>
  <block id="a4dc228188fdd73342ee66658a9afdff" category="sidebar">ハイパースケーラクラウドにおけるネットアップ</block>
  <block id="624e816c7f229d54827ad7bc018eb8da" category="sidebar">サポートされているストレージオプション</block>
  <block id="40d267fad784266cb59c36d76573e7c6" category="sidebar">NetApp on AWS （ VMC ）</block>
  <block id="e7060d0555f178d672a4197df38e1d39" category="sidebar">仮想化環境を構成します</block>
  <block id="96e706be9b4668c0923788c6a8905fef" category="sidebar">データストアの標準オプション</block>
  <block id="2408eed8aca98d53134097e8990c8225" category="sidebar">ゲスト接続ストレージオプション</block>
  <block id="a64cd881ec955d17faa5e396a891e1e6" category="sidebar">NetApp on Azure （ AVS ）</block>
  <block id="d1b0ccc0fc426266cf228929d5424ce4" category="sidebar">ネットアップ on Google Cloud Platform （ GCVE ）</block>
  <block id="b84034a4ed4e546b39d5bd268ff06eaa" category="sidebar">導入 / ベストプラクティス</block>
  <block id="b0f878715a3d12827d6fb02b0df1f23c" category="sidebar">ネットアップと VMware ：基本事項</block>
  <block id="690359e9e894d87f3144da561090e3f0" category="sidebar">VMware vSphere 管理者向けの NetApp ONTAP のメリット</block>
  <block id="584132370dee3f2fccd2ca59888bee18" category="sidebar">パブリッククラウドで VMware を使用</block>
  <block id="b83c823b7beb8bbe271bd6cc3a2353c7" category="sidebar">エンタープライズハイブリッドクラウド</block>
  <block id="631ed8aac33a641d62d751c3abd77c57" category="sidebar">NetApp for AWS VMC</block>
  <block id="9f5fbecd7c791f090de17716e147c3a5" category="sidebar">NetApp for Azure AVS</block>
  <block id="b2ab132403a71f074bc776eb29725292" category="sidebar">ネットアップの Google Cloud Platform GCVE</block>
  <block id="07a2344d318341cbbdb1983d22dc80f0" category="sidebar">セキュリティデータ保護</block>
  <block id="10e5369e04057873bcce3de87e2c6187" category="sidebar">VMware Site Recovery Manager （ SRM ）と NetApp ONTAP 9</block>
  <block id="eccb6fc5c04122d7aef60d899a77089e" category="sidebar">その他のリソース</block>
  <block id="5e4af7ed70d1a211f16d528dcdfc6474" category="sidebar">Virtual Desktop Solutions の略</block>
  <block id="e281a59ee9a608bff3a3a795963fa1b4" category="sidebar">ハイパースケーラ固有のコンテンツ</block>
  <block id="c2080fddb65ca5c27930e1b56e9001b9" category="sidebar">ネットアップのハイパースケーラクラウドソリューション</block>
  <block id="c894f2bd2f75b76c40354457f85448dd" category="sidebar">ネットアップが AWS 上の VMC に最適です</block>
  <block id="7af96168c530ff4f25450ef6ed33bd95" category="sidebar">Azure を基盤とした AVS 対応のネットアップ</block>
  <block id="3c4ca3bb6cded64b5f69a6e81c8b6a65" category="sidebar">Google Cloud の GCVE 向けネットアップ</block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">このティアストレージのテストでは、プロデューサーワークロードとコンシューマーワークロード向けに、 NetApp StorageGRID セットアップを使用して、 3 ノードから 4 ノードのノードを使用しました。テストによると、完了までの時間とパフォーマンス結果は StorageGRID ノードの数に直接比例しました。StorageGRID セットアップには、少なくとも 3 つのノードが必要でした。</block>
  <block id="2c8105fbc386e60a03fe0cf5390eb0ce" category="inline-link-macro">次は、流暢な 3 コネクタです。</block>
  <block id="40acd085e3c223b35d81906b1c904f46" category="paragraph"><block ref="40acd085e3c223b35d81906b1c904f46" category="inline-link-macro-rx"></block></block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID は、ハイパフォーマンスで対費用効果の高いオブジェクトストレージプラットフォームです。階層型ストレージを使用することで、ローカルストレージやブローカーの SAN ストレージに格納されている ConFluent Kafka にあるデータのほとんどが、リモートのオブジェクトストアにオフロードされます。この構成では、クラスタのリバランシング、拡張、縮小、障害が発生したブローカーの交換にかかる時間とコストを削減することで、運用が大幅に改善されます。オブジェクトストレージは、オブジェクトストア階層にあるデータの管理に重要な役割を果たします。そのため、適切なオブジェクトストレージを選択することが重要です。</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID は、ノードベースの分散グリッドアーキテクチャを使用して、インテリジェントでポリシーベースのグローバルデータ管理を実現します。数ペタバイトの非構造化データと数十億のオブジェクトを、ユビキタスなグローバルオブジェクトネームスペースと高度なデータ管理機能を組み合わせることでシンプルに管理できます。単一コールのオブジェクトアクセスは、サイト間を拡張し、高可用性アーキテクチャを簡素化しながら、サイトやインフラストラクチャの停止に関係なく、オブジェクトへの継続的なアクセスを保証します。</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">マルチテナンシーを使用すると、複数の非構造化クラウドアプリケーションやエンタープライズデータアプリケーションを同じグリッド内で安全に処理できるため、 NetApp StorageGRID の ROI とユースケースが向上します。メタデータベースのオブジェクトライフサイクルポリシーを使用して複数のサービスレベルを作成し、複数の地域にわたるデータの保持、保護、パフォーマンス、ローカリティを最適化できます。ユーザは、データ管理ポリシーを調整し、トラフィック制限を監視および適用して、絶えず変化する IT 環境で要件が変化した場合に備えて、システムを停止することなくデータランドスケープに再調整できます。</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID Grid Manager はブラウザベースのグラフィカルインターフェイスで、世界中に分散された複数のサイトにまたがる StorageGRID システムの設定、管理、監視を、 1 つの画面で実行できます。</block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">StorageGRID グリッドマネージャインターフェイスでは、次のタスクを実行できます。</block>
  <block id="a1d8b1b1990901cd5a97dd0f3dee2da9" category="inline-link-macro">ILM ポリシー</block>
  <block id="37e0a993cc0a3c5aacb623e412befc5b" category="inline-link-macro">ILM ルール</block>
  <block id="0beeefc6ac257658ea119788351ad268" category="paragraph">StorageGRID には、オブジェクトのレプリカコピーを保持し、特定のパフォーマンスおよびデータ保護要件に応じて 2+1 や 4+2 などの EC （イレイジャーコーディング）スキームを使用してオブジェクトを格納するなどの、柔軟なデータ管理ポリシーが用意されています。ワークロードと要件が時間の経過とともに変化する場合、 ILM ポリシーも時間の経過とともに変化する必要があることがよくあります。ILM ポリシーの変更は中核的な機能であり、絶えず変化する環境に StorageGRID のお客様がすばやく簡単に適応できるようにします。を確認してください <block ref="b2ddd4069e5288685e27e7989fb1a613" category="inline-link-macro-rx"></block> および <block ref="7593bc4c70a5537fc14593339f7e6540" category="inline-link-macro-rx"></block> StorageGRID でセットアップする。</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712 、 SG5760 、 SG6060 、 SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID は、ストレージノードを追加することでパフォーマンスを拡張します。ストレージノードには、 VM 、ベアメタル、またはなどの専用アプライアンスを指定できます <block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block>。今回のテストでは、 SGF6024 アプライアンスを使用した最小サイズの 3 ノードグリッドで、 Apache Kafka の主要なパフォーマンス要件を超えました。Kafka クラスタを追加のブローカーとともに拡張すれば、ストレージノードを追加してパフォーマンスと容量を高めることができます。</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">StorageGRID でのトラフィック分類</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID には QoS 機能が組み込まれています。トラフィック分類ポリシーを使用すると、クライアントアプリケーションからのさまざまなタイプの S3 トラフィックを監視できます。次に、ポリシーを作成して適用し、イン / アウト帯域幅、読み取り / 書き込み同時要求の数、または読み取り / 書き込み要求の速度に基づいて、このトラフィックに制限を設けることができます。</block>
  <block id="611f69baa46f691eeeb33645e83f0fcb" category="paragraph">Apache Kafka は、 Java と Scala で書かれたストリーム処理を使用したソフトウェアバスのフレームワーク実装です。リアルタイムデータフィードを処理するための、スループットが高く、低レイテンシの統合プラットフォームを提供することを目的としています。Kafka は外部システムに接続して Kafka Connect からデータをエクスポートし、インポートすることができます。また、 Java のストリーム処理ライブラリである Kafka ストリームが提供されます。Kafka では、効率性を重視して最適化されたバイナリの TCP ベースのプロトコルを使用しています。また、ネットワーク往復のオーバーヘッドを軽減するために、メッセージを自然にまとめてグループ化する「メッセージセット」抽象化に依存しています。これにより、より大規模なシーケンシャルディスク処理や、大容量のネットワークパケット、連続するメモリブロックが実現し、 Kafka では、バースト性の高いランダムメッセージ書き込みをリニア書き込みに変換することができます。次の図は、 Apache Kafka の基本的なデータフローを示しています。</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Apache Kafka のユースケース</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka は、メッセージング、 Web サイトのアクティビティ追跡、指標、ログ集約、ストリーム処理に最もよく使用されています。 イベントのソーシングとロギングのコミット</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka はスループットの向上、組み込みのパーティショニング、レプリケーション、およびフォールトトレランスを実現しており、大規模なメッセージ処理アプリケーションに適した解決策となっています。</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka では、リアルタイムのパブリッシュサブスクライブフィードのセットとして、追跡パイプラインでユーザのアクティビティ（ページビュー、検索）を再構築できます。</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka は、多くの場合、運用監視データに使用されます。これには、分散アプリケーションからの統計情報を集約して、運用データの一元化フィードを作成する作業が含まれます。</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">多くの人が、ログアグリゲーション解決策の代わりに Kafka を使用しています。ログアグリゲーションは、一般にサーバから物理ログファイルを収集して処理のために一元的な場所（ファイルサーバや HDFS など）に配置します。Kafka は、ファイルの詳細を抽象化し、ログやイベントデータをメッセージのストリームとしてより明確に抽象化します。これにより、低レイテンシの処理が可能になり、複数のデータソースと分散データ消費のサポートが容易になります。</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Kafka のユーザの多くは、複数のステージで構成されるパイプラインでデータを処理しています。 Kafka のトピックから生の入力データが消費され、さらに消費やフォローアップ処理のために、集約、エンリッチ化、または新しいトピックへと変換されます。たとえば、ニュース記事を推薦するための処理パイプラインでは、 RSS フィードから記事のコンテンツをクロールし、それを「記事」トピックに公開することができます。さらに処理を行うと、このコンテンツをノーマライズまたは重複排除し、クレンジングされた記事コンテンツを新しいトピックにパブリッシュすることができます。また、最終的な処理段階では、このコンテンツをユーザーに推奨しようとする場合があります。このような処理パイプラインでは、個々のトピックに基づいてリアルタイムのデータフローのグラフが作成されます。</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">イベントソースとは、状態の変化を時系列のレコードとしてログに記録するアプリケーション設計のスタイルです。Kafka は、非常に大容量の格納ログデータをサポートしているため、この形式のアプリケーションのバックエンドとして最適です。</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka は分散システム用の一種の外部コミットログとして機能します。ログはノード間でデータをレプリケートするのに役立ち、障害が発生したノードがデータをリストアする際の再同期メカニズムとして機能します。Kafka のログコンパクション機能は、このユースケースに対応しています。</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="section-title">矛盾する</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Conflicent Platform は、 Kafka を完成させるエンタープライズ対応プラットフォームです。高度な機能を備えており、アプリケーションの開発と接続を高速化し、ストリーム処理による変換を可能にし、大規模なエンタープライズ運用を簡易化し、厳しいアーキテクチャ要件に対応します。ConFluent では、 Apache Kafka を作成した元のクリエイターが開発したサービスを利用して、 Kafka のメリットをエンタープライズクラスの機能で拡張しながら、 Kafka の管理や監視の負担を軽減することができます。現在、 Fortune 100 企業の 80% 以上がデータストリーミングテクノロジを採用しており、そのほとんどが Conluent 社を使用しています。</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">以下の図は、 ConFluent Kafka Platform のコンポーネントを示しています。</block>
  <block id="4f9143a5adb8a0385a1c660d201ef274" category="inline-link-macro">次は、流暢な検証です。</block>
  <block id="d566a24bfcb09090b96a073132a83173" category="paragraph"><block ref="d566a24bfcb09090b96a073132a83173" category="inline-link-macro-rx"></block></block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka は、 1 日に数兆ものイベントを処理できる、コミュニティで分散されたイベントストリーミングプラットフォームです。Kafka は、当初はメッセージングキューとして構築され、分散コミットログの抽象化に基づいています。Kafka は、 2011 年に LinkedIn で作成されオープンソースとなって以来、メッセージキューから本格的なイベントストリーミングプラットフォームへと進化してきました。Confluent Platform で Apache Kafka を配布します。Coneluent Platform は、 Kafka を補完するための追加のコミュニティ機能と商用機能を備えています。これらの機能は、本番環境の運用者と開発者の両方のストリーミングエクスペリエンスを大規模に向上させるように設計されています。</block>
  <block id="e1c012d650a6912ddb72ab0ee914d169" category="paragraph">本ドキュメントでは、次のコンテンツを提供することで、ネットアップのオブジェクトストレージ製品での上位階層型ストレージの使用に関するベストプラクティスのガイドラインについて説明します。</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">ネットアップオブジェクトストレージとの競合検証– NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">階層型ストレージのパフォーマンステスト</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">ネットアップのストレージシステムを使用する場合のベストプラクティスのガイドラインを参照してください</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">階層型ストレージが優れている理由</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">この記事は流暢なものです</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">競合製品は、多くのアプリケーション、特にビッグデータ、分析、ストリーミングワークロードに対応するデフォルトのリアルタイムストリーミングプラットフォームになっています。階層型ストレージを使用すると、ユーザは Conluent プラットフォームのストレージからコンピューティングを分離できます。データをより対費用効果の高い方法で保存し、ほぼ無制限のデータ量を保存し、オンデマンドでワークロードを増減できます。また、データやテナントのリバランシングなどの管理タスクが容易になります。S3 互換のストレージシステムでは、これらすべての機能を活用して、すべてのイベントのデータを 1 箇所で民主化できるため、複雑なデータエンジニアリングは不要です。Kafka に階層化ストレージを使用すべき理由については、を参照してください <block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block>。</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">階層化ストレージに NetApp StorageGRID を使用する理由</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID は、業界をリードするネットアップのオブジェクトストレージプラットフォームです。StorageGRID は、ソフトウェアで定義されるオブジェクトベースのストレージ解決策で、 Amazon Simple Storage Service （ S3 ） API などの業界標準のオブジェクト API をサポートします。StorageGRID は、大規模な非構造化データを格納および管理し、セキュアでデータ保持性に優れたオブジェクトストレージを実現します。コンテンツは適切なタイミングで適切な場所の適切なストレージ階層に配置されるため、グローバルに分散されるリッチメディアのワークフローを最適化し、コストを削減できます。</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">StorageGRID の最大の差別化要因は、ポリシーベースのデータライフサイクル管理を可能にする情報ライフサイクル管理（ ILM ）ポリシーエンジンです。ポリシーエンジンでは、メタデータを使用して、データの有効期間全体の格納方法を管理できます。これにより、最初はパフォーマンスを最適化し、データの経過に応じてコストと保持性を自動的に最適化できます。</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">階層型ストレージを有効にします</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">階層型ストレージの基本的な目的は、データストレージのタスクをデータ処理から分離することです。この分離によって、データストレージ階層とデータ処理階層を別々に拡張しやすくなります。</block>
  <block id="e963c7bc15c18e21f60a9969d876e3e8" category="paragraph">流暢な層ストレージの解決策は、 2 つの要因で競合する必要があります。まず、リスト操作の不整合やオブジェクトを使用できないことがあるなど、一般的なオブジェクトストアの整合性と可用性のプロパティを回避または回避する必要があります。次に、階層型ストレージと Kafka のレプリケーションとフォールトトレランスモデルの間の相互作用を正しく処理する必要があります。これには、ゾンビのリーダーが引き続きオフセット範囲を階層化する可能性も含まれます。ネットアップのオブジェクトストレージは、整合性のあるオブジェクトを使用できるようにするとともに、 HA モデルによって、オフセット範囲を階層化するために使用できるストレージにします。ネットアップのオブジェクトストレージを使用すると、オブジェクトの可用性に一貫性があり、オフセット範囲を階層化するために使用される階層化ストレージには HA モデルが採用されています。</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">階層型ストレージでは、ストリーミングデータの末尾付近での低レイテンシの読み取りや書き込みにハイパフォーマンスプラットフォームを使用できます。また、 NetApp StorageGRID などの低コストで拡張性に優れたオブジェクトストレージを使用して、高スループットの履歴読み取りを実行することもできます。また、ネットアップストレージコントローラを搭載した Spark に関するテクニカル解決策もご用意しています。詳細はこちらをご覧ください。Kafka がリアルタイムの分析パイプラインにどのように適しているかを次の図に示します。</block>
  <block id="c7e421673ed217d2262c482dc24d0995" category="paragraph"><block ref="c7e421673ed217d2262c482dc24d0995" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66b784e6401c98dcf152747d22976bf7" category="paragraph">次の図は、 NetApp StorageGRID が ConFluent Kafka のオブジェクトストレージ層にどのように適合するかを示しています。</block>
  <block id="2c3dbe3ccb3831e313d1d072656fa861" category="inline-link-macro">次の例は、解決策アーキテクチャの詳細です。</block>
  <block id="adcb27f49e58936cf868bc3cc2726dd7" category="paragraph"><block ref="adcb27f49e58936cf868bc3cc2726dd7" category="inline-link-macro-rx"></block></block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">矛盾する検証</block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">NetApp StorageGRID で、 Conluent Platform 6.2 の階層型ストレージを使用して検証を実施しました。ネットアップと流暢なチームがこの検証に協力し、検証に必要なテストケースを実施しました。</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">競合するプラットフォームの設定</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">検証には次のセットアップを使用しました。</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">検証には、 3 台の zookeepers 、 5 台のブローカー、 5 台のテストスクリプトを実行するサーバ、 256GB の RAM を搭載した tools サーバ、 16 個の CPU を使用しました。ネットアップストレージの場合は、 4 つの SGF6024 を搭載した SG1000 ロードバランサで StorageGRID を使用しました。ストレージとブローカーは、 100GbE 接続経由で接続されています。</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">次の図に、流暢な検証に使用される設定のネットワークトポロジを示します。</block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">ツールサーバは、要求をノードに送信するアプリケーションクライアントとして機能します。</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">検証 StorageGRID には HTTP プロトコルを使用しましたが、 HTTPS も使用できます。アクセスキーとシークレットキーは、「 confliclus.tir.s3.cred.file.path 」パラメータで指定したファイル名に格納されます。</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">ネットアップオブジェクトストレージ - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">単一サイト構成を StorageGRID で検証用に設定しました。</block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">検証テスト</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">以下の 5 つの検証ケースを完了しました。これらのテストは、 Trogdor フレームワークで実行されます。最初の 2 つは機能テストで、残りの 3 つはパフォーマンステストです。</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">このテストでは、階層化ストレージのニーズに応じて、オブジェクトストア API のすべての基本的な処理（ GET / PUT / DELETE など）が適切に機能するかどうかを確認します。これは、すべてのオブジェクトストアサービスが次のテストよりも先に実施されることを想定した基本的なテストです。合格または不合格の自己主張的なテストです。</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">このテストでは ' エンド・ツー・エンドの階層型ストレージ機能が ' 合格または不合格のアサート型テストで適切に機能するかどうかを判断しますテストでは、デフォルトで階層化が有効になっており、ホットセットサイズが大幅に縮小されたテストトピックが作成されます。新しく作成されたテストトピックへのイベントストリームが生成され、ブローカーがセグメントをオブジェクトストアにアーカイブするのを待機し、イベントストリームを消費して、消費されたストリームが生成されたストリームと一致することを検証します。イベントストリームに生成されるメッセージの数は設定可能で、テストのニーズに応じてユーザが十分な大きさのワークロードを生成できます。ホットセットのサイズを小さくすることで、消費者がアクティブなセグメントの外部でフェッチしたファイルはオブジェクトストアからのみ提供されます。これにより、オブジェクトストアの読み取りの正確性をテストできます。このテストは、オブジェクトストアフォールト挿入の有無にかかわらず実施しました。StorageGRID のいずれかのノードでサービスマネージャサービスを停止し、エンドツーエンド機能がオブジェクトストレージで機能することを検証することで、ノード障害をシミュレートしました。</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">ワークロードベンチマークを消費</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">このテストでは、セグメントをアーカイブすることにより、オブジェクトストアへの書き込みワークロードを間接的に生成しました。コンシューマグループがセグメントを取得すると、読み取りワークロード（セグメント読み取り）がオブジェクトストレージから生成されました。このワークロードはテストスクリプトで生成されました。このテストでは、並列スレッドでのオブジェクトストレージの読み取りと書き込みのパフォーマンスをチェックしました。階層化機能の正確性テストと同様に、オブジェクトストアフォールト挿入を使用したテストと使用しなかったテストを実施しました。</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">保存ワークロードベンチマーク</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">このテストでは、トピックの保持ワークロードが多い場合のオブジェクトストアの削除パフォーマンスを確認しました。保持ワークロードは、テストトピックと並行して多数のメッセージを生成するテストスクリプトを使用して生成されました。テストトピックでは、サイズベースおよび時間ベースの強力な保持設定を使用してイベントストリームをオブジェクトストアから継続的にパージするように設定しました。その後、セグメントがアーカイブされました。その結果、ブローカーによるオブジェクトストレージの削除や、オブジェクトストアの削除処理のパフォーマンス収集が行われ、大量の削除が発生していました。</block>
  <block id="0c7a4422707cf3f11c73c66ea0d5d215" category="inline-link-macro">前のバージョン：サイジング</block>
  <block id="f902aefc255b4eb6b31c283ad42816de" category="paragraph"><block ref="f902aefc255b4eb6b31c283ad42816de" category="inline-link-macro-rx"></block></block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">このドキュメントでは、検証テスト、階層型ストレージのパフォーマンス結果、調整、 S3 コネクタの堪能、セルフバランシング機能など、ネットアップストレージでの Conluent Tiered Storage の使用に関するベストプラクティスを紹介しています。ILM ポリシー、検証のための複数のパフォーマンステストと業界標準の S3 API を使用した流暢なパフォーマンスを考慮した場合、 NetApp StorageGRID オブジェクトストレージは流暢な階層化ストレージに最適な選択肢です。</block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Conluent Platform の無限のストレージ</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">競合する階層型ストレージ - ベストプラクティスとサイジング</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Conluent Platform 用の Amazon S3 シンクコネクタ</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Kafka のサイジング</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">StorageGRID のサイジング</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Kafka のユースケース</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">統合されたプラットフォーム 6.0 の自律分散 Kafka クラスター</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="a5091aedd97daf7c5a5297fa5d73a469" category="cell">2021 年 12 月</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">競合する自己バランシングクラスタ</block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">Kafka クラスタを以前に管理していたことがある場合、パーティションを別のブローカーに手動で再割り当てすることで、ワークロードがクラスタ全体に分散されるようにするという問題に慣れている方がよいでしょう。Kafka を大規模に導入している組織では、大容量のデータを変更するのが難しく、面倒でリスクが伴う可能性があります。特に、ミッションクリティカルなアプリケーションをクラスタの上に構築する場合、リスクが高くなります。しかし、 Kafka を使用するケースが最小であっても、処理に時間がかかり、人為的ミスが発生しやすくなります。</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">このラボでは、流暢な自己分散クラスタ機能をテストし、クラスタトポロジの変更や不均衡な負荷に基づいてリバランシングを自動化しました。一括リバランシングテストは、ノード障害や拡張ノードでブローカー間のデータのリバランシングが必要になった場合に、新しいブローカーを追加する時間を測定するのに役立ちます。従来の Kafka 構成では、クラスタの拡張に合わせてデータの再分散量が増える一方で、階層型ストレージでは少量のデータしかリバランシングされません。この検証に基づき、階層型ストレージのリバランシングには数秒から数分かかりますが、従来の Kafka アーキテクチャでは、クラスタの拡張に伴ってリニアに拡張されます。</block>
  <block id="c9e4cfc44588cc591252c88cad0a3a09" category="paragraph">セルフバランシングクラスタでは、パーティションの再調整が完全に自動化され、 Kafka のスループットが最適化され、ブローカーの拡張が高速化され、大規模なクラスタを実行する際の運用上の負担が軽減されます。安定した状態では、自己バランシングクラスタがブローカー間のデータのスキューを監視し、パーティションを継続的に再割り当てしてクラスタのパフォーマンスを最適化します。プラットフォームをスケールアップまたはスケールダウンすると、新しいブローカーが存在することを自己分散クラスタが自動的に認識したり、古いブローカーが削除されたことを確認したり、後続のパーティションの再割り当てをトリガーしたりします。これにより、ブローカーの追加や運用停止が容易になり、 Kafka クラスタの柔軟性が根本的に向上します。これらの利点は、手動操作、複雑な計算、またはパーティションの再割り当てが一般的に発生する人的ミスのリスクを必要としないことです。その結果、データのリバランシングが完了するまでの時間が大幅に短縮され、クラスタを常時監視するのではなく、価値の高いイベントストリーミングプロジェクトに集中できます。</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">サイジング</block>
  <block id="5ffdfbbb428796f516e072e038d107b0" category="inline-link-macro">Previous ：ベストプラクティスのガイドライン</block>
  <block id="49575973ec85e64724d2a45d401f32b3" category="paragraph"><block ref="49575973ec85e64724d2a45d401f32b3" category="inline-link-macro-rx"></block></block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Kafka サイジングは、シンプル、きめ細かい、リバース、およびパーティションの 4 つの構成モードで実行できます。</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">シンプル</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">シンプルモードは、 Apache Kafka を初めて使用するユーザや初期状態のユースケースに適しています。このモードでは、スループット MBps 、読み取りファンアウト、保持、リソース利用率（デフォルトは 60% ）などの要件を指定します。オンプレミス（ベアメタル、 VMware 、 Kubernetes 、 OpenStack ）やクラウドなどの環境にも移行できます。Kafka クラスタのサイジングは、この情報に基づいて、ブローカーに必要なサーバ数、 Zookeeper 、 Apache Kafka Connect Workers 、スキーマレジストリ、 REST プロキシ、 ksqlDB 、および Conluent コントロールセンターを提供します。</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">階層型ストレージの場合、 Kafka クラスタのサイジングのためのきめ細かい構成モードを検討してください。Granular モードは、経験豊富な Apache Kafka ユーザや明確に定義されたユースケースに適しています。このセクションでは、プロデューサ、ストリームプロセッサ、およびコンシューマのサイジングについて説明します。</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">プロデューサー</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Apache Kafka の開発者（ネイティブクライアント、 REST プロキシ、 Kafka コネクタなど）については、次の情報を参照してください。</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">* 名前。 * Spark 。</block>
  <block id="0ae6d6b48753e01bf1ae73bb86ee6276" category="list-text">* 開発者の種類。 * アプリケーションまたはサービス、プロキシ (REST 、 MQTT 、その他 ) 、および既存のデータベース (RDBMS, NoSQL 、その他 ) 。「わからない」を選択することもできます。</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">* 平均スループット。 * 1 秒あたりのイベント数（ 1 、 000 、 000 など）。</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">* 最大スループット。 * 1 秒あたりのイベント数（ 4 、 000 、 000 など）。</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">* 平均メッセージサイズ。 * バイト単位、非圧縮（最大 1MB 、 1000 など）。</block>
  <block id="dd6d45bc2ad71619bde2260f1776e9b2" category="list-text">* メッセージ形式。 * Avro 、 JSON 、プロトコルバッファ、バイナリ、テキスト、 「わからない」など。</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">* 複製係数 * オプションは 1 、 2 、 3 （流暢な推奨）、 4 、 5 です。 または 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">* 保持時間。 * 1 日（例：）。Apache Kafka にデータを保存しておく期間を教えてください。無期限には、任意の単位で -1 を入力します。無制限の保持期間を 10 年と想定しています。</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">[ ブローカー数を減らし、 Infinite Storage を許可するための階層化ストレージを有効にする ] のチェックボックスをオンにします。</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">階層型ストレージが有効になっている場合は ' リテンションフィールドによって ' ブローカにローカルに保存されるデータのホットセットが制御されますアーカイブ保持フィールドは、アーカイブオブジェクトストレージにデータを格納する期間を制御します。</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">* アーカイブ・ストレージの保存期間 * 1 年（例：）データをアーカイブストレージに保存する期間無期限の任意の単位を指定して -1 を入力します。無制限の保持期間を 10 年と想定しています。</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">* 成長乗数 * 1 （例：）。このパラメータの値が現在のスループットに基づく場合は、 1 に設定します。追加の増加に基づいてサイズを決定するには、このパラメータに増加率を設定します。</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">* プロデューサーインスタンスの数。 * 10 （例：）実行されるプロデューサーインスタンスの数はいくつですか？この値は、 CPU 負荷をサイジング計算に含めるために必要です。空白の値は、 CPU 負荷が計算に組み込まれていないことを示します。</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">この入力例に基づいて、サイジングはプロデューサーに次のように影響します。</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">非圧縮バイト単位の平均スループット： 1Gbps圧縮されていないバイト数のピークスループット： 4Gbps圧縮されたバイト数の平均スループット： 400MBps 。圧縮バイトの最大スループット： 1.6GBps 。デフォルトの 60% の圧縮率に基づいています（この値は変更できます）。</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">必要なホットセットストレージの合計数 :31 、 104TB ( レプリケーションを含む ) 、圧縮。必要なオフブローカーアーカイブストレージの合計： 378 、 432TB 、圧縮使用 <block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> StorageGRID のサイジングの場合：</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">Stream Processors は、 Apache Kafka のデータを使用し、 Apache Kafka に生成するアプリケーションまたはサービスを記述する必要があります。ほとんどの場合、これらは ksqlDB ストリームまたは Kafka ストリームで構築されます。</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">* 名前。 * Spark streamer 。</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">* 処理時間。 * このプロセッサーは 1 つのメッセージを処理するのにどれくらいかかりますか？</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 ミリ秒（シンプルでステートレスな変換）（例）、 10 ミリ秒（ステートフルなメモリ内動作）</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100ms （ステートフルネットワークまたはディスク処理）、 1000ms （サードパーティ製 REST コール）</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">このパラメータをベンチマークして、その所要時間を正確に把握しました。</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">* 出力保持 * 1 日（例）ストリームプロセッサは Apache Kafka に出力を返します。この出力データを Apache Kafka にどれくらいの期間保存しますか？無期限の任意の単位を指定して -1 を入力します。</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">［ ブローカー数を減らし、 Infinite Storage を許可するには、 ［ 階層型ストレージを有効にする ］ チェックボックスをオンにします。</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">* アーカイブ・ストレージの保存期間 * 1 年（例：）データをアーカイブストレージに保存する期間無期限の任意の単位を指定して -1 を入力します。無制限の保持期間を 10 年と想定しています。</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">* 出力パススルー率。 * 100 （例：）ストリームプロセッサは Apache Kafka に出力を返します。Apache Kafka に出力されるインバウンドスループットの割合を教えてください。たとえば、インバウンドスループットが 20Mbps で、この値が 10 の場合、出力スループットは 2Mbps になります。</block>
  <block id="d1a6a4732f959b58cd8c77edcf10b31b" category="list-text">この機能はどのアプリケーションから読み取られますか。「 Spark 」を選択すると、販売担当者タイプに基づいたサイジングで使用された名前になります。上記の入力に基づいて、ストリームプロセッサインスタンスとトピックパーティションの推定にサイジングを行うと、次のような効果が期待できます。</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">このストリームプロセッサアプリケーションには、次の数のインスタンスが必要です。受信するトピックでは、多くのパーティションが必要になる場合があります。このパラメータを確認するには、 [ 流暢 ] に連絡してください</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">平均スループットで 1 、 000 、増加率なし</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">4 、 000 ：増加率のないピークスループット</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1 、 000 ：平均スループットと増加率</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">4 、 000 ：最大スループットで増加率</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">消費者</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Apache Kafka のデータを利用していて、 Apache Kafka にデータを生成していないアプリケーションやサービスについて説明してください。たとえば、ネイティブのクライアントや Kafka Connector などです。</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">* 名前 . * Spark consumer 。</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">* 処理時間。 * この消費者は、 1 つのメッセージを処理するのにどれくらいの時間がかかりますか。</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 ミリ秒（シンプルでステートレスなロギングなどのタスク）</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 ミリ秒（データストアへの高速書き込み）</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 ミリ秒（データストアへの書き込み速度が遅い）</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000 ミリ秒（サードパーティの REST コール）</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">その他のベンチマークされたプロセスの中には、既知の期間があります。</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">* 消費者タイプ。 * アプリケーション、プロキシ、シンクを既存のデータストア（ RDBMS 、 NoSQL など）に。</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">この機能はどのアプリケーションから読み取られますか。このパラメータは、以前に決定したプロデューサーおよびストリームのサイジングを使用して接続します。</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">上記の入力に基づいて、コンシューマインスタンスとトピックパーティションの推定サイズを決定する必要があります。コンシューマアプリケーションには、次の数のインスタンスが必要です。</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">平均スループットで 2 、 000 、増加率はゼロ</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">8 、 000 ：ピークスループットで、増加率はゼロです</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">平均スループットで 2 、 000 、増加率も含まれます</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">8 、 000 ：最大スループット。増大の乗数も含まれます</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">受信トピックでは、この数のパーティションも必要になる場合があります。確認のため、流暢な連絡をします。</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">生産者、ストリームプロセッサ、および消費者の要件に加えて、次の追加要件を提供する必要があります。</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">* 再構築時間。 * 例： 4 時間。Apache Kafka ブローカーホストで障害が発生すると、そのデータは失われ、障害が発生したホストと交換するために新しいホストをプロビジョニングすると、この新しいホストをどのくらいの速さで再構築する必要がありますか？値が不明な場合は、このパラメータを空白のままにします。</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">* リソース使用率目標（パーセンテージ）。 * 例： 60 。平均スループット中にホストをどの程度使用しますか？Conluent の自己バランシングクラスタを使用していない場合は、 60% の使用率を推奨します。この場合、使用率が高くなります。</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">環境の説明</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">* どの環境でクラスターを実行しますか？ * Amazon Web Services 、 Microsoft Azure 、 Google クラウドプラットフォーム、オンプレミスのベアメタル、 VMware オンプレミス、 OpenStack をオンプレミスで運用するのか、 Kubernates をオンプレミスで運用するのか</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">* ホストの詳細。 * コアの数： 48 （例：）、ネットワークカードのタイプ（ 10GbE 、 40GbE 、 16GbE 、 1GbE 、またはその他のタイプ）。</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">* ストレージボリューム。 * ホスト： 12 （例：）。ホストあたりのハードドライブまたは SSD の数はいくつですか。競合するホストごとに 12 台のハードドライブを推奨します。</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">* ストレージ容量 / ボリューム（ GB 単位）。 * 1000 （例：）。1 つのボリュームストアでギガバイト単位のストレージ容量はどれくらいですか？競合する場合は 1TB のディスクを使用します。</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">* ストレージ構成 * ストレージ・ボリュームの構成方法競合製品は、 Conluent のすべての機能を活用するために RAID10 を推奨しています。JBOD 、 SAN 、 RAID 1 、 RAID 0 、 RAID 5 、 その他のタイプもサポートされています。</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">* 単一ボリュームのスループット（ Mbps ）。 * 125 （例：）1 つのストレージボリュームで 1 秒あたりのメガバイト数で読み取りまたは書き込みを行うことができる速度はどれくらいですか。競合するハードディスクドライブは、通常 125 Mbps のスループットを持つ標準ハードディスクドライブをお勧めします。</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">* メモリ容量（ GB ）。 * 64 （例）。</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">環境変数を決定したら、 Size my Cluster （マイクラスタのサイズ）を選択します。前述の例に基づいて、 Con裕福 な Kafka のサイジングを決定しました。</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">* Apache Kafka * Broker count ： 22 。クラスタはストレージバウンドです。階層型ストレージを有効にして、ホスト数を減らし、ストレージを無制限にすることを検討してください。</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">* Apache ZooKeeper. * Count ： 5 ； Apache Kafka Connect Workers ： Count ： 2 ； Schema Registry ： Count ： 2 ； REST Proxy ： Count ： 2 ； ksqlDB ： Count ： 2 ； Conluent Control Center ： Count ： 1 。</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">ユースケースを考慮せずに、プラットフォームチームにリバースモードを使用する。パーティションモードを使用して、 1 つのトピックに必要なパーティションの数を計算します。を参照してください<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> リバースモードとパーティションモードに基づいたサイジングの場合</block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">検証に基づくと、 S3 オブジェクトストレージにはデータを格納するのがベストプラクティスです。</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">高スループットの SAN （特に FC ）を使用して、ブローカーのホットデータやローカルディスクを保持できます。これは、階層型ストレージの構成が流暢であるためです。 ブローカーデータディレクトリに格納されているデータのサイズは、オブジェクトストレージにデータが移動される際のセグメントサイズと保持時間に基づいています。</block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">* Kafka のチューニング。 * 階層型ストレージのパフォーマンスを向上させるには、 TierFetcherNumThreads と TierArchiverNumThreads を増やします。一般的なガイドラインとして、 TierFetcherNumThreads を増やして物理 CPU コア数に合わせ、 TierArchiverNumThreads を CPU コア数の半分に増やします。たとえば、サーバープロパティで、 8 つの物理コアを持つマシンがある場合、 conflicent.tier.fetcher.threads=8 と、 conflicent.tier.Archiver .num.threads=4 を設定します。</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">* トピックが削除されるまでの時間です。 * トピックが削除されると、オブジェクトストレージ内のログセグメントファイルの削除はすぐには開始されません。デフォルト値の 3 時間を指定した時間間隔が設定されているため、この時間が経過するとファイルが削除されます。この間隔の値を変更するには、設定 confluent.tier.topic.delete.check.interval.ms を変更します。トピックまたはクラスタを削除する場合は、それぞれのバケット内のオブジェクトを手動で削除することもできます。</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">* 階層型ストレージの内部トピックに関する ACL 。 * オンプレミス環境に推奨されるベストプラクティスは、階層型ストレージに使用される内部トピックについて、 ACL 承認者を有効にすることです。このデータへのアクセスをブローカーユーザのみに制限するには、 ACL ルールを設定してください。これにより、内部トピックが保護され、階層化されたストレージデータおよびメタデータへの不正アクセスを防止できます。</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">ユーザ「 &lt;Kafka&gt; 」を、導入環境の実際のブローカプリンシパルに置き換えます。</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">たとえば ' コマンド confliclus-tier-state は ' 階層型ストレージの内部トピックに ACL を設定します現在、階層化ストレージに関連する内部トピックは 1 つだけです。この例では、内部トピックのすべての処理にプリンシパル Kafka 権限を提供する ACL を作成しています。</block>
  <block id="c7aa1f1ea2c8ad1712056dd97321d808" category="inline-link-macro">次：サイジング</block>
  <block id="de8a38c4c90ce81d8c4b82c44500e504" category="paragraph"><block ref="de8a38c4c90ce81d8c4b82c44500e504" category="inline-link-macro-rx"></block></block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">このセクションでは、流暢な検証に使用するハードウェアおよびソフトウェアについて説明します。この情報は、ネットアップストレージを使用した流暢なプラットフォームの導入に該当します。次の表に、テストに使用した解決策アーキテクチャと基本コンポーネントを示します。</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">5 台のツールサーバ</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">階層化ストレージ向けの NetApp StorageGRID</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">StorageGRID ソフトウェア</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">SGF6024 × 4</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">100GbE × 4 （ブローカーと StorageGRID インスタンス間のネットワーク接続）</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">矛盾点 3 コネクタ</block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Amazon S3 Sink Connector は、 Apache Kafka のトピックから Avro 、 JSON 、またはバイト形式の S3 オブジェクトにデータをエクスポートします。Amazon S3 シンクコネクタは、 Kafka から定期的にデータをポーリングし、 S3 にアップロードします。ユーザは、各 Kafka パーティションのデータをチャンクに分割するために使用します。データのチャンクはそれぞれ S3 オブジェクトとして表されます。キー名は、トピック、 Kafka パーティション、およびこのデータチャンクの開始オフセットをエンコードします。</block>
  <block id="e621a272d292cd32516db52fc07b5855" category="inline-link-macro">次は、流暢な自己リバランシングクラスタです。</block>
  <block id="56b9b2115a3169192950ec86c26f6add" category="paragraph"><block ref="56b9b2115a3169192950ec86c26f6add" category="inline-link-macro-rx"></block></block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">自己リバランシングクラスタが競合しています</block>
  <block id="a02c6dbd226d5506c1b4b07f6d383615" category="list-text">「 -parallel 」オプションを指定した XCP コピーは、 CPU の数に基づいています。ほとんどの XCP データ転送および移行処理には、デフォルトのパラレルスレッド数（ 7 ）で十分な場合があります。XCP Windows のデフォルトでは、並列プロセスの数は CPU の数と同じです。「 -parallel 」オプションの最大数は、コア数以下にする必要があります。</block>
  <block id="740950b0e27cdd5def3c4295d5840851" category="list-text">データ転送の開始には 10GbE が適しています。ただし、 25GbE と 100GbE でテストした結果、データ転送が向上し、大容量のファイルサイズのデータ転送に推奨されています。</block>
  <block id="ef1ee9d1f1e9874aca751251bbce31bf" category="inline-link-macro">前：流暢な検証。</block>
  <block id="6d08115c54837de983d3ddc9dcd8f038" category="paragraph"><block ref="6d08115c54837de983d3ddc9dcd8f038" category="inline-link-macro-rx"></block></block>
  <block id="d7023badac36eeb28bf29785a97c493c" category="inline-link-macro">前のバージョン：解決策アーキテクチャの詳細。</block>
  <block id="258ee3f437d6a20985ccf4e13065a097" category="paragraph"><block ref="258ee3f437d6a20985ccf4e13065a097" category="inline-link-macro-rx"></block></block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam 、 Joseph Kandatilparamil 、 NetApp Rankesh Kumar 、 Conluent</block>
  <block id="524a5aa4f422c84af378b5418bb1539b" category="inline-link-macro">前：流暢な自己リバランシングクラスタ。</block>
  <block id="ae7f441436d5c9a5dc4278e4ea2b87e8" category="paragraph"><block ref="ae7f441436d5c9a5dc4278e4ea2b87e8" category="inline-link-macro-rx"></block></block>
  <block id="b583dc49832a978014ef0d14fe7ef1ce" category="paragraph">ワークフローの移行、クラウドへの拡張 / バースト対応、バックアップ / リストア、ディザスタリカバリなど、ネットアップが各ハイパースケーラに VMware 環境を提供するソリューションの詳細については、こちらをご覧ください。</block>
  <block id="2c3412ea249289d455415fc5974540d7" category="paragraph">次のマトリックスは、各ハイパースケーラとネットアップストレージオプションの解決策のユースケースを定義したものです。目的のセルの詳細をクリックすると、解決策の詳細が表示されます。</block>
  <block id="205549244e00d8fc3aed42cc242b6e66" category="open-title">AWS （ VMC ）</block>
  <block id="7fb61d6790786c6584895ba13b1d7acf" category="cell">* ユースケース *</block>
  <block id="5e6a9c7508fcb882686fb57577c20564" category="cell">クラウドへのバックアップ</block>
  <block id="fca9cd52865f9c45b9c1c0810944323a" category="cell">クラウドへの DR</block>
  <block id="1f7519825c9e66f611f1b8a2dfab6d98" category="cell">開発 / テスト</block>
  <block id="03a85053364f989565c431e1f3cb14b6" category="cell">バースト時にクラウドを活用</block>
  <block id="520a0900399ea06bc457dd365ce39b56" category="cell">クラウドに移行</block>
  <block id="1d8b77813302d5fc10b4a01c9d1f71ba" category="open-title">Azure （ AVS ）</block>
  <block id="f06436d87956805c42a72d20c6e0c6aa" category="cell">* ANF *</block>
  <block id="a060ea40d8e1f38832adc8dab3110308" category="cell">* CVO*</block>
  <block id="7896a48b4cb2f9b6d3c3612c0b5a8886" category="open-title">Google （ GCVE ）</block>
  <block id="cb56c4671d6ec2da0b5f3b248999cba7" category="cell">* CVS *</block>
  <block id="e79592580385a4ae403f3655a7200469" category="paragraph">ネットアップストレージは、現在、主要なすべてのハイパースケーラクラウドでプライベートプレビューとして提供されています。詳細については、次のリンクを参照してください。</block>
  <block id="bb747e48aa1d3d3e7f7770860486da18" category="inline-link-macro">AWS のネイティブデータストアとしての FSX ONTAP</block>
  <block id="0e8dc2a599bea7faae9351c694a4f162" category="inline-link-macro">Azure のネイティブデータストアとしての Azure NetApp Files （ ANF</block>
  <block id="3e6b003f71badaeb92ae26f7ed351a37" category="inline-link-macro">GCP のネイティブデータストアとしての Cloud Volumes Service （ CVS ）</block>
  <block id="5ab63999a01c682c3e901f550611531f" category="paragraph"><block ref="6b7315f1b0dd5562c105ae89b6efa525" category="inline-link-macro-rx"></block>
<block ref="730b198f919befec53ca8dcebabd176b" category="inline-link-macro-rx"></block>
<block ref="7fb3f61cbe4dcbff12c3d3e4fb2e9565" category="inline-link-macro-rx"></block></block>
  <block id="bf3f0fd9ec5faf81793c3abc5e3b9127" category="admonition">この環境ゲスト接続ストレージのみ。</block>
  <block id="8ad188089680179dea816084001d7bf0" category="sidebar">AI と分析のワークフローに対応した E シリーズと BeeGFS を使用したデータ移動</block>
  <block id="af4c57809e604bab0cdf9a5ac5766ac8" category="cell">* ESXi の高度な設定 *</block>
  <block id="0fef419d5842ff81bf9c9046c637822c" category="inline-link-macro">2007427</block>
  <block id="f812302694bd63641124f6012aebac60" category="cell">そのままにします（ VMware のデフォルトは 0 ですが、 VMFS6 では必要ありません）。詳細については、 VMware の技術情報アーティクルを参照してください <block ref="25cd71618ac903bfc347baf53ab838b7" category="inline-link-macro-rx"></block>。</block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">* NFS 設定 *</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">* FC / FCoE 設定 *</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">* iSCSI 設定 *</block>
  <block id="3b1dbad34c6f708a2653d9c6ae15b15d" category="doc">解決策自動化の新機能</block>
  <block id="120c02d2aa6cda1e3b75902fb4fc0b53" category="doc">ハイブリッドクラウド、デスクトップ仮想化、コンテナソリューションの新機能</block>
  <block id="54998e7855609864b7a05e49355662b5" category="doc">ビジネスアプリケーションとエンタープライズデータベースソリューションの新機能</block>
  <block id="9db3527848e891e0a9340c443515e770" category="doc">ネットアップと VMware のソリューションを今すぐ始めましょう</block>
  <block id="f1e09e8062c8a1cddb6f2f68289ea71b" category="doc">ONTAP for VMware Virtualization の新機能</block>
  <block id="3d94edd87fc615dfe301c7233c56c6c3" category="doc">AI と最新のデータ分析の新機能</block>
  <block id="d035e5417fa83f8b48e9410b914d70ed" category="doc">データ保護およびセキュリティソリューションの新機能</block>
  <block id="c4c3630750312520bc4b93c16056bfd7" category="doc">NVIDIA を使用した NetApp EF シリーズ AI</block>
  <block id="e6ee072aeeb0647d8c0cfe75e4cde51d" category="paragraph">ネットアップと NVIDIA が提供する EF シリーズ AI 統合インフラソリューションの概要</block>
  <block id="f512fcc18626023378bfe28dce07116d" category="list-text"><block ref="f512fcc18626023378bfe28dce07116d" category="inline-link-macro-rx"></block></block>
  <block id="ae02a3224f15623423f197426c44a26d" category="list-text"><block ref="ae02a3224f15623423f197426c44a26d" category="inline-link-macro-rx"></block></block>
  <block id="8ce1a272bf4c47418ea6d69083f2df4f" category="inline-link-macro">BeeGFS 導入ガイド</block>
  <block id="7991adac41b3f0e292dee61e87c39052" category="list-text"><block ref="7991adac41b3f0e292dee61e87c39052" category="inline-link-macro-rx"></block></block>
  <block id="9d2ca817bb7dd69d6f7dc09932a53524" category="summary">ネットアップの人工知能ソリューションは、 AI / ML 分野全体でネットアップストレージの機能を実証する、戦略的かつ技術的なソリューションのセットです。</block>
  <block id="b54a1e289898cf21f63715dfe64025b7" category="doc">ネットアップの人工知能ソリューション</block>
  <block id="2bbac71d034e7a7a1fca44c7500e187b" category="doc">NVIDIA を使用した NetApp ONTAP AI</block>
  <block id="4618b9225719de309c0b0f5aa4718c7b" category="paragraph">ネットアップと NVIDIA が提供する ONTAP AI 統合インフラソリューションの概要</block>
  <block id="ab9d770eb05e7725141740f508566fce" category="section-title">NVIDIA DGX A100 システムを搭載した NetApp ONTAP AI</block>
  <block id="7c962be0dc8fdf28c1c4279fe5256a22" category="section-title">NVIDIA DGX A100 システムと Mellanox を搭載した NetApp ONTAP AI Spectrum Ethernet スイッチ</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">英語</block>
  <block id="37ce0afb395b0346118a74c4f05f20a7" category="list-text"><block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block>&amp;f ： @face_souction _mktg= [AI 、分析、人工知能 ] + [AI blogs on NetApp.com ]</block>
  <block id="706e736fcad235c710eab30a42b219b1" category="cell">* NVIDIA DGX A100 システムと BeeGFS * を搭載した EF シリーズ AI</block>
  <block id="ec690c5998518cfa45b178a530da4125" category="cell">* Lenovo ThinkSystem を使用したエッジネットアップでの AI 推論 *</block>
  <block id="b1d14722f1d9c668c677c2c7f22cfcc6" category="cell"><block ref="b1d14722f1d9c668c677c2c7f22cfcc6" category="inline-link-macro-rx"></block></block>
  <block id="aa84da6cfda7179db9bbd5f34addb637" category="cell">* NetApp AI による感情分析 *</block>
  <block id="7a25f90f4eb7f4d051b5e2903cea9546" category="cell"><block ref="7a25f90f4eb7f4d051b5e2903cea9546" category="inline-link-macro-rx"></block></block>
  <block id="f48991e4773d2a30dd01c029e22e3f32" category="cell">* クリックスルーレート予測 - Azure * での分散トレーニング</block>
  <block id="2b48b8a77ebec6ee8be0f1146585b7c3" category="cell"><block ref="2b48b8a77ebec6ee8be0f1146585b7c3" category="inline-link-macro-rx"></block></block>
  <block id="191ea533aa1478d35c965840430fbfe6" category="summary">ネットアップの最新データ分析ソリューションは、 AI 環境全体でネットアップストレージの機能を実証する、戦略的およびテクノロジ的な機能のセットです。</block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="doc">ネットアップの最新データ分析ソリューション</block>
  <block id="22169240c9a4c0ab61a4ed13c981c5ef" category="sidebar">AI ワークロード向けの統合インフラ</block>
  <block id="8508ab1994a5679882beb6400778e8ba" category="sidebar">NVIDIA を使用した EF シリーズ AI</block>
  <block id="ec820f861118408d42b077dbf109f374" category="sidebar">NetApp E シリーズストレージを使用した IBM Spectrum Scale</block>
  <block id="b63ada7ec650c01320cddeda05deb779" category="sidebar">Lenovo ThinkSystem を使用したエッジネットアップでの AI 推論</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">AI 向け NetApp ONTAP および Lenovo ThinkSystem SR670</block>
  <block id="e5c3eeefe82172631e21562a8d3672a5" category="sidebar">AI 向け NetApp AFF A800 および富士通サーバ PRIMERGY GX2570 M5</block>
  <block id="2fa3e2a0ff5682666455eed0a7b1b569" category="sidebar">データレイクとデータパイプライン</block>
  <block id="6ac39037a7efa2708d15c0e0e20fb188" category="sidebar">自動運転ワークロードのための StorageGRID データレイク</block>
  <block id="eeb4980c2a89f07abf1a0b927066b23c" category="sidebar">AI に対応した E シリーズと BeeGFS を使用したデータ移動</block>
  <block id="13f985aafb32ac9e387186e5a437f96e" category="sidebar">データキャッシング機能を備えたハイブリッドクラウド AI</block>
  <block id="ac82c7a9ef13f3b604553ccfe1a5bd76" category="sidebar">オーケストレーションと管理</block>
  <block id="3cd04d0e6cf45786c9e94148f213b537" category="sidebar">NetApp AI コントロールプレーンを使用して、 AI パイプラインとワークスペースオーケストレーションを実現</block>
  <block id="447e8e0102d91009c125adb678cd7fb5" category="sidebar">Iguazio による MLRun パイプライン</block>
  <block id="71e6eb0dc5951ca93effe179d000f534" category="sidebar">感情分析</block>
  <block id="cfff43e76ea0e95d290a279bdb279a2e" category="sidebar">クリックスルーレート予測 - Azure での分散トレーニング</block>
  <block id="29931fafbbc65eabe1029aee9a3a5a85" category="sidebar">LANE 検出 - Azure の分散トレーニング</block>
  <block id="7656ac1f9ee1e1763f07a285578d922a" category="sidebar">NVIDIA Jarvis を使用した会話型 AI</block>
  <block id="8f0148532a5b5382ec4f005c8a96a4fa" category="sidebar">自動運転</block>
  <block id="f869ce5572b45e50fe014954c4248d60" category="sidebar">ヘルスケア - Diagnostic Imaging （診断イメージング）</block>
  <block id="951b9c6690c2a4c1228ada2a9980d5a8" category="sidebar">クレジットカード詐欺検出</block>
  <block id="f0b83f1f7d211bfb4e278dafd2d6b4fa" category="sidebar">NetApp Storage 解決策を使用した Apache Spark ワークロード</block>
  <block id="6bf79bc16e8a34cf5698aabd27cecef1" category="sidebar">最新のデータ分析解決策の概要</block>
  <block id="cd47dd01745339787e4c7300389401f2" category="sidebar">ベストプラクティス</block>
  <block id="1bd369d8fc8172d625ac41a1815aa09d" category="sidebar">ConFluent Kafka のベストプラクティスです</block>
  <block id="3ed3645b4e41749082a0692a758a3132" category="sidebar">ハイブリッドクラウドソリューション - Spark と Hadoop のユースケース</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">ブログ： Use XCP for Data Migration from a Data Lake and HPC to ONTAP NFS</block>
  <block id="9cb9fe27a24f987a1889d5fc1d5d139e" category="sidebar">『 NetApp E-Series Deployment Guide 』を参照して BeeGFS を導入します</block>
  <block id="d064ecad73d9352507092f40af924057" category="cell">02/02/2022</block>
  <block id="c0598da0ea2338576f8d67854c56e3f6" category="cell">ランディングページを作成し、 AI と最新のデータ分析のためのコンテンツをより効率的に整理</block>
  <block id="84c45df200c907852c1e92875618b432" category="cell">2022 年 1 月 22 日</block>
  <block id="b385810d0a927b9d15a69218e3fb38c4" category="cell">TR ： AI と分析のワークフローに対応する E シリーズと BeeGFS を使用したデータ移動を追加</block>
  <block id="89d5e6802ef5a3ae4296f49d4d6bc447" category="sidebar">その他のリソース</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">ブログ： Apache Spark は NetApp Data Analytics Playground で再生されます</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV ： Big Data Analytics プレイリスト</block>
  <block id="0a2866cc3e2ba203c7e2e3ebeca395be" category="sidebar">UNIX および NFS を使用する NetApp clustered Data ONTAP での SAP と Oracle の運用 Data ONTAP</block>
  <block id="e858f513baeeed4d0c8f4edb6b0a7ce8" category="doc">Azure と AVS 向けのネットアップエンタープライズハイブリッドクラウドソリューション</block>
  <block id="63e6365ca9ee8eced75eccdd9a133b69" category="doc">GCP / GCVE 向けのネットアップエンタープライズハイブリッドクラウドソリューション</block>
  <block id="59eb8568bc4ce9e9a49ab2dd5bb08af1" category="doc">AWS / VMC 向けネットアップエンタープライズハイブリッドクラウドソリューション</block>
  <block id="13dcdfd7bce3161be8066f52b4d2247a" category="cell"><block ref="13dcdfd7bce3161be8066f52b4d2247a" category="inline-link-macro-rx"></block></block>
  <block id="7e2e877818cdb57ef3a43f99102f9d38" category="cell"><block ref="7e2e877818cdb57ef3a43f99102f9d38" category="inline-link-macro-rx"></block></block>
  <block id="5909792f4a0287d5b5f88ee6f430a28f" category="cell"><block ref="5909792f4a0287d5b5f88ee6f430a28f" category="inline-link-macro-rx"></block></block>
  <block id="99643699503906f6a149e103359b31d5" category="cell"><block ref="d35550b71de9d445d0f21340762112d5" category="inline-link-macro-rx"></block>
<block ref="457b0b4c4f040ecdb73aa5b03853579f" category="inline-link-macro-rx"></block></block>
  <block id="7b1ff975fb6d48c12181b30da20dfab0" category="cell"><block ref="3c73250bfc490d47ce28b6cf808148ac" category="inline-link-macro-rx"></block>
<block ref="0f2c04766507e4de89a1d44cbd408339" category="inline-link-macro-rx"></block></block>
  <block id="2a32702602a143372d93bf2d2f395a36" category="cell"><block ref="14800306dfb8ba898026bf23b6a9cfc5" category="inline-link-macro-rx"></block>
<block ref="ef1833f411035de243ce008622899fb9" category="inline-link-macro-rx"></block></block>
  <block id="4e36e97d23b00520e4b573859ee4cb26" category="list-text"><block ref="4e36e97d23b00520e4b573859ee4cb26" category="inline-link-macro-rx"></block></block>
  <block id="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link"><block ref="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link-rx"></block></block>
  <block id="b17e2a7e5f42c90b40de5971850339ae" category="list-text">TR-4597 ：『 VMware vSphere for ONTAP 』<block ref="5938ff9651f6c5e53544676ba8504afc" category="inline-link-rx"></block></block>
  <block id="c39148c472a0504dc9c52734b79f5125" category="sidebar">ゲスト接続ストレージを使用するソリューション</block>
  <block id="511ff82335a683184e92371d0c9fe853" category="sidebar">ネイティブデータストアを使用したソリューション</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">この検証では、 4 台のサーバを Network Shared Disk （ NSD; ネットワーク共有ディスク）サーバとして使用して、 GPFS 用の物理ディスクを提供しました。GPF は、次の図に示すように、 NFS エクスポートとしてエクスポートするために NSD ディスクの上に作成されます。XCP を使用して、 GPFS でエクスポートされた NFS から NetApp NFS ボリュームにデータをコピーしました。</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">NetApp ONTAP NFS への GPF</block>
  <block id="823313a32a4a1131e0469fac26acbdac" category="inline-link-macro">前の図： Data Mover 解決策 for AI</block>
  <block id="c4e4b7ebe157b09b7d1a0db25078dc45" category="paragraph"><block ref="c4e4b7ebe157b09b7d1a0db25078dc45" category="inline-link-macro-rx"></block></block>
  <block id="9a1bdf4376c8448278cf38263e4da8c7" category="paragraph"><block ref="9a1bdf4376c8448278cf38263e4da8c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">GPF の要点</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">GPFS では、次のノードタイプが使用されます。</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">* 管理ノード。 * ノード間の通信に管理コマンドが使用するノード名を含むオプションのフィールドを指定します。たとえば ' 管理ノード mastr-51.netapp.com` は ' クラスタ内の他のすべてのノードにネットワーク・チェックを渡すことができます</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">* クォーラムノード。クォーラムの取得元のノードのプールにノードが含まれているかどうかを判断します。少なくとも 1 つのノードがクォーラムノードとして必要です。</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">* マネージャノード。 * ノードがノードプールの一部であるかどうかを示します。このプールからファイルシステムマネージャとトークンマネージャを選択できます。複数のノードをマネージャーノードとして定義することをお勧めします。マネージャとして指定するノードの数は、ワークロードと所有する GPFS サーバライセンスの数によって異なります。大規模な並列ジョブを実行する場合は、 Web アプリケーションをサポートする 4 ノードクラスタよりも多くのマネージャノードが必要になることがあります。</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*NSD サーバ。 *GPFS で使用する各物理ディスクを準備するサーバ。</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">* プロトコルノード。 *Secure Shell （ SSH; セキュアシェル）プロトコルを介して、 NFS と GPFS データを直接共有するノード。このノードには GPFS サーバーライセンスが必要です。</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">GPFS 、 NFS 、および XCP の操作のリスト</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">このセクションでは、 GPFS を作成し、 NFS エクスポートとして GPFS をエクスポートし、 XCP を使用してデータを転送する操作について説明します。</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">GPFS を作成します</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">GPFS を作成するには、次の手順を実行します。</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">Linux 版のスペクトルスケールデータアクセスをいずれかのサーバにダウンロードしてインストールします。</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">すべてのノードに前提条件パッケージ（シェフなど）をインストールし、すべてのノードで Security-Enhanced Linux （ SELinux ）を無効にする。</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">インストールノードをセットアップし、管理ノードと GPFS ノードをクラスタ定義ファイルに追加します。</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">マネージャーノード、クォーラムノード、 NSD サーバー、および GPFS ノードを追加します。</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">GUI 、管理ノード、 GPFS ノードを追加し、必要に応じて GUI サーバを追加します。</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">別の GPFS ノードを追加し、すべてのノードのリストを確認します。</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">クラスタ定義ファイル内のすべての GPFS ノードで設定するクラスタ名、プロファイル、リモートシェルバイナリ、リモートファイルコピーバイナリ、およびポート範囲を指定します。</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">GPFS 構成設定を表示し、追加の管理ノードを追加します。</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">データ収集を無効にし、 IBM サポートセンターにデータパッケージをアップロードします。</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">インストールの前に、 NTP を有効にし、構成を事前確認します。</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">NSD ディスクを構成、作成、およびチェックする。</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">GPFS を作成します。</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">GPFS をマウントします。</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">GPFS に必要な権限を確認して提供します。</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">「 dd 」コマンドを実行して、 GPFS の読み書きを確認します。</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">GPFS を NFS にエクスポートする</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">GPFS を NFS にエクスポートするには、次の手順を実行します。</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">GPFS を /etc/exports ファイルを介して NFS としてエクスポートします</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">必要な NFS サーバパッケージをインストールします。</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">NFS サービスを開始します。</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">NFS クライアントを検証するために、 GPFS 内のファイルをリストします。</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">NFS クライアントを設定します</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">NFS クライアントを設定するには、次の手順を実行します。</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">GPFS を /etc/exports ファイルを使用して NFS としてエクスポートします。</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">NFS クライアントサービスを開始します。</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">NFS クライアントで NFS プロトコルを使用して GPFS をマウントします。</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">NFS Mounted フォルダ内の GPFS ファイルのリストを検証します。</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">XCP を使用して、 GPFS エクスポート NFS から NetApp NFS にデータを移動します。</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">NFS クライアントで GPFS ファイルを検証します。</block>
  <block id="ae2b7fcf15ee142a2de2b3ba9573b414" category="inline-link-macro">次の例： HDFS と MapR - FS を ONTAP NFS に接続。</block>
  <block id="545d9ad8cb56e65641eb4e8083301a39" category="paragraph"><block ref="545d9ad8cb56e65641eb4e8083301a39" category="inline-link-macro-rx"></block></block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">このセクションでは、 NetApp XCP を使用して GPFS を設定し、 NFS にデータを移動するために必要な詳細な手順について説明します。</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">NFS に対する GPF - 詳細な手順</block>
  <block id="b523cc107fd56956277d38d32b34c938" category="inline-link-macro">前のページ：ビジネス上のメリット</block>
  <block id="c415260b3bf5ed05c37515a8e4e526f3" category="paragraph"><block ref="c415260b3bf5ed05c37515a8e4e526f3" category="inline-link-macro-rx"></block></block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">GPFS を設定します</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">いずれかのサーバに Linux 用 Spectrum Scale Data Access をダウンロードしてインストールします。</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">すべてのノードに前提条件パッケージ（シェフとカーネルヘッダーを含む）をインストールします。</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">すべてのノードで SELinux を無効にする。</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">インストールノードをセットアップします。</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">管理ノードと GPFS ノードをクラスタ定義ファイルに追加します。</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">マネージャノードと GPFS ノードを追加します。</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">クォーラムノードと GPFS ノードを追加します。</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">NSD サーバと GPFS ノードを追加します。</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">GUI 、管理ノード、および GPFS ノードを追加します。</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">別の GUI サーバを追加します。</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">別の GPFS ノードを追加します。</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">すべてのノードを検証およびリストします。</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">クラスタ定義ファイルでクラスタ名を指定します。</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">プロファイルを指定します。</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">GPFS で使用するリモートシェルバイナリを指定します。引数には -r を使用します。</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">GPFS で使用するリモートファイルコピーバイナリを指定します。「 -rc 引数」を使用します。</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">すべての GPFS ノードに設定するポート範囲を指定します。「 -e 引数」を使用します。</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">GPFS 構成設定を表示します。</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">管理ノードを追加</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">NTP を有効にします。</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">インストール前に設定を事前確認します。</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">NSD ディスクを設定します。</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">NSD ディスクを作成します。</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">NSD ディスクのステータスを確認します。</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">GPFS に必要な権限を確認して付与します。</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">「 dd 」コマンドを実行して、 GPFS の読み取りと書き込みを確認します。</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">GPFS を NFS にエクスポートするには、次の手順を実行します。</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">NFS クライアントを検証するために、 GPFS 内のファイルをリストします。</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">NFS クライアントを設定します</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">NFS クライアントにパッケージをインストールします。</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">NFS マウントフォルダ内の GPFS ファイルのリストを確認します。</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">XCP を使用して、 GPFS でエクスポートされた NFS から NetApp NFS にデータを移動します。</block>
  <block id="96a4b9abe25ad94a1d4ab8e0d2237ef6" category="inline-link-macro">次のページ： MapR - FS to ONTAP NFS 。</block>
  <block id="742eb558b5f30d090f7c3ae58b2a554e" category="paragraph"><block ref="742eb558b5f30d090f7c3ae58b2a554e" category="inline-link-macro-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">このセクションでは、この解決策のビジネス上の利点について説明します。</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">ビジネス上のメリット</block>
  <block id="aaff67cd4222a3be5071cf651cab3d48" category="inline-link-macro">従来： HDFS と MapR - FS から ONTAP NFS へ。</block>
  <block id="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="paragraph"><block ref="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="inline-link-macro-rx"></block></block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">ビッグデータ分析から AI にデータを移動することには、次のようなメリットがあります。</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">異なる Hadoop ファイルシステムと GPFS から Unified NFS ストレージシステムにデータを抽出する機能</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Hadoop 統合によりデータ転送を自動化します</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Hadoop ファイルシステムからデータを移動するためのライブラリ開発コストを削減することです</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">NIPAM を使用して、 1 つのデータソースからの複数のネットワークインターフェイスの集約スループットによる最大パフォーマンス</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">データを転送するための、スケジュールされた方法とオンデマンドの方法</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">ONTAP データ管理ソフトウェアを使用した、ユニファイド NFS データ用のストレージ効率化およびエンタープライズ管理機能</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">データ転送用の Hadoop メソッドにより、データ移動のコストがゼロになります</block>
  <block id="a3b97091403bff3b38419087acb1c19e" category="inline-link-macro">次の手順： NFS への GPFS - 詳細な手順。</block>
  <block id="5e982872ec65785f5d685290b9c40026" category="paragraph"><block ref="5e982872ec65785f5d685290b9c40026" category="inline-link-macro-rx"></block></block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">このセクションでは、 NetApp XCP を使用して MapR FS データを ONTAP NFS に移動するために必要な手順について説明します。</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR - FS から ONTAP NFS へ</block>
  <block id="59b0eb4059face89ab060ea59984c8a7" category="inline-link-macro">前の手順： GPFS から NFS へ - 詳細な手順</block>
  <block id="13f1dc977877024b0f36272f1af2b238" category="paragraph"><block ref="13f1dc977877024b0f36272f1af2b238" category="inline-link-macro-rx"></block></block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">MapR ノードごとに 3 つの LUN をプロビジョニングし、すべての MapR ノードの LUN の所有権を付与します。</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">インストール時に、 MapR FS に使用されている MapR クラスタディスク用に新しく追加された LUN を選択します。</block>
  <block id="f7dc1a091cd04b392f9a99c5390b9ce2" category="inline-link">MapR 6.1 のドキュメント</block>
  <block id="24cb5309ea8c5a7c3244adf133110ecf" category="list-text">に従って MapR クラスタをインストールします<block ref="a38d60fa0425a18b5925139ceca806ea" category="inline-link-rx"></block>。</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">「 hadoop jar xxx 」などの MapReduce コマンドを使用して、基本的な Hadoop 動作をチェックします。</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">MapR - FS で顧客データを保持します。たとえば、 Teragen を使用して MapR -FS に約 1 テラバイトのサンプルデータを生成しました。</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">MapR - FS を NFS エクスポートとして設定します。</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">すべての MapR ノードで nlockmgr サービスを無効にします。</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">MapR から特定のフォルダをエクスポートします。これは、「 /opt/MapR /conf/exports 」ファイルのすべての MapR ノードにあります。サブフォルダをエクスポートするときは、異なる権限を持つ親フォルダをエクスポートしないでください。</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">MapR - FS NFS サービスを更新します。</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">仮想 IP 範囲を MapR クラスタ内の特定のサーバまたはサーバセットに割り当てます。次に、 MapR クラスタが NFS データアクセス用の特定のサーバに IP を割り当てます。IP を使用することで高可用性が実現します。つまり、特定の IP を持つサーバまたはネットワークで障害が発生した場合に、 IP 範囲内の次の IP を NFS アクセスに使用できます。</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">すべての MapR ノードからの NFS アクセスを提供する場合は、各サーバに一連の仮想 IP を割り当て、各 MapR ノードのリソースを NFS データアクセスに使用できます。</block>
  <block id="fa6899b17d5e71a360316c355d34c8b3" category="paragraph"><block ref="fa6899b17d5e71a360316c355d34c8b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb6de965ede92bf8bb036bb8fea6eba" category="paragraph"><block ref="8cb6de965ede92bf8bb036bb8fea6eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="031b138609c608ed553a74b2a1c439e1" category="paragraph"><block ref="031b138609c608ed553a74b2a1c439e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">各 MapR ノードに割り当てられている仮想 IP を確認し、 NFS データアクセスに使用します。</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">NFS をエクスポートした MapR FS をマウントするには、 NFS の動作を確認するために割り当てられた仮想 IP を使用します。ただし、 NetApp XCP を使用したデータ転送では、この手順は必要ありません。</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">MapR FS NFS ゲートウェイから ONTAP NFS にデータを転送するように NetApp XCP を設定します。</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">XCP のカタログの場所を設定します。</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">ライセンスファイルを「 /opt/NetApp/xFiles/XCP 」にコピーします。</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">XCP activate コマンドを使用して XCP をアクティブにします。</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">ソースで NFS エクスポートを確認します。</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">複数のソース IP と複数のデスティネーション IP （ ONTAP LIF ）から、複数の MapR ノードから XCP を使用してデータを転送します。</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">ストレージコントローラ上の負荷分散を確認します。</block>
  <block id="93a2605b6bf89fdb9970a6dbc77dee03" category="paragraph"><block ref="93a2605b6bf89fdb9970a6dbc77dee03" category="inline-link-macro-rx"></block></block>
  <block id="b446e9930ab89aa25e7b422c4c23d83f" category="inline-link-macro">前のバージョン： MapR - FS to ONTAP NFS 。</block>
  <block id="185bcaf9470b338d9a2b58870d7bd2bd" category="paragraph"><block ref="185bcaf9470b338d9a2b58870d7bd2bd" category="inline-link-macro-rx"></block></block>
  <block id="ca79886b03835c933143f8eb102ac932" category="list-text">NetApp In-Place Analytics Module Best Practices 』を参照してください</block>
  <block id="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link"><block ref="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link-rx"></block></block>
  <block id="026671d583a546d6b62291e018f78bf7" category="paragraph"><block ref="026671d583a546d6b62291e018f78bf7" category="inline-link-rx"></block></block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">『 NetApp FlexGroup Volume Best Practices and Implementation Guide 』にある、ボリュームへの移行に関するセクション</block>
  <block id="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link"><block ref="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link-rx"></block></block>
  <block id="f473bc55fb079f0338493530316efc6f" category="paragraph"><block ref="f473bc55fb079f0338493530316efc6f" category="inline-link-rx"></block></block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">バージョン 3.0 以降</block>
  <block id="b9365bb9132d1eb8770275a763fc5d69" category="cell">2022 年 1 月</block>
  <block id="e4005842db89b4abb778385f9a8a758f" category="cell">NetApp XCP を使用して、 HDFS と MapR FS から NFS にデータを直接移動する。</block>
  <block id="d835981d77534f5f20446d4648ad7e5b" category="cell">2020年1月</block>
  <block id="637f51ce71f8f8cadc4b75dfda96d45c" category="cell">デフォルトのデータムーバーに XCP が含まれています。NFS データ転送に MapR - FS を追加し、 NFS データ転送に GPFS を追加しました。</block>
  <block id="a10ba827ae758dee0e50d44366fd3d6d" category="cell">2018年11月</block>
  <block id="4b3608ccf8a7154699127b487cc49627" category="paragraph">このドキュメントでは、ビッグデータ分析やハイパフォーマンスコンピューティング（ HPC ）システムからデータを移動して、人工知能（ AI ）ワークフローで使用できるようにする方法について説明します。AI は通常、 NFS エクスポートを介して NFS データを処理します。ただし、ビッグデータ分析とハイパフォーマンスコンピューティング（ HPC ）のプラットフォームに AI データが格納されている可能性があります。これは、 Hadoop 分散ファイルシステム（ HDFS ）、バイナリ大容量オブジェクト（ Blob ）、 S3 ストレージ、 IBM の General Parallel File System （ GPFS ）などです。本ドキュメントでは、 Hadoop ネイティブのコマンド、 NetApp In-Place Analytics Module （ NIPAM ）、および NetApp XCP を使用して、ビッグデータ分析プラットフォームと GPFS から NFS にデータを移動する方法について説明します。このドキュメントでは、ビッグデータや HPC から AI にデータを移動することで得られるビジネス上のメリットについても説明します。</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">このページでは、 AI の運用を目的としたビッグデータ分析からデータにアクセスする際にお客様が直面する可能性のある課題について説明します。</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="doc">お客様の課題</block>
  <block id="14fd125cf7cc7e6f58e0a07d30ecda87" category="paragraph"><block ref="14fd125cf7cc7e6f58e0a07d30ecda87" category="inline-link-macro-rx"></block></block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">AI 運用のためにビッグデータ分析からデータにアクセスしようとすると、お客様は次のような課題に直面することがあります。</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">お客様のデータは、データレイクリポジトリに格納されています。データレイクには、構造化データ、非構造化データ、半構造化データ、ログ、マシン間データなど、さまざまなタイプのデータを格納できます。これらのデータタイプはすべて AI システムで処理する必要があります。</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">AI は Hadoop ファイルシステムには対応していません。一般的な AI アーキテクチャでは、 HDFS データと HCFS データに直接アクセスできないため、 AI に対応したファイルシステム（ NFS ）に移行する必要があります。</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">データレイクのデータを AI に移行するには、通常、特別なプロセスが必要です。データレイク内のデータ量は非常に多くなる可能性があります。効率性、スループット、コスト効率に優れた方法でデータを AI システムに移動する必要がある。</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">データを同期中です。お客様がビッグデータプラットフォームと AI の間でデータを同期したい場合は、ビッグデータを使用して処理されたデータを分析処理に使用できることがあります。</block>
  <block id="02c553e123c56e4cba5728b7e83bb80b" category="inline-link-macro">次： Data Mover の解決策。</block>
  <block id="205e8a4d3382497ff57947382c577faa" category="paragraph"><block ref="205e8a4d3382497ff57947382c577faa" category="inline-link-macro-rx"></block></block>
  <block id="2ea9ecb649c5974bc03036a15d95f5bf" category="summary">Data Mover 解決策 for AI は、お客様のニーズに基づいて AI 運用の Hadoop データを処理します。ネットアップは、 NIPAM を使用して HDFS から NFS にデータを移動します。あるユースケースでは、クラウド内の GPU クラウドインスタンスからデータを処理するために、データをオンプレミスの NFS に移動し、別のお客様が Windows Azure ストレージ Blob から Cloud Volumes Service に移動する必要がありました。</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">AI 向け Data Mover 解決策</block>
  <block id="2337521acd1f46c410245430b841caa8" category="inline-link-macro">前のバージョン： Data Mover の解決策。</block>
  <block id="ee202fa3d5706f12ab6d57e9cb4b4cba" category="paragraph"><block ref="ee202fa3d5706f12ab6d57e9cb4b4cba" category="inline-link-macro-rx"></block></block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">次の図は、 Data Mover の解決策の詳細を示しています。</block>
  <block id="27f83ed51cc554467134084d77b0e050" category="paragraph"><block ref="27f83ed51cc554467134084d77b0e050" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">Data Mover 解決策を構築するには、次の手順が必要です。</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN は HDFS を提供し、 NAS は NIPAM 経由で本番データレイククラスタに NFS ボリュームを提供します。</block>
  <block id="0fad6dd0225bf5a5e9c668c30ea5d38a" category="list-text">お客様のデータは HDFS と NFS にあります。NFS データは、ビッグデータ分析や AI 処理に使用される他のアプリケーションの本番データにすることができます。</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">NetApp FlexClone テクノロジは、本番用 NFS ボリュームのクローンを作成し、オンプレミスの AI クラスタにプロビジョニングします。</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">HDFS SAN LUN からのデータは、 NIPAM および「 hadoop distcp 」コマンドによって NFS ボリュームにコピーされます。NIPAM は、複数のネットワークインターフェイスの帯域幅を使用してデータを転送します。この処理によってデータコピー時間が短縮され、より多くのデータを転送できるようになります。</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">どちらの NFS ボリュームも、 AI 処理用に AI クラスタにプロビジョニングされます。</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">オンプレミスの NFS データを処理するために、クラウド内の GPU を使用する場合は、 NFS ボリュームが NetApp SnapMirror テクノロジを使用して NetApp Private Storage （ NPS ）にミラーリングされ、 GPU のクラウドサービスプロバイダにマウントされます。</block>
  <block id="c590e653cde69438d43731b18edd533c" category="list-text">お客様は、 GPU のデータをクラウドサービスプロバイダから EC2 / EMR 、 HDInsight 、または DataProc サービスで処理したいと考えています。Hadoop データムーバーは、 NIPAM および「 hadoop distcp 」コマンドを使用して、 Hadoop サービスから Cloud Volume サービスにデータを移動します。</block>
  <block id="8cae7d7989a25f83bf9df9952b16ed2b" category="list-text">Cloud Volumes Service データは、 NFS プロトコルを使用して AI にプロビジョニングされます。 AI で処理されたデータは、オンプレミスの場所に送信し、 NIPAM 、 SnapMirror 、 NPS を通じて、 NVIDIA クラスタに加えてビッグデータ分析にも使用できます。</block>
  <block id="980894bd0921c687decdf218e89107e2" category="paragraph">このシナリオでは、 NAS システム内のファイル数が多く、オンプレミスのネットアップストレージコントローラで AI 処理を実行するために必要なリモートサイトにデータが配置されています。このシナリオでは、 XCP Migration Tool を使用してデータをより高速に移行することをお勧めします。</block>
  <block id="002cfe6c68deff9c2fcb4fbb3820a5ff" category="paragraph">ハイブリッドユースケースのお客様は、 Cloud Sync を使用してオンプレミスのデータを NFS 、 CIFS 、 S3 のデータからクラウドに移行し、その逆も、 NVIDIA クラスタ内の GPU などを使用して AI 処理を行うことができます。NetApp ONTAP NFS への NFS データ移行には、 Cloud Sync と XCP Migration Tool の両方が使用されます。</block>
  <block id="22033f5439b399254e73f6f3588b9b9e" category="inline-link-macro">次： NetApp ONTAP NFS への GPFS の追加。</block>
  <block id="f56cb05715de107bd001dd11a41b0cf6" category="paragraph"><block ref="f56cb05715de107bd001dd11a41b0cf6" category="inline-link-macro-rx"></block></block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">ビッグデータクラスタでは、 MapR -FS 、 Windows Azure Storage Blob 、 S3 、 Google ファイルシステムなどの HDFS または HCFS にデータが格納されます。ネットアップは、ソース側で hadoop distcp コマンドを使用し、データを NIPAM の支援によって NetApp ONTAP NFS エクスポートにコピーするソースとして、 HDFS 、 MapR FS 、 S3 を使用してテストを実施しました。</block>
  <block id="6d1963202b436934d6b74acc8232dc94" category="inline-link-macro">前：お客様の課題</block>
  <block id="501ee0e125dd4449de2b29015fab6f3e" category="paragraph"><block ref="501ee0e125dd4449de2b29015fab6f3e" category="inline-link-macro-rx"></block></block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">ビッグデータクラスタでは、 MapR -FS 、 Windows Azure Storage Blob 、 S3 、 Google ファイルシステムなどの HDFS または HCFS にデータが格納されます。ソース側で「 hadoop distcp 」コマンドを使用し、データを NIPAM の助けを得て NetApp ONTAP NFS エクスポートにコピーするソースとして、 HDFS 、 MapR FS 、および S3 を使用してテストを実施しました。</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">次の図は、 HDFS ストレージで稼働している Spark クラスタから、 NVIDIA が AI 処理を行えるようにするための NetApp ONTAP NFS ボリュームへの、一般的なデータ移動を示しています。</block>
  <block id="d824b1bb9493b5a6c5a2e74871468633" category="paragraph"><block ref="d824b1bb9493b5a6c5a2e74871468633" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">「 hadoop distcp 」コマンドは、 MapReduce プログラムを使用してデータをコピーします。NIPAM は MapReduce と連携して、データをコピーする際の Hadoop クラスタのドライバとして機能します。NIPAM では、 1 つのエクスポートのために複数のネットワークインターフェイスに負荷を分散できます。このプロセスにより、 HDFS または HCFS から NFS にデータをコピーするときに、複数のネットワークインターフェイスにデータを分散させることにより、ネットワークスループットが最大になります。</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM は MapR でサポートまたは認定されていません。</block>
  <block id="e68fb74f51fcafb391476c585b1e434d" category="inline-link-macro">次のステップ： Data Mover 解決策 for AI</block>
  <block id="1f4c259e626baca3c7947e6f3db323d4" category="paragraph"><block ref="1f4c259e626baca3c7947e6f3db323d4" category="inline-link-macro-rx"></block></block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">このホワイトペーパーでは、 NetApp XCP と NIPAM を使用して、ビッグデータ分析データと HPC データを AI に移行するためのガイドラインを説明します。また、ビッグデータや HPC から AI にデータを移行することで得られるビジネス上のメリットについても説明します。</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732 ：『 Big data analytics data to 人工知能』</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">このドキュメントでは、ビッグデータ分析データと HPC データを AI に移行する方法について説明します。AI は、 NFS エクスポートを介して NFS データを処理しますが、お客様の AI データは、 HDFS 、 Blob 、 S3 ストレージなどのビッグデータ分析プラットフォームや、 GPFS などの HPC プラットフォームに格納されていることがよくあります。このホワイトペーパーでは、 NetApp XCP と NIPAM を使用して、ビッグデータ分析データと HPC データを AI に移行するためのガイドラインを説明します。また、ビッグデータや HPC から AI にデータを移行することで得られるビジネス上のメリットについても説明します。</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">概念とコンポーネント</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">ビッグデータ分析ストレージ</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">ビッグデータ分析は、 HDFS の主要なストレージプロバイダです。お客様は多くの場合、 Windows Azure Blob Storage 、 MapR File System （ MapR - FS ）、 S3 オブジェクトストレージなどの Hadoop 対応ファイルシステム（ HCFS ）を使用しています。</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">一般的な並列ファイルシステム</block>
  <block id="432f31a1b9dc5a8ef1f048ea3f4f98c8" category="paragraph">IBM の GPFS は、 HDFS の代わりとなるエンタープライズファイルシステムです。GPF は、アプリケーションがブロックサイズとレプリケーションレイアウトを決定できる柔軟性を備えており、優れたパフォーマンスと効率を実現します。</block>
  <block id="2aff401779cc49866458a642f15c0181" category="inline-link">TR-4382 ：『 NetApp In-Place Analytics Module 』</block>
  <block id="ae1165a7ed0006d2dae65ea849898810" category="paragraph">NetApp In-Place Analytics Module （ NIPAM ）は、 NFS データにアクセスする Hadoop クラスタのドライバとして機能します。接続プール、 NFS InputStream 、ファイル・ハンドル・キャッシュ、 NFS OutputStream の 4 つのコンポーネントで構成されています。詳細については、を参照してください<block ref="aedae5b2590b798973be1ab298f44ab7" category="inline-link-rx"></block></block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Hadoop 分散コピー</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy （ DistCp ）は、クラスタ間およびクラスタ内の大規模なコピー作業に使用される分散コピーツールです。このツールは、データの配信、エラー処理、およびレポートに MapReduce を使用します。ファイルとディレクトリのリストが展開され、タスクをマッピングしてソースリストからデータをコピーするように入力されます。次の図は、 HDFS と HDFS 以外の間の DistCp 処理を示しています。</block>
  <block id="1a76b3e0f1199267d461c961d30d07a5" category="paragraph"><block ref="1a76b3e0f1199267d461c961d30d07a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp は、追加のドライバを使用せずに 2 つの HDFS システム間でデータを移動します。ネットアップは HDFS 以外のシステム向けのドライバを提供しています。NFS デスティネーションの場合、 NIPAM は、データのコピー時に Hadoop DistCp が NFS デスティネーションとの通信に使用するデータをコピーするためのドライバを提供します。</block>
  <block id="05fc55cae9e8b2a7fb40e978e4971707" category="paragraph">NetApp Cloud Volumes Service は、卓越したパフォーマンスを発揮するクラウドネイティブのファイルサービスです。このサービスを利用すると、お客様はリソースのスピンアップとスピンダウンを迅速に行い、ネットアップの機能を使用して生産性を高め、スタッフのダウンタイムを短縮し、市場投入までの期間を短縮できます。Cloud Volumes Service は、データセンター全体の設置面積を削減し、ネイティブのパブリッククラウドストレージを消費しないため、ディザスタリカバリやクラウドへのバックアップに最適な選択肢です。</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP は、高速で信頼性の高いネットアップおよびネットアップからネットアップへのデータ移行を可能にするクライアントソフトウェアです。このツールは、あらゆる NAS システムからネットアップストレージコントローラに大量の非構造化 NAS データをコピーするために設計されています。XCP Migration Tool では、マルチコアのマルチチャネル I/O ストリーミングエンジンが使用されており、データの移行、ファイルやディレクトリの一覧表示、スペースレポートなど、多数の要求を並行して処理できます。これは、デフォルトのネットアップデータ移行ツールです。XCP を使用して、 Hadoop クラスタと HPC から NetApp NFS ストレージにデータをコピーできます。次の図は、 Hadoop クラスタと HPC クラスタから XCP を使用した NetApp NFS ボリュームへのデータ転送を示しています。</block>
  <block id="cd7e68aa30250a331c260fee49ff230e" category="paragraph"><block ref="cd7e68aa30250a331c260fee49ff230e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bce96270b79327e5daf4c0745d66023" category="paragraph">NetApp Cloud Sync は、 NFS 、 S3 、 CIFS のデータをオンプレミスストレージとクラウドストレージ間でシームレスかつセキュアに転送して同期する、ハイブリッドデータレプリケーションソフトウェアサービスです。このソフトウェアは、データの移行、アーカイブ、コラボレーション、分析などに使用されます。データが転送されると、 Cloud Sync はソースとデスティネーションの間でデータを継続的に同期します。次に、デルタを転送します。また、自社ネットワーク内、クラウド内、オンプレミス内でもデータを保護できます。このソフトウェアは従量課金制モデルをベースとしており、対費用効果の高い解決策を提供し、データ転送の監視とレポートの機能を提供します。</block>
  <block id="cbba30a09e75669ecb5b3b2d83a25284" category="inline-link-macro">次のステップ：お客様の課題</block>
  <block id="63aa417c654afafebdbdfcaf7a13c8b6" category="paragraph"><block ref="63aa417c654afafebdbdfcaf7a13c8b6" category="inline-link-macro-rx"></block></block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">この解決策では、ネットアップがデータレイク（ HDFS ）と MapR クラスタデータから ONTAP NFS へのデータ移行を検証しました。データは MapR - FS と HDFS に存在します。NetApp XCP は、 HDFS や MapR FS などの分散ファイルシステムから ONTAP NFS にデータを直接移行する新しい機能を導入しました。</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS と MapR - FS を ONTAP NFS に接続</block>
  <block id="9577f33e5dfe124ba394a5c90a123928" category="inline-link-macro">旧称： NetApp ONTAP NFS への GPFS 。</block>
  <block id="a503c5d00affd8b681837e8b44490492" category="paragraph"><block ref="a503c5d00affd8b681837e8b44490492" category="inline-link-macro-rx"></block></block>
  <block id="9c02792070008c1748647d8bdbe24432" category="paragraph">この解決策では、ネットアップがデータレイク（ HDFS ）と MapR クラスタデータから ONTAP NFS へのデータ移行を検証しました。データは MapR - FS と HDFS に存在します。NetApp XCP は、 HDFS や MapR FS などの分散ファイルシステムから ONTAP NFS にデータを直接移行する新しい機能を導入しました。XCP は、非同期スレッドと HDFS C API 呼び出しを使用して、 MapR FS と HDFS の間でデータを通信および転送します。次の図は、データレイク（ HDFS ）と MapR FS から ONTAP NFS へのデータ移行を示しています。この新機能により、ソースを NFS 共有としてエクスポートする必要がなくなります。</block>
  <block id="4581f9b32af32647aa31b2f9d57f6f1f" category="paragraph"><block ref="4581f9b32af32647aa31b2f9d57f6f1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">お客様が HDFS と MapR FS から NFS に移行するのはなぜですか。</block>
  <block id="b075c8e6a9009d582333c59e237e3646" category="paragraph">Cloudera や Hortonworks などの Hadoop ディストリビューションのほとんどは HDFS ディストリビューションと MapR ディストリビューションを使用してデータを格納しています。HDFS と MapR - FS データは、機械学習（ ML ）とディープラーニング（ DL ）に活用できるデータサイエンティストにとって価値ある分析情報を提供します。HDFS と MapR FS のデータは共有されないため、他のアプリケーションでは使用できません。顧客は、共有データ、特に顧客の機密データが複数のアプリケーションで使用される銀行業界を探しています。最新バージョンの Hadoop （ 3.x 以降）は NFS データソースをサポートしており、サードパーティ製ソフトウェアを追加することなくアクセスできます。新しい NetApp XCP 機能を使用すると、データを HDFS および MapR FS から NetApp NFS に直接移動して、複数のアプリケーションへのアクセスを提供できます</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">テストは Amazon Web Services （ AWS ）で実施され、 MapR ノード 12 台と NFS サーバ 4 台を使用した初期パフォーマンステストで MapR FS から NFS にデータを転送しました。</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">サイズ</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">vCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">メモリ</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">ネットワーク</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">NFS サーバ</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge のサイズ</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8 台の 7 、 500 NVMe SSD</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">MapR ノード</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en. 12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">7 、 500 NVMe SSD × 4</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">初期テストでは 20Gbps のスループットを達成し、 2PB のデータを 1 日あたり転送可能でした。</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link">TR-4863 ：『 Best Practice Guidelines for NetApp XCP - Data Mover 、 File Migration 、 and Analytics 』</block>
  <block id="6371d61614d0beaedb75e85d2c297d8f" category="paragraph">HDFS を NFS にエクスポートせずに HDFS データを移行する方法の詳細については、の「 Deployment Steps - NAS 」を参照してください<block ref="6a602f6a965c96a94215a45f0077e771" category="inline-link-rx"></block>。</block>
  <block id="aa722a0d50c9e3bfe81a7128f0e649d7" category="inline-link-macro">次は、ビジネス上のメリットです。</block>
  <block id="4e39bc17db35d21d84b6fb1e9786fdb5" category="paragraph"><block ref="4e39bc17db35d21d84b6fb1e9786fdb5" category="inline-link-macro-rx"></block></block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">ビッグデータ分析データを人工知能に</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">NFS に対する GPF - 詳細な手順</block>
  <block id="75afdb5cd8c025ed0681bdb302fcdcda" category="cell">NVA-1160 に「 OperatorHub および Ansible による Astra Control Center のインストール」という新しいセクションを追加しました</block>
  <block id="593fdc7a2167cd2ada3e71219ceb0ecb" category="paragraph">詳細については、 Astra Trident の Web サイトをご覧ください<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>。</block>
  <block id="3d930ae98e9d9fc9a418d6b8e5e5639f" category="cell">21.12.60</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="2bb7e89d50aed884078c4b7857f5bb39" category="cell">4.6 EUS 、 4.7 、 4.8</block>
  <block id="1e90637438eb06672159d2998d220e86" category="open-title">OperatorHub を使用する</block>
  <block id="bff0144772c74d96da07b6ccefb79f96" category="list-text">ネットアップサポートサイトにログインし、最新バージョンの NetApp Astra Control Center をダウンロードします。そのためには、ネットアップアカウントにライセンスを関連付ける必要があります。tarball をダウンロードしたら、 admin ワークステーションに転送します。</block>
  <block id="baac643870c95006b4243d078606a15d" category="list-text">インストールを開始する前に、 Astra Control Center イメージをイメージレジストリにプッシュします。この手順では、 Docker または Podman のいずれかを使用して実行します。両方の手順については、この手順で説明します。</block>
  <block id="455cbd59356abfa16dcf7666d4ae6c2b" category="list-title">ポドマン</block>
  <block id="ee9b41d8a22021826def077c661525f4" category="list-text">公開されていないプライベートイメージレジストリを使用する場合は、イメージレジストリ TLS 証明書を OpenShift ノードにアップロードします。そのためには、 TLS 証明書を使用して OpenShift -config ネームスペースに ConfigMap を作成し、クラスタイメージ構成にパッチを適用して証明書を信頼できるようにします。</block>
  <block id="9c656c969a87783fcf4b94b721f34bc9" category="list-text">Astra Control Center 用の名前空間 NetApp-acc-operator' を作成します</block>
  <block id="788e8355bdd3a21f3a9017a0610940f4" category="list-text">クラスタ管理者アクセスで Red Hat OpenShift GUI コンソールにログインします。</block>
  <block id="3d68b5654b778f026ac691bc6ed70cc5" category="list-text">[ 演算子 ]&gt;[ 演算子ハブ ] の順に移動し、 Astra を検索します。</block>
  <block id="dc7add750562c445f72d8d016a79ae29" category="list-text">NetApp-acc-operator' タイルを選択し、 [ インストール ] をクリックします。</block>
  <block id="c80be3093b470ca8092538e58a261952" category="image-alt">ACC オペレータタイル</block>
  <block id="c65c283737dc37cea2358a91588ff272" category="list-text">インストールオペレータ画面で、デフォルトのパラメータをすべて受け入れて、「インストール」をクリックします。</block>
  <block id="3677d31e24a1853c961f3f1a9a39a1d6" category="image-alt">ACC オペレータの詳細</block>
  <block id="ba14525c4ccc9b2f692d062104885b19" category="image-alt">ACC オペレーターがインストールを待機します</block>
  <block id="fea3120ff933c367a5882d58dbbe8a08" category="list-text">オペレータのインストールが完了したら、 [View Operator] をクリックします。</block>
  <block id="a573acc0621ea72a06ce987a341768bf" category="image-alt">ACC オペレータによるインストールが完了しました</block>
  <block id="f99196bf6b988223fab800f28cf0323c" category="list-text">次に、オペレーターの Astra Control Center タイルで [Create Instance] をクリックします。</block>
  <block id="11f7c569d04eecd142ba5989efcc2da3" category="image-alt">ACC インスタンスを作成します</block>
  <block id="02780e148f03f25db76204c23985d753" category="list-text">[Create AstraeControl] フォームフィールドに入力し '[Create] をクリックします</block>
  <block id="e31f3b85c5179d88bcf0629842c5342f" category="list-text">必要に応じて、 Astra Control Center インスタンス名を編集します。</block>
  <block id="3336a2124154da151aecfe1809d7c821" category="list-text">必要に応じて、 AutoSupport を有効または無効にします。Auto Support 機能の保持を推奨します。</block>
  <block id="14ddbb7fd85c2907073b06492b95191b" category="list-text">Astra Control Center の FQDN を入力します。</block>
  <block id="fbcd656fecc902b1994e346dc0627266" category="list-text">Astra Control Center のバージョンを入力します。デフォルトで最新のバージョンが表示されます。</block>
  <block id="311a20c50b8e2d72cf9b31eb6339bff4" category="list-text">Astra Control Center のアカウント名を入力し、管理者の詳細（名、姓、メールアドレスなど）を入力します。</block>
  <block id="163e6534daeb1cbd7c56b20a9477802f" category="list-text">ボリューム再利用ポリシーを入力します。デフォルトは Retain です。</block>
  <block id="5863d7f52b409374d0d80b1bcbba68fd" category="list-text">Image Registry に、レジストリの FQDN と、イメージをレジストリにプッシュする際に指定した組織名を入力します（この例では「 astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra` 」）。</block>
  <block id="95279718d2829cd5ed7772d6f0a77ca9" category="list-text">認証が必要なレジストリを使用する場合は、 [ イメージレジストリ ] セクションにシークレット名を入力します。</block>
  <block id="b8f9ae819a2d6559f55aed837fdc2a47" category="list-text">Astra Control Center のリソース制限のスケーリングオプションを設定します。</block>
  <block id="3b489b9fd690a8cdf710454d0ccb5288" category="list-text">デフォルト以外のストレージクラスに PVC を配置する場合は、ストレージクラス名を入力します。</block>
  <block id="6b9265a82fa5bd326052ec55e040a54a" category="list-text">CRD 処理の環境設定を定義します。</block>
  <block id="90aa5928482975bc6ff56f0eaf052451" category="open-title">自動化された [Ansible ]</block>
  <block id="b8571b33af3335fed61ab0d7985d007f" category="list-text">Ansible コンテンツをホストする GitHub リポジトリをクローニングします。</block>
  <block id="5ed95667cae604c0ddee2dbf04f423fe" category="list-text">ネットアップサポートサイトにログインし、最新バージョンの NetApp Astra Control Center をダウンロードします。そのためには、ネットアップアカウントにライセンスを関連付ける必要があります。tar ファイルをダウンロードしたら、ワークステーションに転送します。</block>
  <block id="6238d4091e12ffa6643c0dc68d72ceab" category="list-text">Astra Control Center をインストールする OpenShift クラスタに管理者としてアクセスできる kubeconfig ファイルを作成または取得します。</block>
  <block id="b736c713f352ab43e7543fda4589e96f" category="list-text">ディレクトリを na_Astra_control_site に変更します。</block>
  <block id="4f31682e7040024757006eed6ba0344a" category="list-text">変数 / 変数 .yml ファイルを編集し、必要な情報を入力します。</block>
  <block id="084d6dacfbcd3e90106780f3cb2699fa" category="list-text">プレイブックを実行して Astra Control Center を導入します。Playbook には、特定の構成用の root 権限が必要です。</block>
  <block id="1b9af2e27b0d249822ccdef7fe087cfc" category="paragraph">そのため、この Playbook を実行しているユーザが root である場合やパスワードを使用しない sudo が設定されている場合は、以下のコマンドを実行してこの Playbook を実行してください。</block>
  <block id="9081796e9cbb144a0c6cc05a62c75b37" category="paragraph">ユーザにパスワードベースの sudo アクセスが設定されている場合は、次のコマンドを実行してこの Playbook を実行し、 sudo パスワードを入力します。</block>
  <block id="8d1e5f9175948d3e6f932794744cde16" category="section-title">インストール後の手順</block>
  <block id="8b70487815961b708f216595f5817311" category="paragraph">2022 年 1 月にリリースされた最新バージョンの Astra Trident は 22.01 です。Trident のどのバージョンがサポートされているかを確認できます Kubernetes ディストリビューションのテストに使用<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>。</block>
  <block id="b5d9e69ac9444a6a1cfd78cf106c057e" category="list-text">インストールアーカイブを管理ワークステーションにダウンロードし、内容を展開します。Trident の最新バージョンは 22.01 で、ダウンロードできます<block ref="defadeb91446b93776c7f5696677985c" category="inline-link-rx"></block>。</block>
  <block id="89c771069f269704306d4ca7b118cc7d" category="paragraph">ただし NFSv3 については、クライアントとサーバ間の同時処理をネゴシエートするメカニズムはありません。したがって ' サーバが接続のウィンドウ・サイズを小さくしなくても NFS 接続の最適なパフォーマンスを確保できるように ' クライアント側 sunrpc スロット・テーブル・エントリーの最大数は ' サーバ上でサポートされている値と手動で同期する必要があります</block>
  <block id="9c2d7353683234845149cb6710dc11f8" category="paragraph">ONTAP でサポートされる sunrpcslot table エントリの最大数は 128 です。つまり、 ONTAP は、一度に 128 個の NFS 要求を同時に処理できます。ただし、 Red Hat CoreOS / Red Hat Enterprise Linux では、接続ごとに最大 65 、 536 の sunrpc スロットテーブルエントリがデフォルトでサポートされます。この値を 128 に設定する必要があります。これは OpenShift のマシン構成オペレータ（ MCO ）を使用して実行できます。</block>
  <block id="88cd6afaae477b942c9ab5d396e43cfb" category="paragraph">OpenShift ワーカーノードで最大 sunrpc スロットテーブルエントリを変更するには、次の手順を実行します。</block>
  <block id="e7a7478f209d8b5dcaf38a593ce749b3" category="list-text">MCO が作成されたら、すべてのワーカーノードに設定を適用し、 1 つずつ再起動する必要があります。プロセス全体には約 20~30 分かかります。「 OC GET MCP 」を使用してマシン構成が適用されているかどうかを確認し、ワーカーのマシン構成プールが更新されていることを確認します。</block>
  <block id="068d2023b916134a0573aaad841124e4" category="paragraph">ワーカーノードで iSCSI サービスを実行するように設定するには、次の手順を実行します。</block>
  <block id="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link"><block ref="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link-rx"></block></block>
  <block id="086fce5f74cc93b0516aadec33636e09" category="paragraph"><block ref="086fce5f74cc93b0516aadec33636e09" category="inline-link-rx"></block></block>
  <block id="0611f127a7e1e7ef5bbd782030c2e34a" category="paragraph">NetApp ONTAP で作成されたプロジェクトごとに異なる SVM が作成されたら、各 SVM を異なる Trident バックエンドにマッピングする必要があります。Trident のバックエンド構成は、 OpenShift クラスタリソースへの永続的ストレージの割り当てを促進します。また、マッピング先の SVM の詳細が必要です。これは、バックエンドのプロトコルドライバである必要があります。必要に応じて、ストレージでのボリュームのプロビジョニング方法を定義したり、ボリュームのサイズやアグリゲートの使用などを制限したりできます。Trident バックエンドの定義に関する詳細はこちらをご覧ください<block ref="47a77763732c6cebe093a4a4d61aaa5b" category="inline-link-rx"></block>。</block>
  <block id="891c9b8b0ce367c5e377a1ec23199619" category="paragraph">Trident バックエンドを設定したら、次の手順として StorageClasses を設定します。バックエンドと同じ数のストレージクラスを構成して、各ストレージクラスが 1 つのバックエンドにしかボリュームをスピンアップできない。ストレージクラスを定義する際に StoragePools パラメータを使用して、ストレージクラスを特定の Trident バックエンドにマッピングできます。ストレージクラスを定義する詳細については、を参照してください<block ref="1266deb20a7d7c4814b1225e5e572606" category="inline-link-rx"></block>。そのため、 StorageClass から Trident バックエンドへの 1 対 1 のマッピングで、 1 つの SVM をポイントします。これにより、そのプロジェクトに割り当てられた StorageClass を経由するすべてのストレージ要求が、そのプロジェクト専用の SVM によって処理されます。</block>
  <block id="b09383080793dfb527084933760af6ed" category="paragraph"><block ref="b09383080793dfb527084933760af6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f372cf1de9e60f6875a0b24a5c28b07" category="list-text">スナップショットの詳細を入力し、 [ 次へ ] をクリックして、 [ スナップショット ] をクリックします。Snapshot の作成には約 1 分かかり、作成が完了するとステータスを確認できるようになります。</block>
  <block id="42dd75b4fbc849903d5d179a8e68d570" category="paragraph"><block ref="42dd75b4fbc849903d5d179a8e68d570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0929177ba68c50d4dd73a2a3311ac885" category="paragraph"><block ref="0929177ba68c50d4dd73a2a3311ac885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f789c3d3aacfbd2d2f99ba395ddb8bc5" category="list-text">バックアップの詳細を入力し、バックアップファイルを保存するオブジェクトストレージバケットを選択して次へをクリックします。詳細を確認したら、バックアップをクリックします。アプリケーションのサイズとデータによっては、バックアップに数分かかることがあり、バックアップが正常に完了したあとでバックアップのステータスを確認できるようになります。</block>
  <block id="4ba6af660a8dd39dc1d12fb6ee80ba81" category="paragraph"><block ref="4ba6af660a8dd39dc1d12fb6ee80ba81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b1fda3b0f36b6fd708a9871e1c19c50" category="section-title">アプリケーションのリストア</block>
  <block id="344aed2ab37311beed01bbd40d93caed" category="paragraph">ボタンを押すだけで、アプリケーションを同じクラスタ内の元のネームスペースまたはリモートクラスタにリストアし、アプリケーションを保護してディザスタリカバリに使用できます。</block>
  <block id="8ac352fe46a0c45e744688191b7df581" category="list-text">アプリケーションを復元するには、 [ アプリ ] &gt; [ 管理 ] タブに移動し、該当するアプリをクリックします。アプリケーション名の横にあるドロップダウン・メニューをクリックし '[ リストア ] をクリックします</block>
  <block id="84eb14028ce6ae6f2bf17b71ebe50c69" category="paragraph"><block ref="84eb14028ce6ae6f2bf17b71ebe50c69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b33d7fda666bdb32a2be1f3783106a3c" category="list-text">リストアネームスペースの名前を入力し、リストア先のクラスタを選択して、既存の Snapshot からリストアするかアプリケーションのバックアップからリストアするかを選択します。次へをクリックします。</block>
  <block id="7bbb08271e6b60bc55d6817c7e100528" category="paragraph"><block ref="7bbb08271e6b60bc55d6817c7e100528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9242e3e5428d2ddbd81dece3073767a" category="list-text">レビューペインで「 restore 」と入力し、詳細を確認した後で「 Restore 」をクリックします。</block>
  <block id="7d6d73878ae09dbfd1e5ee7a0ecab66c" category="inline-image-macro">Astra Control Center 復元のレビュー</block>
  <block id="b862f033546ae8bdc1bb091ad8b57023" category="paragraph"><block ref="b862f033546ae8bdc1bb091ad8b57023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b86c631d7b3beb0163beee546245df6" category="list-text">新しいアプリケーションは、 Astra Control Center が選択したクラスタ上のアプリケーションを復元している間、 Restoring 状態になります。アプリケーションのすべてのリソースが Astra によってインストールおよび検出されると、アプリケーションは Available 状態になります。</block>
  <block id="81d066be6d2211bf186bc1960361d8e3" category="paragraph"><block ref="81d066be6d2211bf186bc1960361d8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4600d44abb914105737c3d4a802b87c" category="section-title">アプリケーションのクローニング</block>
  <block id="5394f3451a07ae7dbe101ceb0725a004" category="paragraph">アプリケーションは、開発 / テストやアプリケーションの保護およびディザスタリカバリ目的で、元のクラスタまたはリモートクラスタにクローニングできます。同じストレージバックエンドで同じクラスタ内にあるアプリケーションをクローニングする場合、 NetApp FlexClone テクノロジを使用します。 FlexClone テクノロジを使用すると、 PVC のクローンを瞬時に作成し、ストレージスペースを節約できます。</block>
  <block id="04783413cee5e3c613efc7939cea3560" category="list-text">アプリケーションをクローンするには、 [ アプリケーション（ Apps ） ] &gt; [ 管理（ Managed ） ] タブに移動し、該当するアプリケーションをクリックします。アプリケーション名の横にあるドロップダウンメニューをクリックし、 Clone をクリックします。</block>
  <block id="1cfafd65804d582aac709fefcd3e60cd" category="paragraph"><block ref="1cfafd65804d582aac709fefcd3e60cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="654c7a62842024ed8e405ed0ac9c4377" category="list-text">新しいネームスペースの詳細を入力し、クローニング先のクラスタを選択します。クローンを既存の Snapshot 、バックアップ、またはアプリケーションの現在の状態から作成するかどうかを選択します。詳細を確認したら、 [ 次へ ] をクリックして、 [ レビューペインに複製 ] をクリックします。</block>
  <block id="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="paragraph"><block ref="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60bae26bb7c1e8711f1e39a45fc7b6c7" category="paragraph"><block ref="60bae26bb7c1e8711f1e39a45fc7b6c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d656f81a685df3697a812158d0bd2f21" category="paragraph">NetApp Astra Trident は、コンテナや Kubernetes ディストリビューション向けの、 Red Hat OpenShift などのオープンソースで完全にサポートされているストレージオーケストレーションツールです。詳細については、 Astra Trident の Web サイトをご覧ください<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>。</block>
  <block id="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="list-text"><block ref="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="inline-link-macro-rx"></block></block>
  <block id="ea1c9e7b76d8b7cc203b9f6a9633e241" category="list-text"><block ref="ea1c9e7b76d8b7cc203b9f6a9633e241" category="inline-link-macro-rx"></block></block>
  <block id="4105298f144b4b0e636460eede523df0" category="inline-link-macro">Ansible による Astra Control Center の自動インストール</block>
  <block id="64295ddd382f7876d307bac08ad539fe" category="cell"><block ref="64295ddd382f7876d307bac08ad539fe" category="inline-link-macro-rx"></block></block>
  <block id="bd6059cd679908cdb2d015167d51a3fe" category="cell"><block ref="bd6059cd679908cdb2d015167d51a3fe" category="inline-link-macro-rx"></block></block>
  <block id="6dc07ae6ad84b77b5d06f9d3fff5b819" category="cell"><block ref="6dc07ae6ad84b77b5d06f9d3fff5b819" category="inline-link-macro-rx"></block></block>
  <block id="e32276e1eed6ff0e76971afd985cea2d" category="cell"><block ref="e32276e1eed6ff0e76971afd985cea2d" category="inline-link-macro-rx"></block></block>
  <block id="77697d49d0c6b79e2642435a36c8c1e0" category="cell"><block ref="77697d49d0c6b79e2642435a36c8c1e0" category="inline-link-macro-rx"></block></block>
  <block id="60f031c992a9c99aa5413bddb0ecc644" category="cell"><block ref="60f031c992a9c99aa5413bddb0ecc644" category="inline-link-macro-rx"></block></block>
  <block id="13a82ffd84cedcd28833f58d716b4c3c" category="cell"><block ref="13a82ffd84cedcd28833f58d716b4c3c" category="inline-link-macro-rx"></block></block>
  <block id="6721f3769bff6250dbce3a06c2ae10ac" category="list-text"><block ref="6721f3769bff6250dbce3a06c2ae10ac" category="inline-link-macro-rx"></block></block>
  <block id="74d542ee52cd8400c9b9307ed9a99c12" category="list-text">Astra DevOps のユースケース：</block>
  <block id="3da7df001d5e1f907d2527f52c6ccc00" category="inline-link-macro">NetApp Astra Control を使用すれば、 Kubernetes の CI / CD パイプラインに保護機能を簡単に統合できます</block>
  <block id="3f1cbb7eb907b7cb7f46877360d4a588" category="list-text"><block ref="3f1cbb7eb907b7cb7f46877360d4a588" category="inline-link-macro-rx"></block></block>
  <block id="fa4bd1682f261cdd55edf3e8e7dbfef6" category="inline-link-macro">DevOps とネットアップ： Astra Control を使用して、事後分析とアプリケーションのリストアを実行</block>
  <block id="1188d1aaa4a5f54ec1dab3da3576377a" category="list-text"><block ref="1188d1aaa4a5f54ec1dab3da3576377a" category="inline-link-macro-rx"></block></block>
  <block id="ce932b248d7f57bcada97c64dd7429a7" category="inline-link-macro">NetApp Astra Control Center ：アプリケーションのデータ管理を容易にするボタン</block>
  <block id="0d47bfb381dd96470ac538b5a112db04" category="list-text"><block ref="0d47bfb381dd96470ac538b5a112db04" category="inline-link-macro-rx"></block></block>
  <block id="31dfd224530c16d63981c7742bfefc2b" category="list-text">Ansible プレイブックを使用して Astra Control Center を導入するには、 Ansible がインストールされた Ubuntu / RHEL マシンが必要です。説明に従って、手順 に従います<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Ubuntu およびそれに含まれています<block ref="1988083261a6d1d93abe49ae6e6435ae" category="inline-link-rx"></block> RHEL の場合：</block>
  <block id="6546814199e52492fa0efe5fbff08d5a" category="paragraph">この解決策 では、 SnapCenter で現在サポートされているすべてのデータベースがサポートされます。ここでは、 Oracle データベースと SQL Server データベースのみを示します。この解決策は仮想データベースワークロードに対して検証済みですが、ベアメタルワークロードもサポートされています。</block>
  <block id="f2a59783d2b5c7be84fec0d6de7a5ae9" category="cell">2022 年 8 月 3 日</block>
  <block id="eab6f1cc9736be0f5d62999f998bf36a" category="cell">新しいビデオデモ「 Accelerate Software Development with Astra Control and NetApp FlexClone Technology 」を追加</block>
  <block id="5df42c63d444f6e9e40d96be8f17ac6f" category="cell">2022 年 1 月 3 日</block>
  <block id="9fe0dbff6457627765d03955bd1659be" category="inline-link-macro">ビデオ： Accelerate Software Development with Astra Control and NetApp FlexClone Technology</block>
  <block id="a0eaa75e3e2b8c6220db02697d4acf1f" category="cell"><block ref="a0eaa75e3e2b8c6220db02697d4acf1f" category="inline-link-macro-rx"></block></block>
  <block id="d5ca81c242aff843ea151d778578cbfc" category="admonition">レジストリに信頼されていない証明書を使用している場合は、シェルスクリプトを編集し、 podman push コマンドに「 --tls-verify=false 」を使用します。「 podman push $registry/ $ 」（ echo $astraalImage | sed's /^[^\\/]\\/'/')--tls-verify=false 」）。</block>
  <block id="ec72a928f8eedfaa788b44b6935b50fe" category="doc">Astra Control と NetApp FlexClone テクノロジでソフトウェア開発を高速化：ネットアップを使用した Red Hat OpenShift</block>
  <block id="335ef14df727dc9707e14629b77fcf30" category="doc">AWS でのネットアップストレージのサポート</block>
  <block id="70b9c790cc4671aad4f8d8322d13161b" category="list-text"><block ref="70b9c790cc4671aad4f8d8322d13161b" category="inline-link-macro-rx"></block></block>
  <block id="2b1b2978337fa95de5057d99307c01aa" category="list-text"><block ref="2b1b2978337fa95de5057d99307c01aa" category="inline-link-macro-rx"></block></block>
  <block id="6a8abef867f53cd024908ab859c46238" category="list-text"><block ref="6a8abef867f53cd024908ab859c46238" category="inline-link-macro-rx"></block></block>
  <block id="5fd057c554dfaf16f0d97e4defdb81fd" category="list-text"><block ref="5fd057c554dfaf16f0d97e4defdb81fd" category="inline-link-macro-rx"></block></block>
  <block id="48a9e19e56cfc47077d0352f9d0f2693" category="section-title">Azure Support for NetApp Storage の略</block>
  <block id="79fab3fcc59adc540e33fa185069b7ce" category="list-text"><block ref="79fab3fcc59adc540e33fa185069b7ce" category="inline-link-macro-rx"></block></block>
  <block id="85a5820e8da21c627876736be5d694b8" category="list-text"><block ref="85a5820e8da21c627876736be5d694b8" category="inline-link-macro-rx"></block></block>
  <block id="de049193fe94b917d3e89452cdfee78d" category="list-text"><block ref="de049193fe94b917d3e89452cdfee78d" category="inline-link-macro-rx"></block></block>
  <block id="5f68200d68deb8399b86dd57533f10a4" category="list-text"><block ref="5f68200d68deb8399b86dd57533f10a4" category="inline-link-macro-rx"></block></block>
  <block id="5b7d2a7cd86311f868ed2f3d495a8f0f" category="section-title">ネットアップストレージ向けの GCP サポート</block>
  <block id="3aa200e6ed258b413d3edac26b75184a" category="list-text"><block ref="3aa200e6ed258b413d3edac26b75184a" category="inline-link-macro-rx"></block></block>
  <block id="236b2a8169de601ff6b72a6a78e1f572" category="list-text"><block ref="236b2a8169de601ff6b72a6a78e1f572" category="inline-link-macro-rx"></block></block>
  <block id="b2b70627d90e90b2fcf0b37f68d18d32" category="list-text"><block ref="b2b70627d90e90b2fcf0b37f68d18d32" category="inline-link-macro-rx"></block></block>
  <block id="74186fb00c70b9871392ea68443adfd5" category="list-text"><block ref="74186fb00c70b9871392ea68443adfd5" category="inline-link-macro-rx"></block></block>
  <block id="6f1af1c4707c0ddb6d24c463fa4904f1" category="list-text">リンク： #config [GCP での GCVE の設定</block>
  <block id="b4360d9dcce9e932e3b5b09fdc524745" category="list-text"><block ref="b4360d9dcce9e932e3b5b09fdc524745" category="inline-link-macro-rx"></block></block>
  <block id="fdab91853bf925f2256c6d39ec3f5351" category="section-title">GCP での GCVE の設定</block>
  <block id="74a9966b070c1e73507b6ff0780e3733" category="list-text"><block ref="74a9966b070c1e73507b6ff0780e3733" category="inline-link-macro-rx"></block></block>
  <block id="337bcf72d1e47b982df4965e1063ef67" category="list-text"><block ref="337bcf72d1e47b982df4965e1063ef67" category="inline-link-macro-rx"></block></block>
  <block id="09e89069d02379fc56daa781d256d7b6" category="section-title">AWS （ VMC ）の仮想化環境構成</block>
  <block id="3fb5798a9396698dabb0ac96950db53b" category="list-text"><block ref="3fb5798a9396698dabb0ac96950db53b" category="inline-link-macro-rx"></block></block>
  <block id="046546ab63b0ca36de368801c6fd8a9e" category="list-text"><block ref="046546ab63b0ca36de368801c6fd8a9e" category="inline-link-macro-rx"></block></block>
  <block id="5c7b11ed146406e84fe971b132517bcd" category="section-title">Azure 向け仮想化環境の構成（ AVS ）</block>
  <block id="0027e14144945de23e255b58586424e1" category="list-text"><block ref="0027e14144945de23e255b58586424e1" category="inline-link-macro-rx"></block></block>
  <block id="c2dd14a3829d81f8d6ccd1a2a41e114b" category="list-text"><block ref="c2dd14a3829d81f8d6ccd1a2a41e114b" category="inline-link-macro-rx"></block></block>
  <block id="d70f78589c41399658959afc073dfede" category="list-text"><block ref="d70f78589c41399658959afc073dfede" category="inline-link-macro-rx"></block></block>
  <block id="7ec8289b14700d8be0d8f376eea6b8bf" category="section-title">GCP の仮想化環境構成（ GCVE ）</block>
  <block id="9f7328009a38e32265481f8305d6aa75" category="list-text"><block ref="9f7328009a38e32265481f8305d6aa75" category="inline-link-macro-rx"></block></block>
  <block id="5ee479af89822c5af943f78689918520" category="list-text"><block ref="5ee479af89822c5af943f78689918520" category="inline-link-macro-rx"></block></block>
  <block id="9e98cd6f2c1243193cfc50a29bbe3bd4" category="list-text"><block ref="9e98cd6f2c1243193cfc50a29bbe3bd4" category="inline-link-macro-rx"></block></block>
  <block id="553bafb094b811158ae732981f2dbb4e" category="list-text"><block ref="553bafb094b811158ae732981f2dbb4e" category="inline-link-macro-rx"></block></block>
  <block id="44cf8e167821820f0ebe40745562219b" category="list-text"><block ref="44cf8e167821820f0ebe40745562219b" category="inline-link-macro-rx"></block></block>
  <block id="27a2d4b0295d93eb20519fcf77df27f3" category="list-text"><block ref="27a2d4b0295d93eb20519fcf77df27f3" category="inline-link-macro-rx"></block></block>
  <block id="07004cdc228cde7054ba825a728ee189" category="list-text"><block ref="07004cdc228cde7054ba825a728ee189" category="inline-link-macro-rx"></block></block>
  <block id="202373c4c91793dc8fb54647ff8a2241" category="list-text"><block ref="202373c4c91793dc8fb54647ff8a2241" category="inline-link-macro-rx"></block></block>
  <block id="9597c351929448a6eea4162c4f4a80db" category="list-text"><block ref="9597c351929448a6eea4162c4f4a80db" category="inline-link-macro-rx"></block></block>
  <block id="22aae0cba6d6bb50053c5b84e36b16ad" category="list-text"><block ref="22aae0cba6d6bb50053c5b84e36b16ad" category="inline-link-macro-rx"></block></block>
  <block id="f0969548cbf8208f26497f680b470705" category="list-text"><block ref="f0969548cbf8208f26497f680b470705" category="inline-link-macro-rx"></block></block>
  <block id="3b141b6466b12e3acb21b96825ab3d1b" category="section-title">AWS と VMC</block>
  <block id="f83f574b032c714479d3e32efdc3cbe3" category="section-title">Azure と AVS</block>
  <block id="1789862d26aa4adb9f5c2737bbf6a1fc" category="section-title">GCP と GCVE</block>
  <block id="28a7880d69d2603391bd4ae2a4de0d68" category="section-title">GCO と GCVE</block>
  <block id="e8318a9e631a084c73ef782e37caec2d" category="list-text"><block ref="e8318a9e631a084c73ef782e37caec2d" category="inline-link-macro-rx"></block></block>
  <block id="169210ceac9b94f0632cd1182961e949" category="open-title">CVO シングルノードの導入</block>
  <block id="610db6bf34b03f7873afe01d4eec8e58" category="paragraph">このセクションでは、 AWS （ Amazon Web Services ）上でシングルノードの NetApp CVO （ Cloud Volumes ONTAP ）を導入 / 構成するための、さまざまな Terraform 構成ファイルを提供しています。</block>
  <block id="4a537f87e89ac00b1276af84fa6f2da9" category="paragraph">Terraform ドキュメント :<block ref="e2ea72ce6afb985e72624e098135e8e1" category="inline-link-rx"></block></block>
  <block id="c69eb42cd732c6d937af674afc73ba24" category="paragraph">テンプレートを実行するには、次の手順を実行します。</block>
  <block id="0b2fc5bb85de930f6b1d839951f8df6d" category="list-text">リポジトリをクローニングします。</block>
  <block id="6f5cc42a3e67b7edb3a2d4b86ebfae01" category="list-text">目的のフォルダに移動します</block>
  <block id="71046100fbc383dd8cd1cdd6160f6d6d" category="list-text">CLI から AWS クレデンシャルを設定する。</block>
  <block id="4a4f9b0378c89fa21da9e5528c8a7f47" category="list-text">AWS アクセスキー ID [None] ：アクセスキー</block>
  <block id="6bbb2ea6e07d16e69748545bf2ee6a6d" category="list-text">AWS Secret Access Key [None] ： secretkey</block>
  <block id="7a31be9d48b53cd82a7160af0cd58fbe" category="list-text">デフォルトのリージョン名 [None] ： us-west-2</block>
  <block id="276bf14207394167e2ed4e3eed448680" category="list-text">デフォルトの出力形式は [None] ： json です</block>
  <block id="dd08960caafad89635926c55a0efd3a4" category="list-text">変数 /AWS_CVO-SILE_Node_deployment.tfvar' の変数値を更新します</block>
  <block id="e962d97debd0a377828855d79b5ccf66" category="admonition">変数「 AWS_Connector_deploy_bool 」の値を true または false に設定することで、コネクタを導入することができます。</block>
  <block id="88cefa0997a2272107223ee543b114db" category="list-text">Terraform リポジトリを初期化して、すべての前提条件をインストールし、導入の準備をします。</block>
  <block id="046372e4315eccae02c5be2caaac1ac5" category="list-text">terraform validate コマンドを使用して、 terraform ファイルを確認します。</block>
  <block id="144930ffd88cabf8795c7d4a6698e4ac" category="list-text">設定を事前に実行して、導入で想定されるすべての変更をプレビューします。</block>
  <block id="50a325adfbe874e5e14b044244efa49e" category="list-text">導入を実行</block>
  <block id="3125f7b5833c80fbd03966accb540bf8" category="paragraph">展開を削除します</block>
  <block id="58c9aaf9cf3d4d0215afe012b77aa1bc" category="paragraph">「コネクタ」</block>
  <block id="251861170f071d1ebe67b948f5026905" category="paragraph">CVO 導入用の NetApp AWS Connector インスタンスの Terraform 変数。</block>
  <block id="496ee322ba138fdbc777e5ab2e30145e" category="cell">* 名前 *</block>
  <block id="7464a7978b1ad9e7f36e5f0181e97eb5" category="cell">* タイプ *</block>
  <block id="22d8f94f4a088cb8d7c83ec5f44a03af" category="cell">* AWS_Connector_deploy_bool *</block>
  <block id="c26f15e86e3de4c398a8273272aba034" category="cell">ブール値</block>
  <block id="95ab4e4a16c4f585ede4d3c63167c1ee" category="cell">（必須）コネクタの配置を確認します。</block>
  <block id="e15fa495ec49ba53e0ba45d555c24027" category="cell">* AWS_Connector_name*</block>
  <block id="27118326006d3829667a400ad23d5d98" category="cell">文字列</block>
  <block id="5548283861d04af602b7193306751df7" category="cell">（必須） Cloud Manager Connector の名前。</block>
  <block id="8c3a0cf46a98725e12d666e2e13dc06d" category="cell">* AWS_connector_region *</block>
  <block id="efb4f51f6b08f54633b02a06b94210f2" category="cell">（必須） Cloud Manager Connector を作成するリージョン。</block>
  <block id="358040941579fe064f522f5b1eac2a33" category="cell">* AWS_Connector_key_name*</block>
  <block id="5c2f4db5972ecd2062c5f449f09c661f" category="cell">（必須）コネクタインスタンスに使用するキーペアの名前。</block>
  <block id="0e46676177a5b007dfeefb6ada2b65af" category="cell">* AWS_connector_company *</block>
  <block id="a7f1f5d73f372170ea283996e464af43" category="cell">（必須）ユーザの会社名。</block>
  <block id="9b9081642589bb52bb20161632edc5a6" category="cell">* AWS_Connector_instance_type *</block>
  <block id="ddd1c9b22f94863b3de9a1b551188553" category="cell">（必須）インスタンスのタイプ（ t3.xlarge など）。少なくとも 4 つの CPU と 16 GB のメモリが必要です。</block>
  <block id="f8a700002db36fadde1ab9526f2cf8c3" category="cell">* AWS_connector_subnet_id *</block>
  <block id="76788966b37b9b0df0b8ed78ad67eea9" category="cell">（必須）インスタンスのサブネットの ID 。</block>
  <block id="fafb089eb14a5fe730cfadfd7bed4b4f" category="cell">* AWS_Connector_security_group_id *</block>
  <block id="3e1563f6e3cc58e193b1d6a8c7af1351" category="cell">（必須）インスタンスのセキュリティグループの ID 。複数のセキュリティグループをで区切って指定できます。</block>
  <block id="52df26383575ad500acf38cc3df88e36" category="cell">* AWS_Connector_iAM_instance_profile_name *</block>
  <block id="59409115b42184ffa519bd9aa24b6816" category="cell">（必須）コネクタのインスタンスプロファイルの名前。</block>
  <block id="8953ca5d18d5f2c4a85fdfe10d30a002" category="cell">* AWS_Connector_account_id *</block>
  <block id="bba7484e58b18e8edafdbe619961f73f" category="cell">（オプション）コネクタを関連付けるネットアップアカウントの ID 。指定しない場合、 Cloud Manager は最初のアカウントを使用します。アカウントが存在しない場合、 Cloud Manager は新しいアカウントを作成します。アカウント ID は、 Cloud Manager のアカウントタブにあります<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>。</block>
  <block id="1918f44c178eed586b6fa7d6739af317" category="cell">* AWS_connector_public_ip_bool *</block>
  <block id="a4472307f162bdf147f02784bf81ab9d" category="cell">（任意）インスタンスにパブリック IP アドレスを関連付けるかどうかを指定します。指定しない場合は、サブネットの設定に基づいて関連付けが行われます。</block>
  <block id="9fb01bbff06d549bce01928fa2f7784c" category="paragraph">「シングルノードインスタンス」</block>
  <block id="d166b6e004666a5a8daa6db1c3cf1a13" category="paragraph">単一の NetApp CVO インスタンスの Terraform 変数。</block>
  <block id="19afa3a1ac092d450f21236f1973c705" category="cell">* CVO-NAME *</block>
  <block id="59935a520838700b451a3757f31fd4ac" category="cell">（必須） Cloud Volumes ONTAP 作業環境の名前。</block>
  <block id="ff855355eebbbfbd54d2734a61c43fd4" category="cell">* CVF_REGION *</block>
  <block id="b50ada32f992aba9f7055658a79132f2" category="cell">（必須）作業環境を作成するリージョン。</block>
  <block id="0e9b90f836062c3007935370ef18245f" category="cell">* CVO-subnet_id *</block>
  <block id="6c7cb9b4623284c101253ed002625e53" category="cell">（必須）作業環境を作成するサブネット ID 。</block>
  <block id="a99ec45accc4987a7eb2eff5219f96b3" category="cell">* CVO-vPC_id *</block>
  <block id="a179f6c6854fc89c6f118f4d8c201cad" category="cell">（オプション）作業環境を作成する VPC ID 。この引数を指定しない場合は、指定したサブネット ID を使用して VPC が計算されます。</block>
  <block id="26ff13994e5fbad1e11fc231bc73a5b6" category="cell">* CVO-svm_password* をクリックします</block>
  <block id="c82a889260bdc28c6136ddc6639a4f2e" category="cell">（必須） Cloud Volumes ONTAP の管理パスワード。</block>
  <block id="3815749b59fbccfa0077df4f90c8aa1e" category="cell">* CVF_Writing _speed_state *</block>
  <block id="e382698236dcb1567d375a4be3b12c2f" category="cell">（オプション） Cloud Volumes ONTAP の書き込み速度設定： [ 「 normal 」、「 high 」。デフォルトは「 normal 」です。</block>
  <block id="197b0ef64aabdc02a240f3f472eb4da2" category="open-title">CVO HA の導入</block>
  <block id="a082a9d97b4465f73e12cde3444a5296" category="paragraph">このセクションでは、 AWS （ Amazon Web Services ）のハイアベイラビリティペアに NetApp CVO （ Cloud Volumes ONTAP ）を導入 / 構成するための、さまざまな Terraform 構成ファイルを提供しています。</block>
  <block id="b31736be0fe5e59cc4905aa080c9ab16" category="list-text">変数 /AWS_CVO-HA_DEVELOT.tfvars の変数値を更新します。</block>
  <block id="ff8f4d628633e3ceb42dcca91ef2948e" category="paragraph">HA ペア</block>
  <block id="f7fbe4e66ae4cece99ae14a24f1c44ef" category="paragraph">HA ペアの NetApp CVO インスタンスの変数はテラフォームされます。</block>
  <block id="018a56af12514193b08f44d59f92fe83" category="cell">* CVO-is_HA *</block>
  <block id="93d83a3a243548e55fb126d283923435" category="cell">（オプション）作業環境が HA ペアであるかどうかを示します（ [true 、 false] ）。デフォルトは false です。</block>
  <block id="cea330e4ead03fcfec439b1f44be7c07" category="cell">* CVO-node1 _subnet_id *</block>
  <block id="3a0cbf54e2a847cd873a45840f9965f5" category="cell">（必須）最初のノードを作成するサブネット ID 。</block>
  <block id="d5d3a5e1275b1995e05472c7bfbcb53f" category="cell">* CVO-node2 _subnet_id *</block>
  <block id="5691678a4c059b3a4ebad0f4c6bf6bb5" category="cell">（必須） 2 つ目のノードを作成するサブネット ID 。</block>
  <block id="4377aa272f4cf89d4bbd39432ffb3b0e" category="cell">* CVF_Failover_mode *</block>
  <block id="9d76030e2a28826bff45ea1dff4d6920" category="cell">（任意） HA の場合、 HA ペアのフェイルオーバーモード： [PrivateIP] 、 [FloatingIP] 。「 PrivateIP 」は 1 つのアベイラビリティゾーン用で、「 FloatingIP 」は複数のアベイラビリティゾーン用です。</block>
  <block id="80c8a57adaed641642cd870951a1d4ed" category="cell">* CVO-mediator_subnet_id *</block>
  <block id="49ef0197555436f78dd87f582e510523" category="cell">（オプション） HA の場合は、メディエーターのサブネット ID 。</block>
  <block id="3efb524d034b1e223cb9d31a64f9bbc4" category="cell">* CVO-mediator_key_pair_name *</block>
  <block id="224733036290c1421bed8ad8de688956" category="cell">（オプション） HA の場合は、メディエーターインスタンスのキーペアの名前。</block>
  <block id="069dcc590a2acf756e6ca7f92d7d8355" category="cell">* CVO-cluster_floating_IP *</block>
  <block id="6325a8aefd56c67fab1d0d83b4cb8a2e" category="cell">（任意） HA FloatingIP の場合、クラスタ管理のフローティング IP アドレス。</block>
  <block id="618070e07e603612f24fa88a7ab583a8" category="cell">* CVO-data_floating_IP *</block>
  <block id="d8abdbcf87e3308c6a8e731ef574625c" category="cell">（任意） HA FloatingIP の場合は、データフローティング IP アドレス。</block>
  <block id="f115ec8cf476ea0198405ca27346e423" category="cell">* CVO-data_floating_ip2 *</block>
  <block id="754296c6c8a8cf70377730f6f126f24a" category="cell">* CVO-SVM_floating_IP *</block>
  <block id="797d132b963a11de245eae1725911bfe" category="cell">（オプション） HA FloatingIP の場合、 SVM 管理のフローティング IP アドレス。</block>
  <block id="418ba9c064c1fb64b11195c729d6a8b1" category="cell">* CVO-ROT_ROTLE_IDS*</block>
  <block id="4ee29ca12c7d126654bd0e5275de6135" category="cell">リスト</block>
  <block id="671a800e3791f7531a319e8b81e97c44" category="cell">（任意） HA FloatingIP の場合、フローティング IP で更新されるルートテーブル ID のリスト。</block>
  <block id="5d4a46c0a4567f819ba5935256b18297" category="open-title">FSX の導入</block>
  <block id="d43e39ffb05b35b72664b10dd8b8eb09" category="paragraph">このセクションには、 AWS （ Amazon Web Services ）上で NetApp ONTAP FSX を導入 / 設定するための、さまざまな Terraform 構成ファイルが含まれています。</block>
  <block id="171cc8e4954beec5176905189f71a708" category="list-text">デフォルトの出力形式 [None] ：</block>
  <block id="cbc2cee2851524f322f8d71e55d32a64" category="list-text">変数 /AWS_FSX_deployment.tfvars の変数値を更新します</block>
  <block id="05bf1719b762d4d80bcb0e545b3db1d2" category="paragraph">NetApp AWS Connector インスタンスの Terraform 変数。</block>
  <block id="618716470abe9536903f3c6781c4ac81" category="paragraph">「 FSX インスタンス」</block>
  <block id="5869d95322d3c435fd999596f0cf2303" category="paragraph">NetApp ONTAP FSX インスタンスの Terraform 変数。</block>
  <block id="c64f672849455d583204c525f5ea39ad" category="cell">* FSX_NAME*</block>
  <block id="af87bb54b839634f865f7bd7e2be203a" category="cell">* FSX_REGION *</block>
  <block id="02a52209be6996bc01fd629ac6a5b472" category="cell">* FSX_primary_subnet_id *</block>
  <block id="5dcd0d05819e117f52d439bebd6d2b42" category="cell">（必須）作業環境を作成するプライマリサブネット ID 。</block>
  <block id="0531247f461759a809214a03ea2f5f74" category="cell">* fsx_secondary_subnet_id *</block>
  <block id="b2184e9a131868dbc2332805652a0f02" category="cell">（必須）作業環境を作成するセカンダリサブネット ID 。</block>
  <block id="a333cc205644905efae2cf71519da619" category="cell">* fsx_account_id *</block>
  <block id="323c4fdc16ad2dd9e846afbcd4b69b10" category="cell">（必須） FSX インスタンスを関連付けるネットアップアカウントの ID 。指定しない場合、 Cloud Manager は最初のアカウントを使用します。アカウントが存在しない場合、 Cloud Manager は新しいアカウントを作成します。アカウント ID は、 Cloud Manager のアカウントタブにあります<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>。</block>
  <block id="7355bef79bff8e33a86af33fe4dcca8e" category="cell">* FSX_workspace_id *</block>
  <block id="97377fef3f33f9c8d1fb21c0d81cdf92" category="cell">（必須）作業環境の Cloud Manager ワークスペースの ID 。</block>
  <block id="ab77fdca353b13807c947d554712d8eb" category="cell">* FSX_admin_password *</block>
  <block id="c4bd49cb0034d697fd71cae233c3966c" category="cell">* FSX_Throughput _capacity *</block>
  <block id="e1ae53e33bf94a13f7d73cf885059ea6" category="cell">（任意）スループットの容量。</block>
  <block id="011dda542c81d29bda593f0cf6fafdfa" category="cell">* FSX_storage_capacity_size *</block>
  <block id="16b74c686b794890297f7ff7a9c98c9f" category="cell">（オプション）最初のデータアグリゲートの EBS ボリュームサイズGB の場合、単位は [100 または 500] です。TB の場合、単位は [1,2,4,8,16] です。デフォルトは「 1 」です。</block>
  <block id="da7d44d0ad606f586a3b1f567c8502d6" category="cell">* FSX_storage_capacity_size_unit *</block>
  <block id="5ec54d3d7d1db9fbf915daed12667b29" category="cell">（オプション） ['GB' または 'TB'] 。デフォルトは「 TB 」です。</block>
  <block id="07cc738168b47a86b740bc01e210b442" category="cell">* FSX_cloudmanager_aws _credential _name *</block>
  <block id="48dbb4d925fe4a46f28c0a8466a2f628" category="cell">（必須） AWS クレデンシャルアカウント名。</block>
  <block id="2fbb88fe90f9183c7eab541bc808795f" category="summary">このページでは、テラフォームを使用してネットアップのボリュームをクラウドプロバイダ（ AWS 、 Azure 、 GCP ）に自動で導入する方法について説明します。</block>
  <block id="8eece2f5500ed61d5d5d24d6b8cc6da5" category="doc">Terraform による Cloud Volume オートメーション</block>
  <block id="4e99239b58a385b2fec5a1fb4058a12c" category="paragraph">この解決策 では、 Terraform モジュールを使用して、 AWS （ CVO シングルノード、 CVO HA 構成の FSX ONTAP ）と Azure （ CVO シングルノード、 CVO HA 、 ANF ）への Cloud Volume の自動導入を文書化しています。コードは、から入手できます<block ref="d07ec9f91b2ccc52b0d628a1b144c1d8" category="inline-link-rx"></block></block>
  <block id="e11da9afe91d381489a365c86cc614ab" category="section-title">前提条件</block>
  <block id="95332f844502bac70e3783f2d906688c" category="list-text">Terraform &gt;=0.13</block>
  <block id="82410a61f302c6bdce619218d5036674" category="list-text">Cloud Manager アカウント</block>
  <block id="77913a2ff2c55b56fd6d981e7d7d2303" category="list-text">クラウドプロバイダアカウント– AWS 、 Azure</block>
  <block id="8fdcd620b2871b4f496213f43c8ee21f" category="list-text">ホストマシン（ Terraform がサポートするすべての OS ）</block>
  <block id="e5da768f23935e9c380799d86e27d695" category="section-title">プロバイダのドキュメント</block>
  <block id="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-macro"><block ref="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-rx"></block></block>
  <block id="b78f34c8bc7d03e88e2a6d7d8907ef93" category="paragraph">Cloud Manager の Terraform プロバイダのドキュメントは、次の URL から入手できます。 <block ref="05e9b3cbe087530696c6230448ff6b71" category="inline-link-macro-rx"></block></block>
  <block id="ef335030cde4c62e318574aa31ee49f7" category="section-title">プロバイダバージョンの制御</block>
  <block id="cc6d892dc2fbac39a7a00c3d822275b8" category="paragraph">プロバイダのバージョンを制御することもできます。これは、 Terraform 設定の required_providers ブロックによって制御されます。</block>
  <block id="bf4e80680b83752f1f57ca7d4e99d09b" category="paragraph">構文は次のとおりです。</block>
  <block id="c26cc3bad4e19f3604486c6e2d4dee15" category="paragraph">プロバイダバージョン管理の詳細については、こちらをご覧ください。</block>
  <block id="c335a311e2b771c143fbe09512d98021" category="section-title">実行中の特定のモジュール</block>
  <block id="0d6f6c74055e04156e36ddb127070a54" category="open-title">ANF</block>
  <block id="3f5bad999be275e4e9cf0728a13bf09c" category="paragraph">このセクションでは、 Azure に ANF （ Azure NetApp Files ）ボリュームを導入 / 設定するためのさまざまな Terraform 設定ファイルを示します。</block>
  <block id="61d66a29b98e4203b3fc2ea2884a6c5f" category="paragraph">Terraform ドキュメント :<block ref="745f55dd9f8ecc62d59e6b03ca9efbb7" category="inline-link-rx"></block></block>
  <block id="369baedac810ebc745ed2edf7754972b" category="list-text">Azure CLI にログインします（ Azure CLI がインストールされている必要があります）。</block>
  <block id="443ff7602b19f9692863937e763e1ad2" category="list-text">vars/azure_anf.tfvars の変数値を更新します</block>
  <block id="95f6ca118177fad8a1dd7e7abb74ce56" category="admonition">既存の VNet およびサブネットを使用して ANF ボリュームを導入することもできます。変数「 vnet_creation_bool 」と「 subnet_creation_bool 」の値を false に設定し、「 subnet_id_for _anf_vol 」を指定します。これらの値を true に設定して新しい VNet とサブネットを作成する場合にも、新しく作成したサブネットからサブネット ID が自動的に取得されます。</block>
  <block id="cb01f53471a55574a36eafb375d9493a" category="paragraph">単一のネットアップ ANF ボリュームに対応する Terraform 変数。</block>
  <block id="98bcef9bf5f44342e688bc29fb3fcbca" category="cell">* AZ_location*</block>
  <block id="4b05afb76d83065313c3740cd392a5ca" category="cell">（必須）リソースが存在する、サポートされている Azure の場所を指定します。これを変更すると、新しいリソースが強制的に作成されます。</block>
  <block id="861c040d5ed0212e4bc2aa4f92a2b861" category="cell">* AZ_PREFIX *</block>
  <block id="e6f149d38df85bed35faeca44370c01c" category="cell">（必須）ネットアップボリュームを作成するリソースグループの名前。これを変更すると、新しいリソースが強制的に作成されます。</block>
  <block id="7aa7ec2fc803d9041e6dfd5e142dcd23" category="cell">* AZ_vnet_address_space *</block>
  <block id="c8b090fd446e4181ed79e8e50bed7b91" category="cell">（必須） ANF ボリューム導入用として新しく作成した VNet で使用するアドレススペースです。</block>
  <block id="c5b9420927a71e0bcd6f4c621c66910f" category="cell">* AZ_subnet_address_prefix *</block>
  <block id="94c126b468fd9c408abdff2cccd827a4" category="cell">（必須） ANF ボリューム導入用に新しく作成した VNet で使用するサブネットアドレスプレフィックスです。</block>
  <block id="3c3133cb45a10a4ec442a4589636bfe1" category="cell">* AZ_volume_path *</block>
  <block id="c8fb8ccec1ede566cac7b410b7623186" category="cell">（必須）ボリュームの一意のファイルパス。マウントターゲットの作成時に使用します。これを変更すると、新しいリソースが強制的に作成されます。</block>
  <block id="5e51835c1dd28fa3cab3636a6beb8016" category="cell">* az _capacity_pool_size *</block>
  <block id="a0faef0851b4294c06f2b94bb1cb2044" category="cell">整数</block>
  <block id="35d9ed053f40a07b6df4021b8ced2423" category="cell">（必須）容量プールサイズ（ TB ）。</block>
  <block id="32c4a6ca695ae0fd3f41efe5ab8d3ffc" category="cell">* az_vnet_creation_bool *</block>
  <block id="27226c864bac7454a8504f8edb15d95b" category="cell">ブール値</block>
  <block id="55a1cc8d235c0ca9bd0cf384e2db1fb2" category="cell">（必須）新しい VNet を作成する場合は、このブール値を「 true 」に設定します。既存の VNet を使用するには、このパラメータを「 false 」に設定します。</block>
  <block id="be85fde9f0fcdf86be8ede4b5939a9bf" category="cell">* az_subnet_creation_bool *</block>
  <block id="4b079d5e017c7403047fbbd37df93368" category="cell">（必須）新しいサブネットを作成するには、このブーリアンを「 true 」に設定します。既存のサブネットを使用する場合は 'false に設定します</block>
  <block id="bb74e9c4e24089c59a6af0a7a016b586" category="cell">* az _subnet_id_for _anf_vol *</block>
  <block id="52c0fe6a129fdcf33be82680a15b2d37" category="cell">（必須）「 subnet_creation_bool 」を true に設定して既存のサブネットを使用する場合に、サブネット ID を指定します。false に設定する場合は、デフォルト値のままにします。</block>
  <block id="8376cf4b94c63b51d5e0113c299a75a0" category="cell">* AZ_NetApp_POOL_SERVICE_LEVEL *</block>
  <block id="061fce6317efb41fcda88b5333cb0cc2" category="cell">（必須）ファイルシステムのターゲットパフォーマンス。有効な値は 'Premium'Standard' または Ultra です</block>
  <block id="cd145efde532a4a27c5b6687f4b5f1c0" category="cell">* AZ_NetApp_vol_SERVICE_LEVEL *</block>
  <block id="d655c67b837d5b3363d556955802b670" category="cell">* AZ_NetApp_vol_protocol *</block>
  <block id="9e2a44ac250e0b60bce77fba70ebfd70" category="cell">（オプション）リストで表されるターゲットボリュームプロトコル。サポートされる単一の値には 'CIFS'nfsv3' または 'NFSv4.1 があります引数が定義されていない場合、デフォルトは「 nfsv3 」です。これを変更すると、新しいリソースが強制的に作成され、データが失われます。</block>
  <block id="cac15590a2775bfeaf5f70c36186a840" category="cell">* AZ_NetApp_vol_security_style *</block>
  <block id="80f43a817b6716a1a82af5fe18f178cd" category="cell">（任意）ボリュームセキュリティ形式。有効値は「 Unix 」または「 NTFS 」です。指定されない場合 ' 単一プロトコル・ボリュームは 'nfsv3' または 'nfsv3' ボリュームの場合は 'UNIX' にデフォルトで作成されますが 'CIFS' の場合は 'NTFS' にデフォルト設定されますデュアル・プロトコル・ボリュームでは ' 指定しない場合 'ntfs_' の値になります</block>
  <block id="b095a46d015fe5581a97472eedb3e645" category="cell">* AZ_NetApp_vol_storage_quota *</block>
  <block id="aaff31e02103a31c6f08943798a84789" category="cell">（必須）ファイルシステムに許可される最大ストレージクォータ（ギガバイト単位）。</block>
  <block id="7bc40f4d4f846e8c7177d752ac52b775" category="open-title">ANF データ保護</block>
  <block id="56978261632f1f36ad5f3f3ea6d2cb4b" category="paragraph">このセクションでは、 Azure でデータ保護を使用して ANF （ Azure NetApp Files ）ボリュームを導入 / 設定するためのさまざまな Terraform 設定ファイルについて説明します。</block>
  <block id="9b3e184737a0a337479622611ba072b7" category="list-text">vars/azure_anf_data_protection_tfvars の変数値を更新します。</block>
  <block id="bf052e3d77cd2cde5fa905542df51c46" category="paragraph">「 ANF データ保護」</block>
  <block id="ca374bb23355afcc469fefca9eb99ced" category="paragraph">データ保護が有効な単一の ANF ボリュームに対しては、 Terraform をさまざまに使用します。</block>
  <block id="17745d8782266e5f08c77485447c8727" category="cell">* AZ_alt_location *</block>
  <block id="3bfeadf4c47a658ca94a6066aee32aaa" category="cell">（必須）セカンダリボリュームを作成する Azure の場所</block>
  <block id="2558355ccfd79f11c2c7771d473c28a9" category="cell">* AZ_vnet_primary_address_space *</block>
  <block id="cc551875f8711aaffc6141f504677c0b" category="cell">（必須） ANF プライマリボリューム導入用として新しく作成した VNet が使用するアドレススペース。</block>
  <block id="ea5f0cd471c631d7531bb7fd3b5bac8a" category="cell">* AZ_vnet_secondary_address_space *</block>
  <block id="fffcb59495331e54049ce33d3dcdf943" category="cell">（必須） ANF セカンダリボリューム導入用として新しく作成した VNet が使用するアドレススペース。</block>
  <block id="88220764f0745e8a07a6578ee5a34962" category="cell">* AZ_subnet_primary_address_prefix *</block>
  <block id="02b00c599f6c249474a4fa82513b5ae3" category="cell">（必須） ANF プライマリボリューム導入用に新しく作成した VNet で使用するサブネットアドレスプレフィックスです。</block>
  <block id="1bef049d5f330664e35cad0a064c3b9c" category="cell">* AZ_subnet_secondary_address_prefix *</block>
  <block id="1b60506e52e47ecc443e5be52dca93d7" category="cell">（必須） ANF セカンダリボリューム導入用に新しく作成した VNet で使用するサブネットアドレスプレフィックスです。</block>
  <block id="897362b63a34b0eb8e1453709c1f8403" category="cell">* AZ_volume_path_primary *</block>
  <block id="1240d8345e0d2e3e79133040103d900c" category="cell">（必須）プライマリボリュームの一意のファイルパス。マウントターゲットの作成時に使用します。これを変更すると、新しいリソースが強制的に作成されます。</block>
  <block id="b9dd6d654f6dd5777451c38ccbb3a90f" category="cell">* AZ_volume_path_secondary *</block>
  <block id="2d48913a4e9f87154afa26a5629292ac" category="cell">（必須）セカンダリボリュームの一意のファイルパス。マウントターゲットの作成時に使用します。これを変更すると、新しいリソースが強制的に作成されます。</block>
  <block id="06c1e84417c5bf369b90b26dd5249917" category="cell">* AZ_capacity pool_size_primary *</block>
  <block id="3d618d26614058ac7e5a064cbe202b90" category="cell">* AZ_capacity pool_size_secondary *</block>
  <block id="900391b8f681698a00a1d7681c809eae" category="cell">* az_vnet_primary_creation_bool *</block>
  <block id="ee71ed057be46b5303595075681242b3" category="cell">（必須）プライマリボリューム用の新しい VNet を作成する場合は、このブーリアンを「 true 」に設定します。既存の VNet を使用するには、このパラメータを「 false 」に設定します。</block>
  <block id="1f3233bfcd515798625102d02489c9c2" category="cell">* az_vnet_secondary_creation_bool *</block>
  <block id="8a5a92fb6843cb45a9752dac34d8056a" category="cell">（必須）セカンダリボリューム用の新しい VNet を作成する場合は、このブーリアンを「 true 」に設定します。既存の VNet を使用するには、このパラメータを「 false 」に設定します。</block>
  <block id="0276da5ab0cbfd3afccac3236ff88906" category="cell">* az_subnet_primary_creation_bool *</block>
  <block id="ba2f66ccca4d07fb389900a4c72596a7" category="cell">（必須）このブール値を「 true 」に設定して、プライマリボリュームの新しいサブネットを作成します。既存のサブネットを使用する場合は 'false に設定します</block>
  <block id="78a2830c902a8a1eb6bbedc95b8e859d" category="cell">* az_subnet_secondary_creation_bool *</block>
  <block id="1b869ff43f405cb5056d067f1ce0ea2c" category="cell">（必須）セカンダリボリュームの新しいサブネットを作成するには、このブーリアンを「 true 」に設定します。既存のサブネットを使用する場合は 'false に設定します</block>
  <block id="004f2f461ceadcb0d344b03f2f00c53d" category="cell">* az _primary_subnet_id_for _anf_vol *</block>
  <block id="387a4516572f71aa24490f3bbfc695ef" category="cell">（必須）「 subnet_primary_creation_bool 」を true に設定して既存のサブネットを使用する場合に、サブネット ID を指定します。false に設定する場合は、デフォルト値のままにします。</block>
  <block id="2e9685846dda27855273fdf064f9e6ab" category="cell">* AZ_SECONDARY _subnet_id_on_anf_vol *</block>
  <block id="bf5c8bfc6d7cc2d5fe6e7931244a30eb" category="cell">（必須）「 subnet_secondary_creation_bool 」を true に設定して既存のサブネットを使用する場合に備えて、サブネット ID を指定します。false に設定する場合は、デフォルト値のままにします。</block>
  <block id="ac839f935b4bbb6bed9bda28a8e642c6" category="cell">* AZ_NetApp_POOL_SERVICE_LEVEL_PRIMARY *</block>
  <block id="8cb34f1d64a5bf358b0d3a349ca5bc2f" category="cell">* AZ_NetApp_POOL_SERVICE_LEVEL_SECONDARY *</block>
  <block id="7ad9306273877be4925eef5c298c8082" category="cell">* AZ_NetApp_vol_SERVICE_LEVEL_PRIMARY *</block>
  <block id="5614656fa00c06faf1c3484531a679a9" category="cell">* AZ_NetApp_vol_SERVICE_LEVEL_SECONDARY *</block>
  <block id="4f517398039e7c48806d41487b9419bc" category="cell">* AZ_NetApp_vol_protocol_primary *</block>
  <block id="82b777cb90770b16388fa42e12e046ab" category="cell">* AZ_NetApp_vol_protocol_secondary *</block>
  <block id="59783d86d863461df5e6d03ac2bb42df" category="cell">* AZ_NetApp_vol_storage_quota_policy_primary *</block>
  <block id="de8fa216337d1b3497efb08ceeb2ba75" category="cell">* AZ_NetApp_vol_storage_QUOTA_SECONDARY *</block>
  <block id="0b11ea56e0e5211214ff431c4e076717" category="cell">* AZ_DP_replication_frequency *</block>
  <block id="79ce3fc5fe45b145bb343376fe5351b9" category="cell">（必須）レプリケーション頻度。サポートされる値は「 10 分」、「時間単位」、「日単位」です。値は大文字と小文字が区別されます。</block>
  <block id="c623b4e11f7cb20ff0b7c24a72d3f0ef" category="open-title">ANF デュアルプロトコル</block>
  <block id="d25220d03f7afcb6f5edcbc46e369d45" category="paragraph">このセクションでは、 Azure でデュアルプロトコルを有効にした ANF （ Azure NetApp Files ）ボリュームを導入 / 設定するためのさまざまな Terraform 設定ファイルについて説明します。</block>
  <block id="9568461c901e88398bed16e11ad813d3" category="list-text">vars/azure_anf_dual_protocol.tfvars の変数値を更新します。</block>
  <block id="d263b475ab751de671d08455b33997c1" category="paragraph">デュアルプロトコルが有効な単一の ANF ボリューム用の Terraform 変数。</block>
  <block id="b183512797a1d9ea69a8dab9e27df52c" category="cell">* AZ_NetApp_vol_protocol1 *</block>
  <block id="20fd02f6a193c7aeaee651654a332933" category="cell">（必須）ターゲットボリュームプロトコル。リストで表されます。サポートされる単一の値には 'CIFS'nfsv3' または 'NFSv4.1 があります引数が定義されていない場合、デフォルトは「 nfsv3 」です。これを変更すると、新しいリソースが強制的に作成され、データが失われます。</block>
  <block id="cc032be5baf5b9484eb2d659f4e314c6" category="cell">* AZ_NetApp_vol_protocol2 *</block>
  <block id="910944ff76e7b2acfc482a34501df6f5" category="cell">* AZ_SMB_server_username *</block>
  <block id="152372e48ac8f85f2e4908c5a1489a78" category="cell">（必須） ActiveDirectory オブジェクトを作成するユーザ名。</block>
  <block id="239e5edf090c4c70025b340f651694cc" category="cell">* AZ_SMB_server_password *</block>
  <block id="7b05e834084d190fe540481374f4fe0d" category="cell">（必須） ActiveDirectory オブジェクトを作成するためのユーザパスワード。</block>
  <block id="4e2be381ec92158458ceef11bdf41ef7" category="cell">* AZ_SMB_SERVER_NAME*</block>
  <block id="533dd582bfe3528b9b6ae4ff1889bd8f" category="cell">（必須） ActiveDirectory オブジェクトを作成するサーバ名。</block>
  <block id="f17c01535ba9f04720700d5e0d17172a" category="cell">* AZ_SMB_DNS_servers *</block>
  <block id="e70256203c6e23fcee3efa8d56fcfa85" category="cell">（必須） ActiveDirectory オブジェクトを作成するための DNS サーバ IP 。</block>
  <block id="bdf618611712c6caa6fd0340470ee9f2" category="open-title">Snapshot からの ANF ボリューム</block>
  <block id="174e6e8f24023c93c7c470267f4c2376" category="paragraph">このセクションでは、 Azure 上の Snapshot から ANF （ Azure NetApp Files ）ボリュームを導入 / 設定するためのさまざまな Terraform 設定ファイルを示します。</block>
  <block id="215d5ed09cbe3ca5b10c6d616024053a" category="list-text">vars/azure_anf_volume_from_snapshot.tfvars の変数値を更新します。</block>
  <block id="a753ff452c91c6e4de63b907e8253e05" category="paragraph">Snapshot を使用する単一の ANF ボリューム用の変数を Terraform します。</block>
  <block id="57bd49c8f9a43967f48ec8f1f3ca2846" category="cell">* AZ_SNAPSHOT_ID *</block>
  <block id="ff461cb79e6adda28ae488782f0da97f" category="cell">（必須）新しい ANF ボリュームを作成する際に使用する Snapshot ID 。</block>
  <block id="6af253bfaad5b16a3b1d7d2892c1d583" category="paragraph">このセクションでは、 Azure でシングルノード CVO （ Cvloud Volumes ONTAP ）を導入 / 構成するためのさまざまな Terraform 構成ファイルを取り上げます。</block>
  <block id="04107ff6b0460381c55ff620a1021254" category="list-text">変数 \azure_CVO-SILE_NODE_deployment.tfvars の変数を更新します。</block>
  <block id="73b95097cc4819b49af28734c8da85f9" category="paragraph">単一ノードの Cloud Volumes ONTAP （ CVO ）用の Terraform 変数。</block>
  <block id="3226e634f46cb19ab313171144dd34bd" category="cell">* refresh_token *</block>
  <block id="d687ff26916f17fd879c87b138961b29" category="cell">（必須） NetApp Cloud Manager の更新トークン。これは NetApp Cloud Central から生成できます。</block>
  <block id="2c64afa8a46290b632eba256c644932c" category="cell">* AZ_Connector_name *</block>
  <block id="3eb8706ea09733709f78eddf34865fc5" category="cell">* AZ_Connector_location *</block>
  <block id="758699b195f5916d500521462cf30da9" category="cell">（必須） Cloud Manager Connector を作成する場所。</block>
  <block id="1fab22f54c2298a6c193e9dbf02a5f40" category="cell">* AZ_Connector_subscription_id *</block>
  <block id="3eaa20b60039584fbaada041b1e9c27b" category="cell">（必須） Azure サブスクリプションの ID 。</block>
  <block id="15a22866556f3e50073015243ddd7953" category="cell">* AZ_Connector_company *</block>
  <block id="d6da30a455e4a736b78aebafd5a574ec" category="cell">* AZ_Connector_resource_group *</block>
  <block id="7869ff24b2017b68dfcffe9346969d04" category="cell">（必須）リソースが作成される Azure 内のリソースグループ。</block>
  <block id="9ddf31c7bd196ef12b5afc14819332ae" category="cell">* AZ_Connector_subnet_id *</block>
  <block id="a41a332f5c3dda90835d004d4471e0a8" category="cell">（必須）仮想マシンのサブネットの名前です。</block>
  <block id="dabe6b258248c0eefb5e7f8ef812c828" category="cell">* AZ_Connector_vnet_id *</block>
  <block id="5209c2acb9f23446cfa41482e2ff8ee2" category="cell">（必須）仮想ネットワークの名前。</block>
  <block id="d00bbff7436422db546132791ca30dd2" category="cell">* AZ_Connector_network_security_group_name *</block>
  <block id="b5033b19e9c2388be995930fb1c49365" category="cell">（必須）インスタンスのセキュリティグループの名前。</block>
  <block id="54dee4dedf4b10ae9a250e887c349324" category="cell">* AZ_Connector_associate_public_IP_address *</block>
  <block id="c954a4a98e68d0734dcd6d7ad00db3f5" category="cell">（必須）仮想マシンにパブリック IP アドレスを関連付けるかどうかを指定します。</block>
  <block id="d363651cb914dfbc47f512db8ce8a9c0" category="cell">* AZ_Connector_account_id *</block>
  <block id="53b73bbe0bca0a3d51fbda15ecc058db" category="cell">（必須）コネクタを関連付けるネットアップアカウントの ID 。指定しない場合、 Cloud Manager は最初のアカウントを使用します。アカウントが存在しない場合、 Cloud Manager は新しいアカウントを作成します。アカウント ID は、 Cloud Manager のアカウントタブにあります<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>。</block>
  <block id="b851f892237fb399ca9999caee142ccf" category="cell">* AZ_Connector_admin_password *</block>
  <block id="aa98915ce83ffe89562020e5b4d9a376" category="cell">（必須）コネクタのパスワード。</block>
  <block id="1b9c1e319401f16966d7280c81cdc8dc" category="cell">* AZ_Connector_admin_username*</block>
  <block id="e0f32faffed9caaca61e86caae050f17" category="cell">（必須）コネクタのユーザ名。</block>
  <block id="425624e10c5de04d471a55e4a8b35e31" category="cell">* AZ_CVO-NAME *</block>
  <block id="52ebf6980a494c352ee150c2b801af6e" category="cell">* AZ_CVF_location*</block>
  <block id="722769acb8681ee52ccaaf29f539866d" category="cell">（必須）作業環境を作成する場所。</block>
  <block id="8da06548b40415fd473a86a6dba80f82" category="cell">* AZ_CVO-subnet_id *</block>
  <block id="8ad5f0c73733e0e6f16835416c9cc81a" category="cell">（必須）： Cloud Volumes ONTAP システムのサブネットの名前。</block>
  <block id="f71ced0388b772479b4e5fba15c83077" category="cell">* AZ_CVO-vnet_id *</block>
  <block id="0b3cb9636c3749b52c20181a74644b24" category="cell">（必須）仮想ネットワークの名前。</block>
  <block id="7d2219b61301dda6352db570bb7c5034" category="cell">* AZ_CVO-vnet_resource_group *</block>
  <block id="fecf56abdc6b5472c8da399cad7791b3" category="cell">（必須）仮想ネットワークに関連付けられた Azure 内のリソースグループ。</block>
  <block id="c63d2e90acb0448db277b1b5b8a8d1fa" category="cell">* AZ_CVO-data_encryption_type*</block>
  <block id="e472a1445850887a7f62ae832b27693a" category="cell">（必須）作業環境に使用する暗号化のタイプ： [Azure] 、 [none] 。デフォルトは「 azure 」です。</block>
  <block id="a09db82d06138c721102bb24bf44745c" category="cell">* AZ_CVO-storage_type *</block>
  <block id="0f0f84813d06e378040fbcf33a733c2c" category="cell">（必須）最初のデータ・アグリゲートのストレージ・タイプ： ['Premium_LRS'Standard_LRS'StandardSSD_LRS]デフォルトは 'Premium_LRS' です</block>
  <block id="2dc6453586c69ea950eec68d5ac9658c" category="cell">* AZ_CVO-svm_svm_svm_name * をクリックします</block>
  <block id="404c8599d393a19d0cd6354f8b6ae58c" category="cell">* AZ_CVO-workspace_id *</block>
  <block id="ec0d845babe316d32a485960e8788bd0" category="cell">（必須） Cloud Volumes ONTAP を導入する Cloud Manager ワークスペースの ID 。指定しない場合、 Cloud Manager は最初のワークスペースを使用します。ID は、の [ ワークスペース（ Workspace ） ] タブで確認できます<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>。</block>
  <block id="868f934d26dc5bf64ab570c48f38be79" category="cell">* AZ_CVF_capacity _tier *</block>
  <block id="e8dcbe7d10f08e94b9057a584009a175" category="cell">（必須）最初のデータ・アグリゲートのデータ階層化を有効にするかどうかを指定します（ [`lob`,'none`] ）デフォルトは「 BLOB 」です。</block>
  <block id="25390bc170c676096ec93edd61a5dca6" category="cell">* AZ_CVF_Writing _speed_state *</block>
  <block id="b632952868dfa1143652e0c226514318" category="cell">（必須） Cloud Volumes ONTAP の書き込み速度設定： [`normal`,`high`]デフォルトは「 normal 」です。この引数は HA ペアには関係ありません。</block>
  <block id="52742ffdac7415fc1d35c1a6d0d9fb7a" category="cell">* AZ_CVF_ONTAP_VERSION *</block>
  <block id="90e696b73ff714675fc926a955cc68e1" category="cell">（必須）必要な ONTAP のバージョン。「 use_latest_version 」が true に設定されている場合は無視されます。デフォルトでは最新バージョンが使用されます。</block>
  <block id="39a41303384652e186a359e5d96e8014" category="cell">* AZ_CVF_INSTANY_TYPE *</block>
  <block id="fb03bbd04a925d04740ba3d3eae2e8b6" category="cell">（必須）選択したライセンスタイプに応じて使用するインスタンスのタイプ。 Explore ： [`Standard_DS3_v2'Standard ： [`Standard_DS4_v2'Standard_DS13_v2'Standard_L8s_v2'Premium ： ['Standard_DS5_v2''Standard_DS14_v2'v2''Pay_DS3_v2''''PAY'v2 インスタンスタイプごとに定義された BYOL ：すべてのライセンスタイプサポートされるインスタンスタイプの詳細については、 Cloud Volumes ONTAP リリースノートを参照してください。デフォルトは 'Standard_DS4_v2' です</block>
  <block id="c0abbc4097de55ad558bd265d5e19b2e" category="cell">* AZ_CVF_LICENSE_TYPE *</block>
  <block id="337fb3a0d6e4f27fa4187c6e10b9d41b" category="cell">（必須）使用するライセンスのタイプ。シングルノードの場合： [`azure-CO-EXPLORT-paygo`,`azure-CO-standard-paygo`,azure-CO-Premium-paygo`,`azure-paygo`]HA の場合 : [`azure-HA-COT -standard-paygo`, azure-HA-COT -Premium-paygo`, azure-HA-COT -Premium-BYOL `, HA-capacity-paygo`]デフォルトは「 azure-CO-standard-paygo 」です。「 Capacity-paygo 」または「 HA-Capacity-paygo 」を使用して、「 Bring Your Own License Type Capacity Based 」または「 Freemium 」を選択します。「 Bring Your Own License Type Node-Based 」を選択した場合は、「 azure-CO-Premium-BYOL 」または「 azure-HA-CO-Premium-BYOL 」を使用します。</block>
  <block id="5e952a0432dfc8995121e15b76aa554a" category="cell">* AZ_CVF_NSS_ACCOUNT *</block>
  <block id="c3ae78309504c231f8afd5bc3790d119" category="cell">（必須）この Cloud Volumes ONTAP システムで使用するネットアップサポートサイトのアカウント ID 。ライセンスタイプが BYOL で、 NSS アカウントが指定されていない場合、 Cloud Manager は最初の既存の NSS アカウントの使用を試みます。</block>
  <block id="e7e63db47174977525dadf7a52fc6b39" category="cell">* AZ_tenant_id *</block>
  <block id="66093475775d81b74da52f4377ff5ce5" category="cell">（必須） Azure に登録されているアプリケーション / サービスプリンシパルのテナント ID 。</block>
  <block id="7934d010494793aec0f365d710cdf720" category="cell">* AZ_application_id *</block>
  <block id="587bfaa720a64e832c9eef635797e8d8" category="cell">（必須） Azure に登録されているアプリケーション / サービスプリンシパルのアプリケーション ID 。</block>
  <block id="67830019a9948cfd51759684b5f8a262" category="cell">* AZ_application_key *</block>
  <block id="56d6515673e3c08156696c47a943c020" category="cell">（必須） Azure に登録されているアプリケーション / サービスプリンシパルのアプリケーションキー。</block>
  <block id="eebf102c9b4ea2f3eac16cf21640a1d5" category="paragraph">このセクションでは、 Azure 上で CVO （ Cloud Volumes ONTAP ） HA （ハイアベイラビリティ）を導入 / 構成するためのさまざまな Terraform 構成ファイルを取り上げます。</block>
  <block id="522a4529185faee9fa34a9398ab7263f" category="list-text">変数 \azure_CVF_HA_deployment.tfvars の変数を更新します。</block>
  <block id="e2da3e968f76091801635ce624569dcb" category="paragraph">HA ペア・インスタンス</block>
  <block id="86ed32721429fbcc7b5e123836e3ebcd" category="paragraph">HA ペアの Cloud Volumes ONTAP （ CVO ）の変数は Terraform です。</block>
  <block id="72170ff3a9ca936d7855297f0bbd1eeb" category="cell">（必須）選択したライセンスタイプに応じて使用するインスタンスのタイプ。 Explore ： [`Standard_DS3_v2'Standard ： [`Standard_DS4_v2'Standard_DS13_v2'Standard_L8s_v2'Premium ： [`Standard_DS5_v2', 'Standard_DS14_v2''BYOL ： PAYGO 用に定義されたすべてのインスタンス・タイプサポートされるインスタンスタイプの詳細については、 Cloud Volumes ONTAP リリースノートを参照してください。デフォルトは 'Standard_DS4_v2' です</block>
  <block id="b515d8e49b6ef626aa91dbd970708132" category="cell">（必須）使用するライセンスのタイプ。シングルノードの場合： [`azure-CO-EXPLOR-paygo, azure-CO-standard-paygo, azure-CO-Premium-pole-BYOL 、 capacity-paygo`]HA の場合： [`azure-HA-COT-standard-paygo, azure-HA-CO-Premium-paygo, azure-HA-CO-Premium-BYOL 、 HA-capacity-paygo`]デフォルトは「 azure-CO-standard-paygo 」です。「 Capacity-paygo 」または「 HA-Capacity-paygo 」を使用して、「 Bring Your Own License Type Capacity Based 」または「 Freemium 」を選択します。「 Bring Your Own License Type Node-Based 」を選択した場合は、「 azure-CO-Premium-BYOL 」または「 azure-HA-CO-Premium-BYOL 」を使用します。</block>
</blocks>